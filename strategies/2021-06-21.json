[
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1624260028.234600",
        "client_msg_id": "f92e4b68-8ada-4982-9d51-2df4d8d48bc5",
        "text": "You could try log again (i.e. double log transform)",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624178227.159100",
        "parent_user_id": "U01B8031PM1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3SgWi",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "You could try log again (i.e. double log transform)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01B8031PM1",
        "type": "message",
        "ts": "1624260050.234800",
        "client_msg_id": "d21b3802-88d7-43c6-9fc9-7f5c5c14a4d2",
        "text": "its logs all the way down",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6e482a0e41b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6e482a0e41b232f48d801454006dfa56.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "river_shah",
            "real_name": "river_shah",
            "display_name": "river_shah",
            "team": "T4G9NBD2M",
            "name": "ansar.sa",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624178227.159100",
        "parent_user_id": "U01B8031PM1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZOFaH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "its logs all the way down"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UPMUFSGCR",
        "type": "message",
        "ts": "1624260110.235000",
        "client_msg_id": "841a4f12-a392-45ba-ad97-7e25b8fc6025",
        "text": "In terms of understanding what a double log would mean, from a \"human understanding\" perspective, what would a double log mean?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "31c0bb5a442c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-10-28\/812386967189_31c0bb5a442c5b8d2c61_72.png",
            "first_name": "Jon",
            "real_name": "Jon Jon Jon Jon Jon Jon Jon Jon",
            "display_name": "Jonjonjon",
            "team": "T4G9NBD2M",
            "name": "fcmisc",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624178227.159100",
        "parent_user_id": "U01B8031PM1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "iFXb",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In terms of understanding what a double log would mean, from a \"human understanding\" perspective, what would a double log mean?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1624260133.235200",
        "client_msg_id": "1ed716ef-7b5b-41df-b850-9488447a1822",
        "text": ":man-shrugging:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624178227.159100",
        "parent_user_id": "U01B8031PM1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "k3X2a",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "emoji",
                                "name": "man-shrugging",
                                "unicode": "1f937-200d-2642-fe0f"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1624260178.235400",
        "client_msg_id": "7762ba8a-0da2-4183-bbb7-c87df1492b90",
        "text": "Broadly speaking I would prefer not to apply any transformations and use an appropriate model for the data as is",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624178227.159100",
        "parent_user_id": "U01B8031PM1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "UTrYw",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Broadly speaking I would prefer not to apply any transformations and use an appropriate model for the data as is"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UPMUFSGCR"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UPMUFSGCR",
        "type": "message",
        "ts": "1624262379.235700",
        "edited": {
            "user": "UPMUFSGCR",
            "ts": "1624263695.000000"
        },
        "client_msg_id": "d1def2a2-65b5-449e-92db-d5da502aa9f2",
        "text": "my target variable is \"entry price\" \/ \"exit price\" -1. Which is essentially a function of 2 decimal prices.\n\nI might try taking inspiration from <https:\/\/en.wikipedia.org\/wiki\/Logistic_regression#Formal_mathematical_specification|logistic regression> for my next step.\n\nHas anyone else tried doing regression on similar variables?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "31c0bb5a442c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2019-10-28\/812386967189_31c0bb5a442c5b8d2c61_72.png",
            "first_name": "Jon",
            "real_name": "Jon Jon Jon Jon Jon Jon Jon Jon",
            "display_name": "Jonjonjon",
            "team": "T4G9NBD2M",
            "name": "fcmisc",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624178227.159100",
        "parent_user_id": "U01B8031PM1",
        "attachments": [
            {
                "title": "Logistic regression",
                "title_link": "https:\/\/en.wikipedia.org\/wiki\/Logistic_regression#Formal_mathematical_specification",
                "from_url": "https:\/\/en.wikipedia.org\/wiki\/Logistic_regression#Formal_mathematical_specification",
                "author_name": "Wikipedia",
                "author_link": "https:\/\/en.wikipedia.org\/",
                "text": "In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass\/fail, win\/lose, alive\/dead or healthy\/sick.  This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc.  Each object being detected in the image would be assigned a probability between 0 and 1, with a sum of one.\nLogistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression). Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass\/fail which is represented by an indicator variable, where the two values are labeled \"0\" and \"1\". In the logistic model, the log-odds (the logarithm of the odds) for the value labeled \"1\" is a linear combination of one or more independent variables (\"predictors\"); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value). The corresponding probability of the value labeled \"1\" can vary between 0 (certainly the value \"0\") and 1 (certainly the value \"1\"), hence the labeling; the function that converts log-odds to probability is the logistic function, hence the name. The unit of measurement for the log-odds scale is called a logit, from logistic unit, hence the alternative names. Analogous models with a different sigmoid function instead of the logistic function can also be used, such as the probit model; the defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio.\nIn a binary logistic regression model, the dependent variable has two levels (categorical). Outputs with more than two values are modeled by multinomial logistic regression and, if the multiple categories are ordered, by ordinal logistic regression (for example the proportional odds ordinal logistic model). The logistic regression model itself simply models probability of output in terms of input and does not perform statistical classification (it is not a classifier), though it can be used to make a classifier, for instance by choosing a cutoff value and classifying inputs with probability greater than the cutoff as one class, below the cutoff as the other; this is a common way to make a binary classifier. The coefficients are generally not computed by a closed-form expression, unlike linear least squares; see § Model fitting. The logistic regression as a general statistical model was originally developed and popularized primarily by Joseph Berkson, beginning in Berkson (1944), where he coined \"logit\"; see § History.",
                "fallback": "wikipedia: Logistic regression",
                "service_icon": "https:\/\/a.slack-edge.com\/80588\/img\/unfurl_icons\/wikipedia.png",
                "id": 1,
                "original_url": "https:\/\/en.wikipedia.org\/wiki\/Logistic_regression#Formal_mathematical_specification"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ohFg",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "my target variable is \"entry price\" \/ \"exit price\" -1. Which is essentially a function of 2 decimal prices.\n\nI might try taking inspiration from "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/en.wikipedia.org\/wiki\/Logistic_regression#Formal_mathematical_specification",
                                "text": "logistic regression"
                            },
                            {
                                "type": "text",
                                "text": " for my next step.\n\nHas anyone else tried doing regression on similar variables?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "subtype": "channel_join",
        "user": "U025UEXC1QC",
        "text": "<@U025UEXC1QC> has joined the channel",
        "type": "message",
        "ts": "1624267138.236200"
    },
    {
        "user": "U9JHLMZB4",
        "type": "message",
        "ts": "1624271292.236800",
        "client_msg_id": "153a74da-43c4-4d7f-b093-506df823a4d8",
        "text": "Two parts to this response.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g951ddcb43e7",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3951ddcb43e788a387d6daf330dad5ca.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0018-72.png",
            "first_name": "",
            "real_name": "Peter Coles",
            "display_name": "Peter",
            "team": "T4G9NBD2M",
            "name": "peter",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624221812.216000",
        "parent_user_id": "U9JHLMZB4",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "pjbHf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Two parts to this response."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U9JHLMZB4",
        "type": "message",
        "ts": "1624271294.237000",
        "client_msg_id": "75f9edd1-40b4-4c2c-b4bd-814dc45c7ca0",
        "text": "1) Pandas is very good at handling huge amounts of data. But a single market file also contains a huge amount of data, so if I'm developing a strategy with a year's worth of GB greyhound data, that's 40,000 x huge = overwhelming. So I work initially in Pandas with data from representative points in time from the start, just to make the process manageable.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g951ddcb43e7",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3951ddcb43e788a387d6daf330dad5ca.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0018-72.png",
            "first_name": "",
            "real_name": "Peter Coles",
            "display_name": "Peter",
            "team": "T4G9NBD2M",
            "name": "peter",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624221812.216000",
        "parent_user_id": "U9JHLMZB4",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hIp",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "1) Pandas is very good at handling huge amounts of data. But a single market file also contains a huge amount of data, so if I'm developing a strategy with a year's worth of GB greyhound data, that's 40,000 x huge = overwhelming. So I work initially in Pandas with data from representative points in time from the start, just to make the process manageable."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U9JHLMZB4",
        "type": "message",
        "ts": "1624271315.237200",
        "client_msg_id": "f1dee733-d616-424d-8e59-2d18d7baabb4",
        "text": "2) Flumine's backtesting strategy includes a pretty good simulator to help assess whether the orders your strategy identifies will be matched or not and assesses profitability. Unless you're simply taking the prices on offer, that's vital to understanding whether your strategy has a chance when it comes into contact with an actual market.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g951ddcb43e7",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3951ddcb43e788a387d6daf330dad5ca.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0018-72.png",
            "first_name": "",
            "real_name": "Peter Coles",
            "display_name": "Peter",
            "team": "T4G9NBD2M",
            "name": "peter",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624221812.216000",
        "parent_user_id": "U9JHLMZB4",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gxNyh",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "2) Flumine's backtesting strategy includes a pretty good simulator to help assess whether the orders your strategy identifies will be matched or not and assesses profitability. Unless you're simply taking the prices on offer, that's vital to understanding whether your strategy has a chance when it comes into contact with an actual market."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U9JHLMZB4",
        "type": "message",
        "ts": "1624271350.237400",
        "edited": {
            "user": "U9JHLMZB4",
            "ts": "1624271395.000000"
        },
        "client_msg_id": "12044886-87b8-4146-b87d-0972a5c5062e",
        "text": "This is what <@UGV299K6H> is alluding to when he says that you need to know \"whether you can expect to get matched at a rate sufficient to overcome adverse selection\". I'd say that about half the promising strategies that I construct just from data, simply don't pan out once executional and matching issues are factored in.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g951ddcb43e7",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3951ddcb43e788a387d6daf330dad5ca.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0018-72.png",
            "first_name": "",
            "real_name": "Peter Coles",
            "display_name": "Peter",
            "team": "T4G9NBD2M",
            "name": "peter",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624221812.216000",
        "parent_user_id": "U9JHLMZB4",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "yPGE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This is what "
                            },
                            {
                                "type": "user",
                                "user_id": "UGV299K6H"
                            },
                            {
                                "type": "text",
                                "text": " is alluding to when he says that you need to know \"whether you can expect to get matched at a rate sufficient to overcome adverse selection\". I'd say that about half the promising strategies that I construct just from data, simply don't pan out once executional and matching issues are factored in."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UGV299K6H",
        "type": "message",
        "ts": "1624272430.237700",
        "edited": {
            "user": "UGV299K6H",
            "ts": "1624272469.000000"
        },
        "client_msg_id": "e0247c62-223e-442b-b4fc-333369cfd3e2",
        "text": "In terms of workflow I also do all analysis in jupyter notebook using Pandas. What I actually do is process every market file into an equivalent compressed csv which includes all derived variables. Then I extract the subset of data points that I'm interested in from each market file into another CSV and load that up into my notebook.  So maybe I want 1\/5th of all instances where 1.5 &lt; best available back price &lt; 2 or whatever. That way I don't have to re-process all my markets every time I want a different data set, just relatively quickly extract what I need. I do both the initial processing and the extraction using multiprocessing and when I get frustrated by slowness I buy a new computer.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g3a262a3cfba",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b3a262a3cfba292c18acf5777f65908a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png",
            "first_name": "Michael",
            "real_name": "Michael C",
            "display_name": "Michael",
            "team": "T4G9NBD2M",
            "name": "michael",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1624221812.216000",
        "parent_user_id": "U9JHLMZB4",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "n0Suh",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In terms of workflow I also do all analysis in jupyter notebook using Pandas. What I actually do is process every market file into an equivalent compressed csv which includes all derived variables. Then I extract the subset of data points that I'm interested in from each market file into another CSV and load that up into my notebook.  So maybe I want 1\/5th of all instances where 1.5 < best available back price < 2 or whatever. That way I don't have to re-process all my markets every time I want a different data set, just relatively quickly extract what I need. I do both the initial processing and the extraction using multiprocessing and when I get frustrated by slowness I buy a new computer."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01PJ5YMFBJ",
        "type": "message",
        "ts": "1624309643.249900",
        "client_msg_id": "6fb7be75-85d7-44db-922a-05fc3b5dd563",
        "text": "So ive done sone reading about pandas, linear regression and stuff, and now what youre saying <@U9JHLMZB4> <@U4H19D1D2> <@UGV299K6H> makes great sense, a bit of an eye opener actually!\nSo it all sounds too simple though in an odd sort of way, dump a selection of market files with what you see as useful derived values into a csv, load into pandas, LinearRegression using sklearn, hey presto you have an equation to predicate an outcome say \"fair value\" from market values. Obviously a lot of variables there, choice of derived variables, timeframes,.....potentially a huge number, needing a decent computer to crunch! But I didn't think it could come down to just computing an equation...?\nSounds great though, i will make some baby steps maybe with 1 variable just to understand the framework...\nCheers",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g819c7f591cc",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/819c7f591cc888486f19b3f2f49f2011.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png",
            "first_name": "AndyL",
            "real_name": "AndyL",
            "display_name": "AndyL",
            "team": "T4G9NBD2M",
            "name": "andrew_m_leonard",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mw8CP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So ive done sone reading about pandas, linear regression and stuff, and now what youre saying "
                            },
                            {
                                "type": "user",
                                "user_id": "U9JHLMZB4"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "user",
                                "user_id": "U4H19D1D2"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "user",
                                "user_id": "UGV299K6H"
                            },
                            {
                                "type": "text",
                                "text": " makes great sense, a bit of an eye opener actually!\nSo it all sounds too simple though in an odd sort of way, dump a selection of market files with what you see as useful derived values into a csv, load into pandas, LinearRegression using sklearn, hey presto you have an equation to predicate an outcome say \"fair value\" from market values. Obviously a lot of variables there, choice of derived variables, timeframes,.....potentially a huge number, needing a decent computer to crunch! But I didn't think it could come down to just computing an equation...?\nSounds great though, i will make some baby steps maybe with 1 variable just to understand the framework...\nCheers"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "rocket",
                "users": [
                    "UPMUFSGCR"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U01PJ5YMFBJ",
        "type": "message",
        "ts": "1624309864.251700",
        "client_msg_id": "9f3bf102-b201-4a26-8834-12979c1ae3ca",
        "text": "Im guessing the 'sauce', is in the \"derivations\", ie.how you create some value based on matched money, available money,.....",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g819c7f591cc",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/819c7f591cc888486f19b3f2f49f2011.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0014-72.png",
            "first_name": "AndyL",
            "real_name": "AndyL",
            "display_name": "AndyL",
            "team": "T4G9NBD2M",
            "name": "andrew_m_leonard",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "L4cXP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Im guessing the 'sauce', is in the \"derivations\", ie.how you create some value based on matched money, available money,....."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]