[
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1732377025.890449",
        "client_msg_id": "dfd5cfd2-7e50-4550-af14-71e337de0b1c",
        "text": "Does anyone convert recorded price stream data into another format (e.g. full market books stored in HDF5) to facilitate:\n\n1. Faster deserialisation\n2. Random access lookup of market books\n3. Lazy evaluation of market book fields\netc.?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "reply_count": 32,
        "reply_users_count": 12,
        "latest_reply": "1732629610.680379",
        "reply_users": [
            "UUE6E1LA1",
            "UBS7QANF3",
            "U05N9773A23",
            "U03FS7KM2NL",
            "U07SPFFN010",
            "U04H54Q392N",
            "U4H19D1D2",
            "US2RWCWKY",
            "U012XF5CNPN",
            "U05L8PZD2FM",
            "U028Z5T4AF6",
            "U80AMMRKP"
        ],
        "replies": [
            {
                "user": "UUE6E1LA1",
                "ts": "1732377825.461439"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732378676.897769"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732379152.843129"
            },
            {
                "user": "UUE6E1LA1",
                "ts": "1732380751.074619"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732382228.661029"
            },
            {
                "user": "UUE6E1LA1",
                "ts": "1732382970.672919"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732383165.536689"
            },
            {
                "user": "U05N9773A23",
                "ts": "1732388137.489879"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732389010.939689"
            },
            {
                "user": "U05N9773A23",
                "ts": "1732389670.619359"
            },
            {
                "user": "U03FS7KM2NL",
                "ts": "1732390951.781309"
            },
            {
                "user": "U03FS7KM2NL",
                "ts": "1732390980.481499"
            },
            {
                "user": "U07SPFFN010",
                "ts": "1732393994.717049"
            },
            {
                "user": "U04H54Q392N",
                "ts": "1732399938.062839"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732446779.760249"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1732453838.948059"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732458170.706919"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732458200.880389"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732458222.596949"
            },
            {
                "user": "U03FS7KM2NL",
                "ts": "1732458341.796589"
            },
            {
                "user": "U07SPFFN010",
                "ts": "1732458342.199039"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732458715.699629"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1732460306.988059"
            },
            {
                "user": "U04H54Q392N",
                "ts": "1732460713.888959"
            },
            {
                "user": "U07SPFFN010",
                "ts": "1732461060.054329"
            },
            {
                "user": "US2RWCWKY",
                "ts": "1732491178.807199"
            },
            {
                "user": "US2RWCWKY",
                "ts": "1732491442.366039"
            },
            {
                "user": "U012XF5CNPN",
                "ts": "1732528889.204219"
            },
            {
                "user": "U05L8PZD2FM",
                "ts": "1732533300.189019"
            },
            {
                "user": "U028Z5T4AF6",
                "ts": "1732617370.144799"
            },
            {
                "user": "U028Z5T4AF6",
                "ts": "1732617635.191549"
            },
            {
                "user": "U80AMMRKP",
                "ts": "1732629610.680379"
            }
        ],
        "is_locked": false,
        "subscribed": true,
        "last_read": "1732629610.680379",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dZqq4",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Does anyone convert recorded price stream data into another format (e.g. full market books stored in HDF5) to facilitate:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Faster deserialisation"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Random access lookup of market books"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Lazy evaluation of market book fields"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\netc.?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1732377825.461439",
        "client_msg_id": "b2b31c03-259a-4b92-aaa4-62cc9c777303",
        "text": "I seem to remember asking something similar a couple of years ago. I fairly recently tried processing the data to a full timestamped market book in JSON format but the files were f***ing massive so I binned the idea. I was toying with the idea of using some kind of bespoke binary format to do the same but I ended up moving onto higher priority things. I seem to remember last time you were the only person who thought that it wasn't a shit idea to use a custom format to avoid having to recreate the market book every time you load up (but I might have that wrong).\n\nHave you made any progress in the area yourself?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7601Q",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I seem to remember asking something similar a couple of years ago. I fairly recently tried processing the data to a full timestamped market book in JSON format but the files were f***ing massive so I binned the idea. I was toying with the idea of using some kind of bespoke binary format to do the same but I ended up moving onto higher priority things. I seem to remember last time you were the only person who thought that it wasn't a shit idea to use a custom format to avoid having to recreate the market book every time you load up (but I might have that wrong).\n\nHave you made any progress in the area yourself?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1732378676.897769",
        "client_msg_id": "612a1899-507b-48fe-bbaa-fa54006b271d",
        "text": "No but about to embark on working on this and don't want to reinvent the wheel",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "R9YX\/",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "No but about to embark on working on this and don't want to reinvent the wheel"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1732379152.843129",
        "client_msg_id": "b2c659f7-5074-4e3a-b05f-37a3e59653a6",
        "text": "I'm surprised you didn't have a better response as this could massively speed up backtesting let alone facilitate all kinds of other analysis",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CM4rx",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm surprised you didn't have a better response as this could massively speed up backtesting let alone facilitate all kinds of other analysis"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1732380751.074619",
        "client_msg_id": "4d92ee0b-8db8-4612-9c34-7cbddac4dc39",
        "text": "IIRC the general opinion was that it wasn't worth the effort. I seem to remember maybe one or two people had tried but yours was the only receptive opinion to it. I think I specifically mentioned binary formats though and perhaps that was the source of the negative response.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mN+o+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "IIRC the general opinion was that it wasn't worth the effort. I seem to remember maybe one or two people had tried but yours was the only receptive opinion to it. I think I specifically mentioned binary formats though and perhaps that was the source of the negative response."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1732382228.661029",
        "client_msg_id": "7f41d15a-6e15-49ee-a63a-c212ab6ab63f",
        "text": "Binary format seems like the way to go to me",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uOAwE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Binary format seems like the way to go to me"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1732382970.672919",
        "client_msg_id": "48cf584e-570d-4a7d-9598-c9a9f5d8c41c",
        "text": "Yeah me too but that's just based on prior jobs. I did make some good old fashined pen and paper notes on some ideas I had about it. Might see if I can dig them up. Not that I'd ever be using it for a task like this but Is it easy in python to do things like bit twiddling?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "LdaMI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah me too but that's just based on prior jobs. I did make some good old fashined pen and paper notes on some ideas I had about it. Might see if I can dig them up. Not that I'd ever be using it for a task like this but Is it easy in python to do things like bit twiddling?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1732383165.536689",
        "client_msg_id": "084507de-c05d-4aa9-b976-b9ba0df41546",
        "text": "No idea to be honest. I think I'd probably be offloading a lot of stuff you might have in mind to off the shelf packages",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gn7JG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "No idea to be honest. I think I'd probably be offloading a lot of stuff you might have in mind to off the shelf packages"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1732388137.489879",
        "client_msg_id": "d21ca589-15a2-44fb-b5ee-5d8185652f73",
        "text": "I do all my backtesting in a polars dataframe so I flatten the raw files and convert to .parquet",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "5YFHX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I do all my backtesting in a polars dataframe so I flatten the raw files and convert to .parquet"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1732389010.939689",
        "client_msg_id": "020d85a0-8a9a-412c-a506-12e6974a13dc",
        "text": "How do you handle the variable length arrays of prices?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "FKYL6",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "How do you handle the variable length arrays of prices?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1732389670.619359",
        "client_msg_id": "50663f42-a6b0-42a9-8c8d-805ff6e2244a",
        "text": "You could use a column of type List[Float32], polars handles list columns really well. Or you can just pad the price ladder with size available = 0. I don't require the full ladder so I just create columns for the n best prices and sizes at each timestamp.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "j1RIz",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "You could use a column of type List[Float32], polars handles list columns really well. Or you can just pad the price ladder with size available = 0. I don't require the full ladder so I just create columns for the n best prices and sizes at each timestamp."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UBS7QANF3"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U03FS7KM2NL",
        "type": "message",
        "ts": "1732390951.781309",
        "client_msg_id": "1788AF7B-1BE8-47B1-9BCA-4F8540008C34",
        "text": "Thumbs up for parquet and the fixed number of levels with padding",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g160a197a059",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/160a197a059d9b97aabdd95ca66dc341.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0026-72.png",
            "first_name": "Ralegh",
            "real_name": "Ralegh",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "ralegh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gS9VO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thumbs up for parquet and the fixed number of levels with padding"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03FS7KM2NL",
        "type": "message",
        "ts": "1732390980.481499",
        "client_msg_id": "F9160377-4B4E-41BB-BF25-5CE46D8BB635",
        "text": "If you have a use case you probably know how many levels you need",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g160a197a059",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/160a197a059d9b97aabdd95ca66dc341.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0026-72.png",
            "first_name": "Ralegh",
            "real_name": "Ralegh",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "ralegh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "EJfpv",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If you have a use case you probably know how many levels you need"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U07SPFFN010",
        "type": "message",
        "ts": "1732393994.717049",
        "client_msg_id": "48403fdf-0b9a-46b6-913f-08a248b47086",
        "text": "I'm new to this, but I store live esa and historical data in xtdb. previously, it was just in an binary format, which meant I had to read the whole file to query the market. xtdb time slices are pretty much instant, and allows me to play with many markets at once. drawback is it takes quite the amount of disk space",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "013148a74023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-10-20\/7910027379108_013148a74023365902a3_72.png",
            "first_name": "Jhonny",
            "real_name": "Jhonny",
            "display_name": "Jhonny",
            "team": "T4G9NBD2M",
            "name": "olajeremy123",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "PR6wV",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm new to this, but I store live esa and historical data in xtdb. previously, it was just in an binary format, which meant I had to read the whole file to query the market. xtdb time slices are pretty much instant, and allows me to play with many markets at once. drawback is it takes quite the amount of disk space"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04H54Q392N",
        "type": "message",
        "ts": "1732399938.062839",
        "client_msg_id": "e2603117-a3e9-48ed-b793-2b48d912ea00",
        "text": "not exactly what you asked, but I moved away from the stream JSON format in my engine. The input is of course still JSON as from the stream, but I parse it straight into a point-in-time representation (practically just an array) which is only allocated once, so avoids the creation of a whole bunch of hashes and lists that then get thrown away every update. It makes processing a whole load faster - more of a point1 thing. This applies to both back testing and real world when done like this. In theory a timeseries of the point-in-time version could be something to get fancy with in serialisation\/deserialisation e.g. arrow for a more natural representation, or something smarter re. compression maybe along the lines of gorilla timeseries compression.\n\nregarding lookups, I've been aiming to do pre-processing to extract metadata like the market definitions, to place alongside market recordings. It should works fairly nicely in the archive format you get from the historical data API i.e. tar containing files for individual markets + combined streams. At the moment the best I actually do re. lookups is just reading the first message of a market's recording to determine if it matches the market filter, but if not skip on.\n\nDoing that with fairly speedy disk (NVMe), a memory mapped .tar of recordings, and reading in a separate thread, doesn't feel bad even with implementations that have a load to `TODO: simplify\/speed up\/profile` littered throughout them. It takes about ~2m to go through a day of UK WIN horse racing markets, picking them out from all UK horse racing markets for a day.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "922f15b4653c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-11-24\/8061990184023_922f15b4653c337eadd3_72.jpg",
            "first_name": "Oliver",
            "real_name": "Oliver",
            "display_name": "Oliver",
            "team": "T4G9NBD2M",
            "name": "evilumbrella",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1732377025.890449",
        "parent_user_id": "UBS7QANF3",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zS\/z5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "not exactly what you asked, but I moved away from the stream JSON format in my engine. The input is of course still JSON as from the stream, but I parse it straight into a point-in-time representation (practically just an array) which is only allocated once, so avoids the creation of a whole bunch of hashes and lists that then get thrown away every update. It makes processing a whole load faster - more of a point1 thing. This applies to both back testing and real world when done like this. In theory a timeseries of the point-in-time version could be something to get fancy with in serialisation\/deserialisation e.g. arrow for a more natural representation, or something smarter re. compression maybe along the lines of gorilla timeseries compression.\n\nregarding lookups, I've been aiming to do pre-processing to extract metadata like the market definitions, to place alongside market recordings. It should works fairly nicely in the archive format you get from the historical data API i.e. tar containing files for individual markets + combined streams. At the moment the best I actually do re. lookups is just reading the first message of a market's recording to determine if it matches the market filter, but if not skip on.\n\nDoing that with fairly speedy disk (NVMe), a memory mapped .tar of recordings, and reading in a separate thread, doesn't feel bad even with implementations that have a load to "
                            },
                            {
                                "type": "text",
                                "text": "TODO: simplify\/speed up\/profile",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " littered throughout them. It takes about ~2m to go through a day of UK WIN horse racing markets, picking them out from all UK horse racing markets for a day."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]