[
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679837144.844899",
        "edited": {
            "user": "U016TGY3676",
            "ts": "1679837448.000000"
        },
        "client_msg_id": "664a1be3-e61e-4f39-a676-4a6ae896f9b9",
        "text": "As a complete noob to ML, etc, I'm playing around with sklearn and LogisticRegression with a target variable of runner win\/lose based on market data generated signals. I'm trying to understand the metrics, which are as follows:\n`Accuracy: 0.8346274074821014\nPrecision: 0.8353535353535354\nRecall: 0.998792270531401\nF1-score: 0.9097909790979097\nMSE: 0.16537259251789857`\n\nOn paper, it looks like a reasonable model, however the implied probability of my matched prices in the dataset is `~0.84`. If I understand correctly, I would need to get to an `accuracy` score &gt; matched implied probability?\nEdit: to add some further context, my dataset is a betting history with ~50K bets on 1000 markets and i'm using an 80\/20 split.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "reply_count": 33,
        "reply_users_count": 4,
        "latest_reply": "1679948062.870689",
        "reply_users": [
            "U04AD6RAGGH",
            "U016TGY3676",
            "U9JHLMZB4",
            "UEA14GBRR"
        ],
        "replies": [
            {
                "user": "U04AD6RAGGH",
                "ts": "1679838207.550909"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679838703.141779"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679843363.122429"
            },
            {
                "user": "U9JHLMZB4",
                "ts": "1679845702.582339"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679848123.122869"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679848651.475139"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679848824.504019"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679849027.589989"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679849212.686989"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679849377.983359"
            },
            {
                "user": "U9JHLMZB4",
                "ts": "1679849857.904899"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679852192.603709"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679852955.352019"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679852991.902129"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679854670.419979"
            },
            {
                "user": "UEA14GBRR",
                "ts": "1679855661.997439"
            },
            {
                "user": "UEA14GBRR",
                "ts": "1679855665.057429"
            },
            {
                "user": "UEA14GBRR",
                "ts": "1679855803.705199"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679856054.463639"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679856097.229589"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679856738.856479"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679859520.518359"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679861205.773079"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679863427.831179"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679918611.059149"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679928890.819499"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679934141.181029"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679940656.134579"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679942140.299129"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679944781.737899"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679944885.205979"
            },
            {
                "user": "U016TGY3676",
                "ts": "1679947037.802269"
            },
            {
                "user": "U04AD6RAGGH",
                "ts": "1679948062.870689"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gmqY=",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "As a complete noob to ML, etc, I'm playing around with sklearn and LogisticRegression with a target variable of runner win\/lose based on market data generated signals. I'm trying to understand the metrics, which are as follows:\n"
                            },
                            {
                                "type": "text",
                                "text": "Accuracy: 0.8346274074821014\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "Precision: 0.8353535353535354\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "Recall: 0.998792270531401\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "F1-score: 0.9097909790979097\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "MSE: 0.16537259251789857",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\nOn paper, it looks like a reasonable model, however the implied probability of my matched prices in the dataset is "
                            },
                            {
                                "type": "text",
                                "text": "~0.84",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". If I understand correctly, I would need to get to an "
                            },
                            {
                                "type": "text",
                                "text": "accuracy",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " score > matched implied probability?\nEdit: to add some further context, my dataset is a betting history with ~50K bets on 1000 markets and i'm using an 80\/20 split."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679838207.550909",
        "client_msg_id": "6b15152e-dfb6-4444-b67c-664358625c53",
        "text": "Roughly speaking, yes.\n\nNot roughly speaking, it depends.  I tend to go and compute accuracies (and then expected values) at various odds so I can see a more detailed view.\n\n0.834 is your global acc.  but it might be higher or lower in specific predictable cases.\n\nCan I ask what kind of features you have?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "TnR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Roughly speaking, yes.\n\nNot roughly speaking, it depends.  I tend to go and compute accuracies (and then expected values) at various odds so I can see a more detailed view.\n\n0.834 is your global acc.  but it might be higher or lower in specific predictable cases.\n\nCan I ask what kind of features you have?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679838703.141779",
        "client_msg_id": "4ebe7bd1-47fc-4b15-8ff1-5e5d5b092fb4",
        "text": "also, in case you didn't spot it there is a class called SGDClassifier (<https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html>)\n\nThis is a nice gradient based method for various things, logistic regression being one of them.  Allows incremental learning too.\n\nI've found it to be a bit better than the LogisticRegression class (faster too IMO)",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "attachments": [
            {
                "from_url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html",
                "service_icon": "https:\/\/scikit-learn.org\/stable\/_static\/favicon.ico",
                "id": 1,
                "original_url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html",
                "fallback": "scikit-learn: sklearn.linear_model.SGDClassifier",
                "text": "Examples using sklearn.linear_model.SGDClassifier: Model Complexity Influence Model Complexity Influence Out-of-core classification of text documents Out-of-core classification of text documents Co...",
                "title": "sklearn.linear_model.SGDClassifier",
                "title_link": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html",
                "service_name": "scikit-learn"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lMbhZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "also, in case you didn't spot it there is a class called SGDClassifier ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html"
                            },
                            {
                                "type": "text",
                                "text": ")\n\nThis is a nice gradient based method for various things, logistic regression being one of them.  Allows incremental learning too.\n\nI've found it to be a bit better than the LogisticRegression class (faster too IMO)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679843363.122429",
        "client_msg_id": "d0822f97-ebd2-46e9-b022-333b94dbd590",
        "text": "Thanks <@U04AD6RAGGH>. So my features are signals generated from changes in price, volume, etc. The strategy is inplay horses, so my main concern is that it may be identifying that 1.01=winner, even though that's not always the case...\nWill look at SGD. I also have plans to use a similar model for predicting price movement, i.e. the binary target being `price_now &lt; price_previously`. Any advice on that?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gHuc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "U04AD6RAGGH"
                            },
                            {
                                "type": "text",
                                "text": ". So my features are signals generated from changes in price, volume, etc. The strategy is inplay horses, so my main concern is that it may be identifying that 1.01=winner, even though that's not always the case...\nWill look at SGD. I also have plans to use a similar model for predicting price movement, i.e. the binary target being "
                            },
                            {
                                "type": "text",
                                "text": "price_now < price_previously",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". Any advice on that?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U9JHLMZB4",
        "type": "message",
        "ts": "1679845702.582339",
        "edited": {
            "user": "U9JHLMZB4",
            "ts": "1679845750.000000"
        },
        "client_msg_id": "6a4085bf-469f-4739-b3b9-210459e601c7",
        "text": "I'm rather worried by your recall stat. It implies that you have have hardly any false negatives, which isn't really realistic with the sort of data we work with. I'm wondering whether you have an imbalanced class issue. Have you built a <https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html|confusion matrix> for your model's predictions?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g951ddcb43e7",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3951ddcb43e788a387d6daf330dad5ca.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0018-72.png",
            "first_name": "",
            "real_name": "Peter Coles",
            "display_name": "Peter",
            "team": "T4G9NBD2M",
            "name": "peter",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "attachments": [
            {
                "from_url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html",
                "service_icon": "https:\/\/scikit-learn.org\/stable\/_static\/favicon.ico",
                "id": 1,
                "original_url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html",
                "fallback": "scikit-learn: sklearn.metrics.confusion_matrix",
                "text": "Examples using sklearn.metrics.confusion_matrix: Visualizations with Display Objects Visualizations with Display Objects Label Propagation digits active learning Label Propagation digits active lea...",
                "title": "sklearn.metrics.confusion_matrix",
                "title_link": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html",
                "service_name": "scikit-learn"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "IzWLU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm rather worried by your recall stat. It implies that you have have hardly any false negatives, which isn't really realistic with the sort of data we work with. I'm wondering whether you have an imbalanced class issue. Have you built a "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html",
                                "text": "confusion matrix"
                            },
                            {
                                "type": "text",
                                "text": " for your model's predictions?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "bulb",
                "users": [
                    "U04AD6RAGGH"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679848123.122869",
        "client_msg_id": "22194603-cfc5-44ac-9e33-a804e93a02d5",
        "text": "<@U016TGY3676> I've considered directional forecasting in other scenarios (not horses) and it is usually more robust than regressing the price itself.\n\nHowever a simple rule like `price_now &lt;  price_prev` might get a bit noisy, depending on the window you use to compute this and the variance of price in that window.\n\nOne thing I like to do is fit an HMM with 2 or 3 hidden states, and use those as unsupervised labels for a classifier.  You can then predict regimes in the market, and build strategies for each regime.  This is a common enough technique.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CwBf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U016TGY3676"
                            },
                            {
                                "type": "text",
                                "text": " I've considered directional forecasting in other scenarios (not horses) and it is usually more robust than regressing the price itself.\n\nHowever a simple rule like "
                            },
                            {
                                "type": "text",
                                "text": "price_now <  price_prev",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " might get a bit noisy, depending on the window you use to compute this and the variance of price in that window.\n\nOne thing I like to do is fit an HMM with 2 or 3 hidden states, and use those as unsupervised labels for a classifier.  You can then predict regimes in the market, and build strategies for each regime.  This is a common enough technique."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679848651.475139",
        "client_msg_id": "3d49ae42-5cf7-4f08-8a0c-b2625e9f969a",
        "text": "<@U9JHLMZB4> Ermmm... confusion matrix...no, I'm still on day one of ML and that's only because chat GPT suggested it might be useful. :flushed: What sort of stat numbers would be normal\/expected using market data?\n\n<@U04AD6RAGGH> I'm very much a novice at this, I'm sure I'll understand what you're saying once I do some more studying. :grinning:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "S+0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U9JHLMZB4"
                            },
                            {
                                "type": "text",
                                "text": " Ermmm... confusion matrix...no, I'm still on day one of ML and that's only because chat GPT suggested it might be useful. "
                            },
                            {
                                "type": "emoji",
                                "name": "flushed",
                                "unicode": "1f633"
                            },
                            {
                                "type": "text",
                                "text": " What sort of stat numbers would be normal\/expected using market data?\n\n"
                            },
                            {
                                "type": "user",
                                "user_id": "U04AD6RAGGH"
                            },
                            {
                                "type": "text",
                                "text": " I'm very much a novice at this, I'm sure I'll understand what you're saying once I do some more studying. "
                            },
                            {
                                "type": "emoji",
                                "name": "grinning",
                                "unicode": "1f600"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679848824.504019",
        "client_msg_id": "50c574d6-295d-4bf8-9797-d1e1d9f1d89c",
        "text": "as a quick way to get started, try something like PyCaret\n <https:\/\/pycaret.readthedocs.io\/en\/stable\/index.html>\n\nIt'll give you exposure to a lot of different models, preprocessing steps, and visualizations like confusion matrices.  Great for quick model experimentation",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "KA86",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "as a quick way to get started, try something like PyCaret\n "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/pycaret.readthedocs.io\/en\/stable\/index.html"
                            },
                            {
                                "type": "text",
                                "text": "\n\nIt'll give you exposure to a lot of different models, preprocessing steps, and visualizations like confusion matrices.  Great for quick model experimentation"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679849027.589989",
        "client_msg_id": "5bd93939-b39a-4fc3-822f-fd3feae37457",
        "text": "One thing though, aside from all of these metrics: <http:\/\/nicolas.kruchten.com\/content\/2016\/01\/ml-meets-economics\/>\n\nPay attention to your metrics, but also pay attention to what constitutes \"good\".  Above is a great article on when a higher number isn't always best.\n\nThis is why measuring the Expected Value of your model is crucial.  Accuracy is great, Value is better :slightly_smiling_face:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "attachments": [
            {
                "from_url": "http:\/\/nicolas.kruchten.com\/content\/2016\/01\/ml-meets-economics\/",
                "service_icon": "http:\/\/nicolas.kruchten.com\/favicon.ico",
                "id": 1,
                "original_url": "http:\/\/nicolas.kruchten.com\/content\/2016\/01\/ml-meets-economics\/",
                "fallback": "Machine Learning Meets Economics",
                "text": "The business world is full of streams of items that need to be filtered or evaluated: parts on an assembly line, resum√©s in an application pile, emails in a delivery queue, transactions awaiting processing. Machine learning techniques are increasingly being used to make such processes more efficient: image processing to flag bad parts, text analysis to surface good candidates, spam filtering to sort email, fraud detection to lower transaction costs <http:\/\/etc.In|etc.In> this article, I show how you can take business factors into account when using machine learning to solve these kinds of problems with binary classifiers. Specifically, I show how the concept of expected utility from the field of economics maps onto the Receiver Operating Characteristic (ROC) space often used by machine learning practitioners to compare and evaluate models for binary classification. I begin with a parable illustrating the dangers of not taking such factors into account. This concrete story is followed by a more formal mathematical look at the use of indifference curves in ROC space to avoid this kind of problem and guide model development. I wrap up with some recommendations for successfully using binary classifiers to solve business problems.",
                "title": "Machine Learning Meets Economics",
                "title_link": "http:\/\/nicolas.kruchten.com\/content\/2016\/01\/ml-meets-economics\/",
                "service_name": "nicolas.kruchten.com"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "KdPH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "One thing though, aside from all of these metrics: "
                            },
                            {
                                "type": "link",
                                "url": "http:\/\/nicolas.kruchten.com\/content\/2016\/01\/ml-meets-economics\/"
                            },
                            {
                                "type": "text",
                                "text": "\n\nPay attention to your metrics, but also pay attention to what constitutes \"good\".  Above is a great article on when a higher number isn't always best.\n\nThis is why measuring the Expected Value of your model is crucial.  Accuracy is great, Value is better "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face",
                                "unicode": "1f642"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679849212.686989",
        "client_msg_id": "ea23546a-ba27-4600-aec7-0f007a9d5a19",
        "text": "Just for fun, chat GPT came up with this:\n`import pandas as pd\nfrom hmmlearn import hmm\n\n# Load data into pandas dataframe\ndf = pd.read_csv(\"market_data.csv\")\n\n# Define the state space\nstates = [\"increase\", \"decrease\", \"same\"]\n\n# Define the observation space\nobservations = df[[\"bid_price\", \"ask_price\"]].values\n\n# Define the transition probabilities\ntrans_mat = [[0.7, 0.2, 0.1],\n             [0.3, 0.5, 0.2],\n             [0.2, 0.3, 0.5]]\n\n# Define the emission probabilities\nemissionprob_mat = [[0.2, 0.4, 0.4],\n                    [0.4, 0.3, 0.3],\n                    [0.3, 0.3, 0.4],\n                    [0.4, 0.4, 0.2]]\n\n# Create the HMM model\nmodel = hmm.MultinomialHMM(n_components=3)\nmodel.startprob_ = [0.3, 0.4, 0.3]\nmodel.transmat_ = trans_mat\nmodel.emissionprob_ = emissionprob_mat\n\n# Fit the model to the data\nmodel.fit(observations)\n\n# Make predictions\nprediction = model.predict(df[[\"bid_price\", \"ask_price\"]].values)\npredicted_states = [states[state] for state in prediction]\ndf[\"predicted_states\"] = predicted_states\n\n# Print the predictions\nprint(df[\"predicted_states\"])`\n",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "9O0L",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Just for fun, chat GPT came up with this:\n"
                            },
                            {
                                "type": "text",
                                "text": "import pandas as pd\nfrom hmmlearn import hmm\n\n# Load data into pandas dataframe\ndf = pd.read_csv(\"market_data.csv\")\n\n# Define the state space\nstates = [\"increase\", \"decrease\", \"same\"]\n\n# Define the observation space\nobservations = df[[\"bid_price\", \"ask_price\"]].values\n\n# Define the transition probabilities\ntrans_mat = [[0.7, 0.2, 0.1],\n             [0.3, 0.5, 0.2],\n             [0.2, 0.3, 0.5]]\n\n# Define the emission probabilities\nemissionprob_mat = [[0.2, 0.4, 0.4],\n                    [0.4, 0.3, 0.3],\n                    [0.3, 0.3, 0.4],\n                    [0.4, 0.4, 0.2]]\n\n# Create the HMM model\nmodel = hmm.MultinomialHMM(n_components=3)\nmodel.startprob_ = [0.3, 0.4, 0.3]\nmodel.transmat_ = trans_mat\nmodel.emissionprob_ = emissionprob_mat\n\n# Fit the model to the data\nmodel.fit(observations)\n\n# Make predictions\nprediction = model.predict(df[[\"bid_price\", \"ask_price\"]].values)\npredicted_states = [states[state] for state in prediction]\ndf[\"predicted_states\"] = predicted_states\n\n# Print the predictions\nprint(df[\"predicted_states\"])\n",
                                "style": {
                                    "code": true
                                }
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679849377.983359",
        "client_msg_id": "4fe435f3-adad-412d-9723-4155cab2ebd7",
        "text": "Nice!  It's cool to plot out the states over the sequence of prices too.  To get a feel of what the states really mean.\n\nJust because we label them as \"increase\" or \"neutral\" doesn't really mean anything.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "rolZD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Nice!  It's cool to plot out the states over the sequence of prices too.  To get a feel of what the states really mean.\n\nJust because we label them as \"increase\" or \"neutral\" doesn't really mean anything."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "U016TGY3676"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U9JHLMZB4",
        "type": "message",
        "ts": "1679849857.904899",
        "client_msg_id": "7fdf187d-ba49-42ce-a9e7-98ef33ab8234",
        "text": "<@U016TGY3676> We need to be a bit careful about looking for expected or \"normal\" values in the stats. They will depend a lot on how noisy the data is. Moreover, they're just one part of some subtle evaluations.\n\nTo illustrate, imagine a UK greyhound model that predicts that every dog in a six dog race will lose (there are some poor tutorials out there that actually build models that do this!). the model is pants, but it's also accurate 83.33% of the time. On the other hand a model with some genuine predictive power may have an accuracy down in the 70s but yield better results when used to place actual bets. So I agree with <@U04AD6RAGGH> that calculating expected returns can be a useful metric for deciding whether you have a viable model.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g951ddcb43e7",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/3951ddcb43e788a387d6daf330dad5ca.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0018-72.png",
            "first_name": "",
            "real_name": "Peter Coles",
            "display_name": "Peter",
            "team": "T4G9NBD2M",
            "name": "peter",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mYS9e",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U016TGY3676"
                            },
                            {
                                "type": "text",
                                "text": " We need to be a bit careful about looking for expected or \"normal\" values in the stats. They will depend a lot on how noisy the data is. Moreover, they're just one part of some subtle evaluations.\n\nTo illustrate, imagine a UK greyhound model that predicts that every dog in a six dog race will lose (there are some poor tutorials out there that actually build models that do this!). the model is pants, but it's also accurate 83.33% of the time. On the other hand a model with some genuine predictive power may have an accuracy down in the 70s but yield better results when used to place actual bets. So I agree with "
                            },
                            {
                                "type": "user",
                                "user_id": "U04AD6RAGGH"
                            },
                            {
                                "type": "text",
                                "text": " that calculating expected returns can be a useful metric for deciding whether you have a viable model."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U016TGY3676"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679852192.603709",
        "client_msg_id": "03fef597-3796-4f49-8789-e1786d6752b2",
        "text": "In this case, would expected returns basically be P&amp;L per bet or something else?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uyed",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In this case, would expected returns basically be P&L per bet or something else?"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "heavy_check_mark",
                "users": [
                    "U9JHLMZB4"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679852955.352019",
        "client_msg_id": "cd84a9ef-f30f-4e10-beb1-92de0ab64e81",
        "text": "Expected Value = [P(win) * net winnings] - [P(lose) * net losses]\n\napplying this, for example, to binary logistic regression would yield that P(win) = winner accuracy and P(lose) =  1 - P(win)",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "y0sjT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Expected Value = [P(win) * net winnings] - [P(lose) * net losses]\n\napplying this, for example, to binary logistic regression would yield that P(win) = winner accuracy and P(lose) =  1 - P(win)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679852991.902129",
        "client_msg_id": "2b94300d-9256-40c9-95f7-6c5d943c03bd",
        "text": "winner accuracy being something like: # correctly predicted winners \/ total winners",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "aSf+9",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "winner accuracy being something like: # correctly predicted winners \/ total winners"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679854670.419979",
        "edited": {
            "user": "U016TGY3676",
            "ts": "1679854994.000000"
        },
        "client_msg_id": "d0afef98-0e76-4f6a-8726-aff2d9831572",
        "text": "Going back to my opening post, the model I was using:\n\n`from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error`\n\n`# Convert the target variable to binary (0 for lose, 1 for win)\ndf['winner'] = df['profit'].apply(lambda x: 1 if x &gt; 0 else 0)`\n\n`# Split data into training and test sets\nfeatures = ['sig1', 'sig2', 'sig3']`\n`X_train, X_test, y_train, y_test = train_test_split(df[features], df['winner'], test_size=0.2)`\n\n`# Instantiate a logistic regression model\nmodel = LogisticRegression()`\n\n`# Fit the model to the training data\nmodel.fit(X_train, y_train)`\n\n`# Use the model to make predictions on the test data\ny_pred = model.predict(X_test)`\n\n`# Evaluate the model's performance using appropriate metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\nprint(f\"F1-score: {f1}\")\nprint(f\"MSE: {mse}\")`\n\nBearing in mind that the dataset is a bet history (BACK bets only) where all unmatched bets have been removed and 'profit' is a real-world number, would this not achieve the same result as calculating EV for training? My gut feeling is that the model is shyte, or at least the data I'm using is too optimised due to being pre-filtered by the strategy that generated it. Thoughts?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "0HnW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Going back to my opening post, the model I was using:\n\n"
                            },
                            {
                                "type": "text",
                                "text": "from sklearn.model_selection import train_test_split\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "from sklearn.linear_model import LogisticRegression\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "# Convert the target variable to binary (0 for lose, 1 for win)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "df['winner'] = df['profit'].apply(lambda x: 1 if x > 0 else 0)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "# Split data into training and test sets\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "features = ['sig1', 'sig2', 'sig3']",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "X_train, X_test, y_train, y_test = train_test_split(df[features], df['winner'], test_size=0.2)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "# Instantiate a logistic regression model\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "model = LogisticRegression()\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "# Fit the model to the training data\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "model.fit(X_train, y_train)",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "text",
                                "text": "# Use the model to make predictions on the test data\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "y_pred = model.predict(X_test)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "# Evaluate the model's performance using appropriate metrics\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "accuracy = accuracy_score(y_test, y_pred)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "precision = precision_score(y_test, y_pred)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "recall = recall_score(y_test, y_pred)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "f1 = f1_score(y_test, y_pred)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "mse = mean_squared_error(y_test, y_pred)\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "print(f\"Accuracy: {accuracy}\")\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "print(f\"Precision: {precision}\")\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "print(f\"Recall: {recall}\")\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "print(f\"F1-score: {f1}\")\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "print(f\"MSE: {mse}\")\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\nBearing in mind that the dataset is a bet history (BACK bets only) where all unmatched bets have been removed and 'profit' is a real-world number, would this not achieve the same result as calculating EV for training? My gut feeling is that the model is shyte, or at least the data I'm using is too optimised due to being pre-filtered by the strategy that generated it. Thoughts?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEA14GBRR",
        "type": "message",
        "ts": "1679855661.997439",
        "client_msg_id": "7f959c60-a615-4a73-8a59-48003ad0f5d9",
        "text": "Have you tried asking ChatGPT?  I gave it your original question and got...",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "889680f46fe7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-06\/6774538588752_889680f46fe773047cb9_72.jpg",
            "first_name": "",
            "real_name": "Shaun White",
            "display_name": "ShaunW",
            "team": "T4G9NBD2M",
            "name": "shaunwhite",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tNf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Have you tried asking ChatGPT?  I gave it your original question and got..."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEA14GBRR",
        "type": "message",
        "ts": "1679855665.057429",
        "client_msg_id": "67298e9a-2144-40aa-a3d0-2a3460bdb676",
        "text": "Your understanding is correct. The implied probability of the matched prices in your dataset is approximately 0.84, which means that, on average, the market believes there is an 84% chance of the runner winning. To beat the market, your model's accuracy should be higher than this implied probability.\nIn your case, the accuracy of the LogisticRegression model is 0.8346, which is close to the market's implied probability but not quite above it. This means that, although your model appears to be performing reasonably well, it is not yet outperforming the market.\nTo improve your model's performance, you can try several approaches:\n1. Feature Engineering: Create new features or transform existing features to better capture the underlying patterns in the data.\n2. Feature Selection: Remove irrelevant or noisy features to reduce overfitting and improve model generalization.\n3. Hyperparameter Tuning: Optimize the hyperparameters of your Logistic Regression model, such as regularization strength (C) or using different solvers.\n4. Ensemble Methods: Combine multiple models, like decision trees or other classifiers, to improve overall performance.\n5. Experiment with different algorithms: Try other machine learning algorithms that might better capture the patterns in your dataset.\nRemember to also take into account the Precision, Recall, and F1-score of your model, as they provide additional insights into its performance. For instance, your model's high Recall (0.9988) and lower Precision (0.8354) indicate that it is good at identifying winning bets but may also produce many false positives, which can lead to losses. Balancing these metrics can help you create a more effective betting strategy.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "889680f46fe7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-06\/6774538588752_889680f46fe773047cb9_72.jpg",
            "first_name": "",
            "real_name": "Shaun White",
            "display_name": "ShaunW",
            "team": "T4G9NBD2M",
            "name": "shaunwhite",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "L3L",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Your understanding is correct. The implied probability of the matched prices in your dataset is approximately 0.84, which means that, on average, the market believes there is an 84% chance of the runner winning. To beat the market, your model's accuracy should be higher than this implied probability.\nIn your case, the accuracy of the LogisticRegression model is 0.8346, which is close to the market's implied probability but not quite above it. This means that, although your model appears to be performing reasonably well, it is not yet outperforming the market.\nTo improve your model's performance, you can try several approaches:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Feature Engineering: Create new features or transform existing features to better capture the underlying patterns in the data."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Feature Selection: Remove irrelevant or noisy features to reduce overfitting and improve model generalization."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Hyperparameter Tuning: Optimize the hyperparameters of your Logistic Regression model, such as regularization strength (C) or using different solvers."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Ensemble Methods: Combine multiple models, like decision trees or other classifiers, to improve overall performance."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Experiment with different algorithms: Try other machine learning algorithms that might better capture the patterns in your dataset."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Remember to also take into account the Precision, Recall, and F1-score of your model, as they provide additional insights into its performance. For instance, your model's high Recall (0.9988) and lower Precision (0.8354) indicate that it is good at identifying winning bets but may also produce many false positives, which can lead to losses. Balancing these metrics can help you create a more effective betting strategy."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEA14GBRR",
        "type": "message",
        "ts": "1679855803.705199",
        "edited": {
            "user": "UEA14GBRR",
            "ts": "1679855841.000000"
        },
        "client_msg_id": "10942045-9f1d-4bea-ab08-c6d49935d268",
        "text": "The next hr is usually spent :thinking_face:typing \"What does ....... mean?\"",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "889680f46fe7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-06\/6774538588752_889680f46fe773047cb9_72.jpg",
            "first_name": "",
            "real_name": "Shaun White",
            "display_name": "ShaunW",
            "team": "T4G9NBD2M",
            "name": "shaunwhite",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mkeH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The next hr is usually spent "
                            },
                            {
                                "type": "emoji",
                                "name": "thinking_face",
                                "unicode": "1f914"
                            },
                            {
                                "type": "text",
                                "text": "typing \"What does ....... mean?\""
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "U016TGY3676"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679856054.463639",
        "client_msg_id": "a14aedc1-cd72-4e90-b2d5-edee3bb9f56f",
        "text": "have you tried :\n\n1. normalizing \/ standardizing your inputs (this is important for logistic regression and any gradient based updates)\n2. included the market implied probabilities as a feature",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ei6H",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "have you tried :\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "normalizing \/ standardizing your inputs (this is important for logistic regression and any gradient based updates)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "included the market implied probabilities as a feature"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679856097.229589",
        "client_msg_id": "680290e0-cd2a-4a9b-8dbb-96ff873fbaa1",
        "text": "also yes, hyperparameter optimization and cross-validate the shit out of everything.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XRa2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "also yes, hyperparameter optimization and cross-validate the shit out of everything."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679856738.856479",
        "edited": {
            "user": "U016TGY3676",
            "ts": "1679856777.000000"
        },
        "client_msg_id": "f765d1d4-765a-4782-88af-0aaba647e9d2",
        "text": "<@UEA14GBRR> Yes, chat GPT is where my journey began. It's also writing the code for me. :grinning:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Wwy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UEA14GBRR"
                            },
                            {
                                "type": "text",
                                "text": " Yes, chat GPT is where my journey began. It's also writing the code for me. "
                            },
                            {
                                "type": "emoji",
                                "name": "grinning",
                                "unicode": "1f600"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679859520.518359",
        "edited": {
            "user": "U016TGY3676",
            "ts": "1679859618.000000"
        },
        "client_msg_id": "99b58ed1-e4a4-467f-8673-6bf50e394189",
        "text": "<@U04AD6RAGGH> I did wonder about normalising the features as they are mixed values, i.e. most are in the range 0-1 and a few are raw values such as ¬£10, etc. I've tried using prices as inputs but didn't do the obvious thing and calculate the implied probability. Regarding this, would integers be better, i.e. range 0-1000 rather than 0-1?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "JTCP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U04AD6RAGGH"
                            },
                            {
                                "type": "text",
                                "text": " I did wonder about normalising the features as they are mixed values, i.e. most are in the range 0-1 and a few are raw values such as ¬£10, etc. I've tried using prices as inputs but didn't do the obvious thing and calculate the implied probability. Regarding this, would integers be better, i.e. range 0-1000 rather than 0-1?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679861205.773079",
        "client_msg_id": "5283ca96-f2a7-4008-89bb-5d1cb07dc8a3",
        "text": "So feature scaling applies to logistic regression only when you are interested in regularizing the model somehow (i.e. L1 and L2 terms are non-zero).  In most cases we want to regularize to improve generalization (reduce overfitting).\n\nI would try to just convert everything to implied probabilities and that will act as a scaling transform.  If there are features that you can't do this to (like volume perhaps) then standardize them or play around with some scaling methods to see what works best (e.g. normalization and minmax scaling can also work)\n\nquick and dirty method is to minmax scale things and go from there.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "9Ld",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So feature scaling applies to logistic regression only when you are interested in regularizing the model somehow (i.e. L1 and L2 terms are non-zero).  In most cases we want to regularize to improve generalization (reduce overfitting).\n\nI would try to just convert everything to implied probabilities and that will act as a scaling transform.  If there are features that you can't do this to (like volume perhaps) then standardize them or play around with some scaling methods to see what works best (e.g. normalization and minmax scaling can also work)\n\nquick and dirty method is to minmax scale things and go from there."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U016TGY3676"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679863427.831179",
        "client_msg_id": "7a3c4d56-ce63-4034-879b-0f174653cde3",
        "text": "I can get everything to a range of 0-1 quite easily, so will give that a go.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kZuU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I can get everything to a range of 0-1 quite easily, so will give that a go."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U04AD6RAGGH"
                ],
                "count": 1
            }
        ]
    }
]