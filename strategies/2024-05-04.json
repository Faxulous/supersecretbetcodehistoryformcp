[
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1714814434.689879",
        "client_msg_id": "d8bd7d90-3d8b-4827-9178-caefcb7fd9d6",
        "text": "Does anyone on here have any insights into migrating potentially hundreds of features created on a dataframe into a live production scenario, especially within the context of a flumine strategy? E.g. rolling windows, moving averages etc.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "reply_count": 13,
        "reply_users_count": 5,
        "latest_reply": "1714900788.570989",
        "reply_users": [
            "U4H19D1D2",
            "U05N9773A23",
            "U03FS7KM2NL",
            "U02GGCCLTKM",
            "UC70576CB"
        ],
        "replies": [
            {
                "user": "U4H19D1D2",
                "ts": "1714820492.199359"
            },
            {
                "user": "U05N9773A23",
                "ts": "1714821315.339519"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1714828988.440969"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1714829021.711719"
            },
            {
                "user": "U05N9773A23",
                "ts": "1714830153.862399"
            },
            {
                "user": "U03FS7KM2NL",
                "ts": "1714831516.755019"
            },
            {
                "user": "U02GGCCLTKM",
                "ts": "1714871154.150129"
            },
            {
                "user": "UC70576CB",
                "ts": "1714896230.830979"
            },
            {
                "user": "U05N9773A23",
                "ts": "1714896400.213239"
            },
            {
                "user": "UC70576CB",
                "ts": "1714898082.693719"
            },
            {
                "user": "U05N9773A23",
                "ts": "1714898331.427519"
            },
            {
                "user": "UC70576CB",
                "ts": "1714898531.408719"
            },
            {
                "user": "U03FS7KM2NL",
                "ts": "1714900788.570989"
            }
        ],
        "is_locked": false,
        "subscribed": true,
        "last_read": "1714915292.483617",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "TBo2i",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Does anyone on here have any insights into migrating potentially hundreds of features created on a dataframe into a live production scenario, especially within the context of a flumine strategy? E.g. rolling windows, moving averages etc."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1714820492.199359",
        "client_msg_id": "F63FE6D3-57C6-4831-8B98-6930B5DD0C34",
        "text": "Do you not want to just use pandas? ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "U9+3p",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Do you not want to just use pandas? "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1714821315.339519",
        "client_msg_id": "623dc351-75bd-4fba-b2c2-d05ca22a5a12",
        "text": "Open to anything, do you just append each row to the data frame as it arrives from the stream?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "0MqBc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Open to anything, do you just append each row to the data frame as it arrives from the stream?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1714828988.440969",
        "client_msg_id": "F478C8DA-40FF-4F68-8AE2-DF14E7008BAB",
        "text": "I always use python lists \/ dictionary’s for this when live ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Zk63j",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I always use python lists \/ "
                            },
                            {
                                "type": "text",
                                "text": "dictionary’s"
                            },
                            {
                                "type": "text",
                                "text": " for this when live "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1714829021.711719",
        "edited": {
            "user": "U4H19D1D2",
            "ts": "1714829036.000000"
        },
        "client_msg_id": "D603E6B3-73AD-419A-B4D1-CA67E5A35DE5",
        "text": "Need to be careful when things start getting large as everything slows down and causes latency issues ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "IZJxo",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Need to be careful when things start getting large as everything slows down and causes latency issues "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1714830153.862399",
        "client_msg_id": "2a5ede8b-0022-4496-a9b2-55a3a70a80bf",
        "text": "Interesting. A data frame would allow me to re-use a lot of logic from my feature engineering but maybe it's more efficient to use a nested dictionary and a deque for the rolling windows",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zNv93",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting. A data frame would allow me to re-use a lot of logic from my feature engineering but maybe it's more efficient to use a nested dictionary and a deque for the rolling windows"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U03FS7KM2NL",
        "type": "message",
        "ts": "1714831516.755019",
        "client_msg_id": "C862422B-5D2E-4631-A622-C125D3F214A2",
        "text": "Usually want to preallocate a numpy array per column and fill it with values, can use it as a ring buffer if you don’t have enough memory",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g160a197a059",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/160a197a059d9b97aabdd95ca66dc341.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0026-72.png",
            "first_name": "Ralegh",
            "real_name": "Ralegh",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "ralegh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "FIr82",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Usually want to preallocate a numpy array per column and fill it with values, can use it as a ring buffer if you "
                            },
                            {
                                "type": "text",
                                "text": "don’t"
                            },
                            {
                                "type": "text",
                                "text": " have enough memory"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02GGCCLTKM",
        "type": "message",
        "ts": "1714871154.150129",
        "client_msg_id": "6F0E66F9-5D51-4B0E-BA5A-816745FBCE1B",
        "text": "I use a feature store ( <https:\/\/feast.dev|feast>) but it’s definitely  not ideal if latency is important for you ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "ge8c986b4886",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/e8c986b48866eae41e70e68deddde864.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "John",
            "real_name": "John Foley",
            "display_name": "John Foley",
            "team": "T4G9NBD2M",
            "name": "johnf1004",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "attachments": [
            {
                "from_url": "https:\/\/feast.dev\/",
                "image_url": "https:\/\/feast.dev\/wp-content\/uploads\/2023\/01\/feast-og@2x.png",
                "image_width": 1201,
                "image_height": 630,
                "image_bytes": 18305,
                "service_icon": "https:\/\/feast.dev\/wp-content\/uploads\/2021\/02\/cropped-feast-favicon-300x300.png",
                "id": 1,
                "original_url": "https:\/\/feast.dev",
                "fallback": "Feast: Feast: Feature Store for Machine Learning",
                "text": "Feast is an end-to-end open source feature store for machine learning. It allows teams to define, manage, discover, and serve features.",
                "title": "Feast: Feature Store for Machine Learning",
                "title_link": "https:\/\/feast.dev\/",
                "service_name": "Feast"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ropwN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I use a feature store ( "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/feast.dev",
                                "text": "feast"
                            },
                            {
                                "type": "text",
                                "text": ") but it’s definitely  not ideal if latency is important for you "
                            }
                        ]
                    }
                ]
            }
        ]
    }
]