[
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679918611.059149",
        "client_msg_id": "a686932d-d373-4bc4-946d-d8c15a41a806",
        "text": "I now have some quick n dirty signals as a proof of concept and running against a complete dataset generated by Flumine simulation where the strategy backs every runner for £1 at LTP on every update. Results appear to be more realistic, particularly the recall stat <@U9JHLMZB4> mentioned:\n\n`Accuracy: 0.8649507394792786\nPrecision: 0.6514084507042254\nRecall: 0.34230002846569885\nF1-score: 0.4487777570442247\nMSE: 0.13504926052072141\nLogLoss: 4.867668736665466`\n\nUsing irrelevant features such as market_id and selection_id give poor results as expected. Surprised that the Accuracy is still quite high though. Thoughts?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4RNwj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I now have some quick n dirty signals as a proof of concept and running against a complete dataset generated by Flumine simulation where the strategy backs every runner for £1 at LTP on every update. Results appear to be more realistic, particularly the recall stat "
                            },
                            {
                                "type": "user",
                                "user_id": "U9JHLMZB4"
                            },
                            {
                                "type": "text",
                                "text": " mentioned:\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Accuracy: 0.8649507394792786\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "Precision: 0.6514084507042254\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "Recall: 0.34230002846569885\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "F1-score: 0.4487777570442247\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "MSE: 0.13504926052072141\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "LogLoss: 4.867668736665466\n",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\nUsing irrelevant features such as market_id and selection_id give poor results as expected. Surprised that the Accuracy is still quite high though. Thoughts?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679928890.819499",
        "client_msg_id": "25959a45-e071-4ad2-a58b-5f832b7c8fd8",
        "text": "Per <@U9JHLMZB4>’s comment above, your accuracy can be high when predicting every runner will lose.  In a 10 runner race, you'd have 90% accuracy!  So we have to take a deeper look at things.  Usually you can start at precision and recall:\n\nPrecision is related to False Positives\nRecall is related to False Negatives\n\nIn this case, False Positives can lose you money while False Negatives will miss trades.  So:\n\nlow Recall = Lots of missed trades\nlow Precision = lots of bad trades\n\nFrom your numbers, you are missing more trades than you are losing; which is better than the other way around.\n\nNot surprised that those ID features don't work, they are not \"numbers\" in the sense that a logistic model can deal with them.  They are more like categorical variables.  It's like trying to numerically model a word, it can be done, but needs some preprocessing.\n\nI'm curious: is there one trade per event you are looking for or multiple signals simultaneously?  Trying to understand if you have a class imbalance problem.\n\nAlso, use cross-validation and calibration : <https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.calibration.CalibratedClassifierCV.html>",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "attachments": [
            {
                "from_url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.calibration.CalibratedClassifierCV.html",
                "service_icon": "https:\/\/scikit-learn.org\/stable\/_static\/favicon.ico",
                "id": 1,
                "original_url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.calibration.CalibratedClassifierCV.html",
                "fallback": "scikit-learn: sklearn.calibration.CalibratedClassifierCV",
                "text": "Examples using sklearn.calibration.CalibratedClassifierCV: Probability Calibration curves Probability Calibration curves Probability Calibration for 3-class classification Probability Calibration f...",
                "title": "sklearn.calibration.CalibratedClassifierCV",
                "title_link": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.calibration.CalibratedClassifierCV.html",
                "service_name": "scikit-learn"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kv3",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Per "
                            },
                            {
                                "type": "user",
                                "user_id": "U9JHLMZB4"
                            },
                            {
                                "type": "text",
                                "text": "’s comment above, your accuracy can be high when predicting every runner will lose.  In a 10 runner race, you'd have 90% accuracy!  So we have to take a deeper look at things.  Usually you can start at precision and recall:\n\nPrecision is related to False Positives\nRecall is related to False Negatives\n\nIn this case, False Positives can lose you money while False Negatives will miss trades.  So:\n\nlow Recall = Lots of missed trades\nlow Precision = lots of bad trades\n\nFrom your numbers, you are missing more trades than you are losing; which is better than the other way around.\n\nNot surprised that those ID features don't work, they are not \"numbers\" in the sense that a logistic model can deal with them.  They are more like categorical variables.  It's like trying to numerically model a word, it can be done, but needs some preprocessing.\n\nI'm curious: is there one trade per event you are looking for or multiple signals simultaneously?  Trying to understand if you have a class imbalance problem.\n\nAlso, use cross-validation and calibration : "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.calibration.CalibratedClassifierCV.html"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679934141.181029",
        "client_msg_id": "52a0ac9b-dade-4700-b520-bbdf38e70bcb",
        "text": "<@U04AD6RAGGH> good point on the IDs, I overlooked that. As for the signals, they're calculated on every market update and in the above example, only saved to the CSV for analysis &amp; modelling. As such, the \"bets\" are only placed to populate the CSV. I have a handful of signals at present and trying various combinations to see which ones are good\/bad. This seems like a sensible approach with my current understanding?\n\nWill look at validation and calibration.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3gD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U04AD6RAGGH"
                            },
                            {
                                "type": "text",
                                "text": " good point on the IDs, I overlooked that. As for the signals, they're calculated on every market update and in the above example, only saved to the CSV for analysis & modelling. As such, the \"bets\" are only placed to populate the CSV. I have a handful of signals at present and trying various combinations to see which ones are good\/bad. This seems like a sensible approach with my current understanding?\n\nWill look at validation and calibration."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679940656.134579",
        "client_msg_id": "01026b03-a6db-4a20-b4f4-452dd9727ef0",
        "text": "Seems sensible to me.  If you have a handful of signals as features you can also try just using all of them to start and use something like recursive feature elimination to boil it down to a good set (<https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.RFECV.html>)",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "attachments": [
            {
                "from_url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.RFECV.html",
                "service_icon": "https:\/\/scikit-learn.org\/stable\/_static\/favicon.ico",
                "id": 1,
                "original_url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.RFECV.html",
                "fallback": "scikit-learn: sklearn.feature_selection.RFECV",
                "text": "Examples using sklearn.feature_selection.RFECV: Recursive feature elimination with cross-validation Recursive feature elimination with cross-validation",
                "title": "sklearn.feature_selection.RFECV",
                "title_link": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.RFECV.html",
                "service_name": "scikit-learn"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZplaF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Seems sensible to me.  If you have a handful of signals as features you can also try just using all of them to start and use something like recursive feature elimination to boil it down to a good set ("
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.RFECV.html"
                            },
                            {
                                "type": "text",
                                "text": ")"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679942140.299129",
        "client_msg_id": "6c2c2ae4-5b22-4b54-8ae4-6006745e03a1",
        "text": "Thanks for your help <@U04AD6RAGGH>, it's very much appreciated. I had a quick play with CalibratedClassifierCV but it seems to produce very similar results to my basic LogisticRegression. Is that to be expected? My implementation is:\n\n`#model = LogisticRegression()\nmodel = CalibratedClassifierCV(\n    estimator=LogisticRegression(),\n    method='sigmoid'\n#    method='isotonic'\n)`\nI believe it to be correct? At this stage, I'm starting to steer towards one of the auto ml libraries rather than manually trying the infinite number of combinations.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "iL2Vj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks for your help "
                            },
                            {
                                "type": "user",
                                "user_id": "U04AD6RAGGH"
                            },
                            {
                                "type": "text",
                                "text": ", it's very much appreciated. I had a quick play with CalibratedClassifierCV but it seems to produce very similar results to my basic LogisticRegression. Is that to be expected? My implementation is:\n\n"
                            },
                            {
                                "type": "text",
                                "text": "#model = LogisticRegression()\nmodel = CalibratedClassifierCV(\n    estimator=LogisticRegression(),\n    method='sigmoid'\n#    method='isotonic'\n)",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\nI believe it to be correct? At this stage, I'm starting to steer towards one of the auto ml libraries rather than manually trying the infinite number of combinations."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679944781.737899",
        "client_msg_id": "d6e94b8d-2ffc-460e-b37e-8f669df6aa1e",
        "text": "yep Logistic Regression is by nature well calibrated, the calibration step is really only for something like the SGD method I linked above or things like SVMs and boosted methods.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "onQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "yep Logistic Regression is by nature well calibrated, the calibration step is really only for something like the SGD method I linked above or things like SVMs and boosted methods."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679944885.205979",
        "client_msg_id": "4cabaefc-30f1-449a-9f9c-2514311ce5ad",
        "text": "Usually automl wont help all that much until there is a clear hypothesis to be tested.  E.G. \"I think that features &lt;x, y, z&gt; will have effect &lt;e&gt;\" and then I can go and test for that.  Otherwise it's like throwing shit at a wall to see what sticks... a method I am also familiar with XD",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Dq\/rz",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Usually automl wont help all that much until there is a clear hypothesis to be tested.  E.G. \"I think that features <x, y, z> will have effect <e>\" and then I can go and test for that.  Otherwise it's like throwing shit at a wall to see what sticks... a method I am also familiar with XD"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1679947037.802269",
        "client_msg_id": "01ad6edb-2de0-4095-aef3-33a24504fe9d",
        "text": "My walls are already pebble-dashed with previous efforts, so a few more layers won't hurt. :grinning:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ExN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My walls are already pebble-dashed with previous efforts, so a few more layers won't hurt. "
                            },
                            {
                                "type": "emoji",
                                "name": "grinning",
                                "unicode": "1f600"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U04AD6RAGGH",
        "type": "message",
        "ts": "1679948062.870689",
        "client_msg_id": "b9a8190e-b141-4480-bcee-765b7f114f4f",
        "text": "currently in the middle of reworking some fecal artwork myself",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "2f5fccb5d023",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-11-08\/4353229497089_2f5fccb5d0233ef1b00d_72.jpg",
            "first_name": "Rory",
            "real_name": "Rory",
            "display_name": "R",
            "team": "T4G9NBD2M",
            "name": "rorytyrrell2",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679837144.844899",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "GVer",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "currently in the middle of reworking some fecal artwork myself"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]