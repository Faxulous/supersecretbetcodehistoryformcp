[
    {
        "user": "UC70576CB",
        "type": "message",
        "ts": "1714896230.830979",
        "client_msg_id": "3de6caf7-8f30-4c55-838c-621b042f265e",
        "text": "Do you have any performance issues to worry about? If not, reusing the feature engineering code you used to build the strategy is a much bigger benefit IMHO, as there are so many edge cases to test if you reimplement processing.\n\nIf you need a more performant dataframe, consider <https:\/\/pola.rs\/>",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g3b214cb6303",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/83b214cb63031e2a2ae3958016f7bf23.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0015-72.png",
            "first_name": "",
            "real_name": "Rob",
            "display_name": "Rob",
            "team": "T4G9NBD2M",
            "name": "rnobleeddy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "attachments": [
            {
                "from_url": "https:\/\/pola.rs\/",
                "image_url": "https:\/\/www.pola.rs\/share.jpg",
                "image_width": 1200,
                "image_height": 620,
                "image_bytes": 178564,
                "id": 1,
                "original_url": "https:\/\/pola.rs\/",
                "fallback": "Polars",
                "text": "DataFrames for the new era",
                "title": "Polars",
                "title_link": "https:\/\/pola.rs\/",
                "service_name": "pola.rs"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oIzIy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Do you have any performance issues to worry about? If not, reusing the feature engineering code you used to build the strategy is a much bigger benefit IMHO, as there are so many edge cases to test if you reimplement processing.\n\nIf you need a more performant dataframe, consider "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/pola.rs\/"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1714896400.213239",
        "client_msg_id": "7d634a78-28b8-41cd-8fa8-8576b549b20b",
        "text": "<@UC70576CB> My strategy doesn't seem to be overly sensitive to latency from my testing. All my feature engineering is done with polars, I much prefer it over pandas",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ubmNB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UC70576CB"
                            },
                            {
                                "type": "text",
                                "text": " My strategy doesn't seem to be overly sensitive to latency from my testing. All my feature engineering is done with polars, I much prefer it over pandas"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U012XF5CNPN",
        "type": "message",
        "ts": "1714897814.155859",
        "client_msg_id": "26615598-3F6E-47AC-966C-77973E9E0468",
        "text": "Who knew LLMs would not be able to do statistical analysis? Well, everyone I guess, but it didn’t stop some people trying: <https:\/\/m.slashdot.org\/story\/428028|https:\/\/m.slashdot.org\/story\/428028>",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf0a1c4f12dc",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f0a1c4f12dc16bc00aa5abf1a75d640e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "Paul",
            "real_name": "Paul Robinson",
            "display_name": "Paul",
            "team": "T4G9NBD2M",
            "name": "paul",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714897814.155859",
        "reply_count": 5,
        "reply_users_count": 4,
        "latest_reply": "1714914448.182319",
        "reply_users": [
            "U02RN7YDRQ9",
            "UEA14GBRR",
            "U06RE5C6X2P",
            "U05N9773A23"
        ],
        "replies": [
            {
                "user": "U02RN7YDRQ9",
                "ts": "1714898769.845359"
            },
            {
                "user": "UEA14GBRR",
                "ts": "1714905902.384359"
            },
            {
                "user": "U06RE5C6X2P",
                "ts": "1714906665.184929"
            },
            {
                "user": "U05N9773A23",
                "ts": "1714912015.188789"
            },
            {
                "user": "UEA14GBRR",
                "ts": "1714914448.182319"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "K4X7o",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Who knew LLMs would not be able to do statistical analysis? Well, everyone I guess, but it "
                            },
                            {
                                "type": "text",
                                "text": "didn’t"
                            },
                            {
                                "type": "text",
                                "text": " stop some people trying: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/m.slashdot.org\/story\/428028",
                                "text": "https:\/\/m.slashdot.org\/story\/428028"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "man-facepalming",
                "users": [
                    "U4H19D1D2"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UC70576CB",
        "type": "message",
        "ts": "1714898082.693719",
        "client_msg_id": "e6d0f08b-08b0-47f7-93d0-cd5833852946",
        "text": "If I start again from scratch, I'd use a feature store, but I don't have too big an issue with processing historic data when placing bets, mainly because the historic data appears to be far less powerful then I expected :confused:\n\npolars seems great, I will never need to chunk &amp; parallelise pandas code ever again :wink:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g3b214cb6303",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/83b214cb63031e2a2ae3958016f7bf23.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0015-72.png",
            "first_name": "",
            "real_name": "Rob",
            "display_name": "Rob",
            "team": "T4G9NBD2M",
            "name": "rnobleeddy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kpzeG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If I start again from scratch, I'd use a feature store, but I don't have too big an issue with processing historic data when placing bets, mainly because the historic data appears to be far less powerful then I expected "
                            },
                            {
                                "type": "emoji",
                                "name": "confused",
                                "unicode": "1f615"
                            },
                            {
                                "type": "text",
                                "text": "\n\npolars seems great, I will never need to chunk & parallelise pandas code ever again "
                            },
                            {
                                "type": "emoji",
                                "name": "wink",
                                "unicode": "1f609"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1714898331.427519",
        "client_msg_id": "170f8662-c654-4a43-a28d-7952455e4c01",
        "text": "Interesting. I just did some further tests and while latency doesn't seem to affect the % return very much, it does affect the number of bets I am getting matched.\n\nIf I was to use polars, it would make things far easier, but I would be appending to the dataframe very frequently. Do you think this would add much overhead?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MuNKy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting. I just did some further tests and while latency doesn't seem to affect the % return very much, it does affect the number of bets I am getting matched.\n\nIf I was to use polars, it would make things far easier, but I would be appending to the dataframe very frequently. Do you think this would add much overhead?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UC70576CB",
        "type": "message",
        "ts": "1714898531.408719",
        "client_msg_id": "6a0f0934-0733-4bb3-bc10-12f1cbab78b7",
        "text": "For pandas this is very inefficient, but I very much subscribe to worrying about things that materialise. e.g. <https:\/\/stackify.com\/premature-optimization-evil\/>\n\nCompute is so cheap, we often don't need to worry about optimisation.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g3b214cb6303",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/83b214cb63031e2a2ae3958016f7bf23.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0015-72.png",
            "first_name": "",
            "real_name": "Rob",
            "display_name": "Rob",
            "team": "T4G9NBD2M",
            "name": "rnobleeddy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "attachments": [
            {
                "image_url": "https:\/\/stackify.com\/wp-content\/uploads\/2017\/11\/Premature-optimization-is-the-root-of-all-evil-881x441-1.jpg",
                "image_width": 881,
                "image_height": 441,
                "image_bytes": 42553,
                "from_url": "https:\/\/stackify.com\/premature-optimization-evil\/",
                "service_icon": "https:\/\/stackify.com\/wp-content\/uploads\/2023\/02\/favicon.png",
                "ts": 1511856807,
                "id": 1,
                "original_url": "https:\/\/stackify.com\/premature-optimization-evil\/",
                "fallback": "Stackify: Why Premature Optimization Is the Root of All Evil - Stackify",
                "text": "The performance and scalability of your application are important. Understand what to avoid and what to prioritize when building your app.",
                "title": "Why Premature Optimization Is the Root of All Evil - Stackify",
                "title_link": "https:\/\/stackify.com\/premature-optimization-evil\/",
                "service_name": "Stackify",
                "fields": [
                    {
                        "value": "Matt Watson",
                        "title": "Written by",
                        "short": true
                    },
                    {
                        "value": "5 minutes",
                        "title": "Est. reading time",
                        "short": true
                    }
                ]
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+aLt0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "For pandas this is very inefficient, but I very much subscribe to worrying about things that materialise. e.g. "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/stackify.com\/premature-optimization-evil\/"
                            },
                            {
                                "type": "text",
                                "text": "\n\nCompute is so cheap, we often don't need to worry about optimisation."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02RN7YDRQ9",
        "type": "message",
        "ts": "1714898769.845359",
        "client_msg_id": "dff566b7-e362-4740-a9de-cda97852e98c",
        "text": "I'm sure lots of people will keep trying that path without regard to the fact of how many subtle errors happen in chatGPT's day job. At the other extreme I get 98% accuracy from my models when I leave the target in the dataset :upside_down_face:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "ge46f1f8b708",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/e46f1f8b708a630e3191de7b2c42b1d1.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png",
            "first_name": "edblock",
            "real_name": "edblock",
            "display_name": "foxwood",
            "team": "T4G9NBD2M",
            "name": "eanb",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714897814.155859",
        "parent_user_id": "U012XF5CNPN",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HreFY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm sure lots of people will keep trying that path without regard to the fact of how many subtle errors happen in chatGPT's day job. At the other extreme I get 98% accuracy from my models when I leave the target in the dataset "
                            },
                            {
                                "type": "emoji",
                                "name": "upside_down_face",
                                "unicode": "1f643"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "rolling_on_the_floor_laughing",
                "users": [
                    "U06R7GCC26B"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U03FS7KM2NL",
        "type": "message",
        "ts": "1714900788.570989",
        "client_msg_id": "E1A1879F-E1A5-4DCA-8854-EDA83BD93A4F",
        "text": "I’d suggest whatever you do that if you have sim data then you should generate the features exclusively from the sim, output to a file and train on that, rather than having two different ways to generate the features. Will save a lot of headache ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g160a197a059",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/160a197a059d9b97aabdd95ca66dc341.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0026-72.png",
            "first_name": "Ralegh",
            "real_name": "Ralegh",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "ralegh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714814434.689879",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kKSPS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I’d"
                            },
                            {
                                "type": "text",
                                "text": " suggest whatever you do that if you have sim data then you should generate the features exclusively from the sim, output to a file and train on that, rather than having two different ways to generate the features. Will save a lot of headache "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEA14GBRR",
        "type": "message",
        "ts": "1714905902.384359",
        "client_msg_id": "f268499b-5cab-47d9-bec1-2bc765731ffb",
        "text": "Why were they asking it for a winner rather than value? Ask a stupid question you get a stupid answer.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "889680f46fe7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-06\/6774538588752_889680f46fe773047cb9_72.jpg",
            "first_name": "",
            "real_name": "Shaun White",
            "display_name": "ShaunW",
            "team": "T4G9NBD2M",
            "name": "shaunwhite",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714897814.155859",
        "parent_user_id": "U012XF5CNPN",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+MqdJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Why were they asking it for a winner rather than value? Ask a stupid question you get a stupid answer."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U06RE5C6X2P",
        "type": "message",
        "ts": "1714906665.184929",
        "client_msg_id": "5AE745EF-6C14-4DAE-8B5E-1421AD42D172",
        "text": "98% accuracy doesn’t mean anything if you’re not matching many bets. I would rather have a lower accuracy and more turnover.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "cf7d00541cd6",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-09-14\/7730063745586_cf7d00541cd6a9a19839_72.jpg",
            "first_name": "James",
            "real_name": "James Scott",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "jamesscott3317",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714897814.155859",
        "parent_user_id": "U012XF5CNPN",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Uy\/hf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "98% accuracy "
                            },
                            {
                                "type": "text",
                                "text": "doesn’t"
                            },
                            {
                                "type": "text",
                                "text": " mean anything if "
                            },
                            {
                                "type": "text",
                                "text": "you’re"
                            },
                            {
                                "type": "text",
                                "text": " not matching many bets. I would rather have a lower accuracy and more turnover."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1714912015.188789",
        "client_msg_id": "d427fca8-33ad-4e02-811d-2fd9085c0504",
        "text": "The people who develop these models are incredibly smart but know nothing about gambling. The price is by far the most important thing to consider. Also, especially in horse racing, I'd say the hardest aspect to overcome is the quality and richness of the data",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714897814.155859",
        "parent_user_id": "U012XF5CNPN",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zq6CC",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The people who develop these models are incredibly smart but know nothing about gambling. The price is by far the most important thing to consider. Also, especially in horse racing, I'd say the hardest aspect to overcome is the quality and richness of the data"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UEA14GBRR",
        "type": "message",
        "ts": "1714914448.182319",
        "client_msg_id": "cf21c6fe-df2c-4355-9df2-adfc6f4f2f77",
        "text": "Horse racing analytics are no different to any other probabity based stats like clinical outcomes or war gaming.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "889680f46fe7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-06\/6774538588752_889680f46fe773047cb9_72.jpg",
            "first_name": "",
            "real_name": "Shaun White",
            "display_name": "ShaunW",
            "team": "T4G9NBD2M",
            "name": "shaunwhite",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714897814.155859",
        "parent_user_id": "U012XF5CNPN",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wylAI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Horse racing analytics are no different to any other probabity based stats like clinical outcomes or war gaming."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714930009.297149",
        "client_msg_id": "5eb4cc29-3ffc-4ba5-bd12-db3f186bb259",
        "text": "has anyone done any benchmarking of flumine's processing time, in particular how much time is spent between a streaming msg being receieved, and process_market_book being called? would be very interested in any results\/profiling outputs that can be shared",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "reply_count": 16,
        "reply_users_count": 4,
        "latest_reply": "1714940743.134239",
        "reply_users": [
            "U06R7GCC26B",
            "U4H19D1D2",
            "U0128E7BEHW",
            "UUE6E1LA1"
        ],
        "replies": [
            {
                "user": "U06R7GCC26B",
                "ts": "1714931575.787319"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1714931896.699529"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1714932833.457749"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1714935007.791139"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1714935341.827309"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1714936927.344569"
            },
            {
                "user": "UUE6E1LA1",
                "ts": "1714938532.139769"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1714939329.138499"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1714939523.949719"
            },
            {
                "user": "UUE6E1LA1",
                "ts": "1714939623.139089"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1714939774.052069"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1714940070.655889"
            },
            {
                "user": "UUE6E1LA1",
                "ts": "1714940170.433539"
            },
            {
                "user": "UUE6E1LA1",
                "ts": "1714940256.534339"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1714940324.732459"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1714940743.134239"
            }
        ],
        "is_locked": false,
        "subscribed": true,
        "last_read": "1714940743.134239",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xVXP5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "has anyone done any benchmarking of flumine's processing time, in particular how much time is spent between a streaming msg being receieved, and process_market_book being called? would be very interested in any results\/profiling outputs that can be shared"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U06R7GCC26B",
        "type": "message",
        "ts": "1714931575.787319",
        "client_msg_id": "0FB9F8B6-6E7F-45A0-853F-10AE04693A0C",
        "text": "Not a direct answer… but this thread had some interesting insights from others on latencies and dropouts \n\n <https:\/\/betcode-org.slack.com\/archives\/C4HL6EZTQ\/p1712431855980549|https:\/\/betcode-org.slack.com\/archives\/C4HL6EZTQ\/p1712431855980549>",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g68a674a57e0",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/68a674a57e001129884dc5a186684950.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0004-72.png",
            "first_name": "Ammar",
            "real_name": "Ammar",
            "display_name": "Ammar",
            "team": "T4G9NBD2M",
            "name": "ammarorama",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "attachments": [
            {
                "from_url": "https:\/\/betcode-org.slack.com\/archives\/C4HL6EZTQ\/p1712431855980549",
                "ts": "1712431855.980549",
                "author_id": "U05N9773A23",
                "channel_id": "C4HL6EZTQ",
                "channel_team": "T4G9NBD2M",
                "is_msg_unfurl": true,
                "is_thread_root_unfurl": true,
                "message_blocks": [
                    {
                        "team": "T4G9NBD2M",
                        "channel": "C4HL6EZTQ",
                        "ts": "1712431855.980549",
                        "message": {
                            "blocks": [
                                {
                                    "type": "rich_text",
                                    "block_id": "Sdyvv",
                                    "elements": [
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "A question for TPD folks on here. How common are missed updates? I've been collecting data for a few months and I've noticed that often the gaps between updates don't reflect the granularity of the data I should be receiving. This happens approx 1\/100 updates according to my queries. By far the worst offender is Wolverhampton- there has been a pattern of missing updates every 10s:\n"
                                                }
                                            ]
                                        },
                                        {
                                            "type": "rich_text_preformatted",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "[2024-03-04 19:00:49 WRN] Data loss - received 19:00:48.800 - last received 19:00:48.200\n[2024-03-04 19:00:59 WRN] Data loss - received 19:00:58.800 - last received 19:00:58.200\n[2024-03-04 19:01:09 WRN] Data loss - received 19:01:08.800 - last received 19:01:08.400\n[2024-03-04 19:01:19 WRN] Data loss - received 19:01:18.800 - last received 19:01:18.400\n[2024-03-04 19:01:29 WRN] Data loss - received 19:01:28.800 - last received 19:01:28.200"
                                                }
                                            ],
                                            "border": 0
                                        },
                                        {
                                            "type": "rich_text_section",
                                            "elements": [
                                                {
                                                    "type": "text",
                                                    "text": "I am starting to become paranoid there is an issue my end. Is this normal or should I be investigating further?"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                ],
                "id": 1,
                "original_url": "https:\/\/betcode-org.slack.com\/archives\/C4HL6EZTQ\/p1712431855980549",
                "fallback": "[April 6th, 2024 12:30 PM] bkwdev: A question for TPD folks on here. How common are missed updates? I've been collecting data for a few months and I've noticed that often the gaps between updates don't reflect the granularity of the data I should be receiving. This happens approx 1\/100 updates according to my queries. By far the worst offender is Wolverhampton- there has been a pattern of missing updates every 10s:\n```[2024-03-04 19:00:49 WRN] Data loss - received 19:00:48.800 - last received 19:00:48.200\n[2024-03-04 19:00:59 WRN] Data loss - received 19:00:58.800 - last received 19:00:58.200\n[2024-03-04 19:01:09 WRN] Data loss - received 19:01:08.800 - last received 19:01:08.400\n[2024-03-04 19:01:19 WRN] Data loss - received 19:01:18.800 - last received 19:01:18.400\n[2024-03-04 19:01:29 WRN] Data loss - received 19:01:28.800 - last received 19:01:28.200```\nI am starting to become paranoid there is an issue my end. Is this normal or should I be investigating further?",
                "text": "A question for TPD folks on here. How common are missed updates? I've been collecting data for a few months and I've noticed that often the gaps between updates don't reflect the granularity of the data I should be receiving. This happens approx 1\/100 updates according to my queries. By far the worst offender is Wolverhampton- there has been a pattern of missing updates every 10s:\n```[2024-03-04 19:00:49 WRN] Data loss - received 19:00:48.800 - last received 19:00:48.200\n[2024-03-04 19:00:59 WRN] Data loss - received 19:00:58.800 - last received 19:00:58.200\n[2024-03-04 19:01:09 WRN] Data loss - received 19:01:08.800 - last received 19:01:08.400\n[2024-03-04 19:01:19 WRN] Data loss - received 19:01:18.800 - last received 19:01:18.400\n[2024-03-04 19:01:29 WRN] Data loss - received 19:01:28.800 - last received 19:01:28.200```\nI am starting to become paranoid there is an issue my end. Is this normal or should I be investigating further?",
                "author_name": "Justice",
                "author_link": "https:\/\/betcode-org.slack.com\/team\/U05N9773A23",
                "author_icon": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=48&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-48.png",
                "author_subname": "Justice",
                "mrkdwn_in": [
                    "text"
                ],
                "footer": "Thread in Slack conversation"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HQdU+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Not a direct answer… but this thread had some interesting insights from others on latencies and dropouts \n\n "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/betcode-org.slack.com\/archives\/C4HL6EZTQ\/p1712431855980549",
                                "text": "https:\/\/betcode-org.slack.com\/archives\/C4HL6EZTQ\/p1712431855980549"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1714931896.699529",
        "client_msg_id": "D868EECF-23C5-4EAB-B32A-D597C7B6F9E1",
        "text": "Is this a loaded question?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "M3pry",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Is this a loaded question?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714932833.457749",
        "client_msg_id": "948072bf-a596-486f-b43c-211ca2f0f2d4",
        "text": "Not at all, just in absence of me doing any live profiling. I'm mainly curious about what people see for: a) streaming update from Betfair to arrive, b) how long it takes flumine to decode + call process_market_book. I can easily profile the logic after that, I am just wondering how much time is spent at various stages before process_market_book and wondering if there were some numbers already!",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "aM9dT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Not at all, just in absence of me doing any live profiling. I'm mainly curious about what people see for: a) streaming update from Betfair to arrive, b) how long it takes flumine to decode + call process_market_book. I can easily profile the logic after that, I am just wondering how much time is spent at various stages before process_market_book and wondering if there were some numbers already!"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1714935007.791139",
        "client_msg_id": "D0A38396-43DF-4532-B3AD-9679CA0C5707",
        "text": "Just load up a profiler and have a look.\n\nI assume you are using bflw speed? After the network JSON decoding is slow but not much we can do about that, the streaming logic is heavily optimised (for python) but creating the python objects in bflw is the slow part however flumine does some clever stuff to try and limit\/remove it. The ‘tick to trade’ code within flumine itself is very minimal and normally rounds to zero relative to what happens within a strategy. ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZTyLm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Just load up a profiler and have a look.\n\nI assume you are using bflw speed? After the network JSON decoding is slow but not much we can do about that, the streaming logic is heavily optimised (for python) but creating the python objects in bflw is the slow part however flumine does some clever stuff to try and limit\/remove it. The ‘tick to trade’ code within flumine itself is very minimal and normally rounds to zero relative to what happens within a strategy. "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714935341.827309",
        "client_msg_id": "d8b9a5e0-0bb8-4c1a-81e1-2d3c5b35cbec",
        "text": "I will check out bflw speed, thanks Liam. I ran profiler when backtesting which helped a lot with optimization within the callbacks, but obviously tells you about nothing network related. I'm basically seeing typically around 10millis between the update's publish time and me asking flumine to place an order. I know my logic is no more than around 1.5ms, so I'm wondering how the rest of the 8-9ms is distributed.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "OsyrJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I will check out bflw speed, thanks Liam. I ran profiler when backtesting which helped a lot with optimization within the callbacks, but obviously tells you about nothing network related. I'm basically seeing typically around 10millis between the update's publish time and me asking flumine to place an order. I know my logic is no more than around 1.5ms, so I'm wondering how the rest of the 8-9ms is distributed."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1714936927.344569",
        "client_msg_id": "5C89D90C-D5E5-4A41-9234-500B47A12F6C",
        "text": "If you are worried about that sort of latency then you are using the wrong language tbh ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "t144K",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If you are worried about that sort of latency then you are using the wrong language tbh "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1714938532.139769",
        "client_msg_id": "caa7b982-db2d-4f04-a5a3-46f0592b3bee",
        "text": "10 milliseconds from publish time to your order being placed? I often get bigger latency as the difference between the publish time and the time I've finished parsing the update, nevermind application logic. I always thought this was a reasonable network latency but looks like I need to up my game!",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "9fJAN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "10 milliseconds from publish time to your order being placed? I often get bigger latency as the difference between the publish time and the time I've finished parsing the update, nevermind application logic. I always thought this was a reasonable network latency but looks like I need to up my game!"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714939329.138499",
        "edited": {
            "user": "U0128E7BEHW",
            "ts": "1714939372.000000"
        },
        "client_msg_id": "1a2f20bb-ae1c-4a1d-862e-feeea451a805",
        "text": "We've had a similar conversation before btw so apologies if it sounds similar! Basically I generally see around 10ms from publish time to placement. I added a few extra strategies to my flumine instance and this went up to about 15ms across the strategies, with one showing even 30ms. So I was kinda surprised, when logic in process_market_book is only around 1.5ms. something's getting clogged up somewhere, which might not be unexpected if the additional strategies are ticking at the same time. So I started poking around in flumine internals to see how it spendsnits time, but form what I can see so far, most of the time before me seems to be network. Looks like flumine internals spend negligible part of this 10ms.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "90U9v",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "We've had a similar conversation before btw so apologies if it sounds similar! Basically I generally see around 10ms from publish time to placement. I added a few extra strategies to my flumine instance and this went up to about 15ms across the strategies, with one showing even 30ms. So I was kinda surprised, when logic in process_market_book is only around 1.5ms. something's getting clogged up somewhere, which might not be unexpected if the additional strategies are ticking at the same time. So I started poking around in flumine internals to see how it spendsnits time, but form what I can see so far, most of the time before me seems to be network. Looks like flumine internals spend negligible part of this 10ms."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714939523.949719",
        "client_msg_id": "d23de772-41e4-4162-8b8b-da6c81552f32",
        "text": "So this basically has me wondering if keeping my median latency at 10ms is simply impossible when adding extra strategies, so I should just distribute instances across more cores, or perhaps somehow do computation out of process",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "rt0bE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So this basically has me wondering if keeping my median latency at 10ms is simply impossible when adding extra strategies, so I should just distribute instances across more cores, or perhaps somehow do computation out of process"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1714939623.139089",
        "client_msg_id": "f3931815-a29e-42da-8f02-a332a447ba71",
        "text": "I'd be quite happy with that to be honest. I use C++ and an event based SSL socket and my average from message publish time to message read off the buffer and parsed as JSON is about 13ms. Of course I don't know if mine and Betfair's clocks are synced but I was pretty happy with this. I suspect if I used a specific thread with a blocking socket connection I would shave a little off it but  you can' get rid of network latency completely.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4EMeu",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'd be quite happy with that to be honest. I use C++ and an event based SSL socket and my average from message publish time to message read off the buffer and parsed as JSON is about 13ms. Of course I don't know if mine and Betfair's clocks are synced but I was pretty happy with this. I suspect if I used a specific thread with a blocking socket connection I would shave a little off it but  you can' get rid of network latency completely."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714939774.052069",
        "client_msg_id": "823865ff-30aa-4e1e-b48d-160e8ea40efd",
        "text": "DC you need to take inspiration from Flumine's book building logic, you could probably bring that down a lot if using c++ !",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tAWyT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "DC you need to take inspiration from Flumine's book building logic, you could probably bring that down a lot if using c++ !"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714940070.655889",
        "client_msg_id": "3b19b5e3-6e45-407f-93c4-e7e7a8460227",
        "text": "Ahh sorry you mentioned that was just taking off the socket and parsing as JSON, not book building. Still, should be able to get it down a looot then!",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2a+1b",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Ahh sorry you mentioned that was just taking off the socket and parsing as JSON, not book building. Still, should be able to get it down a looot then!"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1714940170.433539",
        "client_msg_id": "7ee16c36-7a62-4aea-8c34-41b8749e5d6a",
        "text": "I'm pretty happy with what I've got I'm just intrigued by other people's perceptions of what they deem as acceptable latency. It seems reasonable to me to be waiting 13ms (average) from when Betfair push the JSON out and my having received and parsed it.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "G0\/Ux",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm pretty happy with what I've got I'm just intrigued by other people's perceptions of what they deem as acceptable latency. It seems reasonable to me to be waiting 13ms (average) from when Betfair push the JSON out and my having received and parsed it."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1714940256.534339",
        "client_msg_id": "27170a1e-74c7-4912-aa5b-b00092493989",
        "text": "Is the market book updating in flumine slow then?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uKDVJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Is the market book updating in flumine slow then?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714940324.732459",
        "client_msg_id": "3a40cec2-8af6-4456-8377-b4b154745209",
        "text": "No, book building is super fast. Like I said, outside of my logic in Flumine's post-book-building stage, it seems all my latency is network. Flumine itself doesn't add anything really, latency wise, from what I can see.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "pXocP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "No, book building is super fast. Like I said, outside of my logic in Flumine's post-book-building stage, it seems all my latency is network. Flumine itself doesn't add anything really, latency wise, from what I can see."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1714940743.134239",
        "client_msg_id": "0851944b-94f4-4d6c-a3c1-044188aa7793",
        "text": "And I agree, I'm also intrigued about other ppl's perception here of what they seem acceptable ! Obviously it will be betting-style dependent but still, very curious",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1714930009.297149",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WOH2R",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "And I agree, I'm also intrigued about other ppl's perception here of what they seem acceptable ! Obviously it will be betting-style dependent but still, very curious"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]