[
    {
        "user": "U01B8031PM1",
        "type": "message",
        "ts": "1615370709.015000",
        "client_msg_id": "338cc2ae-9a51-4f1a-8eb2-bfc881975405",
        "text": "what is the best way to achieve async, long running function evaluation that is compute heavy without blocking the main thread in python? want to fire off a function with some parameters, main thread keeps running, and then get called back when it is done with the results provided. function orchestration can take time (so process pool pickling etc is acceptable delay as long as main thread not blocked for too long). don’t think asyncio is what I am looking for. Don’t want to introduce zmq pub sub complexity.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6e482a0e41b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6e482a0e41b232f48d801454006dfa56.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "river_shah",
            "real_name": "river_shah",
            "display_name": "river_shah",
            "team": "T4G9NBD2M",
            "name": "ansar.sa",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lGs",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "what is the best way to achieve async, long running function evaluation that is compute heavy without blocking the main thread in python? want to fire off a function with some parameters, main thread keeps running, and then get called back when it is done with the results provided. function orchestration can take time (so process pool pickling etc is acceptable delay as long as main thread not blocked for too long). don’t think asyncio is what I am looking for. Don’t want to introduce zmq pub sub complexity."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01B8031PM1",
        "type": "message",
        "ts": "1615370802.016200",
        "client_msg_id": "3ccdabce-e456-419e-a957-7f16675d2806",
        "text": "function params and return objects are smallish numpy arrays. can use pre allocated shared mem buffers but that will be a small optimisation",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6e482a0e41b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6e482a0e41b232f48d801454006dfa56.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "river_shah",
            "real_name": "river_shah",
            "display_name": "river_shah",
            "team": "T4G9NBD2M",
            "name": "ansar.sa",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "S76",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "function params and return objects are smallish numpy arrays. can use pre allocated shared mem buffers but that will be a small optimisation"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UGV299K6H",
        "type": "message",
        "ts": "1615372101.017600",
        "edited": {
            "user": "UGV299K6H",
            "ts": "1615372124.000000"
        },
        "client_msg_id": "7856d3a5-d3e2-472a-b7bb-44e983a87daa",
        "text": "On a related topic - can I add to <@U01B8031PM1>'s question and ask if it makes sense to re-write complex functions in C and what the threshold is for when that might become worthwhile?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g3a262a3cfba",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b3a262a3cfba292c18acf5777f65908a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png",
            "first_name": "Michael",
            "real_name": "Michael C",
            "display_name": "Michael",
            "team": "T4G9NBD2M",
            "name": "michael",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "9em",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "On a related topic - can I add to "
                            },
                            {
                                "type": "user",
                                "user_id": "U01B8031PM1"
                            },
                            {
                                "type": "text",
                                "text": "'s question and ask if it makes sense to re-write complex functions in C and what the threshold is for when that might become worthwhile?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1615372220.018900",
        "client_msg_id": "1384959c-d22e-4060-be23-0652f49b5977",
        "text": "You can make python pretty fast (hopefully proved that with bflw\/flumine), C comes at a cost in terms of time\/maintenance, happy to look at code if you want?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oKwoS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "You can make python pretty fast (hopefully proved that with bflw\/flumine), C comes at a cost in terms of time\/maintenance, happy to look at code if you want?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UGV299K6H",
        "type": "message",
        "ts": "1615372260.020300",
        "client_msg_id": "653eaa19-7d35-4476-a200-5c00a2407d2e",
        "text": "More hypothetical at this point. I'm thinking of a more complex race projection type function for TPD.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g3a262a3cfba",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b3a262a3cfba292c18acf5777f65908a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png",
            "first_name": "Michael",
            "real_name": "Michael C",
            "display_name": "Michael",
            "team": "T4G9NBD2M",
            "name": "michael",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jpH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "More hypothetical at this point. I'm thinking of a more complex race projection type function for TPD."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1615372264.020600",
        "client_msg_id": "a72f50b7-5c99-4ee0-a3a3-5fe14333278a",
        "text": "<@U01B8031PM1> most will run the heavy computing in a separate process\/service and use an interface (API) for the trading logic to execute",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "X0\/up",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U01B8031PM1"
                            },
                            {
                                "type": "text",
                                "text": " most will run the heavy computing in a separate process\/service and use an interface (API) for the trading logic to execute"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1615372297.021600",
        "client_msg_id": "887BE205-3386-4509-8220-9D8A4DFDA34D",
        "text": "IMVHO, yes. The threshold would be if you can’t otherwise generate predictions for the strategy in time to act on them...",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZzcQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "IMVHO, yes. The threshold would be if you can’t otherwise generate predictions for the strategy in time to act on them..."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "ULDAVFDRP",
        "type": "message",
        "ts": "1615372699.027500",
        "client_msg_id": "5433d95f-a813-40c0-be08-c6c22876f9e9",
        "text": "separate process + redis (although that goes against pub sub complexity )",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g46fe1c1bf03",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b46fe1c1bf03e18d951e7032fb494283.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0019-72.png",
            "first_name": "",
            "real_name": "Oliver Varney",
            "display_name": "Oliver Varney",
            "team": "T4G9NBD2M",
            "name": "oliverashleyvarney",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6lz",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "separate process + redis (although that goes against pub sub complexity )"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UBS7QANF3"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "UGV299K6H",
        "type": "message",
        "ts": "1615372887.029600",
        "client_msg_id": "b960200a-5e2f-4731-a6c2-a221d809ae1c",
        "text": "Thanks <@UBS7QANF3> and <@U4H19D1D2>. Yeah it's a tricky one - it's not exactly that I'm not in time, but I could make a more accurate forecast. I use super dirty to maths to make a book up really quick and I'd like to do it better but the code I have is very slow.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g3a262a3cfba",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b3a262a3cfba292c18acf5777f65908a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png",
            "first_name": "Michael",
            "real_name": "Michael C",
            "display_name": "Michael",
            "team": "T4G9NBD2M",
            "name": "michael",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uN25",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "UBS7QANF3"
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "user",
                                "user_id": "U4H19D1D2"
                            },
                            {
                                "type": "text",
                                "text": ". Yeah it's a tricky one - it's not exactly that I'm not in time, but I could make a more accurate forecast. I use super dirty to maths to make a book up really quick and I'd like to do it better but the code I have is very slow."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1615374042.037100",
        "client_msg_id": "2d130c57-e8cd-4676-82cc-eef06865bef6",
        "text": "<@UGV299K6H> An obvious (but sometimes overlooked) solution is to replace calculation functions with lookup tables. Even if it's just a simple lookup for implied probabilities (or whatever), it can be faster than calculating repeatedly. Sometimes it's faster to have multiple small LUT's rather than one big one, with each lookup providing the key(s) to some other table.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "kPY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UGV299K6H"
                            },
                            {
                                "type": "text",
                                "text": " An obvious (but sometimes overlooked) solution is to replace calculation functions with lookup tables. Even if it's just a simple lookup for implied probabilities (or whatever), it can be faster than calculating repeatedly. Sometimes it's faster to have multiple small LUT's rather than one big one, with each lookup providing the key(s) to some other table."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1615374105.037400",
        "client_msg_id": "974db8a8-db60-4bb6-a18a-a07e8d20afdc",
        "text": "+1 @lru_cache can be your friend",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4lNl2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "+1 @lru_cache can be your friend"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UGV299K6H",
        "type": "message",
        "ts": "1615374257.038800",
        "client_msg_id": "391b218b-8a21-4f49-be8b-ac67cc9ca281",
        "text": "Thanks <@U016TGY3676>, that's not going to work for what I had in mind but I could probably deploy it elsewhere.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g3a262a3cfba",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b3a262a3cfba292c18acf5777f65908a.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0006-72.png",
            "first_name": "Michael",
            "real_name": "Michael C",
            "display_name": "Michael",
            "team": "T4G9NBD2M",
            "name": "michael",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Dx8G",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "U016TGY3676"
                            },
                            {
                                "type": "text",
                                "text": ", that's not going to work for what I had in mind but I could probably deploy it elsewhere."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01B8031PM1",
        "type": "message",
        "ts": "1615374402.041000",
        "edited": {
            "user": "U01B8031PM1",
            "ts": "1615374525.000000"
        },
        "client_msg_id": "a9f0a710-0365-46fe-9c0a-8e1b44340384",
        "text": "<@U4H19D1D2> was hoping for something like this: <https:\/\/github.com\/taskflow\/taskflow> (see the section on launch async tasks) but for python. ok, looks like with python I will need to embrace zmq for these kind of function calls. totally happy with python speeds, however the gil does get in the way of these async function \/ task evals",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6e482a0e41b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6e482a0e41b232f48d801454006dfa56.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "river_shah",
            "real_name": "river_shah",
            "display_name": "river_shah",
            "team": "T4G9NBD2M",
            "name": "ansar.sa",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "attachments": [
            {
                "fallback": "taskflow\/taskflow",
                "text": "A General-purpose Parallel and Heterogeneous Task Programming System",
                "title": "taskflow\/taskflow",
                "footer": "<https:\/\/github.com\/taskflow\/taskflow|taskflow\/taskflow>",
                "id": 1,
                "footer_icon": "https:\/\/github.githubassets.com\/favicon.ico",
                "ts": 1524059130,
                "color": "24292f",
                "fields": [
                    {
                        "title": "Website",
                        "value": "<https:\/\/taskflow.github.io>",
                        "short": true
                    },
                    {
                        "title": "Stars",
                        "value": "5017",
                        "short": true
                    }
                ],
                "mrkdwn_in": [
                    "text",
                    "fields"
                ],
                "bot_id": "B01144Z0734",
                "app_unfurl_url": "https:\/\/github.com\/taskflow\/taskflow",
                "is_app_unfurl": true
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hvJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U4H19D1D2"
                            },
                            {
                                "type": "text",
                                "text": " was hoping for something like this: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/taskflow\/taskflow"
                            },
                            {
                                "type": "text",
                                "text": " (see the section on launch async tasks) but for python. ok, looks like with python I will need to embrace zmq for these kind of function calls. totally happy with python speeds, however the gil does get in the way of these async function \/ task evals"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01B8031PM1",
        "type": "message",
        "ts": "1615374600.042100",
        "client_msg_id": "006ba47c-2219-4f15-983f-8aebeddcf7ff",
        "text": "<@UGV299K6H> cython is also great. would highly recommend and the learning curve is very easy.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6e482a0e41b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6e482a0e41b232f48d801454006dfa56.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "river_shah",
            "real_name": "river_shah",
            "display_name": "river_shah",
            "team": "T4G9NBD2M",
            "name": "ansar.sa",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4nT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UGV299K6H"
                            },
                            {
                                "type": "text",
                                "text": " cython is also great. would highly recommend and the learning curve is very easy."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UGV299K6H"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1615374892.042900",
        "client_msg_id": "f7786812-422d-4e45-b231-cdf6ad6addbf",
        "text": "multiprocessing is pretty sufficient for firing stuff off in a seperate process",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1615374892.042900",
        "reply_count": 3,
        "reply_users_count": 2,
        "latest_reply": "1615376843.043700",
        "reply_users": [
            "U01B8031PM1",
            "U0128E7BEHW"
        ],
        "replies": [
            {
                "user": "U01B8031PM1",
                "ts": "1615375216.043000"
            },
            {
                "user": "U01B8031PM1",
                "ts": "1615375725.043500"
            },
            {
                "user": "U0128E7BEHW",
                "ts": "1615376843.043700"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "++L",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "multiprocessing is pretty sufficient for firing stuff off in a seperate process"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01B8031PM1",
        "type": "message",
        "ts": "1615375216.043000",
        "edited": {
            "user": "U01B8031PM1",
            "ts": "1615375426.000000"
        },
        "client_msg_id": "98666219-2397-4b53-8677-1e645867be2c",
        "text": "how do I collect results please without waiting on the future?\n```exe = ProcessPoolExecutor()\nfutures = exe.map(partial(some_heavy_func, params), iterator)\n# keep executing main thread\n# use shared mem and dump some_heavy_func results in that?```\nalso, ideally I don’t want to poll for result, how does main thread know fresh results await?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6e482a0e41b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6e482a0e41b232f48d801454006dfa56.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "river_shah",
            "real_name": "river_shah",
            "display_name": "river_shah",
            "team": "T4G9NBD2M",
            "name": "ansar.sa",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1615374892.042900",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jTA3",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "how do I collect results please without waiting on the future?\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "exe = ProcessPoolExecutor()\nfutures = exe.map(partial(some_heavy_func, params), iterator)\n# keep executing main thread\n# use shared mem and dump some_heavy_func results in that?"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "also, ideally I don’t want to poll for result, how does main thread know fresh results await?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01B8031PM1",
        "type": "message",
        "ts": "1615375725.043500",
        "client_msg_id": "00744dc7-7377-4b1c-905a-ce23a96c1ccb",
        "text": "sorry if this is more stack overflow question",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6e482a0e41b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6e482a0e41b232f48d801454006dfa56.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "river_shah",
            "real_name": "river_shah",
            "display_name": "river_shah",
            "team": "T4G9NBD2M",
            "name": "ansar.sa",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1615374892.042900",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hUCYB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "sorry if this is more stack overflow question"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U0128E7BEHW",
        "type": "message",
        "ts": "1615376843.043700",
        "client_msg_id": "2d05bc55-b62f-4acc-83cb-59ea9e30b032",
        "text": "What do you want your call back to do? Best way is to launch a thread in the main process, this thread runs the out of process computation and blocks on it. The blocking of your secondary thread won't block your main thread, and when your out of process execution is complete, the secondary thread will wake up and execute logic based on these results.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb57a2bdd15a",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b57a2bdd15acccdb845ce257f38940cc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0024-72.png",
            "first_name": "Dave",
            "real_name": "Dave R",
            "display_name": "Dave",
            "team": "T4G9NBD2M",
            "name": "d7m",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1615374892.042900",
        "parent_user_id": "U0128E7BEHW",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "klm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "What do you want your call back to do? Best way is to launch a thread in the main process, this thread runs the out of process computation and blocks on it. The blocking of your secondary thread won't block your main thread, and when your out of process execution is complete, the secondary thread will wake up and execute logic based on these results."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "subtype": "channel_join",
        "user": "U01R51SFB09",
        "text": "<@U01R51SFB09> has joined the channel",
        "type": "message",
        "ts": "1615377698.044100"
    },
    {
        "subtype": "channel_join",
        "user": "U01R0JE9EJY",
        "text": "<@U01R0JE9EJY> has joined the channel",
        "type": "message",
        "ts": "1615402815.046900"
    }
]