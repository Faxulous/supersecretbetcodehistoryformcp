[
    {
        "user": "UQL0QDEKA",
        "type": "message",
        "ts": "1692779727.735569",
        "client_msg_id": "159b9583-7d69-4354-8580-0150cd0d4e98",
        "text": "For X, Think of something that makes sense\/logical (or gut feel). then branch out and see where it takes you\nBy the way, I recorded he following in my CSV:\n\n\n```def process_market_book(self, market, market_book):\n    with open(self.file_directory, \"a\") as f:\n        writer = csv.DictWriter(f, fieldnames=HEADERS)\n        for runner in market_book.runners:\n            writer.writerow(\n                {\n                    \"market_id\": market_book.market_id,\n                    \"publish_time\": market_book.publish_time,\n                    \"status\": market_book.status,\n                    \"inplay\": market_book.inplay,\n                    \"selection_id\": runner.selection_id,\n                    \"last_price_traded\": runner.last_price_traded,\n                    \"back\": get_price(runner.ex.available_to_back, 0),\n                    \"lay\": get_price(runner.ex.available_to_lay, 0),\n                    \"sp\": runner.sp.actual_sp,\n                    \"cross_matching\": market_book.cross_matching,\n                    \"runner_matched\": runner.total_matched,\n                    \"venue\": market.venue,\n\n                }\n            )```\nand I included SP and Runner Matched in the features of the ML. For my  Inplay strat it rated SP and Runner Matched of high importance using ML, which is what you would expect. This gave me some confidence that the model was working as intended.\nPS looking at the CSV header you posted I think you need to add more stuff in there as a minimum back book, lay book, Back,lay and LTP etc",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g444d10128c0",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/444d10128c0aaf094041a52a76796602.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
            "first_name": "Peter",
            "real_name": "Peter Lenagh",
            "display_name": "PeterLe",
            "team": "T4G9NBD2M",
            "name": "lenagh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "e4Qc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "For X, Think of something that makes sense\/logical (or gut feel). then branch out and see where it takes you\nBy the way, I recorded he following in my CSV:\n\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "def process_market_book(self, market, market_book):\n    with open(self.file_directory, \"a\") as f:\n        writer = csv.DictWriter(f, fieldnames=HEADERS)\n        for runner in market_book.runners:\n            writer.writerow(\n                {\n                    \"market_id\": market_book.market_id,\n                    \"publish_time\": market_book.publish_time,\n                    \"status\": market_book.status,\n                    \"inplay\": market_book.inplay,\n                    \"selection_id\": runner.selection_id,\n                    \"last_price_traded\": runner.last_price_traded,\n                    \"back\": get_price(runner.ex.available_to_back, 0),\n                    \"lay\": get_price(runner.ex.available_to_lay, 0),\n                    \"sp\": runner.sp.actual_sp,\n                    \"cross_matching\": market_book.cross_matching,\n                    \"runner_matched\": runner.total_matched,\n                    \"venue\": market.venue,\n\n                }\n            )"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "and I included SP and Runner Matched in the features of the ML. For my  Inplay strat it rated SP and Runner Matched of high importance using ML, which is what you would expect. This gave me some confidence that the model was working as intended.\nPS looking at the CSV header you posted I think you need to add more stuff in there as a minimum back book, lay book, Back,lay and LTP etc"
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U01PJ5YMFBJ"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U05L8PZD2FM",
        "type": "message",
        "ts": "1692780501.499769",
        "client_msg_id": "8e2a093a-7827-4eba-8c9e-f04189ec4b20",
        "text": "<@UQL0QDEKA> I'm trying to understand what you are doing  so I can maybe advise a bit. You have a bunch of independent vars including implied probability (prices) and a dependent var of whether the runner won or lost and you are trying to build a classifier to tell you what exactly?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb417ed434bb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b417ed434bbea199d58a9b4bd0affeb9.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png",
            "first_name": "Joe",
            "real_name": "Joe",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "stapleton_joe",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "t9uVD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UQL0QDEKA"
                            },
                            {
                                "type": "text",
                                "text": " I'm trying to understand what you are doing  so I can maybe advise a bit. You have a bunch of independent vars including implied probability (prices) and a dependent var of whether the runner won or lost and you are trying to build a classifier to tell you what exactly?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05L8PZD2FM",
        "type": "message",
        "ts": "1692780901.122219",
        "edited": {
            "user": "U05L8PZD2FM",
            "ts": "1692780966.000000"
        },
        "client_msg_id": "11b491fc-8249-4689-ae35-2ba4a1a8bf6a",
        "text": "The obvious trap being to avoid it telling you what you already know that the implied probability is fairly well calibrated.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb417ed434bb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b417ed434bbea199d58a9b4bd0affeb9.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png",
            "first_name": "Joe",
            "real_name": "Joe",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "stapleton_joe",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BsN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The obvious trap being to avoid it telling you what you already know that the implied probability is fairly well calibrated."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1692781027.289779",
        "edited": {
            "user": "UUE6E1LA1",
            "ts": "1692781046.000000"
        },
        "client_msg_id": "b9af1d12-d9a6-4765-9fb1-5d67dd3ac57b",
        "text": "Thinking of using flumine to backtest but I am pretty sure my data exists in a format slightly different to that recorded by bflw and\/or betfair pro data. Basically can someone tell me how I need to modify it or provide a couple of lines example code from a flumine\/bflw recorded market log?\n\nMy data is recorded as a | delimited string on a per market basis as follows:\n\nmessage receive timestamp | pt extracted from main message | JSON string of market change message extracted from the list in the main message\n\nBasically I parse a message, Identify market for each individual msm contained in the mc list and write that mc to the log file for the market in question. Also scattered in the file are calls to response of listMarketCatalogue that I will call whenever a suspension is detected (easily identified and removed).\n\nIn short, how much alteration is required to get into a flumine compatible format?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692781027.289779",
        "reply_count": 2,
        "reply_users_count": 2,
        "latest_reply": "1692787925.520119",
        "reply_users": [
            "U4H19D1D2",
            "UUE6E1LA1"
        ],
        "replies": [
            {
                "user": "U4H19D1D2",
                "ts": "1692787640.605999"
            },
            {
                "user": "UUE6E1LA1",
                "ts": "1692787925.520119"
            }
        ],
        "is_locked": false,
        "subscribed": true,
        "last_read": "1692787925.520119",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Fs1kx",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thinking of using flumine to backtest but I am pretty sure my data exists in a format slightly different to that recorded by bflw and\/or betfair pro data. Basically can someone tell me how I need to modify it or provide a couple of lines example code from a flumine\/bflw recorded market log?\n\nMy data is recorded as a | delimited string on a per market basis as follows:\n\nmessage receive timestamp | pt extracted from main message | JSON string of market change message extracted from the list in the main message\n\nBasically I parse a message, Identify market for each individual msm contained in the mc list and write that mc to the log file for the market in question. Also scattered in the file are calls to response of listMarketCatalogue that I will call whenever a suspension is detected (easily identified and removed).\n\nIn short, how much alteration is required to get into a flumine compatible format?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UQL0QDEKA",
        "type": "message",
        "ts": "1692781917.334809",
        "client_msg_id": "73b52a19-5532-4a05-b49c-06621f589028",
        "text": "Morning Joe. This was really my first attempt at looking at ML. Probably best described as a random walk.:grinning:\nMy initial thoughts were, how to use ML to enhance, refine existing starts and secondly; use ML to look at the recorded data I had and run it against that to see what it found. (no preconceived ideas etc)\nHaving read up a little, I thought that feature importance may be a good place to start.\nI did learn something from the feature importance (Which is not shown above). It is something that I haven't used in my in play stuff but now that ML has made it aware to me, it makes perfect sense and Im testing that in a live environment (1 day in).\nAs input Joe, maybe you could tell me the basic building blocks how you might go about this (just bullet points will do please)\nie :\n• Record Live update data from the API (Doing that)\n• use the price recorded to capture various variables (eg back, lay, ltp, books etc ) to a large CSV (Doing that)\nWhat generic steps would you take from this point?\nThanks Joe\n(PS I need to go offline for a few hours Joe, work calls - Thanks)",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g444d10128c0",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/444d10128c0aaf094041a52a76796602.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
            "first_name": "Peter",
            "real_name": "Peter Lenagh",
            "display_name": "PeterLe",
            "team": "T4G9NBD2M",
            "name": "lenagh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ChpY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Morning Joe. This was really my first attempt at looking at ML. Probably best described as a random walk."
                            },
                            {
                                "type": "emoji",
                                "name": "grinning",
                                "unicode": "1f600"
                            },
                            {
                                "type": "text",
                                "text": "\nMy initial thoughts were, how to use ML to enhance, refine existing starts and secondly; use ML to look at the recorded data I had and run it against that to see what it found. (no preconceived ideas etc)\nHaving read up a little, I thought that feature importance may be a good place to start.\nI did learn something from the feature importance (Which is not shown above). It is something that I haven't used in my in play stuff but now that ML has made it aware to me, it makes perfect sense and Im testing that in a live environment (1 day in).\nAs input Joe, maybe you could tell me the basic building blocks how you might go about this (just bullet points will do please)\nie :\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Record Live update data from the API (Doing that)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "use the price recorded to capture various variables (eg back, lay, ltp, books etc ) to a large CSV (Doing that)"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "What generic steps would you take from this point?\nThanks Joe\n(PS I need to go offline for a few hours Joe, work calls - Thanks)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05L8PZD2FM",
        "type": "message",
        "ts": "1692784955.305209",
        "edited": {
            "user": "U05L8PZD2FM",
            "ts": "1692787139.000000"
        },
        "client_msg_id": "558f8f48-fb6e-4a23-9bf2-58b41d77c3ab",
        "text": "These are two quite different tasks, 1) optimise strategy parameterisation using ML and 2) generating new strategies using ML, I'm not going to discuss 2 as it is vast topic and I've used many different approaches from simple recurrent networks to genetic programming.\n\nTask 1 however is easier to describe. You have a set of (many 1000s of) markets with supporting data, M. You have a strategy S (m, p) that takes a single market's data m and p parameters and returns a profit. S is just conditional logic and state (e.g. its current position), p are the parameters of that logic (e.g. the 'x' in if (price &lt; x) ). Your goal is to find p that maximises something you want, we'll use profit here but in reality you'll want to fiddle with this. The complexity is you (usually) cannot label up all the data in M with a dependent variable \"should_i_bet\", if you can then easy - simple classification problem solvable through any supervised ML procedure, however in almost all cases you cannot since the answer to \"should_i_bet\" is infact what we are searching for.\n\nA way around this is currying the above into a new function F (p) = C(S, M) which returns the total profit when S is run over the full set of markets M with params p.\n\nWe can now use brute force, or preferably some guided brute force (unsupervised ML) to find p that maximises profit.\n\nWe do the usual train \/ test split on the data, and start searching for p with an appropriate search algorithm, I would suggest particle swarm optimisation as a simple starting point. I don't use python but there will definitely be implementations of PSO available.\n\nSo we effectively execute\n``` MTrain, MTest = split(M)\n FTrain = C(S, MTrain)\n FTest = C(S, MTest)\n p = PSO.search(Ftrain, Ftest) ```\nSo that is one way to do it, there are many others but which is right depends completely on how you phrase\/frame the problem you are trying to solve. The obvious drawbacks of this approach are 1) you need a strategy to optimise, 2) there are many tricks that are needed to avoid overfitting \/ curse of dimensionality, 3) you need to quite a lot of hardware, code and data optimisation to get the execution frequency required for this type of ML.\n\nOne implication of rephrasing an existing strategy for this type of search is you may find other applications of it. Imagine the profit surface wrt p looks like the Alps. You have manually tweaked p over the years and are squarely centered on Mont Blanc. With a bit of ML guided search with some diversity forced into the mix, you maybe able to find p for other profit peaks such as the Matterhorn or Finsteraarhorn. What you have now achieved is not an ensemble but a set of independent profitable strategies.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gb417ed434bb",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/b417ed434bbea199d58a9b4bd0affeb9.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png",
            "first_name": "Joe",
            "real_name": "Joe",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "stapleton_joe",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Jr6",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "These are two quite different tasks, 1) optimise strategy parameterisation using ML and 2) generating new strategies using ML, I'm not going to discuss 2 as it is vast topic and I've used many different approaches from simple recurrent networks to genetic programming.\n\nTask 1 however is easier to describe. You have a set of (many 1000s of) markets with supporting data, M. You have a strategy S (m, p) that takes a single market's data m and p parameters and returns a profit. S is just conditional logic and state (e.g. its current position), p are the parameters of that logic (e.g. the 'x' in if (price < x) ). Your goal is to find p that maximises something you want, we'll use profit here but in reality you'll want to fiddle with this. The complexity is you (usually) cannot label up all the data in M with a dependent variable \"should_i_bet\", if you can then easy - simple classification problem solvable through any supervised ML procedure, however in almost all cases you cannot since the answer to \"should_i_bet\" is infact what we are searching for.\n\nA way around this is currying the above into a new function F (p) = C(S, M) which returns the total profit when S is run over the full set of markets M with params p.\n\nWe can now use brute force, or preferably some guided brute force (unsupervised ML) to find p that maximises profit.\n\nWe do the usual train \/ test split on the data, and start searching for p with an appropriate search algorithm, I would suggest particle swarm optimisation as a simple starting point. I don't use python but there will definitely be implementations of PSO available.\n\nSo we effectively execute\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": " MTrain, MTest = split(M)\n FTrain = C(S, MTrain)\n FTest = C(S, MTest)\n p = PSO.search(Ftrain, Ftest) "
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nSo that is one way to do it, there are many others but which is right depends completely on how you phrase\/frame the problem you are trying to solve. The obvious drawbacks of this approach are 1) you need a strategy to optimise, 2) there are many tricks that are needed to avoid overfitting \/ curse of dimensionality, 3) you need to quite a lot of hardware, code and data optimisation to get the execution frequency required for this type of ML.\n\nOne implication of rephrasing an existing strategy for this type of search is you may find other applications of it. Imagine the profit surface wrt p looks like the Alps. You have manually tweaked p over the years and are squarely centered on Mont Blanc. With a bit of ML guided search with some diversity forced into the mix, you maybe able to find p for other profit peaks such as the Matterhorn or Finsteraarhorn. What you have now achieved is not an ensemble but a set of independent profitable strategies."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1692787640.605999",
        "client_msg_id": "1dbafc07-2429-438f-a143-fb69d63568c7",
        "text": "Just needs to be in the betfair format so I imagine not much work to parse out",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692781027.289779",
        "parent_user_id": "UUE6E1LA1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RZB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Just needs to be in the betfair format so I imagine not much work to parse out"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1692787925.520119",
        "client_msg_id": "fd53eaa2-e3f4-4119-bfd0-187f98c7d9aa",
        "text": "ok ill try and find the code that does the logging and see how it treats the pt field - that is my chief concern. I can always create clk fields with artificial junk if the code expects it",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692781027.289779",
        "parent_user_id": "UUE6E1LA1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "pcZ1f",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "ok ill try and find the code that does the logging and see how it treats the pt field - that is my chief concern. I can always create clk fields with artificial junk if the code expects it"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U030GKBMCBF",
        "type": "message",
        "ts": "1692789593.851419",
        "client_msg_id": "7B888614-7CA0-49D1-A414-86AAEC543FD0",
        "text": "Make sure you are using appropriate feature importance methods if you do go down that route <https:\/\/explained.ai\/rf-importance\/|https:\/\/explained.ai\/rf-importance\/>",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "c8efe9a619a7",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-01-27\/3012906420054_c8efe9a619a784f8fc22_72.png",
            "first_name": "Leo",
            "real_name": "Leo",
            "display_name": "Leo",
            "team": "T4G9NBD2M",
            "name": "leomccarthy709",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "attachments": [
            {
                "image_url": "http:\/\/explained.ai\/rf-importance\/images\/cls_dflt_random_annotated.png",
                "image_width": 2412,
                "image_height": 768,
                "image_bytes": 125237,
                "from_url": "https:\/\/explained.ai\/rf-importance\/",
                "id": 1,
                "original_url": "https:\/\/explained.ai\/rf-importance\/",
                "fallback": "Beware Default Random Forest Importances",
                "text": "Training a model that accurately predicts outcomes is great, but most of the time you don't just need predictions, you want to be able to interpret your model. The problem is that the scikit-learn Random Forest feature importance and R's default Random Forest feature importance strategies are biased. To get reliable results in Python, use permutation importance, provided here and in our rfpimp package (via pip). For R, use importance=T in the Random Forest constructor then type=1 in R's importance() function.",
                "title": "Beware Default Random Forest Importances",
                "title_link": "https:\/\/explained.ai\/rf-importance\/",
                "service_name": "explained.ai"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "yswZb",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Make sure you are using appropriate feature importance methods if you do go down that route "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/explained.ai\/rf-importance\/",
                                "text": "https:\/\/explained.ai\/rf-importance\/"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UQL0QDEKA",
        "type": "message",
        "ts": "1692797298.527019",
        "client_msg_id": "d83ae41a-fcf5-40e2-ae37-ce35a84ebf5f",
        "text": "Thanks Joe for taking the time to explain that. Its a big topic. That right there looks like months of learning. I'm not in any rush and I know there are no short cuts at this level. I've the time and patience to do that\nIll just keep on learning in general about this and see where it takes me The learning curve tends to be steep when doing something new, so keen to check it out.\nLeo, thanks for your comments. Ill check that out too\nThanks chaps",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g444d10128c0",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/444d10128c0aaf094041a52a76796602.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
            "first_name": "Peter",
            "real_name": "Peter Lenagh",
            "display_name": "PeterLe",
            "team": "T4G9NBD2M",
            "name": "lenagh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Mvb",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks Joe for taking the time to explain that. Its a big topic. That right there looks like months of learning. I'm not in any rush and I know there are no short cuts at this level. I've the time and patience to do that\nIll just keep on learning in general about this and see where it takes me The learning curve tends to be steep when doing something new, so keen to check it out.\nLeo, thanks for your comments. Ill check that out too\nThanks chaps"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UQL0QDEKA",
        "type": "message",
        "ts": "1692802398.341279",
        "client_msg_id": "5ab8b081-7f51-4d69-aa5d-001aa2d4ba39",
        "text": "<@U030GKBMCBF> Just some feedback...\nI asked chatgpt to comment on your suggestion in the context of my code...this is what is said ;\n\n_The advice your colleague provided is quite accurate. Default feature importances from Random Forest models in scikit-learn can indeed be biased, particularly when the dataset includes different types of features (e.g., categorical and numerical). This bias might lead to incorrect conclusions about the importance of the features._\n_In your code, you were using the default feature importance method by calling the `feature_importances_` attribute from the Random Forest model. This approach calculates feature importance based on the average depth at which each feature appears in the trees of the forest. While it is a common approach, it can be misleading._\n_A more reliable way to assess feature importance is to use permutation importance. Permutation importance works by randomly shuffling the values of a single feature and measuring the resulting decrease in the model's performance. This decrease reflects the importance of that feature._\n\n(provided some suggestions for code)\n\n_This method will give you a more unbiased estimate of feature importance, taking into account the potential correlation between features and the different scales and types of features._\n_Remember to remove or comment out the old code that calculated feature importance using `feature_importances_`._\n_So, to answer your question, considering permutation importance would be an excellent improvement to your code, and it aligns with best practices in machine learning._\n\nSo spot on, thanks again :+1:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g444d10128c0",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/444d10128c0aaf094041a52a76796602.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
            "first_name": "Peter",
            "real_name": "Peter Lenagh",
            "display_name": "PeterLe",
            "team": "T4G9NBD2M",
            "name": "lenagh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "IsW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U030GKBMCBF"
                            },
                            {
                                "type": "text",
                                "text": " Just some feedback...\nI asked chatgpt to comment on your suggestion in the context of my code...this is what is said ;\n\n"
                            },
                            {
                                "type": "text",
                                "text": "The advice your colleague provided is quite accurate. Default feature importances from Random Forest models in scikit-learn can indeed be biased, particularly when the dataset includes different types of features (e.g., categorical and numerical). This bias might lead to incorrect conclusions about the importance of the features.",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "In your code, you were using the default feature importance method by calling the ",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "feature_importances_",
                                "style": {
                                    "italic": true,
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " attribute from the Random Forest model. This approach calculates feature importance based on the average depth at which each feature appears in the trees of the forest. While it is a common approach, it can be misleading.",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "A more reliable way to assess feature importance is to use permutation importance. Permutation importance works by randomly shuffling the values of a single feature and measuring the resulting decrease in the model's performance. This decrease reflects the importance of that feature.",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\n(provided some suggestions for code)\n\n"
                            },
                            {
                                "type": "text",
                                "text": "This method will give you a more unbiased estimate of feature importance, taking into account the potential correlation between features and the different scales and types of features.",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "Remember to remove or comment out the old code that calculated feature importance using ",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "feature_importances_",
                                "style": {
                                    "italic": true,
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ".",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "So, to answer your question, considering permutation importance would be an excellent improvement to your code, and it aligns with best practices in machine learning.",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\nSo spot on, thanks again "
                            },
                            {
                                "type": "emoji",
                                "name": "+1",
                                "unicode": "1f44d"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U02RN7YDRQ9",
        "type": "message",
        "ts": "1692806454.386849",
        "client_msg_id": "1c32f114-6215-4a42-9dea-f4c7782ffa44",
        "text": "Fascinated by the depth of replies you seem to get on gpt now - is that using the plus version and not the freebie ?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "ge46f1f8b708",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/e46f1f8b708a630e3191de7b2c42b1d1.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png",
            "first_name": "edblock",
            "real_name": "edblock",
            "display_name": "foxwood",
            "team": "T4G9NBD2M",
            "name": "eanb",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uHu\/f",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Fascinated by the depth of replies you seem to get on gpt now - is that using the plus version and not the freebie ?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UQL0QDEKA",
        "type": "message",
        "ts": "1692808336.207759",
        "client_msg_id": "b10d9621-9f07-44df-bad5-e74696c6f1ba",
        "text": "Yep he plus version Foxwood\nIve just recoded to include the comments by Leo, results are:\nRandom Forest Accuracy: 0.9062742305480078\nTotal Profit\/Loss using Simple strategy: £26007.66999999987\nTotal Profit\/Loss using ML strategy for X 1.19: £22294.659999999945\n             Feature  Importance\n0  last_price_traded    0.116026\n1               back    0.093928\n2                lay    0.107229\n3          back_book    0.206596\n4           lay_book    0.203972\n5           ltp_book    0.193442\n6             Spread    0.075818\n7     cross_matching    0.002990\n(note: I found an error in my simple strategy :grinning: that why it was such a massive negative in previous text)\nWhat is interesting now is that the ML seems to give a worse result :thinking_face:",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g444d10128c0",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/444d10128c0aaf094041a52a76796602.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
            "first_name": "Peter",
            "real_name": "Peter Lenagh",
            "display_name": "PeterLe",
            "team": "T4G9NBD2M",
            "name": "lenagh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "g30CZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yep he plus version Foxwood\nIve just recoded to include the comments by Leo, results are:\nRandom Forest Accuracy: 0.9062742305480078\nTotal Profit\/Loss using Simple strategy: £26007.66999999987\nTotal Profit\/Loss using ML strategy for X 1.19: £22294.659999999945\n             Feature  Importance\n0  last_price_traded    0.116026\n1               back    0.093928\n2                lay    0.107229\n3          back_book    0.206596\n4           lay_book    0.203972\n5           ltp_book    0.193442\n6             Spread    0.075818\n7     cross_matching    0.002990\n(note: I found an error in my simple strategy "
                            },
                            {
                                "type": "emoji",
                                "name": "grinning",
                                "unicode": "1f600"
                            },
                            {
                                "type": "text",
                                "text": " that why it was such a massive negative in previous text)\nWhat is interesting now is that the ML seems to give a worse result "
                            },
                            {
                                "type": "emoji",
                                "name": "thinking_face",
                                "unicode": "1f914"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1692815798.289539",
        "client_msg_id": "93448F5B-47ED-481D-AF25-EB137FF275C4",
        "text": "Have you plotted the profit? ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "1wa",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Have you plotted the profit? "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UQL0QDEKA",
        "type": "message",
        "ts": "1692817953.849729",
        "client_msg_id": "DA9DAF4F-F8AD-45F0-9497-BE444D6D3061",
        "text": "Good point no I haven’t, I’ll have a look tomorrow :+1: it’s only a month data though and my regular stuff isn’t a straight line up left to right",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g444d10128c0",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/444d10128c0aaf094041a52a76796602.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
            "first_name": "Peter",
            "real_name": "Peter Lenagh",
            "display_name": "PeterLe",
            "team": "T4G9NBD2M",
            "name": "lenagh",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1692712909.007769",
        "parent_user_id": "UQL0QDEKA",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "qkPw\/",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Good point no I "
                            },
                            {
                                "type": "text",
                                "text": "haven’t"
                            },
                            {
                                "type": "text",
                                "text": ", "
                            },
                            {
                                "type": "text",
                                "text": "I’ll"
                            },
                            {
                                "type": "text",
                                "text": " have a look tomorrow "
                            },
                            {
                                "type": "emoji",
                                "name": "+1",
                                "unicode": "1f44d"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "text",
                                "text": "it’s"
                            },
                            {
                                "type": "text",
                                "text": " only a month data though and my regular stuff "
                            },
                            {
                                "type": "text",
                                "text": "isn’t"
                            },
                            {
                                "type": "text",
                                "text": " a straight line up left to right"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]