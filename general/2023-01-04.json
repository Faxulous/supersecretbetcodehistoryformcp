[
    {
        "user": "URMM9463X",
        "type": "message",
        "ts": "1672823051.286549",
        "edited": {
            "user": "URMM9463X",
            "ts": "1672823089.000000"
        },
        "client_msg_id": "324e6a98-0f6a-4d43-91b0-cb5931034f2a",
        "text": "<@U016TGY3676> understood - I don't create new environments that often in production so I'm setting up manually. And in dev I'm letting Pycharm create its own envs for me.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf57720914be",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f57720914be90dd532faed6bdadad7ca.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
            "first_name": "Xxx",
            "real_name": "Xxx",
            "display_name": "D",
            "team": "T4G9NBD2M",
            "name": "derekclements67",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1672782898.956829",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ab2\/f",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U016TGY3676"
                            },
                            {
                                "type": "text",
                                "text": " understood - I don't create new environments that often in production so I'm setting up manually. And in dev I'm letting Pycharm create its own envs for me."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U016TGY3676"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U01C12ZEADQ",
        "type": "message",
        "ts": "1672824819.841729",
        "client_msg_id": "0ab5baa0-8969-4491-a2d0-632101e501de",
        "text": "<@UBS7QANF3> correct.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "e3b7687b0ef8",
            "image_72": "https:\/\/avatars.slack-edge.com\/2020-10-06\/1432945617648_e3b7687b0ef86e4f28b8_72.png",
            "first_name": "Alessio",
            "real_name": "Alessio",
            "display_name": "Alessio",
            "team": "T4G9NBD2M",
            "name": "alessio",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1672757000.845329",
        "parent_user_id": "U03TJKFLE8K",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZhpSv",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UBS7QANF3"
                            },
                            {
                                "type": "text",
                                "text": " correct."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U034LK55D3P",
        "type": "message",
        "ts": "1672872932.353239",
        "client_msg_id": "536a2e79-ff77-4b5c-91f5-ad525d8dab20",
        "text": "ansible - bleah. You can just `pip freeze` your venv into a `requirements.txt` which then you get to install on the production machine. Alternatively you can just work with a docker container as Liam says on both dev\/prod and deploy the container.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "3e9081360251",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-09-23\/4121913702131_3e90813602519cae7745_72.png",
            "first_name": "dont",
            "real_name": "dont",
            "display_name": "dont",
            "team": "T4G9NBD2M",
            "name": "erikseulean",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1672782898.956829",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Yzs",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "ansible - bleah. You can just "
                            },
                            {
                                "type": "text",
                                "text": "pip freeze",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " your venv into a "
                            },
                            {
                                "type": "text",
                                "text": "requirements.txt",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " which then you get to install on the production machine. Alternatively you can just work with a docker container as Liam says on both dev\/prod and deploy the container."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "-1",
                "users": [
                    "UBS7QANF3"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U034LK55D3P",
        "type": "message",
        "ts": "1672873050.117089",
        "client_msg_id": "f7b4f567-bea7-4a66-b854-2571bdc7ab52",
        "text": "`pipenv` related workflows that might help:\n<https:\/\/github.com\/pypa\/pipenv\/blob\/main\/docs\/advanced.rst>",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "3e9081360251",
            "image_72": "https:\/\/avatars.slack-edge.com\/2022-09-23\/4121913702131_3e90813602519cae7745_72.png",
            "first_name": "dont",
            "real_name": "dont",
            "display_name": "dont",
            "team": "T4G9NBD2M",
            "name": "erikseulean",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1672782898.956829",
        "parent_user_id": "U016TGY3676",
        "attachments": [
            {
                "id": 1,
                "footer_icon": "https:\/\/slack.github.com\/static\/img\/favicon-neutral.png",
                "color": "24292f",
                "bot_id": "B021ZJYSBMW",
                "app_unfurl_url": "https:\/\/github.com\/pypa\/pipenv\/blob\/main\/docs\/advanced.rst",
                "is_app_unfurl": true,
                "app_id": "A01BP7R4KNY",
                "fallback": "<https:\/\/github.com\/pypa\/pipenv\/blob\/main\/docs\/advanced.rst | advanced.rst>",
                "text": "```\n.. _advanced:\n\nAdvanced Usage of Pipenv\n========================\n\n.. image:: <https:\/\/farm4.staticflickr.com\/3672\/33231486560_bff4124c9a_k_d.jpg>\n\nThis document covers some of Pipenv's more glorious and advanced features.\n\n☤ Caveats\n---------\n\n- Dependencies of wheels provided in a ``Pipfile`` will not be captured by ``$ pipenv lock``.\n- There are some known issues with using private indexes, related to hashing. We're actively working to solve this problem. You may have great luck with this, however.\n- Installation is intended to be as deterministic as possible.\n\n☤ Specifying Package Indexes\n----------------------------\n\nStarting in release ``2022.3.23`` all packages are mapped only to a single package index for security reasons.\nAll unspecified packages are resolved using the default index source; the default package index is PyPI.\n\nFor a specific package to be installed from an alternate package index, you must match the name of the index as in the following example::\n\n    [[source]]\n    url = \"<https:\/\/pypi.org\/simple>\"\n    verify_ssl = true\n    name = \"pypi\"\n\n    [[source]]\n    url = \"<https:\/\/download.pytorch.org\/whl\/cu113\/>\"\n    verify_ssl = false\n    name = \"pytorch\"\n\n    [dev-packages]\n\n    [packages]\n    torch = {version=\"*\", index=\"pytorch\"}\n    numpy = {version=\"*\"}\n\nYou may install a package such as the example ``torch`` from the named index ``pytorch`` using the CLI by running\nthe following command:\n\n``pipenv install --index=pytorch torch``\n\nAlternatively the index may be specified by full url, and it will be added to the ``Pipfile`` with a generated name\nunless it already exists in which case the existing name with be reused when pinning the package index.\n\n.. note::\n    In prior versions of ``pipenv`` you could specify ``--extra-index-urls`` to the ``pip`` resolver and avoid\n    specifically matching the expected index by name.   That functionality was deprecated in favor of index restricted\n    packages, which is a simplifying assumption that is more security mindful.  The pip documentation has the following\n    warning around the ``--extra-index-urls`` option:\n\n    *Using this option to search for packages which are not in the main repository (such as private packages) is unsafe,\n    per a security vulnerability called dependency confusion: an attacker can claim the package on the public repository\n    in a way that will ensure it gets chosen over the private package.*\n\nShould you wish to use an alternative default index other than PyPI: simply do not specify PyPI as one of the\nsources in your ``Pipfile``.  When PyPI is omitted, then any public packages required either directly or\nas sub-dependencies must be mirrored onto your private index or they will not resolve properly.  This matches the\nstandard recommendation of ``pip`` maintainers: \"To correctly make a private project installable is to point\n--index-url to an index that contains both PyPI and their private projects—which is our recommended best practice.\"\n\nThe above documentation holds true for both ``lock`` resolution and ``sync`` of packages. It was suggested that\nonce the resolution and the lock file are updated, it is theoretically possible to safely scan multiple indexes\nfor these packages when running ``pipenv sync`` or ``pipenv install --deploy`` since it will verify the package\nhashes match the allowed hashes that were already captured from a safe locking cycle.\nTo enable this non-default behavior, add ``install_search_all_sources = true`` option\nto your ``Pipfile`` in the  ``pipenv`` section::\n\n    [pipenv]\n    install_search_all_sources = true\n\n**Note:** The locking cycle will still requires that each package be resolved from a single index.  This feature was\nrequested as a workaround in order to support organizations where not everyone has access to the package sources.\n\n☤ Using a PyPI Mirror\n----------------------------\n\nShould you wish to override the default PyPI index URLs with the URL for a PyPI mirror, you can do the following::\n\n    $ pipenv install --pypi-mirror <mirror_url>\n\n    $ pipenv update --pypi-mirror <mirror_url>\n\n    $ pipenv sync --pypi-mirror <mirror_url>\n\n    $ pipenv lock --pypi-mirror <mirror_url>\n\n    $ pipenv uninstall --pypi-mirror <mirror_url>\n\nAlternatively, setting the ``PIPENV_PYPI_MIRROR`` environment variable is equivalent to passing ``--pypi-mirror <mirror_url>``.\n\n☤ Injecting credentials into Pipfile via environment variables\n-----------------------------------------------------------------\n\nPipenv will expand environment variables (if defined) in your Pipfile. Quite\nuseful if you need to authenticate to a private PyPI::\n\n    [[source]]\n    url = \"https:\/\/$USERNAME:${PASSWORD}@mypypi.example.com\/simple\"\n    verify_ssl = true\n    name = \"pypi\"\n\nLuckily - pipenv will hash your Pipfile *before* expanding environment\nvariables (and, helpfully, will substitute the environment variables again when\nyou install from the lock file - so no need to commit any secrets! Woo!)\n\nIf your credentials contain special characters, make sure they are URL-encoded as specified in `rfc3986 <https:\/\/datatracker.ietf.org\/doc\/html\/rfc3986>`_.\n\nEnvironment variables may be specified as ``${MY_ENVAR}`` or ``$MY_ENVAR``.\n\nOn Windows, ``%MY_ENVAR%`` is supported in addition to ``${MY_ENVAR}`` or ``$MY_ENVAR``.\n\nEnvironment variables in the URL part of requirement specifiers can also be expanded, where the variable must be in the form of ``${VAR_NAME}``. Neither ``$VAR_NAME`` nor ``%VAR_NAME%`` is acceptable::\n\n    [[package]]\n    requests = {git = \"git:\/\/${USERNAME}:${PASSWORD}@private.git.com\/psf\/requests.git\", ref = \"2.22.0\"}\n\nKeep in mind that environment variables are expanded in runtime, leaving the entries in ``Pipfile`` or ``Pipfile.lock`` untouched. This is to avoid the accidental leakage of credentials in the source code.\n\n☤ Injecting credentials through keychain support\n------------------------------------------------\n\nPrivate registries on Google Cloud, Azure and AWS support dynamic credentials using\nthe keychain implementation. Due to the way the keychain is structured, it might ask\nthe user for input. Asking the user for input is disabled. This will disable the keychain\nsupport completely, unfortunately.\n\nIf you want to work with private registries that use the keychain for authentication, you\ncan disable the \"enforcement of no input\".\n\n**Note:** Please be sure that the keychain will really not ask for\ninput. Otherwise the process will hang forever!::\n\n    [[source]]\n    url = \"<https:\/\/pypi.org\/simple>\"\n    verify_ssl = true\n    name = \"pypi\"\n\n    [[source]]\n    url = \"<https:\/\/europe-python.pkg.dev\/my-project\/python\/simple>\"\n    verify_ssl = true\n    name = \"private-gcp\"\n\n    [packages]\n    flask = \"*\"\n    private-test-package = {version = \"*\", index = \"private-gcp\"}\n\n    [pipenv]\n    disable_pip_input = false\n\nAbove example will install ``flask`` and a private package ``private-test-package`` from GCP.\n\n☤ Supplying additional arguments to pip\n------------------------------------------------\n\nThere may be cases where you wish to supply additional arguments to pip to be used during the install phase.\nFor example, you may want to enable the pip feature for using\n`system certificate stores <https:\/\/pip.pypa.io\/en\/latest\/topics\/https-certificates\/#using-system-certificate-stores>`_\n\nIn this case you can supply these additional arguments to ``pipenv sync`` or ``pipenv install`` by passing additional\nargument ``--extra-pip-args=\"--use-feature=truststore\"``.   It is possible to supply multiple arguments in the ``--extra-pip-args``.\nExample usage::\n\n    pipenv sync --extra-pip-args=\"--use-feature=truststore --proxy=127.0.0.1\"\n\n\n☤ Specifying Basically Anything\n-------------------------------\n\nIf you'd like to specify that a specific package only be installed on certain systems,\nyou can use `PEP 508 specifiers <https:\/\/www.python.org\/dev\/peps\/pep-0508\/>`_ to accomplish this.\n\nHere's an example ``Pipfile``, which will only install ``pywinusb`` on Windo…",
                "title": "<https:\/\/github.com\/pypa\/pipenv\/blob\/main\/docs\/advanced.rst | advanced.rst>",
                "footer": "<https:\/\/github.com\/pypa\/pipenv|pypa\/pipenv>",
                "mrkdwn_in": [
                    "text"
                ]
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vPrca",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "pipenv",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " related workflows that might help:\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/pypa\/pipenv\/blob\/main\/docs\/advanced.rst"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "USWDY5P7G",
        "type": "message",
        "ts": "1672874197.066339",
        "client_msg_id": "fc8e4be0-6865-4e1f-9e95-378ce129ab46",
        "text": "My suggested approach is also Docker. Here's a simple blueprint to get you started...\n\nAssuming you have two Python programs (`run-oldstrategies.py`, `run-newstrategies.py`), we are on your dev machine (Linux Debian) in the directory that contains those two programs.\n\n*Step 1 - Create separate environment requirement files*\nActivate the environment containing libraries for the old strategies then do `pip freeze &gt; requirements-oldstrategies.txt`. Do the same for the new strategies environment to generate `requirements-newstrategies.txt`.\n\n*Step 2 - Create separate Dockerfile(s)*\nCreate two empty text files: `Dockerfile-oldstrategies`, `Dockerfile-newstrategies`. As an example, here's what you could put inside Dockerfile-oldstrategies (you can easily figure out the other):\n```FROM python:3.9-slim-bullseye\nRUN apt update -y\nWORKDIR \/opt\/myproject\nCOPY .\/requirements-oldstrategies.txt .\nRUN cat requirements-oldstrategies.txt | grep -v '==0.0.0' &gt; requirements-oldstrategies.sanitised.txt\nRUN pip install --no-cache-dir --upgrade -r requirements-oldstrategies.sanitised.txt\nCOPY . .\nENTRYPOINT [\"python\", \"run-oldstrategies.py\"]```\n*Step 3 - Install Docker*\n<https:\/\/docs.docker.com\/engine\/install\/debian\/>\n\n*Step 4 - Build separate Docker images for the two programs*\n```docker build -t run-oldstrategies -f .\/Dockerfile-oldstrategies .\ndocker build -t run-newstrategies -f .\/Dockerfile-newstrategies .```\n*Step 5 - Install Docker on your production machin*e\nSame as Step 3\n\n*Step 6 - Transfer Docker images from your current machine to the production machine*\n```docker save run-oldstrategies | bzip2 | ssh &lt;USER&gt;@&lt;PRODUCTION_IP&gt; docker load\ndocker save run-newstrategies | bzip2 | ssh &lt;USER&gt;@&lt;PRODUCTION_IP&gt; docker load```\n*Step 7 - Log into production machine, make sure images are there*\n```docker images```\n*Step 8 - Start both Docker containers*\n```docker run -d run-oldstrategies\ndocker run -d run-newstrategies```\n*Step 9 - How to check logs for a Docker container*\nRun `docker ps -a` to get the hash of each container then you run the following command:\n```docker logs &lt;CONTAINER_HASH&gt;```\n",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "693b14d0cc42",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-08-29\/2425858826214_693b14d0cc42bdbfb86a_72.jpg",
            "first_name": "Fab",
            "real_name": "Fab",
            "display_name": "Fab",
            "team": "T4G9NBD2M",
            "name": "me1",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1672782898.956829",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "aVHnl",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My suggested approach is also Docker. Here's a simple blueprint to get you started...\n\nAssuming you have two Python programs ("
                            },
                            {
                                "type": "text",
                                "text": "run-oldstrategies.py",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", "
                            },
                            {
                                "type": "text",
                                "text": "run-newstrategies.py",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "), we are on your dev machine (Linux Debian) in the directory that contains those two programs.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 1 - Create separate environment requirement files",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\nActivate the environment containing libraries for the old strategies then do "
                            },
                            {
                                "type": "text",
                                "text": "pip freeze > requirements-oldstrategies.txt",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". Do the same for the new strategies environment to generate "
                            },
                            {
                                "type": "text",
                                "text": "requirements-newstrategies.txt",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ".\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 2 - Create separate Dockerfile(s)",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\nCreate two empty text files: "
                            },
                            {
                                "type": "text",
                                "text": "Dockerfile-oldstrategies",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", "
                            },
                            {
                                "type": "text",
                                "text": "Dockerfile-newstrategies",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". As an example, here's what you could put inside Dockerfile-oldstrategies (you can easily figure out the other):\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "FROM python:3.9-slim-bullseye\nRUN apt update -y\nWORKDIR \/opt\/myproject\nCOPY .\/requirements-oldstrategies.txt .\nRUN cat requirements-oldstrategies.txt | grep -v '==0.0.0' > requirements-oldstrategies.sanitised.txt\nRUN pip install --no-cache-dir --upgrade -r requirements-oldstrategies.sanitised.txt\nCOPY . .\nENTRYPOINT [\"python\", \"run-oldstrategies.py\"]"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 3 - Install Docker",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/docs.docker.com\/engine\/install\/debian\/"
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 4 - Build separate Docker images for the two programs",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "docker build -t run-oldstrategies -f .\/Dockerfile-oldstrategies .\ndocker build -t run-newstrategies -f .\/Dockerfile-newstrategies ."
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 5 - Install Docker on your production machin",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "e\nSame as Step 3\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 6 - Transfer Docker images from your current machine to the production machine",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "docker save run-oldstrategies | bzip2 | ssh <USER>@<PRODUCTION_IP> docker load\ndocker save run-newstrategies | bzip2 | ssh <USER>@<PRODUCTION_IP> docker load"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 7 - Log into production machine, make sure images are there",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "docker images"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 8 - Start both Docker containers",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "docker run -d run-oldstrategies\ndocker run -d run-newstrategies"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "Step 9 - How to check logs for a Docker container",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\nRun "
                            },
                            {
                                "type": "text",
                                "text": "docker ps -a",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " to get the hash of each container then you run the following command:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "docker logs <CONTAINER_HASH>"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": []
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "rocket",
                "users": [
                    "U016TGY3676"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U04H54Q392N",
        "type": "message",
        "ts": "1672874600.538309",
        "edited": {
            "user": "U04H54Q392N",
            "ts": "1672875575.000000"
        },
        "client_msg_id": "588dc57d-40e8-4a5a-b109-18f938a5b6b5",
        "text": "Docker\/containers have merits, and can be another layer to go with virtualenvs if you want, or you can cut out the virtualenv entirely because you are installing packages straight inside the container instead of a containerised virtualenv. I don't know your deployment experience\/environment, but you may find docker is OTT.\n\nI'd say docker\/containers (as there are other alternative container runtimes) is an additional isolation\/encapsulation layer which can be pretty cool but does have management overhead. You could go in other directions for similar effect, like using packer to produce virtual machine images to then deploy to machines (e.g. EC2\/GCP\/... instances), and in that or outside of that you could use things like ansible\/chef\/puppet (ansible probably is best for this kind of smaller scenario thing so can see why Mo mentioned it), and also a layer like terrafrorm (for extra info: terragrunt is also a good layer for it but I doubt so for the scale required in this case) above that to manage the provisioning of your infrastructure (e.g. from the point of spinning up cloud resources if you've gone that way).\n\nI'd still put emphasis on the likes of Pipenv as your first stop as it isn't conceptually (or in operations) much more than the virtualenvs you are using, but has things that are significant for long term management and reproducibility (i.e. exact package version pinning using the lockfile, a bit like using `pip freeze &gt; requirements.txt` but without being a such a mess to untangle when you want to upgrade something). Another good thing is pipenv\/virtualenvs will continue to work nicely with editors and you can fire them up easily and without extra permissions on machines (although the permissions is likely not an issue for you).\n\nJust for more info: a thing from before the likes of Pipenv was <https:\/\/pypi.org\/project\/pip-tools\/|pip-tools> which isn't far removed from the niceness of Pipenv. That will do the dependency locking side of things, but you'd still want to make the environments you install into (fresh VMs, constainers, virtualenvs, or bare metal).\n\nIf I blogged or was in consultancy, I'd be inclined to draw out graphs (or a graph) showing the potential dependencies of provisioning with spiel about the different parts...",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "922f15b4653c",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-11-24\/8061990184023_922f15b4653c337eadd3_72.jpg",
            "first_name": "Oliver",
            "real_name": "Oliver",
            "display_name": "Oliver",
            "team": "T4G9NBD2M",
            "name": "evilumbrella",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1672782898.956829",
        "parent_user_id": "U016TGY3676",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RhRgc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Docker\/containers have merits, and can be another layer to go with virtualenvs if you want, or you can cut out the virtualenv entirely because you are installing packages straight inside the container instead of a containerised virtualenv. I don't know your deployment experience\/environment, but you may find docker is OTT.\n\nI'd say docker\/containers (as there are other alternative container runtimes) is an additional isolation\/encapsulation layer which can be pretty cool but does have management overhead. You could go in other directions for similar effect, like using packer to produce virtual machine images to then deploy to machines (e.g. EC2\/GCP\/... instances), and in that or outside of that you could use things like ansible\/chef\/puppet (ansible probably is best for this kind of smaller scenario thing so can see why Mo mentioned it), and also a layer like terrafrorm (for extra info: terragrunt is also a good layer for it but I doubt so for the scale required in this case) above that to manage the provisioning of your infrastructure (e.g. from the point of spinning up cloud resources if you've gone that way).\n\nI'd still put emphasis on the likes of Pipenv as your first stop as it isn't conceptually (or in operations) much more than the virtualenvs you are using, but has things that are significant for long term management and reproducibility (i.e. exact package version pinning using the lockfile, a bit like using "
                            },
                            {
                                "type": "text",
                                "text": "pip freeze > requirements.txt",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " but without being a such a mess to untangle when you want to upgrade something). Another good thing is pipenv\/virtualenvs will continue to work nicely with editors and you can fire them up easily and without extra permissions on machines (although the permissions is likely not an issue for you).\n\nJust for more info: a thing from before the likes of Pipenv was "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/pypi.org\/project\/pip-tools\/",
                                "text": "pip-tools"
                            },
                            {
                                "type": "text",
                                "text": " which isn't far removed from the niceness of Pipenv. That will do the dependency locking side of things, but you'd still want to make the environments you install into (fresh VMs, constainers, virtualenvs, or bare metal).\n\nIf I blogged or was in consultancy, I'd be inclined to draw out graphs (or a graph) showing the potential dependencies of provisioning with spiel about the different parts..."
                            }
                        ]
                    }
                ]
            }
        ],
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U016TGY3676"
                ],
                "count": 1
            }
        ]
    },
    {
        "user": "U01B8031PM1",
        "type": "message",
        "ts": "1672897928.469109",
        "client_msg_id": "d9c4e76c-1735-4dad-b6b1-ccdc28560994",
        "text": "Quick sanity check please. Looking at the transaction context managers\n\n```with market.transaction() as t:\n    t.cancel_order(order_0)\n    t.place_order(order_1)\n    t.place_order(order_2)```\nif order order_0 fails, does it mean that the order_1 and order_2 will also fail? if I want them fail, how do I do so?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6e482a0e41b",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6e482a0e41b232f48d801454006dfa56.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0016-72.png",
            "first_name": "river_shah",
            "real_name": "river_shah",
            "display_name": "river_shah",
            "team": "T4G9NBD2M",
            "name": "ansar.sa",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1672897928.469109",
        "reply_count": 4,
        "reply_users_count": 2,
        "latest_reply": "1672906900.805099",
        "reply_users": [
            "U4H19D1D2",
            "U01B8031PM1"
        ],
        "replies": [
            {
                "user": "U4H19D1D2",
                "ts": "1672903774.777199"
            },
            {
                "user": "U01B8031PM1",
                "ts": "1672906142.821529"
            },
            {
                "user": "U01B8031PM1",
                "ts": "1672906238.286339"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1672906900.805099"
            }
        ],
        "is_locked": false,
        "subscribed": true,
        "last_read": "1672906900.805099",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "S0KoJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Quick sanity check please. Looking at the transaction context managers\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_preformatted",
                        "elements": [
                            {
                                "type": "text",
                                "text": "with market.transaction() as t:\n    t.cancel_order(order_0)\n    t.place_order(order_1)\n    t.place_order(order_2)"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nif order order_0 fails, does it mean that the order_1 and order_2 will also fail? if I want them fail, how do I do so?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1672903774.777199",
        "client_msg_id": "945E1542-FEA1-4F8D-A3B2-7EFA5782AE05",
        "text": "Sadly not, cancels and places are separate requests so they will be split and executed on context manager exit.\n\nYou would have to wait for the cancel ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1672897928.469109",
        "parent_user_id": "U01B8031PM1",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Ad6cf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Sa"
                            },
                            {
                                "type": "text",
                                "text": "dly not, cancels and places are "
                            },
                            {
                                "type": "text",
                                "text": "separate"
                            },
                            {
                                "type": "text",
                                "text": " requests so they will be split and executed on context manager exit.\n\nYou would have to wait for the cancel "
                            }
                        ]
                    }
                ]
            }
        ]
    }
]