[
    {
        "subtype": "thread_broadcast",
        "user": "U01LD3EU8B0",
        "thread_ts": "1694418913.431989",
        "root": {
            "user": "U05N9773A23",
            "type": "message",
            "ts": "1694418913.431989",
            "client_msg_id": "a322092b-a485-4133-9c7a-a04e04d9c7dc",
            "text": "Is anyone here working with raw TPD data? I did some work for a client a few years back before they offered TPD Zone and it was raw data only. I'm not interested in using Gruss or BA etc. It seems their API is only available on commercial terms now",
            "team": "T4G9NBD2M",
            "thread_ts": "1694418913.431989",
            "reply_count": 25,
            "reply_users_count": 7,
            "latest_reply": "1695624289.009629",
            "reply_users": [
                "U4H19D1D2",
                "U05N9773A23",
                "UBS7QANF3",
                "UUE6E1LA1",
                "U01DJ4DBF9R",
                "UEA14GBRR",
                "U01LD3EU8B0"
            ],
            "replies": [
                {
                    "user": "U4H19D1D2",
                    "ts": "1694419244.725429"
                },
                {
                    "user": "U05N9773A23",
                    "ts": "1694419475.700889"
                },
                {
                    "user": "U4H19D1D2",
                    "ts": "1694419512.991219"
                },
                {
                    "user": "UBS7QANF3",
                    "ts": "1694419625.014849"
                },
                {
                    "user": "U4H19D1D2",
                    "ts": "1694419659.151099"
                },
                {
                    "user": "U05N9773A23",
                    "ts": "1694419893.337979"
                },
                {
                    "user": "UUE6E1LA1",
                    "ts": "1694419896.198169"
                },
                {
                    "user": "UBS7QANF3",
                    "ts": "1694419993.050439"
                },
                {
                    "user": "U01DJ4DBF9R",
                    "ts": "1694419999.683279"
                },
                {
                    "user": "U05N9773A23",
                    "ts": "1694420168.183129"
                },
                {
                    "user": "UUE6E1LA1",
                    "ts": "1694420316.019589"
                },
                {
                    "user": "UUE6E1LA1",
                    "ts": "1694420338.685309"
                },
                {
                    "user": "U05N9773A23",
                    "ts": "1694420427.384769"
                },
                {
                    "user": "UEA14GBRR",
                    "ts": "1694514548.705569"
                },
                {
                    "user": "UUE6E1LA1",
                    "ts": "1694514920.019199"
                },
                {
                    "user": "U01LD3EU8B0",
                    "ts": "1695551619.963279"
                },
                {
                    "user": "UBS7QANF3",
                    "ts": "1695551696.948199"
                },
                {
                    "user": "U01LD3EU8B0",
                    "ts": "1695551815.492839"
                },
                {
                    "user": "UBS7QANF3",
                    "ts": "1695552057.694359"
                },
                {
                    "user": "U01LD3EU8B0",
                    "ts": "1695552486.344069"
                },
                {
                    "user": "U05N9773A23",
                    "ts": "1695553347.320099"
                },
                {
                    "user": "UBS7QANF3",
                    "ts": "1695554443.510279"
                },
                {
                    "user": "U05N9773A23",
                    "ts": "1695556136.613139"
                },
                {
                    "user": "U05N9773A23",
                    "ts": "1695556361.348159"
                },
                {
                    "user": "UUE6E1LA1",
                    "ts": "1695624289.009629"
                }
            ],
            "is_locked": false,
            "subscribed": true,
            "last_read": "1695624289.009629",
            "blocks": [
                {
                    "type": "rich_text",
                    "block_id": "WjIMr",
                    "elements": [
                        {
                            "type": "rich_text_section",
                            "elements": [
                                {
                                    "type": "text",
                                    "text": "Is anyone here working with raw TPD data? I did some work for a client a few years back before they offered TPD Zone and it was raw data only. I'm not interested in using Gruss or BA etc. It seems their API is only available on commercial terms now"
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        "type": "message",
        "ts": "1695551619.963279",
        "client_msg_id": "0bb1b7a5-c15b-494d-9e90-b52b58be5fd5",
        "text": "I came across this library which may be of interest:\n<https:\/\/github.com\/TotalPerformanceData\/gmaxfeed\/>\n\nI haven't used it, but it appears to be what you are looking for i.e access to the raw data with a TPD licence. Has anyone else used this?",
        "attachments": [
            {
                "id": 1,
                "color": "24292f",
                "bot_id": "B021ZJYSBMW",
                "app_unfurl_url": "https:\/\/github.com\/TotalPerformanceData\/gmaxfeed\/",
                "is_app_unfurl": true,
                "app_id": "A01BP7R4KNY",
                "fallback": "TotalPerformanceData\/gmaxfeed",
                "text": "python3 module for downloading and maintaining files from gmax server on local machine.",
                "title": "TotalPerformanceData\/gmaxfeed",
                "fields": [
                    {
                        "value": "<http:\/\/www.totalperformancedata.com>",
                        "title": "Website",
                        "short": true
                    },
                    {
                        "value": "7",
                        "title": "Stars",
                        "short": true
                    }
                ]
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "NMf\/y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I came across this library which may be of interest:\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/TotalPerformanceData\/gmaxfeed\/"
                            },
                            {
                                "type": "text",
                                "text": "\n\nI haven't used it, but it appears to be what you are looking for i.e access to the raw data with a TPD licence. Has anyone else used this?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1695551696.948199",
        "client_msg_id": "86D5687D-CC97-4F3E-873C-9603FFFCDC1E",
        "text": "This provides access to a REST API for historic data, not for receiving the data in real time",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mDY1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This provides access to a REST API for historic data, not for receiving the data in real time"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01LD3EU8B0",
        "type": "message",
        "ts": "1695551815.492839",
        "client_msg_id": "490e8819-d651-4739-9e68-76bd405ffee3",
        "text": "I've not delved into the code too much but I saw this:\n<https:\/\/github.com\/TotalPerformanceData\/gmaxfeed\/blob\/87e58cf32fcb2e2c3ea147dcdeaa15fbd4f96091\/gmaxfeed\/feeds\/record_live.py>",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "91f0ca4990b2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-02-01\/1685122555351_91f0ca4990b2be2e385b_72.png",
            "first_name": "TT",
            "real_name": "TT",
            "display_name": "TT",
            "team": "T4G9NBD2M",
            "name": "timtaylor.uk1",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "attachments": [
            {
                "id": 1,
                "footer_icon": "https:\/\/slack.github.com\/static\/img\/favicon-neutral.png",
                "color": "24292f",
                "bot_id": "B021ZJYSBMW",
                "app_unfurl_url": "https:\/\/github.com\/TotalPerformanceData\/gmaxfeed\/blob\/87e58cf32fcb2e2c3ea147dcdeaa15fbd4f96091\/gmaxfeed\/feeds\/record_live.py",
                "is_app_unfurl": true,
                "app_id": "A01BP7R4KNY",
                "fallback": "<https:\/\/github.com\/TotalPerformanceData\/gmaxfeed\/blob\/87e58cf32fcb2e2c3ea147dcdeaa15fbd4f96091\/gmaxfeed\/feeds\/record_live.py | record_live.py>",
                "text": "```\n#!\/usr\/bin\/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Jul 18 09:29:47 2019\n\nBasic example of how to listen for packets and avoid missing packets during periods of high congestion.\n\nSuggestion for use:\n    We often cover 4 meetings simultaneously, at this much traffic a python program using threads \n    to save the packet to the appropriate place will likely start to miss packets whilst the process is \n    busy working on the thread fileio stuff and a packet arriving at the socket isn't read in time before the next.\n    \n    To avoid this, 1 process can be dedicated to listening for packets all the time enqueueing the packets\n    for another process to handle the logic to decide where the packet should be saved.\n    \n    Use 2 processes, 1 to listen to updates and 1 to save files.\n    in P1, use 2 threads, 1 for UserTerminate class and 1 for socket.listen() to add packet to queue.\n    in P2, dequeue and save packets\n    \n    To avoid the port blocking upon exiting the program the UserTerminate class can be used to break the listener loop,\n    and can be improved with the GracefulExit SIGTERM interceptor from utils.\n\nIssues in Practice:\n    I've used the above description as the foundation for my recorders for the last year or so and it's never missed a \n    packet, however there have been oddities that are hard to fathom. The flags REUSEPORT and REUSEADDR don't seem to \n    perform the expected behaviour when passing with the python socket api, eg you should be able to multicast from a port\n    for two separate processes when both pass the REUSEPORT flag but this isn't the case (2021-02-03, ubuntu and osx tests), \n    the most recent process to bind to the port just hijacks the port. Strangely, if the second process then releases the \n    port the first process begins to receive packets again.\n    This isn't ideal but not the end of the world, the bigger problem is when the programs aren't gracefully shutdown the\n    port remains blocked for a couple of minutes after and if you restart the program without allowing it to unblock\n    the port will not become unblocked at all after any amount of time resulting in loss of all data packets and probably no\n    warning. \n    This behaviour is the same regardless of whether I pass the REUSEPORT flag or not. Even stranger still, this behaviour\n    persists through a computer reboot (Digital Ocean shared instance - Ubuntu)\n    Finally, this behaviour also presents challenges in using the data for multiple applications. The Redis method in \"rust-listener\"\n    can solve this by simply using as many redis queues as there are applications (or as many queues as there are data preparation processes).\n    redis is a low latency in memory database which can be used easily as a message queue and lends itself very well to these applications.\n    \n    I'm not confident then in using the python socket api for a life-or-death deployment, even if using duplicate\n    redundancy feeds directed to different ports from multiple Gmax sources.\n    \n    As such I've written a small but functional listener in Rust to handle it instead. This is included in the repo under directory \"rust-listener\"\n    and includes options to handle the packets into a file structure itself or add the packets to a redis queue for other processes to get.\n\n@author: George Swindells\n@email: <mailto:george.swindells@totalperformancedata.com|george.swindells@totalperformancedata.com>\n\n\"\"\"\nimport socket, threading, json, os\nimport multiprocessing as mp\nfrom datetime import datetime, timedelta\n\n_dir = os.path.abspath(os.path.dirname(__file__))\nDIREC = os.path.join(_dir, \"TPDLiveRecording\")\nif not os.path.exists(DIREC):\n    os.mkdir(DIREC)\n\n_par_dir, _ = os.path.split(_dir)\n\nfrom .. import get_logger\nlogger = get_logger(name = __name__)\n\n\n# to terminate user can input 't' for a more graceful exit\nclass UserTerminate:\n    \n    def userTerminate(self):\n        while True:\n            inp = input()\n            if inp == \"t\":\n                self.term = True\n                with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as serverSocket:\n                    serverSocket.bind(('127.0.0.1',60000))\n                    data = b'terminate activated'\n                    serverSocket.sendto(data, ('127.0.0.1', 4629))\n                break\n        \n    def __init__(self):\n        self.term = False\n\n\ndef file_management(q:mp.Queue) -> None: # function for secondary file management process, input of queue\n    \n    def file_save(data:str, tstamp:str, sc:str) -> None:\n        with open(os.path.join(DIREC, sc), 'a', newline = '\\r\\n') as wfile:\n            wfile.write(tstamp + ';' + data)\n    \n    def deal_with_datagram(data:str, address:str, ts) -> None:\n        try:\n            data2 = json.loads(data)\n        except Exception:\n            logger.exception(\"Encountered json.loads() error: {0} - {1} - {2} \".format(data, address, ts))\n            return\n        file_save(data = data, tstamp = str(ts), sc = data2['I'])\n            \n    while True:\n        d = q.get() # get data from front of queue, wait indefinitely\n        if d[0] == b'terminate activated':\n            break # if userTerminate activated on concurrent process, put 'terminate' in queue to instruct this process to exit also\n        try:\n            tReceived = datetime.utcnow()\n            print(repr(d[0]))\n            data = d[0].decode('ascii')\n        except Exception: # any exception will only be from decode if some unexpected data is received to port\n            logger.exception(' {0} - {1}'.format(str(d), str(tReceived)))\n            continue\n        \n        deal_with_datagram(data, d[1], tReceived)\n        \n\nif __name__ == '__main__':\n    q = mp.Queue()\n    p = mp.Process(target = file_management, args = (q,))\n    p.start()\n    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n        ut = UserTerminate()\n        x = threading.Thread(target = ut.userTerminate)\n        x.start()\n        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        s.bind(('',4629)) #(HOST='', PORT=4629)\n        while True: # could use GracefullExit class from utils here to try to avoid port blocking on shutdown\n            # wait for data received...\n            data, addr = s.recvfrom(4096)\n            q.put((data, addr))\n            if ut.term:\n                print(\"user terminated...\")\n                break\n    \n\n```",
                "title": "<https:\/\/github.com\/TotalPerformanceData\/gmaxfeed\/blob\/87e58cf32fcb2e2c3ea147dcdeaa15fbd4f96091\/gmaxfeed\/feeds\/record_live.py | record_live.py>",
                "footer": "<https:\/\/github.com\/TotalPerformanceData\/gmaxfeed|TotalPerformanceData\/gmaxfeed>",
                "mrkdwn_in": [
                    "text"
                ]
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Vyyb",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I've not delved into the code too much but I saw this:\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/TotalPerformanceData\/gmaxfeed\/blob\/87e58cf32fcb2e2c3ea147dcdeaa15fbd4f96091\/gmaxfeed\/feeds\/record_live.py"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1695552057.694359",
        "client_msg_id": "B67B3CF4-F83A-4115-9BF3-4D559CCC0543",
        "text": "Yes you’re right there is some example code for receiving the data in live but the primary purpose of the repo in my experience is the REST API\n\nOf course it goes without saying that these are just code samples and you’ll need to separately arrange credentials\/feed access\n\nWorth noting that the historic data is largely useless as it does not reflect the data one would have received under live conditions ",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dTCR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yes "
                            },
                            {
                                "type": "text",
                                "text": "you’re"
                            },
                            {
                                "type": "text",
                                "text": " right there is some example code for receiving the data in live but the primary purpose of the repo in my experience is the REST API\n\nOf course it goes without saying that these are just code samples and "
                            },
                            {
                                "type": "text",
                                "text": "you’ll"
                            },
                            {
                                "type": "text",
                                "text": " need to separately arrange credentials\/feed access\n\nWorth noting that the historic data is largely useless as it does not reflect the data one would have received under live conditions "
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01LD3EU8B0",
        "type": "message",
        "ts": "1695552486.344069",
        "edited": {
            "user": "U01LD3EU8B0",
            "ts": "1695552522.000000"
        },
        "client_msg_id": "885fc4d7-3ec3-4a33-817a-9070d016ea9f",
        "text": "Yeah, I seem to recall discussions about historic data not matching what you receive live. So without access to TPD through betfair, recording the stream yourself and integrating into flumine with middleware seems the only option.\n\nDo you know what the requirements are for getting a TPD feed through betfair are? Is it for PC customers only?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "91f0ca4990b2",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-02-01\/1685122555351_91f0ca4990b2be2e385b_72.png",
            "first_name": "TT",
            "real_name": "TT",
            "display_name": "TT",
            "team": "T4G9NBD2M",
            "name": "timtaylor.uk1",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xuLlg",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, I seem to recall discussions about historic data not matching what you receive live. So without access to TPD through betfair, recording the stream yourself and integrating into flumine with middleware seems the only option.\n\nDo you know what the requirements are for getting a TPD feed through betfair are? Is it for PC customers only?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1695553347.320099",
        "client_msg_id": "d79fe8f4-7f1c-448a-82a0-336e063792da",
        "text": "<@UBS7QANF3> Really? I did not know that. I wanted to mess around and train a reinforcement learning model using Betfair price data and TPD tracking data, but guess that's useless if that's true. Do you know why that is the case? That's very poor. But tbh, my whole experience with the TPD (albeit several years ago) was very poor in general",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Nw\/i\/",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UBS7QANF3"
                            },
                            {
                                "type": "text",
                                "text": " Really? I did not know that. I wanted to mess around and train a reinforcement learning model using Betfair price data and TPD tracking data, but guess that's useless if that's true. Do you know why that is the case? That's very poor. But tbh, my whole experience with the TPD (albeit several years ago) was very poor in general"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1695554443.510279",
        "client_msg_id": "A565AC83-CECB-47AA-AD5D-41D10D159423",
        "text": "I probably should let everyone else spend a lot of time and hard work learning these lessons themselves but the intention of the historic data is to be as accurate (in terms of horses’ positions) as possible not reflect what you would have received live. So they apply some opaque transformations after the fact to try to improve that positional accuracy",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "fRZu",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I probably should let everyone else spend a lot of time and hard work learning these lessons themselves but the intention of the historic data is to be as accurate (in terms of horses’ positions) as possible not reflect what you would have received live"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " So they apply some opaque transformations after the fact to try to improve that positional accuracy"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1695556136.613139",
        "client_msg_id": "f233c150-35d8-44f9-9a89-eff78e2de7c4",
        "text": "<@UBS7QANF3> Very annoying. I personally found the data to be extremely inaccurate. I developed a piece of software for a client that used the data, back when it was only available as raw data.  The data was all over the place and TPD were evasive and condescending when I questioned the accuracy of the data. We decided to cut our losses on the project",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+W3Nj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UBS7QANF3"
                            },
                            {
                                "type": "text",
                                "text": " Very annoying. I personally found the data to be extremely inaccurate. I developed a piece of software for a client that used the data, back when it was only available as raw data.  The data was all over the place and TPD were evasive and condescending when I questioned the accuracy of the data. We decided to cut our losses on the project"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05N9773A23",
        "type": "message",
        "ts": "1695556361.348159",
        "client_msg_id": "ebe4e483-e89c-4923-a645-75ed98391199",
        "text": "<@UBS7QANF3> I sympathise with that. I created a machine learning model that had the racing post and timeform ratings as a feature. Back testing showed huge profits. Thankfully, I thought better of it. After looking into it, turns out these ratings are revised retrospectively, causing data to leak into the model",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g9a60fb53f27",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/9a60fb53f27a5eefe4207d5f5b9ce4bc.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0021-72.png",
            "first_name": "Justice",
            "real_name": "Justice",
            "display_name": "Justice",
            "team": "T4G9NBD2M",
            "name": "bkwdev",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "QrQW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UBS7QANF3"
                            },
                            {
                                "type": "text",
                                "text": " I sympathise with that. I created a machine learning model that had the racing post and timeform ratings as a feature. Back testing showed huge profits. Thankfully, I thought better of it. After looking into it, turns out these ratings are revised retrospectively, causing data to leak into the model"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UUE6E1LA1",
        "type": "message",
        "ts": "1695624289.009629",
        "client_msg_id": "d0c1764a-78c2-4418-a8ff-72a07861ce03",
        "text": "When I started I wrote a GUI app with a price grid trading tool with the view to using it as a visual aid to manually trading. In retrospect this was rather stupid for a variety of reasons, but I am actually quite glad I started off like this because watching the rendered GPS in real time made it very clear what kind of \"surprises\" the data can throw at you. Especially when watching a race replay after and comparing with the GPS visuals. I don't want to criticize though  - there is still plenty of information there despite the errors.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gf53cae45edd",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/f53cae45edd7f7b67bbe98819597612e.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
            "first_name": "",
            "real_name": "D C",
            "display_name": "D C",
            "team": "T4G9NBD2M",
            "name": "oddsvantage",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1694418913.431989",
        "parent_user_id": "U05N9773A23",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hEZS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "When I started I wrote a GUI app with a price grid trading tool with the view to using it as a visual aid to manually trading. In retrospect this was rather stupid for a variety of reasons, but I am actually quite glad I started off like this because watching the rendered GPS in real time made it very clear what kind of \"surprises\" the data can throw at you. Especially when watching a race replay after and comparing with the GPS visuals. I don't want to criticize though  - there is still plenty of information there despite the errors."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]