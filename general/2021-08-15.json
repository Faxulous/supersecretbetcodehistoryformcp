[
    {
        "subtype": "channel_join",
        "user": "U02B1P6JWB0",
        "text": "<@U02B1P6JWB0> has joined the channel",
        "type": "message",
        "ts": "1629053293.244100"
    },
    {
        "subtype": "channel_join",
        "user": "U02ATQJBM8F",
        "text": "<@U02ATQJBM8F> has joined the channel",
        "type": "message",
        "ts": "1629055998.244300"
    },
    {
        "user": "U01PNBCPSKT",
        "type": "message",
        "ts": "1629064867.248100",
        "client_msg_id": "998980F7-CA04-41A8-BC91-04F2DA6C0D4B",
        "text": "I’d like to start building a history of market data with Flumine. Can anyone point me some code to get me started?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "dd487a1a3898",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-02-25\/1797934283412_dd487a1a3898ed0b4ec6_72.png",
            "first_name": "Steve",
            "real_name": "Steve Roach",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "steve_roach",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "y7WsG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I’d like to start building a history of market data with Flumine. Can anyone point me some code to get me started?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U016TGY3676",
        "type": "message",
        "ts": "1629066953.248900",
        "client_msg_id": "34c8d04b-058c-4c1f-bf28-c7b4a4775f48",
        "text": "<https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py|https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py>",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g6a681220e11",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/6a681220e11c1a2ed3685375d658dadb.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png",
            "first_name": "",
            "real_name": "birchy",
            "display_name": "birchy",
            "team": "T4G9NBD2M",
            "name": "birchy",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1629066953.248900",
        "reply_count": 6,
        "reply_users_count": 2,
        "latest_reply": "1629153837.273100",
        "reply_users": [
            "U01PNBCPSKT",
            "U9JHLMZB4"
        ],
        "replies": [
            {
                "user": "U01PNBCPSKT",
                "ts": "1629068883.252500"
            },
            {
                "user": "U9JHLMZB4",
                "ts": "1629098311.253000"
            },
            {
                "user": "U9JHLMZB4",
                "ts": "1629098504.253300"
            },
            {
                "user": "U01PNBCPSKT",
                "ts": "1629115676.259500"
            },
            {
                "user": "U9JHLMZB4",
                "ts": "1629116261.259700"
            },
            {
                "user": "U01PNBCPSKT",
                "ts": "1629153837.273100"
            }
        ],
        "is_locked": false,
        "subscribed": false,
        "attachments": [
            {
                "text": "```\nimport os\nimport json\nimport time\nimport logging\nimport gzip\nimport boto3\nimport queue\nimport threading\nfrom boto3.s3.transfer import S3Transfer, TransferConfig\nfrom botocore.exceptions import BotoCoreError\n\nfrom flumine import BaseStrategy\nfrom flumine.utils import create_short_uuid, file_line_count\n\nlogger = logging.getLogger(__name__)\n\n\nclass MarketRecorder(BaseStrategy):\n\n    \"\"\"\n    Simple raw streaming market recorder, context:\n\n        market_expiration: int, Seconds to wait after market closure before removing files\n        remove_file: bool, Remove txt file during cleanup\n        remove_gz_file: bool, Remove gz file during cleanup\n        force_update: bool, Update zip\/closure if update received after closure\n        load_market_catalogue: bool, Store marketCatalogue as {marketId}.json\n        local_dir: str, Dir to store data\n        recorder_id: str, Directory name (defaults to random uuid)\n    \"\"\"\n\n    MARKET_ID_LOOKUP = \"id\"\n\n    def __init__(self, *args, **kwargs):\n        BaseStrategy.__init__(self, *args, **kwargs)\n        self._market_expiration = self.context.get(\"market_expiration\", 3600)  # seconds\n        self._remove_file = self.context.get(\"remove_file\", False)\n        self._remove_gz_file = self.context.get(\"remove_gz_file\", False)\n        self._force_update = self.context.get(\"force_update\", True)\n        self._load_market_catalogue = self.context.get(\"load_market_catalogue\", True)\n        self.local_dir = self.context.get(\"local_dir\", \"\/tmp\")\n        self.recorder_id = self.context.get(\"recorder_id\", create_short_uuid())\n        self._loaded_markets = []  # list of marketIds\n        self._queue = queue.Queue()\n\n    def add(self) -&gt; None:\n        <http:\/\/logger.info|logger.info>(\"Adding strategy %s with id %s\" % (self.name, self.recorder_id))\n        # check local dir\n        if not os.path.isdir(self.local_dir):\n            raise OSError(\"File dir %s does not exist\" % self.local_dir)\n        # create sub dir\n        directory = os.path.join(self.local_dir, self.recorder_id)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n    def start(self) -&gt; None:\n        # start load processor thread\n        threading.Thread(\n            name=\"{0}_load_processor\".format(self.name),\n            target=self._load_processor,\n            daemon=True,\n        ).start()\n\n    def process_raw_data(self, publish_time, data):\n        market_id = data.get(self.MARKET_ID_LOOKUP)\n        file_directory = os.path.join(self.local_dir, self.recorder_id, market_id)\n        with open(file_directory, \"a\") as f:\n            f.write(\n                json.dumps({\"op\": \"mcm\", \"clk\": None, \"pt\": publish_time, \"mc\": [data]})\n                + \"\\n\"\n            )\n\n    def process_closed_market(self, market, data: dict) -&gt; None:\n        market_id = data.get(self.MARKET_ID_LOOKUP)\n        if market_id in self._loaded_markets:\n            if self._force_update:\n                logger.warning(\n                    \"File: \/{0}\/{1}\/{2} has already been loaded, updating..\".format(\n                        self.local_dir, self.recorder_id, market_id\n                    )\n                )\n            else:\n                return\n        else:\n            self._loaded_markets.append(market_id)\n        <http:\/\/logger.info|logger.info>(\"Closing market %s\" % market_id)\n\n        file_dir = os.path.join(self.local_dir, self.recorder_id, market_id)\n        market_definition = data.get(\"marketDefinition\")\n\n        # check that file actually exists\n        if not os.path.isfile(file_dir):\n            logger.error(\n                \"File: %s does not exist in \/%s\/%s\/\"\n                % (self.local_dir, market_id, self.recorder_id)\n            )\n            return\n\n        # check that file is not empty \/ 1 line (i.e. the market had already closed on startup)\n        line_count = file_line_count(file_dir)\n        if line_count == 1:\n            logger.warning(\n                \"File: %s contains one line only and will not be loaded (already closed on startup)\"\n                % file_dir\n            )\n            return\n\n        self._queue.put((market, file_dir, market_definition))\n\n    def _load_processor(self):\n        # process compression\/load in thread\n        while True:\n            market, file_dir, market_definition = self._queue.get(block=True)\n            # check file still exists (potential race condition)\n            if not os.path.isfile(file_dir):\n                logger.warning(\n                    \"File: %s does not exist in %s\" % (market.market_id, file_dir)\n                )\n                continue\n            # compress file\n            compress_file_dir = self._compress_file(file_dir)\n            # core load code\n            self._load(market, compress_file_dir, market_definition)\n            # clean up\n            self._clean_up()\n\n    def _compress_file(self, file_dir: str) -&gt; str:\n        \"\"\"compresses txt file into filename.gz\"\"\"\n        compressed_file_dir = \"{0}.gz\".format(file_dir)\n        with open(file_dir, \"rb\") as f:\n            with gzip.open(compressed_file_dir, \"wb\") as compressed_file:\n                compressed_file.writelines(f)\n        return compressed_file_dir\n\n    def _load(self, market, compress_file_dir: str, market_definition: dict) -&gt; None:\n        # store marketCatalogue data `{marketId}.json.gz`\n        if market and self._load_market_catalogue:\n            if market.market_catalogue is None:\n                logger.warning(\n                    \"No marketCatalogue data available for %s\" % market.market_id\n                )\n                return\n            market_catalogue_compressed = self._compress_catalogue(\n                market.market_catalogue\n            )\n            # save to file\n            file_dir = os.path.join(\n                self.local_dir, self.recorder_id, \"{0}.json.gz\".format(market.market_id)\n            )\n            with open(file_dir, \"wb\") as f:\n                f.write(market_catalogue_compressed)\n\n    @staticmethod\n    def _compress_catalogue(market_catalogue) -&gt; bytes:\n        market_catalogue_dumped = market_catalogue.json()\n        if isinstance(market_catalogue_dumped, str):\n            market_catalogue_dumped = market_catalogue_dumped.encode(\"utf-8\")\n        return gzip.compress(market_catalogue_dumped)\n\n    def _clean_up(self) -&gt; None:\n        \"\"\"If gz &gt; market_expiration old remove\n        gz and txt file\n        \"\"\"\n        directory = os.path.join(self.local_dir, self.recorder_id)\n        for file in os.listdir(directory):\n            if file.endswith(\".gz\"):\n                gz_path = os.path.join(directory, file)\n                file_stats = os.stat(gz_path)\n                seconds_since = time.time() - file_stats.st_mtime\n                if seconds_since &gt; self._market_expiration:\n                    if self._remove_gz_file:\n                        <http:\/\/logger.info|logger.info>(\n                            \"Removing: %s, age: %ss\"\n                            % (gz_path, round(seconds_since, 2))\n                        )\n                        os.remove(gz_path)\n                    txt_path = os.path.join(directory, file.split(\".gz\")[0])\n                    if os.path.exists(txt_path) and self._remove_file:\n                        file_stats = os.stat(txt_path)\n                        seconds_since = time.time() - file_stats.st_mtime\n                        if seconds_since &gt; self._market_expiration:\n                            <http:\/\/logger.info|logger.info>(\n                                \"Removing: %s, age: %ss\"\n                                % (txt_path, round(seconds_since, 2))\n                            )\n                            os.remove(txt_path)\n\n    @staticmethod\n    def _create_metadata(market_definition: dict) -&gt; dict:\n        try:\n            del market_definition[\"runners\"]\n        except KeyError:\n            pass\n        return dict([a, str(x)] for a, x in market_definition.items())\n\n\nclass S3MarketRecorder(Ma…",
                "title": "<https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py | marketrecorder.py>",
                "footer": "<https:\/\/github.com\/liampauling\/flumine|liampauling\/flumine>",
                "id": 1,
                "footer_icon": "https:\/\/slack.github.com\/static\/img\/favicon-neutral.png",
                "color": "24292f",
                "mrkdwn_in": [
                    "text"
                ],
                "fallback": "<https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py | marketrecorder.py>",
                "bot_id": "B021ZJYSBMW",
                "app_unfurl_url": "https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py",
                "is_app_unfurl": true
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "G\/W",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py",
                                "text": "https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U01PNBCPSKT",
        "type": "message",
        "ts": "1629068883.252500",
        "client_msg_id": "1E24822C-054F-499F-B0B2-7E20A167F704",
        "text": "Thanks for that, <@U016TGY3676> . I was looking for something more standalone and, also, not just storing raw data but processed.\n\nMaybe something like <https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/marketrecorder.py|https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/marketrecorder.py> but one that builds the ladder as well.",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "dd487a1a3898",
            "image_72": "https:\/\/avatars.slack-edge.com\/2021-02-25\/1797934283412_dd487a1a3898ed0b4ec6_72.png",
            "first_name": "Steve",
            "real_name": "Steve Roach",
            "display_name": "",
            "team": "T4G9NBD2M",
            "name": "steve_roach",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1629066953.248900",
        "parent_user_id": "U016TGY3676",
        "attachments": [
            {
                "text": "```\nimport time\nimport logging\nimport betfairlightweight\nfrom pythonjsonlogger import jsonlogger\n\nfrom flumine import Flumine, clients\nfrom flumine.streams.datastream import DataStream\nfrom strategies.marketrecorder import MarketRecorder\n\nlogger = logging.getLogger()\n\ncustom_format = \"%(asctime) %(levelname) %(message)\"\nlog_handler = logging.StreamHandler()\nformatter = jsonlogger.JsonFormatter(custom_format)\nformatter.converter = time.gmtime\nlog_handler.setFormatter(formatter)\nlogger.addHandler(log_handler)\nlogger.setLevel(<http:\/\/logging.INFO|logging.INFO>)\n\ntrading = betfairlightweight.APIClient(\"username\")\nclient = clients.BetfairClient(trading)\n\nframework = Flumine(client=client)\n\nstrategy = MarketRecorder(\n    name=\"WIN\",\n    market_filter=betfairlightweight.filters.streaming_market_filter(\n        event_type_ids=[\"7\"],\n        country_codes=[\"GB\", \"IE\"],\n        market_types=[\"WIN\"],\n    ),\n    stream_class=DataStream,\n    context={\n        \"local_dir\": \"\/tmp\",\n        \"force_update\": False,\n        \"remove_file\": True,\n    },\n)\n\nframework.add_strategy(strategy)\n\nframework.run()\n\n```",
                "title": "<https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/marketrecorder.py | marketrecorder.py>",
                "footer": "<https:\/\/github.com\/liampauling\/flumine|liampauling\/flumine>",
                "id": 1,
                "footer_icon": "https:\/\/slack.github.com\/static\/img\/favicon-neutral.png",
                "color": "24292f",
                "mrkdwn_in": [
                    "text"
                ],
                "fallback": "<https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/marketrecorder.py | marketrecorder.py>",
                "bot_id": "B021ZJYSBMW",
                "app_unfurl_url": "https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/marketrecorder.py",
                "is_app_unfurl": true
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "fxu",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks for that, "
                            },
                            {
                                "type": "user",
                                "user_id": "U016TGY3676"
                            },
                            {
                                "type": "text",
                                "text": " . I was looking for something more standalone and, also, not just storing raw data but processed.\n"
                            },
                            {
                                "type": "text",
                                "text": "\nMaybe something like "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/marketrecorder.py",
                                "text": "https:\/\/github.com\/liampauling\/flumine\/blob\/master\/examples\/marketrecorder.py"
                            },
                            {
                                "type": "text",
                                "text": " but one that builds the ladder as well."
                            }
                        ]
                    }
                ]
            }
        ]
    }
]