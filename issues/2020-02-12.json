[
    {
        "user": "U92CASP1B",
        "type": "message",
        "ts": "1581521890.103700",
        "client_msg_id": "d2b2f19e-5358-4030-96e6-04d9ad613e1f",
        "text": "<@UT3R0JEG4> guess you have to loop, you could do a one pass grouping by market id and output markets into separate files, then it will be as in the normal historical format. I also use this format dumping all stream messages in single file. \n\n<@U4H19D1D2> I asked betfair dev support about the conflated messages, it seems like they conflate messages not only depending on ability to empty buffer. I tried setting RCV_BUFFER to very large (32Mb) in sockopt and checked window size in wireshark and it never decreased to zero I cannot think of another way they are detecting slowdowns :)",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g374352c822f",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/a374352c822fa856c4cfdd782bbb8669.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0007-72.png",
            "first_name": "Jonatan",
            "real_name": "Jonatan",
            "display_name": "Jonatan (skyw)",
            "team": "T4G9NBD2M",
            "name": "almen.jonatan",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Y64A",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UT3R0JEG4"
                            },
                            {
                                "type": "text",
                                "text": " guess you have to loop, you could do a one pass grouping by market id and output markets into separate files, then it will be as in the normal historical format. I also use this format dumping all stream messages in single file. \n\n"
                            },
                            {
                                "type": "user",
                                "user_id": "U4H19D1D2"
                            },
                            {
                                "type": "text",
                                "text": " I asked betfair dev support about the conflated messages, it seems like they conflate messages not only depending on ability to empty buffer. I tried setting RCV_BUFFER to very large (32Mb) in sockopt and checked window size in wireshark and it never decreased to zero I cannot think of another way they are detecting slowdowns :)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UKD8R5P9N",
        "type": "message",
        "ts": "1581576270.104400",
        "client_msg_id": "9f524e17-c03e-48f0-a8eb-f30aa7966dae",
        "text": "Is there a way for historical streams to send updates every 1000ms rather than each update inidividually?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "g09ddf2a3275",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/109ddf2a3275e508d9d062b7ecadc3ba.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png",
            "first_name": "",
            "real_name": "William",
            "display_name": "William",
            "team": "T4G9NBD2M",
            "name": "willdargz",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Nol",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Is there a way for historical streams to send updates every 1000ms rather than each update inidividually?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U4H19D1D2",
        "type": "message",
        "ts": "1581576771.106000",
        "client_msg_id": "0F3801A7-FD72-4D0B-81DE-8E5E17210CE2",
        "text": "No but you could modify the listener to do something similar, I.e only put something on the queue or yield every 1000ms",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "137c5a3ef323",
            "image_72": "https:\/\/avatars.slack-edge.com\/2024-03-15\/6819395173841_137c5a3ef323f1944a1a_72.png",
            "first_name": "liam",
            "real_name": "liam",
            "display_name": "liam",
            "team": "T4G9NBD2M",
            "name": "liam",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2614",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "No but you could modify the listener to do something similar, I.e only put something on the queue or yield every 1000ms"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]