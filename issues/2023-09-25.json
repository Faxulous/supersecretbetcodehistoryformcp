[
    {
        "user": "U05TQFU9TJP",
        "type": "message",
        "ts": "1695627875.996529",
        "client_msg_id": "02356b8f-ecc5-477d-84fb-2e374d88908b",
        "text": "Hello Everyone, I am getting an issue with the Betfair api\nI am retrieving horse racing data for every data with Live api key. I save the live races data ( almost 30-60 races a day ) and retrieve from frontend.\nBut the data saving is delayed as there are more races, ( 1 second per 1 race ) and I need to see them changed every 3-5 seconds.\nI am using MongoDB and Python for the Backend to get data from Betfair api.  Thanks",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gdbbcd3b1954",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/dbbcd3b1954e7c405c747c6a8b9f37ee.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png",
            "first_name": "Software",
            "real_name": "Software Engineer",
            "display_name": "Software Engineer",
            "team": "T4G9NBD2M",
            "name": "tr.soft.engineer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "reply_count": 26,
        "reply_users_count": 3,
        "latest_reply": "1695815964.657119",
        "reply_users": [
            "UBS7QANF3",
            "U05TQFU9TJP",
            "U4H19D1D2"
        ],
        "replies": [
            {
                "user": "UBS7QANF3",
                "ts": "1695628047.692179"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1695628467.110439"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695628684.673619"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695628692.739109"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1695628895.839999"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695630956.371039"
            },
            {
                "user": "UBS7QANF3",
                "ts": "1695631029.743109"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695631651.104509"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1695807854.609869"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695807887.723339"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1695807950.255169"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695807965.034329"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1695813861.483219"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695813917.908829"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1695813981.388229"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695814029.127949"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1695814367.105109"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695814469.405049"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1695814505.453319"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695814535.580739"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695815079.527559"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1695815880.055669"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695815896.967419"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695815948.442729"
            },
            {
                "user": "U05TQFU9TJP",
                "ts": "1695815954.515789"
            },
            {
                "user": "U4H19D1D2",
                "ts": "1695815964.657119"
            }
        ],
        "is_locked": false,
        "subscribed": true,
        "last_read": "1695815964.657119",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dN3j",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Hello Everyone, I am getting an issue with the Betfair api\nI am retrieving horse racing data for every data with Live api key. I save the live races data ( almost 30-60 races a day ) and retrieve from frontend.\nBut the data saving is delayed as there are more races, ( 1 second per 1 race ) and I need to see them changed every 3-5 seconds.\nI am using MongoDB and Python for the Backend to get data from Betfair api.  Thanks"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1695628047.692179",
        "client_msg_id": "207f5986-a7ba-47b1-acc0-03531ff8e7d3",
        "text": "What does your code look like?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "parent_user_id": "U05TQFU9TJP",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "LSqmE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "What does your code look like?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "text": "Here is my code",
        "files": [
            {
                "id": "F05TR1US4UB",
                "created": 1695628270,
                "timestamp": 1695628270,
                "name": "betfair_app.py",
                "title": "betfair_app.py",
                "mimetype": "text\/plain",
                "filetype": "python",
                "pretty_type": "Python",
                "user": "U05TQFU9TJP",
                "user_team": "T4G9NBD2M",
                "editable": true,
                "size": 5545,
                "mode": "snippet",
                "is_external": false,
                "external_type": "",
                "is_public": true,
                "public_url_shared": false,
                "display_as_bot": false,
                "username": "",
                "url_private": "https:\/\/files.slack.com\/files-pri\/T4G9NBD2M-F05TR1US4UB\/betfair_app.py?t=xoxe-152328387089-8357743338709-8373272928225-dfe8ebcd8ca3d2f633bcafeb95191840",
                "url_private_download": "https:\/\/files.slack.com\/files-pri\/T4G9NBD2M-F05TR1US4UB\/download\/betfair_app.py?t=xoxe-152328387089-8357743338709-8373272928225-dfe8ebcd8ca3d2f633bcafeb95191840",
                "permalink": "https:\/\/betcode-org.slack.com\/files\/U05TQFU9TJP\/F05TR1US4UB\/betfair_app.py",
                "permalink_public": "https:\/\/slack-files.com\/T4G9NBD2M-F05TR1US4UB-07902e8603",
                "edit_link": "https:\/\/betcode-org.slack.com\/files\/U05TQFU9TJP\/F05TR1US4UB\/betfair_app.py\/edit",
                "is_starred": false,
                "has_rich_preview": false,
                "file_access": "visible"
            }
        ],
        "upload": false,
        "user": "U05TQFU9TJP",
        "display_as_bot": false,
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "1dHLt",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Here is my code"
                            }
                        ]
                    }
                ]
            }
        ],
        "type": "message",
        "ts": "1695628280.323379",
        "client_msg_id": "704f2461-c5fc-4ef5-9060-1070dcc52d4c"
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1695628467.110439",
        "client_msg_id": "3d012039-f4cb-4d23-9464-9f5c8bd97f74",
        "text": "I assume from your code that you are:\n\n1. Using the REST API\n2. Serially scraping the set of races\nSo it's not surprising that you are experiencing delayed data when you have a lot of races to loop through\n\nThere is a lot else wrong with your code - mainly that you are saving only a small subset of the data\n\nBest practice is to use the market recorder in flumine: <https:\/\/github.com\/betcode-org\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py> to save the raw price stream then you can analyse it after the fact any which way",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "parent_user_id": "U05TQFU9TJP",
        "attachments": [
            {
                "id": 1,
                "footer_icon": "https:\/\/slack.github.com\/static\/img\/favicon-neutral.png",
                "color": "24292f",
                "bot_id": "B021ZJYSBMW",
                "app_unfurl_url": "https:\/\/github.com\/betcode-org\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py",
                "is_app_unfurl": true,
                "app_id": "A01BP7R4KNY",
                "fallback": "<https:\/\/github.com\/betcode-org\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py | marketrecorder.py>",
                "text": "```\nimport os\nimport json\nimport time\nimport logging\nimport gzip\nimport boto3\nimport queue\nimport threading\nfrom boto3.s3.transfer import S3Transfer, TransferConfig\nfrom botocore.exceptions import BotoCoreError\n\nfrom flumine import BaseStrategy\nfrom flumine.utils import create_short_uuid, file_line_count\n\nlogger = logging.getLogger(__name__)\n\n\nclass MarketRecorder(BaseStrategy):\n\n    \"\"\"\n    Simple raw streaming market recorder, context:\n\n        market_expiration: int, Seconds to wait after market closure before removing files\n        remove_file: bool, Remove txt file during cleanup\n        remove_gz_file: bool, Remove gz file during cleanup\n        force_update: bool, Update zip\/closure if update received after closure\n        load_market_catalogue: bool, Store marketCatalogue as {marketId}.json\n        local_dir: str, Dir to store data\n        recorder_id: str, Directory name (defaults to random uuid)\n    \"\"\"\n\n    MARKET_ID_LOOKUP = \"id\"\n\n    def __init__(self, *args, **kwargs):\n        BaseStrategy.__init__(self, *args, **kwargs)\n        self._market_expiration = self.context.get(\"market_expiration\", 3600)  # seconds\n        self._remove_file = self.context.get(\"remove_file\", False)\n        self._remove_gz_file = self.context.get(\"remove_gz_file\", False)\n        self._force_update = self.context.get(\"force_update\", True)\n        self._load_market_catalogue = self.context.get(\"load_market_catalogue\", True)\n        self.local_dir = self.context.get(\"local_dir\", \"\/tmp\")\n        self.recorder_id = self.context.get(\"recorder_id\", create_short_uuid())\n        self._loaded_markets = []  # list of marketIds\n        self._queue = queue.Queue()\n\n    def add(self) -> None:\n        <http:\/\/logger.info|logger.info>(\"Adding strategy %s with id %s\" % (self.name, self.recorder_id))\n        # check local dir\n        if not os.path.isdir(self.local_dir):\n            raise OSError(\"File dir %s does not exist\" % self.local_dir)\n        # create sub dir\n        directory = os.path.join(self.local_dir, self.recorder_id)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n    def start(self) -> None:\n        # start load processor thread\n        threading.Thread(\n            name=\"{0}_load_processor\".format(self.name),\n            target=self._load_processor,\n            daemon=True,\n        ).start()\n\n    def process_raw_data(self, clk: str, publish_time: int, data: dict):\n        market_id = data.get(self.MARKET_ID_LOOKUP)\n        file_directory = os.path.join(self.local_dir, self.recorder_id, market_id)\n        with open(file_directory, \"a\") as f:\n            f.write(\n                json.dumps(\n                    {\"op\": \"mcm\", \"clk\": clk, \"pt\": publish_time, \"mc\": [data]},\n                    separators=(\",\", \":\"),\n                )\n                + \"\\n\"\n            )\n\n    def process_closed_market(self, market, data: dict) -> None:\n        market_id = data.get(self.MARKET_ID_LOOKUP)\n        if market_id in self._loaded_markets:\n            if self._force_update:\n                logger.warning(\n                    \"File: \/{0}\/{1}\/{2} has already been loaded, updating..\".format(\n                        self.local_dir, self.recorder_id, market_id\n                    )\n                )\n            else:\n                return\n        else:\n            self._loaded_markets.append(market_id)\n        <http:\/\/logger.info|logger.info>(\"Closing market %s\" % market_id)\n\n        file_dir = os.path.join(self.local_dir, self.recorder_id, market_id)\n        market_definition = data.get(\"marketDefinition\")\n\n        # check that file actually exists\n        if not os.path.isfile(file_dir):\n            logger.error(\n                \"File: %s does not exist in \/%s\/%s\/\"\n                % (self.local_dir, market_id, self.recorder_id)\n            )\n            return\n\n        # check that file is not empty \/ 1 line (i.e. the market had already closed on startup)\n        line_count = file_line_count(file_dir)\n        if line_count == 1:\n            logger.warning(\n                \"File: %s contains one line only and will not be loaded (already closed on startup)\"\n                % file_dir\n            )\n            return\n\n        self._queue.put((market, file_dir, market_definition))\n\n    def _load_processor(self):\n        # process compression\/load in thread\n        while True:\n            market, file_dir, market_definition = self._queue.get(block=True)\n            # check file still exists (potential race condition)\n            if not os.path.isfile(file_dir):\n                logger.warning(\n                    \"File: %s does not exist in %s\" % (market.market_id, file_dir)\n                )\n                continue\n            # compress file\n            compress_file_dir = self._compress_file(file_dir)\n            # core load code\n            self._load(market, compress_file_dir, market_definition)\n            # clean up\n            self._clean_up()\n\n    def _compress_file(self, file_dir: str) -> str:\n        \"\"\"compresses txt file into filename.gz\"\"\"\n        compressed_file_dir = \"{0}.gz\".format(file_dir)\n        with open(file_dir, \"rb\") as f:\n            with gzip.open(compressed_file_dir, \"wb\") as compressed_file:\n                compressed_file.writelines(f)\n        return compressed_file_dir\n\n    def _load(self, market, compress_file_dir: str, market_definition: dict) -> None:\n        # store marketCatalogue data `{marketId}.json.gz`\n        if market and self._load_market_catalogue:\n            if market.market_catalogue is None:\n                logger.warning(\n                    \"No marketCatalogue data available for %s\" % market.market_id\n                )\n                return\n            market_catalogue_compressed = self._compress_catalogue(\n                market.market_catalogue\n            )\n            # save to file\n            file_dir = os.path.join(\n                self.local_dir, self.recorder_id, \"{0}.json.gz\".format(market.market_id)\n            )\n            with open(file_dir, \"wb\") as f:\n                f.write(market_catalogue_compressed)\n\n    @staticmethod\n    def _compress_catalogue(market_catalogue) -> bytes:\n        market_catalogue_dumped = market_catalogue.json()\n        if isinstance(market_catalogue_dumped, str):\n            market_catalogue_dumped = market_catalogue_dumped.encode(\"utf-8\")\n        return gzip.compress(market_catalogue_dumped)\n\n    def _clean_up(self) -> None:\n        \"\"\"If gz > market_expiration old remove\n        gz and txt file\n        \"\"\"\n        directory = os.path.join(self.local_dir, self.recorder_id)\n        for file in os.listdir(directory):\n            if file.endswith(\".gz\"):\n                gz_path = os.path.join(directory, file)\n                file_stats = os.stat(gz_path)\n                seconds_since = time.time() - file_stats.st_mtime\n                if seconds_since > self._market_expiration:\n                    if self._remove_gz_file:\n                        <http:\/\/logger.info|logger.info>(\n                            \"Removing: %s, age: %ss\"\n                            % (gz_path, round(seconds_since, 2))\n                        )\n                        os.remove(gz_path)\n                    txt_path = os.path.join(directory, file.split(\".gz\")[0])\n                    if os.path.exists(txt_path) and self._remove_file:\n                        file_stats = os.stat(txt_path)\n                        seconds_since = time.time() - file_stats.st_mtime\n                        if seconds_since > self._market_expiration:\n                            <http:\/\/logger.info|logger.info>(\n                                \"Removing: %s, age: %ss\"\n                                % (txt_path, round(seconds_since, 2))\n                            )\n                            os.remove(txt_path)\n\n    @staticmethod\n    def _create_metadata(market_definition: dict) -> dict:\n        try:\n            del market_definition[\"runners\"]\n        except KeyError:\n            pass\n        return dict([a, str(xâ€¦",
                "title": "<https:\/\/github.com\/betcode-org\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py | marketrecorder.py>",
                "footer": "<https:\/\/github.com\/betcode-org\/flumine|betcode-org\/flumine>",
                "mrkdwn_in": [
                    "text"
                ]
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "OpNc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I assume from your code that you are:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Using the REST API"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Serially scraping the set of races"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nSo it's not surprising that you are experiencing delayed data when you have a lot of races to loop through\n\nThere is a lot else wrong with your code - mainly that you are saving only a small subset of the data\n\nBest practice is to use the market recorder in flumine: "
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/github.com\/betcode-org\/flumine\/blob\/master\/examples\/strategies\/marketrecorder.py"
                            },
                            {
                                "type": "text",
                                "text": " to save the raw price stream then you can analyse it after the fact any which way"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05TQFU9TJP",
        "type": "message",
        "ts": "1695628684.673619",
        "client_msg_id": "67722bb6-475a-484b-bfef-00f1ba092678",
        "text": "Thanks",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gdbbcd3b1954",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/dbbcd3b1954e7c405c747c6a8b9f37ee.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png",
            "first_name": "Software",
            "real_name": "Software Engineer",
            "display_name": "Software Engineer",
            "team": "T4G9NBD2M",
            "name": "tr.soft.engineer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "parent_user_id": "U05TQFU9TJP",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "5DGl",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05TQFU9TJP",
        "type": "message",
        "ts": "1695628692.739109",
        "client_msg_id": "06a85b14-3adf-438d-b989-a3518d7a722a",
        "text": "Do I need to use MarketCatalogue api?",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gdbbcd3b1954",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/dbbcd3b1954e7c405c747c6a8b9f37ee.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png",
            "first_name": "Software",
            "real_name": "Software Engineer",
            "display_name": "Software Engineer",
            "team": "T4G9NBD2M",
            "name": "tr.soft.engineer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "parent_user_id": "U05TQFU9TJP",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "p9G",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Do I need to use MarketCatalogue api?"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1695628895.839999",
        "client_msg_id": "18bc4c0d-85e9-4b6e-845e-be5772300099",
        "text": "I don't really understand the question",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "parent_user_id": "U05TQFU9TJP",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "yhBb8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I don't really understand the question"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05TQFU9TJP",
        "type": "message",
        "ts": "1695630956.371039",
        "client_msg_id": "4bb84cb5-6154-4cfb-8a79-5004b58d462b",
        "text": "To get data from betfair",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gdbbcd3b1954",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/dbbcd3b1954e7c405c747c6a8b9f37ee.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png",
            "first_name": "Software",
            "real_name": "Software Engineer",
            "display_name": "Software Engineer",
            "team": "T4G9NBD2M",
            "name": "tr.soft.engineer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "parent_user_id": "U05TQFU9TJP",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "M1E+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "To get data from betfair"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "UBS7QANF3",
        "type": "message",
        "ts": "1695631029.743109",
        "client_msg_id": "872d7e52-e3ac-4911-a7b4-6ce8c08dfaae",
        "text": "flumine's market recorder will save both the price stream and the market catalogues",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gaaf844a4a90",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/eaaf844a4a905431d83430e563b077aa.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0011-72.png",
            "first_name": "",
            "real_name": "Maurice Berk",
            "display_name": "Mo",
            "team": "T4G9NBD2M",
            "name": "maurice",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "parent_user_id": "U05TQFU9TJP",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "5r3n",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "flumine's market recorder will save both the price stream and the market catalogues"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "user": "U05TQFU9TJP",
        "type": "message",
        "ts": "1695631651.104509",
        "client_msg_id": "0a348c5e-ee40-4c91-afc2-430ee584e1fe",
        "text": "ahh Thanks",
        "team": "T4G9NBD2M",
        "user_team": "T4G9NBD2M",
        "source_team": "T4G9NBD2M",
        "user_profile": {
            "avatar_hash": "gdbbcd3b1954",
            "image_72": "https:\/\/secure.gravatar.com\/avatar\/dbbcd3b1954e7c405c747c6a8b9f37ee.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0023-72.png",
            "first_name": "Software",
            "real_name": "Software Engineer",
            "display_name": "Software Engineer",
            "team": "T4G9NBD2M",
            "name": "tr.soft.engineer",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1695627875.996529",
        "parent_user_id": "U05TQFU9TJP",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7=CJ\/",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "ahh Thanks"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]