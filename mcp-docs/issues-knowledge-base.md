# Issues Knowledge Base

*Generated from Slack chat history - 4218 technical conversations*

---

## 2017-09-09

**gerg** - *21:42:45*

I am getting IO error in windows machine. Its failing here in examplehistorical.py



#######################

# create historical stream, update directory to file location

stream = trading.historical.create_stream(

    directory='C:\\Users\Gerg\Desktop',

    listener=listener

)

########################

---------------------------------------------------------------------------

IOError                                   Traceback (most recent call last)

&lt;ipython-input-27-5894684e70b4&gt; in &lt;module&gt;()

     35 

     36 # start stream

---&gt; 37 stream.start(async=False)



C:\Users\Gerg\Anaconda2\lib\site-packages\betfairlightweight\endpoints\historical.pyc in start(self, async)

     45             t.start()

     46         else:

---&gt; 47             self._read_loop()

     48 

     49     def _read_loop(self):



C:\Users\Gerg\Anaconda2\lib\site-packages\betfairlightweight\endpoints\historical.pyc in _read_loop(self)

     48 

     49     def _read_loop(self):

---&gt; 50         with open(self.directory, 'r') as f:

     51             for update in f:

     52                 self.listener.on_data(update)



IOError: [Errno 2] No such file or directory: 'C:\\Users\\Gerg\\Desktop'

*Tags: Errors Debugging, Strategies*

---

**liam** - *21:44:13*

The error above just has your desktop 

*Tags: Errors Debugging*

---

**liam** - *21:52:34*

You need to add the file name of the market you have downloaded and unzipped from the historical data website to the end of that directory 

*Tags: Data Quality*

---

**gerg** - *23:32:09*

[@U4H19D1D2](@U4H19D1D2) Like you said I downloaded the file and gave the entire path to that file, 



# create historical stream, update directory to file location

stream = trading.historical.create_stream(

  directory='C:\\Users\Gerg\Downloads\data\Sites\bodw\api\8223dab0-db21-4435-af78-42d036c9ada0\BASIC-1.119219417',

  listener=listener

)



but I am getting following error. 





IOError                                   Traceback (most recent call last)

&lt;ipython-input-13-9b68443c839e&gt; in &lt;module&gt;()

35 

36 # start stream

---&gt; 37 stream.start(async=False)



C:\Users\Gerg\Anaconda2\lib\site-packages\betfairlightweight\endpoints\historical.pyc in start(self, async)

45             t.start()

46         else:

  ---&gt; 47             self._read_loop()

48 

49     def _read_loop(self):

  

  C:\Users\Gerg\Anaconda2\lib\site-packages\betfairlightweight\endpoints\historical.pyc in _read_loop(self)

48 

49     def _read_loop(self):

  ---&gt; 50         with open(self.directory, 'r') as f:

  51             for update in f:

  52                 self.listener.on_data(update)



IOError: [Errno 22] invalid mode ('r') or filename: 'C:\\Users\\Gerg\\Downloads\\data\\Sites\x08odw\x07pi\\8223dab0-db21-4435-af78-42d036c9ada0\\BASIC-1.119219417'

*Tags: Errors Debugging, Strategies*

---

## 2017-09-11

**gerg** - *01:39:40*

I used forward slashes , not double back slashes.. But in the error its showing double forward slashes

*Tags: Errors Debugging*

---

**seaders** - *01:43:33*

again, check "regular" python first

*Tags: General Technical*

---

**gerg** - *01:47:39*

INFO:betfairlightweight.streaming.stream:[Stream: None]: "MarketStream" created

INFO:betfairlightweight.streaming.stream:[MarketStream: HISTORICAL] 1.119219417 added

*Tags: General Technical*

---

**gerg** - *01:50:22*

yes that is right [@U5D4ZBEAG](@U5D4ZBEAG) .. I am sorry for asking dump question, new to this so trying to understand the expected output.. I am running examplehistorical.py

*Tags: Getting Started*

---

**gerg** - *01:53:54*

[@U5D4ZBEAG](@U5D4ZBEAG) Perfect, you are super helpful.. I see this in the output file

*Tags: General Technical*

---

**seaders** - *01:54:52*

and for what marketbook is,

[https://github.com/liampauling/betfair/blob/b4e85fdc595a74610f85599eb15792411e3e108c/betfairlightweight/resources/bettingresources.py#L430](https://github.com/liampauling/betfair/blob/b4e85fdc595a74610f85599eb15792411e3e108c/betfairlightweight/resources/bettingresources.py#L430)

*Tags: Strategies*

---

**seaders** - *01:55:20*

and that corresponds to BetFair's documentation, [http://docs.developer.betfair.com/docs/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Type+Definitions#BettingTypeDefinitions-MarketBook](http://docs.developer.betfair.com/docs/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Type+Definitions#BettingTypeDefinitions-MarketBook)

*Tags: Strategies*

---

**gerg** - *02:04:03*

So we cant get OODS by using the betfair API ?

*Tags: General Technical*

---

**seaders** - *02:23:09*

and, *at worst*, start up the api with a debugger

*Tags: Errors Debugging*

---

**gerg** - *02:30:41*

Why I am not seeing these fields in the historical data... Sorry to bother you, but can you provide me with links to some docs to understand more on calculating ODDS?

*Tags: Data Quality*

---

**seaders** - *02:34:00*

I don't know how you're editing / running your python stuff, but if you use a good IDE like PyCharm, if you've things set up right,

*Tags: General Technical*

---

**seaders** - *02:35:59*

[https://github.com/liampauling/betfair/blob/b4e85fdc595a74610f85599eb15792411e3e108c/betfairlightweight/resources/bettingresources.py#L407](https://github.com/liampauling/betfair/blob/b4e85fdc595a74610f85599eb15792411e3e108c/betfairlightweight/resources/bettingresources.py#L407)

*Tags: Strategies*

---

**seaders** - *02:42:45*

main thing is running it, breaking it, debugging / logging it, until you're comfortable

*Tags: Errors Debugging*

---

## 2017-10-26

**OT** - *20:45:08*

take the historical stream example and set the listener to lightweight=True.. actually now that I mention this, maybe it's to do with the historical data.. :confused:

*Tags: Data Quality*

---

**liam** - *20:46:05*

If you set logging to debug can you see runner data?

*Tags: Errors Debugging*

---

**OT** - *20:55:35*

I've written a backtester but having big performance problems with the volume of 1sec advanced data.

*Tags: Performance*

---

**liam** - *21:07:47*

Yeh performance is an issue, I have moved to golang for parsing historical data 

*Tags: Data Quality, Performance*

---

**liam** - *21:10:00*

To do a racing market, python: 3mins ish, golang: 8s and this is without goroutines, just copying lightweights design 

*Tags: General Technical*

---

**liam** - *21:14:11*

Yeh, don’t have an example how to use the historical endpoint though

*Tags: General Technical*

---

**OT** - *21:46:36*

Does golang have packages like Python?

*Tags: General Technical*

---

**liam** - *22:01:10*

You can use c in python relatively easily, something I want to do but need to wait for my programming skills to catch up  

*Tags: General Technical*

---

## 2017-12-20

**OT** - *21:09:16*

Just wondering if this is correct behaviour.. before I start to debug further.

*Tags: Errors Debugging*

---

**OT** - *21:39:57*

an empty list would be a bit more Pythonic, I think

*Tags: General Technical*

---

**liam** - *21:40:12*

Is this historical? Initial image or update? What does .streaming_update look like?

*Tags: General Technical*

---

**OT** - *21:41:27*

live data, initial image.

*Tags: Deployment*

---

**liam** - *21:46:09*

[https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/streamingresources.py#L203](https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/streamingresources.py#L203)

*Tags: General Technical*

---

## 2017-12-30

**Unknown** - *19:48:26*

[@U88ENUXN2](@U88ENUXN2) uploaded a file: [https://betfairlightweight.slack.com/files/U88ENUXN2/F8LNJPRLM/-.txt|Untitled](https://betfairlightweight.slack.com/files/U88ENUXN2/F8LNJPRLM/-.txt|Untitled)

*Tags: General Technical*

---

**Lennart** - *20:55:58*

Thanks, Liam - I appreciate your help. That seems to have resolved  the first error but the second one still persists. The wording of the error message ("Certificate folder") seems to suggest that there should be more just the .crt file in the certs folder. I currently just have the .crt file in it - Might that be the issue?

*Tags: Errors Debugging*

---

**Lennart** - *20:57:30*

Sorry for the silly questions - I'm sure this is pretty rudimentary

*Tags: General Technical*

---

## 2018-01-11

**mbk** - *11:32:13*

```

def create_stream(client):

    listener = betfairlightweight.StreamListener()

    stream = client.streaming.create_stream(listener=listener)

    market_filter = streaming_market_filter(

        event_type_ids=['7'],

        country_codes=['GB', 'IE'],

        market_types=['WIN', 'PLACE'],

        )

    market_data_filter = streaming_market_data_filter(

        fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

        ladder_levels=1,

        )

    stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        )

    return stream, listener



if __name__ == '__main__':

    trading = APIClient('username', 'password', 'certs')

    trading.login()

    stream, listener = api.create_stream(trading)



    stream.start(async=True)



    # starting up

    time.sleep(10)

    books = listener.snap()

    stream.stop()



    for b in books:

        md = b.market_definition

        print md.venue, md.market_time

        for runner in md.runners:

            print runner.name



```

*Tags: Strategies*

---

**liam** - *11:36:13*

Look at line 35 in streaming resources 

*Tags: General Technical*

---

**seaders** - *11:45:17*

some places on the BetFair API will update that time, as they get updates... some *won't*

*Tags: General Technical*

---

## 2018-01-12

**mikey155** - *13:38:19*

I'm new to this site. I'm a python newbie, all of my existing apps written in Visual Basic. Following up the previous discussion on horses names, I'm now drilling into historical data, employing betfairlightweight. Your examplestreaminghistorical works as expected as is, but I'm finding errors (missing positional argument in RunnerBook) when I try to acquire horse names. I tried adding name to RunnerBook but get the same error. Probably a naive newbie error but I thought I'd try to get some insight here. Thanks in advance.

*Tags: Getting Started, Data Quality, Errors Debugging*

---

**mikey155** - *14:36:31*

I'm new to this site. I'm a python newbie, all of my existing apps written in Visual Basic. Following up the previous discussion on horses names, I'm now drilling into historical data, employing betfairlightweight. Your examplestreaminghistorical works as expected as is, but I'm finding errors (missing positional argument in RunnerBook) when I try to acquire horse names. I tried adding name to RunnerBook but get the same error. Probably a naive newbie error but I thought I'd try to get some insight here. Thanks in advance.

*Tags: Getting Started, Data Quality, Errors Debugging*

---

**Unknown** - *14:40:57*

You able to share the code / error?

*Tags: Errors Debugging*

---

**mikey155** - *15:29:50*

Liam, In examplestreaminghistorical I modified def on_process as follows:

*Tags: General Technical*

---

**mikey155** - *15:31:54*

And changed RunnerBook in streamingresources as follows:

*Tags: General Technical*

---

**mikey155** - *15:32:50*

I get the following error:

*Tags: Errors Debugging*

---

**mikey155** - *15:33:24*

File "C:/Users/Jam/PycharmProjects/betfair/examples/examplestreaminghistorical.py", line 33, in on_process

    runner.selection_id, runner.name, runner.last_price_traded or ''

AttributeError: 'RunnerBook' object has no attribute 'name'

(this is all in PyCharm)

*Tags: Errors Debugging*

---

**liam** - *15:35:12*

Yeh I strongly advise not updating any of the resources. The runner name is stored in the definition and not not provided in the book. Have you seen the following which shows how to access name? [https://files.slack.com/files-pri/T4G9NBD2M-F89QVUUF9/-.py](https://files.slack.com/files-pri/T4G9NBD2M-F89QVUUF9/-.py)

*Tags: General Technical*

---

**mikey155** - *15:35:57*

I think I'm missing something e.g. changing update_cache? I can figure out how to get results from your code like driving a car but am no good under the bonnet - need to learn plenty more Python

*Tags: General Technical*

---

**mikey155** - *15:40:57*

Thanks that's a good lead. What gets me about Python is that things change so quickly e.g. I'm using Python 3.6 in PyCharm and the word async gives a syntax error. I was able to get round that for the historical data but it might be an issue when I move on to stream API for trading.

*Tags: Data Quality, Errors Debugging, Strategies*

---

## 2018-01-25

**mbk** - *09:50:03*

Using the example in your repo, I get the following response when calling `trading.historic.get_file_list` which raises an exception

*Tags: Errors Debugging, Strategies*

---

**mbk** - *09:50:13*

```

'\r\n\r\n\r\n&lt;!DOCTYPE html&gt;\r\n\r\n&lt;html&gt;\r\n&lt;head&gt;\r\n    &lt;meta name="viewport" content="width=device-width" /&gt;\r\n    &lt;title&gt;ngErrorRedirect&lt;/title&gt;\r\n&lt;/head&gt;\r\n&lt;body&gt;\r\n    &lt;div&gt; \r\n        Error\r\n    &lt;/div&gt;\r\n    &lt;script&gt;\r\n        window.location("[https://historicdata.betfair.com/#/error](https://historicdata.betfair.com/#/error)");\r\n    &lt;/script&gt;\r\n&lt;/body&gt;\r\n&lt;/html&gt;\r\n'

```

*Tags: Errors Debugging*

---

**mbk** - *09:59:41*

the weird thing is that the response has status 200 but the content says error

*Tags: Errors Debugging*

---

**liam** - *10:00:29*

[https://github.com/liampauling/betfair/blob/UAT/betfairlightweight/endpoints/historic.py#L167](https://github.com/liampauling/betfair/blob/UAT/betfairlightweight/endpoints/historic.py#L167)

*Tags: General Technical*

---

**mbk** - *10:11:15*

ah I see this issue was fixed in the UAT branch, but not in master

*Tags: Errors Debugging*

---

## 2018-01-26

**OT** - *02:58:21*

I have had lots of problems with the historic data API. I suspect it has some rate limiting on it (and bandwidth throttling).

*Tags: General Technical*

---

## 2018-02-05

**liam** - *18:32:00*

Just created a new issue #154, I believe my PR #155 will fix it but I am struggling to confirm that dict.values() returns a generator and this is what caused the RuntimeError, anyone know? [https://github.com/liampauling/betfair/pull/155](https://github.com/liampauling/betfair/pull/155)

*Tags: Errors Debugging*

---

**seaders** - *18:43:45*

It is in python 3

*Tags: General Technical*

---

**seaders** - *18:46:14*

They *basically* act like their "iter" equivalents in python 2.x (all those functions have been removed)

*Tags: General Technical*

---

**seaders** - *21:44:11*

^^^ in Python 3, you get a Runtime error, dict changed

*Tags: Errors Debugging*

---

**seaders** - *21:44:25*

^^^ in Python 2, you're all fine

*Tags: General Technical*

---

**seaders** - *21:47:12*

in python 2, if you use `.itervalues()` instead of values, you get a generator, and you get the same error

*Tags: Errors Debugging*

---

**seaders** - *21:53:14*

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1517855520000072](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1517855520000072)

just on this, make sure to read the whole error, cos it does explain, `dictionary changed size during iteration`

*Tags: Errors Debugging*

---

**seaders** - *22:46:31*

[@U4H19D1D2](@U4H19D1D2) I've just PR'd a test which fails the snap thingy in Python 3

*Tags: General Technical*

---

**seaders** - *22:46:40*

but will pass with your fix

*Tags: Errors Debugging*

---

## 2018-02-06

**seaders** - *15:56:23*

all sorted now, my PR has a test in that fails 100% of the time in python 3.x, but with your fix passes 100% of the time

*Tags: Errors Debugging*

---

**Unknown** - *21:11:06*

[@U8J6SKR5E](@U8J6SKR5E) shared a file: [https://betfairlightweight.slack.com/files/U8J6SKR5E/F951FA28M/-|Untitled](https://betfairlightweight.slack.com/files/U8J6SKR5E/F951FA28M/-|Untitled)

*Tags: General Technical*

---

**Unknown** - *21:13:48*

[@U8J6SKR5E](@U8J6SKR5E) shared a file: [https://betfairlightweight.slack.com/files/U8J6SKR5E/F94SVMLMS/-|Untitled](https://betfairlightweight.slack.com/files/U8J6SKR5E/F94SVMLMS/-|Untitled)

*Tags: General Technical*

---

**liam** - *21:51:15*

Lol how do you even send posts like that. What are you trying to do as you don’t need to touch the streaming update, you can just access the prices like you would from a normal market book response, like the bottom of example one 

*Tags: General Technical*

---

**Unknown** - *22:27:34*

[@U8J6SKR5E](@U8J6SKR5E) shared a file: [https://betfairlightweight.slack.com/files/U8J6SKR5E/F94UPJCM8/-|Untitled](https://betfairlightweight.slack.com/files/U8J6SKR5E/F94UPJCM8/-|Untitled)

*Tags: General Technical*

---

## 2018-02-07

**liam** - *11:37:20*

It’s basically betfair telling you that something is wrong but the connection / filter / clk is still valid and open, data should then be sent if it is fixed 

*Tags: Errors Debugging*

---

## 2018-02-20

**hugo** - *11:13:02*

Betfair seem to not be sending an openDate on one of their market definitions causing the MarketDefinition resource init to crash. Making that field an optional arg seems to fix.

*Tags: Errors Debugging*

---

## 2018-04-11

**OT** - *22:33:46*

just decided to update bfl and getting this: TypeError: __init__() got an unexpected keyword argument 'kl'

*Tags: Errors Debugging*

---

**OT** - *22:35:06*

python3.5/site-packages/betfairlightweight/resources/bettingresources.py", line 489, in __init__

    ) if kwargs.get('keyLineDescription') else None

TypeError: __init__() got an unexpected keyword argument 'kl'

*Tags: Errors Debugging, Strategies*

---

## 2018-04-17

**erlend** - *20:55:39*

Yo, I'm getting  "INVALID_SESSION_INFORMATION: Session must be 'Bearer &lt;session&gt;' for a WebApp'" when running examplestreaming.py

*Tags: General Technical*

---

**liam** - *20:57:12*

That using a API-NG appKey and authorised for streaming?

*Tags: General Technical*

---

## 2018-04-19

**erlend** - *12:44:59*

So betfair dev support got back to me with:

The issue is occurring because your App Key is configured as a web application.

Web application App Key must use the Bearer token as the "session" (token_type + " " + access_token). Please see documentation [http://docs.developer.betfair.com/docs/display/1smk3cen4v3lu3yomq5qye0ni/Vendor+Services+in+API-NG#VendorServicesinAPI-NG-MakingAPICallsOnTheUsersBehalf](http://docs.developer.betfair.com/docs/display/1smk3cen4v3lu3yomq5qye0ni/Vendor+Services+in+API-NG#VendorServicesinAPI-NG-MakingAPICallsOnTheUsersBehalf)

*Tags: General Technical*

---

**erlend** - *12:45:08*

Can I do this in betfairlightweight?

*Tags: General Technical*

---

## 2018-04-30

**jfo** - *18:19:43*

anyone have any idea what error code `ANGX-0003` is about?

*Tags: Errors Debugging*

---

## 2018-05-01

**liam** - *08:20:21*

I think I was getting some of those errors when making cleared orders requests last week 

*Tags: Errors Debugging*

---

## 2018-06-02

**liam** - *10:14:07*

1.6.3 now pushed to pypi, minor fix to handle ciso8601 update and setting specific versions for third party libs to prevent it happening again. I used in production last night with no issues (streaming). Thanks [@U9CP5N36K](@U9CP5N36K) as this would have screwed me over.

*Tags: Errors Debugging, Deployment*

---

## 2018-06-06

**Ben** - *18:01:51*

Hi Liam, I get a weird error on a regular basis when i try to close a stream?

*Tags: Errors Debugging*

---

**Unknown** - *18:02:00*

[@U93H3483E](@U93H3483E) uploaded a file: [https://betfairlightweight.slack.com/files/U93H3483E/FB259J072/-.txt|Untitled](https://betfairlightweight.slack.com/files/U93H3483E/FB259J072/-.txt|Untitled)

*Tags: General Technical*

---

**Unknown** - *18:03:13*

[@U93H3483E](@U93H3483E) uploaded a file: [https://betfairlightweight.slack.com/files/U93H3483E/FB2RULYBC/-.py|Untitled](https://betfairlightweight.slack.com/files/U93H3483E/FB2RULYBC/-.py|Untitled)

*Tags: General Technical*

---

**liam** - *18:46:56*

Sure your not double calling stop? Really line 70 should error if it is None 

*Tags: Errors Debugging*

---

## 2018-06-16

**favetelinguis** - *21:00:24*

Is it common for Betfair not to send name for market and runners in the streaming MarketDefinition? They are just None wich intuitively seems wrong.

*Tags: General Technical*

---

## 2018-07-31

**man** - *16:40:15*

Hi! I'm trying to make use of the historicalstreaming.py but I keep getting this error:

File "/usr/local/lib/python3.5/dist-packages/betfairlightweight/streaming/betfairstream.py", line 290, in _read_loop

    for update in f:

  File "/usr/lib/python3.5/codecs.py", line 321, in decode

    (result, consumed) = self._buffer_decode(data, self.errors, final)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xfd in position 10: invalid start byte

*Tags: Errors Debugging*

---

**man** - *16:40:27*

Do you have anyidea how to deal with that?

*Tags: General Technical*

---

**seaders** - *16:44:13*

There's example python code somewhere on here that does that, search for gzip

*Tags: General Technical*

---

**man** - *17:22:34*

Is the streaminghistoricalexample.py up to date? I found that here:

[https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py)

the HistoricalStream class is different

*Tags: General Technical*

---

**Rory** - *22:09:16*

rather than unzip every file, I just handle them using the bz2 module in Python

*Tags: General Technical*

---

## 2018-08-07

**man** - *15:13:56*

I have been trying to use the HistoricalStream to parse historical data with no success. Does any one have sample code which is up to date?

*Tags: Data Quality*

---

**man** - *15:43:59*

I was able to start my historical stream. The problem is that I'm not getting any data out of Queue which i have given for the listener like in examplestreaming.py. Is the Queue correct way to get the parsed data out?

*Tags: General Technical*

---

**man** - *15:56:58*

Sorry for that question I just noticed that the data is written to txt file

*Tags: General Technical*

---

## 2018-08-27

**favetelinguis** - *10:34:04*

[@UAXGAG15J](@UAXGAG15J) what is sort order good for/used for? Does it ever change during the lifetime of a market or is it fixed at the start of a market?

*Tags: Errors Debugging*

---

**liam** - *12:50:58*

Helpful for the website / trading apps, it will be updated during the day but I believe it is static from about 10mins out

*Tags: Strategies*

---

## 2018-09-03

**Rob** - *07:49:42*

Has anyone ran in to this issue before using streaming? It's occurring after the stream has been running for a while, seemingly at random:



```

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\threading.py", line 916, in _bootstrap_inner

    self.run()

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\threading.py", line 864, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 191, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 225, in _receive_all

    data += part.decode(self.__encoding)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd2 in position 1: invalid continuation byte



Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\threading.py", line 916, in _bootstrap_inner

    self.run()

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\threading.py", line 864, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 191, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 225, in _receive_all

    data += part.decode(self.__encoding)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 296: invalid start byte

```

*Tags: Errors Debugging*

---

**liam** - *08:33:57*

No, is that py3.5? I wouldn't recommend launching run in a thread without a lot of error catching anyway due to timeouts/connection issues

*Tags: Errors Debugging*

---

**Rob** - *21:22:25*

python 3.6.6, although I'm not sure I made that choice conciously

*Tags: General Technical*

---

**Rob** - *21:22:46*

I guessed it'd be something like that - I'll add some more error handling

*Tags: Errors Debugging*

---

**Rob** - *21:41:22*

thanks - that must be a red herring. I've added some error handling to try to work out what's happening

*Tags: Errors Debugging*

---

**liam** - *21:41:55*

I assume latest version of bflw?

*Tags: General Technical*

---

**Rob** - *21:44:17*

I think so : `betfairlightweight==1.7.2`

*Tags: General Technical*

---

**Rob** - *21:48:38*

thanks for the reply btw - much appreciated, the package is proving very useful, both for Betfair and indirectly for motivating me to learn more Python

*Tags: General Technical*

---

## 2018-09-04

**liam** - *06:24:50*

Hmm it must be windows, we had a bug a while ago where Betfair was closing the connection now and again by sending an empty string through the socket. The following line solved that but maybe it doesn’t work for windows.

*Tags: Errors Debugging*

---

**liam** - *06:24:55*

[https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py#L221](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py#L221)

*Tags: General Technical*

---

## 2018-09-20

**loken92** - *15:00:38*

Hi!

I am implementing the stream listener and experiencing some issues. For some reason the python script stops at random, without any error. I think it could be related to high latency. Any tips on what could be causing this and how to fix it? Thanks!

*Tags: Errors Debugging, Performance*

---

## 2018-09-21

**liam** - *10:03:29*

[@UCCF7JJVC](@UCCF7JJVC) are you using async? It’s recommended to create a new thread manually with as much exception handling as possible over the start function, been discussed a few times but here is an example

*Tags: Errors Debugging*

---

**liam** - *10:03:32*

[https://github.com/liampauling/flumine/blob/master/flumine/flumine.py#L111](https://github.com/liampauling/flumine/blob/master/flumine/flumine.py#L111)

*Tags: General Technical*

---

## 2018-12-07

**seaders** - *12:57:43*

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1544187441002100](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1544187441002100)

*Tags: General Technical*

---

## 2019-01-28

**wsdlwizard** - *19:34:52*

I am getting 'betfairlightweight.exceptions.LoginError: API login: CERT_AUTH_REQUIRED' error after using the wrapper with no problems for months. I renewed my certificates and uploaded them to Betfair and used curl to get a successful login but it still gives me this error. I then did a pip install to see if the wrapper needed updating. Any ideas? Many thanks.

*Tags: Getting Started, Errors Debugging*

---

**Rory** - *19:37:50*

[@UFQK2K4PK](@UFQK2K4PK) see this post by Seaders ... [https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1545064303107800](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1545064303107800)

*Tags: General Technical*

---

**agberk** - *19:38:53*

yeah you've probably got an old version; `pip uninstall betfairlightweight` then `pip install betfairlightweight==1.8.2`

*Tags: Getting Started*

---

**seaders** - *19:39:51*

`pip install --upgrade betfairlightweight` should do it, shouldn't it?  1.8.2 is the latest on pypi - [https://pypi.org/project/betfairlightweight/](https://pypi.org/project/betfairlightweight/)

*Tags: Getting Started*

---

**wsdlwizard** - *19:58:56*

Yes, I had the old version 1.8.0 so all is good after upgrading to 1.8.2 Thanks very much for the help)

*Tags: General Technical*

---

## 2019-01-29

**Newbie99** - *19:41:00*

Hi,



I'm having real trouble with certs at the moment and having read about a thousand Github pages and various others I'm no closer.



I created certs using XCA and have a .pem and a .crt file. I have uploaded the .crt file to Betfair and enabled it for Bot trading...however thats where it all falls down.



I've tried both the Betfair and Betfairlightweight Python wrappers, but both keep coming up with various error messages, relating to the certs.



For Betfairlightweight, I have no idea where it expects them to be, as there's no certs folder and even if I attempt to change the path, it still doesn't work.



For the Betfair python wrapper, it just produces a similar error, although at least that seems to have a certs folder.



I've tried the following Curl request:



curl -q -k --cert CERT.pem [https://identitysso-cert.betfair.com/api/certlogin](https://identitysso-cert.betfair.com/api/certlogin) -d "username='USERNAME'&amp;password='PASSWORD'" -H "'APPKEY': curlCommandLineTest"

*Tags: Errors Debugging, Strategies*

---

**Newbie99** - *19:41:40*

and I get an HTTP Error Code 400

*Tags: Errors Debugging*

---

**Newbie99** - *19:42:07*

Which doesn't seem to make sense as its not one of the expected error codes from the Betfair site

*Tags: Errors Debugging*

---

**agberk** - *19:49:54*

There's some conflicting information on the bot login page [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login) at one point it says:

&gt; Include a custom Header called “X-Application” with a value that identifies your application.  The value is not validated and is only used to help with troubleshooting and diagnosing any problems.

And then at another it says

&gt; X-Application - You must set the X-Application header to your application key.

Finally the curl example requests has the following headers:

&gt; -H "X-Application: curlCommandLineTest"

*Tags: General Technical*

---

**agberk** - *19:51:15*

Not sure it will solve your problem but what happens when you use either `-H "X-Application: curlCommandLineTest"` or `-H "X-Application: ${your_app_key}"`

*Tags: General Technical*

---

**Newbie99** - *19:57:31*

If I'm understanding correctly, then trying that I get the following responses:



replacing --cert with --key, results in the same error

Attempting to change the end results in INVALID_USERNAME_OR_PASSWORD

*Tags: Errors Debugging*

---

**Newbie99** - *20:09:46*

no, the same HTTP ERROR Code 400 unfortunately

*Tags: Errors Debugging*

---

**Newbie99** - *20:10:44*

so it actually looks like:



&lt;html&gt;&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;HTTP Error Code 400....

*Tags: Errors Debugging*

---

## 2019-01-30

**liam** - *06:49:08*

[@UFTBRB3F1](@UFTBRB3F1) in regards to your question on the forum



certs_dir = r’C:/windows/sucks/python/certs’



trading = APIClient(’username’, ’password’, ’appKey’, certs=certs_dir)

*Tags: Strategies*

---

**Rory** - *13:25:38*

[@U5D4ZBEAG](@U5D4ZBEAG) I'll try shortly and let you know ... but I've downloaded lots of historical data for the last 3 seasons ... regularly get corrupted files like that .... best bet is to try it again ...

*Tags: Data Quality*

---

**liam** - *13:38:20*

i don't know where i read this but I think Neil mentioned that they are rewriting the historical data api

*Tags: Data Quality*

---

**Newbie99** - *18:14:37*

Hi Liam, just going back to the syntax you kindly sent me, I still can't get it to work. The keys must be fine as I can use the generic Python code on the Betfair site and that works, however with betfairlightweight, I am now getting an error that says:



ssl.SSLError: [SSL] PEM lib (_ssl.c:3824)



Intuitively I feel this could be something to do with my key being a .pem file, not a .key file perhaps? But thats a complete guess.

*Tags: Errors Debugging*

---

**Newbie99** - *20:38:38*

ah...okay, that may help. For some reason I can't seem to create a key in open SSL though. There seems to be a script in the Betfair wrapper (as opposed to betfairlighweight), but when I try and invoke SSL, it just returns an error. Python is confusing me a lot!!!

*Tags: Errors Debugging*

---

**seaders** - *22:07:08*

don't do cert generation with python, just use command line, their docs do cover it

*Tags: General Technical*

---

## 2019-01-31

**Newbie99** - *08:04:18*

I just get an error message

*Tags: Errors Debugging*

---

**Newbie99** - *17:30:42*

Hi Liam, I don't unfortunately...but I didn't realise I could do that! I assumed with streaming I had to have cert login working

*Tags: General Technical*

---

**Newbie99** - *18:38:25*

Sorry...dumb question probably, this whole SSL thing is new to me...so if I create a key using Putty...which seems incredibly easy, then presumably there is no issue importing into the XCA gui and somehow signing a file there, which I can then export as a .crt file and upload to Betfair.



Just wanted to check that is the correct approach

*Tags: Getting Started*

---

**Newbie99** - *20:20:51*

That worked btw, managed to figure it out, thank you for your help. I have manged to get in at least :slightly_smiling_face:

*Tags: General Technical*

---

**Newbie99** - *21:53:35*

Still persisting with my attempt to login to the streaming API via node.js too...but failing miserably on that front! If I make progress, I'll post it on the main forum!

*Tags: General Technical*

---

**Rob** - *23:20:10*

while streaming today got several this several times...socket.timeout: The read operation timed out

*Tags: General Technical*

---

**Rob** - *23:22:57*

how to recover from this and keep the streaming connection open? thx

*Tags: General Technical*

---

**liam** - *23:45:34*

You need to catch the error and reconnect, if you do a search [@U4H3EEV45](@U4H3EEV45) has shared a way to do it 

*Tags: Errors Debugging*

---

## 2019-02-05

**Newbie99** - *20:41:28*

Which is the best set of docs, to get up to speed with the various calls etc. when using betfairlightweight. I had a look on Github, but I thought there was another extensive doc I found previously (which I now can't find)?

*Tags: Performance*

---

**seaders** - *21:04:12*

it's the lightweight flag, [https://github.com/liampauling/betfair/blob/a08306a8fc27af9fab046f3b9f343e6780053c10/betfairlightweight/apiclient.py#L8](https://github.com/liampauling/betfair/blob/a08306a8fc27af9fab046f3b9f343e6780053c10/betfairlightweight/apiclient.py#L8)

*Tags: General Technical*

---

**liam** - *21:19:57*

It was more python is really slow and creating millions of resources is really really slow but if it just passes the json back to the user it’s just slow 

*Tags: Performance*

---

## 2019-02-06

**Newbie99** - *22:34:37*

I've been playing around in python and to some extent I can get what I need in the console...however, I'm still stuck with the best way to stream the console results to a webbrowser...I've tried various sockets examples that claim to do the job, but nothing seems to work. Can anyone suggest the best way of getting the console output into a browser (presumably via some kind of websocket connection)?

*Tags: General Technical*

---

**Newbie99** - *23:03:27*

Thanks, however I get exactly the same issue...I don't get any error as such, but it just does nothing. I'm trying to essentially send the output of the example streaming script from Github. The script works fine, I can run it on its own and see the data come back as expected...however whenever I try to put in a any kind of socket connection it simply won't work. I presume there is some kind of conflict that I'm not understanding. Intuitively it seems quite simply, simply send what is shown on the console to a browser...but clearly its not as simple as it seems...although I can not understand why!

*Tags: Errors Debugging*

---

## 2019-02-07

**seaders** - *01:02:11*

```

stream = None

queue = None





def get_queue():

    global queue, stream



    if not queue:

        stream, queue = seadersbfstream.subscribe_to(['1.154237752'])

    return queue





@socketio.on('ping')

def handle_message(_message, *_args, **kwargs):

    market_books = get_queue().get()

    print(market_books)



    for market_book in market_books:

        emit(

            'market_book',

            f'{market_book} '

            f'{market_book.streaming_unique_id} '

            f'{market_book.streaming_update}, '

            f'{market_book.market_definition}, '

            f'{market_book.publish_time} '

        )





if __name__ == '__main__':

    socketio.run(app)

    stream.stop()```

*Tags: General Technical*

---

**seaders** - *11:19:49*

&gt; We’re sorry but it appears there are some problems with our Exchange. Hold tight.  We’re on the case. FYI

 ^^^

*Tags: General Technical*

---

**Kieran Dawson** - *11:57:38*

Hey guys. probably a stupid question but does anyone know some sort of dictionary of MarketIDs?

*Tags: General Technical*

---

**Kieran Dawson** - *11:59:22*

But the market IDs are just numbers for now, so i have no idea how to see what they actually mean

*Tags: General Technical*

---

**seaders** - *12:01:06*

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1533071394000045](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1533071394000045)

*Tags: General Technical*

---

**Newbie99** - *18:38:51*

thank you for your code snippet seaders, however maybe I'm being really dense, but it doesn't appear to be working. The client code says io isn't defined, so I tried with the sample code from the Flask page, which doesn't return an error, but still nothing happens. I feel that the problem is probably still with my server code, which is currently as follows. Python is very new to me, so this attempt at editing the streaming example, might be a bit poor, but as I don't get any errors, its a bit tricky to see where the problem is!



[code]

import os

import logging

import queue



import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



from flask import Flask, render_template

from flask_socketio import SocketIO



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

username = os.environ.get('username')





# create trading instance

trading = betfairlightweight.APIClient(user_name,password,appkey,certs=cert_path)



trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(

    output_queue=output_queue,

)



# create stream

stream = trading.streaming.create_stream(

    listener=listener,

)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

    event_type_ids=['7'],

    country_codes=['GB'],

    market_types=['WIN'],

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3,

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# start stream

stream.start(_async=True)



"""

Data can also be accessed by using the snap function in the listener, e.g:

    market_books = listener.snap(

        market_ids=[1.12345323]

    )

Errors need to be caught at stream.start, resubscribe can then be used to

prevent full image being sent, e.g:

    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=1000,  # send update every 1000ms

        initial_clk=listener.initial_clk,

        clk=listener.clk,

    )

The streaming unique id is returned in the market book which allows multiple

streams to be differentiated if multiple streams feed into the same queue.

"""



# check for updates in output queue

while True:

    market_books = output_queue.get()

    print(market_books)





    for market_book in market_books:

        print(

            market_book,

            market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

            market_book.streaming_update,  # json update received

            market_book.market_definition,  # streaming definition, similar to catalogue request

            market_book.publish_time  # betfair publish time of update

        )



app = Flask(__name__)

app.config['SECRET_KEY'] = 'secret!'

socketio = SocketIO(app)



if __name__ == '__main__':

    socketio.run(app)



stream = None

queue = None





def get_queue():

    global queue, stream



    if not queue:

        stream, queue =  trading.streaming.create_stream(

    listener=listener,

)

    return queue



@socketio.on('ping')

def handle_message(_message):

    market_books = get_queue().get()

    print(market_books)



    for market_book in market_books:

        emit(

            'market_book',

            f'{market_book} '

            f'{market_book.streaming_unique_id} '

            f'{market_book.streaming_update}, '

            f'{market_book.market_definition}, '

            f'{market_book.publish_time} '

        )





if __name__ == '__main__':

    socketio.run(app)

    stream.stop()



[/code]

*Tags: Getting Started, Errors Debugging, Deployment, Strategies*

---

**seaders** - *18:50:43*

have you a debugger working correctly? have you tried stepping through your code?

*Tags: Errors Debugging*

---

**Newbie99** - *20:27:37*

sorry for the simple questions, I blame it partly on a lack of python knowledge, partly on flu and partly on general stupidity :slightly_smiling_face:

*Tags: General Technical*

---

## 2019-02-09

**Newbie99** - *17:22:40*

Okay, sorry I'm back again and really confused!



This appears to connect, but doesn't seem to emit any messages:



```

import os

import logging

import queue



from flask import Flask, render_template

from flask_socketio import SocketIO



import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



app = Flask(__name__)

app.config['SECRET_KEY'] = secretkey

socketio = SocketIO(app)



@app.route('/')

def sessions():

    return render_template('index.html')



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

username = os.environ.get('username')

trading = betfairlightweight.APIClient(user_name,password,appkey,certs=cert_path)

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(

    output_queue=output_queue,

)



# create stream

stream = trading.streaming.create_stream(

    listener=listener,

)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

#    event_type_ids=['7'],

#    country_codes=['GB'],

#    market_types=['WIN'],

    market_ids=['1.130856098'],

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3,

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



#start stream

stream.start(_async=True)





"""while True:

    market_books = output_queue.get()

    print(market_books)



    for market_book in market_books:

        print(

            market_book,

            market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

            market_book.streaming_update,  # json update received

            market_book.market_definition,  # streaming definition, similar to catalogue request

            market_book.publish_time  # betfair publish time of update

        )"""



@socketio.on('ping')

def handle_message(_message):

    market_books = output_queue.get()

    print(market_books)



    for market_book in market_books:

        emit(

            'market_book',

            f'{market_book} '

            f'{market_book.streaming_unique_id} '

            f'{market_book.streaming_update}, '

            f'{market_book.market_definition}, '

            f'{market_book.publish_time} '

        )



if __name__ == '__main__':

    socketio.run(app, debug=True)

```

*Tags: Getting Started, Errors Debugging, Strategies*

---

**Newbie99** - *17:24:07*

the command line console also reports no errors

*Tags: Errors Debugging*

---

**seaders** - *19:13:39*

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1549565443098800](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1549565443098800)

*Tags: General Technical*

---

**Newbie99** - *19:30:48*

I'm just using the standard Idle, which doesn't work as it doesn't seem to understand the defs at the top (which aren't shown here), i.e. certs, password etc. So debugging doesn't work (or doesn't seem to) as it thinks they are executed simultaneously and gives a syntax error (of course in reality this isn't an issue and that piece of code is fine).



But...that aside, the above doesn't produce any errors, the connection is good as I get the connected message in the browser and can see activity on the command line console.



So, short of downloading an alternative debugger (happy to listen to ideas), I'm just using your suggested code really, which at face value appears to be correct, its just that the ping and emit for whatever reason are not triggering...

*Tags: Errors Debugging*

---

**seaders** - *19:31:25*

if you don't have a working debugger, and can't step through your code, you're working blind

*Tags: Errors Debugging*

---

**seaders** - *19:46:13*

can you debug any side of what you're programming at all?

*Tags: Errors Debugging*

---

**Newbie99** - *19:48:07*

I've just never actually had a debugging tool tbh (I'm not a professional coder...although I'm guessing that much is obvious)!!! So have never really thought to go down the debugging tool. With php (which is what I'm far more familiar with), I've never really had an issue with notepad and a browser window. That aside, I'm downloading visual studio as we speak, which will help on the debugging front

*Tags: Errors Debugging*

---

**Newbie99** - *20:33:02*

appreciate you've already helped out a lot, however even with Visual Studio there are no errors thrown up by the debugger....it appears the code is functioning correctly...except of course its not. The issue is around the ping or emit, one or the other (or both) are not behaving as I would expect, but are not throwing up any errors (the debugger just shows the connections to the betfair streaming data as expected).



If I refresh the browser window (which I assume pings the server), the command line console refreshes, so somehow the emit part of the code is not firing. I'm guessing (but it is a guess), its to do with this section:



```

@socketio.on('ping')

def handle_message(_message):

    market_books = output_queue.get()

    print(market_books)

```



But as no error is thrown, I'm not really sure where to go from here!



Apologies again for the dumb questions, 'pure' scripting languages (e.g. Node.js / Python) are new to me and clearly I'm struggling with the logic a bit it would seem!

*Tags: Getting Started, Errors Debugging, Deployment*

---

**Newbie99** - *20:40:07*

cool thanks, that actually may help as now I'm getting a ton of errors (which counter intuitively I think is good, as whatever wasn't firing presumably now is and was probably structured incorrectly)!

*Tags: Errors Debugging*

---

**Newbie99** - *20:42:24*

oh actually no, I'd just messed up an indent...that was causing the error, still just chugs along as if nothing was wrong :disappointed:

*Tags: Errors Debugging*

---

**seaders** - *21:37:46*

I'd recommend doing one of the many free Python tutorials online

*Tags: General Technical*

---

**seaders** - *21:38:23*

and while Visual Studio is okay, I'd probably recommend PyCharm over it, nothing should be running *at all* if you've an indent error

*Tags: Errors Debugging*

---

**Newbie99** - *23:23:57*

yep, it didn't, that was the only time I actually had an error....which is the whole confusing thing about python (to me)!



I am trying to rush things of course....but equally, this must be something that everyone on here faces surely when using the wrapper (unless no one else has ever tried to connect to to browser), so if people with far more experience than me can't spot any obvious errors, I suspect you're right I am wasting my time a bit with Python, as a beginner course isn't going to help with websockets and I'm not going to figure this out unless I randomly stumble across a similar example.



That said I'll give PyCharm a go and see if it helps and report back if I make any progress.



Thank you for your help so far though, it has actually been very useful in understanding where the error might be, even if I haven't quite got there yet. From your advice, I can at least work out where the error probably is occurring, so that is much appreciated.

*Tags: Getting Started, Errors Debugging*

---

## 2019-02-16

**Newbie99** - *17:39:36*

hello again, I have spent a lot of time stepping through the logic in a bit more of a sensible fashion and tidied things up a bit. From a logical point of view, I'm still missing something, the code appears to make sense and doesn't throw up any errors. I've setup a ping from the client, the server then responds with a pong...but only on the first ping. In the console.log on the client after that it pings away, but the server never receives them, which seems odd. I make the assumption that the error is actually along the lines of my server code is not looking for the ping, rather than any issue on the client side. I'm guessing there is an issue with Threads that I'm not understanding, because I can't see what else it could be.

*Tags: Getting Started, Errors Debugging, Deployment*

---

**Newbie99** - *17:39:52*

```

import os

import logging

import queue

from threading import Thread

from flask import Flask, render_template

from flask_socketio import SocketIO, emit

import betfairlightweight

from betfairlightweight.filters import (

            streaming_market_filter,

            streaming_market_data_filter,

        )



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

username = os.environ.get('username')

trading = betfairlightweight.APIClient(user_name, password, appkey, certs=cert_path)

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(

    output_queue=output_queue,

)



# create stream

stream = trading.streaming.create_stream(

    listener=listener,

)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

        event_type_ids=['7'],

        country_codes=['US'],

        market_types=['WIN'],

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3,

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# start stream

stream.start(_async=True)



# Create a flask app

app = Flask(__name__)

app.config['SECRET_KEY'] = 'secret!'

# Use the flask app to create a socketio decorator

socketio = SocketIO(app)

thread = None



@app.route('/')

def index():

    global thread

    if thread is None:

        thread = Thread(target=handle_message)

        thread.start()

        socketio.sleep(2)

        return render_template('index.html')



@socketio.on('connect', namespace='/test')

def test_connect():

        global thread

        socketio.sleep(1)

        market_books = output_queue.get()

        print(market_books)

        for market_book in market_books:

             print(

             market_book,

             market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

             market_book.streaming_update,  # json update received

             market_book.market_definition,  # streaming definition, similar to catalogue request

             market_book.publish_time  # betfair publish time of update

        )



        for market_book in market_books:

             emit('my_response', {'data': 'connect', 'mb': market_book.streaming_update, 'namespace': '/test'})

        socketio.sleep(1)

@socketio.on('ping', namespace='/test')

def handle_message(*_args, **_kwargs):

    global thread

    while True:

        socketio.sleep(2)

        emit('my_response', {'data': 'pong', 'mb': 'pong', 'namespace': '/test'})

        socketio.sleep(2)

        market_books = output_queue.get()

        print(market_books)



        for market_book in market_books:

            print(

                market_book,

                market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

                market_book.streaming_update,  # json update received

                market_book.market_definition,  # streaming definition, similar to catalogue request

                market_book.publish_time  # betfair publish time of update

            )



        for market_book in market_books:

            emit('my_response', {'data': 'update', 'mb': market_book.streaming_update, 'namespace': '/test'})

        socketio.sleep(1)



if __name__ == '__main__':

    socketio.run(app, debug=True, host='127.0.0.1', port=5000)

stream.stop()

```

*Tags: Getting Started, Errors Debugging, Strategies*

---

**Newbie99** - *17:48:44*

But thats the issue I guess, I'm not understanding what is necessary to resolve that, I added the socketio.sleep(1) at the end as someone suggested that could free up the CPU and would exit the thread, but that a) seems a bit untidy and b) clearly doesn't do exactly what I need.



So in effect, it sticks there as the server is looking for instruction and nothing is telling it what to do in effect as I don't get any errors, because it pauses there (which is logical from what you say).



But having read up on python loop logic I don't see an obvious solution here, I thought maybe the logic needs to involve a background thread, but although I can get that to fire, I still end up in the same place as it just executes through once.

*Tags: Errors Debugging, Deployment*

---

**Newbie99** - *18:25:55*

no errors (I took out all the sleep's too as that would have messed things up with the faster pings).



The server log reads fine...but again it only fires once:



```

INFO:engineio.server:a552c499c6ab49508a89e7982010a99c: Received request to upgrade to websocket

INFO:engineio.server:a552c499c6ab49508a89e7982010a99c: Received packet MESSAGE data 2/test,["ping"]

INFO:socketio.server:received event "ping" from a552c499c6ab49508a89e7982010a99c [/test]

INFO:socketio.server:emitting event "my_response" to a552c499c6ab49508a89e7982010a99c [/test]

INFO:engineio.server:a552c499c6ab49508a89e7982010a99c: Sending packet MESSAGE data 2/test,["my_response","received a ping"]

```

*Tags: Errors Debugging, Deployment*

---

**Newbie99** - *18:49:45*

what it doesn't seem to like however, is if I actually try to emit the following:



```

 market_books = output_queue.get()

        for market_book in market_books:

         emit('my_response', {'data': 'update', 'mb': market_book.streaming_update})

```

*Tags: General Technical*

---

**Newbie99** - *20:12:06*

(I stuck in the 300ms sleep as I got a verbose error on the client and thought that should reduce that risk)

*Tags: Errors Debugging*

---

## 2019-02-17

**Newbie99** - *15:28:41*

I have got that sample code up and running, but for me it behaves the same as the previous effort (almost), in that it sends through the initial price cache as expected, however then it just pings away (i.e. the client console.log shows 'pinging').



The server logs, show:



```

INFO:socketio.server:received event "ping" from 41f1cafd420740b3921c67883d9b0bb0 [/]

INFO:socketio.server:emitting event "my_response" to 41f1cafd420740b3921c67883d9b0bb0 [/]

INFO:engineio.server:41f1cafd420740b3921c67883d9b0bb0: Client is gone, closing socket

INFO:engineio.server:41f1cafd420740b3921c67883d9b0bb0: Client is gone, closing socket

```



The client logs are interesting, as there are some errors that show up (which we never had previously):



```

socket.io.min.js:1 POST [http://localhost:5000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550416830901-24&amp;sid=0e8737cace6149e1abff289ba77e7c24](http://localhost:5000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550416830901-24&amp;sid=0e8737cace6149e1abff289ba77e7c24) 500 (Internal Server Error)

socket.io.min.js:1 GET [http://localhost:5000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550416745904-23&amp;sid=0e8737cace6149e1abff289ba77e7c24](http://localhost:5000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550416745904-23&amp;sid=0e8737cace6149e1abff289ba77e7c24) 400 (BAD REQUEST)

```



and also:



```

socket.io.min.js:2 WebSocket connection to '[ws://localhost:5000/socket.io/?EIO=3&amp;transport=websocket&amp;sid=9ae605a3067b40328159b3072a45112c](ws://localhost:5000/socket.io/?EIO=3&amp;transport=websocket&amp;sid=9ae605a3067b40328159b3072a45112c)' failed: WebSocket is closed before the connection is established.

```

*Tags: Errors Debugging, Deployment*

---

**Newbie99** - *17:51:34*

By emitting a text string and commenting out the market_books references below, I can see the PING and respective emit work correctly, therefore this issue appears to be around market_books = output_queue.get() after the first time (as it always works first time round):



```

@socketio.on('ping')

def handle_message(*_args, **_kwargs):

    market_books = output_queue.get()



    for market_book in market_books:

        emit('my_response',

             {'data': 'update', 'mb': market_book.streaming_update})

```

*Tags: Getting Started*

---

## 2019-02-18

**Newbie99** - *19:36:35*

Hmm, I tried a couple of different browsers, with the same result, however I'm 99% sure your diagnosis is correct here, from playing around with sleep in Python and setInterval on the browser side.



Server:



```

@socketio.on('ping')

def handle_message(*_args, **_kwargs):

    emit('my_response2', 'text')

    socketio.sleep(1)

    stream_send()



def stream_send(*_args, **_kwargs):

    market_books = output_queue.get()

    for market_book in market_books:

       emit('my_response',{'message':market_book.streaming_update})

    socketio.sleep(1)

    emit('my_response2', 'text')

```



In the server logs this pauses here:



```

INFO:engineio.server:3fd83d077e694382a70dc6d73429cc51: Sending packet MESSAGE data 2["my_response",{"message":{"id":"1.155109947","marketDefinition":{"bspMarket":true,"turnInPlayEnabled":false,"persistenceEnabled":false,"marketBaseRate":5,"eventId":"29138495","eventTypeId":"7","numberOfWinners":1,"bettingType":"ODDS","marketType":"WIN","marketTime":"2019-02-19T01:10:00.000Z","suspendTime":"2019-02-19T01:10:00.000Z","bspReconciled":false,"complete":true,"inPlay":false,"crossMatching":false,"runnersVoidable":false,"numberOfActiveRunners":9,"betDelay":0,"status":"OPEN","runners":[{"status":"ACTIVE","sortPriority":1,"id":22937351},{"status":"ACTIVE","sortPriority":2,"id":22937352},{"status":"ACTIVE","sortPriority":3,"id":22937353},{"status":"ACTIVE","sortPriority":4,"id":22937354},{"status":"ACTIVE","sortPriority":5,"id":22937355},{"status":"ACTIVE","sortPriority":6,"id":22937356},{"status":"ACTIVE","sortPriority":7,"id":22937361},{"status":"ACTIVE","sortPriority":8,"id":22937362},{"status":"ACTIVE","sortPriority":9,"id":11502826}],"regulators":["MR_NJ","MR_INT"],"venue":"Dover Downs","countryCode":"US","discountAllowed":true,"timezone":"US/Eastern","openDate":"2019-02-18T21:30:00.000Z","version":2645887285,"priceLadderDefinition":{"type":"CLASSIC"}},"rc":[{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.67]],"id":22937361},{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.63]],"id":22937356},{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.65]],"id":22937354},{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.69]],"id":11502826},{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.73]],"id":22937355},{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.69]],"id":22937352},{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.69]],"id":22937353},{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.73]],"id":22937351},{"batb":[[0,1.01,17.52]],"batl":[[0,1000,1.7]],"id":22937362}],"img":true}}]

INFO:socketio.server:emitting event "my_response2" to 3fd83d077e694382a70dc6d73429cc51 [/]

INFO:engineio.server:3fd83d077e694382a70dc6d73429cc51: Sending packet MESSAGE data 2["my_response2","text"]

127.0.0.1 - - [18/Feb/2019 19:28:27] "POST /socket.io/?EIO=3&amp;transport=polling&amp;t=1550518105709-1&amp;sid=3fd83d077e694382a70dc6d73429cc51 HTTP/1.1" 200 219 2.080826

INFO:engineio.server:3fd83d077e694382a70dc6d73429cc51: Upgrade to websocket successful

INFO:engineio.server:3fd83d077e694382a70dc6d73429cc51: Received packet MESSAGE data 2["ping"]

INFO:socketio.server:received event "ping" from 3fd83d077e694382a70dc6d73429cc51 [/]

INFO:socketio.server:emitting event "my_response2" to 3fd83d077e694382a70dc6d73429cc51 [/]

INFO:engineio.server:3fd83d077e694382a70dc6d73429cc51: Sending packet MESSAGE data 2["my_response2","text"]

```



From the client side it appears to ping pong twice successfully on connection, then sends the market book, then (seemingly) it ping pongs twice before stopping (the above is with no delay on emitting a ping on the browser side, if I delay then the behaviour actually seems counter intuitive in that it appears 2 pings arrive before the last pong).



So as you can see, it does appear your diagnosis is correct, but somewhere along the line maybe the messages go out of sync, thus breaking the socket?

*Tags: Deployment, Strategies*

---

## 2019-02-19

**Newbie99** - *12:05:03*

No luck with different ports or browsers, I even tried a fresh install on my Surface Go (which admittedly is also Windows 10, but doesn't have much on it). No joy, but I did get different errors, which may be more useful to decypher:



HTTP400: BAD REQUEST - The request could not be processed by the server due to invalid syntax.

(XHR)GET - [http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550577763533-16&amp;sid=a30e5471ac3446018e7290fa00eba7a5](http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550577763533-16&amp;sid=a30e5471ac3446018e7290fa00eba7a5)



 HTTP400: BAD REQUEST - The request could not be processed by the server due to invalid syntax.

(XHR)POST - [http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550577763604-17&amp;sid=a30e5471ac3446018e7290fa00eba7a5](http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550577763604-17&amp;sid=a30e5471ac3446018e7290fa00eba7a5)



Doesn't make a great deal of sense to me, as the message is logically the same as the previous one that worked fine, but perhaps it needs a line break or something in it?

*Tags: Getting Started, Errors Debugging, Deployment*

---

**Newbie99** - *14:16:17*

Ok, I thought I'd test something and its interesting to see where the problem lies.



```

@socketio.on('ping')

def handle_message(*_args, **_kwargs):

    socketio.sleep(1)

    market_books = output_queue.get()

    emit('my_response2', {'message': 'update', 'mb': len(market_books)})

    socketio.sleep(0.5)

    emit('my_response3')

```



That shouldn't clog anything up, yet it still hangs on the last ping (i.e.  the client receives the message with the number of array items, it pings back, it then receives the null response and pings back...then nothing happens).



On the server side, it looks like this:



```

127.0.0.1 - - [19/Feb/2019 14:14:19] "GET /socket.io/?EIO=3&amp;transport=polling&amp;t=1550585641996-6 HTTP/1.1" 200 381 0.000999

INFO:engineio.server:116a710b7ac54ccb89b0c116f4c15675: Received packet MESSAGE data 2["ping"]

INFO:socketio.server:received event "ping" from 116a710b7ac54ccb89b0c116f4c15675 [/]

(5068) accepted ('127.0.0.1', 60202)

INFO:engineio.server:116a710b7ac54ccb89b0c116f4c15675: Received request to upgrade to websocket

127.0.0.1 - - [19/Feb/2019 14:14:20] "GET /socket.io/?EIO=3&amp;transport=polling&amp;t=1550585659960-8&amp;sid=116a710b7ac54ccb89b0c116f4c15675 HTTP/1.1" 200 215 0.291910

INFO:socketio.server:emitting event "my_response3" to b3a33d164b34497f9e9cbafe6df082a3 [/]

INFO:engineio.server:b3a33d164b34497f9e9cbafe6df082a3: Received packet MESSAGE data 2["ping"]

INFO:socketio.server:received event "ping" from b3a33d164b34497f9e9cbafe6df082a3 [/]

INFO:engineio.server:b3a33d164b34497f9e9cbafe6df082a3: Received packet PING data None

INFO:engineio.server:Receive error -- socket is closed

127.0.0.1 - - [19/Feb/2019 14:14:20] "GET /socket.io/?EIO=3&amp;transport=websocket&amp;sid=b3a33d164b34497f9e9cbafe6df082a3 HTTP/1.1" 200 0 178.484812

```



I thought at first perhaps the loop wasn't ending somehow, but that doesn't appear to be the issue...but at least I can see where the problem must lie...just can't figure out the final step, ha!

*Tags: Errors Debugging, Deployment*

---

## 2019-02-20

**Newbie99** - *16:11:46*

Ok...I think I've figured out why it hangs now...it is to do with output_queue.get() returning an empty value.



I am trying to structure the below to catch (and ignore) an empty outcome (if there are values the queue works fine, which is why it always works first time), however the below returns the error shown in the logs below (which I think confirms my logic is correct, but the way I try to catch it is incorrect):



```

@socketio.on('ping')

def handle_message(*_args, **_kwargs):

    try:

            market_books = output_queue.get(False)

    except output_queue.empty:

            pass

    else:

        for market_book in market_books:

            emit('my_response2', {'message': 'update', 'mb': market_book.streaming_update})

```



Server logs (which I believe confirm my suspicion):



```

ERROR:engineio.server:message handler error

Traceback (most recent call last):

  File "D:/Python37/webpages/betfair_flaskio.py", line 51, in handle_message

    market_books = output_queue.get(False)

  File "D:\Python37\lib\queue.py", line 167, in get

    raise Empty

_queue.Empty



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:\Python37\lib\site-packages\engineio\server.py", line 505, in _trigger_event

    return self.handlers[event](*args)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 590, in _handle_eio_message

    self._handle_event(sid, pkt.namespace, pkt.id, pkt.data)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 526, in _handle_event

    self._handle_event_internal(self, sid, data, namespace, id)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 529, in _handle_event_internal

    r = server._trigger_event(data[0], namespace, sid, *data[1:])

  File "D:\Python37\lib\site-packages\socketio\server.py", line 558, in _trigger_event

    return self.handlers[namespace][event](*args)

  File "D:\Python37\lib\site-packages\flask_socketio\__init__.py", line 258, in _handler

    *args)

  File "D:\Python37\lib\site-packages\flask_socketio\__init__.py", line 641, in _handle_event

    ret = handler(*args)

  File "D:/Python37/webpages/betfair_flaskio.py", line 54, in handle_message

    except output_queue.empty:

TypeError: catching classes that do not inherit from BaseException is not allowed



```

*Tags: Getting Started, Errors Debugging, Deployment*

---

**Newbie99** - *17:31:27*

Tidied up a bit, this appears to work (most of the time), occasionally though I do get an error showing on the client side:



```

@socketio.on('ping')

def handle_message(*_args, **_kwargs):

    try:

            market_books = output_queue.get(False)

    except Exception:

        socketio.sleep(1)

        emit('my_response', {'message': 'pong', 'mb': 'pong'})

    else:

        for market_book in market_books:

            emit('my_response', {'message': 'update', 'mb': market_book.streaming_update})

```



Error messages (client side):



```

GET [http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550683800805-630&amp;sid=0d06865666e74657b6a369ca38adb5f4](http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550683800805-630&amp;sid=0d06865666e74657b6a369ca38adb5f4) 400 (BAD REQUEST)

POST [http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550683801633-631&amp;sid=0d06865666e74657b6a369ca38adb5f4](http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550683801633-631&amp;sid=0d06865666e74657b6a369ca38adb5f4) 400 (BAD REQUEST)

```

*Tags: Errors Debugging*

---

**seaders** - *17:45:18*

try and a blank exception grabber is the boldest of bold a developer can do... :smile: At least log what the exception is!

*Tags: Errors Debugging*

---

**Newbie99** - *18:05:22*

haha, the problem I come up against is logging the empty, I can catch other errors, but couldn't work out how to catch the Empty!

*Tags: Errors Debugging*

---

**Newbie99** - *18:32:47*

I tried that initially, but for some reason I get an error (I've played around with variants too just to see if I could work it out):



```

ERROR:engineio.server:message handler error

Traceback (most recent call last):

  File "D:/Python37/webpages/betfair_flaskio.py", line 51, in handle_message

    market_books = output_queue.get(False)

  File "D:\Python37\lib\queue.py", line 167, in get

    raise Empty

_queue.Empty



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:\Python37\lib\site-packages\engineio\server.py", line 505, in _trigger_event

    return self.handlers[event](*args)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 590, in _handle_eio_message

    self._handle_event(sid, pkt.namespace, pkt.id, pkt.data)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 526, in _handle_event

    self._handle_event_internal(self, sid, data, namespace, id)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 529, in _handle_event_internal

    r = server._trigger_event(data[0], namespace, sid, *data[1:])

  File "D:\Python37\lib\site-packages\socketio\server.py", line 558, in _trigger_event

    return self.handlers[namespace][event](*args)

  File "D:\Python37\lib\site-packages\flask_socketio\__init__.py", line 258, in _handler

    *args)

  File "D:\Python37\lib\site-packages\flask_socketio\__init__.py", line 641, in _handle_event

    ret = handler(*args)

  File "D:/Python37/webpages/betfair_flaskio.py", line 52, in handle_message

    except queue.empty:

AttributeError: module 'queue' has no attribute 'empty'

```

*Tags: Errors Debugging, Deployment*

---

**Newbie99** - *18:36:23*

I still get: ```NameError: name 'Queue' is not defined```

*Tags: Errors Debugging*

---

## 2019-02-22

**Newbie99** - *22:51:48*

Hi, I am back with a question...but don't worry its not code related :slightly_smiling_face: just one of logic!



I'm getting the updates come through, exactly as expected, no issues:



```

{"id":"1.130856098","rc":[{"batb":[[2,3.85,11],[1,3.9,10],[0,3.95,8.38]],"id":10064909}]}

{"id":"1.130856098","rc":[{"batb":[[0,44,6.27],[1,42,2]],"id":12832770},{"batb":[[2,3.8,11],[1,3.85,11],[0,3.9,10.38]],"id":10064909}],"con":true}

{"id":"1.130856098","rc":[{"batb":[[2,40,13.27],[0,44,1]],"id":12832770},{"batl":[[2,5.5,3.13],[1,4.3,16.47],[0,4.2,25.67]],"id":10064909}],"con":true}

```



I'm working on my logic for updating on each update, however before I get too deep in that. I wanted to check if I'd overlooked the obvious when people talk about price caching, is there anything within the wrapper that simply returns the most up-to date complete market state (e.g. can I call a particular function, which already has the logic built in, to show the latest state of a particular market id, as opposed to the last update)?

*Tags: General Technical*

---

## 2019-02-23

**Newbie99** - *10:17:51*

Ah, maybe I'm misunderstanding the data structure, I assumed that the above simply resulted in the latest update being pushed out (that is what appears to be happening, when I push the .streaming_update), I then need to build the logic to update the correct market at my end (which is what I assumed I'd have to do anyway). But is that not the case then (you believe)?

*Tags: General Technical*

---

**Newbie99** - *17:02:18*

I was simply calling:



```

stream = trading.streaming.create_stream(listener=listener.snap(market_ids=['1.130856098']))

```

*Tags: Strategies*

---

**liam** - *17:03:25*

[https://github.com/liampauling/betfair/blob/master/examples/examplestreaming.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaming.py)

*Tags: General Technical*

---

**Newbie99** - *17:06:37*

yeah I'd already tried that and just got null, so I thought maybe I was misunderstanding what the example meant.



In the console I see:



```

1 None &lt;betfairlightweight.resources.streamingresources.MarketDefinition object at 0x0000012F8BE9E748&gt; 2019-02-23 17:05:49.474000

```

*Tags: General Technical*

---

**Newbie99** - *17:20:01*

well that much I'd guessed :wink:



But my stream appears to be working correctly (i.e. I see market updates such as):



```

1 {'id': '1.130856098', 'marketDefinition': {'bspMarket': False, 'turnInPlayEnabled': False, 'persistenceEnabled': False, 'marketBaseRate': 5, 'eventId': '28180290', 'eventTypeId': '2378961', 'numberOfWinners': 1, 'bettingType': 'ODDS', 'marketType': 'NONSPORT', 'marketTime': '2019-03-29T00:00:00.000Z', 'suspendTime': '2019-03-29T00:00:00.000Z', 'bspReconciled': False, 'complete': True, 'inPlay': False, 'crossMatching': False, 'runnersVoidable': False, 'numberOfActiveRunners': 8, 'betDelay': 0, 'status': 'OPEN', 'runners': [{'status': 'ACTIVE', 'sortPriority': 1, 'id': 10064909}, {'status': 'ACTIVE', 'sortPriority': 2, 'id': 12832765}, {'status': 'ACTIVE', 'sortPriority': 3, 'id': 12832766}, {'status': 'ACTIVE', 'sortPriority': 4, 'id': 12832767}, {'status': 'ACTIVE', 'sortPriority': 5, 'id': 12832768}, {'status': 'ACTIVE', 'sortPriority': 6, 'id': 12832770}, {'status': 'ACTIVE', 'sortPriority': 7, 'id': 12832769}, {'status': 'ACTIVE', 'sortPriority': 8, 'id': 12832771}, {'status': 'LOSER', 'sortPriority': 9, 'id': 10317013}, {'status': 'LOSER', 'sortPriority': 10, 'id': 10317010}], 'regulators': ['MR_INT'], 'countryCode': 'GB', 'discountAllowed': True, 'timezone': 'Europe/London', 'openDate': '2019-03-29T00:00:00.000Z', 'version': 2576584033, 'priceLadderDefinition': {'type': 'CLASSIC'}}, 'rc': [{'batb': [[0, 2.66, 9.96], [1, 2.64, 20.7], [2, 2.58, 24.4]], 'batl': [[0, 2.8, 163.58], [1, 2.94, 140.19], [2, 2.96, 11]], 'id': 12832765}, {'batb': [[0, 18.5, 4], [1, 18, 3], [2, 17.5, 2]], 'batl': [[0, 19.5, 2], [1, 20, 7.88], [2, 21, 6.89]], 'id': 12832767}, {'batb': [[0, 8.2, 2], [1, 8, 6], [2, 7.8, 143.63]], 'batl': [[0, 9, 19.87], [1, 9.2, 2], [2, 9.4, 6.37]], 'id': 12832766}, {'batb': [[0, 44, 25.58], [1, 42, 5.23], [2, 38, 4.36]], 'batl': [[0, 55, 4], [1, 60, 2], [2, 70, 2]], 'id': 12832769}, {'batb': [[0, 36, 1], [1, 34, 2], [2, 30, 4]], 'batl': [[0, 40, 3.8], [1, 42, 8.2], [2, 44, 2.01]], 'id': 12832768}, {'batb': [[0, 6, 73.77], [1, 5.9, 14.65], [2, 5.8, 58]], 'batl': [[0, 6.2, 71.22], [1, 6.4, 96.21], [2, 6.6, 109.08]], 'id': 12832771}, {'batb': [[0, 40, 7.47], [1, 38, 2], [2, 36, 4.36]], 'batl': [[0, 44, 1.72], [1, 46, 1], [2, 48, 2]], 'id': 12832770}, {'batb': [[0, 4.1, 2], [1, 4, 31], [2, 3.95, 5.38]], 'batl': [[0, 4.5, 5], [1, 4.7, 61.8], [2, 5.5, 3.14]], 'id': 10064909}], 'img': True} &lt;betfairlightweight.resources.streamingresources.MarketDefinition object at 0x000002720FE564E0&gt; 2019-02-23 17:19:24.141000

```



If I remove that 1 line.

*Tags: Strategies*

---

**Newbie99** - *17:23:26*

```

import logging

import time

import queue

from queue import Empty

from flask import Flask, render_template

from flask_socketio import SocketIO, emit

import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)

from account_info import accname, accpass, acckey, path



logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



trading = betfairlightweight.APIClient(accname, accpass, acckey, certs=path)

trading.login()



output_queue = queue.Queue()

listener = betfairlightweight.StreamListener(output_queue=output_queue)

stream = trading.streaming.create_stream(listener=listener)



# create filters (US WIN horse racing)

market_filter = streaming_market_filter(

#    event_type_ids=['7'],

#    country_codes=['US'],

#    market_types=['WIN'])

     market_ids=['1.130856098'])

market_data_filter = streaming_market_data_filter(

    fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3)



stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000)



stream.start(_async=True)



market_books = listener.snap(market_ids=['1.130856098'])

```

*Tags: Strategies*

---

**Newbie99** - *19:39:15*

Actually, having run a few attempts, the former doesn't seem to work either.



Running:



```

stream.start(_async=True)

time.sleep(2)

market_books = listener.snap(market_ids=['1.130856098'])



while True:

    market_books = output_queue.get()

    for market_book in market_books:

      print(

            market_book.streaming_unique_id,  

            market_book.streaming_update,  

            market_book.market_definition,  

            market_book.publish_time)  

```



Returns:



```

1 {'id': '1.130856098', 'marketDefinition': {'bspMarket': False, 'turnInPlayEnabled': False, 'persistenceEnabled': False, 'marketBaseRate': 5, 'eventId': '28180290', 'eventTypeId': '2378961', 'numberOfWinners': 1, 'bettingType': 'ODDS', 'marketType': 'NONSPORT', 'marketTime': '2019-03-29T00:00:00.000Z', 'suspendTime': '2019-03-29T00:00:00.000Z', 'bspReconciled': False, 'complete': True, 'inPlay': False, 'crossMatching': False, 'runnersVoidable': False, 'numberOfActiveRunners': 8, 'betDelay': 0, 'status': 'OPEN', 'runners': [{'status': 'ACTIVE', 'sortPriority': 1, 'id': 10064909}, {'status': 'ACTIVE', 'sortPriority': 2, 'id': 12832765}, {'status': 'ACTIVE', 'sortPriority': 3, 'id': 12832766}, {'status': 'ACTIVE', 'sortPriority': 4, 'id': 12832767}, {'status': 'ACTIVE', 'sortPriority': 5, 'id': 12832768}, {'status': 'ACTIVE', 'sortPriority': 6, 'id': 12832770}, {'status': 'ACTIVE', 'sortPriority': 7, 'id': 12832769}, {'status': 'ACTIVE', 'sortPriority': 8, 'id': 12832771}, {'status': 'LOSER', 'sortPriority': 9, 'id': 10317013}, {'status': 'LOSER', 'sortPriority': 10, 'id': 10317010}], 'regulators': ['MR_INT'], 'countryCode': 'GB', 'discountAllowed': True, 'timezone': 'Europe/London', 'openDate': '2019-03-29T00:00:00.000Z', 'version': 2576584033, 'priceLadderDefinition': {'type': 'CLASSIC'}}, 'rc': [{'batb': [[0, 2.66, 6.06], [1, 2.64, 20.7], [2, 2.58, 24.4]], 'batl': [[0, 2.68, 1], [1, 2.8, 163.58], [2, 2.94, 140.19]], 'id': 12832765}, {'batb': [[0, 18.5, 4], [1, 18, 3], [2, 17.5, 2]], 'batl': [[0, 19.5, 2], [1, 20, 7.88], [2, 21, 6.89]], 'id': 12832767}, {'batb': [[0, 8.2, 2], [1, 8, 6], [2, 7.8, 143.63]], 'batl': [[0, 9, 19.87], [1, 9.2, 2], [2, 9.4, 6.37]], 'id': 12832766}, {'batb': [[0, 42, 5.3], [1, 38, 4.36], [2, 36, 13.27]], 'batl': [[0, 55, 4], [1, 60, 2], [2, 70, 2]], 'id': 12832769}, {'batb': [[0, 36, 3], [1, 34, 2], [2, 30, 4]], 'batl': [[0, 46, 5.01], [1, 48, 1.91], [2, 50, 4.38]], 'id': 12832768}, {'batb': [[0, 6, 73.77], [1, 5.9, 14.65], [2, 5.8, 58]], 'batl': [[0, 6.2, 71.22], [1, 6.4, 96.21], [2, 6.6, 109.08]], 'id': 12832771}, {'batb': [[0, 40, 7.47], [1, 38, 2], [2, 36, 4.36]], 'batl': [[0, 48, 2], [1, 50, 2.36], [2, 55, 8.09]], 'id': 12832770}, {'batb': [[0, 4.1, 20], [1, 4, 31], [2, 3.95, 5.38]], 'batl': [[0, 4.5, 5], [1, 4.7, 61.8], [2, 5.5, 3.14]], 'id': 10064909}], 'img': True} &lt;betfairlightweight.resources.streamingresources.MarketDefinition object at 0x0000028F6EB9F4E0&gt; 2019-02-23 19:33:02.838000

1 {'id': '1.130856098', 'rc': [{'batl': [[2, 2.8, 163.58], [1, 2.78, 2.61]], 'id': 12832765}, {'batb': [[2, 38, 4.36], [1, 42, 5.23], [0, 44, 25.58]], 'id': 12832769}, {'batb': [[1, 34, 4], [0, 36, 1]], 'id': 12832768}], 'con': True} &lt;betfairlightweight.resources.streamingresources.MarketDefinition object at 0x0000028F6EB1EB70&gt; 2019-02-23 19:36:02.838000



```



i.e. the updates come through exactly the same as if I wasn't using the snap

*Tags: Strategies*

---

**seaders** - *19:47:12*

```

market_ids = ['1.130856098']



market_filter = streaming_market_filter(

    market_ids=market_ids)



...



    while True:

        if output_queue.empty():

            time.sleep(0.5)

            continue



        market_books = output_queue.get()

        print(

            'mbs', market_books)

        print(

            'snap', listener.snap(market_ids)

        )```

*Tags: General Technical*

---

**Newbie99** - *19:48:38*

Ok that of course makes sense, I just assumed I wasn't understanding, I thought that's what Liam suggested above, but I think he didn't spot the error in my code.



Okay, yes, logically that makes sense, I was persisting was flawed logic.

*Tags: Errors Debugging*

---

**Newbie99** - *19:58:55*

All I wanted to do (and maybe I'm misunderstanding what Snap is for), is to get the full market state at every update.



So for example, for market x, I get the initial market on connection, e.g.



```

1 {'id': '1.130856098', 'marketDefinition': {'bspMarket': False, 'turnInPlayEnabled': False, 'persistenceEnabled': False, 'marketBaseRate': 5, 'eventId': '28180290', 'eventTypeId': '2378961', 'numberOfWinners': 1, 'bettingType': .....

```



Then every update an update e.g.



```

1 {'id': '1.130856098', 'rc': [{'batl': [[2, 2.8, 163.58], [1, 2.78, 2.61]], 'id': 12832765}, {'batb': [[2, 38, 4.36], [1, 42, 5.23], [0, 44, 25.58]], 'id': 12832769}, {'batb': [[1, 34, 4], [0, 36, 1]], 'id': 12832768}], 'con': True} 

```



That all works fine of course....however what I thought Snap would help is return an updated version of:



```

1 {'id': '1.130856098', 'marketDefinition': {'bspMarket': False, 'turnInPlayEnabled': False, 'persistenceEnabled': False, 'marketBaseRate': 5, 'eventId': '28180290', 'eventTypeId': '2378961', 'numberOfWinners': 1, 'bettingType': ...

```



On every update, but maybe I'm misunderstanding what the correct use of Snap is?

*Tags: Strategies*

---

**seaders** - *20:01:00*

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1550880399020300](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1550880399020300)

*Tags: General Technical*

---

**seaders** - *20:04:08*

the streaming update of each of those markets is the update that's come through

*Tags: General Technical*

---

**Newbie99** - *20:04:43*

my only confusion was how to get the output of the snap

*Tags: General Technical*

---

**Newbie99** - *20:05:01*

I'm comfortable with the logic and that I'm looking at the right thing, even if my question was poorly worded

*Tags: General Technical*

---

**seaders** - *20:07:48*

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1550880399020300](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1550880399020300)

*Tags: General Technical*

---

**Newbie99** - *20:16:32*

You'd think so...but I do have a habit of some dumb questions when fully sober too!

*Tags: General Technical*

---

## 2019-02-26

**ShahGar** - *13:33:58*

Why is the bet stakes/liquidities retrieved from the streaming api (output_queue.get or listener.snap) "much lower" from those retrieved from the ordinary betfair api (listMarketBook)?

*Tags: General Technical*

---

**seaders** - *13:36:36*

[https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1551186383019800](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1551186383019800)

??

*Tags: General Technical*

---

**ShahGar** - *13:43:51*

I have the following output for streaming

*Tags: General Technical*

---

**ShahGar** - *13:43:53*

market_books[1].streaming_update['rc']

Out[62]:

[{'batb': [[0, 1.87, 375.96],

   [1, 1.86, 6157.88],

   [2, 1.85, 1452.26],

   [3, 1.84, 1629.37],

   [4, 1.83, 33.37]],

  'batl': [[0, 1.88, 1260.18],

   [1, 1.89, 742.09],

   [2, 1.9, 1848.84],

   [3, 1.91, 179.7],

   [4, 1.92, 1753.25]],

  'id': 48461},

 {'batb': [[0, 5.2, 1285.12],

   [1, 5.1, 1012.53],

   [2, 5, 3381.38],

   [3, 4.9, 319.46],

   [4, 4.8, 110.05]],

  'batl': [[0, 5.3, 875.66],

   [1, 5.4, 1790.73],

   [2, 5.5, 708.54],

   [3, 5.6, 95.97],

   [4, 5.7, 379.18]],

  'id': 18567},

 {'batb': [[0, 3.6, 3332.53],

   [1, 3.55, 1756.16],

   [2, 3.5, 2042.72],

   [3, 3.45, 2854.77],

   [4, 3.4, 1307.7]],

  'batl': [[0, 3.65, 3415.63],

   [1, 3.7, 4003.54],

   [2, 3.75, 3113.94],

   [3, 3.8, 2565.14],

   [4, 3.85, 982.2]],

  'id': 58805}]

*Tags: General Technical*

---

**ShahGar** - *14:25:41*

but still streaming is Always much lower than ordinary

*Tags: General Technical*

---

**ShahGar** - *14:28:10*

so streaming will retrieve ordinary sizes/liquid when going to live key, or what do you mean?

*Tags: Deployment*

---

## 2019-03-03

**ShahGar** - *13:51:17*

Is it possible to get the total sizes available to bet on at a called time with the streaming function?

*Tags: General Technical*

---

**liam** - *14:07:14*

What does a called time mean? Streaming gives you the same data as a market book request 

*Tags: General Technical*

---

**liam** - *14:11:36*

[https://github.com/liampauling/betfair/blob/master/examples/examplestreaming.py#L55](https://github.com/liampauling/betfair/blob/master/examples/examplestreaming.py#L55)

*Tags: General Technical*

---

**Newbie99** - *21:25:06*

I have another frustratingly dumb question...all I'm trying to do, is append runner name into market_book, based on selectionId. Logically this shouldn't be difficult, but I keep getting various errors, regardless of which method I use.



All I'm doing is, using the code posted the other day (or very similar):



```

    for market_book in market_books:

       for runner in market_book.runners:



        market_catalogues = trading.betting.list_market_catalogue(

            market_projection=["RUNNER_DESCRIPTION", "RUNNER_METADATA", "COMPETITION", "EVENT", "EVENT_TYPE", "MARKET_DESCRIPTION", "MARKET_START_TIME"],

            filter=betfairlightweight.filters.market_filter(

                market_ids=[market_book.market_id],

            ),

            max_results=100)



        data = []

        for market_catalogue in market_catalogues:

            for runner in market_catalogue.runners:

                data.append(

                    (runner.selection_id, runner.runner_name)

                )

```



That all works fine, but I then want to add runner name into market_book, based on selection_id = selectionId and I can't seem to do it.



Is this just a stupid idea (i.e. am I missing the obvious and market_book(s) is actually immutable?), should I simply be creating a new list and appending that with what I need from market_book(s) and the above 2 column data list, or is it a sensible approach and I'm just don't know how to do it correctly?

*Tags: Errors Debugging, Strategies*

---

**liam** - *21:31:44*

You using streaming still?

*Tags: General Technical*

---

**Newbie99** - *21:35:29*

yes, this is just stuck on the end of the example streaming code from github. All works fine...other than I'm being a bit dense around whether I can append back into market_book(s) or whether I should just create a new list and go down that route (the end game being to output to a browser, but that's sort of irrelevant for now as my python logic is possibly wrong)

*Tags: General Technical*

---

**seaders** - *22:47:36*

```for market_book in market_books:

       for runner in market_book.runners:



        market_catalogues = trading.betting.list_market_catalogue(

            market_projection=["RUNNER_DESCRIPTION", "RUNNER_METADATA", "COMPETITION", "EVENT", "EVENT_TYPE", "MARKET_DESCRIPTION", "MARKET_START_TIME"],

            filter=betfairlightweight.filters.market_filter(

                market_ids=[market_book.market_id],

            ),

            max_results=100)```

Also don't do ^^^ - if you've 1000 market_books, that'll be 1000 calls to list_market_catalogue

*Tags: Strategies*

---

**seaders** - *22:48:33*

Do _something like_,

```

market_catalogues = trading.betting.list_market_catalogue(

            market_projection=["RUNNER_DESCRIPTION", "RUNNER_METADATA", "COMPETITION", "EVENT", "EVENT_TYPE", "MARKET_DESCRIPTION", "MARKET_START_TIME"],

            filter=betfairlightweight.filters.market_filter(

                market_ids=[mb.market_id for mb in market_books],

            ),

            max_results=100)

for market_book in market_books:

       for runner in market_book.runners:

        ```

*Tags: Strategies*

---

**Newbie99** - *23:17:53*

well I'm not adding runner names to market_book :slightly_smiling_face: That was my (perceived) problem!



I have the 'market_book' i.e. the state of the market for any given market_id, which is all good. However, visually I can't see what that relates too, hence I want the runner name, so I can see what the id relates to.



But I think, if I'm understanding correctly, essentially I need to create a new dict, rather than trying to mess around with manipulating the existing market_book from market_books?



Maybe I'm explaining  it badly, but in php for example, this is a really simple thing to do, so perhaps its not clear what I'm attempting here?

*Tags: General Technical*

---

## 2019-03-04

**ShahGar** - *09:24:00*

I'm getting MAXCONNECTION LIMIT ERROR after a while of iterating over and streaming data from different markets, which hinders me from making new streaming connections. I guess I have to close the streaming connections at the end of each iteration. But how can I do that? (I've tried stream.stop())

*Tags: Errors Debugging*

---

**liam** - *10:27:59*

How many are you creating? I have never hit that limit, streaming is designed so that its rare for you to have more than 1 or 2

*Tags: General Technical*

---

**liam** - *11:07:25*

defeats the point of streaming, you need to go up a level on your market filter

*Tags: General Technical*

---

**ShahGar** - *11:08:30*

my filter is market_data_filter = streaming_market_data_filter(fields=['EX_BEST_OFFERS','EX_MARKET_DEF'],ladder_levels=5,)

*Tags: General Technical*

---

**ShahGar** - *11:10:07*

market_filter = streaming_market_filter(market_ids=MARKETIDS)

streaming_unique_id = stream.subscribe_to_markets(market_filter=market_filter,market_data_filter=market_data_filter,conflate_ms=1000)

*Tags: General Technical*

---

**ShahGar** - *11:22:25*

and then to get streaming data of specific market id I can after it use listener.snap(market_ids=MARKETIDS)

*Tags: General Technical*

---

**liam** - *11:23:28*

yeah just ignore anything you dont want, streaming is very light on CPU/memory so having a few markets you don't want isn't a problem

*Tags: Performance*

---

**ShahGar** - *11:56:11*

unfortunately, when i run market_filter = streaming_market_filter(event_type_ids=['1'])

I get an empty list from listener.snap(market_ids=MARKETIDS)

*Tags: General Technical*

---

**ShahGar** - *11:56:50*

However if I use streaming_market_filter(market_ids=MARKETIDS), it works

*Tags: General Technical*

---

**liam** - *13:08:03*

the default limit is 200 unless you ask bdp to bump it (you need a good reason) but for those that got access to streaming when it was first released there was no limit

*Tags: General Technical*

---

**seaders** - *14:09:15*

I'd consider that question like that statement about porn, if you can imagine it, someone's produced a porn about it

*Tags: General Technical*

---

**seaders** - *14:14:41*

ah, I've sympathies, it ain't an easy problem to solve!

*Tags: General Technical*

---

## 2019-03-05

**seaders** - *11:45:47*

[@U4H19D1D2](@U4H19D1D2) [https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/cache.py#L346](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/cache.py#L346)



I was sure it worked differently previously, but for here, how come we only get the data for unmatched_orders, and not the matched_backs and matched_lays?

*Tags: General Technical*

---

**liam** - *11:58:09*

Always been the case, draw back of streaming 

*Tags: General Technical*

---

**seaders** - *11:58:38*

but they come through in the streaming update, though?

*Tags: General Technical*

---

**seaders** - *12:24:04*

[@U92CASP1B](@U92CASP1B) [https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1551481901005000](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1551481901005000)

*Tags: General Technical*

---

**seaders** - *12:27:33*

not when it's resolved (and the money's won or lost)

*Tags: General Technical*

---

## 2019-03-23

**liam** - *09:00:48*

Wait until they fix it, last I heard it was April

*Tags: Errors Debugging*

---

## 2019-03-24

**Paw** - *23:20:22*

when i use examplestreaming.py with market_filter = streaming_market_filter(

    market_ids=['156436827']

)

*Tags: General Technical*

---

**Paw** - *23:20:37*

and market_data_filter = streaming_market_data_filter()

*Tags: General Technical*

---

**Paw** - *23:20:56*

I'm getting ERROR:betfairlightweight.streaming.listener:[Subscription: 2] NOT_AUTHORIZED: AppKey is not configured for service

*Tags: Errors Debugging*

---

**Tom** - *23:27:35*

[@UH9K87HAA](@UH9K87HAA) Yes you need to contact betfair support to activate streaming. You could chance asking CS in the online chat if they can flick the switch and grant you access to streaming. If they can't they'll make a ticket to the dev team to activate it.  [https://responsiblegambling.betfair.com/live-chat/](https://responsiblegambling.betfair.com/live-chat/)

*Tags: Deployment*

---

## 2019-03-25

**Paw** - *19:18:59*

Following up on the data question -&gt; do we have a secondary historical data market on here :wink: I'm looking for a month of premiership initially to start building my ingestion framework and ML models..

*Tags: Data Quality, Strategies*

---

## 2019-03-26

**Unknown** - *05:02:57*

I mean I am looking for the betfair historical data which currently can’t be downloaded from betfair.



I just would like to see some data to play with and write some code while waiting to download the “real” ones.



So maybe someone had some files to share?

*Tags: Data Quality*

---

## 2019-04-02

**Paw** - *21:08:35*

Heya, I'm trying to use the streaming example on a football game (Match Odds) where I want to get data in the same format I'd as when getting  historical data from Betfair (streaming dump)

*Tags: Data Quality*

---

**Paw** - *21:12:36*

got it fixed (it needed a 1.market_id :)

*Tags: Errors Debugging*

---

**Paw** - *21:13:16*

However the streaming seems not to be continuing (only getting one msg just after subscribing)

*Tags: General Technical*

---

**Paw** - *21:20:00*

or to actually formulate my question -&gt; How would I go about modifying the snipped I've send to get continuous update to this market_id with every price change on the ladder? I feel like I can't be that far off..

*Tags: General Technical*

---

**liam** - *21:23:51*

Change logging to DEBUG to see more

*Tags: Errors Debugging*

---

**Paw** - *21:56:06*

I will give it a go and update you afterwards - thanks for all the help!

*Tags: General Technical*

---

## 2019-04-09

**Dado** - *12:50:06*

hi all!



I'm having problems to get player name from selectorid into a TO_SCORE event...

using this:

*Tags: General Technical*

---

**Dado** - *12:50:24*

market_catalogue_filter = betfairlightweight.filters.market_filter(

        event_ids=[14843951],

        market_type_codes=["MATCH_ODDS","CORRECT_SCORE"]

    )

    market_catalogues = trading.betting.list_market_catalogue(

        filter=market_catalogue_filter,

        max_results=1000,

        market_projection=["RUNNER_DESCRIPTION","MARKET_START_TIME", "COMPETITION"]

    )

    print(len(market_catalogues))

*Tags: Strategies*

---

## 2019-04-11

**T** - *00:54:27*

Just hit an error I've never seen before when trying to place a bet

*Tags: Errors Debugging*

---

**T** - *00:56:52*

...OverflowError: Maximum recursion level reached

*Tags: Errors Debugging*

---

**T** - *00:58:56*

Any help would be great

*Tags: General Technical*

---

**T** - *10:35:47*

Hi Liam - um, not sure what you mean (assume Visual Studio code?). I'm running it from a Jupyter Notebook in Python.

*Tags: General Technical*

---

**OT** - *10:54:54*

hi all, has anyone else hit this exception: [https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/cache.py#L144](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/cache.py#L144) even though EX_MARKET_DEF has been set in the filter? I usually get it when I'm re-subscribing (ie from an internet outage), I think. but it's pretty intermittent. It could be some kind of race in my code, too.

*Tags: Errors Debugging*

---

**OT** - *13:29:03*

[@U4H19D1D2](@U4H19D1D2) thanks, I'm debugging it now. I'm suspecting some kind of race between bfl thinking there is a fresh subscription and a delta that's lagging from before the re-subscription. but I haven't found the evidence for it yet.

*Tags: Errors Debugging*

---

**OT** - *15:51:25*

[@U4H19D1D2](@U4H19D1D2) are you saying that if you setup a streaming_market_filter using some parameters other than market_id, it will automatically subscribe to new markets?

*Tags: Getting Started*

---

**Dado** - *15:52:55*

thoroughbreds_event_filter = betfairlightweight.filters.market_filter(

		event_type_ids=[sport_id],

		in_play_only='false',

		market_start_time={

			'to': (datetime.datetime.utcnow() + datetime.timedelta(days=2)).strftime("%Y-%m-%dT%TZ")

		}

	)



	aus_thoroughbred_events = trading.betting.list_events(

		filter=thoroughbreds_event_filter

	)

*Tags: Strategies*

---

**OT** - *15:54:10*

[@UHHQACU9X](@UHHQACU9X) you can just use a typical Python sort method?

*Tags: General Technical*

---

**OT** - *15:59:35*

[@U7QLCB7HA](@U7QLCB7HA) I see.. that's a shame for me - I'm using marketId because I pull the ids from a database after I've added my own metadata

*Tags: General Technical*

---

**Dado** - *16:03:40*

no problem :smile:

*Tags: General Technical*

---

## 2019-04-12

**liam** - *07:34:15*

[@U7QLCB7HA](@U7QLCB7HA) if you are constantly resubscribing then you are missing out on the beauty of streaming 

*Tags: General Technical*

---

## 2019-04-13

**Jack** - *19:47:13*

is streaming api ffree?

*Tags: General Technical*

---

## 2019-04-14

**phil** - *13:03:18*

and got this error

*Tags: Errors Debugging*

---

## 2019-04-23

**OT** - *09:06:52*

[@U4H19D1D2](@U4H19D1D2) I've been doing a bit more research on my setup. I think some of my reasoning behind writing this code (written &gt;1 year ago!) was to not subscribe to any markets that i don't want to see. otherwise at some point I will have to check each incoming market_book and reject the ones I don't want to. for example, there's no way, as far as I can tell, a way to subscribe to horse racing, but only handicap races.. you have to subscribe to all horse racing and then just skip and non-handicap races. my way around this was to just collect market_id for all handicap races and put that into the streaming_market_filter, but you need to re-do it periodically to pick up new races/markets. does that make sense? and how does that fit with your way of managing this kind of problem?

*Tags: Getting Started*

---

**liam** - *09:11:15*

Streaming is lightweight so there is no issue in just ignoring markets. You could do this when you pull off the queue or creat your own listener which filters the markets and only puts what you want into the queue 

*Tags: General Technical*

---

## 2019-05-16

**Newbie99** - *21:34:05*

I'm getting a weird error, out of the blue (on another machine the script runs fine), any ideas what could have got messed up (betfairlightweight appears to be installed correctly, re-installed just now, but no joy):



```

Traceback (most recent call last):

  File "D:/Python37/webpages/betfair_python.py", line 61, in &lt;module&gt;

    market_stream.start(_async=True)

TypeError: start() got an unexpected keyword argument '_async'



```



Any pointers as to what might be causing this?



For reference, if I were to remove the _async=True then instead of an error it just hangs at:



```

INFO:betfairlightweight.streaming.stream:[Stream: 1]: "OrderStream" created

INFO:betfairlightweight.streaming.stream:[Stream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[Connect: 1]: connection_id: 006-160519203236-239625

INFO:betfairlightweight.streaming.listener:[Subscription: 2]: SUCCESS

INFO:betfairlightweight.streaming.listener:[Subscription: 1]: SUCCESS

INFO:betfairlightweight.streaming.stream:[MarketStream: 1] 1.130856098 added, 1 markets in cache

INFO:betfairlightweight.streaming.stream:[Stream: 1]: 1 mc added

```

*Tags: Getting Started, Errors Debugging*

---

## 2019-05-22

**T** - *02:01:45*

Hi guys. I am pretty new to betfairlightweight so please bear with!



I am trying to place an order onto the exchange using the following code:



```limit_order = filters.limit_order(

            size=stake,

            price=price,

            persistence_type='LAPSE')



    instruction = filters.place_instruction(

        order_type='LIMIT',

        selection_id=selection_id,

        side='BACK',

        limit_order=limit_order)



    place_orders = trading.betting.place_orders(

        market_id=market_id,

        instructions=[instruction])```

*Tags: Getting Started, Strategies*

---

**T** - *02:02:55*

I am confronted with this error message:

*Tags: Errors Debugging*

---

**T** - *02:03:24*

``` OverflowError                             Traceback (most recent call last)

&lt;ipython-input-56-134ce2a3b2dc&gt; in &lt;module&gt;()

     26     place_orders = trading.betting.place_orders(

     27         market_id=market_id,

---&gt; 28         instructions=[instruction])

     29 

     30     break



C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\betting.py in place_orders(self, market_id, instructions, customer_ref, market_version, customer_strategy_ref, async_, session, lightweight)

    331         params = clean_locals(locals())

    332         method = '%s%s' % (self.URI, 'placeOrders')

--&gt; 333         (response, elapsed_time) = self.request(method, params, session)

    334         return self.process_response(response, resources.PlaceOrders, elapsed_time, lightweight)

    335 



C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in request(self, method, params, session)

     34         """

     35         session = session or self.client.session

---&gt; 36         request = self.create_req(method, params)

     37         date_time_sent = datetime.datetime.utcnow()

     38         try:



C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in create_req(method, params)

     71                 'method': method,

     72                 'params': params,

---&gt; 73                 'id': 1

     74             }

     75         )



OverflowError: Maximum recursion level reached````

*Tags: Errors Debugging, Strategies*

---

**T** - *02:05:41*

I have read the following threads on Github: [https://github.com/liampauling/betfair/issues/175](https://github.com/liampauling/betfair/issues/175) and [https://github.com/microsoft/vscode-python/issues/581](https://github.com/microsoft/vscode-python/issues/581) but because I am quite inexperienced in Python I still don't know what on earth to do to solve the problem

*Tags: General Technical*

---

**T** - *02:08:10*

I am using betfairlightweight 1.9.1 which I installed via pip. I am running the code in a Jupyter Notebook.

*Tags: Getting Started*

---

**T** - *02:08:49*

The articles talk about vscode which I've literally never heard of/needed before to execute code in Python

*Tags: General Technical*

---

**T** - *02:09:29*

If someone could very clearly explain, step by step, what I need to do to solve this problem, that would be great

*Tags: General Technical*

---

**liam** - *06:55:50*

Quick fix, use pycharm or wait for a new release 

*Tags: Errors Debugging*

---

**liam** - *09:08:58*

when a PR arrives :wink: this doesn't impact me so in no rush to fix but can merge a PR whenever

*Tags: Errors Debugging*

---

**T** - *09:46:02*

post on here if you get round to fixing this problem when you next release a new version

*Tags: Errors Debugging*

---

**T** - *10:07:45*

thanks for your help

*Tags: General Technical*

---

## 2019-05-24

**Newbie99** - *17:45:11*

I keep randomly getting the following error (but not every time, seems to happen 3/5 times for a period then not again for ages, very odd):



```

betfairlightweight.exceptions.InvalidResponse: Invalid response received:

```



Sort of tricky to decipher exactly where its comeing from, possibly from:



```

        market_catalogues = trading.betting.list_market_catalogue(

        market_projection=["RUNNER_DESCRIPTION", "RUNNER_METADATA", "COMPETITION", "EVENT", "EVENT_TYPE",

                           "MARKET_DESCRIPTION", "MARKET_START_TIME"],

        filter=betfairlightweight.filters.market_filter(

        with_orders=["EXECUTION_COMPLETE", "EXECUTABLE"]),

        max_results=800)

```



Also, I think this has only occurred since the last update. Could it be related to the issue in the conversation above by chance, or is that a totally separate issue?

*Tags: Errors Debugging, Strategies*

---

## 2019-05-31

**richard_h** - *02:16:25*

I'm running betfairlightweight to stream data and its memory footprint is slowly increasing over time, is there a way to clear memory? I read something in the history about using snap, is that necessary to not have memory issues? I don't need to save price history but I can't really see where it's being saved.

*Tags: Performance*

---

**liam** - *07:09:22*

my issue was that in framework I had a Market class which was storing a history of all prices/analytics, so come the end of a race this had a rather large memory footprint. I was deleting on closure along with what I thought was all references but after a lot of debugging I found i had a reference to it in my logging framework. you can try deleting all closed markets in the cache (listener.stream._cache)

*Tags: Errors Debugging, Performance*

---

**liam** - *07:11:46*

you can see that flumine will delete that cache object [https://github.com/liampauling/flumine/blob/master/flumine/listener.py#L39](https://github.com/liampauling/flumine/blob/master/flumine/listener.py#L39)

*Tags: General Technical*

---

## 2019-06-07

**Rob** - *18:07:47*

I'm using the streaming api to get market books and have run in to an issue (or question) about traded volume - I'm seeing data like



```

{  

                  "size":46.78,

                  "price":23.36

               },

               {  

                  "size":129.22,

                  "price":24

               },

               {  

                  "size":120.25,

                  "price":24.92

               },

```



Whereas I made the assumption I'd get prices at the ladder levels (so `23`, `24`, `25`, etc) but it looks like I've got some kind of average prices.



For the restful API call I can see a choice of `ROLLED_UP_BY_AVG_PRICE` or `ROLLED_UP_BY_PRICE` but can't easily see if/how this is recreated in the streaming API.

*Tags: General Technical*

---

**Rob** - *18:50:57*

thanks for the help!

*Tags: General Technical*

---

## 2019-06-10

**Newbie99** - *21:48:22*

Is there a quick way to filter markets based on criteria xyz plus specific markets that don't meet those criteria?



For example, what I was hoping to do is:



```

market_filter = streaming_market_filter(

    event_type_ids=['7'],

    country_codes=['US'],

    market_types=['WIN'],

    market_ids=['1.130856098'])

```



That doesn't return anything as I presume the logic is that nothing meets all 4 criteria, so I can see why (I think). So would the correct way to go about this be to call listEventTypes, generate a list of Market_ids that meet those criteria, then add in the ad-hoc ones and return that list of Market_id's into the filter?

*Tags: General Technical*

---

## 2019-06-11

**liam** - *10:34:33*

[@UFTBRB3F1](@UFTBRB3F1) the idea with streaming is to not filter, just ignore the markets you don’t need

*Tags: General Technical*

---

## 2019-06-13

**stefan** - *13:33:10*

Hi all, quick question regarding authentication. I am having trouble to establish a connection using `APIClient`. I am using the sample code `examplestreaming.py` from the repo with my details:



`trading = betfairlightweight.APIClient('xxx', 'xxx', app_key='xxx', cert_files=('./certs/client-2048.crt', './certs/client-2048.key'))`



When connecting I am getting the following error:```INFO:betfairlightweight.streaming.stream:[Stream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[Connect: 1]: connection_id: xxx

ERROR:betfairlightweight.streaming.listener:[Subscription: 2] UNEXPECTED_ERROR: Unknown error authenticating

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 917, in _bootstrap_inner

    self.run()

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 865, in run

    self._target(*self._args, **self._kwargs)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 198, in _read_loop

    self._data(received_data)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 239, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: xxx, data: {"op":"status","id":2,"statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"Unknown error authenticating","connectionClosed":true,"connectionId":"xxx"}

```



I was able to establish a connection using the sample code from betfair: `[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login#Non-Interactive(bot)login-SamplePythoncode](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login#Non-Interactive(bot)login-SamplePythoncode)`

Also the curl command with the same certificates and credentials is working fine to establish a connection.



Any suggestions/help would be very welcome. Thanks.

*Tags: Errors Debugging, Strategies*

---

**liam** - *13:36:08*

/ set logging to DEBUG and share logs

*Tags: Errors Debugging*

---

**stefan** - *13:38:55*

Logs:```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

INFO:betfairlightweight.streaming.stream:[Stream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[Connect: 1]: connection_id: xxx

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 212, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "C:\ProgramData\Anaconda3\lib\ssl.py", line 1037, in recv

    return self.read(buflen)

  File "C:\ProgramData\Anaconda3\lib\ssl.py", line 913, in read

    return self._sslobj.read(len)

ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 917, in _bootstrap_inner

    self.run()

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 865, in run

    self._target(*self._args, **self._kwargs)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 191, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 216, in _receive_all

    raise SocketError('[Connect: %s]: Socket %s' % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 2]: Socket [WinError 10054] An existing connection was forcibly closed by the remote host```

*Tags: Errors Debugging*

---

**liam** - *13:39:36*

different error?

*Tags: Errors Debugging*

---

**stefan** - *13:40:44*

```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

INFO:betfairlightweight.streaming.stream:[Stream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[Connect: 1]: connection_id: xxx

ERROR:betfairlightweight.streaming.listener:[Subscription: 2] UNEXPECTED_ERROR: Unknown error authenticating

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 917, in _bootstrap_inner

    self.run()

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 865, in run

    self._target(*self._args, **self._kwargs)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 198, in _read_loop

    self._data(received_data)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 239, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: xxx, data: {"op":"status","id":2,"statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"Unknown error authenticating","connectionClosed":true,"connectionId":"xxx"}```

*Tags: Errors Debugging*

---

**stefan** - *13:40:50*

That's the one with DEBUG log.

*Tags: Errors Debugging*

---

**stefan** - *16:27:45*

Just a quick follow-up while I am waiting for Betfair to get back. The streaming login -as above - should work with the delayed/dev appKey if enabled for streaming API access, correct? Thanks.

*Tags: General Technical*

---

## 2019-06-15

**stefan** - *11:14:53*

Took Betfair a couple of shots, in the end they reset permissions on the app key and added streaming access again. It works now. Thanks for your help.

*Tags: General Technical*

---

## 2019-06-21

**Newbie99** - *10:51:41*

morning, I keep getting the following today, am I right in thinking this is just an issue at Betfair and there's not really much I can do, other than wait it out?



```

WARNING:betfairlightweight.streaming.stream:[Stream: 1]: Latency high: 1.112811803817749

WARNING:betfairlightweight.streaming.stream:[Stream: 1]: Latency high: 1.1146831512451172

WARNING:betfairlightweight.streaming.stream:[Stream: 1]: Latency high: 1.1135742664337158

```

*Tags: Performance*

---

**liam** - *10:53:03*

you can remove it by setting a higher value on the listener (max_latency)

*Tags: Performance*

---

## 2019-06-25

**Newbie99** - *13:10:31*

When streaming, is 'matches' never populated?



```

market_books = market_queue.get()

        for x in market_books:

            for y in x.runners:

                print(len(y.matches))

```



The above returns 0 as the len for all runners in all markets.



If I call listMarketBook it works fine, but I obviously don't want to have to do that every time.



Assuming the behaviour above is correct, what is an alternative way to calculate positions, to call listMarketBook once at the start, take the starting position and then adjust that on every order change?

*Tags: General Technical*

---

**liam** - *19:17:31*

No order data in streaming 

*Tags: General Technical*

---

**Newbie99** - *19:33:23*

Ok, that makes sense, but then is the new position shown in the order stream (if you enable this flag)?



```

order_filter = streaming_order_filter(

   include_overall_position=True)

```



If so where should I be looking for it, as I can't seem to work it out!

*Tags: General Technical*

---

## 2019-07-12

**Newbie99** - *08:23:53*

overnight (about 4:18 this morning), I got the following error, is this likely to be a problem with my code, or something remote (I ask as I've not seen this error before, so it seems odd that it could suddenly appear without me changing anything)?

*Tags: Errors Debugging*

---

## 2019-07-19

**Newbie99** - *21:01:47*

I keep getting:



```

Traceback (most recent call last):

  File "D:/Python37/webpages/betfair_python.py", line 178, in &lt;module&gt;

    if y.market_id == market_books[i].market_id:

IndexError: list index out of range

```



line 178 relates to ``` if y.market_id == market_books[i].market_id:``` in the code below



Which is confusing me, as in my code, I thought that this line ```for i in range(len(market_books)):``` should have caught that. So apologies once again, for no doubt a very simplistic error, but can anyone spot where I've gone wrong here?



```

while True:

    combined_books = market_queue.get()

    old_order_market_id_list = []

    new_order_market_id_list = []



    for y in combined_books:

        temp_order_books = []

        temp_market_books = []

        if isinstance(y, MarketBook):

            for market_book in market_books:

                if y.market_id not in market_book.market_id:

                    temp_market_books.append(y)

                else:

                    for i in range(len(market_books)):

                        if y.market_id == market_books[i].market_id:

                            temp_market_books.append(y)

                            del market_books[i]



```

*Tags: Errors Debugging*

---

**Newbie99** - *21:27:26*

Ah yes, sorry, so after the first iteration the len will have shrunk! Okay, dumb error! Thanks!

*Tags: Errors Debugging*

---

## 2019-08-09

**Rob (NZ)** - *10:31:01*

i think im getting a similar error to [@UFTBRB3F1](@UFTBRB3F1) got...

*Tags: Errors Debugging*

---

**Rob (NZ)** - *10:31:05*

---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

C:\anaconda\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in process_response(self, response_json, resource, elapsed_time, lightweight)

    106             try:

--&gt; 107                 return [resource(elapsed_time=elapsed_time, **x) for x in result]

    108             except TypeError:



C:\anaconda\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in &lt;listcomp&gt;(.0)

    106             try:

--&gt; 107                 return [resource(elapsed_time=elapsed_time, **x) for x in result]

    108             except TypeError:



C:\anaconda\lib\site-packages\betfairlightweight\resources\bettingresources.py in __init__(self, **kwargs)

    256         self.description = MarketCatalogueDescription(**kwargs.get('description')) if \

--&gt; 257             kwargs.get('description') else None

    258         self.runners = [RunnerCatalogue(**i) for i in kwargs.get('runners', [])]



TypeError: __init__() missing 7 required positional arguments: 'discountAllowed', 'marketBaseRate', 'persistenceEnabled', 'regulator', 'rules', 'rulesHasDate', and 'wallet'



During handling of the above exception, another exception occurred:



InvalidResponse                           Traceback (most recent call last)

&lt;ipython-input-29-d9f9200f7a2b&gt; in &lt;module&gt;

      9     max_results='100',

     10     market_projection = ['MARKET_DESCRIPTION','RUNNER_METADATA','MARKET_START_TIME'],

---&gt; 11     sort='FIRST_TO_START'

     12 )

     13



C:\anaconda\lib\site-packages\betfairlightweight\endpoints\betting.py in list_market_catalogue(self, filter, market_projection, sort, max_results, locale, session, lightweight)

    156         method = '%s%s' % (self.URI, 'listMarketCatalogue')

    157         (response, elapsed_time) = self.request(method, params, session)

--&gt; 158         return self.process_response(response, resources.MarketCatalogue, elapsed_time, lightweight)

    159

    160     def list_market_book(self, market_ids, price_projection=None, order_projection=None,



C:\anaconda\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in process_response(self, response_json, resource, elapsed_time, lightweight)

    107                 return [resource(elapsed_time=elapsed_time, **x) for x in result]

    108             except TypeError:

--&gt; 109                 raise InvalidResponse(response=result)

    110         else:

    111             try:



InvalidResponse: Invalid response received: [{'marketId': '1.161129845', 'marketName': 'R3 2200m Trot S', 'marketStartTime': '2019-08-09T09:00:00.000Z', 'description': {'persistenceEnabled': True, 'bspMarket': True, 'marketTime': '2019-08-09T09:00:00.000Z', 'suspendTime': '2019-08-09T09:00:00.000Z', 'bettingType': 'ODDS', 'turnInPlayEnabled': True, 'marketType': 'WIN', 'regulator': 'MALTA LOTTERIES AND GAMBLING AU

*Tags: Errors Debugging, Strategies*

---

**Rob (NZ)** - *10:34:00*

is it on the betfair api side of things?

*Tags: General Technical*

---

**Rob (NZ)** - *10:34:18*

cause normally it works fine so didnt think it was the betfairlightweight part

*Tags: General Technical*

---

## 2019-08-10

**Rob (NZ)** - *00:00:44*

is that something betfair would look at correcting or is it something we could code around (something like ignore the error and just take the MGA data)

*Tags: Errors Debugging*

---

**liam** - *23:08:43*

I have mentioned to Neil that what happens at the moment is unexpected but I will add a fix in the latest release so that it won’t throw an error 

*Tags: Errors Debugging*

---

## 2019-08-27

**William** - *09:09:38*

Is there an equiavlent to streaming update for lightweight mode?

*Tags: General Technical*

---

**liam** - *12:38:53*

[https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/listener.py#L75](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/listener.py#L75)

*Tags: General Technical*

---

**LK** - *14:35:09*

and another question. is does betfair care how many marketstreams I request? I know the market limit per stream is 200, but do they care if I subscribe to 2000 markets using 10 streams for example?

*Tags: General Technical*

---

**William** - *23:21:34*

Sorry not sure if I asked correctly, is there the equivalent of 'market_book.streaming_update' in lightweight mode? To check if a runner has been changed in an update?

*Tags: General Technical*

---

## 2019-08-28

**liam** - *09:09:22*

pip install betfairlightweight==1.10.2b

*Tags: Getting Started*

---

**liam** - *16:23:47*

2019-08-28 16:23:26,414 | ERROR | [Subscription: 1001] MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s).

*Tags: Errors Debugging*

---

**liam** - *16:25:24*

2019-08-28 16:25:01,820 | ERROR | [Subscription: 1001] MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s).

*Tags: Errors Debugging*

---

**liam** - *16:39:25*

you may need a reason / hopefully you are putting money through some markets or they will question it

*Tags: General Technical*

---

**MarcoS** - *21:25:22*

Hi everybody, is there someone else that have problem with get_market_book_from_stream_bf_api? This method seems to return an empty list. Thanks.

*Tags: General Technical*

---

## 2019-08-29

**LK** - *09:00:55*

I might be missing something but in order to receive order executions from betfair for resting orders, the only 3 options/possibilities are:

- get it streaming from the orderstream

- poll betfair to ask for executions?

- receive immediate feedback if the order sent is matched (crossing order)

*Tags: General Technical*

---

**liam** - *09:15:14*

for streaming they use kafka on top of the rest of their infra, its rare for streaming to fail and nothing else fail, normally one thing fails and the whole thing goes down

*Tags: General Technical*

---

**LK** - *09:16:24*

which is why I switched to using a separate orderstream per strategy, but that is running into connection limits now.

*Tags: Strategies*

---

**Rory** - *09:16:29*

&gt;for streaming they use kafka on top of the rest of their infra



Great choice and nice bit of info :thumbsup:

*Tags: General Technical*

---

**liam** - *09:17:57*

one order stream per account is fine, why per strategy? You can add customerRef and customerStrategyRef to separate orders easily enough

*Tags: Strategies*

---

**liam** - *09:18:42*

[https://ppb.technology/2018/01/12/exchange-market-data-streaming-with-kafka/](https://ppb.technology/2018/01/12/exchange-market-data-streaming-with-kafka/)

*Tags: General Technical*

---

**LK** - *14:23:46*

well this is helpful nevertheless. I was using the market data filter purely on market_ids and for some cases I can ease that restriction now. I was already requesting multiple streams. I guess I have to be thinking a bit harder on how to organize stuff.

*Tags: General Technical*

---

**liam** - *14:29:17*

streaming is cheap, so just disregard the markets you dont want

*Tags: General Technical*

---

**Newbie99** - *22:52:24*

'ERROR:betfairlightweight.streaming.listener:[Subscription: 2] MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s).'



I've just started to get this error now too. It seems a few people are, is this a new thing (in the docs it suggested the limit was 200 markets)?

*Tags: Errors Debugging*

---

## 2019-08-30

**Newbie99** - *11:56:05*

Ah found the problem, I recently started switching my code to use threading and I was opening tons of connections (or trying to) just for the order stream, rather than one connection. All fixed now!

*Tags: Errors Debugging*

---

**Rory** - *15:52:09*

interesting problem ....

*Tags: General Technical*

---

**Rory** - *15:54:39*

but that's not the problem

*Tags: General Technical*

---

**Rory** - *16:00:31*

e.g. just ran it and got this from my code ... ```AttributeError: No market_book found for match:[Wigan v Barnsley]```

*Tags: Errors Debugging*

---

**Rory** - *16:00:50*

```AttributeError: No market_book found for match:[Strasbourg v Monaco]```

*Tags: Errors Debugging*

---

**Rory** - *16:31:01*

```    def grouper(self, iterable, n, fillvalue=None):

        "Collect data into fixed-length chunks or blocks"

        # grouper('ABCDEFG', 3, 'x') --&gt; ABC DEF Gxx"

        args = [iter(iterable)] * n

        return zip_longest(*args, fillvalue=fillvalue)```

*Tags: Errors Debugging*

---

**Rory** - *16:38:24*

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1567178887056300](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1567178887056300)

*Tags: General Technical*

---

**Mo** - *17:21:12*

```

import argparse

import betfairlightweight

import time



market_ids = ['1.161554359', '1.161515961', '1.161776871', '1.161557163', '1.161658694', '1.161554616', '1.161524492', '1.161659060', '1.161516211', '1.161516095', '1.161516559', '1.161516443', '1.161516327', '1.161658810', '1.161524800', '1.161658944', '1.161524184', '1.161657639', '1.161524338', '1.161657890', '1.161525108', '1.161658158', '1.161658024', '1.161658426', '1.161658292', '1.161523876', '1.161658560', '1.161657756', '1.161524030', '1.161554766', '1.161557279', '1.161776286', '1.161524954', '1.161516675', '1.161555048', '1.161554916', '1.161557529', '1.161557663', '1.161557395', '1.161557779', '1.161776201', '1.161555180', '1.161558243', '1.161558002', '1.161524646', '1.161516793', '1.161558484', '1.161555312', '1.161523722', '1.161516909', '1.161776413', '1.161555693', '1.161555444', '1.161776987', '1.161776668', '1.161777339', '1.161777222', '1.161776540', '1.161777104', '1.161555981', '1.161558707']





if __name__ == '__main__':

    parser = argparse.ArgumentParser()

    parser.add_argument('--username')

    parser.add_argument('--password')

    parser.add_argument('--app_key')

    parser.add_argument('--certs')

    args = parser.parse_args()

    api = betfairlightweight.APIClient(

        username=args.username,

        password=args.password,

        app_key=args.app_key,

        certs=args.certs,

        lightweight=True

    )



    api.login()



    for iteration in range(10):

        market_books = api.betting.list_market_book(

            market_ids=market_ids[:40],

            price_projection=betfairlightweight.filters.price_projection(

                price_data=betfairlightweight.filters.price_data(

                    ex_best_offers=True

                )

            )

        ) + api.betting.list_market_book(

            market_ids=market_ids[40:],

            price_projection=betfairlightweight.filters.price_projection(

                price_data=betfairlightweight.filters.price_data(

                    ex_best_offers=True

                )

            )

        )

        received_market_ids = [m['marketId'] for m in market_books]

        print('Requested {} market_ids'.format(len(market_ids)))

        print('Received {} market_ids'.format(len(received_market_ids)))

        print('set(market_ids) - set(received_market_ids) = {}'.format(set(market_ids) - set(received_market_ids)))

        time.sleep(1)



    api.logout()

```

*Tags: Strategies*

---

## 2019-09-06

**liam** - *10:51:35*

odd to use an executor when you will have 3 fixed threads

*Tags: Errors Debugging*

---

**Newbie99** - *11:02:42*

it is most likely my misunderstanding of how it works! Here is the rest:



```

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



trading = betfairlightweight.APIClient(accname, accpass, acckey, certs=path)

trading.login()



order_queue = queue.Queue()

order_listener = betfairlightweight.StreamListener(output_queue=order_queue)

order_stream = trading.streaming.create_stream(listener=order_listener)

order_filter = streaming_order_filter(

    include_overall_position=True

)

order_stream.subscribe_to_orders(

    order_filter=order_filter)

order_stream.start(async_=True)



market_queue = queue.Queue()

market_listener = betfairlightweight.StreamListener(output_queue=market_queue)

market_stream = trading.streaming.create_stream(listener=market_listener)

market_filter = streaming_market_filter(

market_ids=['1.130856098','1.132099836'])



market_data_filter = streaming_market_data_filter(

    fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF', 'EX_TRADED', 'EX_LTP'],

    ladder_levels=3)



market_stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter)



market_stream.start(async_=True)

```

*Tags: Strategies*

---

**liam** - *11:29:48*

depends on what this is for? I have a single 'main' event queue which handles all events, so the application would take a marketBook from a streaming queue do some validation and place it in an Event class and place in the main event queue to be handled

*Tags: General Technical*

---

**liam** - *11:38:13*

not for streaming as these are fixed known threads

*Tags: Errors Debugging*

---

## 2019-09-07

**Unknown** - *13:37:06*

Anyone else ever had an error like this? Looks like the data is being truncated somewhere when being sent over the socket, seems to happen randomly, note that this is a large string as there should be a lot of marketId's in that request as opposed to the two you can see

*Tags: Errors Debugging*

---

## 2019-09-10

**Rob (NZ)** - *09:53:05*

Anyone having any issues with the TypeError: __init__() got an unexpected keyword argument 'avgPriceRaw'



During handling of the above exception, another exception occurred:

*Tags: Errors Debugging*

---

**Rob (NZ)** - *09:56:22*

days_ago = (datetime.datetime.utcnow() - datetime.timedelta(days=1)).strftime("%Y-%m-%dT%TZ")

acct_statement_date_filter = betfairlightweight.filters.time_range(from_=days_ago)



more_available = True

from_record = 0

data = []

while more_available:

    account_statement_result = trading.account.get_account_statement(item_date_range=acct_statement_date_filter, from_record=from_record)

    more_available = account_statement_result.more_available

    from_record += len(account_statement_result.account_statement)

    data.extend(account_statement_result._data['accountStatement'])



recent_transactions = pd.DataFrame(data)

recent_transactions



class_df = pd.DataFrame(json.loads(i['unknownStatementItem']) for i in recent_transactions.itemClassData)

class_df

*Tags: Feature Engineering, Strategies*

---

**Rob (NZ)** - *10:00:44*

oh sweet, its a variation on the example python code they had on the betfair site

*Tags: General Technical*

---

**Rob (NZ)** - *10:02:13*

[https://betfair-datascientists.github.io/api/apiPythontutorial/#get-account-statement](https://betfair-datascientists.github.io/api/apiPythontutorial/#get-account-statement)

*Tags: General Technical*

---

**Mo** - *11:50:07*

I use that endpoint, not through betfairlightweight though

*Tags: General Technical*

---

## 2019-09-11

**Rob (NZ)** - *01:42:02*

[@UBS7QANF3](@UBS7QANF3) do you have any example code of how you use it outside of Betfairlightweight ,   am i right in thinking there is a new variable available in the data so its erroring out as its not expecting it.   Is there anything I could do to help fix it up (i just wonder if others like me who use the example code that betfair provide around python might be in the same boat and im happy to try and help contribute just not how best to make that happen)

*Tags: Errors Debugging*

---

**Mo** - *06:28:31*

Sorry I was mistaken, I do use it with betfairlightweight

*Tags: General Technical*

---

## 2019-09-21

**Justin Fisher** - *12:38:54*

:wave: hello to the code maintainers. First off want to say :pray: for the python package, big fan.



Im having an issue pulling historical data at the moment. It seems like maybe `betfair` and their download historical data isnt working but want to be sure. I usually use the UI but its been returning `10kb` tar files that dont seem to open correctly. I am now trying to use the download approach found at `[https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py)` and added some of my own print statements:

*Tags: Data Quality*

---

**Justin Fisher** - *12:38:58*

```

trading.historic.get_my_data()



{'sport': 'Greyhound Racing', 'plan': 'Basic Plan', 'forDate': '2018-05-01T00:00:00', 'purchaseItemId': 32386}

{'sport': 'Greyhound Racing', 'plan': 'Basic Plan', 'forDate': '2018-06-01T00:00:00', 'purchaseItemId': 32386}

{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-05-01T00:00:00', 'purchaseItemId': 32379}

{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-06-01T00:00:00', 'purchaseItemId': 32379}

{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-11-01T00:00:00', 'purchaseItemId': 22726}

{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-12-01T00:00:00', 'purchaseItemId': 22726}



trading.historic.get_collection_options:

 {'marketTypesCollection': [{'name': '', 'count': 1233}, {'name': 'ANTEPOST_WIN', 'count': 46}, {'name': 'DAILY_WIN_DIST', 'count': 1}, {'name': 'EACH_WAY', 'count': 1113}, {'name': 'FORECAST', 'count': 211}, {'name': 'MATCH_BET', 'count': 1165}, {'name': 'OTHER_PLACE', 'count': 6012}, {'name': 'PLACE', 'count': 4157}, {'name': 'RACE_WIN_DIST', 'count': 188}, {'name': 'REV_FORECAST', 'count': 574}, {'name': 'WIN', 'count': 6909}, {'name': 'WITHOUT_FAV', 'count': 222}], 'countriesCollection': [{'name': 'AR', 'count': 17}, {'name': 'AU', 'count': 4671}, {'name': 'BR', 'count': 10}, {'name': 'CL', 'count': 120}, {'name': 'FR', 'count': 591}, {'name': 'GB', 'count': 6612}, {'name': 'IE', 'count': 1608}, {'name': 'IN', 'count': 128}, {'name': 'NZ', 'count': 744}, {'name': 'PE', 'count': 9}, {'name': 'SE', 'count': 185}, {'name': 'SG', 'count': 138}, {'name': 'US', 'count': 6444}, {'name': 'UY', 'count': 12}, {'name': 'ZA', 'count': 542}], 'fileTypeCollection': [{'name': 'E', 'count': 1233}, {'name': 'M', 'count': 20598}]}



trading.historic.get_data_size:

 {'totalSizeMB': 63, 'fileCount': 23680}



trading.historic.get_file_list:



Traceback (most recent call last):

  File "/Users/justinfisher/anaconda3/lib/python3.6/site-packages/betfairlightweight/endpoints/historic.py", line 166, in request

    response_data = response.json()

  File "/Users/justinfisher/anaconda3/lib/python3.6/site-packages/requests/models.py", line 897, in json

    return complexjson.loads(self.text, **kwargs)

  File "/Users/justinfisher/anaconda3/lib/python3.6/json/__init__.py", line 354, in loads

    return _default_decoder.decode(s)

  File "/Users/justinfisher/anaconda3/lib/python3.6/json/decoder.py", line 339, in decode

    obj, end = self.raw_decode(s, idx=_w(s, 0).end())

  File "/Users/justinfisher/anaconda3/lib/python3.6/json/decoder.py", line 357, in raw_decode

    raise JSONDecodeError("Expecting value", s, err.value) from None

json.decoder.JSONDecodeError: Expecting value: line 4 column 1 (char 6)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "download_data.py", line 48, in &lt;module&gt;

    market_types_collection=['WIN'],

  File "/Users/justinfisher/anaconda3/lib/python3.6/site-packages/betfairlightweight/endpoints/historic.py", line 116, in get_file_list

    (response, elapsed_time) = self.request(method, params, session)

  File "/Users/justinfisher/anaconda3/lib/python3.6/site-packages/betfairlightweight/endpoints/historic.py", line 168, in request

    raise InvalidResponse(response.text)

betfairlightweight.exceptions.InvalidResponse: Invalid response received:





&lt;!DOCTYPE html&gt;



&lt;html&gt;

&lt;head&gt;

    &lt;meta name="viewport" content="width=device-width" /&gt;

    &lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

    &lt;div&gt;

        Error

    &lt;/div&gt;

&lt;/body&gt;

&lt;/html&gt;

```

*Tags: Errors Debugging, Strategies*

---

**Justin Fisher** - *12:40:40*

maybe Im being silly :thinking_face: ... maybe the historical service is experiences issues... any help is appreciated

*Tags: General Technical*

---

## 2019-10-14

**Phil Hughes** - *10:51:55*

The historical data website seems to be up and running again now but I still can't seem to download files via the api. Anyone tried in the last few days?

*Tags: Data Quality*

---

**liam** - *10:53:51*

do you get an error?

*Tags: Errors Debugging*

---

**Unknown** - *11:08:01*

No error. It looks like the files download ok. They have the market id as the name and a .bz2 extension but they won't open in 7-zip. When I opened with notepad they all had the same contents (see attached).

*Tags: Errors Debugging*

---

**liam** - *20:33:11*

Apparently this is now fixed [https://forum.developer.betfair.com/forum/developer-program/historical-data/26927-fixed-historical-data-data-for-nov-18-to-date](https://forum.developer.betfair.com/forum/developer-program/historical-data/26927-fixed-historical-data-data-for-nov-18-to-date)

*Tags: Errors Debugging*

---

## 2019-10-28

**Rory** - *09:24:29*

getting an InvalidResponse error from _trading.account.get_account_statement_ and it's because legacyData has a _handicap_ field, as below

*Tags: Errors Debugging, Strategies*

---

**Rory** - *09:24:41*

```'legacyData': {'avgPrice': 2.91, 'betSize': 22.06, 'betType': 'B', 'betCategoryType': 'E', 'eventId': 163396437, 'eventTypeId': 1, 'fullMarketName': 'Fixtures 27 Oct / Osasuna v Valencia/ Asian Handicap', 'grossBetAmount': 0.0, 'marketName': 'Asian Handicap', 'marketType': 'A', 'placedDate': '2019-10-25T18:49:37.000Z', 'selectionId': 10543, 'selectionName': 'Osasuna -0.5', 'handicap': -0.5, 'startDate': '2019-10-27T20:00:09.000Z', 'transactionType': 'ACCOUNT_CREDIT', 'transactionId': 0, 'winLose': 'RESULT_WON', 'avgPriceRaw': 2.91}```

*Tags: Errors Debugging*

---

**Rory** - *09:25:47*

yeah, adding a _handicap_ field to LegacyData fixes it

*Tags: Errors Debugging*

---

**Unknown** - *14:56:07*

Has anyone seen this error before?

*Tags: Errors Debugging*

---

**JonJonJon** - *15:01:02*

I also get occasional Socket errors. And suspect that my python scripts are not terminating when the socket errors occur. What does the code aim to do when we get socket error

*Tags: Errors Debugging*

---

**Unknown** - *15:02:15*

I.e. i am wondering if these errors are leaving me with lots of python processes that are waiting for streams to send events.

*Tags: Errors Debugging*

---

**liam** - *15:03:40*

np, socket errors are due to either the network or betfair closing the connection so nothing that can be done, you just need to handle them (see general for an example I posted yesterday)

*Tags: Errors Debugging*

---

## 2019-11-28

**Evaldas** - *12:54:03*

Hi, today at about 10:12am all market and order streams just stopped for me. No errors, no timeouts, just nothing. Ive been running this same code for 1+ years, never seen anything like this. Was it just me? I have max_latency=0.5 and heartbeat_ms=3000 on subscribtions. so confused, I have no idea what happened :confused:

*Tags: Errors Debugging, Performance*

---

**Evaldas** - *13:01:51*

thats the part that freaks me out, there is no errors

*Tags: Errors Debugging*

---

**liam** - *13:03:42*

It wouldn’t just stop without throwing an error, if you have a connection Id send it to Neil and he can tell you the logs their side 

*Tags: Errors Debugging*

---

**Evaldas** - *13:03:51*

i run my bots using: python3 run.py &gt;&gt; log.file to catch everything, but there is nothing

*Tags: General Technical*

---

**hugo** - *13:15:07*

stderr is where the exceptions get sent to

*Tags: Errors Debugging*

---

**hugo** - *13:15:18*

you want `python3 run.py 2&gt;&amp;1 &gt;&gt; log.file`

*Tags: General Technical*

---

**Evaldas** - *13:16:11*

so I must have uncatched error somewhere

*Tags: Errors Debugging*

---

**Evaldas** - *13:25:52*

Im using it, stdout just as precaustion, for freak errors

*Tags: Errors Debugging*

---

**Evaldas** - *13:26:08*

but turns out it doesnt log errors, you live and learn

*Tags: Errors Debugging, Deployment*

---

**liam** - *13:37:30*

Are you setup to catch errors and reconnect? 

*Tags: Getting Started, Errors Debugging*

---

**Evaldas** - *13:39:00*

this is one of those freak errors, and I have no idea what

*Tags: Errors Debugging*

---

**Evaldas** - *13:47:34*

thanks for help guys

*Tags: General Technical*

---

## 2019-12-09

**liam** - *10:52:08*

[@U5R89SMJ5](@U5R89SMJ5) you were correct about the stream breaking on the 28th, it also impacted me but I didn't realise till the weekend when reviewing some logs, see below from Neil



&gt; This issue was related to a jurisdictional rules update release that was made on 28th November. This had unintended consequences (namely updates stopped being sent to some Stream connections) so the dev team are currently investigating why this happened and won't be making any similar releases until the root cause of the issue has been fixed.

*Tags: Errors Debugging*

---

## 2019-12-20

**Jonatan (skyw)** - *22:55:19*

Documentation for Flumine, first one did not work for me.

```settings={  # passed to betfairlightweight

        "username": "test",

        "password": "test",

        "app_key": "test",

        "certificate_login": False,

    }



=&gt;



settings={  # passed to betfairlightweight

        betfairlightweight: {

            "username": "test",

            "password": "test",

            "app_key": "test",

        },

        "certificate_login": False,

    }```

*Tags: General Technical*

---

## 2019-12-21

**liam** - *17:27:51*

Error message?

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *19:09:01*

TypeError: type object argument after ** must be a mapping, not NoneType

```# From source

  @staticmethod

    def _create_client(settings):

        """Returns APIClient based on settings

        or looks for username in os.environ

        """

        if settings:

            return APIClient(**settings.get("betfairlightweight"))

        else:

            username = os.environ.get("username")

            return APIClient(username=username)```

*Tags: Errors Debugging*

---

**PeterLe** - *23:56:04*

[@U92CASP1B](@U92CASP1B) Seen this error posted before..advice was :it should be settings={“betfairlightweight”: {“username......

Set certificate_login to true if you have certs setup (you can login without using login_interactive) but don’t recommend it

*Tags: Getting Started, Errors Debugging*

---

## 2020-01-05

**Unknown** - *17:00:05*

Hi guys. i keep  getting the same error. how can i deal with this error attached

my code:

```import os

import logging

import queue

from betfairlightweight import filters

import datetime

import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



import pandas as pd

# create trading instance

trading = betfairlightweight.APIClient('username',

                                       'password',

                                       app_key='appkey',

                                       certs='C:\\Users\\')



# login

trading.login()



# make event type request to find horse racing event type

horse_racing_event_type_id = trading.betting.list_event_types(

    filter=filters.market_filter(

        text_query='Horse Racing'

    )

)

# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

trading.login()



t = datetime.datetime.now()+datetime.timedelta(hours=12)



while datetime.datetime.now() &lt; t:

    h_i1 =datetime.datetime.now()

    h_i2 = h_i1 + datetime.timedelta(hours=12)

    # Define a market filter

    thoroughbreds_event_filter = betfairlightweight.filters.market_filter(

        event_type_ids=['7'],

        market_start_time={

            'from': h_i1.strftime("%Y-%m-%dT%TZ"),

            'to': h_i2.strftime("%Y-%m-%dT%TZ")

        }

    )



    # Print the filter

    # thoroughbreds_event_filter



    # Get a list of all thoroughbred events as objects

    thoroughbred_events = trading.betting.list_events(

        filter=thoroughbreds_event_filter

    )



    # Get a list of all thoroughbred events as objects

    hr_thoroughbred_events = trading.betting.list_events(

        filter=thoroughbreds_event_filter

    )



    # Create a DataFrame with all the events by iterating over each event object

    hr_thoroughbred_events_next_12hours = pd.DataFrame({

        'Event Name': [event_object.event.name for event_object in hr_thoroughbred_events],

        'Event ID': [event_object.event.id for event_object in hr_thoroughbred_events],

        'Event Venue': [event_object.event.venue for event_object in hr_thoroughbred_events],

        'Country Code': [event_object.event.country_code for event_object in

                         hr_thoroughbred_events],

        'Time Zone': [event_object.event.time_zone for event_object in hr_thoroughbred_events],

        'Open Date': [event_object.event.open_date for event_object in hr_thoroughbred_events],

        'Market Count': [event_object.market_count for event_object in hr_thoroughbred_events]

    })

    # create queue

    output_queue = queue.Queue()



    # create stream listener

    listener = betfairlightweight.StreamListener(

        output_queue=output_queue,

    )



    # create stream

    stream = trading.streaming.create_stream(

        listener=listener,

    )



    # create filters (GB WIN racing)

    market_filter = streaming_market_filter(

        event_type_ids=['7'],

        event_ids=hr_thoroughbred_events_next_12hours['Event ID'],

        market_types=['WIN'],

    )

    market_data_filter = streaming_market_data_filter(

        fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

        ladder_levels=5,

    )



    # subscribe

    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=1000,  # send update every 1000ms

    )



    # start stream

    stream.start(async_=True)



    # check for updates in output queue



    while datetime.datetime.now() &lt; t:

        try:

            market_books = output_queue.get()

            print(market_books)



            for market_book in market_books:

                print(

                    market_book.streaming_update, 

                    market_book.publish_time,  

                )

        except:

            output_queue = queue.Queue()



            # create stream listener

            listener = betfairlightweight.StreamListener(

                output_queue=output_queue,

            )



            # create stream

            stream = trading.streaming.create_stream(

                listener=listener,

            )



            # create filters 

            market_filter = streaming_market_filter(

                event_type_ids=['7'],

                event_ids=hr_thoroughbred_events_next_12hours['Event ID'],

                market_types=['WIN'],

            )

            market_data_filter = streaming_market_data_filter(

                fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF' ],

                ladder_levels=5,

            )



            # subscribe

            streaming_unique_id = stream.subscribe_to_markets(

                market_filter=market_filter,

                market_data_filter=market_data_filter,

                conflate_ms=1000,  # send update every 1000ms

            )



            # start stream

            stream.start(async_=True)

    t = t + datetime.timedelta(hours=12)```

 but i doesn't  help. i thought if i put a while loop, then when error occurs it will sleep for 1 second and then subscribe to markets as you suggested and then  start the stream again. but still the code enter a state where the message below is displayed and nothing happens. this happens everyday once .  as you can see in Pycharm, the Run tab is still green, also the stop button(red square) is still active, it seems that my code does not capture the error , but the betfairlightweight source code capture it, then something happens and it stays there.why does my try and except  statements can't capture this error? I have to push  the stop button on the top left  and then rerun the code.  have you seen this issue before, any idea how can this be fixed.

*Tags: Getting Started, Errors Debugging, Feature Engineering, Strategies*

---

**Mo** - *17:03:15*

Can you fix the formatting? It's very hard to read

*Tags: Errors Debugging*

---

**DonJ80** - *17:40:31*

fixed formatting of the code now

*Tags: Errors Debugging*

---

**liam** - *18:10:09*

I can’t see the error at the moment but can try tomorrow when back on the laptop, the reason the program doesn’t end is because you start the stream in async which creates a new thread. Your program is then blocking on the queue.get, v2 is going to remove async as it results in bad habits / the socket timing out/errors without the main thread catching errors.



Remove that try except as it’s a bit pointless along with the while loop.

*Tags: Errors Debugging*

---

**liam** - *18:10:30*

Can you change logging to DEBUG so we can see more?

*Tags: Errors Debugging*

---

**Unknown** - *18:13:29*

thanks Liam, i will change  it to DEBUG

*Tags: Errors Debugging*

---

## 2020-01-06

**Unknown** - *20:02:14*

Hi [@U4H19D1D2](@U4H19D1D2) , i have  changed logging to DEBUG, and got the same error. how can i deal with this error? try and except are pointless as you mentioned. how  can i capture this error such that i stop the stream and then resubscribe to the markets.  what do i need to add? ...thanks

*Tags: Errors Debugging*

---

**DonJ80** - *20:13:07*

yes, i can. i was printing it, it works, it is only when this error happens, that everything freeze. will changing async to false help? how will printing the time below start.stream help? . have you seen this before? this happens once every 10 to 15 hours. what can i do handle it? ...thanks Liam i appreciate it.

*Tags: Errors Debugging*

---

**liam** - *20:15:42*

Ah, if it’s happening every now and again it will be because you are not catching any errors the stream may have. You need to run stream.start in a separate thread with try / except and reconnect on error. It’s common to get timeout or connection closed errors (caused by betfair or internet connection)

*Tags: Errors Debugging*

---

**liam** - *20:16:44*

[https://github.com/liampauling/flumine/blob/aedf15492e0a5e3e366c9416c5cac95e600ddf18/flumine/flumine.py#L78|https://github.com/liampauling/flumine/blob/aedf15492e0a5e3e366c9416c5cac95e600ddf18/flumine/flumine.py#L78](https://github.com/liampauling/flumine/blob/aedf15492e0a5e3e366c9416c5cac95e600ddf18/flumine/flumine.py#L78|https://github.com/liampauling/flumine/blob/aedf15492e0a5e3e366c9416c5cac95e600ddf18/flumine/flumine.py#L78)

*Tags: General Technical*

---

**DonJ80** - *20:22:44*

```  @liam Do you mean something like this?  

try:

       # start stream

       stream.start(async_=True)

except:

        stream.stop()

        # create stream listener

            listener = betfairlightweight.StreamListener(

                output_queue=output_queue,

            )



            # create stream

            stream = trading.streaming.create_stream(

                listener=listener,

            )



            # create filters 

            market_filter = streaming_market_filter(

                event_type_ids=['7'],

                event_ids=hr_thoroughbred_events_next_12hours['Event ID'],

                market_types=['WIN'],

            )

            market_data_filter = streaming_market_data_filter(

                fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF' ],

                ladder_levels=5,

            )



            # subscribe

            streaming_unique_id = stream.subscribe_to_markets(

                market_filter=market_filter,

                market_data_filter=market_data_filter,

                conflate_ms=1000,  # send update every 1000ms

            )



            # start stream

            stream.start(async_=True)

    # check for updates in output queue



    while datetime.datetime.now() &lt; t:

        

            market_books = output_queue.get()

            print(market_books)



            for market_book in market_books:

                print(

                    market_book.streaming_update, 

                    market_book.publish_time,  

                )

       

    t = t + datetime.timedelta(hours=12)```



*Tags: Strategies*

---

**DonJ80** - *20:29:55*

```Do mean like this 

try:

       # start stream

       stream.start(async_=False)

except:

        subscribe_to_markets_function() 

        #this stops the stream, subscribe tomarket and then start the stream   with async =False again.



    while datetime.datetime.now() &lt; t:

        

            market_books = output_queue.get()

            print(market_books)



            for market_book in market_books:

                print(

                    market_book.streaming_update, 

                    market_book.publish_time,  

                )

       

    t = t + datetime.timedelta(hours=12)```



*Tags: General Technical*

---

**liam** - *20:31:02*

No, I recommend reading up on threads and understanding the flumine code

*Tags: General Technical*

---

**liam** - *20:31:35*

[https://docs.python.org/3/library/threading.html|https://docs.python.org/3/library/threading.html](https://docs.python.org/3/library/threading.html|https://docs.python.org/3/library/threading.html)

*Tags: General Technical*

---

## 2020-01-07

**Newbie99** - *21:12:38*

```Traceback (most recent call last):

  File "D:/Python37/webpages/new_betfair.py", line 37, in &lt;module&gt;

    trading.login()

  File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\login.py", line 30, in __call__

    (response, elapsed_time) = self.request(self.url, session=session)

  File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\login.py", line 52, in request

    self._error_handler(response_data)

  File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\login.py", line 57, in _error_handler

    raise self._error(response)

betfairlightweight.exceptions.LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE```

I just received this error...my password hasn't changed and I can log into the Betfair GUI without any issues, so I'm a bit confused, any ideas?

*Tags: Errors Debugging, Strategies*

---

## 2020-01-08

**liam** - *08:53:05*

[@US6CDMD7Z](@US6CDMD7Z) I have added a new example which covers error handling and retrying that you and others might find handy, its a simplification of what I use in production and its rock solid :smile: It is in the v2.0 branch that I am working on [https://github.com/liampauling/betfair/blob/task/version-2.0/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/task/version-2.0/examples/examplestreamingerrhandling.py)

*Tags: Errors Debugging, Deployment*

---

**liam** - *08:54:16*

You can see it working by starting it and then disconnect from wifi/internet, it will then log the errors and attempt to reconnect with exponential backoff, you can then reconnect to the internet and see it reconnect to the stream

*Tags: Errors Debugging*

---

**DonJ80** - *20:28:20*

thanks Liam, i appreciate it. i will test it and let you know. "_*its a simplification of what I use"  what other/new features it includes without giving details and without sharing code, i am and i think others will be very interested to know general information about production level features that professionals like you use or implement and learn from you*_?

*Tags: Feature Engineering, Deployment*

---

## 2020-01-10

**oliver** - *13:44:17*

Hi.

I am using a slightly different structure to the examples on the site ([https://github.com/liampauling/betfair](https://github.com/liampauling/betfair)) as I have been following the guide ([https://betfair-datascientists.github.io/api/apiPythontutorial/](https://betfair-datascientists.github.io/api/apiPythontutorial/)).

I am looking for the horses names. I don't mind how I get the names (either when I list the runners in a race, or just finding the specific name that matches with a specific selection_id using a separate bit of code).

I find the list of the runners in a race via the following code:

```def process_runner_books(runner_books):

    best_back_prices = [runner_book.ex.available_to_back[0].price

                        if runner_book.ex.available_to_back

                        else 100

                        for runner_book

                        in runner_books]

    best_lay_prices = [runner_book.ex.available_to_lay[0].price

                       if runner_book.ex.available_to_lay

                       else 1000.0

                       for runner_book

                       in runner_books]

    selection_ids = [runner_book.selection_id for runner_book in runner_books]

    last_prices_traded = [runner_book.last_price_traded for runner_book in runner_books]

    df = pd.DataFrame({

        'Last Price Traded': last_prices_traded,

        'Best Back Price': best_back_prices,

        'Selection ID': selection_ids,

        'Best Lay Price': best_lay_prices,

    }).set_index('Last Price Traded').sort_index()

    return df



def getting_market_info_for_all_the_horses_in_a_race():

    global runners_df

    price_filter = betfairlightweight.filters.price_projection(price_data=['EX_BEST_OFFERS'])

    market_books = trading.betting.list_market_book(market_ids=[betfair_win_race_id],price_projection=price_filter,)

    market_book = market_books[0]

    runners_df = process_runner_books(market_book.runners)```

If anyone could help me get the horses names I would be most grateful.

Cheers

*Tags: Feature Engineering, Strategies*

---

**oliver** - *14:23:57*

Hi Mo. I fancy that is the route I just can't get it right! The code I tried (along with other slight tweaks) was:     `def finding_the_amount_of_money_match_on_each_market2():`

    `global betfair_win_race_id`

    `datetime_in_a_week = (datetime.datetime.utcnow() + datetime.timedelta(minutes=1100)).strftime("%Y-%m-%dT%TZ")`

    `market_catalogue_filter = betfairlightweight.filters.market_filter(market_ids=[1.167181875], market_start_time={'to': datetime_in_a_week})`

    `market_catalogues = trading.betting.list_market_catalogue(filter=market_catalogue_filter,`

        `market_projection=["RUNNER_DESCRIPTION","EVENT_TYPE","EVENT","COMPETITION","RUNNER_METADATA","MARKET_START_TIME"],`

        `max_results='100',`

        `sort='FIRST_TO_START')`

    `market_types_mooney_valley = pd.DataFrame({`

        `'name': [market_cat_object.runners for market_cat_object in market_catalogues],})`

    `print(market_types_mooney_valley)`      but the ouput was just the selection_ids for the horses

*Tags: Feature Engineering, Strategies*

---

**Mo** - *14:36:45*

The runners is a list of RunnerCatalogue objects. Look the definition of that object up here: [https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py|https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py](https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py|https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py) and see what fields you want

*Tags: Strategies*

---

**oliver** - *14:59:04*

I have had a look at that link before and frankly it goes straight over my head! The relevant section (lines 211 to 231) is structured differently to how I have written my code and I don't know/understand how to convert it.

*Tags: General Technical*

---

## 2020-01-17

**PeterLe** - *16:54:43*

Still learning Python (programming)  so forgive me if this is simple error...and i expect it is, on my part:-)

betfairlightweight all running OK, certs loaded fine too..

Im able to run some of the examples fine.



Im keen to be able to use flumine (output to a local directory on my PC)

$ PIP install flumine completed



However when I run the code im getting this error :



 File "C:/Users/User-1/Desktop/Python/Flumine/flumine-master/flumine/flumine.py", line 7, in &lt;module&gt;

    from .listener import FlumineListener

ImportError: attempted relative import with no known parent package



line 7 in flumine is :



from .listener import FlumineListener



I get the gist of the error, but not sure how to fix it.

Any help appreciated. Thanks in advance

Peter

*Tags: Getting Started, Errors Debugging*

---

**Jonatan (skyw)** - *17:00:52*

looks like your not having the correct PYTHONPATH env set, how are you running it?

*Tags: General Technical*

---

**Unknown** - *17:33:31*

Thanks for your help, Im just running it from Pycharm in debug mode at the mo...I was wondering if it was the way the directories are structured? Pls see image

*Tags: Errors Debugging*

---

**Mo** - *17:37:18*

Did you install flumine to a virtual environment or system wide?

*Tags: Getting Started*

---

**PeterLe** - *18:06:48*

Thanks gents, That solved the "ImportError: attempted relative import with no known parent package" problem

*Tags: Errors Debugging*

---

## 2020-01-21

**Jonatan (skyw)** - *14:06:49*

Not really an Issue,  but related to the asyncio part, I created an example taking the network part out of BetfairStreamer and implemented it using asyncio instead.



[https://github.com/almenjonatan/asynclightweightexample](https://github.com/almenjonatan/asynclightweightexample)



I wanted to learn asyncio, so are probably some fualts, but maybe some piece might be helpful for async support.

*Tags: General Technical*

---

## 2020-01-26

**Jonatan (skyw)** - *12:34:42*

I wonder if this is the intended behavior,



[https://github.com/liampauling/betfair/blob/f41260e759b27ceb1b91444cb7fd626c8a5acfcc/betfairlightweight/streaming/betfairstream.py#L210](https://github.com/liampauling/betfair/blob/f41260e759b27ceb1b91444cb7fd626c8a5acfcc/betfairlightweight/streaming/betfairstream.py#L210)



``` while self._running and part[-2:] != crlf_bytes:

            try:

                part = self._socket.recv(self.buffer_size)```

First could this not result in endless loop (theoretically)?



Assume that we choose our receive read buffer small and that the server pushes messages faster then we can read. Then the kernel buffer will never empty if we are not lucky and find a delimiter.



This would not yield a real world problem but should we not read up until the first delimiter  and then process, or set some limit on how many maximum messages  we should receive?

*Tags: Deployment*

---

## 2020-01-27

**Unknown** - *15:23:47*

Another, weird question,



I parse the data from streaming without betfairlightweight and compared them and wonder for another behavior.



This is a sequence  from mine above, and betfairlightweight below

It seems that some updates are aggregated with betfairlightweight.



This is surely something i am missing, but I think it's better to ask If there eventually would be something wrong.



cheers

*Tags: General Technical*

---

**liam** - *15:34:36*

first assumption is that its betfair doing it, bflw doesn't agg, simply sends what it gets whenever it gets it

*Tags: General Technical*

---

**liam** - *15:43:01*

i think i spent a week trying to fix something caused by this before :face_palm:

*Tags: Errors Debugging*

---

## 2020-01-28

**Jonatan (skyw)** - *14:23:14*

I use this channel as questions/suggestions for V2,



Instead of returning a list of runners, could we not return a mapping instead,  like sort_priority -&gt; runner



Is there any reason that it's a list?

*Tags: General Technical*

---

## 2020-01-31

**Gustav Molander** - *14:32:02*

Hi guys, a nice little channel you have here. :slightly_smiling_face: I just started out with trying to install betfairlightweight. Is there anything special you have to do when using Mac OS (Catalina) regarding python/python3 (pip/pip3) when installing? Im getting a bunch of errors.

*Tags: Getting Started, Errors Debugging*

---

**hugo** - *14:33:47*

What errors are you getting?

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *14:34:11*

Make sure you have python 3.7+, then in your project folder python -m venv venv

then pip install -r requirements.txt

*Tags: Getting Started*

---

**Jonatan (skyw)** - *14:34:38*

in requirements.txt



betfairlightweight

*Tags: General Technical*

---

**Jonatan (skyw)** - *14:39:28*

sorry between those python -m

and pip -r requriements



source venv/bin/activate

*Tags: General Technical*

---

**Unknown** - *14:39:41*

Alright, thanks. I’ll take a look at venvs.

I have python 3.7.6 but im not sure if pip uses the standard python 2 or  3, I havent changed the default python version.



These are the errors:

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *14:40:27*

type python --version

*Tags: General Technical*

---

**Gustav Molander** - *14:41:10*

yeah, the default is 2.7. However i tried changing the default with a simlink and also tried pip3, getting similar errors

*Tags: Errors Debugging*

---

**hugo** - *14:41:25*

[@U92CASP1B](@U92CASP1B) it's very common for python 3 to be accessed using `python3` and for python 2 to be just `python`

*Tags: General Technical*

---

**Gustav Molander** - *14:43:20*

Yes the default is 2.7, but i tried changing the default with 2 different methods, and other programs such as brew are finding the 3.7 just fine. Do you think this is a big problem?

*Tags: General Technical*

---

**Jonatan (skyw)** - *14:43:37*

yeah, but in the error messages I see python 2.7, It might be the case that he needs thos  as well though!

*Tags: Errors Debugging*

---

**Gustav Molander** - *14:45:14*

Im getting the exact same errors when using pip3. Im installing the command tools now!

*Tags: Getting Started, Errors Debugging*

---

**Gustav Molander** - *14:48:27*

Okay nice! Getting some success now, only a single error left:

```ERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: Consider using the `--user` option or check the permissions.```

*Tags: Getting Started, Errors Debugging*

---

**Jonatan (skyw)** - *14:48:49*

Yeah, it does, but next version he still need python3 and python2 is not maintained

Fixing the problem first first for 2.7 then he probably gonna switch anyway :slightly_smiling_face:

*Tags: Errors Debugging*

---

**Gustav Molander** - *14:49:29*

yeah skyw, do you recommend changing default python to 3 or just do pip3 install?

*Tags: Getting Started*

---

**Gustav Molander** - *14:51:51*

That would be ?

```pip3 install betfairlightweight --user```

with user being my username?

*Tags: Getting Started*

---

## 2020-02-06

**Alex F** - *16:57:41*

hey :slightly_smiling_face: i tried installing betfairlightweight, but it fails to build ciso8601, any idea what is up ? also, all i am after is to be able to read nicely the historic data that i have downloaded, is it really worth it to debug everything (ive spent 2 hours already) or just head in a different direction?

*Tags: Getting Started, Errors Debugging*

---

**Mo** - *17:06:25*

Paste the error that you get

*Tags: Errors Debugging*

---

**Alex F** - *17:08:37*

ERROR: Command errored out with exit status 1:

     command: 'C:\Users\alexa\Anaconda3\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '"'"'C:\\Users\\alexa\\AppData\\Local\\Temp\\pip-install-jajffrml\\version\\setup.py'"'"'; __file__='"'"'C:\\Users\\alexa\\AppData\\Local\\Temp\\pip-install-jajffrml\\version\\setup.py'"'"';f=getattr(tokenize, '"'"'open'"'"', open)(__file__);code=f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' egg_info --egg-base 'C:\Users\alexa\AppData\Local\Temp\pip-install-jajffrml\version\pip-egg-info'

         cwd: C:\Users\alexa\AppData\Local\Temp\pip-install-jajffrml\version\

    Complete output (7 lines):

    Traceback (most recent call last):

      File "&lt;string&gt;", line 1, in &lt;module&gt;

      File "C:\Users\alexa\AppData\Local\Temp\pip-install-jajffrml\version\setup.py", line 4, in &lt;module&gt;

        from version import __version__

      File "C:\Users\alexa\AppData\Local\Temp\pip-install-jajffrml\version\version.py", line 2, in &lt;module&gt;

        from itertools import izip_longest

    ImportError: cannot import name 'izip_longest' from 'itertools' (unknown location)

    ----------------------------------------

ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.

*Tags: Getting Started, Errors Debugging*

---

**hugo** - *17:10:40*

```oss $ python3

Python 3.7.3 (default, Oct  7 2019, 12:56:13)

[GCC 8.3.0] on linux

Type "help", "copyright", "credits" or "license" for more information.

&gt;&gt;&gt; from itertools import izip_longest

Traceback (most recent call last):

  File "&lt;stdin&gt;", line 1, in &lt;module&gt;

ImportError: cannot import name 'izip_longest' from 'itertools' (unknown location)

&gt;&gt;&gt;

oss $ python

Python 2.7.16 (default, Oct  7 2019, 17:36:04)

[GCC 8.3.0] on linux2

Type "help", "copyright", "credits" or "license" for more information.

&gt;&gt;&gt; from itertools import izip_longest

&gt;&gt;&gt;```



*Tags: Errors Debugging*

---

**hugo** - *17:11:25*

looks like a python2 vs 3 thing

*Tags: General Technical*

---

**Jonatan (skyw)** - *18:05:28*

Yeah, sorry did not mean to come off as rude :slightly_smiling_face:,

Yeah there are some steps  to do documentation are pretty good though so you should be fine :slightly_smiling_face:



The comment above was meant generally when people installing betfairlightweight they tend to use environments that depends on system libraries, just a strong opinion by me on not how to do it :slightly_smiling_face:. Not really a discussion in issues. Just ask if you have any other problems! GL

*Tags: Getting Started*

---

**Alex F** - *18:07:16*

well, yes, if you could help me out with the ssl cert, that would be great

*Tags: General Technical*

---

**Alex F** - *18:10:18*

i actually did that before asking the question, turned out i typed openssql and thats the reason it did not work

*Tags: General Technical*

---

**Alex F** - *18:17:49*

$ openssl req -new -config openssl.cnf -key client-2048.key -out client-2048.csr

unable to find 'distinguished_name' in config

problems making Certificate Request

16256:error:0E06D06C:configuration file routines:NCONF_get_string:no value:../openssl-1.1.1d/crypto/conf/conf_lib.c:273:group=req name=distinguished_name

any clues, please ?

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *18:40:38*

Should be easy to lookup the error codes though?

*Tags: Errors Debugging*

---

**Mo** - *18:43:38*

You copied that from the Betfair documentation?

*Tags: General Technical*

---

**Mo** - *18:44:32*

I think the Betfair documentation says where the you can find it

*Tags: General Technical*

---

**liam** - *19:58:42*

I wonder if we should make the c based libraries optional defaulting to python, can see them being a constant issue if win10 doesn’t support by default 

*Tags: General Technical*

---

## 2020-02-07

**Jonatan (skyw)** - *15:14:13*

Maybe create a FAQ for betfairlightweight or more detailed install instructions, although the extra work for different operating systems ...

*Tags: Getting Started*

---

**Jonatan (skyw)** - *17:36:45*

Any tips on how to prevent con=True updates, tried increasing buffer size



This is just reading from socket without doing any processing , tried both in cloud and at good computer, cpu  utilizationis very low

*Tags: General Technical*

---

**Jonatan (skyw)** - *17:41:25*

Yeah it just feels like it should able to read it without any problem, it's not that much data oh well :slightly_smiling_face:

*Tags: General Technical*

---

## 2020-02-08

**Alex F** - *08:13:55*

i get the following error:

*Tags: Errors Debugging*

---

**Alex F** - *08:14:18*

Error Loading extension section ssl_client

1696:error:22097082:X509 V3 routines:do_ext_nconf:unknown extension name:../openssl-1.1.1d/crypto/x509v3/v3_conf.c:78:

1696:error:22098080:X509 V3 routines:X509V3_EXT_nconf:error in extension:../openssl-1.1.1d/crypto/x509v3/v3_conf.c:47:name=name_opt, value=ca_default

*Tags: Errors Debugging*

---

## 2020-02-11

**Jack Kaminski** - *00:41:19*

Is there any subscribe to market feature for historical streaming. So I can isolate one event id with a filter out of many market IDs within one input file

*Tags: Feature Engineering*

---

## 2020-02-17

**AP** - *03:27:36*

TypeError: __init__() missing 1 required positional argument: 'placedDate'

*Tags: Errors Debugging*

---

**Unknown** - *09:06:25*

Looks like I have introduced a rather mighty CPU issue when making large API calls with v2, I believe it is to do with they way betfairlightweight uses the requests.Response object, investigating now



edit: now fixed [https://github.com/liampauling/betfair/issues/268](https://github.com/liampauling/betfair/issues/268)

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *15:10:19*

I looked at the commit, just curious, how come is it that decoding solved it?

*Tags: General Technical*

---

## 2020-02-18

**Unknown** - *01:08:01*

Why do I get this error on Ubuntu but not my Mac...

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *01:09:13*

different version of library or python version maybe

*Tags: General Technical*

---

**Jonatan (skyw)** - *01:10:09*

show the whole message and

output pip freeze

and python --version

*Tags: General Technical*

---

**Jack Kaminski** - *01:12:24*

Yeh that's the issue. The venv I have on Ubuntu says it's 3.7 but --python returns 2.7

*Tags: General Technical*

---

**Jonatan (skyw)** - *01:13:41*

remove the venv and do

python3 -m venv venv

*Tags: General Technical*

---

**Jonatan (skyw)** - *01:14:08*

python --version

pip install -r requirements.txt

*Tags: Getting Started*

---

**Jack Kaminski** - *04:08:09*

It still throws an error

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *04:29:31*

Does it still show python 2.7?

*Tags: General Technical*

---

**liam** - *08:21:20*

Have a read of this [https://liampauling.github.io/betfair/streaming/|https://liampauling.github.io/betfair/streaming/](https://liampauling.github.io/betfair/streaming/|https://liampauling.github.io/betfair/streaming/)

*Tags: General Technical*

---

**liam** - *12:01:49*

It allows you to do what you want with the streaming output, it is likely that this example covers all your needs (err catching + reconnect) [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)

*Tags: General Technical*

---

## 2020-02-19

**Mo** - *16:04:32*

I'm getting `betfairlightweight.exceptions.CacheError: "EX_MARKET_DEF" must be requested to use cache` on a stream where I have requested `EX_MARKET_DEF`. I'm assuming Betfair is sending through data on a market without one. Is there any way to gracefully ignore the data in this situation?

*Tags: Errors Debugging*

---

**Mo** - *16:12:05*

Obviously the problem is with Betfair sending junk data but this is a worrying point of failure

*Tags: General Technical*

---

**liam** - *16:13:49*

But lots to fix as it will then fail on create_resource 

*Tags: Errors Debugging*

---

**liam** - *16:22:41*

Yeah we can move the error handling up and disregard the market but you will keep getting updates

*Tags: Errors Debugging*

---

## 2020-02-20

**liam** - *08:10:06*

:thumbsup:  out of interest did the market fix itself in the end do you know?

*Tags: Errors Debugging*

---

## 2020-02-21

**Jonjonjon** - *23:06:05*

Does anyone here use Squid as a proxy server to connect to Betfair?



I have set up a proxy server, and am attempting to download some event types using the following example code, but it gives me this error:



URLError: &lt;urlopen error Tunnel connection failed: 503 Service Unavailable&gt;



```headers = {'X-Application': APPKEY, 'X-Authentication': SESSION_TOKEN, 'content-type': 'application/json'}

event_type_req = '{"jsonrpc": "2.0", "method": "SportsAPING/v1.0/listEventTypes", "params": {"filter":{ }}, "id": 1}'



req = urllib2.Request(API_NG_URL, event_type_req, headers)

req.set_proxy(https_proxy, 'https')

req.set_proxy(http_proxy, 'http')

response = urllib2.urlopen(req)

print response.read()```



*Tags: Errors Debugging, Deployment*

---

## 2020-02-22

**liam** - *08:00:59*

[@UPMUFSGCR](@UPMUFSGCR) just use bflw :slightly_smiling_face:



```from requests import session



session = requests.Session()

s.proxies = {

  "http": http_proxy,

  "https": https_proxy,

}



trading = betfairlightweight.APIClient(

    "username", 

    "password", 

    app_key="app_key", 

    session=session,

)```

although that error looks like something is wrong with the proxy/settings

*Tags: Errors Debugging, Strategies*

---

**Lee** - *12:25:37*

Hi, for the historical data, I have all the files and wrote a little script to extract and merge into one file then call this:

```stream = trading.streaming.create_historical_stream(

    directory='data/merged.txt',

    listener=listener,

)```

Is this the correct way of doing it or is there a better way? Looks like doing it this way i'll need to sort by `publish_time`

*Tags: Data Quality, Strategies*

---

## 2020-02-24

**Jack Kaminski** - *13:04:35*

Can anyone help me with extracting the market definition dictionary from a historical data stream object. Like retrieving the market books only return a marker definition dictionary

*Tags: Data Quality*

---

**jb** - *19:17:14*

Hey guys.  Starting to use the streaming, and I'm calling `stream.start()` and `stream.stop()` in a function.



As I'm working things out I'm failing alot in this function, and unable to call `stream.stop()`.  I can sometimes see orphaned streams writing to logs etc.



Do I need to worry about this, and if so is there anyway to get at these stranded streams and shut them down?  Eg I can't work out what the processes are to kill them in `ps -aux`  - any tips for what to look for?  Thanks.

*Tags: General Technical*

---

**Mo** - *19:22:30*

How are you running your python code?

*Tags: General Technical*

---

**jb** - *19:35:51*

normally calling it from ipython

*Tags: General Technical*

---

**liam** - *19:46:23*

Failing? You getting errors? Streaming isn’t really designed for interactive ide’s 

*Tags: Errors Debugging*

---

**jb** - *19:52:22*

ha yes I did this but turned it off as I couldn't get in and debug (with ipython `%debug`, which is my usual)

*Tags: Errors Debugging*

---

## 2020-02-25

**jb** - *11:22:01*

So how do people run and manage streams - in particular shut them down gracefully?  Some sort of poison pill?  Do you run them in regular python scripts, or something else?

*Tags: General Technical*

---

**liam** - *12:12:01*

Have you seen this? You can just call stop on program exit [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)

*Tags: General Technical*

---

**jb** - *12:22:00*

Yes I'm using that - and can call `stream.stop()` etc as long as my app is running.  But I don't understand how to deal with it if the app crashes.  Or if I want to stop the app with `ctrl-c` then `stream.stop()` won't get called.  (Though the above convo seems to say it's ok as the OS cleans everything up ).

*Tags: General Technical*

---

**Fab** - *12:38:05*

I’m still a Python beginner so don’t guarantee that the following works, but there seems to be a way of catching when your app is exiting or gets killed

*Tags: Getting Started*

---

**Fab** - *12:38:06*

[https://stackoverflow.com/questions/40866576/run-atexit-when-python-process-is-killed](https://stackoverflow.com/questions/40866576/run-atexit-when-python-process-is-killed)

*Tags: General Technical*

---

**liam** - *12:41:42*

Assuming you started a new thread then it will get killed when the __main__ process gets killed as they share ram / run in the same process. Most issues seem to occur when you run streaming in juypter or similar 

*Tags: General Technical*

---

**hugo** - *12:49:44*

note that the thread wont be stopped if all that happens on the main thread is an exception is thrown

*Tags: Errors Debugging*

---

**jb** - *12:56:33*

In case anyone else following this is using streaming with ipython or similar, and at my level of unsophistication, my current solution is to have the script check if a file named `STOP.sig` exists in a certain location and then stop cleanly.  So I can `touch STOP.sig` to stop the stream.

*Tags: General Technical*

---

**klozovin** - *13:19:42*

[@UPEFBEEL8](@UPEFBEEL8) that's work for sure, although dealing with files can be sometimes tricky. If you're on Linux, you can always send a signal to your Python process and catch it... I think there's functionality for dealing with signals in Python stdlib, and you can send the signal via pkill/kill command

*Tags: General Technical*

---

**jb** - *13:25:54*

you mean this?  [https://docs.python.org/3/library/signal.html](https://docs.python.org/3/library/signal.html)

*Tags: General Technical*

---

**Peter** - *16:30:55*

[@UPEFBEEL8](@UPEFBEEL8) In case this helps, I develop in Jupyter notebooks before refactoring into python scripts for deployment. This is the skeleton structure that I use:

*Tags: Deployment*

---

**Peter** - *16:46:35*

Also, I find the following handy, inside that loop. when I'm processing the data into a pandas dataframe in order to display it updating in a cell in a real-time:

```        display.display(your_dataframe)

        display.clear_output(wait=True)```

*Tags: Feature Engineering*

---

**jb** - *19:11:57*

Thanks [@USDCJS1CK](@USDCJS1CK).  Didn't realise you could change the markets streamed on the fly.  And I don't seem to be able to do it.

Are you literally changing the market_ids list you passed to the `streaming_market_filter`?

I have tried that, and also changed the `streaming_market_filter` itself - but the original markets seem to be still streamed (even though the filter shows the new list of markets).

*Tags: General Technical*

---

**liam** - *19:27:51*

Streaming is cheap 

*Tags: General Technical*

---

## 2020-02-26

**Remi** - *13:08:13*

Could someone tell me how to get a detailed view of orders that are near the spread? I am using betting.list_runner_book and looking at the ‘ex’ bets. But the bets that come back are aggregated too much. How do I get a more detailed view?

*Tags: Strategies*

---

**Mo** - *13:25:15*

Try setting ex_best_offers_overrides argument rollup_model to NONE

*Tags: Strategies*

---

**Remi** - *13:27:07*

With `ex_best_offers_overrides=filters.ex_best_offers_overrides(best_prices_depth=99, rollup_model=None)` I get the same response

*Tags: Strategies*

---

**Remi** - *13:51:24*

```best_prices_depth=9,

rollup_limit=1,

rollup_liability_threshold=0.01,

rollup_liability_factor=1```

I tried these with all the different rollupmodels, but I only ever get the same three quotes.

*Tags: Strategies*

---

**Remi** - *14:29:03*

Do you know if any of the betfairlightweight logic is different for GBP/EUR ?

*Tags: General Technical*

---

**Remi** - *14:35:59*

Also, I am on betfairlightweight==2.0.0

*Tags: General Technical*

---

**Unknown** - *15:50:00*

For anyone interested, they found a bug where a matched SP bet caused issues with listing current orders. They’re pushing a fix through end of this week/start of next week. 

*Tags: Errors Debugging*

---

**liam** - *18:26:48*

That’s your problem 

*Tags: General Technical*

---

**Remi** - *18:54:28*

But just to be clear, are you saying that betfair will not give detailed data about the orderbook without a live key (expected behavior) or are you just saying “that’s your problem, FU” ?

*Tags: Deployment*

---

## 2020-02-28

**Rory** - *14:14:41*

I haven't been getting any market stream updates for soccer in the last 30 minutes or so ... anyone else having streaming issues?

*Tags: General Technical*

---

**Ian** - *15:01:22*

on flumine I'm receiving constant high latency warnings on all 3 streams - dogs, horses &amp; football

*Tags: Performance*

---

**Rory** - *15:17:24*

I think I hit an interesting problem ...



I was doing some checks with output_queue.qsize() before calling output_queue.get()



That has been working fine for months but today output_queue.qsize() was always returning 0 ... reading through the docs, that method doesn't seem to be reliable even though it's used internally in the Queue class



Going back to just having a blocking call on output_queue.get() did the trick ... word of warning for others using qsize

*Tags: General Technical*

---

## 2020-02-29

**Lee** - *16:56:26*

Think i’ve spotted an issue with flumine on release 1.0.0.

```class StrategyOne(BaseStrategy):

    def start(self):

        print("StrategyOne")





class StrategyTwo(BaseStrategy):

    def start(self):

        print("StrategyTwo")



strategy_one = StrategyOne(

    market_filter=streaming_market_filter(

        event_type_ids=["1"], country_codes=["GB"], market_types=["OVER_UNDER_25"]

    )

)



strategy_two = StrategyOne(

    market_filter=streaming_market_filter(

        event_type_ids=["1"], country_codes=["GB"], market_types=["OVER_UNDER_25"]

    )

)



framework.add_strategy(strategy_one)

framework.add_strategy(strategy_two)

framework.run()```

Will print out

```✗ python backtest.py

StrategyOne

StrategyOne```

*Tags: Strategies*

---

**agberk** - *17:00:29*

You know you've created a StrategyOne object and assigned it to the variable strategy_two rather than a StrategyTwo object?

*Tags: Strategies*

---

**liam** - *17:00:29*

You’ve used strategy one twice 

*Tags: Strategies*

---

**liam** - *17:10:15*

Historical data 

*Tags: Data Quality*

---

## 2020-03-05

**Peter** - *09:39:22*

[@U4H19D1D2](@U4H19D1D2) I'm trying to understand how unique IDs are used for streaming in BFLW. Although the streaming error handling example shows a class that initialises a unique ID and can overwrite that with a received parameter when the class is instantiated, I'm not seeing anywhere that these are actually used. Instead the streaming subscribe methods (market and order) both start by creating their own unique IDs which are then added to the subscribe message and returned to the streaming error handling class overwriting any that was passed in or initialised when when the class was instantiated. Or am I misunderstanding?

*Tags: Errors Debugging*

---

**liam** - *09:47:53*

Each stream has a unique id, this is incremented per subscribe/resubscribe, anything that comes out of that stream (marketBook/orderBook) has that streaming id as a variable. Of course this could start off as 1001 but end up as 1456 if it has to constantly resubscribe but the streaming class gets the updated id.



Note that betfair send back this unique id in each update [https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/listener.py#L109](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/listener.py#L109)

*Tags: General Technical*

---

**Peter** - *09:54:54*

LOL. That was actually my starting point. I saw in the raw data that the stream IDs that I was passing into my streaming class (based on the error handling example) were being ignored, so worked backwards through the code to see why.

*Tags: Errors Debugging*

---

**Peter** - *10:05:13*

Makes sense. Thanks. And I guess I should just let BFLW handle setting the user ID rather than trying to construct my own.

*Tags: General Technical*

---

**liam** - *10:07:07*

i typically start at 1000 and increment per 1000 [https://github.com/liampauling/flumine/blob/master/flumine/streams/streams.py#L63](https://github.com/liampauling/flumine/blob/master/flumine/streams/streams.py#L63)

*Tags: General Technical*

---

**Peter** - *10:12:10*

Oh. I think a penny just dropped. Are you using a single application, and therefore one instance of the class subscribing to streams? I run separate processes on different servers triggered by cron, so I have multiple independent processes all starting at the same place. However, it's on my todo list for today to dive deeper into flumine, so that may change how I go about this.

*Tags: Deployment*

---

**liam** - *10:13:10*

yeah single, streaming is so lightweight there is no need to have multiple servers unless you are subscribing to a lot of markets / like dealing with dist systems, kiss

*Tags: Deployment*

---

**Peter** - *10:15:13*

That's what I'm learning. Many thanks for your help (and of course for BFLW!)

*Tags: General Technical*

---

**liam** - *10:18:57*

I use something very similar to flumine and handle 500-1000 markets per instance with 20-50 strategies, 3+ order streams, 5+ market streams placing 10's of thousands of bets per hour all off a single server (single cpu / 2gb ram)

*Tags: Deployment*

---

## 2020-03-06

**AP** - *13:52:29*

You can also use the resources here: [https://www.betfair.com.au/hub/models/|https://www.betfair.com.au/hub/models/](https://www.betfair.com.au/hub/models/|https://www.betfair.com.au/hub/models/)



They all have a corresponding endpoint, I have built some useful strategies around them. 

*Tags: Strategies*

---

## 2020-03-09

**Rory** - *11:27:28*

Just curious how people are handling SocketError exceptions using the InPlayService (BetfairStream). The examples have the stream starting in a different Thread, so you never get the chance to recover from those socket errors in the main Thread if the connection drops after the stream has started

*Tags: Errors Debugging*

---

**Rory** - *11:27:29*

[https://github.com/liampauling/betfair/blob/104ff4cb8734038cb9351e74d16dc7bd018111bc/examples/examplestreaming.py#L46](https://github.com/liampauling/betfair/blob/104ff4cb8734038cb9351e74d16dc7bd018111bc/examples/examplestreaming.py#L46)

*Tags: General Technical*

---

**Rory** - *11:28:45*

or has everyone already moved to Flumine for that, which seems to run everything in the main Thread, so you can easily recover and retry

*Tags: General Technical*

---

**liam** - *11:29:14*

Have you seen the error handling / production example?

*Tags: Errors Debugging, Deployment*

---

**Rory** - *11:33:56*

makes sense ... the errors are handled inside the Thread which is doing the streaming, so you can recover

*Tags: Errors Debugging*

---

**jb** - *15:41:34*

Hey guys.  I normally use a VPN (at least from the laptop I tinker on), routing either thru Sweden or UK.  I sometimes get `LoginError: API login: BETTING_RESTRICTED_LOCATION` when logging in from either location - which goes away when I switch to the other one.  My account is registered to GB.



Anyone know what's going on - and also if betfair have any sensitivity about using VPNs etc?  Cheers.

*Tags: Errors Debugging, Strategies*

---

**Riley** - *22:49:48*

[@UPEFBEEL8](@UPEFBEEL8) as [@UBS7QANF3](@UBS7QANF3) said i remember setting up from an Australian google cloud data-centre but still got this error. It is because their address block is still registered in USA and geolocate back to USA

*Tags: Errors Debugging*

---

## 2020-03-11

**Jonatan (skyw)** - *20:27:38*

Since betfairlightweight are using type annotation, do we have any good way using it with tools like mypy? 



This is not specific for betfairlightweight, but for any 3rd party library.

*Tags: General Technical*

---

## 2020-03-15

**Newbie99** - *21:13:37*

`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': [['1.129176457', '1.138419916', '1.166407043', '1.120629096', '1.138799270', '1.169458599']], 'priceProjection': {'priceData': ['SP_AVAILABLE', 'SP_TRADED', 'EX_ALL_OFFERS', 'EX_TRADED'], 'exBestOffersOverrides': {}, 'virtualise': False, 'rolloverStakes': False}, 'orderProjection': 'ALL', 'matchProjection': 'NO_ROLLUP'}` 

`Exception: None` 

`Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-02180926-003c9436b9', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-02180926-003c9436b9', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`

*Tags: Errors Debugging*

---

**Newbie99** - *21:15:38*

but, thats sort of the point, how can 6 markets throw up that error?

*Tags: Errors Debugging*

---

**Newbie99** - *21:16:45*

But yes you are of course right, I should fix that!

*Tags: Errors Debugging*

---

**Newbie99** - *21:20:55*

just to confirm that is the case:



`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': ['1.129176457', '1.138419916', '1.166407043', '1.120629096', '1.138799270', '1.169458599'], 'priceProjection': {'priceData': ['SP_AVAILABLE', 'SP_TRADED', 'EX_ALL_OFFERS', 'EX_TRADED'], 'exBestOffersOverrides': {}, 'virtualise': False, 'rolloverStakes': False}, 'orderProjection': 'ALL', 'matchProjection': 'NO_ROLLUP'}` 

`Exception: None` 

`Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang06b-prd-02170920-003d06bfaf', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang06b-prd-02170920-003d06bfaf', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`

*Tags: Errors Debugging*

---

**Newbie99** - *21:26:47*

(still the same error if I take that out)

*Tags: Errors Debugging*

---

**Newbie99** - *21:28:05*

I was requesting Market Description via a call to listMarketCatalogue, but even when removing that it still produces the error.

*Tags: Errors Debugging*

---

**Mo** - *21:37:14*

Use streaming

*Tags: General Technical*

---

**Alex A** - *21:37:47*

It has lower latency than polling, is easier, and doesn’t have the same system around weighting of requests.

*Tags: Performance*

---

**Alex A** - *21:38:53*

You could make the same requests for up to 200 markets with streaming and that would be fine.

*Tags: General Technical*

---

**Newbie99** - *21:39:39*

Ah I see, okay, so my first call is to get the current position on load, then I switch to streaming for everything subsequent.



Need to re-write that it would appear.



Thank you, much appreciated, will give that a go.

*Tags: General Technical*

---

**Newbie99** - *21:43:26*

out of curiosity though, is there a better way to get a starting position than calling listMarketBook on startup (or is that the only/best way, but just simply don't call the full history/depth etc and pick up the rest later from streaming)?

*Tags: General Technical*

---

## 2020-03-16

**Peter** - *17:17:50*

Couple of Flumine newbie questions ... Using it to stream historic data locally, but this appears to create an unnecessary streaming connection with Betfair, Tried overriding the enter method to remove login in, and then also to remove workers to drop the keep alive, but it continued to log new connection IDs (or if I processed multiple files in a loop, multiple connection IDs). Is there a way to stop this?

*Tags: Deployment*

---

**Peter** - *17:19:53*

The other question is how to stop it once the stream file has been processed. When I execute framework.run() it logs the closure of the historical stream, but continues executing indefinitely, i.e. the python script doesn't exit. Is there a way to force that and clean up any threads that it has created?

*Tags: General Technical*

---

## 2020-03-17

**Peter** - *07:24:36*

```class HistoricalFlumine(Flumine):

    def __enter__(self):

        [http://logger.info|logger.info](http://logger.info|logger.info)("Starting historical flumine")

        self.strategies.start()

        [http://logger.info|logger.info](http://logger.info|logger.info)("strategies started ...")

        self.streams.start()

        [http://logger.info|logger.info](http://logger.info|logger.info)("streams started ...")

        self._running = True```

*Tags: General Technical*

---

**Peter** - *07:28:02*

This brings me back to the second question, which is whether there is a way to force exit of the framework.run() loop. At the moment my scripts log the following

```{"asctime": "2020-03-17 07:21:01,625", "levelname": "INFO", "message": "Stopped HistoricalStream 0"}```

*Tags: General Technical*

---

**Peter** - *07:29:00*

I can provide a fully worked example and logs if they would still be helpful.

*Tags: General Technical*

---

**Peter** - *07:40:42*

I guess my question might reduce to "how do I inject an event with type TERMINATOR into the stream?"

*Tags: General Technical*

---

**liam** - *08:09:18*

This is basically the conclusion I came to, running any historical data in a separate thread doesn't really work as it need to be moved into the main thread. One way would be to override process_market_book and add the terminator to the queue if market_book.closed

*Tags: Data Quality*

---

**Peter** - *10:19:34*

&lt;chuckling&gt;As part of my investigations, I forced an exit by overriding the Historical Stream class and pushing a terminator event onto the handler queue after the loop that reads the markets in the run method. This triggered an API error, when Betfair objected to the attempt to logout (no doubt because I had previously side stepped logging in).&lt;/chuckling&gt;

*Tags: Errors Debugging*

---

## 2020-03-19

**brightcake** - *11:05:27*

feel like I might be missing something very obvious here but when I use the trading.historic.get_file_list() method I seem to be getting a timeout error: Exception: HTTPSConnectionPool(host='[http://historicdata.betfair.com|historicdata.betfair.com](http://historicdata.betfair.com|historicdata.betfair.com)', port=443): Read timed out. (read timeout=16)

*Tags: Errors Debugging, Strategies*

---

## 2020-03-21

**kense** - *13:59:50*

Just for info, I tried to "pip install betfairlightweight" and found that it returned an error when attempting to build the wheel for ujson (it was collecting ujson-2.0.1). When I did a "pip install flumine" afterwards, it installed ujson without any issues, but it was version 1.35 (and also included betfairlightweight 2.1.0 rather than 2.2.0). Apologies if you're already aware...

*Tags: Getting Started, Errors Debugging*

---

**kense** - *14:00:53*

"ERROR: Could not build wheels for ujson which use PEP 517 and cannot be installed directly"

*Tags: Getting Started, Errors Debugging*

---

**liam** - *14:01:13*

Noticed this, looks like ujson have changed something which makes the build fail, what version of python? I think 3.7+ it’s ok 

*Tags: General Technical*

---

**kense** - *14:02:26*

Tried to 'pip install --upgrade betfairlightweight' after it had installed with the 'install flumine' but got the same error.

*Tags: Getting Started, Errors Debugging*

---

## 2020-03-22

**Newbie99** - *21:25:42*

I'm getting the following:



  `File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\betting.py", line 157, in list_market_catalogue`

    `(response, elapsed_time) = self.request(method, params, session)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 51, in request`

    `check_status_code(response)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\utils.py", line 17, in check_status_code`

    `raise StatusCodeError(response.status_code)`

`betfairlightweight.exceptions.StatusCodeError: Status code error: 400`



Which I'm guessing, is possibly due to to large a single listMarketCatalogue call on startup to get runner names (I can't see the error code in the docs, but that would make sense).



I was trying to keep the calls down to a minimum, but what is the best way to avoid this, is it just a case of call once per market on startup (once started is fine as then I only need to call on any runner changes)?

*Tags: Errors Debugging, Strategies*

---

## 2020-03-23

**liam** - *19:37:46*

[@U92CASP1B](@U92CASP1B)

1. my understanding is that bufsize is the maximum size, so using the [https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py#L218|bflw code](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py#L218|bflw code) in your example two parts will be read from the socket and joined together 'abc' + '\r\n' 

2. not sure I would comfortable in processing streaming data on the fly, i.e before the entire message has been sent but I could see it being useful if you have very large subscriptions but even then does conflate happen that often? I have never had an issue 

*Tags: General Technical*

---

**liam** - *20:02:07*

I don’t see the problem, and must have processed close to billions of updates without any issues 

*Tags: General Technical*

---

**Jonatan (skyw)** - *20:10:08*

the problem can happen when market_cache updates takes time.



because you process and queues on the same thread as you are reading the socket.



the default recv is 1024 bytes, I kernel space you have 65k bytes normally.



If we start queing up messages in kernel space we probably have to read them all + more until processing again, instead of just queing them and then process.

*Tags: General Technical*

---

**Jonatan (skyw)** - *20:11:30*

As said just want to make it aware, maybe not a real problem can occur and can be hard to see why :slightly_smiling_face:

*Tags: General Technical*

---

**Jason** - *22:22:59*

Ive been struggling to install Betfairlightweight for the last few days. Im using pycharm



`Collecting betfairlightweight==2.2.0`

  `Using cached betfairlightweight-2.2.0-py3-none-any.whl (60 kB)`

`Collecting ujson==2.0.1`

  `Using cached ujson-2.0.1.tar.gz (7.1 MB)`

  `Installing build dependencies: started`

  `Installing build dependencies: finished with status 'done'`

  `Getting requirements to build wheel: started`

  `Getting requirements to build wheel: finished with status 'done'`

  `Installing backend dependencies: started`

  `Installing backend dependencies: finished with status 'done'`

    `Preparing wheel metadata: started`

    `Preparing wheel metadata: finished with status 'done'`

`Collecting requests&lt;=2.23.0`

  `Using cached requests-2.23.0-py2.py3-none-any.whl (58 kB)`

`Collecting ciso8601==2.1.3`

  `Using cached ciso8601-2.1.3.tar.gz (15 kB)`

`Requirement already satisfied: certifi&gt;=2017.4.17 in c:\users\justin\anaconda3\envs\build\lib\site-packages (from requests&lt;=2.23.0-&gt;betfairlightweight==2.2.0) (2019.11.28)`

`Collecting chardet&lt;4,&gt;=3.0.2`

  `Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)`

`Collecting urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1`

  `Using cached urllib3-1.25.8-py2.py3-none-any.whl (125 kB)`

`Collecting idna&lt;3,&gt;=2.5`

  `Using cached idna-2.9-py2.py3-none-any.whl (58 kB)`

`Building wheels for collected packages: ujson, ciso8601`

  `Building wheel for ujson (PEP 517): started`

  `Building wheel for ujson (PEP 517): finished with status 'error'`

  `Building wheel for ciso8601 (setup.py): started`

  `Building wheel for ciso8601 (setup.py): finished with status 'error'`

  `Running setup.py clean for ciso8601`

`Failed to build ujson ciso8601`



  `ERROR: Command errored out with exit status 1:`

   `command: 'C:\Users\Justin\anaconda3\envs\Build\python.exe' 'C:\Users\Justin\AppData\Roaming\Python\Python37\site-packages\pip\_vendor\pep517\_in_process.py' build_wheel 'C:\Users\Justin\AppData\Local\Temp\tmpswrbz18z'`

       `cwd: C:\Users\Justin\AppData\Local\Temp\pycharm-packaging\ujson`

  `Complete output (5 lines):`

  `running bdist_wheel`

  `running build`

  `running build_ext`

  `building 'ujson' extension`

  `error: Microsoft Visual C++ 14.0 is required. Get it with "Build Tools for Visual Studio": [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)`

  `----------------------------------------`

  `ERROR: Failed building wheel for ujson`

  `ERROR: Command errored out with exit status 1:`

   `command: 'C:\Users\Justin\anaconda3\envs\Build\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '"'"'C:\\Users\\Justin\\AppData\\Local\\Temp\\pycharm-packaging\\ciso8601\\setup.py'"'"'; __file__='"'"'C:\\Users\\Justin\\AppData\\Local\\Temp\\pycharm-packaging\\ciso8601\\setup.py'"'"';f=getattr(tokenize, '"'"'open'"'"', open)(__file__);code=f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' bdist_wheel -d 'C:\Users\Justin\AppData\Local\Temp\pip-wheel-_l78ovpi'`

       `cwd: C:\Users\Justin\AppData\Local\Temp\pycharm-packaging\ciso8601\`

  `Complete output (14 lines):`

  `running bdist_wheel`

  `running build`

  `running build_py`

  `package init file 'ciso8601\__init__.py' not found (or not a regular file)`

  `creating build`

  `creating build\lib.win-amd64-3.7`

  `creating build\lib.win-amd64-3.7\ciso8601`

  `copying ciso8601\__init__.pyi -&gt; build\lib.win-amd64-3.7\ciso8601`

  `copying ciso8601\py.typed -&gt; build\lib.win-amd64-3.7\ciso8601`

  `warning: build_py: byte-compiling is disabled, skipping.`

  

  `running build_ext`

  `building 'ciso8601' extension`

  `error: Microsoft Visual C++ 14.0 is required. Get it with "Build Tools for Visual Studio": [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)`

  `----------------------------------------`

  `ERROR: Failed building wheel for ciso8601`

`ERROR: Could not build wheels for ujson which use PEP 517 and cannot be installed directly`

*Tags: Getting Started, Errors Debugging*

---

**Jonatan (skyw)** - *22:25:58*

Have you tried the line, long time I used windows and python.

*Tags: General Technical*

---

**Jonatan (skyw)** - *22:25:59*

`error: Microsoft Visual C++ 14.0 is required. Get it with "Build Tools for Visual Studio": [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)`

*Tags: Errors Debugging*

---

## 2020-03-26

**brightcake** - *15:40:12*

Can't seem to use the get_file_list method - tried using the example in the github repo and get a betfairlightweight.exceptions.InvalidResponse: Invalid response received: error

*Tags: Errors Debugging*

---

**liam** - *16:12:09*

full error?

*Tags: Errors Debugging*

---

**brightcake** - *16:22:05*

`Traceback (most recent call last):`

  `File "C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\historic.py", line 199, in request`

    `response_json = json.loads(response.content.decode("utf-8"))`

`ValueError: Expected object or value`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

  `File "C:\Users\user\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py", line 3319, in run_code`

    `exec(code_obj, self.user_global_ns, self.user_ns)`

  `File "&lt;ipython-input-10-03764898e36f&gt;", line 14, in &lt;module&gt;`

    `file_type_collection=["M"]`

  `File "C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\historic.py", line 148, in get_file_list`

    `(response, response_json, elapsed_time) = self.request(method, params, session)`

  `File "C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\historic.py", line 201, in request`

    `raise InvalidResponse(response.text)`

`betfairlightweight.exceptions.InvalidResponse: Invalid response received:` 

`[!DOCTYPE html](!DOCTYPE html)`

`&lt;html&gt;`

`&lt;head&gt;`

    `&lt;meta name="viewport" content="width=device-width" /&gt;`

    `&lt;title&gt;ngErrorRedirect&lt;/title&gt;`

`&lt;/head&gt;`

`&lt;body&gt;`

    `&lt;div&gt;` 

        `Error`

    `&lt;/div&gt;`

`&lt;/body&gt;`

`&lt;/html&gt;`

*Tags: Errors Debugging*

---

**brightcake** - *20:16:35*

```logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))

trading = betfairlightweight.APIClient(username,

                                       password,

                                       app_key=app_key,

                                       certs=certs,

                                       cert_files=cert_files)



trading.login()

# trading.historic.read_timeout = 64

file_list = trading.historic.get_file_list(

    "Soccer",

    "Basic Plan",

    from_day=1,

    from_month=3,

    from_year=2017,

    to_day=31,

    to_month=3,

    to_year=2019

)

print(file_list)```

Code looks like this. I'm quite sure i've purchased all of the available football data, not sure what's going wrong here.

*Tags: Strategies*

---

## 2020-03-31

**mandelbot** - *09:53:24*

So im trying to run the example marketrecorder.py but I get the following error:

Traceback (most recent call last):

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\marketrecorder.py", line 46, in &lt;module&gt;

    framework.add_strategy(strategy)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\flumine\baseflumine.py", line 66, in add_strategy

    self.strategies(strategy)  # store in strategies

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\flumine\strategy\strategy.py", line 26, in _call_

    strategy.add()

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\strategies\marketrecorder.py", line 154, in add

    super().add()

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\strategies\marketrecorder.py", line 37, in add

    raise OSError("File dir %s does not exist" % self.local_dir)

OSError: File dir /tmp does not exist



I tried to create the dir in question but get the same. What am I missing? Appologies for the dumb question, I'm new to python and coding and am still trying to understand how this library works.

*Tags: Getting Started, Errors Debugging, Strategies*

---

**Mo** - *09:55:36*

Change the `local_dir` on this line:  [https://github.com/liampauling/flumine/blob/2a261e27d5738ed405f9f1d24446bdfe8b078cc1/examples/marketrecorder.py#L35](https://github.com/liampauling/flumine/blob/2a261e27d5738ed405f9f1d24446bdfe8b078cc1/examples/marketrecorder.py#L35) to somewhere that will exist on Windows

*Tags: General Technical*

---

**mandelbot** - *10:17:08*

```Doh! Thanks, that was dumb. Although now I'm getting these: Traceback (most recent call last):

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\marketrecorder.py", line 46, in &lt;module&gt;

    framework.add_strategy(strategy)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\flumine\baseflumine.py", line 66, in add_strategy

    self.strategies(strategy)  # store in strategies

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\flumine\strategy\strategy.py", line 26, in _call_

    strategy.add()

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\strategies\marketrecorder.py", line 155, in add

    self.s3.head_bucket(Bucket=self._bucket)  # validate bucket/access

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\client.py", line 316, in _api_call

    return self._make_api_call(operation_name, kwargs)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\client.py", line 612, in _make_api_call

    http, parsed_response = self._make_request(

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\client.py", line 632, in _make_request

    return self._endpoint.make_request(operation_model, request_dict)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\endpoint.py", line 102, in make_request

    return self._send_request(request_dict, operation_model)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\endpoint.py", line 132, in _send_request

    request = self.create_request(request_dict, operation_model)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\endpoint.py", line 115, in create_request

    self._event_emitter.emit(event_name, request=request,

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\hooks.py", line 356, in emit

    return self._emitter.emit(aliased_event_name, **kwargs)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\hooks.py", line 228, in emit

    return self._emit(event_name, kwargs)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\hooks.py", line 211, in _emit

    response = handler(**kwargs)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\signers.py", line 90, in handler

    return self.sign(operation_name, request)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\signers.py", line 160, in sign

    auth.add_auth(request)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\auth.py", line 357, in add_auth

    raise NoCredentialsError

botocore.exceptions.NoCredentialsError: Unable to locate credentials```

*Tags: Errors Debugging, Strategies*

---

**Mo** - *10:19:13*

You need to configure your AWS credentials

*Tags: Deployment*

---

**liam** - *10:20:09*

just use the MarketRecorder if you want to save locally but I will be honest if you really need programming experience (basic is fine) to use these libraries. The errors are telling you the problem

*Tags: Errors Debugging*

---

**mandelbot** - *10:24:07*

Ah I didn't realize I need AWS, how do I configure to save locally? (i am using marketrecorder). I do have some basic programming experience (VBA).

*Tags: Deployment*

---

**liam** - *10:25:28*

replace the S3MarketRecorder with this one [https://github.com/liampauling/flumine/blob/2a261e27d5738ed405f9f1d24446bdfe8b078cc1/examples/strategies/marketrecorder.py#L16](https://github.com/liampauling/flumine/blob/2a261e27d5738ed405f9f1d24446bdfe8b078cc1/examples/strategies/marketrecorder.py#L16)

*Tags: General Technical*

---

## 2020-04-02

**D C** - *12:40:20*

If you want highly accurate position info I have found the GPS coords to exhibit significant error at times. On a close finish the data is often useless inside the final half furlong. In particular there often seems to be a periodically constant offset present in some of the GPS coords. I have recorded quite a few videos of races where the final GPS result is not accurate at all, but the market does tell you when that is the case.

*Tags: Errors Debugging*

---

**D C** - *12:41:58*

I personally calculate distances between successive GPS coords but I don't try to project them onto the racing line myself. That's quite an advanced problem in the parametric space (unless of course its a 5 furlong with no turns)

*Tags: General Technical*

---

## 2020-04-03

**Josh** - *15:20:04*

Hi all, hope everyone is safe and well. 



When trying to pip install betfairlightweight I get an error reading



Failed building wheel for ciso8601

Failed building wheel for ujson



Just wondered if anyone could shed some light on this

*Tags: Getting Started, Errors Debugging*

---

**Josh** - *15:29:29*

Yes installed and unfortunately had the same error, cheers liam I will keep checking back

*Tags: Getting Started, Errors Debugging*

---

## 2020-04-04

**Max** - *23:59:31*

Hi all, could anyone help me debug this error? I'm running the historical examples from [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py). Everything works until `get_file_list`: [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py#L38-L52](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py#L38-L52)



It fails with this error; any ideas?



```---------------------------------------------------------------------------

JSONDecodeError                           Traceback (most recent call last)

/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/historic.py in request(self, method, params, session)

    164         try:

--&gt; 165             response_data = response.json()

    166         except ValueError:



/usr/local/lib/python3.7/site-packages/requests/models.py in json(self, **kwargs)

    896                     pass

--&gt; 897         return complexjson.loads(self.text, **kwargs)

    898 



/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/__init__.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)

    347             parse_constant is None and object_pairs_hook is None and not kw):

--&gt; 348         return _default_decoder.decode(s)

    349     if cls is None:



/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py in decode(self, s, _w)

    336         """

--&gt; 337         obj, end = self.raw_decode(s, idx=_w(s, 0).end())

    338         end = _w(s, end).end()



/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py in raw_decode(self, s, idx)

    354         except StopIteration as err:

--&gt; 355             raise JSONDecodeError("Expecting value", s, err.value) from None

    356         return obj, end



JSONDecodeError: Expecting value: line 4 column 1 (char 6)



During handling of the above exception, another exception occurred:



InvalidResponse                           Traceback (most recent call last)

&lt;ipython-input-40-107c6aa3e9f7&gt; in &lt;module&gt;

     11     market_types_collection=["WIN", "PLACE"],

     12     countries_collection=["GB", "IE"],

---&gt; 13     file_type_collection=["M"],

     14 )

     15 print(file_list)



/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/historic.py in get_file_list(self, sport, plan, from_day, from_month, from_year, to_day, to_month, to_year, event_id, event_name, market_types_collection, countries_collection, file_type_collection, session)

    114         params = clean_locals(locals())

    115         method = 'DownloadListOfFiles'

--&gt; 116         (response, elapsed_time) = self.request(method, params, session)

    117         return response

    118 



/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/historic.py in request(self, method, params, session)

    165             response_data = response.json()

    166         except ValueError:

--&gt; 167             raise InvalidResponse(response.text)

    168 

    169         return response_data, elapsed_time



InvalidResponse: Invalid response received: 





[!DOCTYPE html](!DOCTYPE html)



&lt;html&gt;

&lt;head&gt;

    &lt;meta name="viewport" content="width=device-width" /&gt;

    &lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

    &lt;div&gt; 

        Error

    &lt;/div&gt;

&lt;/body&gt;

&lt;/html&gt;```

*Tags: Errors Debugging, Strategies*

---

## 2020-04-05

**Mo** - *07:53:48*

What historical data do you own?

*Tags: Data Quality*

---

**Mo** - *12:33:54*

That’s fine, so have you successfully run the streaming example?

*Tags: General Technical*

---

**Mo** - *12:41:03*

[https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py|https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py](https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py|https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py)

*Tags: Strategies*

---

**mandelbot** - *12:46:43*

I will look into, thanks for your help and patience :slightly_smiling_face:

*Tags: General Technical*

---

**mandelbot** - *12:51:32*

That's exactly what I needed, many thanks. Another question about stream, once I start one, how do I embed arguments. Not sure how this would work since it's not a loop.

*Tags: General Technical*

---

**mandelbot** - *12:55:21*

If it were polling I would set a loop to request the marketbook every x seconds and then check if my criteria are met, and place bets accordingly. How would it work with streaming?

*Tags: General Technical*

---

**mandelbot** - *13:15:55*

I see so I would place my bets here correct? [https://github.com/liampauling/betfair/blob/104ff4cb8734038cb9351e74d16dc7bd018111bc/examples/examplestreaming.py#L73](https://github.com/liampauling/betfair/blob/104ff4cb8734038cb9351e74d16dc7bd018111bc/examples/examplestreaming.py#L73)

*Tags: General Technical*

---

**mandelbot** - *13:21:17*

Thanks, sorry for all the questions. I'm an economist by education (lot of good that has done me!)

*Tags: General Technical*

---

**Mo** - *13:22:03*

No worries, here to help

*Tags: General Technical*

---

**Max** - *20:24:45*

This was the problem! Thanks a lot [@UBS7QANF3](@UBS7QANF3)

*Tags: General Technical*

---

**Max** - *20:26:03*

I would have expected an error message like "No data available on your account"; `ngErrorRedirect` will do

*Tags: Errors Debugging*

---

**Unknown** - *20:28:30*

No worries. The historic data API is a bit cryptic with its error messages unfortunately 

*Tags: Errors Debugging*

---

## 2020-04-08

**Christian Tox** - *14:39:39*

Hello totally new, sorry for newbie question: trying to do interactive login from Denmark and get "betfairlightweight.exceptions.LoginError: API login: DANISH_AUTHORIZATION_REQUIRED".



Looking at the developer docs I found that: "*Please note:* *Danish residents* cannot use the Non-Interactive (bot) login method due to the NEMID requirement which is only supported by the [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Interactive+Login+-+Desktop+Application|Interactive Login - Desktop Application](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Interactive+Login+-+Desktop+Application|Interactive Login - Desktop Application) method". [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login)



 Is it still possible for me to use betfairlightweight ?

*Tags: Errors Debugging*

---

**Christian Tox** - *14:46:59*

Hi, to be clear, I did this upon receiving the error:



`trading = betfairlightweight.APIClient(username="", password="", app_key="")` 

`trading.login_interactive()`



then got error



`betfairlightweight.exceptions.LoginError: API login: DANISH_AUTHORIZATION_REQUIRED`



thank you.

*Tags: Errors Debugging, Strategies*

---

**Christian Tox** - *15:45:21*

emailed support, hope they can help. Thanks regardless!

*Tags: General Technical*

---

**Christian Tox** - *17:21:05*

can I pass that token with betfairlightweight?

*Tags: General Technical*

---

**Christian Tox** - *18:22:09*

Hmm I go:

`session_token = "token string"`

`trading = betfairlightweight.APIClient(username= "username", password="password", app_key="app key")`

`trading.set_session_token(session_token=session_token)`

`trading.login_interactive()`



And get it again:

`betfairlightweight.exceptions.LoginError: API login: DANISH_AUTHORIZATION_REQUIRED`

*Tags: Errors Debugging, Strategies*

---

**Christian Tox** - *18:27:03*

Yea that's what I expected too. If I



`print(trading.session_token)`



it returns the correct token. But trading.login_interactive still gives same error

*Tags: Errors Debugging, Strategies*

---

## 2020-04-09

**JK** - *06:41:30*

Hey guys, ive got some historic stream data in bz2 files, 1 per market, but im having trouble reading it. Im using the example script at [https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py)



My main code looks like this



```# create listener

listener = HistoricalListener(max_latency=None)



# create historical stream, update directory to file location

stream = trading.streaming.create_historical_stream(

    directory='../data/Jan/1/29636351',

    listener=listener,

)



# start stream

stream.start()```

But I am getting the error `[Errno 13] Permission denied: '../data/Jan/1/29636351` , anyone else had this issue? Have googled to no avail. Is this the correct way to write the data to txt?

*Tags: Errors Debugging, Performance, Strategies*

---

**JK** - *06:53:54*

still get the same permission denied error after unzipping :disappointed:

*Tags: Errors Debugging*

---

**JK** - *07:02:34*

Thanks a lot! It's now reading it, but getting another issue:

```INFO:betfairlightweight.streaming.stream:[Stream: HISTORICAL]: "MarketStream" created

Traceback (most recent call last):

  File "C:\Users\jhgwa\Documents\101-layer\stream_[http://listener.py|listener.py](http://listener.py|listener.py)", line 74, in &lt;module&gt;

    stream.start()

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://betfairstream.py|betfairstream.py](http://betfairstream.py|betfairstream.py)", line 286, in start

    self._read_loop()

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://betfairstream.py|betfairstream.py](http://betfairstream.py|betfairstream.py)", line 294, in _read_loop

    if self.listener.on_data(update) is False:

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://listener.py|listener.py](http://listener.py|listener.py)", line 115, in on_data

    self._on_change_message(data, unique_id)

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://listener.py|listener.py](http://listener.py|listener.py)", line 148, in _on_change_message

    self.stream.on_update(data)

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://stream.py|stream.py](http://stream.py|stream.py)", line 51, in on_update

    if latency &gt; self._max_latency:

TypeError: '&gt;' not supported between instances of 'float' and 'NoneType'```

Have you seen this one before? To do with the `max_latency` param?

*Tags: Errors Debugging, Performance*

---

**JK** - *07:16:01*

changed the `max_latency` to 0.01 and it worked. Thanks for your help :slightly_smiling_face:

*Tags: Performance*

---

## 2020-04-10

**Oliver Varney** - *21:51:27*

Does anyone run a backend sql server database. If so, what library/ module do they use?. I can get down to about 10 milliseconds insert/updates  but I'm not sure if I can go further with python?

*Tags: Deployment*

---

**Jonatan (skyw)** - *21:56:32*

It's built on PostGreSQL

*Tags: General Technical*

---

**Oliver Varney** - *21:58:13*

I'm trying to understand what are typical updates times for a python connector

*Tags: General Technical*

---

**liam** - *21:59:19*

You shouldn’t connect direct to a db from production code without an api in front (imho)

*Tags: Deployment*

---

**liam** - *22:05:10*

10ms seems pretty quick, I don’t think you will get quicker than that with something that isn’t in memory, why is speed important? / do you need use a db for this and not just python?

*Tags: Performance*

---

**Oliver Varney** - *22:08:17*

I only ask as there is no source online that give typical update times for python so I thought I would ask the community

*Tags: General Technical*

---

**Mo** - *23:13:31*

Although I know [@U4H19D1D2](@U4H19D1D2) would tell you just to store it in a Python structure :wink:

*Tags: General Technical*

---

## 2020-04-11

**Lee** - *16:48:57*

When using flumine to backtest with multiple files I get a delay from when I get the log message `Exiting flumine` to when it actually exits which increases with more files ranging from 10-20 seconds per a file. When I had 6 files I had to wait for 120 seconds. I’m adding multiple files like below:

```strategy = Ex(

    market_filter={

        "markets": [

            "marketdata/1.169499207",

            "marketdata/1.169499212",

            .......

        ]

    }

)```



*Tags: Strategies*

---

**Lee** - *19:05:41*

```(.venv) ➜ git:(master) ✗ python [http://example.py|example.py](http://example.py|example.py) &amp;&amp; date

{"asctime": "2020-04-11 18:03:44,005", "levelname": "INFO", "message": "Creating new &lt;class 'flumine.streams.historicalstream.HistoricalStream'&gt; (1000) for strategy Ex"}

{"asctime": "2020-04-11 18:03:44,006", "levelname": "INFO", "message": "Creating new &lt;class 'flumine.streams.historicalstream.HistoricalStream'&gt; (2000) for strategy Ex"}

{"asctime": "2020-04-11 18:03:44,006", "levelname": "INFO", "message": "Starting flumine"}

{"asctime": "2020-04-11 18:03:44,006", "levelname": "INFO", "message": "Register: marketSubscription 0"}

{"asctime": "2020-04-11 18:03:44,006", "levelname": "INFO", "message": "[Stream: 0]: \"MarketStream\" created"}

{"asctime": "2020-04-11 18:03:44,006", "levelname": "INFO", "message": "Starting historical market 'marketdata/1.169499207'"}

{"asctime": "2020-04-11 18:03:44,009", "levelname": "INFO", "message": "[MarketStream: 0] 1.169499207 added, 1 markets in cache"}

{"asctime": "2020-04-11 18:03:44,012", "levelname": "INFO", "message": "Adding: 1.169499207 to live markets and blotter"}

{"asctime": "2020-04-11 18:04:11,383", "levelname": "INFO", "message": "Completed historical market 'marketdata/1.169499207'"}

{"asctime": "2020-04-11 18:04:11,384", "levelname": "INFO", "message": "Register: marketSubscription 0"}

{"asctime": "2020-04-11 18:04:11,384", "levelname": "INFO", "message": "[Stream: 0]: \"MarketStream\" created"}

{"asctime": "2020-04-11 18:04:11,384", "levelname": "INFO", "message": "Starting historical market 'marketdata/1.169499212'"}

{"asctime": "2020-04-11 18:04:11,387", "levelname": "INFO", "message": "[MarketStream: 0] 1.169499212 added, 1 markets in cache"}

{"asctime": "2020-04-11 18:04:11,389", "levelname": "INFO", "message": "Adding: 1.169499212 to live markets and blotter"}

{"asctime": "2020-04-11 18:04:36,102", "levelname": "INFO", "message": "Completed historical market 'marketdata/1.169499212'"}

{"asctime": "2020-04-11 18:04:36,102", "levelname": "INFO", "message": "Backtesting complete"}

{"asctime": "2020-04-11 18:04:36,102", "levelname": "INFO", "message": "Exiting flumine"}

Sat Apr 11 19:04:45 BST 2020```



*Tags: Deployment, Strategies*

---

**Lee** - *19:18:35*

```PID     COMMAND           %CPU   TIME      #TH     #WQ   #PORTS MEM     PURG

9457    Python            99.7   03:24.24  1/1     0     14     11G     0B   ```

*Tags: General Technical*

---

**Lee** - *19:19:08*

```{"asctime": "2020-04-11 18:14:24,998", "levelname": "INFO", "message": "Register: marketSubscription 0"}

{"asctime": "2020-04-11 18:14:24,998", "levelname": "INFO", "message": "[Stream: 0]: \"MarketStream\" created"}

{"asctime": "2020-04-11 18:14:24,998", "levelname": "INFO", "message": "Starting historical market 'marketdata/1.169500956'"}

{"asctime": "2020-04-11 18:14:25,002", "levelname": "INFO", "message": "[MarketStream: 0] 1.169500956 added, 1 markets in cache"}

{"asctime": "2020-04-11 18:14:25,005", "levelname": "INFO", "message": "Adding: 1.169500956 to live markets and blotter"}

{"asctime": "2020-04-11 18:15:59,279", "levelname": "INFO", "message": "Completed historical market 'marketdata/1.169500956'"}

{"asctime": "2020-04-11 18:15:59,281", "levelname": "INFO", "message": "Backtesting complete"}

{"asctime": "2020-04-11 18:15:59,281", "levelname": "INFO", "message": "Exiting flumine"}

Sat Apr 11 19:16:51 BST 2020```

*Tags: Deployment*

---

**liam** - *19:33:05*

Not seeing a problem here, it runs the markets sequentially and takes a while to run each one depending on market type 

*Tags: General Technical*

---

## 2020-04-13

**Josh** - *16:47:46*

Just done a quick search and found a similar problem with historic stream data. Had the "[Errno 13] Permission denied:" error. File has been unzipped and full path passed in to code. Any thoughts appreciated. Cheers

*Tags: Errors Debugging*

---

**Josh** - *16:54:03*

[Errno 13] Permission denied error still appears

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *16:57:47*

I'm not sure about windows,



Your user running python probably do not have access to the file. If you put the file in some weird place I guess this could happen. I would suggest moving it to somewhere where your user has read write access.



Then you could right click on the file and check that your user has read permission. Someone else using windows probably have a better answer : )

*Tags: General Technical*

---

**Josh** - *16:58:55*

Cheers Jonathan, I moved to documents for this reasom but still no luck. Thanks for your help

*Tags: General Technical*

---

**Josh** - *18:53:58*

Something to do with permissions on the laptop I was using, works perfectly fine on another computer. Thanks for your help all

*Tags: General Technical*

---

## 2020-04-16

**Mo** - *11:55:37*

[https://github.com/liampauling/betfair/blob/master/betfairlightweight/endpoints/account.py#L59-L93](https://github.com/liampauling/betfair/blob/master/betfairlightweight/endpoints/account.py#L59-L93)

*Tags: General Technical*

---

**mandelbot** - *12:53:40*

Well I run automations on betfair, still trying to get to grips with bflw

*Tags: General Technical*

---

**Newbie99** - *14:34:59*

```import account_info as ai

import logging

import betfairlightweight as bf



logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



trading = bf.APIClient(ai.accname, ai.accpass, ai.acckey, certs=ai.path)

trading.login()



filters = bf.filters





market_catalogues = trading.betting.list_market_catalogue(

    filter=filters.market_filter(event_type_ids=[7],

                                 market_countries=["AU"],

                                 market_type_codes=["WIN"]

                                 ),

    market_projection=[

        "MARKET_START_TIME",

        "MARKET_DESCRIPTION",

        "EVENT"

    ],  # runner description required

    sort="FIRST_TO_START",

    max_results=800,

)



def check_rules(rules, search_string):

    check_rules = True if search_string in str(rules) else False

    return check_rules



for market_catalogue in market_catalogues:

    print(market_catalogue.market_name, ' ', market_catalogue.event.venue, ' ', check_rules(market_catalogue.description.rules, 'This is a Racing NSW Turnover Charge market'))```

This is a back of an envelope way to check market catalogue, looking at Aussie Racing markets and seeing if that text string is included in the rules.

*Tags: Strategies*

---

## 2020-04-17

**Unknown** - *02:07:27*

This will help

*Tags: General Technical*

---

**Josh** - *12:03:11*

Hi all, having trouble reading .bz2 files. Have passed in full path to code and unzipped files

```# create historical stream, update directory to file location

stream = trading.streaming.create_historical_stream(

    directory="C:/1.166899581",

    listener=listener,

)```

Seems to work but no output other than headers



```INFO:betfairlightweight.streaming.listener:Register: marketSubscription 0

INFO:betfairlightweight.streaming.stream:[Stream: 0]: "HistoricalStream" created```

Thanks for any help in advance

*Tags: Strategies*

---

## 2020-04-24

**Dave** - *14:27:59*

On the Dev branch of flumine, is it possible for flumine to pick up existing open orders and populate them into the blotter? Not sure if the functionality is there and I just can't find it :slightly_smiling_face:

*Tags: General Technical*

---

**liam** - *14:36:02*

No, not currently, was thinking about this today, the issue is that currently it will only pick up orders that have been created by itself, if its changed to pull in all orders what do we do about the trade/strategy that its linked to. I guess they would be orphaned orders, my preference would be not to go down this route at all

*Tags: Strategies*

---

**Dave** - *14:39:45*

ahh I see, fair enough. Just thinking about recovery after a disconnect/restart - I guess you'd just have to use the http client to get current orders with the same strategy ref and manually create order objects and load em into the blotter yourself I suppose (provided you want to manage them at strategy-ref level and nothing more fine-grained)

*Tags: Strategies*

---

**Newbie99** - *15:26:55*

Would using the customer_strategy_ref be an option to do a sweep on startup/restart and have flumine look for only those refs that had a match with a current strategy?

*Tags: Strategies*

---

**liam** - *15:48:23*

it currently uses the strategyRef more as an instanceRef as the hostname is used rather than the strategy name, maybe this needs to be changed to {hostname}-{strategy_name} but I am very wary of making things complicated

*Tags: Strategies*

---

**liam** - *15:54:58*

[@U0128E7BEHW](@U0128E7BEHW) are you just making a listCurrentOrders request, you able to share code, pseudo or real? Interested in how use cases as it will help in development :slightly_smiling_face:

*Tags: General Technical*

---

**Dave** - *17:05:42*

Precisely yep - basically added a dict in Markets class to hold orders by market ID on startup, and when a new market is added it checks if there are any orders in that dict and adds as a list called "recovered_orders" to the market object so it's accessible thereafter. Ideally I'd convert those bflw order objects into the Flumine Order/Trades objects so their lifecycles are automatically habdled but don't wanna invest time in making that yet hah, I will just check market.orders and market.recovered_orders together when looking at my open orders. My strategy is pretty simple so this works for me as a quick hack to get going but is an ugly solution

*Tags: Strategies*

---

**liam** - *17:17:43*

That’s the thing, redis just adds another layer of complexity, certainly want to look at adding it as an ‘extra’. Last thing I want is the requirement to run a database/api/redis/docker before an order can be placed 

*Tags: General Technical*

---

**Mo** - *17:34:18*

I don’t think it’s fair to say it adds complexity, it should reduce complexity in the flumine code base to delegate that responsibility to Redis

*Tags: General Technical*

---

## 2020-04-25

**liam** - *11:52:07*

Ah I might have a look, my stolen stackoverflow function may creates issues but it’s only to deal with the length restriction betfair put on the reference. I looked at using the startegyRef in conjunction but thy would mean using a separate package per execution per strategy which just over complicates things 

*Tags: Strategies*

---

**Dave** - *12:15:59*

Fair enough - when I looked at customerRef in the past as I was concerned there was some extra latency on Betfair side for insertion of order into the market (as it checks for dupes first) but probably won't end up being the bottleneck unless you're colo'd and using your own network stack :grin:

*Tags: Performance*

---

**user34** - *19:42:55*

I have just updated to version 2.3.0 and now get the following new error:

*Tags: Errors Debugging*

---

**user34** - *19:43:03*

File "/anaconda3/lib/python3.6/site-packages/betfairlightweight/streaming/listener.py", line 91, in __init__

    super(StreamListener,self).__init__(max_latency)



TypeError: super(type, obj): obj must be an instance or subtype of type

*Tags: Errors Debugging, Performance*

---

**user34** - *19:43:38*

listener = StreamListener(max_latency=None)

*Tags: Performance*

---

**user34** - *19:44:32*

I have tried reinstalling to remove the older listener classes, but it doesn't seem to help.

*Tags: Getting Started*

---

**user34** - *20:25:27*

No, Spyder, but I could use Jupyter if that would help.

*Tags: General Technical*

---

**liam** - *20:31:13*

Just searched that error and jupyter comes up as a potential reason, wouldn’t be surprised if it’s occurring with spyder as well 

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:21:22*

I've had that error before if I re-run the same code within  a Python process in an interactive tool, such as Jupyter. e.g. when jumping around and executing different code snippets. But it went away when I ran the code as a standalone script or application.

*Tags: Errors Debugging*

---

## 2020-04-26

**user34** - *10:28:53*

import logging

from betfairlightweight import StreamListener



logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))

listener = betfairlightweight.StreamListener(max_latency=None)

*Tags: Performance*

---

**user34** - *10:29:19*

import logging

from betfairlightweight import StreamListener



logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))

listener = StreamListener(max_latency=None)

*Tags: Performance*

---

**Jonatan (skyw)** - *10:32:05*

from betfairlightweight.streaming.listenener import Streamlistener

*Tags: General Technical*

---

**Jonatan (skyw)** - *13:11:17*

You're right I was only looking at my own code, I have no trouble running it with Anaconda environment with python 3.8.2 though. Hope  you solve it.

*Tags: General Technical*

---

## 2020-04-30

**Julio** - *11:21:12*

Hello all, I am thrilled to see such a great community on the Slack. I running my algo based on the test_streaming.py to refresh the prices. It works perfectly when the race sis far from starting. But when the races are

*Tags: General Technical*

---

**liam** - *11:36:52*

Welcome :slightly_smiling_face: test_streaming.py? Can you share your code, are you not using the examples?

*Tags: General Technical*

---

**Julio** - *11:39:22*

sorry - i used examplestreaming.py

*Tags: General Technical*

---

**Julio** - *11:52:17*

I thought about this, but then i'll still have the issue, with the place_order(). I think i'll have to rewrite my code, to put the strategy and the marketdata/orders into different threads.

*Tags: Strategies*

---

**liam** - *11:52:28*

[https://github.com/liampauling/flumine](https://github.com/liampauling/flumine)

*Tags: General Technical*

---

**Julio** - *11:53:15*

I'll have a look at flumine - I might not have to re invent the wheel :slightly_smiling_face:

*Tags: General Technical*

---

**Jonatan (skyw)** - *12:58:20*

[@U7E6NE1DM](@U7E6NE1DM) you could also check latency when you pull from queue you will probably notice blocking code / long running calculations quicker instead of waiting for the queue to fill up.

*Tags: Performance*

---

**Julio** - *13:32:54*

Thanks Jonatan. indeed I can see that: WARNING:betfairlightweight.streaming.stream:[Stream: 1001]: Latency high: [tel:15264482498|5.526448249](tel:15264482498|5.526448249). Is this represents the number of seconds a message stays in the queue before being pick up?

*Tags: Performance*

---

## 2020-05-04

**Unknown** - *11:34:41*

In regards to the historical data does anyone have issues with lots of updates having `img=True` and thus the cache being replaced? My assumption is that the data can be trusted and replacing the cache with the update is safe but who knows with this data (first time I have actually used Betfairs data rather than my own)

*Tags: Getting Started, Data Quality*

---

**Mo** - *11:53:57*

Never observed any problems

*Tags: General Technical*

---

## 2020-05-06

**Newbie99** - *10:39:29*

`ERROR:betfairlightweight.streaming.listener:[Subscription: None] UNEXPECTED_ERROR: Unknown error`

`ERROR:streaming_errors:MarketStreaming run error`

`Traceback (most recent call last):`

  `File "D:\Python37\webpages\streaming_errors.py", line 46, in run`

    `self.stream.start()`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 59, in start`

    `self._read_loop()`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 209, in _read_loop`

    `self._data(received_data)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 250, in _data`

    `raise ListenerError(self.listener.connection_id, received_data)`

`betfairlightweight.exceptions.ListenerError: connection_id: XXXXXXX, data: {"op":"status","statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"Unknown error","connectionClosed":true,"connectionId":"XXXXXXX"}`

*Tags: Errors Debugging*

---

**Newbie99** - *10:39:40*

Has anyone else been getting error messages this morning?

*Tags: Errors Debugging*

---

**Newbie99** - *10:40:08*

If I'm understanding the docs correctly, this is likely an error at Betfair's end, not mine, so there's not much I can do about it, other than wait it out!

*Tags: Errors Debugging*

---

**liam** - *10:40:22*

problems, i did last week but not today

*Tags: General Technical*

---

## 2020-05-08

**liam** - *09:21:53*

If so could you share a market? Want to try and debug this issue, I am hoping there is an easy fix

*Tags: Errors Debugging*

---

**Mo** - *09:49:00*

No worries, hope it helps

*Tags: General Technical*

---

**liam** - *09:50:30*

you mean you dont use flumine :smile:

*Tags: General Technical*

---

## 2020-05-11

**Schwaino** - *10:00:19*

```def bet(marketid, runnerid, odds):

    bank = 300

    stake = round(bank/20/odds,2)

    limit_order_filter = betfairlightweight.filters.limit_order(

    size= stake, 

    price=10,

    persistence_type='MARKET_ON_CLOSE')

    

    instructions_filter = betfairlightweight.filters.place_instruction(

    selection_id=str(runnerid),

    order_type="LIMIT",

    side="BACK",

    limit_order=limit_order_filter)

    

    order = trading.betting.place_orders(

    market_id=str(marketid), # The market id we obtained from before

    customer_strategy_ref='back_the_fav',

    instructions=[instructions_filter]) # This must be a list)

    return order```

*Tags: Strategies*

---

**liam** - *10:01:54*

print(order._data) or inspect it in the debugger to see what the error is

*Tags: Errors Debugging*

---

**Schwaino** - *10:37:40*

I have converted the strings inside the function so thats ok. I found the problem the runner id was a scratched runner. On that note when you get the runner books are the Selection IDs not in order??

*Tags: General Technical*

---

**liam** - *10:52:54*

python is dynamically typed so it treats the marketId as a float and thus converts to a float stripping the final zero

*Tags: General Technical*

---

**Schwaino** - *10:53:22*

bloody python!!!

*Tags: General Technical*

---

**Schwaino** - *10:53:45*

I had that problem when i was putting the runner ids into a data frame

*Tags: General Technical*

---

## 2020-05-12

**Schwaino** - *07:23:05*

Thank you Mo problem solved

*Tags: General Technical*

---

## 2020-05-13

**Dave** - *22:36:50*

qq about order validation in flumine, specifically regarding position limit enforcement

*Tags: General Technical*

---

**Dave** - *22:42:50*

back selection A with a stake of 2, so exposure is -2. If I then lay it at odds of, say, 1.5, my liability on this lay is 1. If I have max selection exposure as say, 2, then it does: if -2 - 1 &lt; -2 then error.

*Tags: Errors Debugging*

---

**Dave** - *22:43:40*

However in this case my lay is risk reducing, so it shouldn't error right? Should I be specifying my maxselectionexposure as a negative value?

*Tags: Errors Debugging*

---

## 2020-05-14

**Lee** - *09:41:01*

In flumine under process_market_book i can access total_matched for both market and runners but can't access that under framework.markets. Both the properties below return 0. Is that expected behaviour?

```for market in framework.markets:

    print("market", market.market_book.total_matched)

    for runner in market.market_book.runners:

        print("runner", runner.total_matched)```

*Tags: General Technical*

---

**brightcake** - *18:35:31*

seem to be getting this error 'errorCode': 'INVALID_SESSION_INFORMATION' when trying to initiate an instance of 'trading.betting.list_event_types'. It seems to work fine outside of an object but as soon as I encase it within a class it gives me this strange behaviour. Does anyone know what this could be?

*Tags: Errors Debugging, Strategies*

---

## 2020-05-15

**Dave** - *08:44:56*

bit of a weird one, but I keep getting the following segfault when running flumine under centos 7:

```New Thread 0x7fff8a7fc700 (LWP 3990)]                                       Program received signal SIGSEGV, Segmentation fault.                         [Switching to Thread 0x7fffb7606700 (LWP 3973)]                              double_conversion::StringToDoubleConverter::StringToIeee&lt;char const*&gt; (          this=0x0,                                                                    input=0x7fffa8f8bf9b "0.0,\"sortPriority\":12,\"metadata\":{\"SIRE_NAME\":\"Alta Christiano\",\"CLOTH_NUMBER_ALPHA\":\"7\",\"OFFICIAL_RATING\":null,\"COLOURS_DESCRIPTION\":\"Blue Gold Diamond\",\"COLOURS_FILENAME\":\"c20200515trots_GLOUCESTERP"..., length=1036207,                                            read_as_double=read_as_double@entry=true,              ```

*Tags: General Technical*

---

**Lee** - *19:34:40*

Am i right in thinking this issue will only be a problem if i'm backing and laying within the same race?

*Tags: General Technical*

---

## 2020-05-22

**Newbie99** - *09:47:25*

I've never tried a 'FILL_AND_KILL' order before, so was just playing around, but I keep getting an error, suggesting the param's are wrong (FILL_OR_KILL works fine).



Params: {'marketId': '1.170485933', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 28385567, 'side': 'BACK', 'limitOrder': {'price': 1000, 'persistenceType': 'LAPSE', 'size': 5, 'timeInForce': 'FILL_AND_KILL', 'minFillSize': 3}, 'customerOrderRef': '1.170485933_28385567_1'}], 'customerStrategyRef': 'manual_orders'}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}



Presumably FILL_AND_KILL is not the correct value to pass here, does anyone know what the correct one would be?

*Tags: Errors Debugging, Strategies*

---

**Newbie99** - *10:02:22*

sorry one more question, if I'm reading that correctly minFillSize can only be set in conjunction with FILL_OR_KILL, so there's no way to set a min fill of x but keep the rest of the order live?

*Tags: Deployment*

---

## 2020-05-24

**Steve** - *11:56:19*

Hi, I'm just started using the streaming API. I consistently get the following message: WARNING:betfairlightweight.streaming.stream:[Stream: 1]: Latency high: 0.5950710773468018. Is this an issue with my connection or the BF server? And what precissely is the 0.5950710773468018 a reference to.

*Tags: Performance, Deployment*

---

**liam** - *12:02:18*

[https://liampauling.github.io/betfair/streaming/#logging|https://liampauling.github.io/betfair/streaming/#logging](https://liampauling.github.io/betfair/streaming/#logging|https://liampauling.github.io/betfair/streaming/#logging)

*Tags: General Technical*

---

## 2020-05-25

**JazzMan** - *19:11:07*

Question on backtesting (Horse Racing). How far back do guys go? I wouldn’t want to go further back than about 2 months, in normal circumstances. This is mainly because the behaviour of the data is always changing with new bots coming on board ect… Also, I have had strategies that have stopped working and the only difference I believe is the data movements changing.

*Tags: General Technical*

---

**Mo** - *19:27:21*

Trading frequently doesn't help you if a lot of the outcomes are correlated

*Tags: Strategies*

---

**Mo** - *19:43:11*

This might not be as true in horse racing but also think about whether there is a bias to certain races at that time of the year, eg jumps vs flats that might mean a strategy trained on it doesn’t perform as well the rest of the year 

*Tags: Strategies*

---

**liam** - *19:45:08*

This is very strategy dependant, value backing / laying (handful of orders per race) then yeah I agree. Value taking preplay or inplay 100s/1000s of orders per race then you can drop your sample right down 

*Tags: Strategies*

---

## 2020-05-26

**Julio** - *11:01:17*

I have exactly the same issue. But I am still no convince if it is because of 1) change in market 2) algos learning my strategy and beating it 3) survivorship biais (still running a loosing strat - among all losing strat some will still win at the beginning)

*Tags: Strategies*

---

**Lee** - *20:16:46*

Using the S3MarketRecorder class i seem to be missing half the markets at the same venue compared to the betfair historic data. I'm not seeing any error messages. Any idea what might be happing here or how to debug it?



*Missing data counts*

```date	    venue	  betfair	recorder

21/04/2020	Albion	  16	    8

21/04/2020	Globe	  14	    7

21/04/2020	Menangle  16	    8```

*Using the following filters*

```market_recorder.S3MarketRecorder(

    market_filter=filters.streaming_market_filter(

        event_type_ids=["7"],

        market_types=["WIN"],

        country_codes=["US", "AU", "GB"],

    ),

    market_data_filter=streaming_market_data_filter(

        fields=[

            "EX_BEST_OFFERS_DISP",

            "EX_TRADED",

            "EX_TRADED_VOL",

            "EX_LTP",

            "EX_MARKET_DEF",

            "SP_TRADED",

            "SP_PROJECTED",

        ],

        ladder_levels=3,

    ),

    stream_class=datastream.DataStream,

    context={

        "local_dir": "/tmp",

        "bucket": "my-bucket-name",

        "force_update": False,

        "remove_file": True,

    },



)```

*Tags: Errors Debugging*

---

## 2020-05-29

**JS** - *09:09:29*

Hi guys -  first time post from a newbie down under. I'm trying to setup betfairlightweight to bring through race fields and test on my model but have come across an issue in regards to the Certificates.  I followed this guide from Betfair in terms of certificate generation [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA) which gives me a .crt and a .pem file. I realise though that it requires a .crt and a .key file as opposed to a .pem whihc this guide gives. I dont really understand the openssl side of things so thats why ive opted to use the XCA way. Any ideas on where to from here? any help would be much appreciated. Thanks!

*Tags: Getting Started, Strategies*

---

**JS** - *09:28:08*

yes great it worked. Just had to paste it into the new text file and then name it .key. Thanks very much for your help!

*Tags: General Technical*

---

**Unknown** - *15:37:07*

Folks, re the certificates. As a beginner myself, I had the same issues..This question comes up a lot. I recently got this working. So if it helps someone in the future this is what isued to get it working.

Follow this link:



[http://www.betfairprotrader.co.uk/2015/08/creating-digital-certificate-for-betfair.html](http://www.betfairprotrader.co.uk/2015/08/creating-digital-certificate-for-betfair.html)



and then I continued with is link:



[https://helpcenter.gsx.com/hc/en-us/articles/115015887447-Extracting-Certificate-crt-and-PrivateKey-key-from-a-Certificate-pfx-File](https://helpcenter.gsx.com/hc/en-us/articles/115015887447-Extracting-Certificate-crt-and-PrivateKey-key-from-a-Certificate-pfx-File)



I had a single folder "certs" in the top level directory C:

This is what it looked like (see image), although I may have too many files in there now :grinning:



Your Python code should resemble something like this :-



trading = betfairlightweight.APIClient("UserName", "Password", app_key="YourAppKey", certs=r"C:\certs")

# login

trading.login()



Hope the helps

regards

Peter

*Tags: Getting Started, Strategies*

---

## 2020-05-30

**Newbie99** - *22:38:51*

Give [@U4H19D1D2](@U4H19D1D2) a shout before you pay up, I believe he may be able to help you out on that front

*Tags: General Technical*

---

## 2020-05-31

**Unknown** - *20:01:18*

Total beginner to programming (just a couple of python courses under my belt), so sorry for what are easy questions...

Im using BFLW Exampleone and trying to build out from there. The idea at this stage is to learn rather than a fully functioning program to place bets etc

Initial thoughts are to start with one market at at time, extract EX_BEST_OFFERS for each selection and store the three back odds and three lay odds (Do you store these values in a list?)

Ill only be active in play, so I guess I can loop on the Inplay flag from the market ID?

Ill create some bet logic and just print to console for now, of what the bet would have been ie selctionID; Side, Size etc..



Does this sound logical as first steps? Also, if anyone has very basic code they can share (with secret sauce removed!) it would be appreciated



Also, When I place the operation via the Visualiser, I can see the price and size (see image) , but when I run it in BFLW I can only see "object at 0x0000018286D26108" for example. Is this a location in memory where the EX_BEST_OFFERS values are stored?

if so, how do you access those values via python?



Sorry for newbie questions, thanks in advance

regards

Peter

*Tags: Getting Started, Performance*

---

**liam** - *20:08:33*

Debugger is your friend here, what IDE are you using?

*Tags: Errors Debugging*

---

**liam** - *20:16:56*

[https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html|https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html](https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html|https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html)

*Tags: Errors Debugging*

---

**Remi** - *20:17:12*

&gt;  I can see the price and size (see image) , but when I run it in BFLW I can only see “object at 0x0000018286D26108” for example. Is this a location in memory where the EX_BEST_OFFERS values are stored?

&gt; if so, how do you access those values via python?

Yes, that is just the address to the PriceSize object. PriceSize does not implement __str__ method so if you print it it doesn’t get converted to a pretty string representation. If you want to see price and size you need to print price_size.price and price_size.size. The visualizer shows it as json which is ‘just’ text and not a python object.

*Tags: Performance*

---

**liam** - *20:17:13*

Using the debugger you can interrogate the objects 

*Tags: Errors Debugging*

---

**Ruben** - *20:22:45*

Pycharm has a great debugger, it allows you to stop the code at any point and inspect the values of your variables, execute code line-by-line, step into your own functions and much more

*Tags: Errors Debugging*

---

**PeterLe** - *20:29:27*

Great many thanks guys; I haven't used the debugger before, So I need to go away and learn that and the definitions. Thanks again

*Tags: Errors Debugging*

---

**liam** - *20:30:26*

Regarding your program design, any reason why you don’t want to use streaming?

*Tags: General Technical*

---

**PeterLe** - *20:35:48*

No, I would like to use streaming Liam; shows how far advanced I am!:grinning: Is there a better example i should be using to build out from ?

*Tags: General Technical*

---

**liam** - *20:50:50*

Depends on what you are trying to do, the great thing about streaming is that you subscribe to markets and then get updates on updates. Without streaming you need to find the markets you want and then continue to poll the marketBook endpoint for updates 

*Tags: General Technical*

---

**liam** - *20:51:40*

That’s not to say that you shouldn’t start with the latter to get to grips with the data etc but streaming makes everything simpler 

*Tags: General Technical*

---

**PeterLe** - *21:02:46*

Yes Streaming is the preferred method. All my current stuff is in C# which were written for me, but Id really like to learn this for myself, as I have lots of ideas, id like to try. Ill have a look at the examplestreaming.py tomorrow. Thanks

*Tags: General Technical*

---

**Unknown** - *23:50:59*

Managed to get the examplestreaming.py working; much simpler than what i was trying to do, although it seemed sensible at the time :grinning:, one step further today, thanks again guys

*Tags: General Technical*

---

## 2020-06-02

**Andrey Yunoshev** - *12:33:55*

```Exception in thread MarketStream_output_thread:

Traceback (most recent call last):

  File "/usr/local/lib/python3.7/site-packages/flumine/streams/marketstream.py", line 47, in handle_output

    block=True, timeout=self.streaming_timeout

  File "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py", line 178, in get

    raise Empty

_queue.Empty



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py", line 926, in _bootstrap_inner

    self.run()

  File "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py", line 870, in run

    self._target(*self._args, **self._kwargs)

  File "/usr/local/lib/python3.7/site-packages/flumine/streams/marketstream.py", line 51, in handle_output

    market_ids=self.flumine.markets.open_market_ids

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/markets.py", line 44, in open_market_ids

    return [m.market_id for m in self.markets.values() if not m.closed]

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/markets.py", line 40, in markets

    return {key: value for key, value in self._markets.items()}

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/markets.py", line 40, in &lt;dictcomp&gt;

    return {key: value for key, value in self._markets.items()}

RuntimeError: dictionary changed size during iteration```

*Tags: Errors Debugging*

---

**liam** - *12:47:14*

Can you create an issue on github? Its a quick fix

*Tags: Errors Debugging*

---

**Lee** - *12:57:25*

flumine seems to be getting some users :slightly_smiling_face:

*Tags: General Technical*

---

**liam** - *13:20:39*

[@U013R0E7SUV](@U013R0E7SUV) I have no idea how that can cause a RuntimeError, my understanding of dicts is that `items()` prevents this as it returns a list

*Tags: Errors Debugging*

---

**Lee** - *13:39:37*

I think in Python 3 it returns a generator

*Tags: General Technical*

---

**liam** - *13:40:26*

ah your right [https://docs.python.org/3/library/stdtypes.html#dictionary-view-objects](https://docs.python.org/3/library/stdtypes.html#dictionary-view-objects)

*Tags: General Technical*

---

**liam** - *13:41:10*

i think its hard to replicate as the exception is occurring when the view gets changed when the the dictcomp is processing

*Tags: Errors Debugging*

---

**liam** - *13:54:18*

Have I missed anything? [https://github.com/liampauling/flumine/pull/196/files](https://github.com/liampauling/flumine/pull/196/files)

*Tags: General Technical*

---

**Lee** - *14:03:48*

I’m just wondering if it’s going to move the error to somewhere else. Do you have a way to reproduce it?

*Tags: Errors Debugging*

---

**liam** - *14:06:03*

the error was due to the dodgy dictcomp on a dictionary that is changing based on new markets, removing it should solve any further issues as far as i can see

*Tags: Errors Debugging*

---

## 2020-06-04

**Ruben** - *08:04:04*

leaving this here in case someone else comes accross the same problem: I was using a Live key but getting delayed data. Turns out that even if you have an activated live key, if your betfair account is not funded, you will get delayed data

*Tags: Deployment*

---

## 2020-06-05

**Dave Simonds** - *13:42:48*

Hi everyone, been a member for a month or so, great insightful group, really happy to be here.



I do have a quick question….“TOO_MANY_REQUESTS” error.

This was introduced a few months back (just before the lockdown) and until now i’ve not really paid too much attention to it…. however its screwing me over big time now that racing is back. Your orders basically get denied if you attempt more than 1000 per second



I was just wondering is this something that applies across the board or is it only for non PC users? I remember someone once saying upper-tier PC users don’t pay a transactions charge and this kind of feels similar.



This really sucks because it looks like i am going to lose my only viable strategy, I’ve had a great 18 months out of it but to see things end because of a crappy rule change is a real shame

*Tags: Errors Debugging, Strategies*

---

**Mo** - *13:44:17*

Is your strategy really reliant on that?

*Tags: Strategies*

---

**Dave Simonds** - *14:06:49*

Yeah I’ve had a few back and forwards with Neil (assuming you mean the guys on their helpdesk)… he seems a good guy… i think he’s probably fed up of me hounding him over this.



I certainly wouldn’t say I’m spamming, betfair publish a market and I place my bets fast, in the event of a failure I retry, speed is imperative for many strategies (from what i can gather).



Private APIs? …. never heard of them, keen to learn tho!!! what are they for?

*Tags: Performance*

---

**liam** - *14:10:08*

you can try using the exchange transactional subdomain however not sure where the order count gets executed, if its further down the stack it won't help

*Tags: General Technical*

---

**Dave Simonds** - *14:16:15*

sounds weird reading that back, but id rather try once and be at the front of the queue, over thrying 5 times, racking up errors, pissing off Betfair &amp; still being beaten to market

*Tags: Errors Debugging*

---

**Mo** - *14:21:51*

True but it’s always hard to balance between spending time on something new that might not pan out versus improving an established strategy that you know works

*Tags: Strategies*

---

**Dave Simonds** - *14:28:06*

Theres a bit more to it than just smashing the server… I’ve probably not explained things very well. Sometimes when betfair publish their markets there is no delay, and then its a simple as getting your bet on quick, I’m pleased to say my code-base is quite good at this and I’m first to market more often than not. If all markets were published and in a ready state then I would not need to retry, and like i said if 1 retry is effectively 150 attempts (150 runners across 10 markets published simultaneously) you really rack up the errors quite quickly

*Tags: Errors Debugging, Deployment*

---

**Stefan** - *16:13:33*

So you you listen to streaming api for new published market/s, then you place 1.01 lay bets on any market selection. If you say betfair adds just 10 of markets in batch, how you can go in thousands of bets placed in 1 second? This strategy makes sense only for some market types, limit that to reduce amount of placed bets.

*Tags: Strategies*

---

## 2020-06-08

**Andrey Yunoshev** - *11:52:49*

Hi, right, I understand currently place lay and back orders for the same runner not possible? Is it a significant issue? Or can it be fixed? Or some workaround?

*Tags: Errors Debugging*

---

**liam** - *11:54:39*

it will block the second because it limits one live trade per selection per strategy, you can override the [https://github.com/liampauling/flumine/blob/master/flumine/strategy/strategy.py#L118|validate](https://github.com/liampauling/flumine/blob/master/flumine/strategy/strategy.py#L118|validate) function, test first!

*Tags: Deployment, Strategies*

---

**liam** - *12:00:40*

`RunnerContext.invested` is your golden source in knowing if you have a live trade in the market, if you override it then you need another way to prevent your strategy from placing trades/orders on every update

*Tags: Deployment, Strategies*

---

## 2020-06-11

**Remi** - *14:48:29*

`"errorCode":"ERROR_IN_MATCHER"`

*Tags: Errors Debugging*

---

**liam** - *15:10:22*

Anyone know how to get the error when this happens? (docker/python)

```14:03:07

Segmentation fault (core dumped)```

*Tags: Errors Debugging*

---

**liam** - *15:15:33*

nice, found it, ujson causing issues, anyone able to translate?

```Jun 11 14:03:07 ip-172-31-38-187 kernel: python[5081]: segfault at 0 ip 00007f4b75638a49 sp 00007f4b6cff76f0 error 4 in ujson.cpython-38-x86_64-linux-gnu.so[7f4b7562f000+14000]```

*Tags: Errors Debugging*

---

**Mo** - *15:16:34*

You’d need to have compiled with debug symbols to see the source file name and line number 

*Tags: Errors Debugging*

---

**liam** - *15:29:40*

yeah, looking at the issue log it could be one of many different things, wonder if bflw should using a different library..

*Tags: General Technical*

---

**Mo** - *15:42:09*

Can't say I've ever had any problems with it. Seems likely the issue here was it was given junk data because of Betfair API issues; obviously it would be better if it could handle this more robustly but if the two are related it's not like you'd have been able to run your system anyway

*Tags: General Technical*

---

**liam** - *16:14:48*

Yeah I think your right, just hate the idea of an error like this

*Tags: Errors Debugging*

---

**mandelbot** - *16:32:38*

Anyone have any error messages from the API around the exact time it crashed? Betfair claiming to me the crash was at 13:25 but it was clearly around 13:18

*Tags: Errors Debugging*

---

**liam** - *16:39:02*

13:17:19 is when I started getting errors

*Tags: Errors Debugging*

---

**Unknown** - *16:44:15*

```{

    "asctime": "2020-06-11 12:17:19,379",

    "levelname": "ERROR",

    "message": "_get_cleared_markets error",

    "filename": "accounthandler.py",

    "funcName": "_get_cleared_markets",

    "module": "accounthandler",

    "process": 6,

    "threadName": "account_handler",

    "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n    httplib_response = self._make_request(conn, method, url,\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 386, in _make_request\n    six.raise_from(e, None)\n  File \"[string](string)\", line 2, in raise_from\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 382, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/usr/local/lib/python3.8/site-packages/sentry_sdk/integrations/stdlib.py\", line 102, in getresponse\n    rv = real_getresponse(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.8/http/client.py\", line 1332, in getresponse\n    response.begin()\n  File \"/usr/local/lib/python3.8/http/client.py\", line 303, in begin\n    version, status, reason = self._read_status()\n  File \"/usr/local/lib/python3.8/http/client.py\", line 264, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n  File \"/usr/local/lib/python3.8/socket.py\", line 669, in readinto\n    return self._sock.recv_into(b)\n  File \"/usr/local/lib/python3.8/ssl.py\", line 1241, in recv_into\n    return self.read(nbytes, buffer)\n  File \"/usr/local/lib/python3.8/ssl.py\", line 1099, in read\n    return self._sslobj.read(len, buffer)\nConnectionResetError: [Errno 104] Connection reset by peer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/requests/adapters.py\", line 413, in send\n    resp = conn.urlopen(\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 648, in urlopen\n    retries = retries.increment(method, url, error=e, _pool=self,\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/util/retry.py\", line 347, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/packages/six.py\", line 685, in reraise\n    raise value.with_traceback(tb)\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n    httplib_response = self._make_request(conn, method, url,\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 386, in _make_request\n    six.raise_from(e, None)\n  File \"[string](string)\", line 2, in raise_from\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 382, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/usr/local/lib/python3.8/site-packages/sentry_sdk/integrations/stdlib.py\", line 102, in getresponse\n    rv = real_getresponse(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.8/http/client.py\", line 1332, in getresponse\n    response.begin()\n  File \"/usr/local/lib/python3.8/http/client.py\", line 303, in begin\n    version, status, reason = self._read_status()\n  File \"/usr/local/lib/python3.8/http/client.py\", line 264, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n  File \"/usr/local/lib/python3.8/socket.py\", line 669, in readinto\n    return self._sock.recv_into(b)\n  File \"/usr/local/lib/python3.8/ssl.py\", line 1241, in recv_into\n    return self.read(nbytes, buffer)\n  File \"/usr/local/lib/python3.8/ssl.py\", line 1099, in read\n    return self._sslobj.read(len, buffer)\nrequests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/betfairlightweight-0.0.0b13-py3.8.egg/betfairlightweight/endpoints/baseendpoint.py\", line 36, in request\n    response = session.post(\n  File \"/usr/local/lib/python3.8/site-packages/requests/api.py\", line 110, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/requests/api.py\", line 56, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/requests/sessions.py\", line 488, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/requests/sessions.py\", line 609, in send\n    r = adapter.send(request, **kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/requests/adapters.py\", line 473, in send\n    raise ConnectionError(err, request=request)\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/equine-1.11.2-py3.8.egg/equine/account/accounthandler.py\", line 130, in _get_cleared_markets\n    cleared_markets = client.betting_client.betting.list_cleared_orders(\n  File \"/usr/local/lib/python3.8/site-packages/betfairlightweight-0.0.0b13-py3.8.egg/betfairlightweight/endpoints/betting.py\", line 438, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/usr/local/lib/python3.8/site-packages/betfairlightweight-0.0.0b13-py3.8.egg/betfairlightweight/endpoints/baseendpoint.py\", line 43, in request\n    raise APIError(None, method, params, e)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.170718126'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))",

    "trading_function": "list_cleared_orders",

    "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.170718126'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))"

}```

*Tags: Errors Debugging, Strategies*

---

## 2020-06-12

**Rich** - *14:19:45*

Hi, I'm playing with the historical data (HistoricalGeneratorStream).  There doesn't seem to be any code here to deal with the bzip/tar file layout.  What is expected to be the content of the 'directory="/tmp/BASIC-1.132153978"' Is this a json file, several json files in one directory etc? Thanks

*Tags: Data Quality*

---

**liam** - *14:33:28*

it process one file at a time, yes, not sure what you mean? Got some code to share with the problem?

*Tags: General Technical*

---

**Rich** - *14:34:48*

```num_of_markets = 3



class HistoricalGeneratorStreamTarBz(HistoricalGeneratorStream):

    """Copy of 'Betfair Stream' for parsing historical data (no threads).

    RB: Edited for reading tarred/bzipped files

    """

    def _read_loop(self):

        tar = tarfile.open("D:/BetfairHorseMarketsDetailed.tar")

        i = 0

        self._running = True

        for member in tar.getmembers():

            bzf=tar.extractfile(member)

            f = bz2.open(bzf)

            i += 1

            if i &gt; num_of_markets: #change this to get more than 3 markets!

                self.stop()

                break

            content=f.readlines()

            for update in content:

                if self.listener.on_data(update) is False:

                    self.stop()

                    raise ListenerError("HISTORICAL", update)

                if not self._running:

                    break

                else:

                    yield self.listener.snap()

            else:

                self.stop()



stream = HistoricalGeneratorStreamTarBz('', listener)

gen = stream.get_generator()```

*Tags: Data Quality, Errors Debugging*

---

**Newbie99** - *14:34:56*

Not sure if this will help you (its what I use for processing the flumine data, so you'll need to add in another line for the unzipping, but allows you to process multiple folders):



```root_folder = 'xyz'

completed_folder = 'xyz'

folders = os.listdir(root_folder)

market_list = []

for folder in folders:

    folder = os.path.join(root_folder, folder)

    folder_path = os.listdir(folder)

    market_file_list = [market_file for market_file in folder_path if not market_file.endswith('.zip')]

    file_dict = [{'full_path': os.path.join(folder, x), 'market_id': x} for x in market_file_list]

    market_list.extend(file_dict)



for market in market_list:

    file_path = market['full_path']

    file_name = market['market_id']



    # create historical stream (update directory to your file location)

    stream = trading.streaming.create_historical_generator_stream(

        directory=file_path, listener=listener,

    )



    # create generator

    gen = stream.get_generator()



    # Creates a list of market_ids within the generator

    market_ids = [market_book.market_id for market_books in gen() for market_book in market_books]



    # Creates a list of market_books within the generator

    market_books = [market_book for market_books in gen() for market_book in market_books]```



*Tags: Strategies*

---

**Rich** - *14:35:39*

When I download the historical data straight from the betfair website, I get a TAR file of bzipped json files.

*Tags: Data Quality*

---

**Mo** - *14:37:51*

Example to read bz2 files directly using `smart_open` package:





```import smart_open

from unittest.mock import patch



...



stream = trading.streaming.create_historical_generator_stream(

    directory=path,

    listener=listener

)



with patch("builtins.open", smart_open.open):

    g = stream.get_generator()

    for market_books in g():

        ...```



*Tags: Strategies*

---

**liam** - *14:54:13*

it defaults to this, it just isn't giving you a log message for it [https://github.com/liampauling/flumine/blob/master/examples/strategies/marketrecorder.py#L116](https://github.com/liampauling/flumine/blob/master/examples/strategies/marketrecorder.py#L116)

*Tags: General Technical*

---

**Unknown** - *15:43:38*

[@U0159ENQVBP](@U0159ENQVBP) JonJonJon posted an excellent  file that demonstrates backtesting a whole folder of data files without having to unzip anything.  Well worth a look for inspiration! You can find it here: [https://betfairlightweight.slack.com/files/UPMUFSGCR/F013J0H5F3M/backtest_multi.py|Backtest Multi](https://betfairlightweight.slack.com/files/UPMUFSGCR/F013J0H5F3M/backtest_multi.py|Backtest Multi)

*Tags: General Technical*

---

**PeterLe** - *16:31:14*

[@U012ZFYR19V](@U012ZFYR19V) [@UPMUFSGCR](@UPMUFSGCR) Thanks for posting these, as a newbie to Python, I find all these examples really useful in looking at the code and trying to work out how it works

*Tags: General Technical*

---

**Mark** - *18:02:19*

[@UQL0QDEKA](@UQL0QDEKA)  [@UPMUFSGCR](@UPMUFSGCR) Yeah, I'm an absolute newbie at Python and it's been an eye-opener going from the most basic of JSON files in my "*Python Crash Course*" book to the mind boggling multiline deep-nested monstrosity that is a Betfair Historical Data File! None of the Python gurus seem to cover that in their YouTube videos :astonished:

I'm currently collecting snippets I may find useful along the journey, such as the Certs tutorial and of course, the Backtest file, while the example files are a great help too. That Liam fella's a clever bloke :wink:. It took me a while to figure out that I could save snippets in my Saved Items area so the data file to database example by [@UNQGKT0CR](@UNQGKT0CR) fell off the end of the message list before I could grab it. I was originally going to suggest a Newbies section where common problems and solutions could be stored but I guess the Saved Items and Files links pretty much has that covered already.

*Tags: Data Quality*

---

**PeterLe** - *18:16:48*

Yes I only realised lately that you can save things too. :grinning:, I got the certs working, so happy to help you get that piece up and running if you get stuck!

*Tags: General Technical*

---

**liam** - *18:51:02*

I like that idea, so much great stuff gets lost in the slack atm which I guess is a good problem to have!

*Tags: General Technical*

---

**Rich** - *21:37:15*

Yes, running from a Jupyter notebook. no name=='main', and have replaced the root folder path to be relevant to where my folder is (and just put the ExampleStrategy in)

*Tags: Strategies*

---

**JonJonJon** - *21:39:24*

I have a feeling the multiprocessing module might struggle from Jupyter. That's probably the problem. I just run it as a script.

*Tags: General Technical*

---

## 2020-06-13

**mandelbot** - *06:51:47*

I'm not sure to be honest. I guess so? Ideally I'd place the markets in folders by date and then have it pick up where it left off after a restart. I wouldn't run more than one instance on the same market in that case. Though I guess this is a bit error prone. How are you able to run them 24/7? Is it because you use an S3 recorder?

*Tags: Errors Debugging*

---

**liam** - *06:52:59*

S3 recorder, running on an aws ec2 instance (nano) and I just start and forget 

*Tags: Deployment*

---

**mandelbot** - *08:23:45*

I can turn off deleting of the zip by commenting out this line correct                      [https://github.com/liampauling/flumine/blob/4afe60589ea714b7596a88dcef86615b2eed1b6e/examples/strategies/marketrecorder.py#L131](https://github.com/liampauling/flumine/blob/4afe60589ea714b7596a88dcef86615b2eed1b6e/examples/strategies/marketrecorder.py#L131) ?

*Tags: General Technical*

---

**mandelbot** - *08:34:10*

Thanks, sorry for taking up your time with all the questions :)

*Tags: General Technical*

---

**liam** - *08:39:11*

Np, exactly what it’s for, I will look to cleanup that strategy and improve the docs 

*Tags: Strategies*

---

**Mo** - *08:42:50*

[@U4H19D1D2](@U4H19D1D2) do you see this being part of the package documentation?

*Tags: General Technical*

---

**liam** - *09:27:35*

Could go nuclear and move bflw + flumine into a GitHub organisation? Then create an examples repo?

*Tags: General Technical*

---

## 2020-06-14

**Unknown** - *01:11:39*

I'm having the same error message come up but am running as a script:

*Tags: Errors Debugging*

---

**Peter** - *09:09:39*

I've having similar (possibly the same) problems with [@UPMUFSGCR](@UPMUFSGCR)’s backtest_mult script. that is the exception appears to be being thrown in the ___get__result method in concurrent/futures/_base class, but the exception I'm seeing is rather more specific: "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc0 in position 15: invalid start byte".  As this is being thrown deep in a module with which I'm not familiar, I'm wondering whether anybody else has any ideas about this. I've tried importing multiprocessing and setting the start method to fork and I get the same exception whether I run it as a script or in Jupyter.

*Tags: Errors Debugging*

---

**Peter** - *09:48:57*

`from unittest.mock import patch`

`from concurrent import futures`

`import os`

`import time`

`import logging`

`import multiprocessing`



`from pythonjsonlogger import jsonlogger`



`import pandas as pd`

`import smart_open`



`from flumine import FlumineBacktest, clients`

`from strategies.lowestlayer import LowestLayer`





`logger = logging.getLogger()`



`custom_format = "%(asctime) %(levelname) %(message)"`

`log_handler = logging.StreamHandler()`

`formatter = jsonlogger.JsonFormatter(custom_format)`

`formatter.converter = time.gmtime`

`log_handler.setFormatter(formatter)`

`logger.addHandler(log_handler)`

`logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))`





`def run_backtest(market):`



    `client = clients.BacktestClient()`

    `framework = FlumineBacktest(client=client)`



    `strategy = LowestLayer(`

        `market_filter={"markets": [market]},`

        `max_order_exposure=1000,`

        `max_selection_exposure=10,`

        `context={"stake": 2},`

    `)`

    `framework.add_strategy(strategy)`



    `with patch("builtins.open", smart_open.open):`

        `framework.run()`



    `market = next(iter(framework.markets))`



    `data = []`

    `for order in market.blotter:`

        `datum = [`

            `order.market_id,`

            `order.selection_id,`

            `order.responses.date_time_placed,`

            `order.status,`

            `order.order_type.price,`

            `order.average_price_matched,`

            `order.size_matched,`

            `order.simulated.profit,`

        `]`

        `data.append(datum)`



    `return pd.DataFrame(`

        `data,`

        `columns = ['market_id', 'selection_id', 'time_placed', 'status', 'price', 'average_price_matched', 'size_matched', 'simulated_profit']`

    `)`



`data_folder = os.path.expanduser('~/data/betfair/test')`

`markets = []`

`_markets = os.listdir(data_folder)`

`_markets = [x for x in _markets if x.endswith('.zip')]`

`_markets = [os.path.join(data_folder, x) for x in _markets]`

`markets.extend(_markets)`



`multiprocessing.set_start_method('fork')`



`print('Running strategy across %i markets' % len(markets))`

`with futures.ProcessPoolExecutor(max_workers=24) as pool:`

    `all_futures = [`

        `pool.submit(`

            `run_backtest,`

            `market=market`

        `)`

        `for market in markets`

    `]`



`all_dfs = []`

`for i, future in enumerate([http://futures.as|futures.as](http://futures.as|futures.as)_completed(all_futures)):`

    `print('Future %i of %i completed' % (i+1, len(all_futures)))`

    `# all_dfs.append(future.result())`

    `all_dfs.append(future.result())`



`df = pd.concat(all_dfs)`

`print(df)`



`print(df.groupby('market_id')['simulated_profit'].sum().sum())`

*Tags: Feature Engineering, Strategies*

---

**JonJonJon** - *19:36:43*

If you are still trying/failing...



I don't really use Jupyter notebook for multiprocessing. But it might work if you  put the code that does the multiprocessing into  a Python module, and then call that from Jupyter.

*Tags: General Technical*

---

**JonJonJon** - *19:37:43*

But if you are doing long running analysis, the recommended workflow is to run the long computations in Python, save the results to disk, and then analyse them at leisure later.

*Tags: General Technical*

---

**JonJonJon** - *19:38:44*

For example, I used to work in a quant team where the models took 6 hours to run. So they would start the model at the beginning of the day. Do something else. And then when they wanted to analyse the results later, they could just load them from disk/database.

*Tags: Strategies*

---

**Rich** - *19:39:33*

Yes, I've been pickling my ML models to disk in another project i'm playing with.

*Tags: Strategies*

---

## 2020-06-15

**Sandy Caskie** - *13:13:30*

I am trying to get the price historical data for back and lay for horse racing events prior to the race start. I have been able to download the historical data using the GitHub repository [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py). I have then tried to view this data using the code from this repository [https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py). Though when I do this I receive the following error:



```AttributeError: 'Streaming' object has no attribute 'create_historical_generator_stream'```

When I look at the downloaded historical data file and read it as .txt file I can see it has the last traded price per runner. Therefore it appears that the downloaded file does have the data I am looking for. Though I cannot see a date-time stamp or if it is back or lay price for the traded price. Therefore I have two questions:



1. Is this the correct method to get back and lay price data up until the race starts?

2. Has this attribute name been changed or something? That is why I am getting this error.

*Tags: Data Quality, Errors Debugging*

---

**Sandy Caskie** - *13:24:32*

```Name: betfairlightweight

Version: 1.9.1```



*Tags: General Technical*

---

**mandelbot** - *13:27:30*

I keep getting latency warnings when I run the marketrecorder (even though other instances are fine). I am running on an AWS EC2. Any ideas why? Is it because im running a few instances?

`{"asctime": "2020-06-15 12:20:13,784", "levelname": "WARNING", "message": "[Stream: 1001]: Latency high: 2465.7244164943695"}`

that instance gets jammed up and continues only after hitting return

*Tags: Performance, Deployment*

---

**liam** - *13:28:43*

If you go in the AWS console what’s your CPU use like? 

*Tags: Deployment*

---

**liam** - *13:34:00*

Can you screenshot the ec2 monitoring graph page? 

*Tags: Deployment*

---

**mandelbot** - *13:38:31*

BTW when I said instances I meant instances of the market recorder

*Tags: Data Quality*

---

**liam** - *13:38:51*

go to EC2 / instances click on the instance and then monitoring

*Tags: Deployment*

---

**liam** - *13:57:41*

can you share the code? Seems very odd for one stream to have problems

*Tags: General Technical*

---

**mandelbot** - *13:59:23*

The code is just the same as the market recorder example

*Tags: Data Quality*

---

**mandelbot** - *14:00:41*

no latency errors and recording markets

*Tags: Errors Debugging, Performance*

---

**mandelbot** - *14:02:20*

I noticed one of them wasn't reporting any logs, so when I hit return it dumped a bunch of latency errors

*Tags: Errors Debugging, Performance*

---

**liam** - *14:03:28*

but are you running separate python processes? Or just adding another strategy with the different market filter?

*Tags: Strategies*

---

**mandelbot** - *14:04:09*

dont know how to do the latter yet :smile:

*Tags: General Technical*

---

**mandelbot** - *14:12:20*

Just put them all into one python and got a bunch of latency warnings again

*Tags: Performance*

---

**brightcake** - *14:12:25*

fwiw i'm recording around 200 markets and it uses up around 0.15% of the CPU on my AWS

*Tags: Deployment*

---

**liam** - *14:14:26*

spin up a linux instance and all your problems will be solved

*Tags: General Technical*

---

**liam** - *14:15:29*

thats fair enough, try a single python process first but we don't offer any warranty on windows use

*Tags: General Technical*

---

**liam** - *14:19:54*

haha, you won't look back, i think a 'how to setup a python/bflw/flumine instance on aws for free' could be a good thing to add to the faq/docs/repo

*Tags: Getting Started, Deployment*

---

**mandelbot** - *14:22:32*

Happened again, one python this time

`{"asctime": "2020-06-15 13:19:45,614", "levelname": "ERROR", "message": "DataStream run error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 220, in _receive_all\n    part = self._socket.recv(self.buffer_size)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ssl.py\", line 1226, in recv\n    return self.read(buflen)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ssl.py\", line 1101, in read\n    return self._sslobj.read(len)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\flumine\\streams\\datastream.py\", line 113, in run\n    self._stream.start()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 59, in start\n    self._read_loop()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 202, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 224, in _receive_all\n    raise SocketError(\"[Connect: %s]: Socket %s\" % (self._unique_id, e))\nbetfairlightweight.exceptions.SocketError: [Connect: 3002]: Socket [WinError 10054] An existing connection was forcibly closed by the remote host"}`

`{"asctime": "2020-06-15 13:19:45,614", "levelname": "WARNING", "message": "[Stream: 1001]: Latency high: 302.40696835517883"}`

*Tags: Errors Debugging, Performance*

---

**liam** - *14:24:11*

can you run with debug logs on? Might be tricky to debug this as it look os specific

*Tags: Errors Debugging*

---

**mandelbot** - *14:25:20*

debug logs, I dont know what that is. But I will look it up. In the mean time i will switch to a linux! Thanks liam.

*Tags: Errors Debugging*

---

**liam** - *14:27:43*

```logging.getLogger("betfairlightweight").setLevel(logging.DEBUG)```

*Tags: Errors Debugging*

---

**Sandy Caskie** - *14:37:50*

```ERROR: Command errored out with exit status 1:

  command: /Users/Sandy/anaconda3/bin/python /Users/Sandy/anaconda3/lib/python3.6/site-packages/pip install --ignore-installed --no-user --prefix /private/var/folders/1y/7v8fvfy51_sfdx_r21tgkq5h0000gn/T/pip-build-env-r8el7tjn/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i [https://pypi.org/simple](https://pypi.org/simple) -- 'setuptools&gt;=42' wheel 'setuptools_scm[toml]&gt;=3.4'

    cwd: None

 Complete output (41 lines):

 Traceback (most recent call last):

  File "/Users/Sandy/anaconda3/lib/python3.6/runpy.py", line 193, in _run_module_as_main

   "__main__", mod_spec)

  File "/Users/Sandy/anaconda3/lib/python3.6/runpy.py", line 85, in _run_code

   exec(code, run_globals)

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/__main__.py", line 19, in &lt;module&gt;

   sys.exit(_main())

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/cli/main.py", line 73, in main

   command = create_command(cmd_name, isolated=("--isolated" in cmd_args))

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/commands/__init__.py", line 96, in create_command

   module = importlib.import_module(module_path)

  File "/Users/Sandy/anaconda3/lib/python3.6/importlib/__init__.py", line 126, in import_module

   return _bootstrap._gcd_import(name[level:], package, level)

  File "&lt;frozen importlib._bootstrap&gt;", line 994, in _gcd_import

  File "&lt;frozen importlib._bootstrap&gt;", line 971, in _find_and_load

  File "&lt;frozen importlib._bootstrap&gt;", line 955, in _find_and_load_unlocked

  File "&lt;frozen importlib._bootstrap&gt;", line 665, in _load_unlocked

  File "&lt;frozen importlib._bootstrap_external&gt;", line 678, in exec_module

  File "&lt;frozen importlib._bootstrap&gt;", line 219, in _call_with_frames_removed

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/commands/install.py", line 24, in &lt;module&gt;

   from pip._internal.cli.req_command import RequirementCommand

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/cli/req_command.py", line 21, in &lt;module&gt;

   from pip._internal.req.constructors import (

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/req/__init__.py", line 11, in &lt;module&gt;

   from .req_file import parse_requirements

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/req/req_file.py", line 25, in &lt;module&gt;

   from pip._internal.req.constructors import (

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/req/constructors.py", line 28, in &lt;module&gt;

   from pip._internal.req.req_install import InstallRequirement

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/req/req_install.py", line 30, in &lt;module&gt;

   from pip._internal.operations.install.wheel import install_wheel

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/operations/install/wheel.py", line 10, in &lt;module&gt;

   import compileall

  File "/Users/Sandy/anaconda3/lib/python3.6/compileall.py", line 20, in &lt;module&gt;

   from concurrent.futures import ProcessPoolExecutor

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/concurrent/futures/__init__.py", line 8, in &lt;module&gt;

   from concurrent.futures._base import (FIRST_COMPLETED,

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/concurrent/futures/_base.py", line 381

   raise exception_type, self._exception, self._traceback

             ^

 SyntaxError: invalid syntax

 ----------------------------------------

ERROR: Command errored out with exit status 1: /Users/Sandy/anaconda3/bin/python /Users/Sandy/anaconda3/lib/python3.6/site-packages/pip install --ignore-installed --no-user --prefix /private/var/folders/1y/7v8fvfy51_sfdx_r21tgkq5h0000gn/T/pip-build-env-r8el7tjn/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i [https://pypi.org/simple](https://pypi.org/simple) -- 'setuptools&gt;=42' wheel 'setuptools_scm[toml]&gt;=3.4' Check the logs for full command output.```

I then uninstalled betfairlightweight and tried re-installing but got the same error. Looking online this seems like an internal error regarding pip any idea why this could happen?

*Tags: Getting Started, Errors Debugging*

---

**Jonatan (skyw)** - *16:19:16*

I have also got connection reset error from betfair, as you i also assumed it was the number of markets that I had subscribed to, when increasing the  number of subscriptions the error went away.

*Tags: Errors Debugging*

---

**Peter** - *16:24:39*

[@U010GM77S4W](@U010GM77S4W) An extra tip when setting up new instances. At the top of the list that AWS will offer you are the t2 series, but scroll down to the t3s - they're better and cheaper. E.g. Your t2.micro in London is $0.0132 ph, but the t3.micro is only $0.0118 ph. Moreover your t2 has a single cpu, the t3 has two (memory is the same 1GB for both).

*Tags: Performance, Deployment*

---

**Rich** - *16:28:30*

AWS linux probably best

*Tags: Deployment*

---

**liam** - *16:28:44*

yeah i use aws linux 2

*Tags: Deployment*

---

**Peter** - *16:42:30*

This might help: a little script that I run on my flumine servers to initialise them. Can probably be optimised a little, but it works for me on AWS Linux 2. The only wrinkle is that sometimes I have to tweak the python version - up or down! Haven't worked out why yet.

*Tags: Deployment*

---

**Peter** - *16:42:38*

`#!/bin/bash`



`yum install -y python37 python37-pip`

`yum install -y gcc gcc-c++ python3-devel ujson ciso8601 htop`



`pip3 install numpy pandas python-dotenv tenacity typing betfairlightweight flumine boto3 htop`

*Tags: Getting Started, Feature Engineering*

---

**Jonatan (skyw)** - *16:45:58*

I use ubuntu 20.04 image python 3.8 out of the box :)

*Tags: General Technical*

---

**Peter** - *16:46:38*

As a newbie to Linux, be aware that there are broadly two flavours: Debian and Centos. Most of the help you'll find on the web is for Ubuntu which is Debian-flavoured. But if you use the AWS Linux its Centos-flavoured. So f you're googling, always include Centos in your search.

*Tags: Deployment*

---

**mandelbot** - *16:52:14*

Thanks! Super helpful. I have used linux before, but it's been about a decade now.

*Tags: General Technical*

---

**Sandy Caskie** - *21:13:37*

Hi, sorry I missed your message. Its a problem to do with pip, so my end and not to do with betfair lightweight. I tried it on another computer and its working fine. Cheers for your help Liam.

*Tags: General Technical*

---

## 2020-06-16

**Rich** - *14:08:16*

[https://www.theregister.com/2020/06/16/aws_credit_virtual_summit_incentive/](https://www.theregister.com/2020/06/16/aws_credit_virtual_summit_incentive/)

*Tags: Deployment*

---

## 2020-06-17

**EJono** - *13:34:45*

Hey everyone, I had a question regarding bf historical data and was pointed towards this group on the developer forums. don't want to flood the wrong message board. Is this the right place to post my concerns?

*Tags: Data Quality*

---

**liam** - *13:36:46*

Just seen 'LetsGo' [https://forum.developer.betfair.com/forum/developer-program/historical-data/31991-selection-ids-from-basic-historical-data?p=32003#post32003|post](https://forum.developer.betfair.com/forum/developer-program/historical-data/31991-selection-ids-from-basic-historical-data?p=32003#post32003|post), not sure what his problem is :rolling_on_the_floor_laughing:

*Tags: General Technical*

---

**EJono** - *13:36:47*

I am trying to obtain selection ids from past matches of rugby matches etc through parsing a few months of historical data, downloaded via the basic plan. I was under the impression that betfairlightweight was the perhaps the optimal way to go about investigating previous data but I am having some problems operating directly on the downloaded data.tar files from betfair. I was curious if anyone knows what I should be doing in order to create a setup (in python) for retrieving information from these downloaded files either through utilising betfairlightweight or otherwise?



Any help is greatly appreciated

*Tags: Getting Started, Data Quality*

---

**liam** - *13:39:59*

What problems are you having?

*Tags: General Technical*

---

**EJono** - *13:52:24*

Accessing the directory of the downloaded files seems to be the high level problem I'm having. The BASIC file in the below photo is just the extracted entry of the initially downloaded data.tar file that I downloaded from bf historical data page yesterday

*Tags: Data Quality*

---

**EJono** - *13:54:34*

When I direct it straight to one of the bz2 files it comes across a Unicode error

*Tags: Errors Debugging*

---

**Jono** - *16:38:09*

hey [@UBS7QANF3](@UBS7QANF3) ive been trying to use the example you gave a few scrolls up that uses smart_open but im having some problems using that too. ive tried "pip install smart_open" but cant seem to use the library

*Tags: Getting Started*

---

**Jono** - *16:40:51*

Requirement already satisfied: smart-open in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (2.0.0)

Requirement already satisfied: requests in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from smart-open) (2.22.0)

Requirement already satisfied: boto in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from smart-open) (2.49.0)

Requirement already satisfied: boto3 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from smart-open) (1.14.4)

Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from requests-&gt;smart-open) (1.25.8)

Requirement already satisfied: idna&lt;2.9,&gt;=2.5 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from requests-&gt;smart-open) (2.8)

Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from requests-&gt;smart-open) (3.0.4)

Requirement already satisfied: certifi&gt;=2017.4.17 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from requests-&gt;smart-open) (2019.11.28)

Requirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from boto3-&gt;smart-open)

(0.10.0)

Requirement already satisfied: botocore&lt;1.18.0,&gt;=1.17.4 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from boto3-&gt;smart-open) (1.17.4)

Requirement already satisfied: s3transfer&lt;0.4.0,&gt;=0.3.0 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from boto3-&gt;smart-open) (0.3.3)

Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from botocore&lt;1.18.0,&gt;=1.17.4-&gt;boto3-&gt;smart-open) (2.8.1)

Requirement already satisfied: docutils&lt;0.16,&gt;=0.10 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from botocore&lt;1.18.0,&gt;=1.17.4-&gt;boto3-&gt;smart-open) (0.15.2)

Requirement already satisfied: six&gt;=1.5 in c:\users\jonathan wadsworth\appdata\local\packages\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\localcache\local-packages\python38\site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.18.0,&gt;=1.17.4-&gt;boto3-&gt;smart-open) (1.14.0)

*Tags: General Technical*

---

**Mo** - *16:41:58*

And what error do you get trying to use it?

*Tags: Errors Debugging*

---

**Jono** - *16:44:38*

it hasnt actually caused additional problems yet (outside of the ones i was already having when i joined the group), it just feels as if im building on unsteady foundations if i cant get theis seemingly small issue sorted

*Tags: General Technical*

---

**liam** - *17:06:26*

the fact you have cloned the bflw repo rather than installed it and running it inside the same repo could cause issues as well

*Tags: Getting Started*

---

**Jono** - *17:17:02*

ive made some of the changes you folks have suggested and am now succesfully into the .tar file... newbie round of applause. Ill continue improving the repository in the ways suggested and will check back in tomorrow when ive got some stamina back. thanks ever so much guys for all the help, i wouldnt have got anywhere today without it. Cheers

*Tags: General Technical*

---

**Mo** - *17:19:58*

Happy to help :+1:

*Tags: General Technical*

---

**jaderson felipe** - *19:03:37*

I downloaded the file and unzipped it ... but when I try to open it using PANDAS I always get an error ... could someone help me?

*Tags: Errors Debugging, Feature Engineering*

---

**Mo** - *19:06:52*

What file? What error?

*Tags: Errors Debugging*

---

## 2020-06-18

**Unknown** - *00:05:00*

I put .. but still with error

*Tags: Errors Debugging*

---

**Mo** - *05:43:30*

[https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py) should help you get started

*Tags: General Technical*

---

**Lee** - *09:31:08*

are the betfair api docs down for everyone? i'm getting an nginx error page

*Tags: Errors Debugging*

---

## 2020-06-20

**Ruben** - *17:52:43*

Quick question: a while ago I run a piece of code that created a market stream subscription to some event ids, and I got the error when trying to create the subscription stream "INVALID_INPUT, unable to un-marshall". Some hours later, I ran the same code again, and it worked fine

*Tags: Errors Debugging*

---

**liam** - *17:53:14*

Do you know what bflw version you are using?

*Tags: General Technical*

---

**liam** - *17:55:07*

Hmm, I have also seen this and thought it was fixed with the use of `sendall` on the socket but I guess it’s not fixed it 

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *18:12:55*

One have to establish a protocol, either some delimiter or fixed size messages?

*Tags: Errors Debugging*

---

**liam** - *18:19:11*

As per the docs betfair use the delimiter so I am not sure what is going on here, it’s very tricky to debug/replicate 

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *18:19:44*

I looked at the code and you add it! Probably some part not being sent then. Not code error I believe

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *18:20:02*

I would guess network error

*Tags: Errors Debugging*

---

**Mo** - *18:22:19*

I don’t think a network error would present at the application layer like that 

*Tags: Errors Debugging*

---

**Mo** - *18:30:52*

You’re not seeing either a socket error or an SSL error so you must have successfully sent a complete SSL frame

*Tags: Errors Debugging*

---

## 2020-06-22

**JK** - *07:23:30*

hey guys, i hit listClearedOrders every 15 mins to get my recent bets and add them to a database, but recently ive been getting a timeout error. Anyone know how to fix this/anyone else been having the same issue?

*Tags: Errors Debugging*

---

**liam** - *07:35:57*

by default bflw has it set to 15s, I use this endpoint a lot and have never hit a timeout, whats your connection like? Is it a requests timeout? (whats the traceback look like?)

*Tags: Errors Debugging*

---

**JK** - *08:14:26*

```Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 387, in _make_request

    six.raise_from(e, None)

  File "&lt;string&gt;", line 2, in raise_from

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 383, in _make_request

    httplib_response = conn.getresponse()

  File "/usr/lib/python3.6/http/client.py", line 1356, in getresponse

    response.begin()

  File "/usr/lib/python3.6/http/client.py", line 307, in begin

    version, status, reason = self._read_status()

  File "/usr/lib/python3.6/http/client.py", line 268, in _read_status

    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")

  File "/usr/lib/python3.6/socket.py", line 586, in readinto

    return self._sock.recv_into(b)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py", line 317, in recv_into

    raise timeout('The read operation timed out')

socket.timeout: The read operation timed out



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/adapters.py", line 449, in send

    timeout=timeout

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 641, in urlopen

    _stacktrace=sys.exc_info()[2])

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/util/retry.py", line 368, in increment

    raise six.reraise(type(error), error, _stacktrace)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise

    raise value

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 603, in urlopen

    chunked=chunked)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 389, in _make_request

    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 307, in _raise_timeout

    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)

urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=16)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 43, in request

    timeout=(self.connect_timeout, self.read_timeout)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/api.py", line 116, in post

    return request('post', url, data=data, json=json, **kwargs)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/api.py", line 60, in request

    return session.request(method=method, url=url, **kwargs)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/sessions.py", line 533, in request

    resp = self.send(prep, **send_kwargs)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/sessions.py", line 646, in send

    r = adapter.send(request, **kwargs)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/adapters.py", line 529, in send

    raise ReadTimeout(e, request=request)

requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=16)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "get_new_bets_minutely.py", line 159, in &lt;module&gt;

    main1()

  File "get_new_bets_minutely.py", line 48, in main1

    include_item_description = "true"

  File "/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py", line 288, in list_cleared_orders

    (response, elapsed_time) = self.request(method, params, session)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 48, in request

    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders 

Params: {'recordCount': 500, 'fromRecord': 1500, 'includeItemDescription': 'true', 'settledDateRange': {'to': None, 'from': None}, 'betStatus': 'SETTLED'} 

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=16)```

*Tags: Errors Debugging, Strategies*

---

**liam** - *08:18:58*

Can you try bumping the timeout



```from betfairlightweight.endpoints.betting import Betting



Betting.read_timeout = 32```

*Tags: Strategies*

---

**JK** - *08:20:18*

i tried doing `client.betting.read_timeout = 45` where client is an `APIClient` object, but that returned

```Error: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-05191058-003bfd', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-05191058-003d', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}```

*Tags: Errors Debugging, Strategies*

---

**Mo** - *08:20:25*

The timeout will help, whether it's enough will depend on your level of betting activity

*Tags: Strategies*

---

**Newbie99** - *15:55:07*

Placing a single bet, I just got back an Error Code of 'ERROR_IN_ORDER', which is a fairly common one to see, but normally it is because another order has an 'INVALID_BET_SIZE' or something along those lines.



In this case however, that was the only error code (and it was just the lone bet)...looking at the timestamp it was sent just before the market was suspended (i.e. I received a market_book update @ 15:27:16.626763, with the next one coming @ 15:27:16.721394, showing it had been suspended (the place order instruction was sent just before the update).



Is that error consistent with the bet being rejected due to a market being suspended (I'm assuming this is correct behaviour, but just wanted to check due to the non-descriptive error message)?

*Tags: Errors Debugging*

---

**liam** - *16:30:40*

Yeah this can sometimes happen, gave up trying to get betfair to fix 

*Tags: Errors Debugging*

---

## 2020-06-23

**Paul Smith** - *02:25:40*

[@UFTBRB3F1](@UFTBRB3F1) whenever you get back a ERROR_IN_ORDER there should always be an accompanying reason.  This could be INVALID_BET_SIZE or MARKET_SUSPENDED, etc.  You need to check the reasn for the error.  Sometimes it can be a late scratching that has been removed from the market and you have updated your list of selections to see this change.

*Tags: Errors Debugging*

---

## 2020-06-26

**D C** - *15:47:24*

Afternoon all. Are any of you noticing sticky streaming API in-running today. I have had bad examples at Doncaster 14:25 and 15:25 where there are no price updates for in excess of 4 seconds - right at the closing stage of the race. Anyone else seeing this? I am getting heartbeat so I know I am still connected to the server but no price updates are getting sent.

*Tags: Deployment*

---

**D C** - *15:52:03*

Didnt notice any issue yesterday. Any idea if this is confined to streaming or is NG having issues too?

*Tags: General Technical*

---

**Jonatan (skyw)** - *15:56:05*

How does this manifest itself except from, "it should've been more messages", are messages conflated or are there delay, or that downstream error present?

*Tags: Errors Debugging*

---

**D C** - *15:57:42*

No errors-  just no orders matched (or none reported)

*Tags: Errors Debugging*

---

**D C** - *16:07:53*

6 seconds at the death of an in-running race with no orders matched and no orders placed or cancelled? At the very least you would expect the tracksiders to be hammering away. Not saying that orders are not getting placed and filled, just that the stream has stuck and has either not reported them or has delayed reporting them. Until I can check my NG bots I can't tell if this is a pure streaming issue or a generic problem with order submission. Maybe someone else will notice it by then

*Tags: General Technical*

---

**Jonatan (skyw)** - *16:11:02*

Yeah I am not doubting there are a problem, just wonder if the stream fails to report them completely or if they are delayed.

Just to know what to keep an eye on.

*Tags: General Technical*

---

**D C** - *18:37:42*

[@U4H19D1D2](@U4H19D1D2) You had no issues at all with the streaming API ?

*Tags: General Technical*

---

## 2020-06-27

**Alex A** - *13:37:29*

How long do people find it normally takes to place a bet with async=true (from the Betfair api, not the bflw version)?

*Tags: General Technical*

---

**Lee** - *17:12:51*

is there a reason why i sometimes get the market catalogue response? my understanding was i'd get an error response if i was requesting too much data or calling too quickly. all 3 requests are the same

```&gt;&gt;&gt; trading.betting.list_market_catalogue(

    filter=filters.market_filter(

        event_type_ids=[7],

        market_countries=["GB"],

        market_type_codes=["WIN"],

        market_ids=["1.171017510"],

    ),

    market_projection=["RUNNER_METADATA"],

)

[]

&gt;&gt;&gt; trading.betting.list_market_catalogue(

    filter=filters.market_filter(

        event_type_ids=[7],

        market_countries=["GB"],

        market_type_codes=["WIN"],

        market_ids=["1.171017510"],

    ),

    market_projection=["RUNNER_METADATA"],

)

[&lt;MarketCatalogue&gt;]

&gt;&gt;&gt; trading.betting.list_market_catalogue(

    filter=filters.market_filter(

        event_type_ids=[7],

        market_countries=["GB"],

        market_type_codes=["WIN"],

        market_ids=["1.171017510"],

    ),

    market_projection=["RUNNER_METADATA"],

)

[]```

*Tags: Errors Debugging, Strategies*

---

## 2020-06-28

**Andrey Yunoshev** - *14:01:59*

```AU

PLACE ORDER BACK

INFO:flumine.order.order:Order status update: Pending

PLACE ORDER LAY

INFO:flumine.order.order:Order status update: Pending

INFO:flumine.markets.blotter:1 order packages created

	BACK/PENDING 0.0 price, 0.0 size

	LAY/PENDING 0.0 price, 0.0 size

INFO:flumine.execution.betfairexecution:execute_place

INFO:flumine.order.trade:Trade status update: Pending

INFO:flumine.execution.baseexecution:Order Place: SUCCESS

INFO:flumine.order.order:Order status update: Executable

INFO:flumine.order.trade:Trade status update: Live

INFO:flumine.order.trade:Trade status update: Pending

INFO:flumine.execution.baseexecution:Order Place: SUCCESS

INFO:flumine.order.order:Order status update: Executable

INFO:flumine.order.trade:Trade status update: Live

INFO:flumine.order.order:Order status update: Execution complete

INFO:flumine.order.trade:Trade status update: Complete

REPLACE PRICE, FROM 4.0 TO 3.7

INFO:flumine.order.order:Order status update: Replacing

	BACK/REPLACING 0.0 price, 0.0 size

	LAY/EXECUTION_COMPLETE 3.7 price, 2.16 size

INFO:flumine.markets.blotter:1 order packages created

INFO:flumine.execution.betfairexecution:execute_replace

INFO:flumine.order.trade:Trade status update: Pending

INFO:flumine.execution.baseexecution:Order Cancel: SUCCESS

INFO:flumine.order.order:Order status update: Execution complete

INFO:flumine.execution.baseexecution:Order Replace: SUCCESS

INFO:flumine.order.order:Order status update: Pending

INFO:flumine.order.order:Order status update: Executable

INFO:flumine.order.trade:Trade status update: Live

INFO:flumine.streams.orderstream:Stopped OrderStream 1001

INFO:flumine.streams.marketstream:Stopped MarketStream 2001

INFO:flumine.streams.marketstream:Stopped output_thread (MarketStream 2001)

INFO:flumine.execution.baseexecution:Shutting down Execution (SimulatedExecution)

INFO:flumine.execution.baseexecution:Shutting down Execution (BetfairExecution)

INFO:flumine.streams.orderstream:Stopped output_thread (OrderStream 1001)

INFO:flumine.baseflumine:Exiting flumine

Traceback (most recent call last):

  File "./pydogs/greyscout2live.py", line 727, in &lt;module&gt;

    framework.run()

  File "/usr/local/lib/python3.7/site-packages/flumine/flumine.py", line 32, in run

    self._process_current_orders(event)

  File "/usr/local/lib/python3.7/site-packages/flumine/baseflumine.py", line 183, in _process_current_orders

    strategy_orders = market.blotter.strategy_orders(strategy)

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/blotter.py", line 27, in strategy_orders

    return [order for order in self if order.trade.strategy == strategy]

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/blotter.py", line 27, in &lt;listcomp&gt;

    return [order for order in self if order.trade.strategy == strategy]

RuntimeError: dictionary changed size during iteration```

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *14:04:53*

Haven’t seen this before, can you create a GitHub issue and I will try and fix 

*Tags: Errors Debugging*

---

**Andrey Yunoshev** - *14:08:08*

[https://github.com/liampauling/flumine/issues/221](https://github.com/liampauling/flumine/issues/221)

*Tags: General Technical*

---

## 2020-06-29

**Dylan** - *10:38:12*

Hey! fairly new to the project however, I'm getting a SUBSCRIPTION_LIMIT_EXCEEDED error, would the assumption be that my filters are too broad? What controls this?

```ERROR:betfairlightweight.streaming.listener:[Subscription: 1] SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 345 markets whereas max allowed number was: 200

INFO:betfairlightweight.streaming.listener:[Subscription: 1]: FAILURE (1 connections available)



#main.py

market_filter = streaming_market_filter(

    event_type_ids=["7"], country_codes=["AU"], market_types=["WIN"]

)

market_data_filter = streaming_market_data_filter(

    fields=["EX_MARKET_DEF"], ladder_levels=3

)```

*Tags: Getting Started, Errors Debugging*

---

**Dylan** - *10:45:09*

will betfairlightweight track all AUS markets even outside the event?

*Tags: General Technical*

---

**Andrey Yunoshev** - *10:46:45*

```        market_filter=streaming_market_filter(

            event_type_ids=["4339"],

            market_types=["WIN"],

            bsp_market=True,

            turn_in_play_enabled=False,

            # country_codes=["AU"],

            # country_codes=["GB"],

            # betting_types=["ODDS"],

            country_codes=["AU", "GB", "US"],

        ),```

*Tags: Strategies*

---

**Andrey Yunoshev** - *10:53:27*

multiple stream not help in case flumine

*Tags: General Technical*

---

**liam** - *10:54:22*

well you could just duplicate the strategy with a different stream per

*Tags: Strategies*

---

**D C** - *13:12:15*

Inplay near the end. I was getting a best back price of 2.86 when the best lay price was 1.01. Could be an error in my GUI but I have not seen this before

*Tags: Errors Debugging*

---

**liam** - *18:27:17*

Looks like a fix was deployed this morning so it is now at least consistent  [@U0131E2H1SP](@U0131E2H1SP) [https://forum.developer.betfair.com/forum/developer-program/announcements/32066-retrospective-api-release-to-prevent-minimum-bet-abuse-19th-june|https://forum.developer.betfair.com/forum/developer-program/announcements/32066-retrospective-api-release-to-prevent-minimum-bet-abuse-19th-june](https://forum.developer.betfair.com/forum/developer-program/announcements/32066-retrospective-api-release-to-prevent-minimum-bet-abuse-19th-june|https://forum.developer.betfair.com/forum/developer-program/announcements/32066-retrospective-api-release-to-prevent-minimum-bet-abuse-19th-june)

*Tags: Errors Debugging, Deployment*

---

## 2020-06-30

**LK** - *11:56:26*

the market in question does not seem to exist on betfair, yet it was streamed

*Tags: General Technical*

---

**LK** - *11:59:57*

not sure how to reach them about something like this.

*Tags: General Technical*

---

**Dave Simonds** - *20:52:18*

I think i remember seeing somewhere in the documentation that its OK to do if its for greening up.



you’re right, it is a hack but the only legitimate way you can green-up if only 50p of a larger steak gets matched

*Tags: General Technical*

---

## 2020-07-01

**Andrey Yunoshev** - *12:14:38*

[@U4H19D1D2](@U4H19D1D2) the new one 'RuntimeError: dictionary changed size during iteration'  [https://github.com/liampauling/flumine/issues/228](https://github.com/liampauling/flumine/issues/228)

*Tags: Errors Debugging*

---

**Martin Johansson** - *17:54:24*

LoginError: API login: AUTHORIZED_ONLY_FOR_DOMAIN_SE

*Tags: Errors Debugging*

---

## 2020-07-03

**liam** - *08:05:39*

This should have been fixed in v1.8.0 with the other bug, have you tried upgrading?

*Tags: Errors Debugging*

---

**Jonatan (skyw)** - *10:31:09*

If it this solution and it is as I asked above I still don't think it's fixed correctly 

[https://github.com/liampauling/flumine/commit/bc532c5b5cc3392b07d057b4e269826ced8b742f|https://github.com/liampauling/flumine/commit/bc532c5b5cc3392b07d057b4e269826ced8b742f](https://github.com/liampauling/flumine/commit/bc532c5b5cc3392b07d057b4e269826ced8b742f|https://github.com/liampauling/flumine/commit/bc532c5b5cc3392b07d057b4e269826ced8b742f)

*Tags: Errors Debugging*

---

**liam** - *10:36:18*

I see what you are saying, quick google and it says lists are thread safe [https://stackoverflow.com/questions/6319207/are-lists-thread-safe](https://stackoverflow.com/questions/6319207/are-lists-thread-safe)

*Tags: General Technical*

---

**Alex A** - *19:15:30*

They’ve now fixed and released this.

*Tags: Errors Debugging*

---

## 2020-07-06

**birchy** - *22:51:15*

~Hi All,~

~"errorMessage":"AppKey is not configured for service"~

~Have been running bots for years but only just getting into streaming. Any ideas?~

Scratch that! I have a main account and a sub-account. Turns out that my main account is enabled for streaming but sub-account isn't.

*Tags: Errors Debugging*

---

## 2020-07-08

**liam** - *16:00:28*

This should now be fixed, from Neil:



_market definition issue was fixed as part of a release on Friday evening (3rd July)._

*Tags: Errors Debugging*

---

## 2020-07-11

**Unknown** - *12:11:57*

Whats the best approach to dealing with a socket error? Delete the current subscription and create a new one?

*Tags: Errors Debugging*

---

**liam** - *12:31:41*

[https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)

*Tags: General Technical*

---

## 2020-07-14

**liam** - *11:04:18*

_While we have snapshots disabled (for performance reasons), this will happen whenever we do a release or restart. This is a defect that we have listed to fix at a future date._



_In the meantime, the dev team will look at an alternative solution e.g. excluding closed markets from the initial image._

*Tags: Errors Debugging, Performance*

---

## 2020-07-21

**JC** - *11:50:09*

When working with the inplayservice endpoint in bflw, if I don't set `_lightweight_=True` for my trading instance, the JSON response returned triggers an InvalidResponse exception (I think due to single quotes being used for strings instead of double?). Not sure if I'm missing something here. Also when working with the scores API for tennis, `trading.scores.list_available_events()` returns an empty list. Not sure if this is because my key isn't authorised or whether there actually are no matches on the scores API atm lol.

*Tags: Errors Debugging, Strategies*

---

## 2020-07-23

**PeterLe** - *09:59:01*

Morning folks

A quick question please

Ive just added three new sub accounts (ie in addition to other sub accounts i have under the master account) and wanting to create the keys.

I log into the first new account, open a new chrome tab and then navigate to API Account operations. I can see the SSIOD OK.

I click on createDeveloperAppKeys and then adjacent I type in the account user name into the text box "Application Name"

When i click "Execute" I get an error "Exception in response: Exception: AccountAPINGException Error Code: UNEXPECTED_ERROR Error details: "

Ive got other sub acounts and i dont recall having an issues when I set them up?

(I appreciate that the Application Name has to be unique).

I just wondered if anyone had any ideas please? (Maybe the sub accounts have to be verified before you can create keys etc?) I could contact Neil, but dont want to bother him if Im doing something stupid!

Thanks in advance

Peter

*Tags: Errors Debugging*

---

**Mo** - *10:00:55*

Application name needs to be _globally_ unique. Not necessarily your problem but that tripped me up on the last subaccount I created 

*Tags: Multi Client*

---

**liam** - *10:04:50*

Have you tried another name? I had the same problem and I think it was to do with either the length or the addition of special chars

*Tags: General Technical*

---

**PeterLe** - *10:08:23*

No I havent Liam. My other accounts (which work fine) are all the same name with the exception of the last digit. Id like to keep them using the same naming convention if poss. Ive dropped Neil an email now so Ill see what he can suggest. Thanks for the help gents.

*Tags: Errors Debugging*

---

**Michael** - *11:59:18*

I had the same problem, in my case I think it was because I was trying to use the account login name as the application name.

*Tags: General Technical*

---

**Michael** - *12:01:05*

Either way a change in name fixed it

*Tags: Errors Debugging*

---

**Mo** - *12:03:25*

Now that you mention it, I think that was my problem as well

*Tags: General Technical*

---

**Mo** - *12:04:58*

Yeah, checking my notes that was indeed the problem

*Tags: General Technical*

---

**Andrey Yunoshev** - *12:31:46*

I always (around each 10 min) have warning "latency high", at home and at ec2 Ireland also. Its is normal?

*Tags: Performance, Deployment*

---

**Andrey Yunoshev** - *12:37:54*

thanks, I dont see any spike, but I will try ec2 instance with 2 vcpu

*Tags: Deployment*

---

**PeterLe** - *12:49:05*

[@UBS7QANF3](@UBS7QANF3), [@U4H19D1D2](@U4H19D1D2) [@UGV299K6H](@UGV299K6H) API keys sorted now; yes I made the exact same mistake; i used the Username as the application name

All sorted now!

Lets hope i can make good use of the new accounts! :grinning:

Great community; thanks for help guys

*Tags: General Technical*

---

**liam** - *12:50:38*

[@U013R0E7SUV](@U013R0E7SUV) you must have some sort of memory leak, without seeing the code it will be hard to debug but bflw streaming code shoudln't be the cause

*Tags: Errors Debugging, Performance*

---

**Andrey Yunoshev** - *12:55:06*

I mostly thinking about betfair API itself

*Tags: General Technical*

---

## 2020-07-24

**Andrey Yunoshev** - *09:14:46*

[@U4H19D1D2](@U4H19D1D2) as you have time, I trying profile my using flumine, and found - [https://monosnap.com/file/7jWykosfQKwxtyAwNlIMKI5DNkKvU6](https://monosnap.com/file/7jWykosfQKwxtyAwNlIMKI5DNkKvU6) - most of time using blotter process_orders function. look like wired? this is not ok, right?

*Tags: General Technical*

---

**Andrey Yunoshev** - *09:17:14*

flumine-1.10.1

*Tags: General Technical*

---

**liam** - *09:43:46*

confused as to why that is being called so many times, hard to debug without seeing code which obviously might be tricky without revealing your strategies

*Tags: Errors Debugging*

---

**Andrey Yunoshev** - *09:55:02*

also look like `INFO:flumine.baseflumine:Market closed` spamed too much, not like it really happens

*Tags: General Technical*

---

**Jon** - *13:59:59*

hi, is a noob question okay?

*Tags: General Technical*

---

**Mo** - *14:08:36*

I think someone shared such a thing in the past but you won’t be able to find it because of limited history on Slack. 



We intend to add recipes like this to the documentation but there isn’t one yet. 



In the meantime, look at the `.ex` field on each runner and the `.availableToBack` and `.availableToLay` fields on that

*Tags: General Technical*

---

**Jon** - *14:20:08*

and also when i iterate with something like

    `best_lay_sizes = [runner_book.ex.available_to_lay[0].size`

                      `if runner_book.ex.available_to_lay[0].size`

                      `else 1.01`

                      `for runner_book`

                      `in runner_books]`

i get

```AttributeError: 'NoneType' object has no attribute 'available_to_back'```



*Tags: Errors Debugging*

---

**Jon** - *14:23:23*

i'm a total noob at python so i don't even know how to examine this [&lt;MarketBook&gt;] thing

*Tags: General Technical*

---

**Mo** - *14:24:09*

What IDE are you using? I'd recommend PyCharm and you can use the debugger to inspect the MarketBook object

*Tags: Errors Debugging*

---

**Mo** - *14:32:31*

Also you can read the package source code on GitHub: [https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py#L542](https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py#L542)

*Tags: Strategies*

---

**Jon** - *14:33:59*

actually it seems the bf visualizer is helpful for seeing the structure of objects: [https://docs.developer.betfair.com/visualisers/api-ng-sports-operations/](https://docs.developer.betfair.com/visualisers/api-ng-sports-operations/)

*Tags: General Technical*

---

**Michael** - *14:40:13*

Not that I'm in any position to teach anyone Python... but here goes: If you just want to know what attributes and object has you can print [d for d in dir(MarketBook) if not d.startswith('__')]

*Tags: General Technical*

---

**Jon** - *14:40:41*

```---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-234-4f4cb3a4297e&gt; in &lt;module&gt;

      3 )

      4 

----&gt; 5 market_book_to_data_frame(market_books)



&lt;ipython-input-232-a1a850e150a8&gt; in market_book_to_data_frame(market_book)

     15             'size': price_size['size']

     16         }

---&gt; 17         for runner in market_book['runners']

     18         for side in ['Back', 'Lay']

     19         for depth, price_size in enumerate(runner.get('ex', {}).get(f'availableTo{side}', []))



TypeError: list indices must be integers or slices, not str```

*Tags: Errors Debugging*

---

**Jon** - *14:42:26*

thanks. okay now get no error but just blank output

*Tags: Errors Debugging*

---

**Jon** - *14:47:19*

`# Create a price filter. Get all traded and offer data`

`price_filter = betfairlightweight.filters.price_projection(`

    `price_data=['EX_BEST_OFFERS']`

`)`



`market_books = trading.betting.list_market_book(`

    `market_ids=['1.171523770'],`

    `price_projection=price_filter`

`)`



`market_book_to_data_frame(market_books[0])`

*Tags: Strategies*

---

**Jon** - *14:47:51*

i get

```---------------------------------------------------------------------------

KeyError                                  Traceback (most recent call last)

&lt;ipython-input-252-bb440a3eeded&gt; in &lt;module&gt;

     10 )

     11 

---&gt; 12 market_book_to_data_frame(market_books[0])



&lt;ipython-input-235-a1a850e150a8&gt; in market_book_to_data_frame(market_book)

     15             'size': price_size['size']

     16         }

---&gt; 17         for runner in market_book['runners']

     18         for side in ['Back', 'Lay']

     19         for depth, price_size in enumerate(runner.get('ex', {}).get(f'availableTo{side}', []))



C:\ProgramData\Anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy)

    467         elif isinstance(data, abc.Iterable) and not isinstance(data, (str, bytes)):

    468             if not isinstance(data, (abc.Sequence, ExtensionArray)):

--&gt; 469                 data = list(data)

    470             if len(data) &gt; 0:

    471                 if is_list_like(data[0]) and getattr(data[0], "ndim", 1) == 1:



&lt;ipython-input-235-a1a850e150a8&gt; in &lt;genexpr&gt;(.0)

     17         for runner in market_book['runners']

     18         for side in ['Back', 'Lay']

---&gt; 19         for depth, price_size in enumerate(runner.get('ex', {}).get(f'availableTo{side}', []))

     20     )



KeyError: 'publishTime'```



*Tags: Errors Debugging, Feature Engineering*

---

**Jon** - *14:48:33*

```&lt;ipython-input-241-74dcdf18ad7c&gt; in &lt;listcomp&gt;(.0)

      8                         if runner_book.ex.available_to_back[0].price

      9                         else 1.01

---&gt; 10                         for runner_book

     11                         in runner_books]

     12     best_back_sizes = [runner_book.ex.available_to_back[0].size



IndexError: list index out of range```



*Tags: Errors Debugging*

---

**Mo** - *14:49:01*

My bad, I based my code on streaming data

*Tags: General Technical*

---

**Jon** - *14:49:08*

don't get how there can be an index error when just doing a for ... in

*Tags: Errors Debugging*

---

**liam** - *15:01:46*

Or wrap it in a function and forgot about it [https://github.com/liampauling/flumine/blob/4de6cdfeb6aa1a1a12f25a87bc9db176efa18985/flumine/utils.py#L90|https://github.com/liampauling/flumine/blob/4de6cdfeb6aa1a1a12f25a87bc9db176efa18985/flumine/utils.py#L90](https://github.com/liampauling/flumine/blob/4de6cdfeb6aa1a1a12f25a87bc9db176efa18985/flumine/utils.py#L90|https://github.com/liampauling/flumine/blob/4de6cdfeb6aa1a1a12f25a87bc9db176efa18985/flumine/utils.py#L90)

*Tags: General Technical*

---

**Jon** - *15:05:53*

i can't find anywhere that explains how to get additional data with trading.betting.list_market_catalogue

*Tags: Strategies*

---

**Jon** - *15:08:25*

i.e. how to get runner names

*Tags: General Technical*

---

**Jon** - *15:29:07*

this seems to work:

`market_catalogue_filter = betfairlightweight.filters.market_filter(market_ids=[id])`



`market_catalogues = trading.betting.list_market_catalogue(`

    `filter=market_catalogue_filter,`

    `market_projection=[`

        `"RUNNER_DESCRIPTION"`

        `],`    

`)`



`# Create a DataFrame containing runners for the market catalogue`

`golf_runners_df = pd.DataFrame({`

    `'Selection ID': [runner.selection_id for runner in market_catalogues[0].runners],`

    `'Runner Name': [runner.runner_name for runner in market_catalogues[0].runners],`

`})`

*Tags: Feature Engineering, Strategies*

---

**Jon** - *15:29:23*

thank you so much everyone, now just to work out how to merge the dataframes :slightly_smiling_face:

*Tags: Feature Engineering*

---

## 2020-07-25

**Mark** - *10:49:14*

Happy weekend chaps!

I've been using the examplestreaminghistorical.py from BFLW to run through some of the historical data files offered by Betfair recently. It's been working great.. except when I run through a Greyhound file where a reserve runner replaces the original. This seems to happen at least once per meeting and the whole thing chokes.



I haven't touched anything except the location of each data file (obviously!) According to the Traceback, it's tripping up over a number of processes and I haven't a clue where to start.



I've updated BFLW to 2.6.0 and I'm using the out-of-the-box examplestreaminghistorical.py without modification.



Has anyone else come across the same thing and can point me in the right direction? Cheers!



```Traceback (most recent call last):

  File "G:/python/scratchpad/examplestreaminghistorical.py", line 34, in &lt;module&gt;

    for market_books in gen():

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 326, in _read_loop

    if self.listener.on_data(update) is False:

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\listener.py", line 127, in on_data

    self._on_change_message(data, unique_id)

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\listener.py", line 167, in _on_change_message

    self.stream.on_update(data)

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\stream.py", line 59, in on_update

    self._process(data[self._lookup], publish_time)

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\stream.py", line 152, in _process

    market_book_cache.create_resource(

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\cache.py", line 218, in create_resource

    data = self.serialise

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\cache.py", line 267, in serialise

    "runners": [

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\cache.py", line 269, in &lt;listcomp&gt;

    self.market_definition_runner_dict[

KeyError: (27395886, 0)



Process finished with exit code 1```

*Tags: Data Quality, Errors Debugging*

---

## 2020-07-27

**liam** - *08:48:29*

here is the fix, see commit message for details [https://github.com/liampauling/betfair/pull/322/commits/4e173b4b22e01f18dbf8e7703de9b6c702950152](https://github.com/liampauling/betfair/pull/322/commits/4e173b4b22e01f18dbf8e7703de9b6c702950152)

*Tags: Errors Debugging*

---

**liam** - *09:01:44*

[https://github.com/liampauling/betfair/pull/323|2.7.0](https://github.com/liampauling/betfair/pull/323|2.7.0) ready to go today, anything else need to be fixed?

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:42:21*

I get this issue running the tests for Flumine:



  `File "/home/jon/PycharmProjects/flumine/flumine/streams/historicalstream.py", line 70, in snap`

    `cache.create_resource(self.unique_id, None, self._lightweight)`

`TypeError: create_resource() takes 3 positional arguments but 4 were given`



I have master branches from betfairlightweight and flumine on my computer.



Do I need to checkout specific versions to make it work?

*Tags: Errors Debugging*

---

**birchy** - *22:44:59*

Just a thought...but would it be worth using a credentials file for storing login username, password, app key, certs path, etc? It's common to have ~/.aws/credentials, ~/.ssh/config, etc so why not ~/.betfair/credentials? Could also put the certs folder in .betfair and the relative path in the credentials file. Saves putting sensitive info in the .py files and avoids accidentally publishing account info on github/etc. And before you ask...No...I haven't done that. :joy:

*Tags: Deployment*

---

## 2020-07-28

**Unknown** - *02:22:13*

shouldnt the "flumine" be "framework". ([https://liampauling.github.io/flumine/quickstart/](https://liampauling.github.io/flumine/quickstart/))

*Tags: General Technical*

---

**liam** - *08:22:54*

[@UPMUFSGCR](@UPMUFSGCR) haven't upgraded flumine to handle 2.7.0 yet so will need to use 2.6.0

*Tags: General Technical*

---

**liam** - *08:32:42*

[https://github.com/liampauling/flumine/pull/245](https://github.com/liampauling/flumine/pull/245)

*Tags: General Technical*

---

**liam** - *09:24:15*

[@U016TGY3676](@U016TGY3676) bflw is currently setup to use env vars and up to the user to handle how its used, I guess its personal preference but there is no reason you can't override the client to use a config file. It's probably a bit late in the day to move to using a config file only like aws which means we would have the added complication of handling both but open to thoughts

*Tags: Getting Started, Deployment*

---

**mlpanda** - *11:52:52*

Hey, perhaps a simple question but can't seem to find an answer to it; when I obtain the `marketId` for the next horse race using:



```def getMarketCatalogueForNextGBWin(eventTypeID):

    if (eventTypeID is not None):

        print ('Calling listMarketCatalouge Operation to get MarketID and selectionId')

        now = datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ')

        market_catalogue_req = '{"jsonrpc": "2.0", "method": "SportsAPING/v1.0/listMarketCatalogue", "params": {"filter":{"eventTypeIds":["' + eventTypeID + '"],"marketCountries":["GB"],"marketTypeCodes":["WIN"],'\

                                                                                                                                                             '"marketStartTime":{"from":"' + now + '"}},"sort":"FIRST_TO_START","maxResults":"1","marketProjection":["RUNNER_METADATA"]}, "id": 1}'```

How can I then get the corresponding `eventId` and `raceId` for that given `marketId`?

*Tags: General Technical*

---

**liam** - *12:07:08*

[@UF3AYKZMW](@UF3AYKZMW) its much easier using bflw :slightly_smiling_face: [https://github.com/liampauling/betfair/blob/master/examples/exampleone.py](https://github.com/liampauling/betfair/blob/master/examples/exampleone.py)

*Tags: General Technical*

---

**mlpanda** - *15:26:27*

Any suggestions why this code snippet



```market_catalogues = trading.betting.list_market_catalogue(

    filter=filters.market_filter(

        event_type_ids=["7"],  # filter on just horse racing

        market_countries=["GB"],  # filter on just GB countries

        market_type_codes=["WIN"],  # filter on just WIN market types

    ),

    market_projection=[

        "MARKET_START_TIME",

        "RUNNER_DESCRIPTION",

        "EVENT",

    ],  # runner description required

    max_results=100,

)```

gives me the error



`Exception: Timeout value connect was (3.05, 16), but it must be an int or float.`



It's rather strange as it works on my local mac, but when I run it on an EC2 instance in AWS (location: London) it fails with the above message. I'm also located in London locally, so seems odds.



Any suggestions would be very much appreciated :)

*Tags: Errors Debugging, Deployment, Strategies*

---

**Aaron** - *15:46:57*

uninstall and reinstall requests on your im assuming ubuntu EC2 instance. Few threads on SO indicate this may be the fix

*Tags: Getting Started, Errors Debugging, Deployment*

---

**mlpanda** - *17:56:24*

Hey again, I was wondering if you know how to get the aggregate liability on a specific selectionid? It is a bit slow to fetch all trades and sum up the matched amount when the number of trades grow quite fast (testing some market making). Is there any endpoint for that?

*Tags: Performance*

---

**Mo** - *18:08:56*

Right. You might find it easier to deal with a large number of orders using streaming 

*Tags: General Technical*

---

## 2020-07-29

**Lee** - *08:18:59*

Can i ignore these occasional SocketErrors in flumine? `SocketError: [Connect: 2002]: Socket [Errno 104] Connection reset by peer"`

*Tags: Errors Debugging*

---

**L** - *09:47:58*

I have been getting these errors intermittently as well and have been ignoring them

*Tags: Errors Debugging*

---

**Newbie99** - *09:50:12*

Has anyone ever seen this?



When replacing I get this error (very occasionally):

*Tags: Errors Debugging*

---

**Newbie99** - *09:50:18*

```

Replace Error: RELATED_ACTION_FAILED

Exception in thread Thread-1:

Traceback (most recent call last):

  File "/usr/lib64/python3.7/threading.py", line 926, in _bootstrap_inner

    self.run()

  File "/usr/lib64/python3.7/threading.py", line 870, in run

    self._target(*self._args, **self._kwargs)

  File "racing.py", line 568, in combined_queue

    replaced_orders_report = rf.replace_orders(market_id, replace_list, market_info, trading, filters)

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 1941, in replace_orders

    'selection_id': place_instruction_report.instruction.selection_id,

AttributeError: 'NoneType' object has no attribute 'selection_id'```

*Tags: Errors Debugging, Deployment, Strategies*

---

**Newbie99** - *09:50:48*

The error just suggests the instruction somehow isn't populated for the report

*Tags: Errors Debugging*

---

**Newbie99** - *09:51:17*

I couldn't find a 'RELATED_ACTION_FAILED' error code in the docs

*Tags: Errors Debugging*

---

## 2020-07-30

**Unknown** - *12:43:24*

I think I have been looking at this too long, can someone spot my error? it is something to do with the marketStartTime filter parameter - Resolved thanks -



I forgot the T and Z in the datetime format i.e ("%Y-%m-%d*T*%H:%M:%S*Z*")

*Tags: Errors Debugging*

---

**birchy** - *12:58:11*

I also regularly find the answer just after I posted the question. :grinning:

*Tags: General Technical*

---

**Twatter** - *13:09:56*

[@U016535QCJ2](@U016535QCJ2) Hahaha - I should try that... "I'm struggling to make loadsa money out of this betfair strategy... can anyone spot the mistake in it?"

*Tags: Strategies*

---

**Mo** - *13:11:00*

If it makes you feel any better, I spent a long time looking at it to try to help and I didn’t spot the problem

*Tags: General Technical*

---

**mlpanda** - *22:27:12*

Hey, has anyone had the issue of receiving an empty list when using the historical data example in betfair lightweight: [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py)



In `my_data` I have the following data purchased:

`{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-05-01T00:00:00', 'purchaseItemId': 48406}`



But when I use the following function:

```# get file list

file_list = trading.historic.get_file_list(

    "Horse Racing",

    "Advanced Plan",

    from_day=1,

    from_month=5,

    from_year=2020,

    to_day=31,

    to_month=5,

    to_year=2020,

    market_types_collection=["WIN", "PLACE"],

    countries_collection=["GB", "IE"],

    file_type_collection=["M"],

)

print(file_list)```

I get an empty list in `file_list`. If I try to expand the dates to e.g. `to_month=6` I get an error (probably because I haven't purchased data for June), but I'm puzzled why I get an empty list for the above example.

*Tags: Data Quality, Errors Debugging, Strategies*

---

## 2020-08-02

**birchy** - *21:41:02*

Not sure if it was intentional or just overlooked, but flumine utils.py is short on function comments. Would be good to make this more friendly for beginners. Also, are there any plans to add other simple functions such as vwap, sma, wom, etc?

*Tags: Getting Started*

---

## 2020-08-06

**Josh** - *17:59:51*

[@U4H19D1D2](@U4H19D1D2) Are you still seeing segfaults from ujson? I noticed your comment on a github issue on the ujson repo back on June 17th. I started to run into the same thing on v3.0.0. Not sure if 3.1.0 fixes it or maybe you've just gone back to the stdlib json module.

*Tags: Errors Debugging*

---

**Mo** - *19:42:56*

Understandable. Well if someone can find one then I can take a look at trying to fix it

*Tags: Errors Debugging*

---

**Dave** - *20:13:18*

I managed to avoid the segfaults I was getting by downgrading ujson. Can't remember which version to, sorry :( [https://betfairlightweight.slack.com/archives/C4H05ML2E/p1589528696364100](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1589528696364100)

*Tags: General Technical*

---

**liam** - *20:19:00*

I think I might have to do that with bflw, how did you get it to print so much info about the error? MarketCatalogue race market :+1:

*Tags: Errors Debugging*

---

**Josh** - *20:23:08*

I tried deserializing all of the market catalogues and market books from a session where I saw a segfault that I had managed to write to disk and I couldn't reproduce it. I'm guessing the source must have been a call within bflw and the raw data that caused it was lost while still in memory.

*Tags: Performance*

---

**mlpanda** - *23:16:43*

Hey [@U4H19D1D2](@U4H19D1D2), first of all thanks for creating Flumine! I have so far used the backtesting module (and matched the results close enough to my own simple backtester) and I am now looking to use the paper trading functionality. I am currently looking at the example here: [https://github.com/liampauling/flumine/blob/7b50f7e8672c4c5e7c46ac5684617374f1e58c61/docs/quickstart.md](https://github.com/liampauling/flumine/blob/7b50f7e8672c4c5e7c46ac5684617374f1e58c61/docs/quickstart.md)

I don't really understand why the strategy is passed the path to a file rather than the streaming_market_filter() which is passed during live mode. I would expect  the paper trading to look exactly like the live mode except that the trades wouldn't be executed. Am I misunderstanding something here?

*Tags: Deployment, Strategies*

---

## 2020-08-07

**liam** - *09:03:09*

Ah yes that is incorrect, ignore the strategy part as it should be the same as live, the only change for paper trading is

```client = clients.BetfairClient(trading, paper_trade=True)```

*Tags: Deployment, Strategies*

---

**liam** - *09:03:33*

Btw easier to view the docs on the dedicated site [https://liampauling.github.io/flumine/quickstart/#paper-trading](https://liampauling.github.io/flumine/quickstart/#paper-trading)

*Tags: Strategies*

---

**mlpanda** - *17:58:52*

Hey, has anyone had issues with getting last_price_traded/total_matched through Flumine?

I am using the fields ["EX_ALL_OFFERS", "EX_MARKET_DEF", "EX_TRADED"] which should be sufficient, so I think the issue is related to login. Note that I do get the market_id, publish_time and selection_id.



For logging in, I have tried both interactive and non-interactive login. If I stop the run and try e.g. client._get_account_details() I do get an "INVALID_APP_KEY" error, however if I manually try to login with trading.login() it returns "SUCCESS".



I am using the app_key from [https://docs.developer.betfair.com/visualisers/api-ng-account-operations/](https://docs.developer.betfair.com/visualisers/api-ng-account-operations/) which historically has worked fine. I did notice that trading.login() returns a session_token which is different from the one in the link above. Any suggestions would be super helpful, thanks.

*Tags: Errors Debugging, Strategies*

---

**mlpanda** - *18:08:23*

Yes I am:



```trading = betfairlightweight.APIClient("username", "password", app_key="appkey")



client = clients.BetfairClient(trading, interactive_login=False, paper_trade=True)



framework = Flumine(client=client)```



*Tags: Strategies*

---

**Mo** - *18:46:23*

Yeah the documentation has some issues...

*Tags: General Technical*

---

**mlpanda** - *18:47:41*

You just saved me a stressful weekend of debugging wrong things :tada:

*Tags: Errors Debugging*

---

## 2020-08-08

**Ruben** - *15:17:26*

anyone ever got a "NO_SESSION" error when calling keep_alive()? after several successful keep_alive() calls

*Tags: Errors Debugging, Deployment*

---

## 2020-08-09

**liam** - *10:32:49*

This was a bug I thought I fixed, which version you using?

*Tags: Errors Debugging*

---

**liam** - *10:34:09*

Fixed in 1.10.5 in this commit [https://github.com/liampauling/flumine/commit/37ca7312707e7a66ac5776126354dee13829995b|https://github.com/liampauling/flumine/commit/37ca7312707e7a66ac5776126354dee13829995b](https://github.com/liampauling/flumine/commit/37ca7312707e7a66ac5776126354dee13829995b|https://github.com/liampauling/flumine/commit/37ca7312707e7a66ac5776126354dee13829995b)

*Tags: Errors Debugging*

---

**liam** - *10:35:14*

Ah bollocks, that fixes it for backtesting but not for paper trading 

*Tags: Errors Debugging, Strategies*

---

## 2020-08-11

**liam** - *20:03:42*

It depends on the market capacity and volatility as you would expect. I find on inplay racing it underplays the match rate compared to live which I prefer as it means I know that if I am breaking even or making profit backtesting then it’s time to get some money in the market.



With flumine you use the exact same strategy code live as you do backtesting so it also acts as a good integration test as well.

*Tags: Deployment, Strategies*

---

## 2020-08-12

**Lee** - *12:40:05*

I think i might not be understanding the MarketOnCloseOrder correctly. I'm trying to take SP just before going inplay but can't seem to get any money matched (flumine backtesting). I've removed my trigger and try to place an order on all runners and still get zero matched.

I've also set my strategy exposure high and not getting any voilation errors on the orders in the logs.

I'm creating an order using the following

```order = trade.create_order(

    side="BACK", order_type=MarketOnCloseOrder(liability=20)

)```

Any idea where i'm going wrong or if it's just a misunderstanding



here's a log too

```{"asctime": "2020-08-12 11:32:33,047", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.170576255", "selection_id": 19436243, "handicap": 0, "id": "138165247530344110", "customer_order_ref": "890b98c67ce74-138165247530344110", "bet_id": "100000000007", "trade": {"id": "83599e5e-dc8f-11ea-80ef-d45d6453ef52", "strategy": "xxxxxxx", "status": "TradeStatus.LIVE", "orders": ["138165247530344110"], "notes": "", "market_notes": "15.5,16,15.5"}, "order_type": {"order_type": "Market on close", "liability": 20}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Execution complete", "status_log": "Pending, Executable, Execution complete"}```

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *12:52:19*

Whats the market type, confident it has SP / it becomes reconciled? [https://github.com/liampauling/flumine/blob/master/flumine/backtest/simulated.py#L41](https://github.com/liampauling/flumine/blob/master/flumine/backtest/simulated.py#L41)

*Tags: General Technical*

---

**liam** - *12:54:08*

Can you see if `_process__sp` is being called via the debugger?

*Tags: Errors Debugging*

---

**liam** - *13:00:56*

I see the problem

*Tags: General Technical*

---

**liam** - *13:01:54*

[https://github.com/liampauling/flumine/blob/9a047934458899f4f452a10f9fa6375fd37a0ade/flumine/order/process.py#L59](https://github.com/liampauling/flumine/blob/9a047934458899f4f452a10f9fa6375fd37a0ade/flumine/order/process.py#L59)

*Tags: General Technical*

---

**liam** - *13:03:54*

or remove the status if on this line [https://github.com/liampauling/flumine/blob/9a047934458899f4f452a10f9fa6375fd37a0ade/flumine/markets/middleware.py#L121](https://github.com/liampauling/flumine/blob/9a047934458899f4f452a10f9fa6375fd37a0ade/flumine/markets/middleware.py#L121)

*Tags: General Technical*

---

**Lee** - *13:05:21*

cool i think i understand the problem, my first thought was i was misunderstanding the purpose of the order type

*Tags: General Technical*

---

## 2020-08-13

**Remi** - *12:23:21*

A few weeks ago I made a script to go through the account statements to evaluate performance for different markets etc. This is the call I am making:

```account_statement = Trading.account.get_account_statement(item_date_range=time_range(from_=from_date, to=to_date),

                                                                      from_record=from_counter)```

*Tags: Performance, Strategies*

---

**Remi** - *12:24:03*

Today I am getting the following error:

```betfairlightweight/resources/accountresources.py", line 88, in __init__

    self.legacy_data = LegacyData(**legacyData)

TypeError: __init__() missing 1 required positional argument: 'marketName'```

*Tags: Errors Debugging*

---

**Mo** - *12:27:58*

That would fix this problem but I guarantee you there are situations where other required fields are missing

*Tags: Errors Debugging*

---

## 2020-08-14

**mlpanda** - *17:59:39*

What is the error message? From looking at it, it looks fine - except I'm not sure whether the use of ' instead of " could cause an error. How about that you try with " everywhere

*Tags: Errors Debugging*

---

**Jono** - *18:05:30*

I will try using " everywhere to rule that out. Im constructing my own request just to try and understand what is going on at base level. bflw makes all the processes extremely headache free so obviously im not doing this testing for efficiency

*Tags: General Technical*

---

**Mo** - *18:06:07*

Seems a bit pointless. Use bflw and spend your extra time developing profitable strategies

*Tags: General Technical*

---

**Twatter** - *19:12:38*

[@U0154JA98TH](@U0154JA98TH) Try using Jsonlint to verify it... it doesn't like it since:

```Error: Parse error on line 6:

...nstructions": [{			'selectionId': '3789

----------------------^

Expecting 'STRING', '}', got 'undefined'```



*Tags: Errors Debugging*

---

## 2020-08-17

**liam** - *13:51:10*

Now [https://github.com/liampauling/flumine/commit/6b036f9a9e2bd92f927c739c6703ead90049f7a2|fixed](https://github.com/liampauling/flumine/commit/6b036f9a9e2bd92f927c739c6703ead90049f7a2|fixed) bug in the integration test meant it went unnoticed

*Tags: Errors Debugging*

---

## 2020-08-18

**qwerty.nat** - *00:33:56*

Just did a pip install flumine. filled in my login details in the example market recorder application to test all is ok.

`trading = betfairlightweight.APIClient(username="user",password="pass",app_key="slkfj", certs="/path/to/cert",lightweight=True)`

It fails after running for about 30 seconds,

`Traceback (most recent call last):`

  `File "marketrecorder.py", line 36, in &lt;module&gt;`

    `framework.run()`

  `File "/home/nathan/.local/lib/python3.8/site-packages/flumine/flumine.py", line 23, in run`

    `self._process_market_catalogues(event)`

  `File "/home/nathan/.local/lib/python3.8/site-packages/flumine/baseflumine.py", line 200, in _process_market_catalogues`

    `market = self.markets.markets.get(market_catalogue.market_id)`

`AttributeError: 'dict' object has no attribute 'market_id'`

If i set lightweight to False in the APIClient it all works without any error.

*Tags: Getting Started, Data Quality, Errors Debugging, Strategies*

---

**JojoBeans** - *22:58:25*

I keep getting the following error trying to run the example code

```SocketError: [Connect: 2]: Connection closed by server```

Any ideas on what could be causing it?

*Tags: Errors Debugging, Deployment*

---

## 2020-08-19

**JojoBeans** - *19:25:13*

Thanks for getting back! The code I'm running is from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



trading = betfairlightweight.APIClient(username, password, app_key=api_key)

trading.login_interactive()

betfair_socket = trading.streaming.create_stream()

market_filter = streaming_market_filter(

    event_type_ids=['29946086']

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_ALL_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=1

)



betfair_socket.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

)



betfair_socket.start()  # blocking

*Tags: Strategies*

---

**JojoBeans** - *19:25:36*

The output looks like

```---------------------------------------------------------------------------

SocketError                               Traceback (most recent call last)

&lt;ipython-input-48-10c95a06d625&gt; in &lt;module&gt;

     21 )

     22 

---&gt; 23 betfair_socket.start()  # blocking



~/anaconda3/envs/py36_new/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py in start(self)

     57             self._connect()

     58             self.authenticate()

---&gt; 59         self._read_loop()

     60 

     61     def stop(self) -&gt; None:



~/anaconda3/envs/py36_new/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py in _read_loop(self)

    200         """

    201         while self._running:

--&gt; 202             received_data_raw = self._receive_all()

    203             if self._running:

    204                 self.receive_count += 1



~/anaconda3/envs/py36_new/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py in _receive_all(self)

    232                     raise SocketError(

    233                         "[Connect: %s]: Connection closed by server"

--&gt; 234                         % (self._unique_id,)

    235                     )

    236                 else:



SocketError: [Connect: 2]: Connection closed by server```



*Tags: Errors Debugging, Deployment*

---

**liam** - *19:46:35*

Try with a listener like this example [https://github.com/liampauling/betfair/blob/master/examples/examplestreaming.py|https://github.com/liampauling/betfair/blob/master/examples/examplestreaming.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaming.py|https://github.com/liampauling/betfair/blob/master/examples/examplestreaming.py)

*Tags: General Technical*

---

**JojoBeans** - *20:38:51*

I've tried that and I seem to be further along but now I'm getting betfairlightweight.exceptions.ListenerError: connection_id: 107-190820193544-1162785, data: {"op":"status","id":2,"statusCode":"FAILURE","errorCode":"NOT_AUTHORIZED","errorMessage":"AppKey is not configured for service","connectionClosed":true,"connectionId":"107-190820193544-1162785"}

Thanks for all the help!

*Tags: Errors Debugging*

---

**liam** - *20:39:28*

You need to send an email to bdp and get your app key authorised for streaming 

*Tags: General Technical*

---

**JojoBeans** - *20:39:29*

I contacted to support to enable streaming (I'm on an old delayed key) and they said they did but perhaps not...

*Tags: General Technical*

---

## 2020-08-20

**Chris** - *00:23:53*

*Context:* New to using this package. Have a hopefully quick question regarding recording market data in a manner that is consistent with the Backtesting and Paper Trading components of Flumine.



*Narrow question*: Does anyone have the MarketRecorder data file that is referenced in the marketrecorder.py file located in the flumine examples? ([https://github.com/liampauling/flumine/blob/69d68904b4ae0c8ba3c0d60991c3a6a38066040d/examples/marketrecorder.py#L8](https://github.com/liampauling/flumine/blob/69d68904b4ae0c8ba3c0d60991c3a6a38066040d/examples/marketrecorder.py#L8))



*Broader question*: What is the standard data interface to ensure backtesting/paper trading works with Flumine?

An interface is alluded to in a few different places. One example is in the following code snippet at the following link:



...

trading = betfairlightweight.APIClient("username")

client = clients.BetfairClient(trading, paper_trade=True)

framework = Flumine(client=client)



strategy = ExampleStrategy(

    market_filter={"markets": [_*"/tmp/marketdata/1.170212754"*_]}

)

framework.add_strategy(strategy)

...



[https://liampauling.github.io/flumine/quickstart/#backtesting](https://liampauling.github.io/flumine/quickstart/#backtesting)

*Tags: Getting Started, Strategies*

---

**Unknown** - *08:32:24*

Hi [@U0198BFR9GR](@U0198BFR9GR), flumine ingests historical files either purchased from betfair or recorded yourself, there are [https://github.com/liampauling/flumine/tree/69d68904b4ae0c8ba3c0d60991c3a6a38066040d/tests/resources|two](https://github.com/liampauling/flumine/tree/69d68904b4ae0c8ba3c0d60991c3a6a38066040d/tests/resources|two) in the package itself used for the integration tests, however attached is the example I have used in that example. Paper trading uses live data but records orders / position locally.

*Tags: Deployment, Strategies*

---

## 2020-08-24

**birchy** - *22:35:12*

Any ideas why smart_open() can't open files saved with marketrecorder.py? I recently had issues getting backtesting running with self-recorded data but have had success using `.bz2` historical data acquired from Betfair. Turned out that there was nothing wrong with my original backtest code, but my recording code is shyte. :man-facepalming:



`def _zip_file(self, file_dir: str,`

    `market_id: str) -&gt; str:

    """zips txt file into filename.bz2"""

    zip_file_directory = os.path.join(

        self.local_dir,

        self.recorder_id,

        "%s.bz2" % market_id

    )

    with zipfile.ZipFile(

        zip_file_directory,

        mode="w"

    ) as zf:

        zf.write(

            file_dir,

            os.path.basename(file_dir),

            compress_type=zipfile.ZIP_BZIP2

        )

    return zip_file_directory`

*Tags: Data Quality*

---

## 2020-08-25

**Lee** - *13:12:09*

started getting the following exception

```  File "/Users/leeunsworth/git/sports-trading/.venv/lib/python3.7/site-packages/flumine/markets/middleware.py", line 63, in __call__

    self._process_simulated_orders(market, market_analytics)

  File "/Users/leeunsworth/git/sports-trading/.venv/lib/python3.7/site-packages/flumine/markets/middleware.py", line 125, in _process_simulated_orders

    order.simulated(market.market_book, runner_analytics)

  File "/Users/leeunsworth/git/sports-trading/.venv/lib/python3.7/site-packages/flumine/backtest/simulated.py", line 49, in __call__

    market_book.publish_time_epoch, runner_analytics.traded

AttributeError: 'NoneType' object has no attribute 'traded'```

*Tags: Errors Debugging, Strategies*

---

**Lee** - *13:31:56*

was just looking how to get the runner status in an efficient way

*Tags: General Technical*

---

**liam** - *13:43:03*

I would put it here [https://github.com/liampauling/flumine/blob/5c87ea49e1cc6feeb3e83655a3624fb359dadd1d/flumine/backtest/simulated.py#L58](https://github.com/liampauling/flumine/blob/5c87ea49e1cc6feeb3e83655a3624fb359dadd1d/flumine/backtest/simulated.py#L58)

*Tags: General Technical*

---

**Jono** - *14:48:17*

ill shoot any questions i have about the inplayservice response once ive got something up and running, cheers for the help!

*Tags: General Technical*

---

## 2020-08-26

**ricky** - *10:07:07*

I am using streaming API, for inplay football game, I am recording home game lay price,

Below is the snopshoot of what i got,



Lay price

...

2.54

2.54

280.0   --- unexplained high value

280.0   --- unexplained high value

2.64

2.64

...



During this time, market_book.status is "open", market_book inplay status is "True". ( no goal no card no threat at the time)



I need plot all lay price, have a peak data in the middle is not ideal, my question is what is the best way to filter this unexplained high value. (Of cource i want to avoid if a team is in big lead, in this case the price will be high )

*Tags: General Technical*

---

**ricky** - *10:48:51*

[@UBS7QANF3](@UBS7QANF3) what do you mean virtual price stream? before i used streaming, i previously pollling the data via lightweightAPI every 5 seconds, i remembered this peak data still occured.

*Tags: General Technical*

---

**birchy** - *11:23:14*

[@U0160KZB6QP](@U0160KZB6QP) check the traded volume as well. It's not uncommon to see a few spikes when someone with more money than sense gets deep into their martingale strategy. :grinning:

*Tags: Strategies*

---

**ricky** - *12:01:43*

All, I saw this happended in thinly traded market with total match around £90000, i was using bestAvailableToLay price value from "runner_book.ex.available_to_lay[0].price". My program continuous monitoring the traded volumn when the price variety, in this case the price change from 2.54 to 280.0 then back to 2.64, i didnt see traded volomn changed:joy:.

(its possible a bug in my program, but most case it was works ok)



Could anyone guide me how to get display price? Maybe i can compare the display price with virtual price.

*Tags: Errors Debugging*

---

**ricky** - *16:48:58*

I am using Live key in streaming, price and volumn got Instant updated, however i did not understand why both "runner.total_matched" and "runner.last_price_traded" alway return None?



My data filter setting:

market_data_filter = streaming_market_data_filter(

    fields=["EX_BEST_OFFERS", "EX_MARKET_DEF", "EX_TRADED"], ladder_levels=10

)

*Tags: Deployment*

---

## 2020-08-27

**Ruben** - *12:44:46*

Good morning, I was running the example marketrecorder.py, and it worked fine for ~20 minutes; then I started seeing "INVALID_SESSION_INFORMATION" errors in the log, that come from the "poll_market_catalogue()" method of the worker.py

*Tags: Errors Debugging*

---

## 2020-08-29

**jhaa** - *13:06:16*

I got a segmentation fault after running a bot using the streaming api for like half a day.



Never seen a SIGSEGV in python before.  I did not have the python faulthandler module enabled so I do not have a backtrace.

*Tags: General Technical*

---

**jhaa** - *23:13:21*

using v1.35 u ujson I get errors where the bot gets wrong exposure numbers from the feed and keeps placing bets

*Tags: Errors Debugging*

---

**jhaa** - *23:14:10*

i have not really debugged this, fortunately it is on one of my testing sub accounts

*Tags: Errors Debugging*

---

## 2020-08-31

**qwerty.nat** - *11:40:22*

Anyone ever had any issues sending data too fast to the REST endpoint ?

`{"faultcode":"Client","faultstring":"ANGX-0004","detail":{"APINGException":{"requestUUID":"ie1-ang12a-prd-08061002-003376d0e9","errorCode":"NO_APP_KEY","errorDetails":""},"exceptionname":"APINGException"}}`

even if it is something as simple as listEventTypes (  `[https://api.betfair.com/exchange/betting/rest/v1.0/listEventTypes/](https://api.betfair.com/exchange/betting/rest/v1.0/listEventTypes/)"`  ) I get the error above, If i put a sleep in between the 2 calls they will both work,  managed to replicate it with a quick 'c' libcurl app as well, so it's not bflw issue, but a general betfair issue i think. more curious than anything else

*Tags: Errors Debugging, Strategies*

---

**Misha** - *11:54:13*

It's not a general Betfair issue as I have been hammering the API for years and I have never seen a "NO_APP_KEY" error (and I have logged every error to a database for the last 3 years)

*Tags: Errors Debugging*

---

## 2020-09-01

**Lisa** - *01:58:17*

Hi, I'm hoping this will be a quick and simple issue but I can't download betfairlightweight. Has anyone come across any issues before? looks like it is to do with ciso8601. any ideas? thanks

*Tags: General Technical*

---

**Mo** - *07:30:20*

Welcome. Can you paste the error message?

*Tags: Errors Debugging*

---

## 2020-09-03

**Jon** - *17:05:01*

Anyone else currently getting "betfairlightweight.exceptions.LoginError: API login: CLOSED"?

*Tags: Errors Debugging*

---

## 2020-09-05

**Jonjonjon** - *19:34:23*

Has anyone seen this issue before?



Oops no service available at [https://api.betfair.com/exchange/betting/json-rpc/v1](https://api.betfair.com/exchange/betting/json-rpc/v1) HTTP Error 502: Bad Gateway Traceback

*Tags: Errors Debugging, Strategies*

---

**Jonjonjon** - *19:43:02*

Ah, please ignore that. I fixed it. I have very bad infrastructure and a legacy bot does not use BFLW. It is on an old server that I don't have time to move. And I accidently killed the proxy server I used this morning. My own fault for being disorganised.

*Tags: Errors Debugging, Deployment*

---

**Ruben** - *23:08:17*

there's something that is keeping me a bit worried....I run my market recorder on a very modest server (1 GB RAM), and yesterday the python process suddenly stopped, without any errors/warnings in the log, nor in stdout. I have no clue what could have caused this, any ideas?

*Tags: Data Quality, Errors Debugging, Deployment*

---

## 2020-09-06

**birchy** - *00:37:52*

Agree with [@U0128E7BEHW](@U0128E7BEHW). Python Memory Error triggers the OOM process killer on Linux systems. Usually happens if you're appending to a list/dict/etc but forgetting to remove old entries and/or limiting the size. For lists, it's simply a case of doing something like `mylist = mylist[-1000:]`

*Tags: Errors Debugging, Performance*

---

**Jonjonjon** - *10:25:18*

The problems I had yesterday all had "Kill" at the end of the log files, and were due to lack of RAM. Have you tried monitoring your RAM usage? I do it using the top or htop commands.

*Tags: General Technical*

---

**liam** - *10:44:06*

Using up to one gb is impressive, I have an issue open [https://github.com/liampauling/flumine/issues/248|https://github.com/liampauling/flumine/issues/248](https://github.com/liampauling/flumine/issues/248|https://github.com/liampauling/flumine/issues/248) I use a mixture of docker and a worker to log memory usage 

*Tags: Performance*

---

**Ruben** - *13:45:57*

thanks for the help, will try monitoring, see if I catch it

*Tags: General Technical*

---

## 2020-09-08

**Mo** - *08:43:05*

Yes, it's a known problem with ujson

*Tags: General Technical*

---

**liam** - *08:44:46*

And [https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1599033634033600|2.8.0b](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1599033634033600|2.8.0b) or uninstall ujson

*Tags: Getting Started*

---

**Ruben** - *08:47:07*

I see, thanks to both of you for the help!

*Tags: General Technical*

---

## 2020-09-10

**Jonjonjon** - *21:40:22*

[@U4H19D1D2](@U4H19D1D2) I have situations where I have backed a horse at high odds. Then I try to lay the horse at lower odds. StrategyExposure prevents me from doing so, in a way that I believe is unjustified.



e.g. If I back £2 @ 1000, I should be able to lay £2 @ 500, as that is decreasing my exposure. However, I can't do that in this unit test:



```@mock.patch("flumine.controls.tradingcontrols.StrategyExposure._on_error")

def test_validate_selection2(self, mock_on_error):

    mock_market = mock.Mock()

    blotter = Blotter(mock_market)

    mock_market.blotter = blotter



    mock_strategy = mock.Mock()

    mock_lookup = mock.Mock()



    mock_matched_order = mock.Mock()

    mock_matched_order.order_type.ORDER_TYPE = OrderTypes.LIMIT

    mock_matched_order.side = 'BACK'

    mock_matched_order.order_type.size = 2

    mock_matched_order.size_matched = 2

    mock_matched_order.average_price_matched = 1000.

    mock_matched_order.id = 123

    mock_matched_order.trade.strategy = mock_strategy

    mock_matched_order.lookup = mock_lookup



    blotter._orders = {123:mock_matched_order}



    self.mock_flumine.markets.markets = {"1.234": mock_market}



    order = mock.Mock()

    order.trade.strategy = mock_strategy

    order.trade.strategy.max_order_exposure = float('inf')

    order.trade.strategy.max_selection_exposure = 10

    order.order_type.ORDER_TYPE = OrderTypes.LIMIT

    order.side = "LAY"

    order.order_type.size = 2

    order.order_type.price = 500.

    order.lookup = mock_lookup

    order_package = mock.Mock()

    order_package.market_id = "1.234"

    order_package.package_type = OrderPackageType.PLACE

    order_package.__iter__ = mock.Mock(return_value=iter([order]))



    self.trading_control._validate(order_package)



    self.assertEqual(0, mock_on_error.call_count)```

Apologies in advance if I've made a mistake and am making a false accusation.

*Tags: Errors Debugging, Strategies*

---

## 2020-09-11

**Jonjonjon** - *08:54:21*

Not sure if I'm reading the code correctly, but I'd find it easier to read the code if Blotter.selection_exposure returned 2 numbers... "profit if selection wins", "profit it selection loses" (matched PIW ad matched PIL).



The the code in StrategyExposure._validate could do something similar, calculating each new order's PIW and PIL. (new PIW and new PIL)



Then the exposure, as a result of the current matched orders, and proposed new order, would be



min(matched PIW+new PIW, matched PIL + new PIL).



However, given that Blotter.selection_exposure only considers matched sizes, could a user's exposure go over the limit if they have unmatched bets?

*Tags: Strategies*

---

**liam** - *09:23:39*

Np mate, you are helping us all :slightly_smiling_face: my normal use cases means I don't hit these problems

*Tags: General Technical*

---

**DH** - *09:44:15*

Wow, I'm seeing latencies of much more like 100ms here when I use `async=True` (as opposed to 120ms ish when using `async=False`), from a London-based VM. I'm using bflw though - is this an area where bflw is known to be slow? I can't see anything that could be responsible for adding so much latency!

*Tags: Performance*

---

**DH** - *12:02:31*

I'll investigate - when I look at my streaming latencies (published time vs utcnow()) they're very close to 10ms. And other requests like listing markets are around 20ms. :thinking_face:

*Tags: General Technical*

---

**DH** - *12:06:04*

Not with `async=True` though, if I've understood correctly? (just updated my initial question for clarity)

*Tags: General Technical*

---

**Jonjonjon** - *22:46:33*

I just added it here: [https://github.com/liampauling/flumine/issues/270](https://github.com/liampauling/flumine/issues/270) HOpefully my thoughts make sense

*Tags: General Technical*

---

## 2020-09-13

**Ruben** - *21:18:48*

When backtesting with flumine, is it expected for the `market.market_catalogue` object to be `None` in all calls to `process_market_book()` ? The `market`  object seems to be populated, but the attribute `market_catalogue`  which is what I use to access selection names, is always `None`

*Tags: General Technical*

---

**Lee** - *21:27:19*

market catalogue is a separate from the streaming data. You can record the data in a similar way to the market stream here [https://github.com/liampauling/flumine/blob/master/examples/strategies/marketrecorder.py#L186|https://github.com/liampauling/flumine/blob/master/examples/strategies/marketrecorder.py#L186](https://github.com/liampauling/flumine/blob/master/examples/strategies/marketrecorder.py#L186|https://github.com/liampauling/flumine/blob/master/examples/strategies/marketrecorder.py#L186)

*Tags: General Technical*

---

**Newbie99** - *21:28:05*

I'll have to defer to [@U4H19D1D2](@U4H19D1D2) for that, but my guess is that when recording the data it makes sense to capture the streaming data, take a snapshot of the market catalogue and then include that, rather than attempt to somehow get the market catalogue separately (as it isn't streamed)

*Tags: General Technical*

---

**Ruben** - *21:33:00*

makes sense [@UFTBRB3F1](@UFTBRB3F1), thanks for the help [@UUCD6P13J](@UUCD6P13J)!

*Tags: General Technical*

---

## 2020-09-14

**jhaa** - *17:54:30*

i just did a fresh venv on a new vps with latest bflw and i get:



TypeError: Type is not JSON serializable: numpy.float64

*Tags: Errors Debugging*

---

**liam** - *17:56:08*

so orjson can do that but it's an option, can you not convert to a python float beforehand?

*Tags: General Technical*

---

**liam** - *17:56:53*

or uninstall orjson if you are going to be passing in numpy types

*Tags: Getting Started*

---

**liam** - *17:57:36*

[https://github.com/ijl/orjson#numpy](https://github.com/ijl/orjson#numpy)

*Tags: General Technical*

---

**jhaa** - *17:58:02*

ok i just uninstalled ujson so it defaults to the slow python version

*Tags: Getting Started, Performance*

---

**jhaa** - *19:01:21*

ok that was a simple fix

*Tags: Errors Debugging*

---

**jhaa** - *19:02:05*

how likely is a switch to orjson going to fix that issues where the queue gets stuck when there are too many markets in the stream?

*Tags: Errors Debugging*

---

**liam** - *19:12:17*

That’s a ram/CPU issue however orjson is quicker thus uses less CPU so it will help but sounds like you need to profile 

*Tags: General Technical*

---

## 2020-09-15

**jhaa** - *16:44:53*

when I hand this function a single market_id instead of a list it does not give an error

*Tags: Errors Debugging*

---

## 2020-09-16

**jhaa** - *14:25:57*

I am trying to find the memory leak with tracemalloc from the std lib. I run coarse order and market stream for like 1500 markets. After a few hours the python process uses 900gb in ram. This is the tracemalloc output sorted by memory used :



/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/streaming/listener.py:105: size=16.6 MiB, count=274719, average=63 B

/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/streaming/cache.py:346: size=15.6 MiB, count=51110, average=320 B

/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/resources/bettingresources.py:651: size=10.7 MiB, count=55851, average=200 B

/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/streaming/cache.py:36: size=6651 KiB, count=63150, average=108 B



That does not add up to 900gb. What am I missing? Anybody has a best practice how to do this?

*Tags: Performance, Strategies*

---

**jhaa** - *14:26:47*

I am likely missing something that is not in bflw but in my own code

*Tags: General Technical*

---

**liam** - *14:28:27*

you shouldn't get that with just bflw, I would try without your code to try and isolate

*Tags: General Technical*

---

**Chris** - *21:43:45*

Hey guys -



I just had an error that originated from there being an order with status EXECUTION_COMPLETE in the market.blotter.live_orders object. My rough expectation was that the only orders I would see in the market.blotter.live_orders object would have a pending status (PENDING, CANCELLING, UPDATING, REPLACING) or the EXECUTABLE status.



Are my expectations wrong here (execution_complete is a valid status for an order in the live_orders object)? Or, was this error a timing / race condition issue that I should be accounting for (i.e. I tried to use the live_orders object before the order could be removed from the live orders object)?

*Tags: Errors Debugging, Deployment*

---

## 2020-09-17

**agberk** - *13:59:58*

Might not care about supporting python3.5 anymore but just to let you know - the recent `orjson==3.3.0` dependency is only available on python &gt;=3.6; had an issue with a 3.5 venv

*Tags: General Technical*

---

**Dave** - *21:37:13*

perhaps a stupid question - I've been hitting some timeouts when running a strategy on flumine. I'm just recording some data but subscribing to all WIN markets in GB/ire/us/aus. Is there a recommended value for the "streaming_timeout" param when subscribing to a large number of markets?

*Tags: Strategies*

---

## 2020-09-18

**liam** - *06:13:54*

That doesn’t do [https://liampauling.github.io/flumine/advanced/#parameters|anything](https://liampauling.github.io/flumine/advanced/#parameters|anything) when recording data, do the timeouts come when subscribing or during streaming?

*Tags: General Technical*

---

**Dave** - *06:49:55*

During streaming, let me gather more info then (thought it may be a known issue!). Cheers

*Tags: General Technical*

---

**liam** - *07:00:24*

Sounds like it’s your network then, logs might help, are you on the cloud?

*Tags: General Technical*

---

**Dave** - *08:33:31*

It's possible! DO droplet. I'll have a peek through the logs. How does flumine handle network issues? Just reconnect and re-subscribe to markets once network is available again?

*Tags: General Technical*

---

**Lee** - *10:16:02*

[@U0128E7BEHW](@U0128E7BEHW) I'm using DO too and seeing a couple of these Timeout errors every few days. I'm getting them on both the streams and worker api calls.

*Tags: Errors Debugging*

---

**liam** - *10:17:46*

I get a few errors on AWS, I think its betfair tbh and yes it will reconnect

*Tags: Errors Debugging, Deployment*

---

**liam** - *10:32:18*

here is the [https://github.com/liampauling/flumine/blob/52d31acab3dd7aa4194e6c5ee2aef67405c4c877/flumine/streams/datastream.py#L99|logic](https://github.com/liampauling/flumine/blob/52d31acab3dd7aa4194e6c5ee2aef67405c4c877/flumine/streams/datastream.py#L99|logic) if your interested, all streams use it

*Tags: General Technical*

---

## 2020-09-21

**JonM** - *16:44:45*

Hi all, almost certainly doing something dim here.  Using flumine, I seem unable to access market_books with a "CLOSED" status (so can't pick out the winner for example).  Illustrative code here:



```class ExamplePrinter(BaseStrategy):

    

    def start(self) -&gt; None:

        print("starting strategy 'ExamplePrinter'")

    

    def check_market_book(self, market: Market, market_book: MarketBook) -&gt; bool:

        # process_market_book only executed if this returns True

        return True



    def process_market_book(self, market: Market, market_book: MarketBook) -&gt; None:

        # process marketBook object

        if market_book.status != 'OPEN':

            print(f'status: {market_book.status}')



client = clients.BetfairClient(trading)



framework = Flumine(

    client=client,

)



strategy = ExamplePrinter(

    market_filter=streaming_market_filter(

        market_ids=['1.173247293']

    ),

)



framework.add_strategy(strategy)



framework.run()```

This only outputs when the market_book is "SUSPENDED", it never outputs "CLOSED". I can tell from logging that the market closes and the stream stops, so how would I access closed market books?

*Tags: Strategies*

---

**liam** - *16:46:29*

It doesn't currently, see this [https://github.com/liampauling/flumine/blob/3728274bce91cf3d56f42da67b43d116bc2f860e/flumine/baseflumine.py#L132|line](https://github.com/liampauling/flumine/blob/3728274bce91cf3d56f42da67b43d116bc2f860e/flumine/baseflumine.py#L132|line), instead `strategy.process_closed_market` is [https://github.com/liampauling/flumine/blob/3728274bce91cf3d56f42da67b43d116bc2f860e/flumine/strategy/strategy.py#L101|called](https://github.com/liampauling/flumine/blob/3728274bce91cf3d56f42da67b43d116bc2f860e/flumine/strategy/strategy.py#L101|called) but not always, was thinking of changing it this morning

*Tags: Strategies*

---

## 2020-09-24

**Andrey Yunoshev** - *12:11:04*

Hi guys, I got distracted and then returned to the project, updated everything and get the latency warning all the time

Constantly increasing



Here is simple code



[https://gist.github.com/yunoshev/b4705edeea0fd5851657c1a86553f343](https://gist.github.com/yunoshev/b4705edeea0fd5851657c1a86553f343)



Here is INFO log



[https://gist.github.com/yunoshev/8f7b553365f9635eee37cc5d14dd1079](https://gist.github.com/yunoshev/8f7b553365f9635eee37cc5d14dd1079)





with small modification



```"High latency between current time and MarketBook publish time: " + str(latency),```



I miss something? :slightly_smiling_face: o_O?

*Tags: Performance*

---

**liam** - *12:26:14*

Streaming timeout at 0.1 won’t help as it will process extra snaps every 0.1s 

*Tags: General Technical*

---

**liam** - *12:29:09*

The latency is increasing so it is probably the timeout 

*Tags: Performance*

---

**Andrey Yunoshev** - *12:32:38*

```WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time: 14.497617959976196

WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time: 2.081183910369873

WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time: 2.5980770587921143

WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time: 6.860579967498779

WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time: 2.2120819091796875

WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time: 28.355962991714478

WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time: 28.356460094451904```

*Tags: Performance*

---

**Andrey Yunoshev** - *12:32:44*

Streaming timeout = 2s

*Tags: General Technical*

---

**Andrey Yunoshev** - *12:50:29*

I downgrade to flumine==1.6.3, and everything OK with streaming timeout 0.1 - have any warning. But it just mean old version not have this warning at all?

*Tags: General Technical*

---

**Newbie99** - *18:29:51*

[@U013R0E7SUV](@U013R0E7SUV) are you using AWS by chance? I'm now getting the same error, with crazy latency times on a t3.mico, on a t2.micro running an older version no issues it seems (also locally no issues).

*Tags: Errors Debugging, Performance, Deployment*

---

**Kai** - *20:45:40*

[@UFTBRB3F1](@UFTBRB3F1) what are the latency values that you get? The t3 instances have far more CPU steal so they might not be the best choice for latency critical applications.

It shouldn't be 30 sec, but a few seconds might be caused just by CPU steal

*Tags: Performance*

---

## 2020-09-25

**Chris C** - *10:02:11*

On the high latency warnings: I get crazy latency warning as well, but only for markets where nothing is happening, like:

```{"asctime": "2020-09-25 08:58:20,824", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.173462701", "latency": 2271.97003865242, "pt": "2020-09-25T08:20:28.854000"}```



*Tags: Performance*

---

**liam** - *10:15:24*

which is fine and shouldn't raise this error

*Tags: Errors Debugging*

---

**liam** - *11:04:37*

Yeah the framework pushes out all MarketBook updates through the event queue but then it also sends out snaps every x `streaming_timeout` seconds, which means when comparing the publish time to the current time it will create this warning as it is technically stale data but in reality it's not. Need to look at maybe adding a flag to any updates which are from a snap to then prevent this warning

*Tags: General Technical*

---

**Misha** - *11:14:02*

A quick question: why did you decide to send out periodic snapshots when there are no updates?

*Tags: General Technical*

---

**richard** - *13:20:11*

Really sorry, probably a stupid question here, but I’m having issues with creating the filter to cancel orders. My code:

betId = *‘212122833595’*

 instructions_filter = betfairlightweight.filters.cancel_instruction(bet_id=str(betId))

 print(instructions_filter)

 result = trading.betting.cancel_orders(instructions=instructions_filter)

 print(result._data)

But I’m getting this error:

“betfairlightweight.exceptions.APIError: SportsAPING/v1.0/cancelOrders

Params: {‘instructions’: {‘betId’: ‘212122833595’}}

Exception: None

Error: {‘code’: -32602, ‘message’: ‘DSC-0018’}

Full Response: {‘jsonrpc’: ‘2.0’, ‘error’: {‘code’: -32602, ‘message’: ‘DSC-0018’}, ‘id’: 1}” Can anyone tell me what I’m doing wrong - I’m looking to cancel just this specific bet?

*Tags: Errors Debugging, Strategies*

---

**D** - *15:49:58*

hi, sorry if this is a question that gets asked loads. I’ve built a web app using the betfair api already in laravel  - I realise now that python would be a much better fit :eyes:  anyway,  ive got a working app key and i’ve uploaded a new .crt to my account in betfair  I’m getting the `Exception: [Errno 2] No such file or directory: '/certs/'` error, even though I’ve generated a .crt, .csr and a .key file. I’ve also copied the /certs directory to every single directory within my project directory I’m on mac so `/certs/` is read only if `/` is referring to my actual root filesystem. I’ve copied the certs folder to my home directory and tried pdating the path to `~/certs` but thats giving me the same error as well

*Tags: Errors Debugging*

---

**Mo** - *16:37:31*

Are you using `~/certs` in Python? Because I doubt it will expand `~` to your home directory

*Tags: General Technical*

---

**D** - *17:10:38*

Ah, yeah I am - I’m a newbie to python. What does the `/` resolve to? I assumed it was project root?

*Tags: General Technical*

---

**Mo** - *17:12:52*

Python's sort of irrelevant here, it's your shell that expands `~` to your home directory. I wouldn't expect any programming language to make the substitution

*Tags: General Technical*

---

**D** - *17:13:59*

that was my next assumption :sweat_smile:  i’m running this on Mac at the minute, My project is living at `~/Apps/Betfair` so `/` is going for my disk root, which rightfully gives me a read only error. :thinking_face: do i pu them somewhere like `/etc/ssl` and use that as the cert path? I’ve seen elsewhere having these stored in environment files would make sense when time come to push it live

*Tags: Errors Debugging, Deployment*

---

## 2020-09-28

**birchy** - *22:09:30*

I have a favour to ask...I've been offered a GPS feed via Betfair, so am wondering if anyone can point me to some python source code to get started with? Have also asked betfair, but obviously they're all at home with their feet up right now.

*Tags: General Technical*

---

## 2020-10-01

**liam** - *11:49:46*

lots of errors coming in my end

*Tags: Errors Debugging*

---

## 2020-10-02

**Jonjonjon** - *21:20:26*

If I record my own data, using the market recorder, and then use it for backtesting, there is a problem with in the market cache, as it expects some runners variables to be populated before it starts doing stuff with market books. Has anyone else encountered this?

*Tags: Data Quality*

---

**Jonjonjon** - *21:34:19*

If I look at the example PRO data, for the flumine integration test in /tests/resources/PRO-..., I see runner names:



`{"op":"mcm","clk":"1306210655","pt":1585638069280,"mc":[{"id":"1.170258213","marketDefinition":{"bspMarket":true,"turnInPlayEnabled":true,"persistenceEnabled":true,"marketBaseRate":6.0,"eventId":"29761984","eventTypeId":"7","numberOfWinners":1,"bettingType":"ODDS","marketType":"WIN","marketTime":"2020-04-01T05:30:00.000Z","suspendTime":"2020-04-01T05:30:00.000Z","bspReconciled":false,"complete":true,"inPlay":false,"crossMatching":false,"runnersVoidable":false,"numberOfActiveRunners":17,"betDelay":0,"status":"OPEN","runners":[{"adjustmentFactor":6.86,"status":"ACTIVE","sortPriority":1,"id":13269170,"name":"1. Duecourse"},{"adjustmentFactor":14.71,"status":"ACTIVE","sortPriority":2,"id":25646051,"name":"2. Kooweerup"},{"adjustmentFactor":6.86,"status":"ACTIVE","sortPriority":3,"id":26222589,"name":"3. Lankan Star"},{"adjustmentFactor":6.86,"status":"ACTIVE","sortPriority":4,"id":27788383,"name":"5. Stravain"},{"adjustmentFactor":11.44,"status":"ACTIVE","sortPriority":5,"id":25179363,"name":"6. Street Icon"},{"adjustmentFactor":0.95,"status":"ACTIVE","sortPriority":6,"id":27203134,"name":"7. Graceful Storm"},{"adjustmentFactor":0.95,"status":"ACTIVE","sortPriority":7,"id":24337837,"name":"8. Australian Design"},{"adjustmentFactor":6.86,"status":"ACTIVE","sortPriority":8,"id":24974771,"name":"9. Lickopaint"},{"adjustmentFactor":1.48,"status":"ACTIVE","sortPriority":9,"id":16654159,"name":"10. Miss Skeptical"},{"adjustmentFactor":3.0,"status":"ACTIVE","sortPriority":10,"id":24644431,"name":"11. Here De Fox"},{"adjustmentFactor":3.0,"status":"ACTIVE","sortPriority":11,"id":24619456,"name":"12. Snitz And The City"},{"adjustmentFactor":10.29,"status":"ACTIVE","sortPriority":12,"id":23630960,"name":"13. Wild Vixen"},{"adjustmentFactor":18.72,"status":"ACTIVE","sortPriority":13,"id":28273728,"name":"14. Shilo Lass"},{"adjustmentFactor":1.98,"status":"ACTIVE","sortPriority":14,"id":28273729,"name":"15. Fortune Rose"},{"adjustmentFactor":3.0,"status":"ACTIVE","sortPriority":15,"id":28273730,"name":"16. Belzella"},{"adjustmentFactor":1.48,"status":"ACTIVE","sortPriority":16,"id":28273731,"name":"17. Super Hussey"},{"adjustmentFactor":1.48,"status":"ACTIVE","sortPriority":17,"id":28273732,"name":"18. Ultra Smart"}],"regulators":["MR_NJ","MR_INT"],"venue":"Sandown","countryCode":"AU","discountAllowed":true,"timezone":"Australia/Sydney","openDate":"2020-04-01T02:00:00.000Z","version":3233644674,"name":"R7 1200m Hcap","eventName":"Sand (AUS) 1st Apr"},`

*Tags: Strategies*

---

## 2020-10-03

**liam** - *06:21:49*

Yeah only from the stuff you buy [https://github.com/liampauling/betfair/blob/63b119ddda855572a4f436810e719e4b70dd22bb/betfairlightweight/resources/streamingresources.py#L32|https://github.com/liampauling/betfair/blob/63b119ddda855572a4f436810e719e4b70dd22bb/betfairlightweight/resources/streamingresources.py#L32](https://github.com/liampauling/betfair/blob/63b119ddda855572a4f436810e719e4b70dd22bb/betfairlightweight/resources/streamingresources.py#L32|https://github.com/liampauling/betfair/blob/63b119ddda855572a4f436810e719e4b70dd22bb/betfairlightweight/resources/streamingresources.py#L32)

*Tags: General Technical*

---

## 2020-10-04

**Unknown** - *14:15:29*

If I point flumine/examples/backtest.py at the attached file, I get this error:



`Traceback (most recent call last):`

  `File "/home/jon/PycharmProjects/flumine/examples/backtest.py", line 34, in &lt;module&gt;`

    `framework.run()`

  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/backtest.py", line 44, in run`

    `for event in stream_gen():`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/betfairstream.py", line 342, in _read_loop`

    `yield self.listener.snap()`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/listener.py", line 43, in snap`

    `return self.stream.snap(market_ids)`

  `File "/home/jon/PycharmProjects/flumine/flumine/streams/historicalstream.py", line 70, in snap`

    `cache.create_resource(self.unique_id, self._lightweight)`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/cache.py", line 219, in create_resource`

    `data = self.serialise`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/cache.py", line 270, in serialise`

    `"runners": [`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/cache.py", line 272, in &lt;listcomp&gt;`

    `self.market_definition_runner_dict[`

`KeyError: (15431638, 0)`



The data was recorded using Flumine. I have a feeling it might be because I did not start recording the data as soon as the market became available.



I can get around it by deleting all data, until I have a marketDefinition update containing  a list of runners, but that is time consuming and hacky.

*Tags: Errors Debugging*

---

## 2020-10-05

**Connor Jardine** - *19:28:26*

Hi, I’m having issues running etfairlightweight on a raspberry pi, just wondering if anyone has been successful and if they can help me with the issue? Thanks :)

*Tags: General Technical*

---

**Lee** - *19:28:48*

Hi, what issues/errors are you getting?

*Tags: Errors Debugging*

---

**liam** - *19:35:59*

moved from ujson due to memory leaks and random faults however orjson complains at numpy types and now this

*Tags: Performance*

---

**birchy** - *21:57:38*

Not sure if this is related, but I've noticed my marketrecorder is stopping unexpectedly every 4 or 5 days. Only thing I can find in the logs is that it reports high latency for a couple of hours and then exits with no other errors logged. Could it be a memory issue? Have just restarted with `logging.level = WARNING` to try and narrow it down a bit.

Flumine 1.12.3

Orjson 3.3.0

Edit: have just upgraded Flumine to 1.13.0

*Tags: Errors Debugging, Performance*

---

**Jonjonjon** - *23:10:51*

Thanks Connor. Are they susceptible to heat problems?

*Tags: General Technical*

---

## 2020-10-06

**Misha** - *06:36:15*

Is Python/Flumine running as a 32-bit application or a 64-bit application?

*Tags: General Technical*

---

**liam** - *06:46:44*

It’s very easy to introduce memory leaks in python, I know there is one in flumine but shouldn’t be when just recording data 

*Tags: Performance*

---

**D C** - *08:53:45*

I don't really know python other than pure basics.  Does it give you control over dynamic memory allocation or is this due to some shoddy libraries/packages that already have leaks?

*Tags: Performance*

---

**liam** - *08:54:57*

You have very limited control, python does all of the memory allocation internally using c/references

*Tags: Performance*

---

**D C** - *08:58:09*

So it is actually a problem with the python internals? Something failing to release memory? I don't have much experience with languages in which you don't do your own memory allocation and cleanup so quite interested in how other languages achieve cleanup properly.

*Tags: Performance*

---

**birchy** - *10:09:36*

Have just checked `/var/log/syslog` and no errors there. `/var/log/messages` has not been used since 2012 in Ubuntu machines.

*Tags: Errors Debugging*

---

## 2020-10-07

**liam** - *08:14:29*

Isolated the flumine [https://github.com/liampauling/flumine/issues/248#issuecomment-704743300|memory leak](https://github.com/liampauling/flumine/issues/248#issuecomment-704743300|memory leak) to the bflw cache:man-facepalming: Going to look at either adding a clear/remove_market function or handle a clear up within the code itself (remove if closed for x seconds), not sure what peoples thoughts are on the latter as it may cause issues when betfair update results etc. at a later date

*Tags: Performance*

---

**liam** - *08:20:58*

only within flumine, the cache within bflw lives

*Tags: Deployment*

---

**Lee** - *08:21:51*

oh so people who use bflw with their own framework will probably see the same issue?

*Tags: General Technical*

---

**liam** - *08:23:21*

yeah anyone who uses bflw, but note this instance is processing every racing market and around 15k orders per day

*Tags: General Technical*

---

## 2020-10-08

**Jorge** - *11:16:34*

Hi guys, do you know of any tool to monitor RAM usage by a Python process? I am wondering if it's the API calls what is using most of my RAM memory, or maybe it is that I am saving a row to pandas DataFrame every 10 secs with the state of the bot and I keep this dataframe in memory...

*Tags: Feature Engineering, Performance*

---

**liam** - *15:55:34*

I have tried almost everything in finding memory leaks and this is what I did to find the above in flumine/bflw using `pympler`



```from pympler import summary, muppy

from pympler.util import stringutils



def get_pympler_memory():

    mem_summary = summary.summarize(muppy.get_objects())

    mem_summary = [

        [i[0], i[1], i[2], stringutils.pp(i[2]).lstrip()] for i in mem_summary

    ]

    mem_sorted = sorted(mem_summary, key=itemgetter(2), reverse=True)

    mem_sum_bytes = sum([i[2] for i in mem_sorted])

    mem_sum_human = stringutils.pp(mem_sum_bytes).lstrip()

    return mem_sum_bytes, mem_sum_human, mem_sorted```

Used like so:



```mem_sum_bytes, mem_sum_human, mem_sorted = get_pympler_memory()

[http://logger.info|logger.info](http://logger.info|logger.info)(

    "pympler",

    extra={

        "total_bytes": mem_sum_bytes,

        "total": mem_sum_human,

        "memory": mem_sorted[:64],

    },

)```

You can then plot or just look to see which objects are increasing in size or count.

*Tags: Performance*

---

**Unknown** - *19:25:31*

I was looking for memory leaks in my bot using tracemalloc, and found (I think) some big ones in bflw. This is a little over my head, and I'm not sure what I'm looking at. But basicaly I made empty bflw bot that only subscribes to all UK/AU/US racing markets, also to order stream from my live bots (~50k bets a week) and counts currenty open markets. Ran this for a 7-8 days, dumping memory snapshots every 10minutes, graphed it. Red line is resident memory, blue currenty subscribed open markets. bflw 2.8.0. Hope this helps

*Tags: Performance, Deployment*

---

**liam** - *19:27:38*

Yeah that looks the same as what I am seeing, plan on having a fix in beta soon 

*Tags: Errors Debugging*

---

**Newbie99** - *22:40:57*

```{"asctime": "2020-10-08 21:05:56,243", "levelname": "ERROR", "message": "_get_cleared_markets error", "exc_info": "Traceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 381, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 978, in _validate_conn\n    conn.connect()\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connection.py\", line 362, in connect\n    self.sock = ssl_wrap_socket(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 384, in ssl_wrap_socket\n    return context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"D:\\Python38\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"D:\\Python38\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"D:\\Python38\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nsocket.timeout: _ssl.c:1106: The handshake operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n    resp = conn.urlopen(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 726, in urlopen\n    retries = retries.increment(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\util\\retry.py\", line 403, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\packages\\six.py\", line 735, in reraise\n    raise value\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n    httplib_response = self._make_request(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 384, in _make_request\n    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n    raise ReadTimeoutError(\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 36, in request\n    response = [http://session.post|session.post](http://session.post|session.post)(\n  File \"D:\\Python38\\lib\\site-packages\\requests\\api.py\", line 119, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\api.py\", line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n    r = adapter.send(request, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 529, in send\n    raise ReadTimeout(e, request=request)\nrequests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\flumine\\worker.py\", line 200, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 45, in request\n    raise APIError(None, method, params, e)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.173991824'], 'customerStrategyRefs': ['BlueOcean'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.173991824'], 'customerStrategyRefs': ['BlueOcean'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)"}



{"asctime": "2020-10-08 21:12:32,721", "levelname": "ERROR", "message": "get_account_funds error", "exc_info": "Traceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 381, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 978, in _validate_conn\n    conn.connect()\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connection.py\", line 362, in connect\n    self.sock = ssl_wrap_socket(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 384, in ssl_wrap_socket\n    return context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"D:\\Python38\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"D:\\Python38\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"D:\\Python38\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nsocket.timeout: _ssl.c:1106: The handshake operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n    resp = conn.urlopen(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 726, in urlopen\n    retries = retries.increment(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\util\\retry.py\", line 403, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\packages\\six.py\", line 735, in reraise\n    raise value\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n    httplib_response = self._make_request(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 384, in _make_request\n    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n    raise ReadTimeoutError(\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 36, in request\n    response = [http://session.post|session.post](http://session.post|session.post)(\n  File \"D:\\Python38\\lib\\site-packages\\requests\\api.py\", line 119, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\api.py\", line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n    r = adapter.send(request, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 529, in send\n    raise ReadTimeout(e, request=request)\nrequests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\flumine\\clients\\betfairclient.py\", line 56, in _get_account_funds\n    return self.betting_client.account.get_account_funds()\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\account.py\", line 35, in get_account_funds\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 45, in request\n    raise APIError(None, method, params, e)\nbetfairlightweight.exceptions.APIError: AccountAPING/v1.0/getAccountFunds \nParams: {} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)", "error": "AccountAPING/v1.0/getAccountFunds \nParams: {} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)"}```

*Tags: Errors Debugging, Deployment, Strategies*

---

**Newbie99** - *22:40:57*



Have been getting these errors over the last 24 hours (using Flumine live), has anyone else seen similar, or is it just likely to be a timeout caused by a network issue from my end?

*Tags: Errors Debugging, Deployment*

---

## 2020-10-09

**Lee** - *17:34:34*

Just come across this error on flumine==1.13.0

```  File "/Users/leeunsworth/git/sports-betting/.venv/lib/python3.7/site-packages/flumine/markets/blotter.py", line 135, in selection_exposure

    unmatched_exposure = calculate_unmatched_exposure(ub, ul)

  File "/Users/leeunsworth/git/sports-betting/.venv/lib/python3.7/site-packages/flumine/utils.py", line 164, in calculate_unmatched_exposure

    lay_exp = sum((i[0] - 1) * -i[1] for i in ul)

  File "/Users/leeunsworth/git/sports-betting/.venv/lib/python3.7/site-packages/flumine/utils.py", line 164, in &lt;genexpr&gt;

    lay_exp = sum((i[0] - 1) * -i[1] for i in ul)

TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'```

*Tags: Errors Debugging, Strategies*

---

**Jonjonjon** - *20:20:47*

[@UUCD6P13J](@UUCD6P13J) Do you have any tips on how I can reproduce the error?

*Tags: Errors Debugging*

---

**Lee** - *21:11:13*

Looks a bit of a silly example :slightly_smiling_face:

```from flumine import BaseStrategy

from flumine.order.ordertype import LimitOrder

from flumine.order.trade import Trade

from flumine.utils import get_price





class ExposureIssue(BaseStrategy):

    def check_market_book(self, market, market_book):

        if market_book.status not in ["CLOSED", "SUSPENDED"] and market_book.inplay:

            return True



    def process_market_book(self, market, market_book):

        for runner in market_book.runners:

            lay = get_price(runner.ex.available_to_lay, 0)

            trade = Trade(

                market_book.market_id, runner.selection_id, runner.handicap, self,

            )

            order = trade.create_order(side="LAY", order_type=LimitOrder(lay, 2))

            self.place_order(market, order)```

*Tags: Strategies*

---

**Lee** - *21:12:03*

I've grabbed a couple of market id's from yesterday which causes the exception `1.173953839` and `1.173953766`

*Tags: Errors Debugging*

---

**Misha** - *21:41:19*

There can be errors in the supplied data - probably missing updates

*Tags: Errors Debugging*

---

**Misha** - *21:41:51*

Tennis streaming data contains quite a few of these

*Tags: General Technical*

---

**Jonjonjon** - *21:44:09*

Thanks [@U016535QCJ2](@U016535QCJ2).



[@U4H19D1D2](@U4H19D1D2) - do you think we need to make BFLW adjust for this scenario? Or perhaps do some analysis to see how often we get crossed prices?

*Tags: General Technical*

---

**Jonjonjon** - *21:46:47*

[@UUCD6P13J](@UUCD6P13J) The problem is because I'm iterating over a list of orders that include the order violations.

*Tags: General Technical*

---

**Misha** - *21:47:26*

It should only happen for historical data - not live data

*Tags: Data Quality, Deployment*

---

**Lee** - *21:48:26*

I tested these two files on flumine 1.12.0 and works fine so there's definitely a regression.

*Tags: General Technical*

---

**Lee** - *21:49:44*

I'm not sure I agree [@U016535QCJ2](@U016535QCJ2), the historic data a lot of us use we record and is the same as live data. The exposure code run is the same either way (live or historic).

*Tags: Deployment*

---

**Misha** - *21:50:32*

The historical data is supplied by Betfair, and it is of indeterminate quality

*Tags: Data Quality*

---

**Misha** - *21:51:06*

Live data is captured by you

*Tags: Deployment*

---

## 2020-10-12

**Unknown** - *21:28:23*

Any ideas why MarketRecorder seems to have stopped loading to S3? I've noticed this several times now and restarting the bot fixes it. Still running at present but looks like it's only saved one file since 3rd October. Logging is set to WARNING and there's nothing on there that rings any alarm bells. Haven't checked the actual files as I'm not on the PC right now. Or could it be AWS display being a bit wanky?

*Tags: Errors Debugging, Deployment*

---

**birchy** - *22:47:30*

It's AWS. Have just looped through the files and am still getting new markets. Was going to delete my original message, but thought I'd leave it here in case anyone else has this issue...

*Tags: Deployment*

---

## 2020-10-13

**birchy** - *09:35:49*

Yeah, ordered by last modified date in AWS but new files not showing. Looped through my local backups and could see files from yesterday, etc, which are not showing in the AWS view.

*Tags: Deployment*

---

**Lee** - *10:31:37*

orjson strikes again

```       Collecting orjson==3.4.0; sys_platform == "darwin" or sys_platform == "linux" (from betfairlightweight==0.0.0b21-&gt;-r /tmp/build/requirements/base.txt (line 4))

       Downloading [https://files.pythonhosted.org/packages/ca/ab/cece004aaae000741d059dcb9b1f6f62a6a5ecb2e11b3ecca09e6180c327/orjson-3.4.0.tar.gz](https://files.pythonhosted.org/packages/ca/ab/cece004aaae000741d059dcb9b1f6f62a6a5ecb2e11b3ecca09e6180c327/orjson-3.4.0.tar.gz) (655kB)

       Complete output from command python setup.py egg_info:

       Traceback (most recent call last):

       File "&lt;string&gt;", line 1, in &lt;module&gt;

       File "/app/.heroku/python/lib/python3.7/tokenize.py", line 447, in open

       buffer = _builtin_open(filename, 'rb')

       FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-build-29ykcrms/orjson/setup.py'

       

----------------------------------------

       Command "python setup.py egg_info" failed with error code 1 in /tmp/pip-build-29ykcrms/orjson/```



*Tags: Getting Started, Errors Debugging*

---

## 2020-10-14

**Mo** - *20:56:11*

Just use your live key and streaming

*Tags: Deployment*

---

## 2020-10-16

**Newbie99** - *09:10:23*

I'm getting a:



```Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang15b-prd-09230859-00277b1814', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang15b-prd-09230859-00277b1814', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}```

Just looking for: Aussie horse racing win only, so I'm guessing Betfair are up to their old tricks, not removing markets again perhaps?

*Tags: Errors Debugging*

---

**Newbie99** - *09:12:42*

shouldn't throw an error though surely?

*Tags: Errors Debugging*

---

## 2020-10-17

**Rob (NZ)** - *11:07:41*

should I be putting my password into a specific file? (this is to get flumine running)

*Tags: General Technical*

---

**Newbie99** - *11:10:03*

you should just be able to do this:



```trading = betfairlightweight.APIClient(account_name, account_password, account_key, certs=cert_path)```

*Tags: Strategies*

---

**Rob (NZ)** - *11:12:34*

```import betfairlightweight

from flumine import Flumine, clients



trading = betfairlightweight.APIClient("username")

client = clients.BetfairClient(trading)



framework = Flumine(

    client=client,

)```



*Tags: Strategies*

---

**Rob (NZ)** - *11:12:50*

so i was missing those attributes, cheers for the help

*Tags: General Technical*

---

**AP** - *23:28:09*

I am deploying a function app (serverless) on Azure and got the following error related to orjson when deploying:



```Collecting orjson==3.4.0; sys_platform == "darwin" or sys_platform == "linux" (from betfairlightweight-&gt;-r requirements.txt (line 14))

  Downloading [https://files.pythonhosted.org/packages/ca/ab/cece004aaae000741d059dcb9b1f6f62a6a5ecb2e11b3ecca09e6180c327/orjson-3.4.0.tar.gz](https://files.pythonhosted.org/packages/ca/ab/cece004aaae000741d059dcb9b1f6f62a6a5ecb2e11b3ecca09e6180c327/orjson-3.4.0.tar.gz) (655kB)

  Installing build dependencies: started

  Installing build dependencies: finished with status 'done'

    Complete output from command python setup.py egg_info:

    Traceback (most recent call last):

      File "&lt;string&gt;", line 1, in &lt;module&gt;

      File "/opt/hostedtoolcache/Python/3.6.12/x64/lib/python3.6/tokenize.py", line 452, in open

        buffer = _builtin_open(filename, 'rb')

    FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-install-muey9qtb/orjson/setup.py'```

*Tags: Getting Started, Errors Debugging, Deployment*

---

**Lee** - *23:42:26*

I had the same issue the other day, it’s a problem with orjson 3.4. I just downgraded orjson version but can also try below 

*Tags: General Technical*

---

## 2020-10-19

**George Whewell** - *10:41:44*

hi, any issues with historical data api? i've tried increasing timeout to 10mins and still getting timeout with this:

```for line in client.historic.get_file_list(

    "Soccer",

    "Basic Plan",

    from_day=1,

    from_month=9,

    from_year=2020,

    to_day=2,

    to_month=9,

    to_year=2020,

    market_types_collection=["MATCH_ODDS"],

    countries_collection=["GB"],

    file_type_collection=["E"],

):```

*Tags: Data Quality*

---

**birchy** - *20:13:15*

In Flumine backtesting, should `market_catalogue` be populated? I have the following path structure:

`marketdata/marketCatalogue` and `marketdata/streaming`

I can preload the marketCatalogue JSON for parsing pre-backtest, but was wondering if it should already be loaded in `check_market_book()`?

*Tags: General Technical*

---

**birchy** - *20:32:42*

Thanks [@U4H19D1D2](@U4H19D1D2), that's not a big issue. I presume it will be present when running live?

Also, I notice all of the examples use a single filepath for the list `strategy.market_filter['markets']` . I've been feeding it with a full list of 2000+ paths, which seems to be working fine, but I just wanted to confirm that I'm doing that correctly?

*Tags: Deployment, Strategies*

---

## 2020-10-20

**river_shah** - *16:14:56*

stack overflow coming back with minimal suggestions. wondering if anyone has any ideas:

```➜  / pip install flumine

Collecting flumine

  Using cached flumine-1.14.0-py3-none-any.whl (95 kB)

Collecting betfairlightweight==2.9.0

  Using cached betfairlightweight-2.9.0-py3-none-any.whl (60 kB)

Collecting python-json-logger==2.0.0

  Using cached python-json-logger-2.0.0.tar.gz (8.2 kB)

Collecting tenacity==5.0.3

  Using cached tenacity-5.0.3-py2.py3-none-any.whl (38 kB)

Collecting requests

  Using cached requests-2.24.0-py2.py3-none-any.whl (61 kB)

Collecting orjson==3.4.0; sys_platform == "darwin" or sys_platform == "linux"

  Using cached orjson-3.4.0.tar.gz (655 kB)

  Installing build dependencies ... done

  Getting requirements to build wheel ... done

    Preparing wheel metadata ... error

    ERROR: Command errored out with exit status 1:

     command: /usr/local/bin/python3.9 /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pip/_vendor/pep517/_in_process.py prepare_metadata_for_build_wheel /var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/tmp8bxpoz4e

         cwd: /private/var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/pip-install-kfkcy84b/orjson

    Complete output (13 lines):

    :boom: maturin failed

      Caused by: Cargo metadata failed. Do you have cargo in your PATH?

      Caused by: Error during execution of `cargo metadata`: error: failed to run `rustc` to learn about target-specific information



    Caused by:

      process didn't exit successfully: `rustc - --crate-name ___ --print=file-names -Z mutable-noalias --crate-type bin --crate-type rlib --crate-type dylib --crate-type cdylib --crate-type staticlib --crate-type proc-macro --print=sysroot --print=cfg` (exit code: 1)

      --- stderr

      error: the option `Z` is only accepted on the nightly compiler





    Checking for Rust toolchain....

    Running `maturin pep517 write-dist-info --metadata-directory /private/var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/pip-modern-metadata-h04wo8ou --interpreter /usr/local/bin/python3.9 --manylinux=off --strip=on`

    Error: Command '['maturin', 'pep517', 'write-dist-info', '--metadata-directory', '/private/var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/pip-modern-metadata-h04wo8ou', '--interpreter', '/usr/local/bin/python3.9', '--manylinux=off', '--strip=on']' returned non-zero exit status 1.

    ----------------------------------------

ERROR: Command errored out with exit status 1: /usr/local/bin/python3.9 /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pip/_vendor/pep517/_in_process.py prepare_metadata_for_build_wheel /var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/tmp8bxpoz4e Check the logs for full command output.```



*Tags: Getting Started, Errors Debugging*

---

**river_shah** - *16:51:49*

I am ruing the day I upgraded python to 3.9 from 3.7. all sorts of random issues popping up with basic installs (not just bflw and flumine related)

*Tags: Getting Started*

---

## 2020-10-21

**river_shah** - *08:16:29*

reverted python back to 3.7. just leaving a note here to say that python 3.9 and macos catalina play very badly together at this point so avoid the change if you can

*Tags: General Technical*

---

## 2020-10-24

**mandelbot** - *08:23:50*

hrms, why do I get a 'TOO_MUCH_DATA' exception even though I'm filtering the market catalogue and have max_results &lt; 1000?

*Tags: Errors Debugging*

---

## 2020-10-25

**Vitaly** - *15:40:11*

After updating flumine to 1.14.0. I've received error in my marketlogger:

Traceback (most recent call last):

  File "marketlogger.py", line 47, in &lt;module&gt;

    framework.run()

  File "/home/lvv77/.local/lib/python3.6/site-packages/flumine/flumine.py", line 44, in run

    self._process_close_market(event)

  File "/home/lvv77/.local/lib/python3.6/site-packages/flumine/baseflumine.py", line 269, in _process_close_market

    strategy.process_closed_market(market, event.event)

  File "/home/lvv77/bf6/strategies/marketrecorder.py", line 71, in process_closed_market

    file.write(market.market_catalogue.json())

TypeError: write() argument must be str, not bytes

*Tags: Errors Debugging, Strategies*

---

**Vitaly** - *15:44:55*

I've returned to 1.11.2. It works fine.

Looks like with updating flumine I should change something in my logger. But can't understand what exactly. Can someone suggest?

*Tags: General Technical*

---

**RichL** - *15:49:05*

Hmm, problem is probably that orjson returns bytes, not python unicode strings.

*Tags: General Technical*

---

**RichL** - *18:57:23*

Perhaps make it optional? try: import orjson / except ImportError: import json ?

*Tags: Errors Debugging*

---

## 2020-10-27

**AP** - *03:58:10*

Hi all,



Just wondering if this error is from a flumine setting or my own account?



```"message": "Order has violated ORDER_VALIDATION and will not be placed", "control": "ORDER_VALIDATION", "error": "Order size is less than min bet size (5) or payout (30) for currency"```

*Tags: Errors Debugging*

---

**Misha** - *04:01:33*

That's not a Betfair API error

*Tags: Errors Debugging*

---

**AP** - *04:27:30*

Yeah thinking it’s a setting in the flumine order validation 

*Tags: General Technical*

---

**Misha** - *04:37:17*

You get different error messages if it goes through to the API

*Tags: Errors Debugging*

---

**Misha** - *04:39:52*

Here are the API errors: [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-InstructionReportErrorCode](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-InstructionReportErrorCode)

*Tags: Errors Debugging, Strategies*

---

**liam** - *07:47:49*

This is due to the `OrderValidation` trading control, you either need to remove that control ([https://github.com/liampauling/flumine/blob/master/flumine/baseflumine.py#L70|added by default](https://github.com/liampauling/flumine/blob/master/flumine/baseflumine.py#L70|added by default)) completely or we can look to add a flag to the client `.min_bet_restriction` or similar

*Tags: Strategies*

---

**Mai** - *18:18:03*

I'm trying to scrape 'totalMatched' vol info from betfair but my code keeps returning 0.0 but returns other tags correctly. Is betfair blocking these requests somehow? I've tried diff combinations of user-agents. Here's my code:



`ua = UserAgent(verify_ssl=False)`



`headers = {`

     `'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',`

    `'User-Agent': ua.random}`

`r = requests.get('[https://www.betfair.com/www/sports/exchange/readonly/v1/bymarket?_ak=nzIFcwyWhrlwYMrh&amp;currencyCode=GBP&amp;locale=en_GB&amp;marketIds=1.174684442&amp;rollupModel=STAKE&amp;types=MARKET_STATE,MARKET_RATES,MARKET_DESCRIPTION,EVENT,RUNNER_DESCRIPTION,RUNNER_STATE,RUNNER_EXCHANGE_PRICES_BEST,RUNNER_METADATA,MARKET_LICENCE](https://www.betfair.com/www/sports/exchange/readonly/v1/bymarket?_ak=nzIFcwyWhrlwYMrh&amp;currencyCode=GBP&amp;locale=en_GB&amp;marketIds=1.174684442&amp;rollupModel=STAKE&amp;types=MARKET_STATE,MARKET_RATES,MARKET_DESCRIPTION,EVENT,RUNNER_DESCRIPTION,RUNNER_STATE,RUNNER_EXCHANGE_PRICES_BEST,RUNNER_METADATA,MARKET_LICENCE)', headers = headers)`

`soup = bs(r.content, 'xml')`

`for horse in soup.select('RunnerNode'):`

    `name = horse.select_one('runnerName').text`

    `#matchedVol = 0.0`

    `matchedVol =  horse.select('totalMatched')`

    `print(name, matchedVol)` 

*Tags: Strategies*

---

**Mai** - *18:23:15*

nothing, i think that was the problem. didnt place a single bet before askimg

*Tags: General Technical*

---

**Mo** - *18:23:40*

I'm not aware that's a problem either

*Tags: General Technical*

---

## 2020-10-28

**jhaa** - *12:53:46*

I use this [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)



I have a bizarre bug where every other day there is a timeout and when the OrderStream restarts I do not seem to get orders for certain markets. For example earlier today there were connection issues and the bot was trading 61 markets, 2 of those the placed orders were not recorded and the bot kept placing the order again and again until it ran out of funds. The other 59 markets showed no such behaviour.



Has anybody seen stuff like this?

*Tags: Errors Debugging, Strategies*

---

**liam** - *13:05:06*

Sounds like the problem is the lack of local state / error handling on the order stream working

*Tags: Errors Debugging*

---

**jhaa** - *13:06:52*

10/28 10:29:48 OrderStreaming run error

Traceback (most recent call last):

  File "/home/code/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 216, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "/usr/lib/python3.8/ssl.py", line 1226, in recv

    return self.read(buflen)

  File "/usr/lib/python3.8/ssl.py", line 1101, in read

    return self._sslobj.read(len)

socket.timeout: The read operation timed out



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "/home/code/dev/betfair_jhaa/v2/core/SafeStreamingThread.py", line 60, in run

    self.stream.start()

  File "/home/code/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 59, in start

    self._read_loop()

  File "/home/code/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 198, in _read_loop

    received_data_raw = self._receive_all()

  File "/home/code/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 220, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 568]: Socket The read operation timed out



...



10/28 10:30:08 Starting OrderStreaming

10/28 10:30:08 [Connect: 568]: connection_id: 108-281020093008-805670

10/28 10:30:08 [Subscription: 569]: SUCCESS (9 connections available)

10/28 10:30:08 [Subscription: 568]: SUCCESS (9 connections available)

10/28 10:30:08 [Stream: 568]: 54 oc resubscribed

*Tags: Errors Debugging*

---

**liam** - *13:09:29*

i think you can assume that the order stream / logic is pretty solid and the error is probably on your logic (assuming betfair weren't having issues)

*Tags: Errors Debugging*

---

**JonM** - *22:46:50*

Anybody noticed anything odd with the accounts API this evening?  My nightly account scraper is throwing errors on what looks like a perfectly acceptable response:

*Tags: Errors Debugging*

---

**JonM** - *22:49:13*

`Traceback (most recent call last):`

  `File "&lt;input&gt;", line 1, in &lt;module&gt;`

  `File "xxxxxxx/python3.8/site-packages/betfairlightweight/endpoints/account.py", line 87, in get_account_statement`

    `return self.process_response(`

  `File "/xxxxxxxxxxx/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 115, in process_response`

    `raise InvalidResponse(response=result)`

`betfairlightweight.exceptions.InvalidResponse: Invalid response received: {'accountStatement': [{'refId': '215131991392', 'itemDate': '2020-10-28T20:20:27.000Z'.......` 

*Tags: Errors Debugging*

---

## 2020-10-29

**JonM** - *07:56:15*

No, going to give that a try now.  I think I've narrowed it down to a problem with just yesterday's account statement.  I moved some funds to my poker wallet (just so they're out of the way as I live test a new strategy).  Is there a known issue at all with this?

*Tags: Deployment, Strategies*

---

**JonM** - *07:59:49*

Boom!  `lightweight` parameter fixes it.  Thanks [@UBS7QANF3](@UBS7QANF3).  Another bit of flimsiness in my code identified and fixed!

*Tags: Errors Debugging*

---

**Mo** - *08:01:24*

I _always_ set `lightweight=True` for that endpoint because of the number of times Betfair have sent through data that conflicts with the documentation

*Tags: General Technical*

---

**John T** - *12:23:29*

Just moved to using the betfairlightweight library (why didn't I do this earlier) to replace the one I wrote. So far managed to replace most of my own functionality  by just deleting big chunks of code. The first issue I have found is how do I save the raw data from BF as well as pass it back to the listener so I can use it for replay? I may just be missing something very simple?

*Tags: General Technical*

---

**birchy** - *19:09:37*

[@U4H19D1D2](@U4H19D1D2) is it worth adding these to Flumine `utils.py` ?

```def ticks_spread(price1: float, price2: float) -&gt; int:

    """returns number of ticks between price1 and price2"""

    try:

        return PRICES.index(as_dec(price2)) - PRICES.index(as_dec(price1))

    except:

        return 0



def runner_vwap(runner: RunnerBook) -&gt; Optional[float]:

    """returns runner vwap calculated from EX_TRADED"""

    try:

        tt = 0.0

        tw = 0.0

        for pd in runner.ex.traded_volume:

            tt += pd['size']

            tw += pd['size'] * pd['price']

        return tw / tt

    except:

        return```

*Tags: General Technical*

---

**birchy** - *19:45:59*

Was going to raise a PR but I have nfi how to do it. :flushed:

*Tags: General Technical*

---

**Mo** - *19:51:11*

Suggestions:



1) The comment for ticks_spread implies you’re calculating PRICES.index(as_dec(price1)) - PRICES.index(as_dec(price2))

2) You should return None on exception in ticks_spread rather than implying the prices are identical

3) I’d explicitly return None on exception in runner_vwap

4) I’d call the functions calculate_ticks_spread and calculate_runner_vwap

*Tags: Errors Debugging*

---

**birchy** - *20:35:44*

Also, should that be using `pd.price` instead of `pd['price']` ? PyCharm is flagging the latter as an error, but `pd.price` fails in an external project:

```for runner in market_book.runners:

    for pd in runner.ex.traded_volume:

        print(pd['price'], pd['size']) # OK

        print(pd.price, pd.size) # error```

*Tags: Errors Debugging*

---

**liam** - *20:37:24*

It gets patched to speed things up [https://github.com/liampauling/flumine/blob/master/flumine/patching.py|https://github.com/liampauling/flumine/blob/master/flumine/patching.py](https://github.com/liampauling/flumine/blob/master/flumine/patching.py|https://github.com/liampauling/flumine/blob/master/flumine/patching.py)

*Tags: Performance*

---

## 2020-10-30

**Misha** - *11:11:18*

Has anyone encountered this error returned from the streaming API via a StatusMessage: "Failure (Timeout - Timed out trying to read message make sure to add \r\n Read data : {&lt;conflateMs&gt;:0,&lt;heartbeatMs&gt;:5000,&lt;id&gt;:28,&lt;marketDataFilter&gt;:{&lt;fields&gt;:[&lt;EX_BEST_OFFERS_DISP&gt;,&lt;EX_LTP&gt;,..."?

*Tags: Errors Debugging*

---

**Misha** - *11:11:50*

Have received this 6 times in 9 days, but never seen it before that (same streaming code running for well over 2 years)

*Tags: General Technical*

---

**Misha** - *11:20:02*

So no idea what is different, because I have logged every error in all my systems for the last 3 years, and I can confirm that October 21 is the first time I have ever seen it

*Tags: Getting Started, Errors Debugging*

---

**Misha** - *11:21:08*

And that's running at least one, if not more, streaming API connections 24/7 since the beginning of 2018

*Tags: General Technical*

---

**Misha** - *11:31:04*

I will if it becomes an issue. At the moment I see it less that once a day, and I get the odd error every now and again anyway

*Tags: Errors Debugging*

---

**liam** - *11:35:52*

```2020-10-30 11:34:31,767 | ERROR | [MarketStream: None]: TIMEOUT: Timed out trying to read message make sure to add \r\n

Read data : {"op":"marketSubscription","id":1000,"marketFilter":{"eventTypeIds":["1","7"],"marketTypes":["WIN","PLACE"],"countryCodes":["AU"],"raceTypes":["Flat"]},"marketDataFilter":{"fields":["EX_BEST_OFFERS","EX_TRADED","EX_TRADED_VOL","EX_LTP","EX_MARKET_DEF"],"ladderLevels":5},"initialClk":null,"clk":null,"conflateMs":null,"heartbeatMs":null,"segmentationEnabled":true}

Exception in thread Thread-1:```

*Tags: Errors Debugging*

---

**liam** - *11:38:59*

bflw had a bug where `send` was used instead of `sendall` which meant in some cases not all bytes where sent not sure if C has something similar

*Tags: Errors Debugging*

---

**Misha** - *11:50:24*

No, but given that every message sent has been going through the same single line of code, if there was a protocol problem I would have seen it a long time ago

*Tags: General Technical*

---

## 2020-11-03

**Jonjonjon** - *23:34:09*

Should this be replaced with:



`size=order.size_remaining`



[https://github.com/liampauling/flumine/blob/a5d7b8f50cf7350df5e23ba2228902b967eaee7b/flumine/order/trade.py#L112](https://github.com/liampauling/flumine/blob/a5d7b8f50cf7350df5e23ba2228902b967eaee7b/flumine/order/trade.py#L112)



If not, suppose way lay £2@30.0.

We then cancel £0.50, so that the bet becomes £1.5@30.0



If we subsequently replace the order, with price 40.0, it currently becomes replaced with a bet of £2@40, while I would expect it to be replaced with a bet of £1.5@40.0

*Tags: General Technical*

---

**Jonjonjon** - *23:40:19*

Should this be replaced with:



```self.size_cancelled += _size_reduction```

[https://github.com/liampauling/flumine/blob/a5d7b8f50cf7350df5e23ba2228902b967eaee7b/flumine/backtest/simulated.py#L138](https://github.com/liampauling/flumine/blob/a5d7b8f50cf7350df5e23ba2228902b967eaee7b/flumine/backtest/simulated.py#L138)



If not, multiple cancellations give strange results.

*Tags: General Technical*

---

## 2020-11-04

**liam** - *08:34:20*

[https://github.com/liampauling/flumine/pull/313](https://github.com/liampauling/flumine/pull/313)

*Tags: General Technical*

---

**liam** - *09:14:40*

Opted for the size that is actually placed based on the API response [https://github.com/liampauling/flumine/pull/315](https://github.com/liampauling/flumine/pull/315)

*Tags: General Technical*

---

**Jonjonjon** - *20:50:17*

When testing this, by:



Placing a bet for £2.

Cancelling £0.50, leaving £1.50.

Replacing the bet...



The original bet shows £1.50 size cancelled, £0.50 size remaining. Should it be £2.00 size cancelled, £0.00 size remaining instead?



If so, I think the problem is caused by these lines:



[https://github.com/liampauling/flumine/blob/a5d7b8f50cf7350df5e23ba2228902b967eaee7b/flumine/backtest/simulated.py#L138-L143](https://github.com/liampauling/flumine/blob/a5d7b8f50cf7350df5e23ba2228902b967eaee7b/flumine/backtest/simulated.py#L138-L143)

*Tags: General Technical*

---

## 2020-11-05

**liam** - *08:22:08*

Are you using the latest version? Running on branch release/1.14.4 I get this on the cancelled:



```{"asctime": "2020-11-05 08:19:21,236", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.175089224", "selection_id": 25092874, "handicap": 0, "id": "138238571553631800", "customer_order_ref": "27cfde50caeb3-138238571553631800", "bet_id": "100000000001", "trade": {"id": "97b62c12-1f3f-11eb-9cb4-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.PENDING", "orders": ["138238571553631800"], "notes": "", "market_notes": "4.4,4.5,4.5"}, "order_type": {"order_type": "Limit", "price": 2.0, "size": 2.0, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 2.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Execution complete", "status_log": "Pending, Executable, Cancelling, Executable, Replacing, Execution complete"}```

And the new replacement order:



```{"asctime": "2020-11-05 08:19:21,237", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.175089224", "selection_id": 25092874, "handicap": 0, "id": "138238571612366820", "customer_order_ref": "27cfde50caeb3-138238571612366820", "bet_id": "100000000002", "trade": {"id": "97b62c12-1f3f-11eb-9cb4-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.PENDING", "orders": ["138238571553631800", "138238571612366820"], "notes": "", "market_notes": "4.4,4.5,4.5"}, "order_type": {"order_type": "Limit", "price": 2.02, "size": 1.5, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 1.5, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Executable", "status_log": "Pending, Executable"}```

*Tags: Strategies*

---

**Jonjonjon** - *09:31:09*

You're right. A good `git pull` fixed it. Apologies for the false accusation.

*Tags: Errors Debugging*

---

**liam** - *09:32:01*

:thumbsup:  i have now released 1.14.4, testing my side and things look good, lots of bugs fixed in that release :slightly_smiling_face:

*Tags: Errors Debugging*

---

**liam** - *09:40:40*

Released in [https://github.com/liampauling/flumine/pull/316/commits/0299f44990215a4fa6b70d6080d4e213e3bfec77|1.14.4](https://github.com/liampauling/flumine/pull/316/commits/0299f44990215a4fa6b70d6080d4e213e3bfec77|1.14.4)

*Tags: General Technical*

---

**John T** - *14:43:13*

My second question on using the library. Looks like in the cache.py file the 'mb' and 'ml' values are recorded and stored into the OrderBookRunner. However when serialise_orders is called it looks like only the unmatched_orders are serialised? Are the 'mb' and 'ml' values returned anywhere?

*Tags: General Technical*

---

## 2020-11-09

**Jorge** - *08:30:06*

Hi guys, I am not able to pip install betfairlightweight[speed]... I get the error:

• _maturin failed_

      _Caused by: Cargo metadata failed. Do you have cargo in your PATH?_

Can anyone help me?

*Tags: Getting Started, Errors Debugging, Performance*

---

**liam** - *08:32:33*

this help? [https://github.com/liampauling/betfair/issues/343](https://github.com/liampauling/betfair/issues/343)

*Tags: General Technical*

---

**Jorge** - *08:41:29*

Seems to be working, thanks liam! I also had to upgrade pip and python3-dev

*Tags: General Technical*

---

## 2020-11-10

**Jorge** - *09:09:19*

Hi, is it possible to configure logging with a dictConfig, _logging.config.dictConfig(dict_log_config)_, when using betfairlightweight?

*Tags: General Technical*

---

**Jorge** - *09:11:06*

I am running the error handling example: [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py), it works with

```logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))```

but it doesn't work for me when I change this line by _logging.config.dictConfig(dict_log_config)_

*Tags: Errors Debugging*

---

**Jorge** - *09:13:32*

It's the dict I usually use to log my applications: contains 2 handlers

```dict_log_config = {

    "version": 1,

    "handlers": {

        "consoleHandler": {

            "level": "DEBUG",

            "class": "logging.StreamHandler",

            "formatter": "standard",

            "stream": '[ext://sys.stdout](ext://sys.stdout)',

        },

        "fileHandler": {

            "level": "DEBUG",

            "class": "logging.FileHandler",

            "formatter": "standard",

            "filename": log_path,

        }

    },

    "loggers": {

        "": {  # root logger

            "handlers": ["consoleHandler", "fileHandler"],

            "level": "DEBUG",

        }

    },

    "formatters": {

        "standard": {

            "format": "%(asctime)s | %(levelname)s | %(message)s"

        }

    }

}```



*Tags: Errors Debugging*

---

**liam** - *09:19:48*

I added bflw to the loggers and it works fine

*Tags: General Technical*

---

**liam** - *09:19:58*

```        'betfairlightweight': {

            'handlers': ['consoleHandler'],

            'level': 'INFO',

            'propagate': False

        },```

*Tags: General Technical*

---

**Jorge** - *09:26:49*

Aha, I was missing that! Not used to use external libraries in Python myself. Thanks so much liam!

*Tags: General Technical*

---

**Jorge** - *12:21:51*

Hi again, what is the best way to change the streaming.stream.market_filter when the streaming is already running?

Right now I am stopping the streaming, creating another Streaming object and starting it. Using the *[https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|examples/examplestreamingerrhandling.py)* as base code.

*Tags: General Technical*

---

**Jorge** - *12:24:22*

My use case is I want to subscribe for market_books of the market_ids I have bots in, and when I launch a new bot I want to add it to the streaming (and remove it from streaming when it stops running)

*Tags: General Technical*

---

**liam** - *12:30:01*

Streaming is lightweight, subscribing is costly, ignore the markets you don’t want 

*Tags: General Technical*

---

## 2020-11-11

**Jorge** - *08:18:48*

Hi, when Streaming, is it possible to get information about the market like event_name? The name of the runners would also work for me

*Tags: General Technical*

---

**Jorge** - *13:42:58*

Is it needed to send keepAlive requests to keep the trading client running while using MarketStreaming?

*Tags: Deployment, Strategies*

---

**Jorge** - *14:50:01*

So for NG we do need to send keepAlives, but the MarketStreaming itself does not need keepAlives, right?

*Tags: Deployment*

---

**Mo** - *14:53:37*

That is correct but betfairlightweight handles that for you

*Tags: General Technical*

---

**Jorge** - *14:55:20*

Do you mean bflw handles the MarketStreaming keepAlives or the NG keepAlives? (sorry for too many questions, just migrating my code to bflw at the moment)

*Tags: Deployment*

---

**Mo** - *14:55:53*

As I said, it's correct that streaming does not require the session token to be kept alive

*Tags: Deployment*

---

**Mo** - *14:56:22*

So I mean that betfairlightweight handles renewing the session token for API-NG calls

*Tags: General Technical*

---

**liam** - *15:00:20*

So the production example handles it by just logging in on run [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)

*Tags: Deployment*

---

**Jorge** - *15:02:09*

Yes, this is for the streaming case, got it!

*Tags: General Technical*

---

**Remi** - *15:03:58*

While streaming, if I get an updated market_book from the queue and I change the object like this:

```runner = market_book.runners[0]

runner.ex.available_to_back[0].size += 1.0```

*Tags: General Technical*

---

**ricky** - *17:07:06*

How to display profit in *paper trade* mode? in below, "for market in framework.markets:" never execute.

Where is the best place to check the orders and profit from market.blotter? (i tried add method process_closed_market in class LowestLayer but without luck)



strategy = LowestLayer(

    market_filter=streaming_market_filter(market_ids=["1.175359552"]),

    max_order_exposure=50,

    max_selection_exposure=10,

    context={"stake": 2},

)

framework.add_strategy(strategy)

framework.run()



for market in framework.markets:

    print("Profit: {0:.2f}".format(sum([o.simulated.profit for o in market.blotter])))

    for order in market.blotter:

        print(

            market.market_id,

            order.selection_id,

            order.side,

            order.responses.date_time_placed,

            order.status,

            order.order_type.price,

            order.average_price_matched,

            order.size_matched,

            order.simulated.profit,

        )

*Tags: Strategies*

---

**mandelbot** - *17:23:45*

Why do I get this seemingly contradictory response when backtesting?

```

{"asctime": "2020-11-11 17:20:32,589", "levelname": "ERROR", "message": "[MarketStream: 0] Unable to add 1.174790521 to cache due to marketDefinition not being present (make sure EX_MARKET_DEF is requested)"}

{"asctime": "2020-11-11 17:20:32,589", "levelname": "INFO", "message": "[MarketStream: 0] 1.174790521 added, 1 markets in cache"}```



*Tags: Errors Debugging*

---

**Unknown** - *17:44:18*

No I record them using the flumine marketrecorder

*Tags: General Technical*

---

**Josh** - *17:52:16*

Should an order with the following specification



```"limitOnCloseOrder": {

                    "liability": 17.0,

                    "price": 1.7

                },```

come back with a "INVALID_ODDS" error? Should it be "1.70"?

*Tags: Errors Debugging*

---

**liam** - *18:37:48*

Are you passing in a weird data type? Numpy?

*Tags: General Technical*

---

**Josh** - *18:44:40*

No, just standard Python floats. This issue seems to have cropped up when I upgraded from bflw 2.7.2 to 2.10. I was definitely seeing some floating point issues in some of the prices (e.g. 2.52999999), so I'm not making sure to round(x, 2) everything

*Tags: General Technical*

---

**liam** - *18:47:59*

Set logging to debug and see what is sent 

*Tags: Errors Debugging*

---

**Josh** - *18:50:50*

thanks, I'll poke around and see what I can figure out. Just explicitly using `round` seems to have solved the immediate issue

*Tags: General Technical*

---

## 2020-11-12

**Oliver Varney** - *00:02:11*

hmm, I have got an order here unmatched that I cant cancel, either through the front end (website) or flumine

*Tags: General Technical*

---

**Oliver Varney** - *06:25:27*

cant cancel and it throws an error when I try and update the price both through api and website

*Tags: Errors Debugging*

---

**Oliver Varney** - *06:34:31*

and forwarded it onto Neil and helpdesks

*Tags: General Technical*

---

**Oliver Varney** - *09:10:51*

[@U4H19D1D2](@U4H19D1D2) just herd from another person who has the identical issue, dont believe they use flumine at all

*Tags: General Technical*

---

**Oliver Varney** - *09:13:52*

and my code cancels stale orders after a period of time, so after that time it repeatably tried and flumine just kept sending.

*Tags: General Technical*

---

**lil_algo** - *14:41:23*

Hi! I'm looking for some help. When trying to log in using betfiarligthweight I get the error message:

```LoginError: API login: AUTHORIZED_ONLY_FOR_DOMAIN_SE```

I have found the locale parameter, but what should I give it? I have tried 'SE' and '.se'

*Tags: Errors Debugging*

---

**lil_algo** - *14:49:25*

Solved it! "sweden" did the trick :slightly_smiling_face:

*Tags: General Technical*

---

## 2020-11-13

**Chris** - *11:16:07*

I'm subscribing to all GB,IE racing markets, and I'm only getting 208 markets added to the stream, but if I look up the same parameters in the API-NG I get 217 markets, I assume it is something I am doing rather than a problem at the BF side, anyone any ideas?



``` event_type_ids=["7"], country_codes=["GB", "IE"], market_types=["WIN","PLACE","OTHER_PLACE"]```

```INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: 1.175438218 added, 205 markets in cache

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: 1.175438034 added, 206 markets in cache

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: 1.175438035 added, 207 markets in cache

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: 207 mc added

WARNING:betfairlightweight.streaming.stream:[MarketStream: 1]: Latency high: 1.0258991718292236

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: 1.175438002 added, 208 markets in cache```



*Tags: Performance*

---

**Chris** - *11:36:18*

I see it as GB on the API-NG, does that mean the data is different between the streaming &amp; the API-NG, I assumed it was the same but just being presented in a different manner

*Tags: General Technical*

---

**liam** - *11:43:07*

I emailed Neil and I can see that things look to be getting fixed

*Tags: Errors Debugging*

---

**thambie1** - *18:57:44*

Looks like my account was closed with no notification or warning at all. According to support chat due to "business grounds due to market data control reasons". Didn't look like escalating with them would be fruitful so I put in a ticket through the developer support program. Given that they closed my account at 4pm on a Friday, looks like I'll have to wait till Monday for a response. If anyone has any suggestions or advice on how to resolve this please let me know!

*Tags: General Technical*

---

**thambie1** - *19:09:09*

I was betting a bit more earlier, but I'm testing a new strategy and have been betting about $100 per day for the past two weeks. I'm using the stream api to track up to 1000 markets, while hitting the rest api for metrics. Maybe I was hitting the rest api too often... I don't know.

*Tags: Strategies*

---

**Ruben** - *20:07:45*

for reference, I have been collecting data using flumine's market_recorder for about a month, no bets placed

*Tags: General Technical*

---

**thambie1** - *20:11:19*

I didn't receive any emails either. Around 4pm is when my bot started throwing errors.

*Tags: Errors Debugging*

---

**Ruben** - *21:04:43*

but how else can I build up a repository to backtest? I can't buy historical data since I'm on a non-UK market, so it wouldn't be at all representative

*Tags: Data Quality*

---

**Ruben** - *21:23:28*

yes, I will from now on, I thought that as far as I was streaming, it was okay

*Tags: General Technical*

---

**Michael** - *21:24:53*

No - even if you're a good customer they don't like you streaming anything you don't bet on, for example if you bet only on Tennis they won't let you harvest Football for very long.

*Tags: General Technical*

---

## 2020-11-14

**Misha** - *10:15:18*

Swings and roundabouts: I can't get discounts on commission via a different plan, but I do have access to historical streaming data through contacts here

*Tags: General Technical*

---

**Ryan Clapham** - *19:55:03*

Hi all, very new to the betfair api. I was wondering if someone could point be in the right direction. I have looked everywhere on the betfairlightweight docs but can not see anywhere it says to display odds that are available to take. Any help is much appreciated.

*Tags: Getting Started*

---

**Ryan Clapham** - *20:02:53*

```[&lt;betfairlightweight.resources.bettingresources.PriceSize object at 0x03D79FA0&gt;, &lt;betfairlightweight.resources.bettingresources.PriceSize object at 0x03D79FB8&gt;, &lt;betfairlightweight.resources.bettingresources.PriceSize object at 0x03D79FD0&gt;] [&lt;betfairlightweight.resources.bettingresources.PriceSize object at 0x03D7C028&gt;]```

*Tags: Strategies*

---

## 2020-11-16

**Jonjonjon** - *10:50:20*

My flumine script stops running after a few hours. I'm not seeing anything in the logs to indicate why. Has anyone else seen this before?

*Tags: General Technical*

---

**liam** - *11:14:51*

and a worker to monitor cpu/ram every few minutes

```import os

import logging

import psutil

import threading



logger = logging.getLogger(__name__)



PID = os.getpid()

_TWO_20 = float(2 ** 20)





def memory_profiler(context: dict, flumine, interval=1) -&gt; None:

    # get process

    process = psutil.Process(PID)

    # cpu

    cpu = psutil.cpu_percent(interval=interval)

    # ram

    memory_used = process.memory_info()[0] / _TWO_20

    memory = {

        "used": round(memory_used, 1),

        "percentage": round(process.memory_percent(), 1),

    }

    [http://logger.info|logger.info](http://logger.info|logger.info)(

        "memory_profiler",

        extra={"cpu": cpu, "memory": memory, "threads": threading.enumerate()},

    )```

*Tags: Performance*

---

**ricky** - *13:20:38*

I plan to use LoggingControl to store order data, i tried "LowestLayer" example in both backtesting and paper trade mode without success.

I can see orders.txt has been created but only with header information. No order data were generated. for some reason _process_cleared_orders_meta or _process_order never get call but i can see order data in market.blotter. Any idea?



from controls.backtestloggingcontrol import BacktestLoggingControl



logger = logging.getLogger()

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



strategy = LowestLayer(

    market_filter={"markets": [_market]},

    max_order_exposure=1000,

    max_selection_exposure=1000,

    context={"stake": 2},

)

control = BacktestLoggingControl()

framework.add_strategy(strategy)

framework.add_logging_control(control)



framework.run()

*Tags: Strategies*

---

**liam** - *13:29:11*

what version of flumine? working fine on 1.14.8 (feature was added in 1.14.2)

*Tags: Feature Engineering*

---

**brightcake** - *19:51:51*

Quick Flumine code question: does the selection_id attribute of the Trade object give the runner id?

*Tags: General Technical*

---

**Ruben** - *21:05:09*

After talking to someone from the bdp support team, it appears my account was closed because I have made almost 50 million data requests in the last three months. That comes down to about 6 requests/second. Is that possible from just using the default flumine market_recorder? that's all I was doing...

*Tags: General Technical*

---

**Misha** - *21:18:52*

Assume that the data you are requesting is not very time sensitive - anything that changes rapidly comes through the streaming API. To monitor all data for all tennis markets (every match, every market) worldwide I am doing about one request per second. So there should be no reason to hit the request API anywhere near as frequently as that

*Tags: General Technical*

---

**liam** - *21:39:04*

Yeah that isn’t right as it only uses streaming and then the odd catalogue request 

*Tags: General Technical*

---

## 2020-11-17

**Michael** - *07:42:52*

Perhaps there's more that could be done to make it clear to new users that data harvesting without betting just isn't allowed. As far as warnings go my own experience was that I did get a warning when I pushed it a bit. We also know that there are plenty of small players who consume a lot of data and BF don't have a problem with them so it's perfectly feasible to start small, just don't take the piss. Given that it looks like the cancellations we've heard about here are edge cases or possibly mistakes (which will likely get sorted out).

*Tags: Strategies*

---

**Jorge** - *08:19:40*

Hi guys, is it possible to get the Streaming Market Data in Euros when using betfairlightweight? My account is in EUR, not in GBP. For example, I'd like to get the available_to_back sizes in EUR.

*Tags: General Technical*

---

**Ruben** - *11:34:59*

In my case, the support guy I'm speaking to sais that I've made 50 million requests in 3 months (I haven't, I'm just using the market_recorder.py straight from the flumine repo), and also sais he won't provide any more info or breakdown on the particular requests

*Tags: General Technical*

---

**Jorge** - *11:36:07*

Hi, what is the difference between getting market_book.runners[0].ex.available_to_back[0].price and market_book.streaming_update['rc'][0]['batb']? (assuming they are the same runner_id)

*Tags: General Technical*

---

**Alessio** - *11:40:00*

also isn't the streaming_update just the pdate while the market_book is consolidated in the cache?

*Tags: General Technical*

---

**Jorge** - *11:42:59*

Yes, that's my question. What is the difference (if any) between the streaming_update and the market_book consolidated in the cache?

*Tags: General Technical*

---

**Mo** - *11:43:23*

The `streaming_update` is the raw mesage from the stream

*Tags: General Technical*

---

## 2020-11-18

**dan2002** - *21:03:13*

Hi, when i run marketrecorder.py (from flumine.exmaples) with my live api key for 24hr, i managed to record some data but only a very small number of files are zipped after markets close. not all with market closed are zipped. anyone had the same issue?

*Tags: Deployment*

---

**Jonjonjon** - *23:21:18*

Does anyone have any tips for hunting memory leaks in Python code?

*Tags: Performance*

---

**Josh** - *23:38:00*

Look for circular references that should be handled with `weakref` . I've found these using `gc.garbage` with `DEBUG_SAVEALL` turned on.

*Tags: Errors Debugging*

---

## 2020-11-19

**Kai** - *11:15:41*

memory leaks can be an absolute nightmare, further complicated by the internal memory management and caching in python.

The first thing would probably be to make sure that you are still referencing the objects somewhere.

tracemalloc would be a good start, and then there are many other tools.

[https://pythonhosted.org/Pympler/muppy.html](https://pythonhosted.org/Pympler/muppy.html)

*Tags: Performance*

---

**Unknown** - *19:08:50*

Does anyone know what this error means?

I seem to be getting it when flumine is exiting the main loop

*Tags: Errors Debugging*

---

**Oliver Varney** - *19:16:57*

most likely either ending up with a number that is not on the ladder, order some kind of number that has round errors

*Tags: Errors Debugging*

---

**Oliver Varney** - *19:19:49*

[https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/flumine/utils.py#L77](https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/flumine/utils.py#L77)

*Tags: General Technical*

---

**brightcake** - *19:26:33*

Strange, I am not doing anything to modify the price at which I'm feeding into flumine. Any ideas as to what could cause this?

*Tags: General Technical*

---

## 2020-11-20

**ricky** - *17:48:35*

When i was running backtesting, i realised i can not get market name (e.g. " Flat/Hurdle") from market_definition.

Is there a way i can record market_catalogue data via MarketRecorder via my home computer? ( Unfortunately S3MarketRecorder do requed S3 bucket info, i want to test locally before try AWS)

*Tags: Deployment*

---

**Lee** - *18:09:12*

You can use this line just change it from uploading to s3 but write to a file [https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/marketrecorder.py#L178|https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/marketrecorder.py#L178](https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/marketrecorder.py#L178|https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/marketrecorder.py#L178)

*Tags: General Technical*

---

**ricky** - *18:32:18*

def _load(self, market, zip_file_dir: str, market_definition: dict) -&gt; None:

	print('load start in MarketRecorder')

	file_directory = os.path.join(

						zip_file_dir,

						"marketCatalogue",

						)

	if market and self.context.get("load_market_catalogue", True):

		if market.market_catalogue is None:

			logger.warning(

				"No marketCatalogue data available for %s" % market.market_id

			)

			return

		try:

			with open(file_directory, "a") as f:

				f.write(market.market_catalogue.json())

			[http://logger.info|logger.info](http://logger.info|logger.info)(

				"%s successfully loaded marketCatalogue to s3" % market.market_id

			)

		except (BotoCoreError, Exception) as e:

			logger.error("Error loading to s3: %s" % e)

*Tags: Errors Debugging*

---

## 2020-11-21

**liam** - *02:32:00*

I have tried everything, I use pympler now to track objects it’s much easier than trying to understand gc 



[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1602168934132000|https://betfairlightweight.slack.com/archives/C4H05ML2E/p1602168934132000](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1602168934132000|https://betfairlightweight.slack.com/archives/C4H05ML2E/p1602168934132000)

*Tags: General Technical*

---

**Lee** - *10:06:18*

the `_load` method is called on [https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/marketrecorder.py#L89|here](https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/marketrecorder.py#L89|here), step through in a debugger where it goes after it’s called

*Tags: Errors Debugging*

---

**Lee** - *10:08:32*

You only want to check whatever price you’re posting [https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/lowestlayer.py#L46|here](https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/lowestlayer.py#L46|here)

*Tags: General Technical*

---

**Jonjonjon** - *22:25:25*

Has anyone ever seen this error when using the `multiprocessing` module to run several flumine backtests?



```_pickle.PicklingError: Can't pickle &lt;class 'datetime.datetime'&gt;: it's not the same object as datetime.datetime```



*Tags: Errors Debugging*

---

**Jonjonjon** - *22:27:55*

I think flumine does. It is not something I'm doing directly

*Tags: General Technical*

---

**birchy** - *22:40:22*

Flumine monkey patches datetime

*Tags: General Technical*

---

## 2020-11-23

**Unknown** - *01:47:00*

Hi,



First of all, thank you for the betfairlightweight &amp; flumine libraries.



I am seeking advice from the community w/ respect to latency when backtesting w/ Flumine. The objective of the tests below is to compare the performance of Flumine in the context of backtesting with the performance of a simple, naive implementation.



Test1:

Using [https://github.com/liampauling/flumine/blob/master/examples/backtest.py](https://github.com/liampauling/flumine/blob/master/examples/backtest.py) with an empty strategy. The log level has been raised to CRITICAL



Test2:

A python script  iterates thru the same collection of files, reads each line and parses them as JSON. The JSON structure doesn’t get processed further.



Both tests run on the same machine sequentially. The machine has 60GB of memory and 16 CPUs.



Size on disk for data is 1.6M for `betfair/tennis/xds_nfs/edp_processed/BASIC/2019/Jan/15`



Test1 runs in ~2 minutes

Test2 runs in 5 seconds



I understand that Test1 does a lot more than Test2. Flumine will create data structures, maintain states, etc…



But am I doing it right? Before I go the route to run profiler, what would be some comments?



PS: I did try the multithreaded approach found here [https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1598171342144900](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1598171342144900) courtesy of Jonjon &amp; Birchy and it did run in ~5 seconds. Would love to get some thoughts though. Thank you!

*Tags: Performance, Strategies*

---

**Mo** - *05:46:28*

Your results are to be expected. Improving betfairlightweight performance is an active topic of discussion here. In the mean time, you have plenty of cores so the multiprocessing approach is the way to go

*Tags: Performance*

---

**Matthieu Labour** - *14:35:53*

Yes :slightly_smiling_face:. A question for me w/ respect to backtesting is should it be done within Flumine or should it be done as a separate system. As I go deeper into the source code, I would be happy to help if i can be relevant. Thank you!

*Tags: General Technical*

---

**liam** - *14:38:11*

Depends I know some ([@UBS7QANF3](@UBS7QANF3)?) backtest using simpler (quicker) / flat data but for me being able to test a strategy using real data is extremely valuable 

*Tags: Strategies*

---

**Mo** - *15:40:42*

Yeah, personally I use pre-processed data for "backtesting"/strategy development and real data for implementation testing

*Tags: Strategies*

---

**thambie1** - *16:28:12*

It's a huge pain in my development cycle waiting for backtests to run. And I've already done a ton of optimizations on my code base.

*Tags: Performance, Strategies*

---

**liam** - *16:40:37*

I guess it’s all strategy dependant, I can create a strategy in two lines that would make double figure percentage ROI but in the real world I have no chance in hell getting matched enough to actually make it profitable. For me matching rates are crucial, [@UBS7QANF3](@UBS7QANF3) do you factor this in based on the book? I have always found this impossible when working with flat data hence going down the route of mimicking/simulating the betfair matcher but ignoring double counting of available liquidity 

*Tags: Strategies*

---

**Mo** - *16:52:14*

I'm willing to but probably don't have the time to do it justice right now. As [@U4H19D1D2](@U4H19D1D2) says, it's totally strategy dependent. If you don't care about the full market book - for example, your strategy is just deciding whether the best price is value - you can store these in simple CSV files that you can read in a fraction of the time compared to a scraped/historic Betfair prices file

*Tags: Strategies*

---

## 2020-11-24

**brightcake** - *19:57:05*

Did any of you guys experience this error when trying to use multiprocessing?

```AttributeError: Can't get attribute 'abc' on &lt;module '__main__' from 'abc_d.py'&gt;```



*Tags: Errors Debugging*

---

**brightcake** - *20:00:23*

lifesaver! All of the solutions on SO didn't seem to be much help

*Tags: General Technical*

---

**liam** - *20:00:56*

I spent a day once with a similar error 

*Tags: Errors Debugging*

---

## 2020-11-25

**Dermot** - *10:53:16*

Is anyone else having trouble with the api this morning? Can’t login via certlogin (from home or from ec2 ) and the [http://docs.developer.betfair.com|docs.developer.betfair.com](http://docs.developer.betfair.com|docs.developer.betfair.com) seems dead

*Tags: Deployment*

---

## 2020-11-26

**Ryan Clapham** - *13:07:25*

Hi, I was wondering if someone could help me. I seem to be getting a KeyError. At the minute its KeyError: 36413516. I am cycling through all win, place and eachway markets and recording prices into a dictionary. I did not know if its something to do with not showing the non-runners. Take the 14:33 Lingfield for example. On the win market reeceltic is showing as a non-runner but on the place and eachway market its not showing at all.

*Tags: Errors Debugging*

---

**Ryan Clapham** - *13:09:53*

```trading = betfairlightweight.APIClient(username, password, app_key=app_key, certs=cert_path)



trading.login()```

*Tags: Strategies*

---

## 2020-11-27

**Jonjonjon** - *08:42:50*

On an old server, which hasn't been ported to BFLW, I am getting this error message:



`Oops no service available at [https://api.betfair.com/exchange/betting/json-rpc/v1](https://api.betfair.com/exchange/betting/json-rpc/v1) Traceback (most recent call last): File "/home/content/28/xxx/html/xxx/helpers.py", line 66, in callAping_direct ).encode('utf-8')) File "/usr/local/lib/python2.7/urllib2.py", line 126, in urlopen return _opener.open(url, data, timeout) File "/usr/local/lib/python2.7/urllib2.py", line 400, in open response = self._open(req, data) File "/usr/local/lib/python2.7/urllib2.py", line 418, in _open '_open', req) File "/usr/local/lib/python2.7/urllib2.py", line 378, in _call_chain result = func(*args) File "/usr/local/lib/python2.7/urllib2.py", line 1215, in https_open return self.do_open(httplib.HTTPSConnection, req) File "/usr/local/lib/python2.7/urllib2.py", line 1177, in do_open raise URLError(err) URLError: 2020-11-27`

*Tags: Errors Debugging, Deployment, Strategies*

---

**Jonjonjon** - *08:45:06*

Is there a quick fix for that? Or do I need to port my code?

*Tags: Errors Debugging*

---

**liam** - *08:56:10*

so the error is todays date?

*Tags: Errors Debugging*

---

**Jonjonjon** - *08:58:53*

Ah, sorry. html encoding error:



`Oops no service available at [https://api.betfair.com/exchange/betting/json-rpc/v1](https://api.betfair.com/exchange/betting/json-rpc/v1)`

`&lt;urlopen error [Errno -2] Name or service not known&gt;`

`Traceback (most recent call last):`

  `File "/home/content/28/xxx/html/xxx/helpers.py", line 66, in callAping_direct`

    `).encode('utf-8'))`

  `File "/usr/local/lib/python2.7/urllib2.py", line 126, in urlopen`

    `return _opener.open(url, data, timeout)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 400, in open`

    `response = self._open(req, data)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 418, in _open`

    `'_open', req)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 378, in _call_chain`

    `result = func(*args)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 1215, in https_open`

    `return self.do_open(httplib.HTTPSConnection, req)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 1177, in do_open`

    `raise URLError(err)`

`URLError: &lt;urlopen error [Errno -2] Name or service not known&gt;`

*Tags: Errors Debugging, Strategies*

---

## 2020-11-28

**mandelbot** - *06:30:31*

Here's another example, it's not nonrunners...first date is market start time

`1.174235551 2020-10-16 13:53:00 23160590 2020-10-16 13:38:00.219000 OrderStatus.EXECUTION_COMPLETE BACK 30.0 10 0.0`



`{"asctime": "2020-11-28 06:21:33,082", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.174235551", "selection_id": 23160590, "handicap": 0, "id": "138258372930769969", "customer_order_ref": "c13a2832c6a96-138258372930769969", "bet_id": "100000000003", "trade": {"id": "f5c31430-3141-11eb-8cda-5c969d7d9766", "strategy": "Bot", "status": "TradeStatus.LIVE", "orders": ["138258372930769969"], "notes": "", "market_notes": "30,29,30"}, "order_type": {"order_type": "Limit", "price": 30, "size": 10, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 10, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 30.0}, "status": "Execution complete", "status_log": "Pending, Executable, Execution complete"}`

*Tags: Deployment, Strategies*

---

**liam** - *06:31:58*

Here is the logic [https://github.com/liampauling/flumine/blob/c466dc6a076719f0fbb5886bfcded1c400f50207/flumine/backtest/simulated.py#L312|https://github.com/liampauling/flumine/blob/c466dc6a076719f0fbb5886bfcded1c400f50207/flumine/backtest/simulated.py#L312](https://github.com/liampauling/flumine/blob/c466dc6a076719f0fbb5886bfcded1c400f50207/flumine/backtest/simulated.py#L312|https://github.com/liampauling/flumine/blob/c466dc6a076719f0fbb5886bfcded1c400f50207/flumine/backtest/simulated.py#L312)

*Tags: General Technical*

---

## 2020-11-29

**Aaron Smith** - *16:56:38*

Hello folks! I m having an error i currently cant explain, its certainly not an issue of flumine itself, but maybe one of you guys can help me out anyway :slightly_smiling_face:

I keeps getting the following warning:

```{"asctime": "2020-11-28 21:23:28,772", "levelname": "WARNING", "message": "Order 217999225444 not present in blotter", "bet_id": "217999225444", "market_id": "1.176099484", "customer_strategy_ref": "ip-xxx-xx-xxx-xx", "customer_order_ref": "stratname-138258912423034860"}```

I dont see how i managed to get orders which are not in the blotter, as with markets.place_order any order should automatically be added to the blotter?

Also on a complete diffrent topic: Sometimes i get prints and [http://logging.info|logging.info](http://logging.info|logging.info)() outputs in the console output, but mostly not. How can i choose which kind of outputs i want to get in my console?

Its is entirely possible i m overlooking the obvious, i m new to coding (corona made me do it :smile: )

Thanks to anyone taking the time to help me :slightly_smiling_face:

*Tags: Getting Started, Errors Debugging, Strategies*

---

**liam** - *17:11:03*

I assume you are getting this because you have restarted, flumine will try and pull the order in 

*Tags: General Technical*

---

**liam** - *17:13:43*

Ah so this message is when you have an order that wasn’t created by the flumine instance, we certainly can cache it so the warning only prints once 

*Tags: General Technical*

---

**Oliver Varney** - *17:21:22*

my process is this, I override _add_market in the flumine file, I call the list_current_orders, loop through current_orders and recreate the trade and add the orders to that trade, then store somewhere suitable so that its accessible in the main flumine functions (check_market_book,process_market_book, process_orders functions)

*Tags: General Technical*

---

**Aaron Smith** - *17:36:42*

Thanks. I m a little hesitant with overwriting stuff in the flumine framework for now, as i want to keep it as close to the original as i can to not have to rethink everything that i tweaked whenever i m getting some error. When i feel more comfortable with the framework, that may change.

Regarind the order: It must have been an order created by flumine and it must ve been a matched order, as i was only using Fill_or_Kill orders. It is only a handful of orders that are repeaditly logged. The warnings also occured on the first time i started flumine (so before any restart), looping over 3 diffrent orders

*Tags: Getting Started, Errors Debugging*

---

**Oliver Varney** - *17:50:47*

[https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/order/process.py#L19](https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/order/process.py#L19)

*Tags: General Technical*

---

**Oliver Varney** - *17:56:11*

[https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/order/process.py#L74](https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/order/process.py#L74)

*Tags: General Technical*

---

**Aaron Smith** - *18:20:46*

I see. Still 2 things i didnt understand yet: How did the order escape from getting added to the blotter in the first place? I can see the restart argument, but the framework wasnt restarted (well, it was, but these warnings were already logged after the very first start). Also, how come the warning is being logged over and over again when the order should ve been added by the create_order_from_current  -function? Right now the only possibility to escape from being added to the blotter that i see is if

```if strategy is None:

        # todo log

        return```

it escapes here (that snippet is taken from the create_order_from_current  -function) . But i dont see how this would happen either.

*Tags: Strategies*

---

**Oliver Varney** - *18:49:07*

Are you sure you created the orders through flumine on the same computer, with the same strategy name ? the strategy name hash doesnt look like it has a match if the strategy returned is None, or you havent added a strategy if that's possible, or the order does not had an customer_order_ref. can you use the debugger to check the value of strategy_name_hash is in strategies.hashes.get(strategy_name_hash)

*Tags: Errors Debugging, Strategies*

---

**Aaron Smith** - *20:23:25*

I can not test it right now, but after a deeper look it actually seems very possible that this is exactly what happend. (dont know how thought, its all been started by flumine and from the same computer)

*Tags: General Technical*

---

**Aaron Smith** - *20:23:51*

I ll let you know, Thanks a lot Oliver and liam for helping me :slightly_smiling_face:

*Tags: Deployment*

---

## 2020-12-01

**jhaa** - *16:40:31*

So I had my bots running for a few weeks without any issues. This morning around 5AM there were a few disconnects. I use the tenacity example StreamingThread for the reconnection handling.  One bot that trades like 70 markets restarts the order thread and market thread without issues for any markets.



The other bot trades 30 markets and does not get appropriate order updates for two of those markets and therefor keeps placing the same bet again and again until no funds are left in the account. They run the same code(one bflw 2.92 and the other 2.80 though, 2.92 broke).



I am running out of ideas how to debug this. ANy suggestion?

*Tags: Errors Debugging*

---

## 2020-12-02

**Aaron Smith** - *13:50:16*

[@ULDAVFDRP](@ULDAVFDRP), [@U4H19D1D2](@U4H19D1D2), or anyone else if he can/wants to help: I am still on the market.blotter problem (discussed if you scroll up a little, recap: Warning that order is missing in market.blotter is logged continously) :smile: I thought i d give you a quick update: It seems as if the orders actually are in the market.blotter. Looking at the order_ids in market.blotter._orders.keys(), i get the same order_ids as in the logging-message, for example:

```{"asctime": "2020-12-02 13:27:17,851", "levelname": "WARNING", "message": order_ids in market.blotter: "138262084251310400"}

{"asctime": "2020-12-02 13:27:17,851", "levelname": "WARNING", "message": order_ids in market.blotter: "138262084322493840"}

{"asctime": "2020-12-02 13:27:17,967", "levelname": "WARNING", "message": "Order 218299836481 not present in blotter", "bet_id": "218299836481", "market_id": "1.176256522", "customer_strategy_ref": "ip-xxx-xx-xx-xx", "customer_order_ref": "strat-138262084251310400"}

{"asctime": "2020-12-02 13:27:17,968", "levelname": "WARNING", "message": "Order 218299847629 not present in blotter", "bet_id": "218299847629", "market_id": "1.176256522", "customer_strategy_ref": "ip-xxx-xx-xx-xx", "customer_order_ref": "strat-138262084322493840"}```

So it seems to me like this warning is being logged even though the order is actually present in the market.blotter. The warning is being logged when in _process_current_orders_

```order = markets.get_order(

                market_id=current_order.market_id,

                order_id=order_id,

            )```

get_order returns None. But get_order is just checking in the market.blotter. I am still confused here :smile: I d appreciate if one of you guys has another look at it, thanks to everyone taking the time!

*Tags: Strategies*

---

**birchy** - *15:26:13*

[@U4H19D1D2](@U4H19D1D2) Just had this on a Flumine fresh install on a Lightsail instance:

```File "/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/login.py", line 53, in request

    raise APIError(None, exception=e)

betfairlightweight.exceptions.APIError: None

Params: None

Exception: [('SSL routines', 'SSL_CTX_use_certificate', 'ca md too weak')]```

Seems to be OpenSSL related: [https://stackoverflow.com/questions/52218876/how-to-fix-ssl-issue-ssl-ctx-use-certificate-ca-md-too-weak-on-python-zeep|StackOverflow Link](https://stackoverflow.com/questions/52218876/how-to-fix-ssl-issue-ssl-ctx-use-certificate-ca-md-too-weak-on-python-zeep|StackOverflow Link)

OpenSSL version 1.1.1

Flumine version 1.14.12

BetfairLightWeight version 2.10.2



Working fine on my production instance which has exactly the same setup and same certs?



Only difference I can find so far is:

```Linux 5.4.0-1029-aws #30~18.04.1-Ubuntu SMP

Linux 5.4.0-1029-aws #30-Ubuntu SMP```

Ubuntu 18.04 working fine, Ubuntu 20.04 is throwing the error.

*Tags: Getting Started, Errors Debugging, Deployment*

---

**birchy** - *16:36:36*

Obviously, you're correct _again_ [@UBS7QANF3](@UBS7QANF3) :grinning:

```$ uname -v

#30~18.04.1-Ubuntu SMP Tue Oct 20 11:09:25 UTC 2020



$ apt-cache policy openssl

openssl:

  Installed: 1.1.1-1ubuntu2.1~18.04.6

  Candidate: 1.1.1-1ubuntu2.1~18.04.6

  Version table:

 *** 1.1.1-1ubuntu2.1~18.04.6 500

        500 [http://eu-west-1.ec2.archive.ubuntu.com/ubuntu](http://eu-west-1.ec2.archive.ubuntu.com/ubuntu) bionic-updates/main amd64 Packages

        500 [http://security.ubuntu.com/ubuntu](http://security.ubuntu.com/ubuntu) bionic-security/main amd64 Packages

        100 /var/lib/dpkg/status

     1.1.0g-2ubuntu4 500

        500 [http://eu-west-1.ec2.archive.ubuntu.com/ubuntu](http://eu-west-1.ec2.archive.ubuntu.com/ubuntu) bionic/main amd64 Packages

------------------

$ uname -v

#31-Ubuntu SMP Fri Nov 13 11:40:37 UTC 2020



$ apt-cache policy openssl

openssl:

  Installed: 1.1.1f-1ubuntu2

  Candidate: 1.1.1f-1ubuntu2

  Version table:

 *** 1.1.1f-1ubuntu2 500

        500 [http://eu-west-1.ec2.archive.ubuntu.com/ubuntu](http://eu-west-1.ec2.archive.ubuntu.com/ubuntu) focal/main amd64 Packages

        100 /var/lib/dpkg/status```

OpenSSL 1.1.1f is the one that's failing

*Tags: Getting Started, Deployment*

---

**birchy** - *16:45:19*

Yeah, was just thinking that but am slightly cautious in case the new certs break my production server

*Tags: Deployment*

---

**birchy** - *16:47:38*

The new server is only a temporary setup for testing, but longer term I guess I'll need to upgrade production server to Ubuntu 20+ anyway.

*Tags: Getting Started, Deployment*

---

**Ryan Clapham** - *16:51:35*

Evening, for some reason I am getting the error 'AttributeError: 'dict' object has no attribute 'price'' Could a fresh pair of eyes have a look over my code please

*Tags: Errors Debugging*

---

**birchy** - *16:56:04*

```available_to_back = runner.ex.available_to_back[0].price

available_to_back = runner.ex.available_to_back[0]['price']```

It's a bit nicer to create a function for getting the price/size as it may also be None. Or you can use:

```from flumine.utils import get_price, get_size```



*Tags: General Technical*

---

**Jonjonjon** - *17:01:34*

Is it related to the patching that happens here:



[https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/__init__.py#L12-L14](https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/__init__.py#L12-L14)

*Tags: General Technical*

---

**liam** - *17:03:50*

Is that code from flumine? Doesn’t look like it 

*Tags: General Technical*

---

**liam** - *17:04:21*

I will add a proper error anyway when it’s accessed incorrectly as it is a bit odd 

*Tags: Errors Debugging*

---

**birchy** - *17:17:11*

[@U4H19D1D2](@U4H19D1D2) would it not be better to use just one format for price/size? Bit confusing for newbies. I know I certainly got caught out by the .price/['price'] thing in Flumine.

*Tags: General Technical*

---

**liam** - *17:19:07*

Always a balancing act between speed and readability/use but this is worth the confusion, see my favourite [https://github.com/liampauling/flumine/commit/64ae76f0cb5571a040ce9904febf35df733931c4|commit](https://github.com/liampauling/flumine/commit/64ae76f0cb5571a040ce9904febf35df733931c4|commit) 

*Tags: Performance*

---

**birchy** - *22:02:47*

Thanks for the info. Can't remember how to generate them now. Been a few years since I last did my SSL certs. :flushed:

*Tags: General Technical*

---

## 2020-12-03

**mandelbot** - *09:10:33*

any idea why i sometimes get this error in backtests?

```{"asctime": "2020-12-03 09:07:03,177", "levelname": "CRITICAL", "message": "Unknown error [&lt;class 'decimal.ConversionSyntax'&gt;] in strategy_process_market_book &lt;bound method test.process_market_book of &lt;strategies.test.test object at 0x000001E1A1A639D0&gt;&gt; 1.174842429", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\utils.py\", line 208, in call_process_market_book\n    strategy_process_market_book(market, market_book)\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\flumine\\examples\\strategies\\test.py\", line 47, in process_market_book\n    price_ticks_away(back, -20) and \\\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\utils.py\", line 125, in price_ticks_away\n    price_index = PRICES.index(as_dec(price))\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\utils.py\", line 55, in as_dec\n    return Decimal(str(value))\ndecimal.InvalidOperation: [&lt;class 'decimal.ConversionSyntax'&gt;]"}```

*Tags: Errors Debugging, Strategies*

---

**mandelbot** - *09:49:45*

I set a condition to back != None and back &gt; 1.3 and still getting that error.

*Tags: Errors Debugging*

---

**liam** - *09:52:57*

Wrap in a try and except and log what back is on the error 

*Tags: Errors Debugging*

---

**mandelbot** - *09:58:16*

You were right it is a None, was still returning an error because the back != None was in the same if statement.

*Tags: Errors Debugging*

---

**Aaron Smith** - *12:38:38*

well, the logs are a big mess right now, as i still wasnt able to fix the repeated log of the market.blotter warning. I am checking for if an order is complete somewhere within my strat already and just added a log under _if order.complete-section_ and _else-section_. It always goes to else, i feel like the logs will just add confusion with how messy they are :smile:

*Tags: Errors Debugging*

---

**liam** - *12:39:58*

A log entry of that order will help as you can see the status and status log, debugger would be even better as you will be able to see the place response and the current_status (which will tell you everything)

*Tags: Errors Debugging*

---

**Oliver Varney** - *13:10:43*

[https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/execution/betfairexecution.py#L69](https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/execution/betfairexecution.py#L69)

*Tags: General Technical*

---

**Aaron Smith** - *16:08:45*

```{"asctime": "2020-12-03 15:00:04,154", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.176309310", "selection_id": 28615071, "handicap": 0, "id": "138263004041538760", "customer_order_ref": "strat-138263004041538760", "bet_id": null, "trade": {"id": "3979446e-3578-11eb-b83b-0a13a1974215", "strategy": "strat", "status": "TradeStatus.LIVE", "orders": ["138263004041538760"], "notes": "", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 2.22, "size": 6.76, "persistence_type": "LAPSE", "time_in_force": "FILL_OR_KILL", "min_fill_size": 0.01, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 6.76, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}



{"asctime": "2020-12-03 15:00:04,155", "levelname": "INFO", "message": "1 order packages created", "order_packages": [{"id": "39799d2e-3578-11eb-b83b-0a13a1974215", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f9ca51b9b10&gt;", "market_id": "1.176309310", "orders": ["138263004041538760"], "package_type": "Place", "customer_strategy_ref": "ip-172-31-34-22", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}], "bet_delay": 0}



{"asctime": "2020-12-03 15:00:04,156", "levelname": "INFO", "message": "New requests.Session created", "sessions_created": 1, "session": "&lt;requests.sessions.Session object at 0x7f9c9c29ce90&gt;", "session_time_created": 1607007604.1561081, "session_time_returned": 1607007604.1561098}



{"asctime": "2020-12-03 15:00:04,329", "levelname": "INFO", "message": "[OrderStream: 1001]: 1.176309310 added, 3 markets in cache"}



{"asctime": "2020-12-03 15:00:04,330", "levelname": "WARNING", "message": "Order 218390745703 not present in blotter", "bet_id": "218390745703", "market_id": "1.176309310", "customer_strategy_ref": "ip-172-31-34-22", "customer_order_ref": "strat-138263004041538760"}



{"asctime": "2020-12-03 15:00:04,338", "levelname": "INFO", "message": "execute_place", "trading_function": "place", "elapsed_time": 0.18191218376159668, "response": {"customerRef": "39799d2e357811ebb83b0a13a1974215", "status": "SUCCESS", "marketId": "1.176309310", "instructionReports": [{"status": "SUCCESS", "instruction": {"selectionId": 28615071, "handicap": 0.0, "limitOrder": {"size": 6.76, "price": 2.22, "minFillSize": 0.01, "timeInForce": "FILL_OR_KILL"}, "customerOrderRef": "strat-138263004041538760", "orderType": "LIMIT", "side": "BACK"}, "betId": "218390745703", "placedDate": "2020-12-03T15:00:04.000Z", "averagePriceMatched": 2.236449704142012, "sizeMatched": 6.76, "orderStatus": "EXECUTION_COMPLETE"}]}, "order_package": {"id": "39799d2e-3578-11eb-b83b-0a13a1974215", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f9ca51b9b10&gt;", "market_id": "1.176309310", "orders": ["138263004041538760"], "package_type": "Place", "customer_strategy_ref": "ip-172-31-34-22", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}}



{"asctime": "2020-12-03 15:00:04,339", "levelname": "INFO", "message": "Trade status update: Pending", "id": "3979446e-3578-11eb-b83b-0a13a1974215", "strategy": "strat", "status": "TradeStatus.PENDING", "orders": ["138263004041538760"], "notes": "", "market_notes": "2.24,2.26,None"}



{"asctime": "2020-12-03 15:00:04,339", "levelname": "INFO", "message": "Order Place: SUCCESS", "bet_id": null, "order_id": "138263004041538760", "status": "SUCCESS", "error_code": null}



{"asctime": "2020-12-03 15:00:04,339", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.176309310", "selection_id": 28615071, "handicap": 0, "id": "138263004041538760", "customer_order_ref": "strat-138263004041538760", "bet_id": "218390745703", "trade": {"id": "3979446e-3578-11eb-b83b-0a13a1974215", "strategy": "strat", "status": "TradeStatus.PENDING", "orders": ["138263004041538760"], "notes": "", "market_notes": "2.24,2.26,None"}, "order_type": {"order_type": "Limit", "price": 2.22, "size": 6.76, "persistence_type": "LAPSE", "time_in_force": "FILL_OR_KILL", "min_fill_size": 0.01, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 6.76, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 2.236449704142012}, "status": "Executable", "status_log": "Pending, Executable"}



{"asctime": "2020-12-03 15:00:04,340", "levelname": "INFO", "message": "Trade status update: Live", "id": "3979446e-3578-11eb-b83b-0a13a1974215", "strategy": "strat", "status": "TradeStatus.LIVE", "orders": ["138263004041538760"], "notes": "", "market_notes": "2.24,2.26,None"}



{"asctime": "2020-12-03 15:00:04,580", "levelname": "WARNING", "message": "Order 218390745703 not present in blotter", "bet_id": "218390745703", "market_id": "1.176309310", "customer_strategy_ref": "ip-172-31-34-22", "customer_order_ref": "strat-138263004041538760"}```

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *17:20:36*

so that first log is the response from Betfair, the second is flumine, we currently wait for the order stream to return the order so you will see `Pending, Executable, Execution Complete` (logic in process.py) however I might change this to handle based on the response, do you see another log after this?



I am unable to replicate your issue and I don’t understand why you are getting the warnings as you shouldn’t, have you changed some of the code base?

*Tags: General Technical*

---

**liam** - *17:21:27*

```{"asctime": "2020-12-03 17:15:29,340", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.176254838", "selection_id": 19746489, "handicap": 0, "id": "138263085288320640", "customer_order_ref": "27cfde50caeb3-138263085288320640", "bet_id": "218400243460", "trade": {"id": "2428e4da-358b-11eb-8b34-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138263085288320640"], "notes": "", "market_notes": "4.4,4.5,4.5"}, "order_type": {"order_type": "Limit", "price": 4.4, "size": 2.0, "persistence_type": "LAPSE", "time_in_force": "FILL_OR_KILL", "min_fill_size": 0.01, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 2, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 4.4}, "status": "Execution complete", "status_log": "Pending, Executable, Execution complete"}```

*Tags: Deployment, Strategies*

---

**Aaron Smith** - *17:34:15*

Thanks for looking into it! I didnt leave out any logs, after this the last log just repeats for a long time. I didnt fork flumine and am only importing my installed flumine version, so the flumine code is unchanged. For now, all i did was write a strategy and run the framework

*Tags: Getting Started, Strategies*

---

**Oliver Varney** - *17:41:41*

whats returned from this line order_id = current_order.customer_order_ref[STRATEGY_NAME_HASH_LENGTH + 1 :]

*Tags: Strategies*

---

**liam** - *17:41:45*

Hang on [@U01DVUAE2G1](@U01DVUAE2G1) why is your customer strategy ref start with ‘Strat’ it should be a hash of Strat 

*Tags: Strategies*

---

**Oliver Varney** - *17:41:57*

is your strategy hash called strat

*Tags: Strategies*

---

**Aaron Smith** - *17:43:08*

the start is not named strat (i replaced that word, its the only thing i replaced, but it was showing my actual strategy name there)

*Tags: Strategies*

---

**liam** - *17:43:31*

It should be a hash of your strategy name 

*Tags: Strategies*

---

**Oliver Varney** - *17:46:33*

[https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/strategy/strategy.py#L229](https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/strategy/strategy.py#L229)

*Tags: Strategies*

---

**Oliver Varney** - *17:46:55*

are you sure your not overriding this in your strategy class

*Tags: Strategies*

---

**liam** - *17:46:55*

Within your strategy can you print that :point_up:

*Tags: Strategies*

---

**Oliver Varney** - *17:50:13*

[https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/order/order.py#L249](https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/order/order.py#L249)

*Tags: General Technical*

---

**Gabriel** - *18:27:14*

Hey guys, I was just wondering if there is a way to access my current betfair balance within flumine?

*Tags: General Technical*

---

**birchy** - *20:07:00*

And then I remembered I'd written a tutorial: Betfair API-NG - Creating SSL Certificates ([http://bespokebots.com|bespokebots.com](http://bespokebots.com|bespokebots.com)[http://www.bespokebots.com/betfair-ssl-certs.php|)](http://www.bespokebots.com/betfair-ssl-certs.php|))

:man-facepalming:

*Tags: General Technical*

---

## 2020-12-04

**Gabriel** - *11:39:21*

I tried making an MarketOnCloseOrder and gave it a liability. Error says it needs a size. In the docs it says it only needs a liability, also how would a size help if its a 'lay' order, where size cant really be determined as it doesnt know the price yet?

*Tags: Errors Debugging*

---

**Gabriel** - *16:40:24*

[@UNQGKT0CR](@UNQGKT0CR) Thats how i understood it aswell, thanks for confirming :slightly_smiling_face: However, what am i doing wrong here?

```trade = flumine.order.trade.Trade(

                                    market_id=market_id, 

                                    selection_id=selection_id,

                                    handicap=handicap,

                                    strategy=self

                                )



                                liability = - matched_quantity      # this is &gt; 2

                                order = trade.create_order(

                                            side="BACK", 

                                            order_type=flumine.order.order.MarketOnCloseOrder(liability=liability)

                                        )



                                self.place_order(market, order)```

what am i missing here? It wont place the order, all variables seem correct.

*Tags: Strategies*

---

**Gabriel** - *18:06:20*

There was exactly 1 log regarding this order:

```{"asctime": "2020-12-04 17:43:32,949", "levelname": "CRITICAL", "message": "Unknown error 'MarketOnCloseOrder' object has no attribute 'size' in strategy_process_market_book &lt;bound method MyStrat.process_market_book of &lt;strategy_object object at 0x7f7981f08dd0&gt;&gt; 1.176351611", "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 391, in size_remaining\n



    return self.current_order.size_remaining or 0.0\n



AttributeError: 'NoneType' object has no attribute 'size_remaining'\n



\n



During handling of the above exception, another exception occurred:\n



\n



Traceback (most recent call last):\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/utils.py\", line 208, in call_process_market_book\n



    strategy_process_market_book(market, market_book)\n



  File \"/home/jenkins-slave-strat/workspace/ProdTest/my_strat.py\", line 208, in process_market_book\n



    self.place_order(market, order)\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/strategy/strategy.py\", line 134, in place_order\n



    market.place_order(order)\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/markets/market.py\", line 53, in place_order\n



    order.place(self.market_book.publish_time)\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 289, in place\n



    self.placing()\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 86, in placing\n



    self._update_status(OrderStatus.PENDING)\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 81, in _update_status\n



    [http://logger.info|logger.info](http://logger.info|logger.info)(\"Order status update: %s\" % self.status.value, extra=[http://self.info|self.info](http://self.info|self.info))\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 266, in info\n



    \"size_remaining\": self.size_remaining,\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 396, in size_remaining\n



    return self.order_type.size\nAttributeError: 'MarketOnCloseOrder' object has no attribute 'size'"}```

For some reason it tries to get the size, which an MarketOnCloseOrder doesnt have

*Tags: Errors Debugging, Strategies*

---

**Jonjonjon** - *21:44:56*

Ah nice. Thanks for that [@UD9D2794H](@UD9D2794H). I think I made a mistake with the horse that got taken out... Caius marcus is what I had the problem with. Let me investigate more...

*Tags: General Technical*

---

**Jonjonjon** - *21:55:00*

It's Top Power that I am having issues with. It refused the enter the stalls and was declared non runner. I guess Betfair did it later.



However, it had an adjustment factor of 75.18.



In a strategy I am testing, I layed at 3.2.



Applying the adjustment factor, the average price matched drops to 0.79, which is below 1.01 and therefore invalid.



Is 75.18 a valid adjustment factor?



The adjustment factor code is here:



[https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/markets/middleware.py#L104-L107](https://github.com/liampauling/flumine/blob/4f08f389a3c5c2722b60252055b143cfdfefb0f7/flumine/markets/middleware.py#L104-L107)

*Tags: Strategies*

---

**Jonjonjon** - *22:01:52*

[https://en-betfair.custhelp.com/app/answers/detail/a_id/408/~/exchange%3A-in-a-horse-race%2C-how-will-non-runners-be-treated%3F](https://en-betfair.custhelp.com/app/answers/detail/a_id/408/~/exchange%3A-in-a-horse-race%2C-how-will-non-runners-be-treated%3F)

*Tags: General Technical*

---

## 2020-12-05

**liam** - *14:45:21*

I can release v1.14.13 now which will fix your first issue

*Tags: Errors Debugging*

---

**Gabriel** - *14:46:25*

aah, okay, so if i want to remain unmatched till the end, i have to use 1.01, then put a ridicolous hight stake, so that once it goes to bsp, that stake is reduced by dividing it by actual_bsp so that the liability remains fixed?

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:06:05*

Thanks [@U4H19D1D2](@U4H19D1D2). I have raised this:



[https://github.com/liampauling/flumine/issues/347](https://github.com/liampauling/flumine/issues/347)

*Tags: General Technical*

---

## 2020-12-07

**Oliver Varney** - *17:09:20*

[@UE72WCRR8](@UE72WCRR8) I had a latency issue due to some dodgey code (for which i have fixed now). My experience of what will happen if your check + process functions in flumine take longer to process then the stream takes to update is a steady increasing in backlogged market books. you can add a latency check in these flumine functions not to process the market book if the latency is greater than X s (so you catch up). Id assume it would be much more preferable to fix the code to be able to keep up with the stream.

*Tags: Errors Debugging, Performance*

---

**jhaa** - *17:15:05*

no I use plain betfairlightweight. My average processing time is &lt; 0.01s

*Tags: General Technical*

---

**liam** - *17:25:55*

The issue you have is that things rarely recover, you have a latency issue that then exponentially increases as the process hogs CPU and before you know it you are looking at 500+ seconds delay with no escape.



Skipping updates before processing could help but I would always push for finding and removing any potential bottleneck.

*Tags: Performance*

---

**birchy** - *19:42:05*

[@U4H19D1D2](@U4H19D1D2) Speaking of 500+ second delays, did you have any luck with finding a solution for Flumine handling a few thousand markets with one strategy?

*Tags: Strategies*

---

**liam** - *19:45:46*

Started with a [https://github.com/liampauling/flumine/issues/344|task](https://github.com/liampauling/flumine/issues/344|task) and an initial [https://github.com/liampauling/flumine/pull/340|commit](https://github.com/liampauling/flumine/pull/340|commit) 

*Tags: General Technical*

---

## 2020-12-09

**Mick** - *14:40:28*

(my first ever post - forgive me if I'm breaking all the rules!)... I have made some BACK bets successfully but now when I tried my first LAY bet with instruction={'orderType': 'LIMIT', 'selectionId': 2548529, 'side': 'LAY', 'limitOrder': {'price': 8.4, 'persistenceType': 'LAPSE', 'size': 2.332857142857143}} i get place_orders.status = FAILURE .. can't fathom why. Don't know where to begin diagnosing this problem. Any suggestions?

*Tags: General Technical*

---

## 2020-12-10

**Mick** - *12:12:42*

I am trying to read the adjustment factor associated with a race. I set price_filter = betfairlightweight.filters.price_projection(price_data=['EX_BEST_OFFERS']) then call market_books = trading.betting.list_market_book(market_ids=[mk_id],price_projection=price_filter) but if I then try and print(market_books[0].adjustment_factor) I get "'MarketBook' object has no attribute 'adjustment_factor'"... do I need to add something else to my price_data list? If so what?

*Tags: Strategies*

---

## 2020-12-11

**Artur Gräfenstein** - *18:56:56*

no error from Ukraine

*Tags: Errors Debugging*

---

## 2020-12-15

**mandelbot** - *07:43:05*

How come I'm getting `"levelname": "WARNING", "message": "Order has violated: MAX_ORDER_COUNT Error: Max Order Count has been reached (9837) for current hour"` in backtests even though I have `max_trade_count = 100` ? Is it counting bets per simulated time or actual time?

*Tags: Errors Debugging*

---

**mandelbot** - *07:49:21*

`"levelname": "ERROR", "message": "Transaction limit reached", "transaction_count": 11668, "transaction_limit": 5000, "client": "&lt;flumine.clients.backtestclient.BacktestClient object at 0x000001B5B3C7EFD0&gt;"}`

*Tags: Errors Debugging*

---

**liam** - *08:16:22*

I fixed this so fairly sure that is just telling you that you are placing that many per backrest hour, have you tried bumping the 5k limit on the client although I would make sure you actually want to be placing that many?

*Tags: Errors Debugging*

---

## 2020-12-17

**ricky** - *11:04:03*

I am recording marketdata via AWS S3 (S3MarketRecorder) , I expect market_catalogue shall be stored in Json format, but i got flat file.

I am new to AWS, i am not sure if it is cause by my setting problem or the source code need change to



self.s3.put_object(

	Body=str(json.dumps(market.market_catalogue.json())),

	Bucket=self._bucket,

	Key=os.path.join(

		"marketdata",

		"marketCatalogue",

		market.market_id,

	),

)

*Tags: Getting Started, Deployment*

---

**birchy** - *15:44:07*

Does betfair enable XM by default in streaming data? Reason I ask is because I've been using Flumine MarketRecorder to save data for backtesting and just discovered that all of my data has `cross_matching=True` which is a bit if an "oh, bugger" moment for me. The `listMarketBook` API docs state that XM is OFF by default and I've always expected that behaviour unless I had specifically set the flag `virtualise=True` in order to enable it...which I haven't.

*Tags: Errors Debugging*

---

**Mo** - *15:47:06*

The cross matched prices will be in the bdatb etc fields in the streaming data as opposed to atb

*Tags: General Technical*

---

**thambie1** - *15:50:20*

tangent question, does bflw have code to virtualize the order book or perform cross matching among &gt; 2 runners?

*Tags: General Technical*

---

**Unknown** - *15:50:34*

Not sure that Flumine does return virtual prices?

*Tags: General Technical*

---

**liam** - *16:11:03*

Flumine returns whatever you ask it to return based on the market_filter 

*Tags: General Technical*

---

**Mo** - *16:11:29*

There's two different things to consider here:



1. If you request the displayed prices, do you get them when accessing ex.availableToBack on a runner? It depends what else you asked for:

```    def serialise_available_to_back(self) -&gt; list:

        if self.available_to_back.prices:

            return self.available_to_back.serialise

        elif self.best_display_available_to_back.prices:

            return self.best_display_available_to_back.serialise

        elif self.best_available_to_back.prices:

            return self.best_available_to_back.serialise

        else:

            return []```

2. Does bflw virtualise the book for you? No

*Tags: General Technical*

---

## 2020-12-18

**Matthieu Labour** - *00:08:46*

Hello all.

Would it be possible to rename `_requires` into, for example, `extra_requires`

at the following location [https://github.com/liampauling/betfair/blob/master/setup.py#L10](https://github.com/liampauling/betfair/blob/master/setup.py#L10)

The reason is that I am running into an error with python 3.6.9

```Traceback (most recent call last):                                                                               

  File "/home/xxx/.local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/requirements.py", line 99, in __init__                                                                                   req = REQUIREMENT.parseString(requirement_string)                             

  File "/home/xxx/.local/lib/python3.6/site-packages/pkg_resources/_vendor/pyparsing.py", line 1654, in parseString                                                                                           raise exc                                                                                ```

Generally, what is the best way to make a request for changes, report an issue and contribute? Should I, for example, create an issue on github? Can I create a PR, add reviewers, merge?

Thank you!

*Tags: Getting Started, Errors Debugging*

---

**liam** - *06:34:46*

Huh? This doesn’t look like a bflw error to me, the setup file is valid and works on py3.6

*Tags: Getting Started, Errors Debugging*

---

**Mick** - *10:39:42*

I find that trading.keep_alive() usually works fine but occasionally it produces "betfairlightweight.exceptions.StatusCodeError: Status code error: 520" - any ideas?

*Tags: Errors Debugging, Deployment, Strategies*

---

**Misha** - *11:00:58*

Transient errors happen - have had a handful of 520s over the past 24 hours. Perfectly normal as a client (who knows why the server is generating them)

*Tags: Errors Debugging, Deployment*

---

**Matthieu Labour** - *12:30:51*

It craps out when importing bflw as a dependency in another project that is pipenv. I will put a dummy project together to show the issue

*Tags: General Technical*

---

**Matthieu Labour** - *12:36:44*

`_requires` does not conform with the string parser `home/xxx/.local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/requirements.py` The parser does not like when the token starts with `_`

*Tags: General Technical*

---

## 2020-12-19

**liam** - *05:31:26*

Odd, happy to accept a pr if it fixes it 

*Tags: Errors Debugging*

---

## 2020-12-23

**Oliver Varney** - *08:29:55*

the obvious issue, is you have no clue on available volumes, but it can be useful to see if you can build a profitable model with the assumption that there will be some volume around

*Tags: Strategies*

---

**liam** - *08:46:57*

fixed stakes? or based on liability?

*Tags: Errors Debugging*

---

**Mick** - *08:48:03*

[@U4H19D1D2](@U4H19D1D2): I may use kelly at some point

*Tags: Strategies*

---

**liam** - *08:49:11*

using fixed kelly should remove some of the volatility but cashing out is only giving money away, I profit off this so I shouldn't really tell you not to but...

*Tags: Errors Debugging, Strategies*

---

**Michael** - *08:50:24*

Under Kelly there might be circumstances where you close particular bets but it wouldn't be a blanket strategy. If you want a blanket strategy then you let them all run.

*Tags: Strategies*

---

**Michael** - *08:52:15*

For a whole heap of reasons you probably won't be able to use Kelly properly anyway though, so I wouldn't sweat it.

*Tags: Strategies*

---

**Michael** - *08:56:14*

Just whatever you do don't close as a blanket strategy, that's a bad idea.

*Tags: Strategies*

---

**Michael** - *09:08:51*

So back to your original question - I'd say the basic data LTP is a totally reasonable way to estimate your ability to do that and analyse its effect on your returns and I wouldn't apply any transformation to is as you're potentially just introducing and unnecessary error.

*Tags: Data Quality, Errors Debugging*

---

**Michael** - *09:19:41*

One of the problems with your * 1.02 for example is that it will effect different prices differently and that will skew your analysis, it also includes assumptions that we know aren't true - like the spread being the same across all prices. If you're not careful you can end up introducing all kinds of kinks in your analytical road. That's why I would prefer to keep your analysis as close to the source data as you can and then just discount it when you're all done.

*Tags: General Technical*

---

**Michael** - *09:24:21*

Think about what the purpose of your analysis is - it's to determine the best strategy and find the best bets right? It's not to tell you what your income will be next year (or it shouldn't be anyway). Viewed from that perspective your 'optimism discount' doesn't really matter.

*Tags: Strategies*

---

**Michael** - *09:32:21*

If you're going to do that why not just take a stab at what you think your strategy will look like and try it with minimum stakes collecting the data as you go? That's far and away the best way to get a strategy going anyway. Real bets places are far more valuable than hypothetical historical ones.

*Tags: Strategies*

---

**Mick** - *11:53:41*

My main challenge with my system is actually to get as much money on as early as possible when there are the biggest mistakes in the market. If I could bet at the bookies without being gubbed I'd bet the evening before. Sadly the exchanges are almost deserted at that time or offering silly odds. So now I'm thinking about 7? 8? 9?am ... looking for a sweet spot balancing market errors with liquidity.

*Tags: Errors Debugging*

---

**mandelbot** - *12:26:41*

Not sure what mandatory field im missing?



```{"levelname": "ERROR", "message": "Execution error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\execution\\betfairexecution.py\", line 196, in _execution_helper\n    response = trading_function(order_package, http_session)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\execution\\betfairexecution.py\", line 39, in place\n    return order_package.client.betting_client.betting.place_orders(\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\betfairlightweight\\endpoints\\betting.py\", line 500, in place_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/placeOrders \nParams: {'marketId': '1.17', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 2, 'side': 'BACK', 'handicap': 0, 'limitOrder': {'price': 6.0, 'persistenceType': 'LAPSE', 'size': 2, 'timeInForce': 30}, 'customerOrderRef': '662fae5f621ab-138280164330968924'}], 'customerRef': 'aa6e175d451311ebaa7f020100017805', 'customerStrategyRef': 'ID17805', 'async': False} \nException: None \nError: {'code': -32602, 'message': 'DSC-0018'} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}", "trading_function": "place", "response": "SportsAPING/v1.0/placeOrders \nParams: {'marketId': '1.17', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 2, 'side': 'BACK', 'handicap': 0, 'limitOrder': {'price': 6.0, 'persistenceType': 'LAPSE', 'size': 2, 'timeInForce': 30}, 'customerOrderRef': '662fae5f621ab-138280164330968924'}], 'customerRef': 'aa6e175d451311ebaa7f020100017805', 'customerStrategyRef': 'ID17805', 'async': False} \nException: None \nError: {'code': -32602, 'message': 'DSC-0018'} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}", "order_package": {"id": "aa6e175d-4513-11eb-aa7f-020100017805", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x000001F891D98820&gt;", "market_id": "1.177217695", "orders": ["138280164330968924"], "package_type": "Place", "customer_strategy_ref": "ID17805", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 1}}```

*Tags: Errors Debugging, Strategies*

---

## 2020-12-27

**JC** - *11:33:34*

Is there an order type in bflw where if it is not filled at in_play==True, it will take BSP?

*Tags: General Technical*

---

## 2020-12-29

**Alessio** - *21:33:58*

let's say you go for a very simple strategy, in a binary market (say, over/under X) always back Under, fixed small stakes (say, 5 bucks)

*Tags: Errors Debugging, Strategies*

---

## 2020-12-30

**Alessio** - *09:43:44*

'profit' of flumine should already do that, no?

*Tags: General Technical*

---

**Mo** - *09:44:40*

I don’t know, I don’t use flumine :wink:

*Tags: General Technical*

---

**Alessio** - *10:03:52*

[https://github.com/liampauling/flumine/blob/dabcaab5853ed71e95eed1c076706a41ded334e9/flumine/markets/blotter.py](https://github.com/liampauling/flumine/blob/dabcaab5853ed71e95eed1c076706a41ded334e9/flumine/markets/blotter.py) interestingly

*Tags: General Technical*

---

**Mo** - *10:12:44*

I think your point that losing -2% was good because it's less than the spread which I agree with but I wanted to point out that -2% after commission would be close to gross break even and gross break even strategies can be net profitable when combined with a strategy that generates premium charge

*Tags: Strategies*

---

**Mo** - *11:50:34*

I think they recognise it has flaws and have some regrets over its introduction but they need(ed) some way of recovering their cost of acquisition. There are probably better ways of incentivising behaviour that improves the exchange ecosystem but they obviously haven't felt the various trials they've run with different fee structures have achieved that while maintaining or improving their bottom line.

*Tags: Deployment*

---

**mandelbot** - *11:54:51*

Well that's the question isn't it

*Tags: General Technical*

---

**Misha** - *12:11:53*

And no. I never had access to the model :joy:

*Tags: Strategies*

---

**river_shah** - *14:21:10*

Maybe talent acquisition and retention, formalizing risk management, modelling process benefits. I guess anytime the scale goes 20+ people need more formal procedures / corporatization in place. Not sure re tax benefits

*Tags: Strategies*

---

**Misha** - *20:51:33*

My client was one of the big ones. Biggest profit on Betfair was UK racing (running with their model on my software). They did horse racing worldwide, and their main source of income was Asian exotic bets (across multiple selections/races)

*Tags: Strategies*

---

**Misha** - *21:30:31*

The last client employs over 100 people. But the model is developed by only one person

*Tags: Strategies*

---

**Misha** - *21:38:34*

I also know the limits to my skills (I am definitely no gun modeller), as does my partner, who although has worked as a software developer for decades, leaves the system development to me

*Tags: Strategies*

---

**Misha** - *21:40:43*

We are ramping up bet sizes on January 1 to a level that should easily exceed 2 full time wages, if the modelling is good. Have been betting at lower levels for about 3 months so :crossed_fingers:

*Tags: Strategies*

---

**D C** - *23:09:48*

Pure Maths [@U016535QCJ2](@U016535QCJ2) ? That is quite unusual. Usually pure maths is the abstract stuff that is of little direct use in modelling. Applied maths, particularly stuff like nonlinear optimisation and stats would be a far better background for a pro gambler.

*Tags: Strategies*

---

**D C** - *23:10:57*

Don't see it myself. An expert in number theory would not be much use at modelling.

*Tags: Strategies*

---

**Misha** - *23:18:35*

Basically being taught how to "think", and how to "solve problems", which is basically what underlies Pure Maths, is the key

*Tags: General Technical*

---

**Misha** - *23:19:55*

Another thing I remember from my exams: "Read the question, then read it again, and then when you are halfway through, read it again". This is to make sure you are solving the right problem

*Tags: General Technical*

---

**Misha** - *23:21:34*

Also remember the anecdote from one of my lecturers. When he couldn't solve the question to get his PhD (was too hard), he changed the question to something easier, and then solved that

*Tags: General Technical*

---

**Misha** - *23:25:21*

BTW, I have a model for tennis in-play that works and relies on no higher-level maths or machine learning other than basic statisitcs

*Tags: Strategies*

---

**Misha** - *23:26:33*

So it is possible to get there (but certainly not the only or main way) without using any suggested techniques. Basically pure problem solving

*Tags: General Technical*

---

**Misha** - *23:30:40*

Last lesson from Pure Maths: take time to understand the problem, so that you can break the bigger problem into a number of smaller problems. The better you understand the subject, the smaller those individual problems are, and the easier they are to "solve"

*Tags: General Technical*

---

**Misha** - *23:33:11*

And then once you "solve" them, keep looking for more "elegant" solutions. By elegant I mean simpler and less moving parts. My model that I have refined over the past few months uses a "minimal" set of data and only a few arbitrary threshold values. It's now much simpler than it was a month ago

*Tags: Strategies*

---

## 2020-12-31

**Sam Asin** - *04:58:00*

Real analysis etc. is just so good for practicing thinking through problems.

*Tags: General Technical*

---

**Dave** - *08:32:55*

[@U016535QCJ2](@U016535QCJ2) what do you mean by your model "only uses a few arbitrary thresholds"? Surprised your thresholds are arbitrary and not set empirically?

*Tags: Strategies*

---

**Misha** - *08:38:08*

Neither can be measured directly, because the outputs are the model, and you shouldn't set a threshold just to get better results from the model (neither give anything like linear results as I change thresholds, and the "noise" is significant)

*Tags: Strategies*

---

**mandelbot** - *09:52:05*

How can I write errors/orders from a strategy to a text file?

*Tags: Errors Debugging, Strategies*

---

**Alessio** - *10:01:05*

[@U016535QCJ2](@U016535QCJ2) out of curiosity and if you don't mind. Do you start from BF odds and refine them or do you have a complete model on the side and only compare it with BF at the very end?

*Tags: Strategies*

---

**Misha** - *10:21:25*

The second one. For this model I never look at the Betfair price at all until I decide whether to bet. I come up with my own probabilities just from the historical stats and the current score

*Tags: Strategies*

---

**Mick** - *12:25:44*

I am reading the back bet odds/size with the following..

price_filter = betfairlightweight.filters.price_projection(price_data=['EX_BEST_OFFERS'])

market_books = trading.betting.list_market_book(market_ids=[mk_id],price_projection=price_filter)

...and I see the set of three back prices just like on the exchange website. Early in the

morning the best back price available may be stable for many minutes on end (maybe even longer).

However when I actually programatically place an order with trading.betting.place_orders, I

very often find that I succeed in getting an even better price. Why might that be?

*Tags: Strategies*

---

**Mo** - *12:29:05*

How are you calculating the market probability that you compare your model against with the Brier score?

*Tags: Strategies*

---

**Misha** - *12:36:31*

Early stages yet - model will take another 12 months to get to a decent maturity (as you well know)

*Tags: Strategies*

---

**Mick** - *13:01:39*

I am using price_filter = betfairlightweight.filters.price_projection(price_data=['EX_BEST_OFFERS'])

*Tags: General Technical*

---

**Alessio** - *14:08:48*

(applied ML also include really doing it, as in clean your data, look at errors, etc etc..)

*Tags: Errors Debugging*

---

**MacrcoPolo** - *14:25:20*

What I love about folk who want to do datascience is that they're generally obsessed with complex models and hitting the .fit() method on tensor flow, when actually spending time making sure your data is clean and working on sensible features is 95%+ of the job...

*Tags: Feature Engineering, Strategies*

---

**MacrcoPolo** - *14:28:51*

(That said... I've spent the past few days working on an inference problem, so maybe I'm full of shit?)

*Tags: General Technical*

---

## 2021-01-01

**Misha** - *00:22:57*

I spend a huge part of my time "cleaning" data, and another huge part of my time just looking at it by running query after query. I have several data sets for different purposes (historically sourced data, live collected data, etc) and it's all in databases on SQL server. I have probably run an average of 100 hand-crafted queries per day for the last 3 months on my data. My view is that you really really need to understand your data. The longer I go the more insights I get from the data. Also remember I use absolutely no ML (my partner working on his model does)

*Tags: Deployment, Strategies*

---

**Misha** - *00:24:29*

One thing that might be different to many others is that I am building a model based on historical tennis results, so apart from using a starting price (calculated) for each match, I don't use pricing data at all in my model

*Tags: Strategies*

---

**Oliver Varney** - *01:51:12*

fuck understanding your data the model does this for you

*Tags: Strategies*

---

**Misha** - *01:54:09*

In my case it has been the most important thing. It allows me to focus on things that matter and increase the accuracy of the model. But I am looking at a sport, not prices

*Tags: Strategies*

---

**Misha** - *02:01:58*

I suspect that you work from market movements rather than stats, so a different "type" of model (my approach might not be applicable)

*Tags: Strategies*

---

**Oliver Varney** - *02:05:09*

I work with an AI model, you maths guys are far too smart for me, im literally retarded in comparison, yet id guess my  model would outperform yours quite easily in pre off horses

*Tags: Strategies*

---

**Misha** - *02:08:04*

I just stick to tennis. My knowledge of horses wouldn't amount to enough to build a decent model

*Tags: Strategies*

---

**Sam Asin** - *06:41:18*

sometimes i also think you can just catch things that are really hard to get in a model. Like pick up on a subtle pattern. Especially if you're dealing with limited data.

*Tags: Strategies*

---

**liam** - *06:45:19*

Funny how we all approach the game differently, for me it’s all about taking a simple idea and getting in the market with real money. See what works and what doesn’t, iterate to maximise profit/matching and move on.



I think the longest I have spent on making a model was a day (I get bored very quickly developing strategies) but that was only because I was crunching a few years of inplay data.

*Tags: Strategies*

---

**Misha** - *06:57:40*

[@U4H19D1D2](@U4H19D1D2) - Are you modelling off market movements? Or a statistical model?

*Tags: Strategies*

---

**liam** - *07:00:36*

Ignoring TPD my strategies are based purely off the market with the modelling more on execution to improve matching rates 

*Tags: Strategies*

---

**Michael** - *09:52:27*

I find I have a lot in common with [@U4H19D1D2](@U4H19D1D2) when it comes to strategy development, although I think I'm more into drilling into the detail of my bets than he is. I note that [@ULDAVFDRP](@ULDAVFDRP)'s comments are made at 2am and that the tone and grammar might suggest a little influence of alcohol...? Even so I can put my hand up for quite a bit of it. I also have very little maths training - nothing above GCSE. I don't even know where to start with advanced maths but I've done just fine like that and I'm still growing. As I understand it [@ULDAVFDRP](@ULDAVFDRP) is a premium account holder? If so that means he's done pretty well too - presumably well into six figures at least which is much more than most of the statistics experts. Higher level maths may be useful but it certainly neither necessary nor sufficient. One thing I'm sure every winning player will agree on is that projections mean very little until you have real money in the market. We've all seen how easy it is to write what seems like a brilliant model only to see it totally fail when you try getting money down. That happens because of mechanisms that never entered your model, you don't see them coming and sometimes you don't understand them even afterwards. Over time we learn to temper our confidence in our projections and base it on our history instead.

*Tags: Strategies*

---

**PeterLe** - *10:39:11*

Well Im ashamed to say that Ive never run model as such, although I do run 8/9 accounts every day and compare/contrast using real money; works just fine for me (all in profit)

It’s a reoccurring theme on here. I whole heartily agree that GCSE maths is quite sufficient to take you to seven figures (and beyond). So for those of you who haven’t got a Phd in maths all is not lost, don’t give up.

Test sensibly (using a well thought out idea, £2 Stakes), observes results, hone and refine.Why think up complicated strategies when there are simple ones aplenty :+1:

*Tags: Strategies*

---

**liam** - *10:52:20*

might be easier if you share the code if possible? Single trade? what does the strategy initialisation look like?

*Tags: Strategies*

---

**birchy** - *11:37:10*

That's a Flumine default. I found it when trying to backtest a strategy with &gt;1 trade per runner. Just set it to 2+ and job done.

*Tags: Strategies*

---

**liam** - *11:37:17*

yeah you have the trade count limit and the strategy investment limit (default is 1 live order per runner per strategy)

*Tags: Deployment, Strategies*

---

**liam** - *11:38:07*

however if you have logging setup the warnings will show if you set [https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/strategy/strategy.py#L45|log_validation_failures](https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/strategy/strategy.py#L45|log_validation_failures) to True

*Tags: Getting Started, Strategies*

---

**Alessio** - *11:42:08*

that's because the order is not in sync with the status on the other side though, not just flumine refusing it

*Tags: General Technical*

---

**liam** - *11:47:06*

Yeah there is flumine blocking it if it violates one of the controls or the actual place request failing in which case you have to wait till the status updates 

*Tags: General Technical*

---

**Misha** - *12:03:35*

Would think that any performance penalty would be negligible

*Tags: Performance*

---

**Dave** - *12:08:08*

Well, at least newer versions of python use a faster decimal implementation. Generally I like to keep things as fast as possible, maybe in real-time trading it doesn't matter too much given network bottlenecks and whatnot, but if it cuts my backtesting time 10x due to a large number of markets pumping through at once then I find that to be a win. For me, decimal slowdown is indeed negligible.

*Tags: Performance, Strategies*

---

**Mo** - *12:09:00*

[@U016535QCJ2](@U016535QCJ2) seems a bit irrelevant to comment on C#'s Decimal implementation when we're talking about flumine

*Tags: General Technical*

---

**Misha** - *12:09:17*

Is Python's implementation slow?

*Tags: Performance*

---

**Misha** - *12:10:09*

Premature optimisation is a very common problem

*Tags: General Technical*

---

**Misha** - *12:12:48*

[@UBS7QANF3](@UBS7QANF3) - there are certain things in common that don't change with language. I would be surprised if Python isn't pretty efficient at handling decimals

*Tags: General Technical*

---

**Dave** - *12:13:16*

Python3 uses cdecimal which is significantly faster than the old decimal implementation. But still, being able to backtest + review results quickly IMO is super important. And if you backtest on a large number of markets then what might seem negligible on a single-maeket basis ends up adding up if you go through millions of markets. Especially if you have these "negligible inneficiencies" everywhere

*Tags: General Technical*

---

**Misha** - *12:16:27*

Optimisation is about working out the bottlenecks, as one or two simple optimsations usually account for 90% of the performance gains. But I still come back to the fact that if you aren't measuring the performance gain, how would you know if you are getting a gain/

*Tags: Performance*

---

**Dave** - *12:21:58*

Hmm - often it is not required to measure it if you know the impact already. E.g. one simple optimisation in python is to assign functions on objects to variables. If you're appending a large number of items to a list, you will probably want to do `push = mylist.append` and use `push(myitem)` in your loop rather than  `mylist.append(myitem)` . Someone might call it premature optimisation as it would take a laaarge number of case for the gains to be really material, but you may end up facing such a large number of calls during backtesting.

*Tags: General Technical*

---

**D C** - *12:38:20*

I'm very confused by what people mean by "decimal" here? Is this python speak for double precision floating point arithmetic or a library of some kind?

*Tags: General Technical*

---

**Misha** - *12:48:59*

Decimals are encoded exactly, so no rounding errors (nothing to do with language). Short for binary coded decimal

*Tags: Errors Debugging*

---

**Misha** - *12:53:12*

If you use decimals you can do value comparison (equals). Not do with floating point as rounding errors can leave inexact values

*Tags: Errors Debugging*

---

**liam** - *13:19:21*

+1 [https://wiki.python.org/moin/PythonSpeed/PerformanceTips|this](https://wiki.python.org/moin/PythonSpeed/PerformanceTips|this) is a good read if you haven’t read yet

*Tags: Performance*

---

**Misha** - *14:25:35*

Things to watch for in any language: string concatenation if strings are immutable (true for C#), sorted lists versus dictionaries (if you don't need sorting, dictionaries which use hash tables are much faster). streaming to/from text (always comparatively very slow), deep copying of tree-like objects (better to copy references to nodes that don't change)

*Tags: Performance*

---

**Misha** - *14:29:00*

Oh, and disk I/O is incredibly slow in comparison to in-memory processing. Databases even slower. Don't have this stuff in a time-sensitive processing pipeline unless absolutely necessary

*Tags: Performance*

---

**Alessio** - *15:30:52*

Correct, but modern databases with granular locking mechanism have evolved quite a lot. And the new wave is even more around that. I know Redis's author and he spent most of his time engineering exactly around this stuff.

*Tags: General Technical*

---

**Misha** - *21:57:25*

Yes, all database servers have improved performance and efficiency over the years

*Tags: Performance, Deployment*

---

## 2021-01-03

**JC** - *12:51:09*

I'm running a strategy via flumine and getting the following response error from Betfair, anyone got any idea what might be going wrong? The strategy worked fine in backtesting



`{"asctime": "2021-01-03 12:50:30,712", "levelname": "ERROR", "message": "Execution error"`



`\nException: None \nError: {'code': -32602, 'message': 'DSC-0018'} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}`

*Tags: Errors Debugging, Strategies*

---

**JC** - *12:57:44*

this is the start of the log

`{"asctime": "2021-01-03 12:45:09,144", "levelname": "ERROR", "message": "Execution error", "trading_function": "place", "response": "SportsAPING/v1.0/placeOrders \nParams: {'marketId': '1.177514173', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 24003006, 'side': 'BACK', 'handicap': 0, 'limitOrder': {'price': 2.02, 'persistenceType': 'LIMIT', 'size': 4}, 'customerOrderRef': 'ec2e3b2b42f12-138289707090911470'}], 'customerRef': '833f4dc64dc111eb97cd0a1ab5524ac8', 'customerStrategyRef': 'ip-172-31-40-12', 'async': False} \nException: None \nError: {'code': -32602, 'message': 'DSC-0018'} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}", "order_package": {"id": "833f4dc6-4dc1-11eb-97cd-0a1ab5524ac8", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f59562b9a50&gt;", "market_id": "1.177514173", "orders": ["138289707090911470"], "package_type": "Place", "customer_strategy_ref": "ip-172-31-40-12"}}`

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *13:06:30*

Could they make that error message any more cryptic 

*Tags: Errors Debugging*

---

**nthypes** - *16:26:07*

```line 35, in process_market_book\n    s = runner.last_price_traded - runner.sp.near_price\nTypeError: unsupported operand type(s) for -: 'float' and 'str'"}```

*Tags: Errors Debugging*

---

**liam** - *16:32:57*

This is betfair so it can be a string, helper function [https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/utils.py#L112|here](https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/utils.py#L112|here) that flumine uses 

*Tags: General Technical*

---

## 2021-01-04

**Lee** - *20:15:01*

What happens in the case of duplicating a strategy? An order from each strategy will be combined into one packaged and one of them will be ignored?

*Tags: Strategies*

---

**Lee** - *22:12:27*

[https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/strategy/strategy.py#L158|https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/strategy/strategy.py#L158](https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/strategy/strategy.py#L158|https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/strategy/strategy.py#L158)

*Tags: Strategies*

---

**Alessio** - *22:29:59*

log_violation_errors is an extra bool that makes them pop

*Tags: Errors Debugging*

---

## 2021-01-05

**Mick** - *07:50:59*

Just got Error code from betfairlightweight -32099... is there somewhere to look up the meaning of the error codes?

*Tags: Errors Debugging*

---

**Mick** - *07:55:25*

Doh!... it's actually printed as part of the message... it's TIMEOUT_ERROR

*Tags: Errors Debugging*

---

**mandelbot** - *08:22:37*

On a seperate note why would an order not get matched even though it's taking the price available?

`"orders": ["138291273086345874"], "notes": "", "market_notes": "6.6,6.8,6.8", "status": "Pending", "status_log": "Pending"}, "order_type": {"order_type": "Limit", "price": 6.8, "size": 59.64, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 59.64, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2020-11-08 04:39:45.242000", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Executable", "status_log": "Pending, Executable", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 33.57, "matched": []}}`

`{"asctime": "2021-01-05 08:15:08,634", "levelname": "INFO", "message": "Trade status update: Live", "id": "1fd92291-4f2e-11eb-bc86-5c969d7d9766", "strategy": "projectedBotAUSHR", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138291273086345874"], "notes": "", "market_notes": "6.6,6.8,6.8", "status": "Live", "status_log": "Pending, Live"}`

*Tags: Deployment, Strategies*

---

**Alessio** - *10:03:28*

Hey [@U4H19D1D2](@U4H19D1D2) how did you choose the 1200 seconds for the API keep_alive? I am seeing repeatedly this stuff:

`{"asctime": "2021-01-05 09:56:39,831", "levelname": "ERROR", "message": "keep_alive error", "exc_info": "Traceback (most recent call last):\n File \"/usr/local/lib/python3.7/site-packages/flumine/worker.py\", line 97, in keep_alive\n  resp = client.keep_alive()\n File \"/usr/local/lib/python3.7/site-packages/flumine/clients/betfairclient.py\", line 32, in keep_alive\n  return self.betting_client.keep_alive()\n File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/keepalive.py\", line 30, in __call__\n  (response, response_json, elapsed_time) = self.request(session=session)\n File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/keepalive.py\", line 56, in request\n  self._error_handler(response_json)\n File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/keepalive.py\", line 63, in _error_handler\n  raise self._error(response)\nbetfairlightweight.exceptions.KeepAliveError: API keepAlive FAIL: NO_SESSION", "trading_function": "keep_alive", "response": "API keepAlive FAIL: NO_SESSION"}`

*Tags: Errors Debugging, Deployment, Strategies*

---

**Alessio** - *10:15:33*

(it's logging in correctly, working everything, but i get those keep alive errors)

*Tags: Errors Debugging, Deployment*

---

**Lee** - *10:19:19*

[https://github.com/liampauling/betfair/blob/0818be2d30b0e27d354ed48c50d8c9545d0f691f/betfairlightweight/baseclient.py#L56|here](https://github.com/liampauling/betfair/blob/0818be2d30b0e27d354ed48c50d8c9545d0f691f/betfairlightweight/baseclient.py#L56|here) it looks like you can provide `italy` as the locale to the client. are you doing that already?

*Tags: General Technical*

---

**liam** - *10:23:29*

There is an issue for this, flumine needs to be updated, welcome a pr on it 

*Tags: General Technical*

---

**liam** - *12:57:10*

[https://github.com/liampauling/flumine/issues/358|#358](https://github.com/liampauling/flumine/issues/358|#358)

*Tags: General Technical*

---

## 2021-01-07

**birchy** - *14:16:27*

stupid question...where do I set a custom `customer_strategy_ref` in Flumine? Been all through order, trade, place_order(), etc but not found it yet...

*Tags: Strategies*

---

**liam** - *14:36:00*

flumine uses it internally so you can't use it for anything custom

*Tags: General Technical*

---

**birchy** - *14:47:52*

OK...so how do I identify which strategy placed the bets when calling `listClearedOrders` ? i.e. some identifier that tells me where the bet originated from without having a local cache?

*Tags: Strategies*

---

**birchy** - *14:48:49*

pre-flumine/bflw, I used the `customer_strategy_ref` it is returned by the API

*Tags: Strategies*

---

**Newbie99** - *14:49:24*

you need to create a hash of the strategy name and see if it matches, something along these lines:



```strategy_name_list = [{'strategy_name': strategy,

                      'strategy_hash': flumine.utils.create_cheap_hash(strategy, 13)}

                      for strategy in strategy_list]```

*Tags: Strategies*

---

**Newbie99** - *14:49:42*

(where strategy_list is a list of your strategy names)

*Tags: Strategies*

---

**liam** - *14:50:13*

flumine way of doing this is to use loggingcontrol class to record all your orders/trades to either csv/db/api

*Tags: General Technical*

---

**birchy** - *14:53:33*

Based on this? [https://github.com/liampauling/flumine/blob/master/examples/controls/backtestloggingcontrol.py](https://github.com/liampauling/flumine/blob/master/examples/controls/backtestloggingcontrol.py)

*Tags: General Technical*

---

**liam** - *14:59:06*

yep, docs [https://liampauling.github.io/flumine/advanced/#logging-controls|here](https://liampauling.github.io/flumine/advanced/#logging-controls|here)

*Tags: General Technical*

---

## 2021-01-08

**jhaa** - *10:24:56*

I could just replicate the same thing on a different fixture

*Tags: Errors Debugging*

---

## 2021-01-09

**Ruben** - *12:17:02*

good morning everyone, I'm backtesting a market with flumine, pre-event, and I'm submitting a `LimitOrder` with `persistence_type = 'LAPSE'` . The market is supposed to turn in-play at 20:15:00. Looking at `order.responses.place_responses`  I see this order was placed at 20:15:38. Why could this be? The market turned inplay later than expected?

*Tags: General Technical*

---

**liam** - *12:30:59*

Watch out when backtesting and persistence as we don’t have much logic surrounding it [https://github.com/liampauling/flumine/issues/192|https://github.com/liampauling/flumine/issues/192](https://github.com/liampauling/flumine/issues/192|https://github.com/liampauling/flumine/issues/192)

*Tags: General Technical*

---

**Lee** - *13:13:46*

I've just been looking through the codebase to understand why markets are not clearing and calling my log control for an hour but i'm not sure i quite understand it.

```2021-01-08T13:31:29.835886969Z app[prod.1]: {"asctime": "2021-01-08 13:31:29,835", "levelname": "INFO", "message": "Market 1.177713641 closed", "market_id": "1.177713641", "date_time_closed": "2021-01-08T13:31:29.835544"}

2021-01-08T13:31:29.838371374Z app[prod.1]: {"asctime": "2021-01-08 13:31:29,837", "levelname": "INFO", "message": "Market closed", "market_id": "1.177713641", "client": {"….

2021-01-08T14:35:15.808288346Z app[prod.1]: {"asctime": "2021-01-08 14:35:15,807", "levelname": "INFO", "message": "Removing market 1.177713641", "client":

2021-01-08T14:35:15.808770984Z app[prod.1]: {"asctime": "2021-01-08 14:35:15,808", "levelname": "INFO", "message": "Market removed", "market_id": "1.177713641"}

2021-01-08T14:37:43.073071965Z app[prod.1]: {"asctime": "2021-01-08 14:37:43,072", "levelname": "INFO", "message": "1.177713641: x cleared orders found, more available: False"}

2021-01-08T14:37:43.076750659Z app[prod.1]: {"asctime": "2021-01-08 14:37:43,074", "levelname": "WARNING", "message": "Market 1.177713641 not present when clearing", "market_id": "1.177713641",

2021-01-08T14:38:15.168358314Z app[prod.1]: {"asctime": "2021-01-08 14:38:15,168", "levelname": "INFO", "message": "Market level cleared", "market_id": "1.177713641", "profit": x, "bet_count": x}```

Based on these logs it seems like at 13.31

1. we get a market closed event as the `market_book.status = "CLOSED"` 

2. triggers [https://github.com/liampauling/flumine/blob/master/flumine/baseflumine.py#L252|this](https://github.com/liampauling/flumine/blob/master/flumine/baseflumine.py#L252|this) code and adds the market to the `cleared_market_queue` 

3. a worker polls betfair for the cleared orders for the market and will retry until success

4. on success updates my log control (doesn't get here until 14:38)

Then 14:35 the market is removed which seems like it was called based on [https://github.com/liampauling/flumine/blob/master/flumine/baseflumine.py#L293|this](https://github.com/liampauling/flumine/blob/master/flumine/baseflumine.py#L293|this) line (which happens after at least 1 hour). But I don't see the "Market closed" log again so was this method called somewhere else or the code stuck inbetween or just betfair updating status to `CLOSED` late?

*Tags: General Technical*

---

## 2021-01-11

**Newbie99** - *22:23:16*

```{"asctime": "2021-01-11 22:06:46,792", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.177838493", "selection_id": 25383704, "handicap": 0, "id": "138296955628176706", "customer_order_ref": "869aeb021cad4-138296955628176706", "bet_id": "221534743900", "trade": {"id": "f3590071-5458-11eb-b622-2016d8944b85", "strategy": "simple_back_mm", "status": "TradeStatus.LIVE", "orders": ["138296954581483634", "138296954616777215", "138296955628176706"], "notes": "", "market_notes": "13.5,14,13.5"}, "order_type": {"order_type": "Limit", "price": 13.5, "size": 0.2, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.01, "size_remaining": 0.19, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 13.5}, "status": "Violation", "status_log": "Pending, Executable, Replacing, Violation"}

INFO:flumine.order.trade:Trade status update: Complete

{"asctime": "2021-01-11 22:06:46,793", "levelname": "INFO", "message": "Trade status update: Complete", "id": "f3590071-5458-11eb-b622-2016d8944b85", "strategy": "simple_back_mm", "status": "TradeStatus.COMPLETE", "orders": ["138296954581483634", "138296954616777215", "138296955628176706"], "notes": "", "market_notes": "13.5,14,13.5"}

WARNING:flumine.controls:Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency

{"asctime": "2021-01-11 22:06:46,794", "levelname": "WARNING", "message": "Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency", "control": "ORDER_VALIDATION", "error": "Order size is less than min bet size (2) or payout (10) for currency", "order": {"market_id": "1.177838493", "selection_id": 25383704, "handicap": 0, "id": "138296955628176706", "customer_order_ref": "869aeb021cad4-138296955628176706", "bet_id": "221534743900", "trade": {"id": "f3590071-5458-11eb-b622-2016d8944b85", "strategy": "simple_back_mm", "status": "TradeStatus.COMPLETE", "orders": ["138296954581483634", "138296954616777215", "138296955628176706"], "notes": "", "market_notes": "13.5,14,13.5"}, "order_type": {"order_type": "Limit", "price": 13.5, "size": 0.2, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.01, "size_remaining": 0.19, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 13.5}, "status": "Violation", "status_log": "Pending, Executable, Replacing, Violation"}}```

With Flumine, the above violates (obviously because its less than GBP 10), however using the REST API it is possible to replace small orders, so should it work from Flumine, or is the above expected behaviour (specifically on a replace)?



If so, other than quickly placing and cancelling, is there a smarter way to submit small orders (I know this comes up every now and again, but I thought the replace approach was the correct one and I'd never really had much of a need when streaming before)?

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2021-01-13

**liam** - *10:57:13*

simulation limitation pending a fix [https://github.com/liampauling/flumine/blob/2adcd24379e07dfc1a017ffcc7895d99102814ee/flumine/backtest/simulated.py#L37](https://github.com/liampauling/flumine/blob/2adcd24379e07dfc1a017ffcc7895d99102814ee/flumine/backtest/simulated.py#L37)

*Tags: Errors Debugging*

---

**Mo** - *12:46:26*

If you are using flumine to do the recording then the following is handled for you but it might be useful for you to be aware that the live streaming data does not contain runner names or competition information and that you need to record the market catalogue as well

*Tags: Deployment*

---

**Oliver Varney** - *13:57:35*

can someone confirm what the streaming_market_data_filter would be for the betfair pro files. [@UBS7QANF3](@UBS7QANF3) you said their volumes were non virtual right ?

*Tags: General Technical*

---

**Oliver Varney** - *14:01:10*

yes my model is trained off these files so I will need to match the settings

*Tags: Strategies*

---

**Mo** - *14:07:26*

That is the filter for virtual prices but you can request EX_ALL_OFFERS and EX_BEST_OFFERS_DISP simultaneously; if your prices file contains both then bflw will prioritise the *non-virtual prices*

*Tags: General Technical*

---

**river_shah** - *14:16:49*

Thanks [@UBS7QANF3](@UBS7QANF3) Appreciate your help as always

*Tags: General Technical*

---

## 2021-01-14

**Newbie99** - *09:31:57*

This is confusing me a bit, I've been getting this a lot over the last couple of days (seemingly out of the blue). Whilst the error is self explanatory, what I'm not understanding is how it occurs, as I check the order status before any cancel or replace:



```Traceback (most recent call last):

  File "jumps.py", line 187, in &lt;module&gt;

    framework.run()

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/flumine.py", line 32, in run

    self._process_current_orders(event)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/baseflumine.py", line 238, in _process_current_orders

    strategy.process_orders(market, strategy_orders)

  File "/home/ec2-user/trading/env/projects/simple_book.py", line 418, in process_orders

    rf.cancel_and_replace_orders(self, orders, market)

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 3563, in cancel_and_replace_orders

    back_all_runners_without_back_price

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 3699, in replace_all_orders

    self.replace_order(market, order, back_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/strategy/strategy.py", line 146, in replace_order

    market.replace_order(order, new_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/markets/market.py", line 70, in replace_order

    order.replace(new_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/order.py", line 332, in replace

    raise OrderUpdateError("Current status: %s" % self.status)

flumine.exceptions.OrderUpdateError: Current status: OrderStatus.CANCELLING```

*Tags: Errors Debugging, Deployment, Strategies*

---

**Newbie99** - *09:34:30*

```{"asctime": "2021-01-14 09:12:30,117", "levelname": "INFO", "message": "Order status update: Cancelling", "market_id": "1.177891689", "selection_id": 16786966, "handicap": 0, "id": "138299083469138870", "customer_order_ref": "6012fe3b915f7-138299083469138870", "bet_id": "221690469430", "date_time_created": "2021-01-14 09:12:26.913912", "publish_time": "2021-01-14 09:12:26.886000", "trade": {"id": "9ef0aa3a-5648-11eb-a0bb-02f9e1e2dd3a", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138299083469138870"], "notes": "", "market_notes": "8.4,8.8,8.6", "status": "Live", "status_log": "Pending, Live"}, "order_type": {"order_type": "Limit", "price": 8.2, "size": 2.08, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 2.08, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-01-14 09:12:27.117261", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Cancelling", "status_log": "Pending, Executable, Cancelling", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}}

INFO:flumine.streams.orderstream:Stopped OrderStream 1001

{"asctime": "2021-01-14 09:12:30,117", "levelname": "INFO", "message": "Stopped OrderStream 1001"}

INFO:flumine.streams.marketstream:Stopped MarketStream 2001

{"asctime": "2021-01-14 09:12:30,118", "levelname": "INFO", "message": "Stopped MarketStream 2001"}

INFO:flumine.execution.baseexecution:Shutting down Execution (SimulatedExecution)

{"asctime": "2021-01-14 09:12:30,118", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

INFO:flumine.execution.baseexecution:Shutting down Execution (BetfairExecution)

{"asctime": "2021-01-14 09:12:30,119", "levelname": "INFO", "message": "Shutting down Execution (BetfairExecution)"}

INFO:flumine.worker:BackgroundWorker keep_alive shutting down

{"asctime": "2021-01-14 09:12:30,119", "levelname": "INFO", "message": "BackgroundWorker keep_alive shutting down", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x7f7644889680&gt;"}

INFO:flumine.streams.orderstream:Stopped output_thread (OrderStream 1001)

{"asctime": "2021-01-14 09:12:30,365", "levelname": "INFO", "message": "Stopped output_thread (OrderStream 1001)"}

INFO:flumine.streams.marketstream:Stopped output_thread (MarketStream 2001)

{"asctime": "2021-01-14 09:12:32,043", "levelname": "INFO", "message": "Stopped output_thread (MarketStream 2001)"}

INFO:flumine.worker:BackgroundWorker poll_account_balance shutting down

{"asctime": "2021-01-14 09:12:34,120", "levelname": "INFO", "message": "BackgroundWorker poll_account_balance shutting down", "worker_name": "poll_account_balance", "function": "&lt;function poll_account_balance at 0x7f76448967a0&gt;"}

INFO:flumine.worker:BackgroundWorker poll_market_catalogue shutting down

{"asctime": "2021-01-14 09:12:38,120", "levelname": "INFO", "message": "BackgroundWorker poll_market_catalogue shutting down", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x7f7644896710&gt;"}

INFO:flumine.worker:BackgroundWorker poll_cleared_orders shutting down

{"asctime": "2021-01-14 09:12:42,121", "levelname": "INFO", "message": "BackgroundWorker poll_cleared_orders shutting down", "worker_name": "poll_cleared_orders", "function": "&lt;function poll_cleared_orders at 0x7f7644896830&gt;"}

INFO:flumine.baseflumine:Exiting flumine

{"asctime": "2021-01-14 09:12:46,214", "levelname": "INFO", "message": "Exiting flumine", "client": {"id": "74093be2", "exchange": "Betfair", "betting_client": "APIClient", "chargeable_transaction_count": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxOrderCount object at 0x7f7643506d50&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}, "markets": {"market_count": 262, "open_market_count": 259}, "streams": ["&lt;OrderStream(OrderStream, stopped daemon 140145877423872)&gt;", "&lt;MarketStream(MarketStream, stopped daemon 140145869031168)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140146403047232)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 140145910994688)&gt;", "&lt;BackgroundWorker(poll_account_balance, started daemon 140145902601984)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 140145894209280)&gt;", "&lt;BackgroundWorker(poll_cleared_orders, started daemon 140145885816576)&gt;"]}

Traceback (most recent call last):

  File "jumps.py", line 187, in &lt;module&gt;

    framework.run()

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/flumine.py", line 32, in run

    self._process_current_orders(event)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/baseflumine.py", line 238, in _process_current_orders

    strategy.process_orders(market, strategy_orders)

  File "/home/ec2-user/trading/env/projects/simple_book.py", line 418, in process_orders

    rf.cancel_and_replace_orders(self, orders, market)

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 3563, in cancel_and_replace_orders

    back_all_runners_without_back_price

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 3699, in replace_all_orders

    self.replace_order(market, order, back_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/strategy/strategy.py", line 146, in replace_order

    market.replace_order(order, new_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/markets/market.py", line 70, in replace_order

    order.replace(new_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/order.py", line 332, in replace

    raise OrderUpdateError("Current status: %s" % self.status)

flumine.exceptions.OrderUpdateError: Current status: OrderStatus.CANCELLING

(env) [ec2-user@ip-172-31-8-45 projects]$       ```

*Tags: Errors Debugging, Deployment, Strategies*

---

**Newbie99** - *09:37:39*

my logic is quite simple under process current orders tbh:



```    def process_orders(self, market, orders):

        if market.market_book is not None and \

                market.market_book.status not in ['CLOSED','SUSPENDED'] and \

            len([order for order in market.blotter.strategy_orders(self) if order.status == OrderStatus.EXECUTABLE]) != 0:



            rf.cancel_and_replace_orders(self, orders, market)```

*Tags: Strategies*

---

**Newbie99** - *09:43:29*

As in the logic within the function? Its completely possible its not perfect, but what I don't understand is, given I check the order is Executable at multiple points, how can the status be incorrect (even if say I'm trying to cancel when I mean to replace, it wouldn't throw that error)?

*Tags: Errors Debugging*

---

**liam** - *09:43:29*

Recommend [http://sentry.io|sentry.io](http://sentry.io|sentry.io) btw as you would then get the full traceback with a lot more info although that error could be improved

*Tags: Errors Debugging*

---

## 2021-01-18

**liam** - *05:47:45*

Are you able to login with bflw ok?

*Tags: General Technical*

---

**Unknown** - *11:49:11*

Hi [@U4H19D1D2](@U4H19D1D2) I am now using pympler to track my memory leaks and found that some 'list' are taking a lot of my RAM memory. Do you know how can I locate the exact lists which are causing the problem?

*Tags: Performance*

---

**liam** - *11:52:04*

If you are not creating any yourself then it is likely to the bflw and the Available class, is the memory leaking or stable?

*Tags: Performance*

---

**Jorge** - *11:55:07*

I had this problem before using bflw so it is most probably not that. It is stable, but a single process takes up to 80MB RAM for me, and I am not storing big amounts of data so I want to optimize it...

*Tags: General Technical*

---

**Jorge** - *12:30:17*

Well, the size of my python lists (as returned from pympler) increases non-stop (for ex. 500MB after 1 hour of running the process). But I guess some of these are being removed?

*Tags: General Technical*

---

**Diniz** - *17:58:42*

Not really, I get the same errors.

Do the certificates need to have a specific name? I'm just passing the folder where they are

*Tags: Errors Debugging*

---

**liam** - *18:05:11*

Python version? OS? Are you getting this on login?

*Tags: General Technical*

---

**Diniz** - *18:30:51*

Python 3.8, Windows 10.

yes, just running



&gt; trading = betfairlightweight.APIClient(

&gt;         "username", "password", app_key="app_key", certs="/certs"

&gt;     )

&gt;  trading.login()

*Tags: Strategies*

---

**Diniz** - *18:35:11*

with the same arguments I'm passing to bflw

*Tags: General Technical*

---

**liam** - *18:35:36*

So where are your certs? I guess not in /certs as per the bflw example?

*Tags: General Technical*

---

**Diniz** - *18:39:36*

I'm getting this error atm: urllib3.exceptions.SSLError: Client private key is encrypted, password is required

*Tags: Errors Debugging*

---

## 2021-01-19

**jhaa** - *19:03:46*

I have a bunch of football fixtures in a database and query the inplay scores using the event_ids. Some of those fixtures are accumulators or specials which cause the query to return an error:



`Traceback (most recent call last):`

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 108, in process_response

    return [resource(elapsed_time=elapsed_time, **x) for x in result]

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 108, in &lt;listcomp&gt;

    return [resource(elapsed_time=elapsed_time, **x) for x in result]

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/resources/inplayserviceresources.py", line 193, in __init__

    self.score = Score(**kwargs.get("score"))

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/resources/inplayserviceresources.py", line 87, in __init__

    self.home = HomeAwayBase(**home)

TypeError: __init__() missing 1 required positional argument: 'name'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File "/home/code/PycharmProjects/betfair_jhaa/v2/core/StreamEngine.py", line 247, in query_inplay_scores

    scores = [http://self.trading.in|self.trading.in](http://self.trading.in|self.trading.in)_play_service.get_scores(event_ids=event_ids)

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/endpoints/inplayservice.py", line 99, in get_scores

    return self.process_response(

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 110, in process_response

    raise InvalidResponse(response=result)

betfairlightweight.exceptions.InvalidResponse: Invalid response received:

*Tags: Errors Debugging, Strategies*

---

**liam** - *19:05:09*

Yeah, if you have the response that would be great to see what the error is 

*Tags: Errors Debugging*

---

**liam** - *19:12:55*

Cheers, I think we are always going to have problems with these undocumented endpoints and resource creation, lightweight mode gets around this of course but raw dicts aren’t for everyone 

*Tags: General Technical*

---

## 2021-01-21

**liam** - *13:29:53*

Getting place errors, anyone else?

*Tags: Errors Debugging*

---

**D C** - *13:33:51*

no problems for me in the last at lingfield

*Tags: General Technical*

---

**Lee** - *13:34:25*

no problem for me either

*Tags: General Technical*

---

**jhaa** - *15:01:29*

Every other day one of the threads in my bot stops working without throwing an error or crashing the whole thing. I suspect tenacity might be the reason why I get no error message. I use the example that restarts the order and market streams. Any suggestion what might cause this or anybody has experienced similar?

*Tags: Errors Debugging*

---

**liam** - *15:02:32*

sharing the code might help us guess

*Tags: General Technical*

---

**jhaa** - *15:05:46*

well I do not know where to start looking in the code if there is no error message... I use tenacity the way it is used here:  [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)

*Tags: Errors Debugging*

---

**jhaa** - *15:08:15*

I have a slow thread and a fast thread that do different things and have different urgencies. A week ago I could see in the logs that the slow thread stopped working because I only had output from the fast thread in the logs. Today it was the other way around. There are no error messages.

*Tags: Errors Debugging, Performance*

---

**jhaa** - *15:10:02*

as in the thing thre an exception without printing/logging the error message

*Tags: Errors Debugging*

---

**jhaa** - *15:10:58*

so without error message I do not know where to start looking

*Tags: Errors Debugging*

---

**Jonjonjon** - *15:14:20*

[@UE72WCRR8](@UE72WCRR8) I had similar problems due to a memory leak.



In `process_market_book` I stored market-level data, and forgot to delete it when the market closed.

*Tags: Performance*

---

**jhaa** - *15:19:40*

[@UN1497LJC](@UN1497LJC) is that flumine? I use plain bflw.

*Tags: General Technical*

---

**liam** - *15:19:47*

is it exactly as per the bflw example?

*Tags: General Technical*

---

**jhaa** - *15:20:50*

```class SafeStreamingThread(threading.Thread):

    def __init__(

        self,

        client: betfairlightweight.APIClient,

        market_filter: dict,

        market_data_filter: dict,

        conflate_ms: int = None,

        streaming_unique_id: int = 1000,

        queue = None,

        listener = None

    ):

        threading.Thread.__init__(self, daemon=True, name=self.__class__.__name__)

        self.client = client

        self.market_filter = market_filter

        self.market_data_filter = market_data_filter

        self.conflate_ms = conflate_ms

        self.streaming_unique_id = streaming_unique_id

        self.stream = None

        self.output_queue = queue

        self.listener = listener #StreamListener(output_queue=self.output_queue)



    @retry(wait=wait_exponential(multiplier=1, min=2, max=20))

    def run(self) -&gt; None:

        [http://logging.info|logging.info](http://logging.info|logging.info)("Starting MarketStreaming")

        self.client.login()

        self.stream = self.client.streaming.create_stream(

            unique_id=self.streaming_unique_id, listener=self.listener

        )

        try:

            self.streaming_unique_id = self.stream.subscribe_to_markets(

                market_filter=self.market_filter,

                market_data_filter=self.market_data_filter,

                conflate_ms=self.conflate_ms,

                initial_clk=self.listener.initial_clk,  # supplying these two values allows a reconnect

                clk=self.listener.clk,

            )

            self.stream.start()

        except BetfairError:

            logging.error("MarketStreaming run error", exc_info=True)

            raise

        except Exception:

            logging.critical("MarketStreaming run error", exc_info=True)

            raise

        [http://logging.info|logging.info](http://logging.info|logging.info)("Stopped MarketStreaming {0}".format(self.streaming_unique_id))



    def stop(self) -&gt; None:

        if self.stream:

            self.stream.stop()```



*Tags: Errors Debugging*

---

**Jonjonjon** - *15:24:46*

[@UE72WCRR8](@UE72WCRR8) Yes, I use Flumine. And [@U4H19D1D2](@U4H19D1D2) already pointed out that the problem I had is probably unrelated to yours.

*Tags: General Technical*

---

**liam** - *15:24:59*

Only way this could fail without logs is if it errors on that login call 

*Tags: Errors Debugging*

---

**jhaa** - *15:28:39*

supposedly it writes the error message

*Tags: Errors Debugging*

---

**liam** - *15:37:40*

test it by raising a random error or disconnecting from the internet

*Tags: Errors Debugging*

---

## 2021-01-23

**birchy** - *15:02:25*

[@U4H19D1D2](@U4H19D1D2) I'm developing my first Flumine middleware. Just to confirm, if I want to add runner info to the market, is it correct to add it to `market.context` , or should it be added somewhere else? Can middleware add data to a `RunnerBook` ?

*Tags: General Technical*

---

## 2021-01-27

**Peter C** - *16:17:52*

What is the easiest way to pull out which runner won when streaming historical data using flumine? I'm currently calculating it from last traded price, but it feels like there's a more explicit route which I'm missing

*Tags: Data Quality*

---

## 2021-01-28

**Oliver Varney** - *08:59:47*

the dev status site says its fixed now I think, it looked like a getAccountFunds issue

*Tags: Errors Debugging*

---

**liam** - *09:01:27*

yeah I am getting errors

*Tags: Errors Debugging*

---

**liam** - *09:04:55*

flumine does, not sure it has ever fatally crashed

*Tags: General Technical*

---

**thambie1** - *09:05:50*

pretty nice... gotta read some more flumine code tomorrow :slightly_smiling_face:

*Tags: General Technical*

---

**thambie1** - *09:12:35*

Yeah, that parts easy. The part I need to put some effort into is handling the business logic afterwards. In this particular case, how should be bot handle the case where my account funds knowledge is stale? Keep betting normal sizes, and risk getting an insufficient funds error? Keep betting, and not have my fail safes regarding losing too much money too quickly?

*Tags: Errors Debugging, Strategies*

---

**liam** - *09:15:35*

i think the real problem is basing fail safes on your balance, surely you trust the strategy / exposure calculations to not have to do that

*Tags: Strategies*

---

**Lee** - *09:19:20*

have a look at how flumine uses `max_order_exposure` and `max_selection_exposure`

*Tags: General Technical*

---

## 2021-01-30

**birchy** - *11:09:28*

[@U4H19D1D2](@U4H19D1D2) possibly, but I'm aiming for 10+ sports and would need different filters for each sport. I'd probably be better off making this a polling bot and calling markets list and caching the IDs I want to keep. My CPU is already at 80% with 10 second conflated streaming and I've only added 2 sports. :rolling_on_the_floor_laughing: 

Can now see the limitations of streaming vs polling, which presumably is why Betfair still have both available.

*Tags: General Technical*

---

**liam** - *11:39:59*

come monday that CPU should be much lower as I am going to refactor the order execution logic, out of interest what version of bflw are you using?

*Tags: General Technical*

---

**Misha** - *11:42:59*

It's possible to process a lot of markets, but you have to be super-efficient and do very little in the main processing thread. I'm not sure how Flumine is architected, but I tend to allocate pre-processing of the stream to other threads

*Tags: General Technical*

---

**liam** - *12:03:06*

so resource creation/processing is, the problem is that on every update the main thread checks every market to see if there are orders to process, this is fine when you have &lt;250 markets but the problem becomes O(n2)

*Tags: General Technical*

---

**liam** - *12:08:00*

the problem is that it was designed to group orders together into a single request where possible, this is fine for my use case/strategies but not great if you want to process a lot of markets

*Tags: General Technical*

---

**liam** - *12:28:46*

Did that upgrade help?

*Tags: General Technical*

---

**birchy** - *12:31:01*

My usage for this particular strategy is to have a small number of bets in lots of markets preplay, where speed is not required. Slow and steady wins this particular race, so polling is probably better suited. It's a shame that `listMarketCatalogue` doesn't have a param like `notMarketIds` where we could specify a list of market IDs that we're no longer interested in.

*Tags: Performance, Strategies*

---

**Dave** - *12:37:10*

If flumine had a multi-process mode, would be awesome.

*Tags: General Technical*

---

**liam** - *12:44:02*

Yeah its a complication I want to avoid at all costs, do you know the latency you add by doing that?

*Tags: Performance*

---

**birchy** - *13:02:49*

Just to clarify, if my bot identifies a market that it definitely doesn't need anymore, is it ok to close the market from within the Flumine strategy via `close_market`?

*Tags: Strategies*

---

**birchy** - *13:25:06*

[@U4H19D1D2](@U4H19D1D2) Is there a recommended way to close a market subscription gracefully from within a strategy, i.e. from `check_market_book` after identifying a market I don't want?

*Tags: Strategies*

---

**mandelbot** - *15:38:55*

im getting the following error when running backtests with the latest flumine and bflw

```Traceback (most recent call last):

  File "C:\Users\Admin\AppData\Local\Programs\Python\Python39\Lib\site-packages\flumine\examples\backtest2gh.py", line 54, in &lt;module&gt;

    framework.run()

  File "C:\Users\Admin\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\backtest\backtest.py", line 42, in run

    for event in stream_gen():

  File "C:\Users\Admin\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\streams\historicalstream.py", line 148, in _read_loop

    data = stream_snap()

  File "C:\Users\Admin\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\streams\historicalstream.py", line 67, in snap

    cache.market_definition["marketTime"]

KeyError: 'marketTime'```



*Tags: Errors Debugging*

---

**liam** - *15:48:47*

No market time in the def? That’s odd, upgrading flumine to 1.16.1 might fix 

*Tags: Errors Debugging*

---

**mandelbot** - *15:56:41*

i used betfairlightweight[speed] --upgrade though

*Tags: Performance*

---

**birchy** - *16:01:13*

Oh bugger. I guess the way forward is to poll listMarketCatalogue and specify the market id's in `streaming_market_filter`?

*Tags: Errors Debugging*

---

**birchy** - *16:33:52*

I can probably use specific filters for each event type and run a strategy per sport. Tempted to go 100% polling with this bot and save streaming for inplay, where speed IS important.

Also, just checked in and bot had crashed and burned. Last log was:

`{"asctime": "2021-01-30 08:31:23,529", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.178427846", "latency": 752.4693222045898, "pt": "2021-01-30T08:18:50.921000"}`

I'm guessing it's been terminated by the Linux OOM killer as ram was on 65% of 2GB when I last looked yesterday. That is/was using only

`streaming_market_filter(event_type_ids=['1'])`

*Tags: Performance, Strategies*

---

**Jorge** - *17:07:41*

Hi, when Streaming Orders, what is the best way to get the market_id from a CurrentOrders object? I am currently extracting in from current_orders.streaming_update['id'].

*Tags: General Technical*

---

**liam** - *17:13:52*

Well for streaming it makes sense so we could add it but wouldn’t want it on the resource as it would confuse those who use polling and see it as None all the time and could theoretically contain multiple markets orders 

*Tags: General Technical*

---

**Jorge** - *17:16:22*

Understood, well for me it works to get it from current_orders.streaming_update['id'] everytime I need it

*Tags: General Technical*

---

**Unknown** - *17:31:52*

Just as an FYI, restarted the bot with the above mentioned filter and no code changes. Strategy is minimal, i.e. nothing more than a single loop through the runners in `process_market_book`.

bflw 2.12.0

flumine 1.16.1

*Tags: Strategies*

---

## 2021-02-01

**liam** - *15:50:46*

[@U016TGY3676](@U016TGY3676) refactor [https://github.com/liampauling/flumine/pull/371|here](https://github.com/liampauling/flumine/pull/371|here) I am seeing a 10x decrease in CPU usage when subscribed to 1000+ markets but not fully tested yet and a pretty major refactor so be careful

*Tags: General Technical*

---

## 2021-02-02

**liam** - *09:29:00*

Note this is becoming a lot cleaner in the PR mentioned [https://betfairlightweight.slack.com/archives/C4H05ML2E/p1612194646142600|here](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1612194646142600|here)

*Tags: General Technical*

---

**liam** - *09:44:59*

yeah I use it a lot, you need to be careful when calling `market.place_order` as it doesn't call `strategy.validate_order` the PR I am working on fixes this by removing the `strategy.place_order` call completely

*Tags: Errors Debugging, Strategies*

---

## 2021-02-03

**Newbie99** - *16:44:57*

```INFO:flumine.order.order:Order status update: Execution complete

{"asctime": "2021-02-03 15:52:25,074", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.178737548", "selection_id": 12059876, "handicap": 0, "id": "138316603346915167", "customer_order_ref": "81ec14d3e0056-138316603346915167", "bet_id": "223429282318", "trade": {"id": "c9080f5e-6637-11eb-b51f-2016d8944b85", "strategy": "betting_market_back", "status": "TradeStatus.PENDING", "orders": ["138316603346915167"], "notes": "", "market_notes": "16.5,55,16.5"}, "order_type": {"order_type": "Limit", "price": 55.0, "size": 0.28, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.28, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Execution complete", "status_log": "Pending, Executable, Cancelling, Execution complete"}```

I might be mis-reading this, but given this was the last message from a cancellation, should the size_remaining &amp; size_cancelled not be the other way around (i.e. size_cancelled 0.28, size_remaining 0.0)?

*Tags: Strategies*

---

**liam** - *16:49:34*

assuming this log is from [https://github.com/liampauling/flumine/blob/dff610d5929d1c98cd39aa57ae1cab05ca7c4a87/flumine/execution/betfairexecution.py#L66|here](https://github.com/liampauling/flumine/blob/dff610d5929d1c98cd39aa57ae1cab05ca7c4a87/flumine/execution/betfairexecution.py#L66|here) it is because the `order.status` hasn't been updated yet, ie the update from order stream hasn't come through. Currently use that as the golden source however happy to discuss changing this

*Tags: General Technical*

---

**Newbie99** - *17:47:02*

for reference, this is the message from a cancel I requested (as opposed to BPE):



```INFO:flumine.order.order:Order status update: Execution complete

{"asctime": "2021-02-03 17:44:49,317", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.178739219", "selection_id": 20867982, "handicap": 0, "id": "138316670786111761", "customer_order_ref": "81ec14d3e0056-138316670786111761", "bet_id": "223440411072", "trade": {"id": "7cb88910-6647-11eb-a5d2-2016d8944b85", "strategy": "betting_market_back", "status": "TradeStatus.LIVE", "orders": ["138316670786111761"], "notes": "", "market_notes": "13.5,15,15.5"}, "order_type": {"order_type": "Limit", "price": 15.0, "size": 1.08, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 1.08, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Execution complete", "status_log": "Pending, Executable, Cancelling, Executable, Execution complete"}

INFO:flumine.order.trade:Trade status update: Complete```

*Tags: Deployment, Strategies*

---

**Peter C** - *20:40:15*

I'm trying to access live data for the first time - using the quickstart example from the docs. I import the example strategy, and start(self) runs, but then check_market_book doesn't appear to be called, but the program continues to run with no error. Has anyone experienced this before?

*Tags: Getting Started, Errors Debugging, Deployment, Strategies*

---

## 2021-02-04

**Peter C** - *07:29:52*

For anyone searching for this in the future the issue was that I hadn't imported the logging and therefore couldn't see the error message

*Tags: Errors Debugging*

---

**mandelbot** - *12:52:40*

```trading.login()



client = clients.BetfairClient(trading)



framework = Flumine(client=client)



strategy = MarketRecorder(

    name="WIN",

    market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["4339"],

        country_codes=["AU"],

        market_types=["WIN"]

        # market_ids=["1.169056942"],

        # event_ids=[29671376]

    ),

    stream_class=DataStream,

    context={

        "local_dir": "/home/ubuntu/Documents/Historical/GH/AU/",

        "bucket": "fluminetest",

        "force_update": False,

        "remove_file": False,

    },

)



strategy2 = MarketRecorder(

    name="WIN",

    market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["4339"],

        country_codes=["GB"],

        market_types=["WIN"]

        # market_ids=["1.169056942"],

        # event_ids=[29671376]

    ),

    stream_class=DataStream,

    context={

        "local_dir": "/home/ubuntu/Documents/Historical/GH/GB/",

        "bucket": "fluminetest",

        "force_update": False,

        "remove_file": False,

    },

)



strategy3 = MarketRecorder(

    name="WIN",

    market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU", "US", "SE", "FR"],

        market_types=["WIN"]

        # market_ids=["1.169056942"],

        # event_ids=[29671376]

    ),

    stream_class=DataStream,

    context={

        "local_dir": "/home/ubuntu/Documents/Historical/HR/AUUS/",

        "bucket": "fluminetest",

        "force_update": False,

        "remove_file": False,

    },

)



strategy4 = MarketRecorder(

    name="WIN",

    market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["GB","IE"],

        market_types=["WIN"]

        # market_ids=["1.169056942"],

        # event_ids=[29671376]

    ),

    stream_class=DataStream,

    context={

        "local_dir": "/home/ubuntu/Documents/Historical/HR/GBIE/",

        "bucket": "fluminetest",

        "force_update": False,

        "remove_file": False,

    },

)

framework.add_strategy(strategy)

framework.add_strategy(strategy2)

framework.add_strategy(strategy3)

framework.add_strategy(strategy4)



framework.run()```



*Tags: Strategies*

---

**mandelbot** - *13:16:56*

Absolutely nothing, straight out of the box flumine and bflw

*Tags: General Technical*

---

**mandelbot** - *13:19:46*

flumine 1.15.3

*Tags: General Technical*

---

**liam** - *13:20:06*

bflw?

*Tags: General Technical*

---

**mandelbot** - *13:20:14*

bflw 2.11.1

*Tags: General Technical*

---

**mandelbot** - *13:20:47*

using them on an ubuntu ec2

*Tags: Deployment*

---

**mandelbot** - *13:20:59*

but was also occurring on a windows server ec2

*Tags: Deployment*

---

**liam** - *13:26:02*

what are your logs saying? any errors / restarts?

*Tags: Errors Debugging*

---

**mandelbot** - *13:29:17*

hrms seems like im getting some timeout errors

*Tags: Errors Debugging*

---

**mandelbot** - *13:29:41*

`{"asctime": "2021-02-04 13:26:56,741", "levelname": "ERROR", "message": "poll_market_catalogue error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/flumine/worker.py\", line 132, in poll_market_catalogue\n    \"MARKET_DESCRIPTION\",\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py\", line 233, in list_market_catalogue\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue \nParams: {'maxResults': 25, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'filter': {'marketIds': ['1.178881473', '1.178881478', '1.178881488', '1.178881493', '1.178777677', '1.178777679', '1.178777426', '1.178833494', '1.178847880', '1.178847882', '1.178777194', '1.178883033', '1.178883028', '1.178883003', '1.178883008', '1.178883023', '1.178883018', '1.178883013', '1.178848742', '1.178848744', '1.178848702', '1.178848700', '1.178777963', '1.178777027']}} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang18a-prd-01140948-002d67ab25', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang18a-prd-01140948-002d67ab25', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_market_catalogue", "response": "SportsAPING/v1.0/listMarketCatalogue \nParams: {'maxResults': 25, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'filter': {'marketIds': ['1.178881473', '1.178881478', '1.178881488', '1.178881493', '1.178777677', '1.178777679', '1.178777426', '1.178833494', '1.178847880', '1.178847882', '1.178777194', '1.178883033', '1.178883028', '1.178883003', '1.178883008', '1.178883023', '1.178883018', '1.178883013', '1.178848742', '1.178848744', '1.178848702', '1.178848700', '1.178777963', '1.178777027']}} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang18a-prd-01140948-002d67ab25', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang18a-prd-01140948-002d67ab25', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}`

*Tags: Errors Debugging, Strategies*

---

**Lee** - *16:23:16*

I think i need to regenerate my cert again as i get ssl errors on later versions of openssl. If i upload another certificate under the Security settings page, will it add a second cert or replace my existing?

*Tags: Errors Debugging*

---

**Lee** - *17:01:29*

na, was getting the ca too weak error

*Tags: Errors Debugging*

---

**river_shah** - *18:40:37*

```2021-02-04 18:38:21.901 INFO  [OrderStream: 1001]: connection_id: 202-040221183821-2787044

2021-02-04 18:38:21.901 INFO  [MarketStream: 2001]: connection_id: 204-040221183821-2814581

2021-02-04 18:38:32.806 ERROR MarketStream run error

Traceback (most recent call last):

  File "/home/xxx/.local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 225, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "/apps/python/3.7.9/lib/python3.7/ssl.py", line 1056, in recv

    return self.read(buflen)

  File "/apps/python/3.7.9/lib/python3.7/ssl.py", line 931, in read

    return self._sslobj.read(len)

socket.timeout: The read operation timed out



During handling of the above exception, another exception occurred:```

Logins fine (can list market catalogue etc) but then get this when trying to stream. Not sure where to start debugging.

*Tags: Errors Debugging*

---

**river_shah** - *18:58:05*

works from inside a docker container on the same host…wondering if I blew something in an openssl update (same code between container and host so I think problem resides in base os)

*Tags: General Technical*

---

## 2021-02-05

**river_shah** - *17:02:18*

[@U4H19D1D2](@U4H19D1D2) can bflw and flumine allow interactive login please for streaming? if I don’t pass a cert path and use `trading.login_interactive()` the framework throws exception.

*Tags: Errors Debugging, Strategies*

---

**river_shah** - *17:42:43*

```  File "/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 229, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 1021]: Socket The read operation timed out```



*Tags: Errors Debugging*

---

**liam** - *18:51:24*

I would try creating a bflw stream and bump the timeout to see if that is he issue 

*Tags: General Technical*

---

## 2021-02-08

**ricky** - *23:44:42*

WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time

WARNING:betfairlightweight.streaming.stream:[MarketStream: 2001]: Latency high: 1.961205244064331

WARNING:betfairlightweight.streaming.stream:[MarketStream: 2001]: Latency high: 1.808332920074463

WARNING:betfairlightweight.streaming.stream:[MarketStream: 2001]: Latency high: 1.6995792388916016

WARNING:betfairlightweight.streaming.stream:[MarketStream: 2001]: Latency high: 1.0950758457183838

WARNING:betfairlightweight.streaming.stream:[MarketStream: 2001]: Latency high: 0.7914028167724609

WARNING:betfairlightweight.streaming.stream:[MarketStream: 2001]: Latency high: 0.5924580097198486

WARNING:betfairlightweight.streaming.stream:[MarketStream: 2001]: Latency high: 0.507713794708252



bflw: 2.12.0

flumine: 1.16.0



I run flumine via ubtuntu in an virtual machine. When i place live bet, i somethime receive "Latency high" warning. (less than 300 markets running)



1) Do you think my virtual machine can cost network delay? ( My latptop 4 cores, 8GB RAMs, 120Mbps boardband)

2) "Latency high: 1.961205244064331" means 1.96s delay? should i set both conflate_ms = 2000, and streaming_timeout = 2 to reduce warning?

3) I was running inplay strategies, betfair might push more udpate from one market to other, is there a way i can meaure my code execution time so that i can improve my code?

*Tags: Performance, Deployment*

---

## 2021-02-09

**ricky** - *09:53:50*

System clock synchronized: yes (via timedatectl command)

i have two flumine instances running at the same time, CPU loading could reach 40% for one instance.

These are the only two tasks running in VM.

*Tags: General Technical*

---

**ricky** - *10:16:33*

First flumine instance only monitor signal and send me email notification plus recording live data.

Secod flumine instance has nothing to do with first fluime instance, it calcuate the back/lay signal, and trigger to bet.

*Tags: Deployment*

---

**ricky** - *10:29:40*

I am running inplay football strategies, because my code might invlove heavy calculation(like dict array and sort etc). if befair push update every 30ms,

when my function/class cost more than 30 ms execution time it can cost Latency high warning?

*Tags: Performance*

---

**ricky** - *10:31:35*

nothing block, but maybe some python library function too slow to execute, not sure.

*Tags: Performance*

---

**liam** - *10:32:12*

and your using flumine to place the order?

*Tags: General Technical*

---

**ricky** - *10:43:09*

i am not sure what streaming_timeout  does? but should i use both conflate_ms = 2000, and streaming_timeout = 2 to reduce the warning?

*Tags: General Technical*

---

**liam** - *10:44:33*

streaming_timeout should be used on quiet markets [https://liampauling.github.io/flumine/advanced/#parameters](https://liampauling.github.io/flumine/advanced/#parameters)

*Tags: General Technical*

---

**ricky** - *11:14:19*

Sorry if it have been asked before,

The default conflate_ms is None, but what is the betfair cycle time (how quick betfair can push an update to flumine)?

*Tags: General Technical*

---

**ricky** - *16:14:24*

I used backtestloggingcontrol from the example,



When i run flumine to place a bet, i want to check if my bet matched/umatched in betfair website.

Without waitting for market close, is there a way to check price_matched, size_matched for immediate feedback?



I tried add def _process_order(self, event) in backtestloggingcontrol, but "price_matched", "size_matched" field is not accurate from _process_order, sometime work sometime not.

*Tags: General Technical*

---

**ricky** - *16:53:15*

As i mentioned, i have two instance of fluime running, one only monitor, recording and send me signal notification, another one is check and place bet.

I only start live bet via fluinme last two weeks, i am still tesing my strategies, in particular i need solve my latency issue, i feel more confidence when i can see bet actual place in betfair website.

*Tags: Performance, Deployment*

---

**liam** - *16:55:28*

so `logging` as set up per the examples will tell you what is happening/happened, loggingcontrol is for storing order/market/trade data in a csv/database/api but has it its limitations in that you need to wait for market closure for a few of the functions to be called.



It sounds like you just want logs?

*Tags: General Technical*

---

## 2021-02-11

**AP** - *18:28:03*

Quick q about submitting a lay order that uses a target payout with flumine. It looks like the size variable is still required to submit an order in that way when I think it’s superseded by the target size variable?

*Tags: General Technical*

---

## 2021-02-14

**Jonjonjon** - *18:07:42*

Has anyone else had the same problem? I'm now wondering if I will have issues if I ever go on holiday abroad.

*Tags: General Technical*

---

**Jonjonjon** - *18:14:30*

I hope they fix it for you quickly!

*Tags: Errors Debugging*

---

**Newbie99** - *18:31:46*

when its a banned country it just says you can't from that location (or the API errors)

*Tags: Errors Debugging*

---

**Newbie99** - *18:32:02*

(I've only ever tried from Europe if that helps at all)

*Tags: General Technical*

---

**thambie1** - *19:51:22*

[@UQL0QDEKA](@UQL0QDEKA) I've considered creating a new account to switch currencies at some point. How difficult and time consuming was the process to move over api access, historical data purchases, money, etc to the new account?

*Tags: Data Quality*

---

**PeterLe** - *19:55:31*

Well in truth it took a couple of weeks, so unless you really have to, id probably give it a miss.I had an account manager to help sort it out and he was brilliant actually (I didnt have any purchases though)

*Tags: General Technical*

---

## 2021-02-15

**birchy** - *08:43:34*

Oh. I've got individual certs for each account and handle them via an AWS style credentials file.

*Tags: Deployment*

---

**RicHep** - *16:42:47*

i used to have a website that finds steamers on betfair and compares to oddchecker, then displays better odds at the bookies, used to make 5-10 grand a month in 2012-2017, you could run up 10k in a ladbrokes account no problem, now it’s impossible

*Tags: General Technical*

---

**tobsve** - *19:29:37*

well, I can try. The auth etc are no problem. But when using

```trading.betting.list_events(

    filter=filters.market_filter(text_query="Chelsea v Newcastle")

)```

i get  30267429 Chelsea v Newcastle

So now I have a event_list_id



And here... I just get blown away. I totally don't understand

*Tags: Strategies*

---

**jhaa** - *21:08:12*

Traceback (most recent call last):

  File "/home/code/venv/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 113, in process_response

    return resource(elapsed_time=elapsed_time, **result)

  File "/home/code/venv/lib/python3.6/site-packages/betfairlightweight/resources/bettingresources.py", line 695, in __init__

    self.orders = [CurrentOrder(**i) for i in kwargs.get("currentOrders")]

  File "/home/code/venv/lib/python3.6/site-packages/betfairlightweight/resources/bettingresources.py", line 695, in &lt;listcomp&gt;

    self.orders = [CurrentOrder(**i) for i in kwargs.get("currentOrders")]

TypeError: __init__() missing 1 required positional argument: 'regulatorCode'

*Tags: Errors Debugging, Strategies*

---

**jhaa** - *21:08:52*

I have this unseen error in my logs from calling:





```current_orders = self.trading.betting.list_current_orders(market_ids=[stream_market.get_market_id()],

                                                          from_record=from_record)```



*Tags: Errors Debugging, Strategies*

---

**Jonjonjon** - *21:20:08*

I recorded some data, and there is a bsp of "Infinity"



`{"op": "mcm", "clk": null, "pt": 1612419337919, "mc": [{"id": "1.178772818", "marketDefinition": {"bspMarket": true, "turnInPlayEnabled": true, "persistenceEnabled": true, "marketBaseRate": 6, "eventId": "30265109", "eventTypeId": "7", "numberOfWinners": 1, "bettingType": "ODDS", "marketType": "WIN", "marketTime": "2021-02-04T06:04:00.000Z", "suspendTime": "2021-02-04T06:04:00.000Z", "bspReconciled": true, "complete": true, "inPlay": true, "crossMatching": false, "runnersVoidable": false, "numberOfActiveRunners": 0, "betDelay": 1, "status": "CLOSED", "settledTime": "2021-02-04T06:15:13.000Z", "runners": [{"adjustmentFactor": 0.922, "status": "REMOVED", "sortPriority": 1, "removalDate": "2021-02-03T21:42:31.000Z", "id": 38389550}, {"adjustmentFactor": 2.491, "status": "REMOVED", "sortPriority": 2, "removalDate": "2021-02-03T21:42:41.000Z", "id": 38389553}, {"adjustmentFactor": 18.868, "status": "LOSER", "sortPriority": 3, "bsp": 8.351698159, "id": 28143714}, {"adjustmentFactor": 0.709, "status": "LOSER", "sortPriority": 4, "bsp": 969.8251431363869, "id": 15424296}, {"adjustmentFactor": 16.667, "status": "LOSER", "sortPriority": 5, "bsp": 8.63260113914148, "id": 28485888}, {"adjustmentFactor": 39.11, "status": "WINNER", "sortPriority": 6, "bsp": 1.910361925779252, "id": 38389544}, {"adjustmentFactor": 4.255, "status": "LOSER", "sortPriority": 7, "bsp": 29.698602524282755, "id": 369626}, {"adjustmentFactor": 6.41, "status": "LOSER", "sortPriority": 8, "bsp": 13, "id": 2648545}, {"adjustmentFactor": 7.143, "status": "LOSER", "sortPriority": 9, "bsp": 19.893867845765776, "id": 38389545}, {"adjustmentFactor": 1.408, "status": "LOSER", "sortPriority": 10, "bsp": 107.95724409554154, "id": 38389546}, {"adjustmentFactor": 2.439, "status": "LOSER", "sortPriority": 11, "bsp": 49.13699878256768, "id": 1254801}, {"adjustmentFactor": 1.667, "status": "LOSER", "sortPriority": 12, "bsp": 158.11592936579493, "id": 38389551}, {"adjustmentFactor": 0.909, "status": "LOSER", "sortPriority": 13, "bsp": 209.13771912477907, "id": 38389552}, {"adjustmentFactor": 0.414, "status": "LOSER", "sortPriority": 14, "bsp": "_*Infinity*_", "id": 38389555}], "regulators": ["MR_INT"], "venue": "Doomben", "countryCode": "AU", "discountAllowed": true, "timezone": "Australia/Queensland", "openDate": "2021-02-04T03:34:00.000Z", "version": 3608935591, "raceType": "Flat", "priceLadderDefinition": {"type": "CLASSIC"}}, "_stream_id": 2009}]}`



It causes an issue here:



[https://github.com/liampauling/flumine/blob/0b0bb9d8b7a2ca94c05996284692bccaede679c1/flumine/backtest/simulated.py#L230](https://github.com/liampauling/flumine/blob/0b0bb9d8b7a2ca94c05996284692bccaede679c1/flumine/backtest/simulated.py#L230)



I think it might happen when there isn't enough size to match an SP.

*Tags: Strategies*

---

## 2021-02-16

**liam** - *09:23:17*

What errors?

*Tags: Errors Debugging*

---

**Lee** - *09:41:42*

looks fixed now

*Tags: Errors Debugging*

---

**Jonjonjon** - *12:04:39*

Apologies for forgetting to post the error:



  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/backtest.py", line 44, in run`

    `self._process_market_books(events.MarketBookEvent(event))`

  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/backtest.py", line 84, in _process_market_books`

    `middleware(market)  # todo err handling?`

  `File "/home/jon/PycharmProjects/flumine/flumine/markets/middleware.py", line 67, in _call_`

    `self._process_simulated_orders(market, market_analytics)`

  `File "/home/jon/PycharmProjects/flumine/flumine/markets/middleware.py", line 142, in _process_simulated_orders`

    `order.simulated(market.market_book, runner_analytics)`

  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/simulated.py", line 44, in _call_`

    `self._process_sp(market_book.publish_time_epoch, runner)`

  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/simulated.py", line 230, in _process_sp`

    `size = round(remaining_risk / (actual_sp - 1.0), 2)`

`TypeError: unsupported operand type(s) for -: 'str' and 'float'`

*Tags: Errors Debugging*

---

## 2021-02-18

**qwerty.nat** - *11:22:05*

Just confirming, does bflw hit the api keep alive for us or we need to hit it ourselves once every 24 hours to keep our session token valid?

*Tags: Deployment*

---

**Alessio** - *11:27:42*

but flumine does it, no?

*Tags: General Technical*

---

## 2021-02-20

**Aaron Smith** - *16:18:31*

flumine just threw a bunch of high latency warnings. I m curious what caused this high latency. I suppose one way to get high latency is by to much calculations in your strat so it cant keep up? Highest cpu-utilization was 15% though. Is it possible for an ec2 instance to just "randomly" have a bad connection sometimes?

*Tags: Performance, Deployment*

---

**Newbie99** - *16:33:06*

I definitely get random high latency warnings from an ec2 instance. Not to often, but some days it does seem to randomly happen

*Tags: Performance, Deployment*

---

**Angelos** - *17:58:50*

got the same issue today as well. flumine processes everything on a single thread, so if you’ve got a lot of markets to go through, then it might not be able to process everything in less than 2 seconds

*Tags: General Technical*

---

**Angelos** - *18:00:42*

don’t think it’s possible to split the markets into multiple threads(correct me if i’m wrong) so i’m thinking of creating multiple python runs where i would split the markets in multiple shells

*Tags: General Technical*

---

**liam** - *18:01:59*

Bflw warning is likely to be network if your CPU is only 15%, the 2s warning is bad, what are you doing that takes 2s???

*Tags: General Technical*

---

**Lee** - *18:33:44*

[@U01DVUAE2G1](@U01DVUAE2G1) which latency warnings did you get? `Latency high` or `High latency between current time and MarketBook publish time`

I get a few `Latency high` most days.

*Tags: Performance*

---

**liam** - *19:01:06*

You should use a worker for this as per the example [https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py|https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py](https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py|https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py)

*Tags: General Technical*

---

**Aaron Smith** - *19:14:16*

[@UUCD6P13J](@UUCD6P13J) i get both. `Latency high` disregards processing time and just checks how long it took to get the market_update? In that case, if you get the `Latency high` one, the `High Latency`  one is sorta guranteed to follow?

*Tags: Performance*

---

**liam** - *19:15:24*

High latency means you are spending too much time in the strategy, are you doing something slow?

*Tags: Performance, Strategies*

---

**Aaron Smith** - *19:16:43*

and `latency high`  means the market_book update took to long to reach me?

*Tags: Performance*

---

**Angelos** - *19:18:59*

how frequent is that event fired?

~guessing i’ll have to implement `_process_custom_event` in my strategy to grab the scores for this right?~

*Tags: Strategies*

---

**Aaron Smith** - *19:27:28*

i m confused here, `High latency between current time and MarketBook publish time`  is thrown before the strategy actually processes the market_book, so it does not take processing time into account?

*Tags: Performance, Strategies*

---

**Aaron Smith** - *19:45:14*

I m still kinda confused, i hope you are patient with me :smile: Okay so: I get a bunch of market_books as an event. I loop over these market_books and check if _latency = current_time - publish_time &gt; 2._ If this is the case, it means that a previous market_book took to long to process or that the market_book came in late in the first place. Something here i didnt get right, because if the market_book came in late in the first place, it shouldnt throw this warning but only the `latency high`  warning if i got you right? But if the market_book arrived 2 seconds late in the first place, _latency = current_time - publish_time &gt; 2_ would be true aswell? Sencond, given a market_book takes to long to process, then the next market_book in the loop (and every market_book coming after) will have high latency and their market_ids are printed out, however its not actually those markets that caused the latency but the previous one?

*Tags: Performance*

---

**MacrcoPolo** - *19:59:27*

What are the actual values of the latency you're getting roughly?

*Tags: Performance*

---

**Aaron Smith** - *20:13:09*

for `"[MarketStream: 2001]: Latency high: ___"`  it ranges from 0.5 to 5. Whenever its above 2.0, it also prints the `"High latency between current time and MarketBook publish time"` , which i guess kinda shows that the problem is not in the process time of the market_books, but rather that the first latency is part of the 2nd latency

*Tags: Performance*

---

**Newbie99** - *20:19:19*

[@U4H19D1D2](@U4H19D1D2) will be able to correct me here, but wasn't there an issue whereby if updates weren't that frequent (e.g. illiquid markets such as some of the US stuff) then you could get a latency warning, not because anything is wrong as such, but simply because the gap between the current time and last publish time is quite large?

*Tags: Performance*

---

## 2021-02-21

**liam** - *06:05:21*

[@UFTBRB3F1](@UFTBRB3F1) that was fixed a while ago by checking if the update is a snap or not. [@U01DVUAE2G1](@U01DVUAE2G1) you probably right here although its difficult to debug as betfair will start to conflate if you are not pulling off the socket quick enough. However if you are getting the 2s warning then you are either maxing your CPU or you are processing the updates too slow. If you get the `Latency High..` warning you either have network or CPU issues.

They are just supposed to be warnings to highlight potential issues, they could probably be improved in the codebase or by the user elsewhere, I did create an [https://github.com/liampauling/flumine/issues/338|issue](https://github.com/liampauling/flumine/issues/338|issue) to track this better to allow easier tracing/profiling

*Tags: Errors Debugging, Performance*

---

**birchy** - *10:53:50*

Just to add to the latency issue, it's important to ensure that your OS time is synchronised with an NTP server. Linux does this by default. Windows tries, but it's a bit fluffy.

*Tags: Performance, Deployment*

---

## 2021-02-24

**Aaron Smith** - *15:10:44*

Hey guys, i m still struggeling with my Latency issue, i have little clue how to "debug" this. I thought i d just put out all my current warning logs, maybe someone can make any sense of it, i d be grateful :smile: first: the latency issue seemingly isnt the result of to much processing per market update, even when i m not processing anything, i still eventually get the same problem. The framework is running on an ec2 instance, which i thought should be rather stable. Its a linux instance, so OS time should be in sync with an NTP server.

Problem: _"[MarketStream: 2001]: Latency high: 1.0108046531677246"_

Latency can go up to 6s.



That said, my suspicous logs:

• sometimes i get _"Market &lt;market_id&gt; not present when closing"_, i dont know why it happens, timewise it doesnt seem to correlate with the _Latency high_ warning.

• And now the probably bigger problem:

```{"asctime": "2021-02-23 21:19:59,560", "levelname": "ERROR", "message": "[MarketStream: 4001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 12930 markets whereas max allowed number was: 200"}

{"asctime": "2021-02-23 21:20:10,572", "levelname": "ERROR", "message": "MarketStream run error", "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py\", line 216, in _receive_all\n    part = self._socket.recv(self.buffer_size)\n  File \"/usr/lib64/python3.7/ssl.py\", line 1056, in recv\n    return self.read(buflen)\n  File \"/usr/lib64/python3.7/ssl.py\", line 931, in read\n    return self._sslobj.read(len)\nsocket.timeout: The read operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/flumine/streams/marketstream.py\", line 32, in run\n    self._stream.start()\n  File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py\", line 59, in start\n    self._read_loop()\n  File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py\", line 198, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py\", line 220, in _receive_all\n    raise SocketError(\"[Connect: %s]: Socket %s\" % (self._unique_id, e))\nbetfairlightweight.exceptions.SocketError: [Connect: 4002]: Socket The read operation timed out"}

{"asctime": "2021-02-23 21:20:12,575", "levelname": "WARNING", "message": "[Listener: 4002]: stream already registered, replacing data"}```

These 3 fellas are getting logged right behind each other. The first few hours everything seems fine, until eventually these show up. I m not sure why it tries to subscribe to 12k (its always roughly 12k) markets, thats at least not what i m telling it to do. The fact it doesnt give this error the first few hours makes me feel like something bad is stacking up in the background (allthough if this was to log as soon as i hit &gt;200 markets, the jump from 200 to 12k seems kinda big). I know its not you guys job to solve my probs, but maybe some smart being immediatly has an idea of whats up - i d surely appreciate it :slightly_smiling_face:

*Tags: Errors Debugging, Performance, Deployment*

---

**Aaron Smith** - *15:15:56*

market_filter = betfairlightweight.filters.market_filter(market_ids=market_ids)

    market_data_filter = betfairlightweight.filters.streaming_market_data_filter(fields=["EX_BEST_OFFERS", "EX_MARKET_DEF"],                                                                                          ladder_levels=1)



len(market_ids) is roughly 90

*Tags: General Technical*

---

**liam** - *15:23:22*

this will be the source of you problem, I can only assume the stream fails (betfair or network issue) a reconnect is attempted but the filter is a list of empty marketIds so it attempts to connect to all markets

*Tags: General Technical*

---

**liam** - *15:35:37*

yeah that could be the problem, simple to fix no?

*Tags: Errors Debugging*

---

**Aaron Smith** - *15:36:23*

yea should be an easy fix, just didnt know it would react like that. Thanks liam :slightly_smiling_face:

*Tags: Errors Debugging*

---

## 2021-02-26

**Newbie99** - *10:29:39*

[@U4H19D1D2](@U4H19D1D2) in flumine 1.17.2 I saw there's a mention of a bug fix around potential exposure, I'm seeing a lot of these:



```INFO:flumine.order.order:Order status update: Violation

{"asctime": "2021-02-26 10:17:21,505", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.179742967", "selection_id": 28253114, "handicap": 0, "id": "138336274415049218", "customer_order_ref": "6012fe3b915f7-138336274415049218", "bet_id": null, "date_time_created": "2021-02-26 10:17:21.504921", "publish_time": null, "trade": {"id": "d00f5a01-781b-11eb-8ae9-2016d8944b85", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138336274415049218"], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 16.0, "size": 1.0, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 1.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}}

WARNING:flumine.controls:Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure```

When by my calcs I shouldn't be anywhere near a violation. I'm placing orders using market.place(order) as opposed to strategy.place and this is paper trading if it makes a difference.



Is it possible a bug remains, or perhaps more likely is there another change I need to make (I read through the change logs but I appear to have missed something)?

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *10:32:03*

its because of the change in 1.17.0, you see the logs states `strategy.validate_order failure` this means this [https://github.com/liampauling/flumine/blob/806b5e1bd3f76886818da08dfa1d8db1a78e62fd/flumine/strategy/strategy.py#L179|function](https://github.com/liampauling/flumine/blob/806b5e1bd3f76886818da08dfa1d8db1a78e62fd/flumine/strategy/strategy.py#L179|function) is returning false which is likely because you already have a live trade. I am basically trying to force the user to check the `RunnerContext` first, see [https://github.com/liampauling/flumine/blob/806b5e1bd3f76886818da08dfa1d8db1a78e62fd/examples/strategies/lowestlayer.py#L37|here](https://github.com/liampauling/flumine/blob/806b5e1bd3f76886818da08dfa1d8db1a78e62fd/examples/strategies/lowestlayer.py#L37|here) for example

*Tags: Deployment, Strategies*

---

**Newbie99** - *17:15:05*

```{"asctime": "2021-02-26 15:42:09,137", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.179756075", "selection_id": 28040651, "handicap": 0, "id": "138336469255121051", "customer_order_ref": "6012fe3b915f7-138336469255121051", "bet_id": "100000000018", "date_time_created": "2021-02-26 15:42:05.512104", "publish_time": "2021-02-26 15:42:05.763000", "trade": {"id": "2d6ee89a-7849-11eb-841c-2016d8944b85", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138336469255121051"], "notes": "", "market_notes": "11,11.5,11.5", "status": "Pending", "status_log": "Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 10.5, "size": 1.57, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 1.57, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-02-26 15:42:05.716102", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Execution complete", "status_log": "Pending, Executable, Replacing, Execution complete", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 139.7, "matched": []}}

INFO:flumine.execution.baseexecution:Order Cancel: SUCCESS

{"asctime": "2021-02-26 15:42:09,138", "levelname": "INFO", "message": "Order Cancel: SUCCESS", "bet_id": "100000000018", "order_id": "138336469255121051", "status": "SUCCESS", "error_code": null}

INFO:flumine.execution.baseexecution:Order Replace: SUCCESS

{"asctime": "2021-02-26 15:42:09,139", "levelname": "INFO", "message": "Order Replace: SUCCESS", "bet_id": null, "order_id": "138336469291386029", "status": "SUCCESS", "error_code": null}

INFO:flumine.order.order:Order status update: Violation

{"asctime": "2021-02-26 15:42:09,140", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.179756075", "selection_id": 28040651, "handicap": 0, "id": "138336469291386029", "customer_order_ref": "6012fe3b915f7-138336469291386029", "bet_id": "100000000057", "date_time_created": "2021-02-26 15:42:09.138602", "publish_time": null, "trade": {"id": "2d6ee89a-7849-11eb-841c-2016d8944b85", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138336469255121051", "138336469291386029"], "notes": "", "market_notes": "11,11.5,11.5", "status": "Pending", "status_log": "Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 11.0, "size": 1.57, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 1.57, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-02-26 15:42:09.139609", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 254.41, "matched": []}}

WARNING:flumine.controls:Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure

{"asctime": "2021-02-26 15:42:09,141", "levelname": "WARNING", "message": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure", "control": "STRATEGY_EXPOSURE", "error": "strategy.validate_order failure", "order": {"market_id": "1.179756075", "selection_id": 28040651, "handicap": 0, "id": "138336469291386029", "customer_order_ref": "6012fe3b915f7-138336469291386029", "bet_id": "100000000057", "date_time_created": "2021-02-26 15:42:09.138602", "publish_time": null, "trade": {"id": "2d6ee89a-7849-11eb-841c-2016d8944b85", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138336469255121051", "138336469291386029"], "notes": "", "market_notes": "11,11.5,11.5", "status": "Pending", "status_log": "Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 11.0, "size": 1.57, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 1.57, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-02-26 15:42:09.139609", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure", "simulated": {"profit": 0.0, "piq": 254.41, "matched": []}}} ```

*Tags: Errors Debugging, Deployment, Strategies*

---

**Newbie99** - *18:22:49*

I only use replace on one new strategy I'm testing...just so happened that was the one I used to test today, ha!

*Tags: Strategies*

---

**Newbie99** - *18:26:36*

[https://github.com/liampauling/flumine/issues/382#issue-817570814](https://github.com/liampauling/flumine/issues/382#issue-817570814)

*Tags: General Technical*

---

**birchy** - *19:22:25*

In a Flumine strategy, what are the (dis)advantages of `process_orders()` vs `market.blotter.live_orders` ? I presume the actual orders are updated at the same time and both of these contain the _same_ orders?

*Tags: Deployment, Strategies*

---

## 2021-02-27

**birchy** - *02:04:28*

Did a `pip` Flumine upgrade earlier am now getting lots of errors in my backtest code:

```File "...snip.../tradingcontrols.py", line 22, in _validate

if order.EXCHANGE == ExchangeType.BETFAIR:

AttributeError: 'Market' object has no attribute 'EXCHANGE'```

Not sure if this is a bug or whether I need to make any further changes to my strategy code? Have added the `RunnerContext` check as discussed between [@U4H19D1D2](@U4H19D1D2) and [@UFTBRB3F1](@UFTBRB3F1) above. Note that I'm not using `market.replace_order()` ...these errors are from plain old `market.place_order(order)`

*Tags: Errors Debugging, Strategies*

---

## 2021-02-28

**Jaume Colom Ferrer** - *19:01:13*

I am trying to download historic files, but its returning me a 302 http error

*Tags: Errors Debugging*

---

**Jaume Colom Ferrer** - *19:01:20*

`DEBUG:urllib3.connectionpool:[https://historicdata.betfair.com:443](https://historicdata.betfair.com:443) "POST /api/DownloadListOfFiles HTTP/1.1" 302 None`

`DEBUG:urllib3.connectionpool:[https://historicdata.betfair.com:443](https://historicdata.betfair.com:443) "GET /home/ngErrorRedirect HTTP/1.1" 200 None`

*Tags: Errors Debugging*

---

## 2021-03-01

**IndikaE** - *10:51:05*

Hi. First post here - been lurking for a while. I absolutely love flumine, and I am preparing to deploy my first strategy. I just noticed, that after upgrading to flumine 1.17.4 that I started to hit the transaction limit(5000) when backtesting on around 1000 markets. My strategy usually places only 1-10 orders per market. I initially thought that I had a problem with the monkey patching of datetime, so that the control would use actual system time(this would explain the limit kicking in). However, after debugging a bit, now I don’t believe that to be the case(patched time seems to be ok). My markets are passed and processed in random chronological order, could this be causing trouble in the max transaction limit control? Also the first error occurs with a transaction_count of 6152, not 5001, as I would have expected. As I saw that some changes to this control were made with the latest version, I thought it might be an issue, but I absolutely cannot rule out that I am doing something wrong here. 

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *11:00:18*

It is likely that its due to the order you are processing the markets and this line [https://github.com/liampauling/flumine/blob/bbd145b7f18a63790fa844e9a0cdc9bab3991542/flumine/controls/clientcontrols.py#L62|here](https://github.com/liampauling/flumine/blob/bbd145b7f18a63790fa844e9a0cdc9bab3991542/flumine/controls/clientcontrols.py#L62|here). If the first market you process is actually the last chronological market then the reset will never get called, try ordering the markets first, I do this before getting the markets

```market_ids.sort()  # in creation order ```

or just disable the control

```client = clients.BacktestClient(

    transaction_limit=None,

)```

*Tags: General Technical*

---

**birchy** - *14:35:56*

[@U4H19D1D2](@U4H19D1D2) Well done on the recent Flumine updates. Even on my shitty old hardware, the backtests are significantly faster. How did you manage such a big optimisation?

*Tags: General Technical*

---

**Unknown** - *14:42:38*

Yeah she really does fly now, a lot of the improvement came from stripping out as much as possible in the listener/stream code and then preventing duplicate resource creation by caching if there hasn't been an update but all of this was in bflw so makes live streaming quicker as well

*Tags: Deployment*

---

**birchy** - *15:07:53*

Yeah...My hardware is not even 50% of that. :joy:

Just as an FYI, I've not tried my "million markets" strategy since this update. I implemented it in my own polling library as the strategy plods along steadily on a 10 second poll rate. Only took just over an hour from project to production, so a no brainer really. I think streaming is better suited to the faster aim-&gt;fire type strategies such as inplay geegees (which I had never got involved in previously).

*Tags: Deployment, Strategies*

---

**liam** - *15:15:11*

yeah I think flumines original design did lend to multi markets but its now in a much better shape because of the refactor

*Tags: General Technical*

---

**Peter C** - *16:50:11*

Today I've updated to the latest version of flumine from 1.16.3. I've added a runner_context.live_trade_count

*Tags: Deployment*

---

**liam** - *16:55:46*

there was a bug with replace fixed this morning, what version are you on now?

*Tags: Errors Debugging*

---

**Peter C** - *17:06:36*

I have 'if runner_context.live_trade_count &lt;= 4:' because I have max_live_trade_count = 4 when I add my strategy to the framework - is this wrong?

*Tags: Deployment, Strategies*

---

**Peter C** - *17:11:49*

I mean in both the runner context check and when the strategy is pulled into the framework the limit is 4

*Tags: Strategies*

---

**Newbie99** - *17:56:34*

Also using 1.17.5, once I get a violation for an order below min size then this warning appears and can't place a subsequent order, is this intended behaviour (I would have assumed once you try to place a correctly sized order, the message should go and the order should flow upstream)?



This is just paper trading (in case that makes a difference).



Correctly failed order:

```{"asctime": "2021-03-01 16:18:18,238", "levelname": "WARNING", "message": "Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency", "control": "ORDER_VALIDATION", "error": "Order size is less than min bet size (2) or payout (10) for currency", "order": {"market_id": "1.179865560", "selection_id": 38527720, "handicap": 0, "id": "138339079234466185", "customer_order_ref": "869aeb021cad4-138339079234466185", "bet_id": "100000000162", "date_time_created": "2021-03-01 16:12:03.446618", "publish_time": "2021-03-01 16:12:03.626000", "trade": {"id": "933fb664-7aa8-11eb-a42d-2016d8944b85", "strategy": "simple_back_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138339078008452709", "138339079234466185"], "notes": "", "market_notes": "190,330,340", "status": "Live", "status_log": "Pending, Live, Pending, Live"}, "order_type": {"order_type": "Limit", "price": 180.0, "size": 0.05, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.05, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-03-01 16:12:03.447618", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Pending, Executable, Violation", "violation_msg": "Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency", "simulated": {"profit": 0.0, "piq": 3.65, "matched": []}}}```

Correctly sized order that fails to place, due to previous violation:

```{"asctime": "2021-03-01 16:25:39,365", "levelname": "WARNING", "message": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure", "control": "STRATEGY_EXPOSURE", "error": "strategy.validate_order failure", "order": {"market_id": "1.179865560", "selection_id": 38527720, "handicap": 0, "id": "138339087393647136", "customer_order_ref": "869aeb021cad4-138339087393647136", "bet_id": null, "date_time_created": "2021-03-01 16:25:39.364713", "publish_time": null, "trade": {"id": "c2a66a1f-7aaa-11eb-a8f0-2016d8944b85", "strategy": "simple_back_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138339087393647136"], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 290.0, "size": 0.06, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.06, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure", "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}}}```

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *18:00:48*

Haha, the only bug I know of was the replace one fixed today! 

*Tags: Errors Debugging*

---

**liam** - *18:03:41*

Can you turn strategy.log_validation on? What’s confusing is that the first order should be valid?

*Tags: Strategies*

---

**liam** - *19:04:02*

That is interesting, don’t suppose you can create a simple strategy and share a file so I can replicate?

*Tags: Strategies*

---

**Peter C** - *19:09:47*

I will try and create a simple strategy that replicates this and let you know, but unsure if I'll be able to replicate the issue. You're welcome to my output data from the tests as well if that helps

*Tags: Strategies*

---

**Peter C** - *19:59:10*

Hi Liam, I'm struggling to recreate the matching issue but I'll keep trying and get back to you. To answer your other question, when an order is matched in 1.17.5 that isn't matched in 1.16.3 that order is matched 300-1000 seconds after placement

*Tags: General Technical*

---

**liam** - *20:00:23*

Is that coinciding with market closure? or a suspension? If you set simulated logging to debug you can see when the orders get matched 

*Tags: Errors Debugging*

---

**Peter C** - *20:02:43*

I don't believe either because orders placed within a few seconds of each other are matched at both ends of the 300-1000 elapsed seconds scale. I'll try setting to debug and see what I get.

*Tags: Errors Debugging*

---

**Peter C** - *20:03:56*

I think this is the root of my problem earlier because if I give the strategy a higher max exposure to account for the extra matched bets it starts to look a lot more like my backtests on 1.16.3 but on a different scale

*Tags: Strategies*

---

## 2021-03-02

**liam** - *08:35:37*

Could be this bug [https://github.com/liampauling/flumine/issues/354](https://github.com/liampauling/flumine/issues/354) mixed with this one [https://github.com/liampauling/flumine/issues/290](https://github.com/liampauling/flumine/issues/290)

*Tags: Errors Debugging*

---

**liam** - *08:35:50*

If you can get a simple strategy that I can replicate I can look into it

*Tags: Strategies*

---

**liam** - *09:47:12*

What is the x axis here? Can you share more info on what the strategy uses, for example just limit orders? back / lay? cancel requests? replace requests?

*Tags: Strategies*

---

**Peter C** - *09:51:37*

X axis is number of markets. Strategy uses only limit orders, back and lay, with a try/except block for replace orders. The 'equivalent' file is my attempt to bring the strategy from 1.16.3 to 1.17.5 by adding a runner context check, and changing the orders from self.place_order(market, order) to market.place_order(order). The identical file test is the file I created to try and bring the strategy to 1.17.5 tested in both 1.16.3 and 1.17.5

*Tags: Strategies*

---

**Newbie99** - *09:57:57*

```import time

import logging

import betfairlightweight

from betfairlightweight.filters import streaming_market_filter

from pythonjsonlogger import jsonlogger

from flumine import Flumine, clients, BaseStrategy

from flumine.order.trade import Trade

from flumine.order.ordertype import LimitOrder

from flumine.order.order import OrderStatus

from flumine.utils import get_price



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))





class ExampleStrategy(BaseStrategy):

    def start(self):

        # subscribe to streams

        print("starting strategy 'ExampleStrategy'")



    def check_market_book(self, market, market_book):

        # process_market_book only executed if this returns True

        if market_book.status != "CLOSED":

            return True



    def process_market_book(self, market, market_book):

        # process marketBook object

        self.log_validation_failures = True

        for runner in market_book.runners:

            if (

                runner.status == "ACTIVE"

                and runner.last_price_traded

                and get_price(runner.ex.available_to_back, 0) &gt;= 20



            ):

                trade = Trade(

                    market_id=market_book.market_id,

                    selection_id=runner.selection_id,

                    handicap=runner.handicap,

                    strategy=self,

                )

                order = trade.create_order(

                    side="LAY", order_type=LimitOrder(price=1.01, size=2.00)

                )

                market.place_order(order)



    def process_orders(self, market, orders):

        for order in orders:

            if order.status == OrderStatus.EXECUTABLE:

                if order.elapsed_seconds and order.elapsed_seconds &gt; 1:

                    if order.size_remaining == 2.00:

                        market.replace_order(order,2)



trading = betfairlightweight.APIClient("username")

client = clients.BetfairClient(trading, paper_trade=True)





framework = Flumine(client=client)



strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

            event_type_ids=['7'],

            country_codes=['GB','IE','AU','US'],

            market_types=['WIN']),

)

framework.add_strategy(strategy)



framework.run()```



*Tags: Strategies*

---

**liam** - *10:45:40*

For me this errors because you continually try to replace the order, so get the `prices match` error

*Tags: Errors Debugging*

---

**liam** - *10:48:35*

ah i think i see the problem, the replace is causing a += 1 to the number of live trades when in reality it is still just 1

*Tags: Deployment*

---

**liam** - *10:59:57*

Can you try [https://github.com/liampauling/flumine/pull/385|v1.17.6b0](https://github.com/liampauling/flumine/pull/385|v1.17.6b0)

*Tags: General Technical*

---

**liam** - *11:00:26*

Can you try [https://github.com/liampauling/flumine/pull/385|v1.17.6b0](https://github.com/liampauling/flumine/pull/385|v1.17.6b0)

*Tags: General Technical*

---

**Peter C** - *12:05:08*

For me there is no difference in result between 1.17.5 and 1.176b0. I installed by typing:

`pip install -Iv flumine==1.17.6b0`

*Tags: Getting Started*

---

**Newbie99** - *12:57:38*

yeah, that test script is non-sensical, its just to demo this issue :slightly_smiling_face:



I now get this error:



`{"asctime": "2021-03-02 12:56:07,189", "levelname": "WARNING", "message": "validate_order failed: live_trade_count (1) &gt;= max_live_trade_count (1)"}`

*Tags: Errors Debugging, Deployment*

---

**Newbie99** - *13:07:20*

oh yes good point, probably shouldn't have rushed that. Ok let me try on a proper strategy and report back

*Tags: Strategies*

---

**Newbie99** - *13:23:58*

Ok cool, I added a check to that test script (i.e. not to place a new order if there is an existing order).



No errors.



Tried on my main script.



Also no errors.



So at a glance, it appears you have caught it!

*Tags: Errors Debugging*

---

**mandelbot** - *18:05:52*

I'm having some trouble using `market.context` . My process is I record to `market.context`, using `round(market.seconds_to_start)`as a key, a list including for example total_matched and price. The problem is when I attempt to call the context I always get a keyerror. When I print `market.context` I can see that the data I want is there but it seems im not referencing it correctly?

*Tags: Errors Debugging*

---

**Lee** - *18:30:31*

think this is the place [https://github.com/liampauling/flumine/blob/b1717c7b13909d15fae865c88ecfd2108a4786d6/flumine/markets/markets.py#L27](https://github.com/liampauling/flumine/blob/b1717c7b13909d15fae865c88ecfd2108a4786d6/flumine/markets/markets.py#L27)

*Tags: General Technical*

---

## 2021-03-03

**liam** - *09:14:42*

hmm, without debugging going to be tricky unless you can replicate a simple example strategy

*Tags: Errors Debugging, Strategies*

---

**Lee** - *21:24:32*

yeah i'm getting timeout errors

*Tags: Errors Debugging*

---

**Mo** - *21:25:58*

Every account I try to scrape seems to hit this at some point:

```{'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0003', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'ie1-aanbf04b-prd-02080927-001532aeaa', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}}}, 'id': 1}```

*Tags: Errors Debugging*

---

**Lee** - *21:31:57*

user error for my first error

*Tags: Errors Debugging*

---

## 2021-03-04

**Mo** - *08:44:54*

Ah just got a reply from Neil, yeah it's a known issue that they're hoping to fix this morning

*Tags: Errors Debugging*

---

**Misha** - *08:47:45*

[@UBS7QANF3](@UBS7QANF3) - imagine if it took you 24 hours to fix a problem with your system. How hard is it to get a fairly "simple" call working?

*Tags: Errors Debugging*

---

**Oliver Varney** - *09:12:29*

I find it hard to imagine that betfair would hand over a tried and tested business model to their competitor

*Tags: Strategies*

---

**Oliver Varney** - *09:12:57*

yes would be an initial problem [@UBS7QANF3](@UBS7QANF3)

*Tags: General Technical*

---

**Atho55** - *11:23:20*

I would imagine that the Sportsbook and Exchange have differing business models such that in reality they compete with each other but having the Exchange odds visible in the Sportsbook and the option to direct your bet to either could direct funds towards the exchange if the odds are better and if to a value there is no commission.

*Tags: Strategies*

---

**V** - *15:07:45*

The best way is probably as you said, a local in flight tracker. Add orders to the tracker on placement. The strategy can then check the tracker to see if it has any orders in flight and choose not to place any more. When the order comes in from the order stream you remove it from the in flight tracker.

*Tags: Strategies*

---

**birchy** - *15:41:52*

[@U4H19D1D2](@U4H19D1D2), yeah, have just seen that in the source code. So I have no idea why I'm getting double-bets. Only happens in live strategy. Backtest doesn't do it and it's the same copy/pasted strategy. :thinking_face:

*Tags: Deployment, Strategies*

---

**birchy** - *15:43:59*

[https://github.com/liampauling/flumine/blob/b1717c7b13909d15fae865c88ecfd2108a4786d6/flumine/strategy/runnercontext.py#L20](https://github.com/liampauling/flumine/blob/b1717c7b13909d15fae865c88ecfd2108a4786d6/flumine/strategy/runnercontext.py#L20)

*Tags: Strategies*

---

**AP** - *17:13:19*

Just to confirm, is the runner context unique to each strategy?

*Tags: Strategies*

---

**liam** - *17:22:24*

Yeah stored in the strategy object 

*Tags: Strategies*

---

## 2021-03-05

**birchy** - *09:43:01*

Think I may have a race condition in my strategy code. Are the orders in `process_orders(self, market, orders)` ordered by place date?

*Tags: Strategies*

---

**liam** - *09:46:22*

depends, what version of python are you using?

*Tags: General Technical*

---

**birchy** - *09:48:27*

3.8.8 on dev machine

3.6.9 on production machine

First time I've actually checked that.

*Tags: Getting Started, Deployment*

---

**liam** - *10:13:24*

so theoretically yes as python dicts are ordered from py3.5+ but trusting the order is a bit flaky

*Tags: General Technical*

---

**liam** - *10:20:23*

releasing 1.17.6 now which should prevent any race condition by storing the tradeId [https://github.com/liampauling/flumine/pull/385](https://github.com/liampauling/flumine/pull/385)

*Tags: General Technical*

---

**Lee** - *11:19:42*

yeah getting a couple of errors here and there since around 9ish. API and streaming timeout issues

*Tags: Errors Debugging*

---

**Lee** - *11:20:58*

currently getting lots of high latency warnings

*Tags: Performance*

---

## 2021-03-06

**Alessio** - *18:47:36*

And then boom:

```File "/usr/local/lib/python3.7/site-packages/flumine/baseflumine.py", line 244, in _process_close_market

market.blotter.process_closed_market(event.event)

 File "/usr/local/lib/python3.7/site-packages/flumine/markets/blotter.py", line 61, in process_closed_market

  for runner in market_book.runners:

AttributeError: 'dict' object has no attribute 'runners'```



*Tags: Errors Debugging*

---

**liam** - *18:48:57*

Are you passing a dataclass into a strategy?

*Tags: Strategies*

---

**liam** - *18:50:50*

What does the setup look like in terms of framework.add_strategy

*Tags: Getting Started, Strategies*

---

**Alessio** - *18:51:36*

``` strategy = S3MarketRecorder(

      name="Soccer " + '_'.join(mtype),

      market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["1"],

        market_types=mtype,

        turn_in_play_enabled=True,

        country_codes = ccountries,

      ),

      stream_class=DataStream,

      context={

        "bucket": 'betfair-hist',

        "local_dir": "/home/user/dumper/bf/1_soccer_" + "_".join(mtype) + "_" +str(cidx)

      },

  )

  framework.add_strategy(strategy)```

*Tags: Strategies*

---

**Alessio** - *18:51:53*

```strategy = sure_strategy.TakeTheSureStrategy(

      name = 'Take The Sure',

      market_filter=uo25_filter,

      max_live_trade_count=4,

      max_trade_count=4,

      max_order_exposure=40.0,

      max_selection_exposure=40.0

)

framework.add_strategy(strategy)```

*Tags: Deployment, Strategies*

---

**Aaron Smith** - *18:53:56*

i m getting the same error when ever i add the S3 recorder to my framework (not immediatly, but eventually)

*Tags: Errors Debugging*

---

**liam** - *18:56:46*

You should be able to just need to fix this bug, issue is in the blotter where it is trying to update the orders with the runner status, if the raw data stream closes first then it calls the close market func and errors 

*Tags: Errors Debugging*

---

**Alessio** - *18:59:19*

(happy to fix it)

*Tags: Errors Debugging*

---

**liam** - *19:00:53*

So the recorder has created a stream and your order placing strategy has created a stream, however they share the local market object in the framework, you can see the handling for this in _processclose_market_ where the instance type is checked (recorder requires the raw update and strategy uses objects)

*Tags: Strategies*

---

**liam** - *19:05:38*

Ideally no, tricky bug as we want the blotter function to be called if there are orders I.e real strategy live on that market 

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *19:07:27*

When you run a recorder strategy you use the data stream which is a super lightweight mode as the raw updates are passed through the strategy to allow you to record it 

*Tags: Strategies*

---

**Alessio** - *19:09:05*

oh that's not that trivial to fix

*Tags: Errors Debugging*

---

## 2021-03-07

**birchy** - *17:41:48*

[@U4H19D1D2](@U4H19D1D2) think I've found the problem. Been through the logs and discovered a couple of intermittent critical errors due to a bug in my strategy code. Just to clarify, does Flumine reload the orders on restart?

*Tags: Errors Debugging, Strategies*

---

## 2021-03-08

**liam** - *11:51:50*

Should be fixed in 1.17.8

*Tags: Errors Debugging*

---

**birchy** - *13:01:26*

[@U4H19D1D2](@U4H19D1D2) Think this may be a bug, as the declarations say that `total_matched` should be `float` , however I can confirm that I'm seeing `None` :

[https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/resources/bettingresources.py#L560](https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/resources/bettingresources.py#L560)



[https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/resources/bettingresources.py#L478](https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/resources/bettingresources.py#L478)

*Tags: Errors Debugging, Strategies*

---

**liam** - *13:01:59*

Is this from streaming?

*Tags: General Technical*

---

**liam** - *13:31:26*

Here is the streaming logic where bflw defaults to [https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/streaming/cache.py#L197|None](https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/streaming/cache.py#L197|None) (its the same for the runners) but I would agree this should be update to 0 so the response is the same as a marketbook request with nothing matched

*Tags: General Technical*

---

## 2021-03-09

**liam** - *08:05:13*

Now fixed and released in bflw/flumine

*Tags: Errors Debugging*

---

## 2021-03-12

**mandelbot** - *10:50:54*

Not really sure why im getting this message:

```{"asctime": "2021-03-12 10:49:39,261", "levelname": "WARNING", "message": "Market not available to create order 138348389780580590", "bet_id": "226843537092", "market_id": "1.180439597", "customer_strategy_ref": "ID16985", "customer_order_ref": "c8312d8fc9d8c-138348389780580590", "strategy_name_hash": "c8312d8fc9d8c"}```

*Tags: Strategies*

---

**Peter** - *11:40:32*

Converting my first strategy from BFLW to Flumine and enjoying the paradigm shift (and the ability to throw away lots of code). I have a question about exposures. I'm overriding the default max_order_exposure and max_selection_exposure attributes for my strategy. When these exposures have been reached subsequent orders are flagged as violations. Is the violation recognition intended primarily as a fallback protection, or is it fine to use it as the front line approach to managing exposure, i.e. should I be be adding additional code to recognise and avoid "placing" orders that the framework will intercept and reject or would that be considered overkill / duplication?

*Tags: Strategies*

---

**liam** - *12:10:10*

use the [https://github.com/liampauling/flumine/blob/3175e4f4a1fa115c9d41294958fee67005a38bc7/flumine/markets/blotter.py#L74|blotter](https://github.com/liampauling/flumine/blob/3175e4f4a1fa115c9d41294958fee67005a38bc7/flumine/markets/blotter.py#L74|blotter)



```market.blotter.selection_exposure(...```

*Tags: General Technical*

---

**Peter C** - *14:40:26*

Thanks Liam - sorry for the barrage of stupid questions but what does the 'strategy' argument want? I've tried everything I can think of

*Tags: Strategies*

---

**liam** - *14:40:53*

its the strategy class, so if you were in the strategy its just `self`

*Tags: Strategies*

---

**Peter C** - *14:41:46*

Thanks. I did try that so my error must be somewhere else. Cheers

*Tags: Errors Debugging*

---

**Jorge** - *15:32:31*

In bflw, does the Market Data Streaming return info for CLOSED markets?

*Tags: General Technical*

---

**liam** - *16:01:07*

Bflw will give you every update 

*Tags: General Technical*

---

## 2021-03-15

**IndikaE** - *20:43:03*

Long story short: I need danish authentication , and I figured out how to do that. I handle it in the ApiClient by using the .set_session_token() - no issue there. But then I pass the bflw ApiClient to a BetfairClient and start a Flumine instance with this client. But then Flumine by default runs the login procedure for self.client - and then everything blows up - because normal login does not work for danish authentication. I fixed it by simply commenting out self.client.login() in the enter method of BaseFlumine. Everything seems to work fine. However, I would like to know if there could be some hidden issue with this method of authentication. Does anyone know of a better(less hacky) way around this? If this method is indeed ok, then maybe the framework should detect when the client has the session token set, and just skip login? 

*Tags: Errors Debugging*

---

## 2021-03-16

**IndikaE** - *05:42:25*

Of course. Thanks! Now I feel quite embarrassed for even having asked such a question. I might not have been getting enough sleep lately, working so hard on getting my strategy to production :flushed: 

*Tags: Deployment, Strategies*

---

**James McKenzie** - *12:49:40*

Hi guys, I have an AUS betfair account that I just have an app key, username and password for. Im trying to scrape race cards for AUS races and hitting the error -

```betfairlightweight.exceptions.RaceCardError: Unable to find appKey```

seems the app key is being found from a request response in the RaceCard.login method. Does anyone know why I am getting this error and can I fix it by just editing the login method to take the app key that I have. Cheers.

*Tags: Errors Debugging*

---

**Aaron Smith** - *15:33:50*

Hey guys! I got this error:

```{"asctime": "2021-03-16 15:10:03,427", "levelname": "ERROR", "message": "[MarketStream: 2002]: MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s)."}```

and now i m slightly confused on what exactly counts as a connection :smile:

*Tags: Errors Debugging*

---

**river_shah** - *15:35:18*

`MarketStream` and `OrderStream` each consume a connection. Each instance of flumine will consume two connections

*Tags: General Technical*

---

## 2021-03-19

**Jorge** - *07:17:55*

Hi guys, why is flumine polling account balance every 2 mins? Is it possible to turn this off when recording market data only?

*Tags: General Technical*

---

**Peter C** - *15:09:45*

Is it possible to filter markets by start time in streaming_market_filter when you add a strategy to the framework? I've tried but can't filter markets by start time at this point. If it's not possible to filter by start time at the point, how could I discard the markets that start too far in the future for me?

*Tags: Strategies*

---

**Peter** - *15:18:49*

You can't specify a start time in your market subscription, but you can use the market.seconds_to_start attribute in your strategy's check_market_book method to simply ignore markets that are too far into the future.

*Tags: Strategies*

---

**Peter C** - *15:20:35*

Thanks for your help. Is this acceptable from betfair's point of view? I don't want to stream markets for a day and a half only to use the last 10 minutes if this is not considered acceptable usage

*Tags: General Technical*

---

**Peter C** - *15:22:53*

ok, thanks for your help. An easy solve!

*Tags: General Technical*

---

**Jorge** - *16:25:02*

PR finished: [https://github.com/liampauling/flumine/pull/397](https://github.com/liampauling/flumine/pull/397)

*Tags: General Technical*

---

## 2021-03-23

**river_shah** - *18:22:54*

nice, was in the park for a workout. everything failed safe, +1 for flumine

*Tags: Errors Debugging*

---

## 2021-03-24

**Jorge** - *07:23:40*

Hi guys, in the marketrecorder example, [https://github.com/liampauling/flumine/blob/master/examples/marketrecorder.py](https://github.com/liampauling/flumine/blob/master/examples/marketrecorder.py), what would be a case when `context['force_update'] == True` is useful? For me, some files remained locally after the S3 upload, is 'force_update' designed for these cases?

*Tags: General Technical*

---

## 2021-03-31

**Oliver Varney** - *08:25:26*

do you use it for logging or just exceptions ?

*Tags: Errors Debugging*

---

**liam** - *08:28:29*

just exceptions, its the 503 from my workers which has maxed me out

*Tags: Errors Debugging*

---

**Oliver Varney** - *08:29:23*

Does each 503 exception count as an event

*Tags: Errors Debugging*

---

## 2021-04-06

**Jonjonjon** - *22:15:32*

Should [https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/strategy/strategy.py#L203-L206|this code](https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/strategy/strategy.py#L203-L206|this code):



        `if runner_context.trade_count &gt;= self.max_trade_count:`

            `order.violation_msg = "strategy.validate_order failed: trade_count ({0}) &gt;= max_trade_count ({1})".format(`

                `runner_context.trade_count, self.max_live_trade_count`

            `)`



Become



        `if runner_context.trade_count &gt;= self.max_trade_count:`

            `order.violation_msg = "strategy.validate_order failed: trade_count ({0}) &gt;= max_trade_count ({1})".format(`

                `runner_context.trade_count, self._*max_trade_count*_`

            `)`

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2021-04-12

**Newbie99** - *15:46:16*

When trying to place an order using:



```trade = Trade(

           market_id=market.market_id,

           selection_id=selection_id,

           handicap=handicap,

           strategy=self,

       )

   order = trade.create_order(

       side=direction, order_type=LimitOrder(price=price, size=stake, persistence_type=persistence_type)

   )



order_placed = market.place_order(order)```

I am trying to catch errors as follows:



```if order_placed is False:

	# Do stuff```

I just noticed an order (correctly) failing due to BPE, so this is expected behaviour and from logs I can see the following:



```{"asctime": "2021-04-12 13:39:15,049", "levelname": "INFO", "message": "Order Place: FAILURE", "bet_id": null, "order_id": "138375275548404227", "status": "FAILURE", "error_code": "BET_LAPSED_PRICE_IMPROVEMENT_TOO_LARGE"}```

However, from place_order in execution.transaction thought the above would return True or False and I could catch the error that way and do whatever I need, but it doesn’t appear to be catching for failures in live (I could have sworn this worked in paper trading, but haven’t been able to replicate yet), it does return True for successfully placed orders, but doesn’t return False.



 So, what is the correct way to catch these errors, as I’m clearly mis-reading the code?

*Tags: Errors Debugging, Deployment, Strategies*

---

**Alessio** - *21:05:36*

The way you can do it is keeping intenral state by market and the order objects stored in the strategy. process_market_book -&gt; place the order. then in process_orders(market, orders) you can loop over them and see 'order.status'. If you index stuff by market id you can use the market.market_id to link to the state. Also, remember that the Trade constructor has a 'notes' argument where you can put an OrderedDict of what you want, and you can access the trade from the order.

*Tags: Strategies*

---

**Alessio** - *21:30:33*

but don't quote me on that, that's an error_code i never saw

*Tags: Errors Debugging*

---

## 2021-04-14

**Jorge** - *17:16:02*

Hi [@U4H19D1D2](@U4H19D1D2), I'm checking the updated marketrecorder example using gzip compression and there is a bug [https://github.com/liampauling/flumine/blob/66089f81a8d5cd7f74ffe2d864745e823cb6bf51/examples/strategies/marketrecorder.py#L191|here](https://github.com/liampauling/flumine/blob/66089f81a8d5cd7f74ffe2d864745e823cb6bf51/examples/strategies/marketrecorder.py#L191|here) , I guess should be changed by

```market_catalogue_compressed = gzip.compress(

    market.market_catalogue.json()

)```

*Tags: Errors Debugging*

---

## 2021-04-15

**Jorge** - *08:46:35*

I got: `AttributeError: 'bytes' object has no attribute 'encode'`  in that line

*Tags: Errors Debugging*

---

**Jorge** - *15:37:49*

I installed bflw using: `pip install betfairlightweight[speed]` , which installed orjson

*Tags: Getting Started, Performance*

---

## 2021-04-16

**liam** - *09:47:25*

np, I have now updated the [https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/examples/strategies/marketrecorder.py#L190|example](https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/examples/strategies/marketrecorder.py#L190|example) to handle

*Tags: General Technical*

---

**liam** - *10:01:26*

I have made a first step of reducing the errors in flumine itself, v1.18.3 just released but I have this filter as a starting point

```class DuplicateFilter(logging.Filter):

    def __init__(self, *args, **kwargs):

        super(DuplicateFilter, self).__init__(*args, **kwargs)

        self._logs = []

        self.level = logging.WARNING  # todo

        self.log_count = 100  # todo



    def filter(self, record):

        if record.levelno &gt; self.level:

            current_log = (record.module, record.levelno, record.msg)

            if current_log in self._logs:

                return False

            self._logs.append(current_log)

        return True```

*Tags: Errors Debugging*

---

**Oliver Varney** - *10:08:11*

and maybe it would need regex as well as for example the latency warnings that may pop up all are slightly differnent ?

*Tags: Performance*

---

**Jorge** - *10:13:41*

Aha, okay I still have to figure out how to use the recorded data for backtest purposes

*Tags: General Technical*

---

**liam** - *10:14:37*

You mean the one line [https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/examples/backtest.py#L25|change](https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/examples/backtest.py#L25|change)? :sunglasses:

*Tags: General Technical*

---

**Jorge** - *10:27:01*

Are those market_catalogue files or streaming files?

*Tags: General Technical*

---

**liam** - *10:27:40*

Sorry 3 lines as you have to change the client and FlumineBacktest framework, it then takes the raw streaming files (betfair or self recorded)

*Tags: General Technical*

---

**Unknown** - *14:12:42*

i believe i have set up the certs folder correctly but i keep receiving this error when trying to login()



"   Exception: [WinError 3] The system cannot find the path specified: '/certs/'   "



I have the certs folder at the same level as the python file executing. I receive the same error when performing the example strategy listed in the docs in both vscode and jupyter here are what the two directories look like. Is there something basic/obvious im setting up wrong?

*Tags: Errors Debugging, Strategies*

---

**Jono** - *14:34:38*

is there a way to pass this location to the bflw login() method that flumine executes?

*Tags: General Technical*

---

**liam** - *14:36:09*

ie [https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/examples/example.py#L68|here](https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/examples/example.py#L68|here)

*Tags: General Technical*

---

**Jono** - *16:45:33*

are there any steps in the certs production steps laid out in:



[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA)



which are outdated? I keep recieving an error that im fairly confident relates to the private key being incorrect specifically this error: "`HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3991)')))`"



the ploading of the relevant crt file to bf was successful and the trading client is able to find the corresponding .pem file but unfortunately the above problem is stopping me from getting further. Is there a preferred way of setting up certs that i should be following rather than this or what is listed in the bf docs? Alternatively is there a way to run flumine with an interactive login so i can forego the certs?

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *16:52:39*

Yeah it’s a var on the flumine client 

*Tags: General Technical*

---

## 2021-04-19

**Peter C** - *09:06:55*

Yeah I'm getting errors

*Tags: Errors Debugging*

---

**Oliver Varney** - *10:24:33*

so did the new flumine version rate limit the logs as expected liam?

*Tags: General Technical*

---

**liam** - *10:25:51*

yeah wasn't bad at about 150 errors

*Tags: Errors Debugging*

---

**liam** - *10:47:13*

havent used a filter yet, this was just from updating the worker errors to warnings

*Tags: Errors Debugging*

---

**liam** - *10:47:30*

do you get a lot of those errors? as they aren't good

*Tags: Errors Debugging*

---

## 2021-04-20

**Robert** - *15:32:35*

anyone know an easy way to check betfair who won and placed for a race? I am assuming this is not possible for historical data without using their historical API. How about with the live API

*Tags: Data Quality, Deployment*

---

## 2021-04-21

**thambie1** - *06:35:22*

Thanks for the confirmation... time to debug

*Tags: Errors Debugging*

---

**Peter C** - *08:56:35*

Hi All, I have an issue when backtesting using marketOnClose orders. The order is placed, but stays 'executable' - it is never matched at SP. This happens regularly in backtesting, but not always. I never have this problem in live markets - the bet at SP is always placed/matched successfully. Is this a known problem with backtesting these order types, or am I doing something wrong? I have replicated the problem in a simple file if necessary. Cheers

*Tags: Deployment*

---

**Peter C** - *09:36:37*

Sorry, maybe the file I sent doesn't show the problem very well. When backtesting, I have this problem on active runners I have been laying pre-off - so I don't think it's isolated to non-runners. Sometimes my recorded files don't contain any SP info - these files cause problems (but so do some that have the SP info) - is it normal for some files to be missing the SP info?

*Tags: General Technical*

---

**Peter C** - *10:07:23*

Weird, when I debug I get an SP of 'none'. I bet I'm doing something stupid somewhere, I'll have a dig and uncover it. Thank you for your help

*Tags: Errors Debugging*

---

**Peter C** - *10:28:38*

Yeah I get the same, I must be doing something dumb somewhere else in my code. Thanks again for your help - it's been really useful

*Tags: General Technical*

---

## 2021-04-23

**Oliver Varney** - *13:12:16*

didnt see the price close to off but looks somewhere between 15-25, if you model is looking for fatfinger mistakes or wild price swings surely it would of got caught up in it

*Tags: Strategies*

---

**Oliver Varney** - *13:14:57*

could be time to turn off the lay at bsp models

*Tags: Strategies*

---

## 2021-04-25

**rjj** - *10:24:13*

Hi, can someone tell me what messages of the form [marketstream: 2001]: latency high: 0.57733 mean. My algo seems to freeze when I get a batch of these, does it result in unsubscribing from a market for instance?

*Tags: Performance*

---

## 2021-04-26

**liam** - *09:29:43*

Its either a network or CPU issue, do you have monitoring in place to check either? The latency is calculated by comparing the MarketBook `publish_time` with your current clock time to alert you to issues.

*Tags: Performance*

---

## 2021-04-28

**moseley82** - *12:34:47*

Hey guys, hoping somebody might be able to help me here... trying to use a script that I've not used for probably 6ish weeks now and I'm getting this error:



`Params: {'marketIds': [['1.182032085']], 'priceProjection': {'priceData': ['EX_BEST_OFFERS'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}` 

`Exception: None` 

`Error: {'code': -32602, 'message': 'DSC-0018'}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}`



Which happens when trying to execute this part of my script:



`market_books_1x2 = trading.betting.list_market_book(market_ids=[market_matchodds],price_projection=price_filter)`



After looking up the error I can see DSC-0018 means "A parameter marked as mandatory was not provided". Does anybody know if something has changed recently that I now need to account for?



Thanks!

*Tags: Errors Debugging, Strategies*

---

**moseley82** - *13:36:05*

Ah, that appears to be the problem! Curious as to why it used to work and now it doesn't, and not really sure why I set it like that in the first place... regardless, thanks for casting your eyes over it and picking it up

*Tags: General Technical*

---

## 2021-04-30

**Oliver Varney** - *12:19:26*

not seeing anything in the logs atm, what error, 503?

*Tags: Errors Debugging*

---

**Oliver Varney** - *12:20:30*

actually status page is saying performance issue for auth

*Tags: Performance*

---

**thambie1** - *12:21:01*

For once I'm having a problem with streaming rather than rest api. Can't open streaming connection

*Tags: General Technical*

---

**Oliver Varney** - *12:21:37*

stream authentication - Performance issues

*Tags: Performance*

---

**Oliver Varney** - *12:23:16*

just literally change this second from Performance issues to operational

*Tags: Performance*

---

## 2021-05-01

**mandelbot** - *12:53:42*

[@UBS7QANF3](@UBS7QANF3) I'm not finding the documentation for this, would you direct me to it?

*Tags: General Technical*

---

## 2021-05-07

**Jonjonjon** - *09:32:17*

I've found a potential bug in in exposure calculations, if Flumine attempts to replace an order. I've raised an issue and will take a look at fixing it at some point:



[https://github.com/liampauling/flumine/issues/423](https://github.com/liampauling/flumine/issues/423)

*Tags: Errors Debugging*

---

**liam** - *09:32:41*

forseen at one point :face_palm:  [https://github.com/liampauling/flumine/blob/4924616d3764ab5ea861a21a72054dc93d812d61/flumine/controls/tradingcontrols.py#L122](https://github.com/liampauling/flumine/blob/4924616d3764ab5ea861a21a72054dc93d812d61/flumine/controls/tradingcontrols.py#L122)

*Tags: Strategies*

---

**Jonjonjon** - *09:38:39*

There can't be that many people using the replace orders function if I'm the first one to hit this problem. Doesn't anyone else like to move their exit orders around, setting the price to track "fair value"?

*Tags: General Technical*

---

**Newbie99** - *10:49:12*

Yeah I've reported a few bugs around replace,  [@U4H19D1D2](@U4H19D1D2) has fixed everything now though (although override the min size check on a replace as that still doesn't work for me, i.e. it violates, but no-one else has been able to replicate that so its closed).

*Tags: Errors Debugging*

---

## 2021-05-11

**Greg** - *02:25:35*

Hi all. Having a go (be gentle -have only been studying Python for 3 months-so here come the very dumb questions:laughing:) at logging in with the delayed key/Flumine. Managed to login  run the example strategy (using AU markets-[https://liampauling.github.io/flumine/](https://liampauling.github.io/flumine/)) I have set paper trading to True but that, changing the price entry (see LimitOrder below) point, changing _runner.last_price_traded &lt; 10_ and setting the filter to AU instead of GB are about the only changes I have made. Unfortunately I get not output at all-or errors. 'Couple of questions to kick off with : *1*.I have seen references on this channel to the delayed key (despite mine being created after April 8th 2020 so should have access to streaming )being utterly useless and I wondered if this is the problem? i.e.: is the delayed key pointless and does it effectively prevent anything from working? *2*. Does Flumine (being a fully featured/ backtesting platform) effectively supersede BFLW (I know BFLW is a dependency for Flumine) ? *3*. The example strategy has an (LAY) order parameter of _order_type=LimitOrder(price=1.01,size=2.00)_ I tried to change the price to &lt;10 for example but get an error. How do you set a price range for multiple runners in Flumine using limit orders? Thanks in advance.Apologies for the basic questions and I'll try limit them as I go. Cheers

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

**Greg** - *07:22:26*

added the jsonlogger and saw an error re size of bet.Aussie currency needs min bet of $6 not 2 :face_with_hand_over_mouth:..thanks for the pointer to the logs

*Tags: Errors Debugging*

---

## 2021-05-13

**Peter** - *15:59:52*

Running into an odd problem that I'm hoping somebody here can provide some insight into. I have a strategy running where some of the bets placed are MARKET_ON_CLOSE, placed near the off time. Most work fine, but a small proportion are LAPSED. I'm trying to reason as to why. So far I've confirmed that they're not non-runners, not below £2 min bet size and not placed too late.  To make this still more difficult, when backtesting the markets the bets work fine, which would seem to argue against my latest hypothesis (insufficient liquidity to balance the SP book).

*Tags: Strategies*

---

**Peter** - *16:06:37*

Ah. OK. I thought that the backtesting was confirming the liquidity. I guess I got overconfident because backtesting has been absolutely awesome at perfectly replicating every real world problem I've run into up until now.

*Tags: General Technical*

---

**Peter** - *16:08:47*

I'm inclined then to settle on insufficient liquidity, especially since available to lay exceeds available to back in the SP portion of the market. Bummer though since that would constrain the strategy's scalability. Many thanks for the insight.

*Tags: Strategies*

---

## 2021-05-14

**Peter** - *08:52:07*

Seeing a lot of API errors this morning during order placement. Orders are getting through after connections are aborted and reset, but it sort of feels like BFLW is overcoming flakiness in the Exchange API by sheer persistence.

*Tags: Errors Debugging*

---

**Peter** - *08:55:01*

I suspect that this is impacting time to placement, which happily isn't a big deal for the strategy that's encountering the issue at the moment. But if you have strategies running where this is more significant, you might want to check that they're OK.

*Tags: Strategies*

---

**Peter** - *08:57:22*

`{"asctime": "2021-05-14 07:41:57,530", "levelname": "ERROR", "message": "OrderStream 1003 run error", "exc_info": "Traceback (most recent call last):`

  `File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 225, in _receive_all`

    `part = self._socket.recv(self.buffer_size)`

  `File \"/usr/local/lib/python3.9/ssl.py\", line 1226, in recv`

    `return self.read(buflen)`

  `File \"/usr/local/lib/python3.9/ssl.py\", line 1101, in read`

    `return self._sslobj.read(len)`

`socket.timeout: The read operation timed out`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

  `File \"/usr/local/lib/python3.9/site-packages/flumine/streams/orderstream.py\", line 45, in run`

    `self._stream.start()`

  `File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 60, in start`

    `self._read_loop()`

  `File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 207, in _read_loop`

    `received_data_raw = self._receive_all()`

  `File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 229, in _receive_all`

    `raise SocketError(\"[Connect: %s]: Socket %s\" % (self._unique_id, e))`

`betfairlightweight.exceptions.SocketError: [Connect: 1004]: Socket The read operation timed out"}`

*Tags: Errors Debugging*

---

**Lee** - *09:13:51*

I just had a SocketError too

*Tags: Errors Debugging*

---

**liam** - *10:24:15*

either that or my error monitoring has gone to shit

*Tags: Errors Debugging*

---

**Peter** - *17:20:11*

Returning to yesterday's issue - ~MATCH_ON_CLOSE~ MARKET_ON_CLOSE bets being lapsed. It turned out not to be a liquidity issue. Instead it was that I was calculating and rounding (2 decimal places) the transaction size and storing it in market.context, but when I pulled it out again, floating point precision being what it is, very occasionally what I received back would be different by 0.00000000000000001, which Betfair doesn't like and the order would be rejected. I suspect that my logging control log csv was showing the order as lapsed because it believed the order to have been placed, but didn't receive a settlement when the market cleared. Nevertheless, I learned valuable information about how far I can push backtesting, so thanks for the help with that, and I'll still be investigating the risks of not being able to fully match these orders , since that's still likely to be relevant when I start looking at scaling this strategy.

*Tags: Strategies*

---

**Peter** - *17:54:54*

`def _validate_betfair_liability(self, order):`

        `if order.order_type.liability is None:`

            `self._on_error(order, "Order liability is None")`

        `elif order.order_type.liability &lt;= 0:`

            `self._on_error(order, "Order liability is less than 0")`

*Tags: Errors Debugging*

---

**Peter** - *17:55:24*

Unlike for order size, there's no rounding error check for liabilities.

*Tags: Errors Debugging*

---

**liam** - *18:17:33*

Good spot, mind creating a GitHub issue for that so we can get it fixed?

*Tags: Errors Debugging*

---

**Phil Anderson** - *18:19:38*

Hi, can someone help me with MARKET_ON_CLOSE persistence type please?

I keep getting failed placement when I change from LAPSE or PERSIST to MARKET_ON_CLOSE.

I'm still testing on delayed key. Could this be the problem? I couldnt find anything to say I shouldnt be able to.

Below is code I've been using, and only changinh persistence type



```limit_order = filters.limit_order(

    price=12.5, size=2, persistence_type="MARKET_ON_CLOSE"

)

instruction = filters.place_instruction(

    order_type="LIMIT",

    selection_id=runner.selection_id,

    side="BACK",

    limit_order=limit_order,

)

place_orders = trading.betting.place_orders(

    market_id=j.market_id, instructions=[instruction], # list

)```



*Tags: Errors Debugging, Strategies*

---

## 2021-05-16

**Newbie99** - *14:48:25*

..going back to something that comes up quite a lot, but am looking at a slightly different approach...regarding existing orders post a shutdown.



So, assuming orders were created in the past (but importantly via Flumine) and the system has been shutdown, lets say yesterday and re-started today.



Upon startup, you run this:



```print(market.blotter.strategy_orders(self))```

It shows an empty list.



When the first order is placed, it then comes up with messages like this:



```WARNING:flumine.order.process:Order 233484712267 not present in blotter

{"asctime": "2021-05-16 13:41:06,704", "levelname": "WARNING", "message": "Order 233484712267 not present in blotter", "bet_id": "233484712267", "market_id": "1.160683973", "customer_strategy_ref": "BlueOcean", "customer_order_ref": "d0df7e7076e65-138404651686586786"}

INFO:flumine.order.process:Order 233484712267 added to blotter```

and from that point onwards everything works as expected.



So all that makes sense, however, in reality I don't want that first order to be placed as its effectively a duplicate. So how can I get the above to run before an order is placed (at which point Flumine won't place the order as it will see 1 already exists)?

*Tags: Strategies*

---

**Newbie99** - *15:16:49*

No, as in I placed an order via Flumine (unmatched), compeltely shut down, then started up again.

*Tags: General Technical*

---

**Oliver Varney** - *15:19:40*

I only ask as the stream doesnt return fully matched orders on restart, im not sure if liam added logic to flumine to grab fully matched orders. Although it doesnt sound like this case if you say it wasnt matched

*Tags: General Technical*

---

**Newbie99** - *16:01:41*

[@ULDAVFDRP](@ULDAVFDRP) yeah that isn't a problem, I know they won't be included, so my plan for already fully matched orders is to call list_current_orders on startup, then I create a single CurrentOrder object (which is just a rolled up total of all historic orders, as there is no roll up for current_orders unlike cleared). That gives me starting exposure, so that part is fine.



The problem is with these live unexecuted orders that do get picked up....but not until an order has been placed.

*Tags: Deployment*

---

**Newbie99** - *16:21:57*

What do you mean by the patch file? I've gone through the flumine Github (well that's just a permanent browser window these days :slightly_smiling_face:  and I have some ideas, but I presume its something along the line of process_current_orders isn't triggered unless it detects a new live order and once this has been run it then processes other orders that it couldn't have known about as they were placed in a prior session. So if I can work out the correct trigger, then potentially I can create a dummy order or something and do it that way (I could presumably create an order that will definitely fail, but that feels too 'hacky')!

*Tags: Deployment*

---

**liam** - *19:43:07*

Can you get bflw to work by itself? What python version / os are you using?

*Tags: General Technical*

---

**liam** - *19:48:27*

There is a flag in the flumine client to use that however I assume you want to start using certs?

*Tags: General Technical*

---

**Graham** - *20:09:33*

someone asked a similar question and you posted [https://betfairlightweight.slack.com/archives/C4H05ML2E/p1618580169102400](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1618580169102400)

*Tags: General Technical*

---

**liam** - *20:11:48*

Set it on the client [https://github.com/liampauling/flumine/blob/8c69f49f28c145c9f4ca4d0130067e4277975c4e/flumine/clients/baseclient.py#L24|https://github.com/liampauling/flumine/blob/8c69f49f28c145c9f4ca4d0130067e4277975c4e/flumine/clients/baseclient.py#L24](https://github.com/liampauling/flumine/blob/8c69f49f28c145c9f4ca4d0130067e4277975c4e/flumine/clients/baseclient.py#L24|https://github.com/liampauling/flumine/blob/8c69f49f28c145c9f4ca4d0130067e4277975c4e/flumine/clients/baseclient.py#L24)

*Tags: General Technical*

---

## 2021-05-17

**Newbie99** - *14:23:05*

[@ULDAVFDRP](@ULDAVFDRP) I have made progress here:



```    def process_market_book(self, market, market_book):

        # process marketBook object



        ''' Adds existing market orders (from a previous session) into the current strategy  '''

        for order in self.existing_orders:

            if order.customer_order_ref is not None and order.market_id == market.market_id:

                if order.bet_id not in [o.bet_id for o in market.blotter._live_orders]:

                    print('Adding Bet_id: ', order.bet_id, ' to blotter for market: ', market.market_id)

                    trade = Trade(order.market_id, order.selection_id, order.handicap, self)

                    order_id = order.customer_order_ref[STRATEGY_NAME_HASH_LENGTH + 1:]

                    order = trade.create_order_from_current(order, order_id)

                    order.status = OrderStatus.EXECUTABLE

                    market.blotter.__setitem__(customer_order_ref=order.customer_order_ref, order=order)



        print(market.blotter._live_orders)```

So by trying that approach it adds the order that was created in a previous session into the blotter...however it also then adds a duplicate into the blotter....but importantly does not send a request to try and place this on the exchange (at least from what I can see...it definitely hasn't placed any and I'm not seeing any errors to suggest its trying to).



So it feels like this approach is close, by chance [@U4H19D1D2](@U4H19D1D2) can you see what I might need to tweak here to pick up the previous session order and not create a duplicate in the current live blotter?

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *15:00:14*

Yeah so its caused by the order stream starting before the market stream has loaded/processed all markets which means you get the warning regarding the missing local market. Easy fix would be to delay the start of the order stream but this would still cause issues because you would then potentially have the same issue during the start delay. I think better fix is for me to figure out this [https://github.com/liampauling/flumine/blob/05182a42c654f505b12f176bcbe7d37edbf099c5/flumine/streams/orderstream.py#L65|todo](https://github.com/liampauling/flumine/blob/05182a42c654f505b12f176bcbe7d37edbf099c5/flumine/streams/orderstream.py#L65|todo) so that it effectively retries to add the live orders

*Tags: Errors Debugging, Deployment*

---

**liam** - *15:04:54*

so its a quick fix where it will snap the order stream every 5s (default) however you would need some logic/delay to stop and orders being placed on initial startup, does that make sense?

*Tags: Errors Debugging*

---

**liam** - *15:21:29*

[@UFTBRB3F1](@UFTBRB3F1) can you try [https://github.com/liampauling/flumine/pull/437|1.18.11b0](https://github.com/liampauling/flumine/pull/437|1.18.11b0) works on my side

*Tags: General Technical*

---

**liam** - *15:59:00*

middleware [https://github.com/liampauling/flumine/pull/437/files#diff-dae24ee21ed02d5552079cb23302f678d32cfa8f30d20885222eef2e545ae81e|example](https://github.com/liampauling/flumine/pull/437/files#diff-dae24ee21ed02d5552079cb23302f678d32cfa8f30d20885222eef2e545ae81e|example) added on how to add execution complete orders on startup

*Tags: General Technical*

---

**Newbie99** - *16:04:24*

Ah thats much better than my way! I just called list_current_orders and got a net exposure from that!



Are there likely to be any performance issues here if you have 1000's of orders (I'm thinking a use case for this could be say Wimbledon - Tournament Winner, so you could have a strategy running that market for potentially weeks)?

*Tags: Performance, Strategies*

---

**Newbie99** - *21:10:11*

I think I'm misunderstanding how to implement middleware (I put that in before framework.run()) and get the following error, where should I be calling this from?



```    framework.add_market_middleware(OrdersMiddleware())

TypeError: __init__() missing 1 required positional argument: 'flumine'```

*Tags: Errors Debugging*

---

**Lee** - *21:14:46*

if you're using the example you need to instantiate OrdersMiddleware with flumine which i think in your case might be framework. i.e. `framework.add_market_middleware(OrdersMiddleware(framework))`

*Tags: General Technical*

---

**Lee** - *21:15:27*

it's because the OrdersMiddleware class has the init method [https://github.com/liampauling/flumine/pull/437/files#diff-dae24ee21ed02d5552079cb23302f678d32cfa8f30d20885222eef2e545ae81eR18](https://github.com/liampauling/flumine/pull/437/files#diff-dae24ee21ed02d5552079cb23302f678d32cfa8f30d20885222eef2e545ae81eR18)

*Tags: General Technical*

---

**Newbie99** - *22:54:01*

[@U4H19D1D2](@U4H19D1D2) when running that middleware example I get a ton of these errors (is it possible there is no error catching if there are no completed orders for that market/strategy combo as that appears to be the case, but I could be wrong)?



```{"asctime": "2021-05-17 21:51:02,008", "levelname": "CRITICAL", "message": "Unknown error  in &lt;middleware_example.OrdersMiddleware object at 0x000001D04E45E580&gt; (1.180015935)", "exc_info": "Traceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\flumine\\utils.py\", line 220, in call_middleware_error_handling\n    middleware(market)\n  File \"D:\\Python38\\lib\\site-packages\\flumine\\markets\\middleware.py\", line 16, in __call__\n    raise NotImplementedError\nNotImplementedError"}

INFO:flumine.baseflumine:Adding: 1.180957876 to markets

{"asctime": "2021-05-17 21:51:02,011", "levelname": "INFO", "message": "Adding: 1.180957876 to markets"}

CRITICAL:flumine.utils:Unknown error  in &lt;middleware_example.OrdersMiddleware object at 0x000001D04E45E580&gt; (1.180957876)

Traceback (most recent call last):

  File "D:\Python38\lib\site-packages\flumine\utils.py", line 220, in call_middleware_error_handling

    middleware(market)

  File "D:\Python38\lib\site-packages\flumine\markets\middleware.py", line 16, in __call__

    raise NotImplementedError

NotImplementedError```

*Tags: Errors Debugging, Strategies*

---

**Lee** - *23:00:57*

Try upgrading flumine, the __ call__ method I think was changed to be not mandatory 

*Tags: General Technical*

---

**Newbie99** - *23:08:52*

I seem to have the latest version of flumine, so its not that.



Removing the logic does remove the errors as expected, but seems to produce a lot of latency warnings on startup (may just be co-incidence as I'm not sure why that would be...it did take a long time to cycle through everything)!



```WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time

{"asctime": "2021-05-17 22:06:31,634", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.167249195", "latency": 2.0103297233581543, "pt": "2021-05-17T22:06:29.624000"}```

*Tags: Errors Debugging, Performance*

---

## 2021-05-18

**Newbie99** - *10:21:50*

```print(market.blotter._strategy_selection_orders[(self, runner.selection_id, runner.handicap)])```



*Tags: Strategies*

---

**liam** - *10:23:47*

that should work, use the helper function though rather than the private _var

*Tags: General Technical*

---

**liam** - *10:29:35*

np, check the middleware isn't erroring

*Tags: Errors Debugging*

---

## 2021-05-20

**agberk** - *11:47:33*

Am I right in thinking this potentially blocks indefinitely?



[https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py#L198](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py#L198)



From [https://docs.python.org/3/library/socket.html#timeouts-and-the-connect-method](https://docs.python.org/3/library/socket.html#timeouts-and-the-connect-method)



&gt; The `connect()` operation is also subject to the timeout setting, and in general it is recommended to call `settimeout()` before calling `connect()`

*Tags: General Technical*

---

**liam** - *12:32:51*

My default is disabling network but I think you get a connection error 

*Tags: Errors Debugging*

---

**Newbie99** - *17:38:54*

[@U4H19D1D2](@U4H19D1D2) should this scenario be able to occur (as I've replicated it a few times, but didn't think it could):



1. Order placed via Flumine on runner x for market y (market.place_order)

2. Order cancelled manually in Betfair GUI

3. Identical replacement order placed via Flumine  on runner x for market y (market.place_order)

4. Duplicate identical replacement order placed via Flumine on runner x for market y (market.place_order)

Ignoring whether my logic is dodgy or not, surely the in-built Flumine logic shouldn't allow that scenario as it only allows 1 live order per runner per strategy?



Obviously if that is by design I can add some logic to stop it when not desired, but I thought that scenario should not be able to occur due to the 1 order per runner per strategy limit?

*Tags: Deployment, Strategies*

---

**Newbie99** - *17:48:45*

Do you want the logs (not sure if they will help)...my only guess is potentially a latency issue (I noticed a couple of high latency warnings around the same time)?

*Tags: Performance*

---

**liam** - *17:57:07*

Latency shouldn’t impact, yeah logs would help, I assume the strategy is using a simple place_order only 

*Tags: Performance, Strategies*

---

**Newbie99** - *18:18:01*

the place function is literally this:



```

def place_new_order(self, market, market_book, selection_id, handicap, price, stake, persistence_type, order_direction):

    trade = Trade(

        market_id=market_book.market_id,

        selection_id=selection_id,

        handicap=handicap,

        strategy=self,

    )

    order = trade.create_order(

        side=order_direction, order_type=LimitOrder(price=price, size=stake, persistence_type=persistence_type)

    )

    market.place_order(order)```



*Tags: Strategies*

---

## 2021-05-21

**liam** - *09:13:22*

Just released [https://github.com/liampauling/flumine/pull/439|1.18.12](https://github.com/liampauling/flumine/pull/439|1.18.12) with a fix to a race condition, I am not 100% that this is the issue you are seeing but looks like I introduced a race condition on start up, now refactored

*Tags: Errors Debugging*

---

**Newbie99** - *10:12:32*

all I did was manually click cancel in the GUI, my bot sees exposure is &gt; or &lt; x and places an order accordingly. I'll attach the updated logs and can give you some of the logic if you like, but not sure the latter will help much?

*Tags: General Technical*

---

**Newbie99** - *10:16:47*

from a logic / code perspective, so I don't overload you, what bit would help?

*Tags: General Technical*

---

**liam** - *10:17:15*

what version of flumine for those logs?

*Tags: General Technical*

---

**Newbie99** - *10:36:30*

```def populate_existing_positions(trading, market=False, group=True, order_status='ALL', flumine=True):



    ''' current order BFLW object properties '''

    '''

        betId: str,

        averagePriceMatched: float,

        bspLiability: float,

        handicap: float,

        marketId: str,

        orderType: str,

        persistenceType: str,

        placedDate: str,

        selectionId: int,

        side: str,

        sizeCancelled: float,

        sizeLapsed: float,

        sizeMatched: float,

        sizeRemaining: float,

        sizeVoided: float,

        status: str,

        priceSize: dict,

        regulatorCode: str = None,

        matchedDate: str = None,

        customerStrategyRef: str = None,

        customerOrderRef: str = None,

        regulatorAuthCode: str = None,

        lapsedDate: str = None,

        lapseStatusReasonCode: str = None,

        cancelledDate: str = None,

    '''

    '''

    Betfair Order type structure

    

        t = [{'market_id': '1.182015190', 'selection_id': 38378512, 'handicap': 0, 'id': '138378879025142090',

          'customer_order_ref': '0e6bc4bda0c6d-138378879025142090', 'bet_id': '230289893583',

          'date_time_created': '2021-04-16 17:45:02.514251', 'publish_time': '2021-04-16 17:45:02.504000',

          'trade': {'id': '78b5d6de-9edb-11eb-b72a-02f9e1e2dd3a', 'strategy': 'each_way_arb',

                    'place_reset_seconds': 0.0, 'reset_seconds': 0.0,

                    'orders': ['138378879025142090'], 'offset_orders': [],

                    'notes': '', 'market_notes': '4.9,5,4.9', 'status': 'Complete',

                    'status_log': 'Pending, Live, Complete'},

          'order_type': {'order_type': 'Limit', 'price': 4.3, 'size': 2,

                         'persistence_type': 'PERSIST', 'time_in_force': None,

                         'min_fill_size': None, 'bet_target_type': None, 'bet_target_size': None},

          'info': {'side': 'BACK', 'size_matched': 0.0, 'size_remaining': 0.0, 'size_cancelled': 0.0, 'size_lapsed': 2,

                   'size_voided': 0.0, 'average_price_matched': 0.0},

          'responses': {'date_time_placed': '2021-04-16 17:45:02.776941', 'elapsed_seconds_executable': None},

          'runner_status': None, 'status': 'Lapsed',

          'status_log': 'Pending, Lapsed', 'violation_msg': None,

          'simulated': {'profit': 0.0, 'piq': 0.0, 'matched': []}}]

    

    '''



    if flumine is True:

        completed_order_list = get_current_orders_flumine(self=trading, order_status=order_status, market=market)

    else:

        completed_order_list = get_current_orders(trading, order_status)



    order_list = []

    back_amount = 0

    lay_amount = 0

    for current_order in completed_order_list:

        if current_order.size_matched &gt; 0:

            if group is True:

                # order_bet_id = str(current_order.side) + '_' + str(current_order.market_id) + '_' + str(current_order.handicap) + '_' + str(current_order.selection_id)

                order_bet_id = str(current_order.side)[0] + str(current_order.market_id)[2:] + str(current_order.selection_id)

                # print(order_bet_id)

                customer_order_ref = config.hostname

                order_type = "LIMIT"

                persistence_type = "PERSIST"

            else:

                order_bet_id = current_order.bet_id

                customer_order_ref = current_order.customer_order_ref

                order_type = current_order.order_type

                persistence_type = current_order.persistence_type

            if order_bet_id not in [t.bet_id for t in order_list]:

                # print(order_bet_id)

                s = CurrentOrder(

                    order_bet_id,

                    current_order.average_price_matched,

                    0,

                    current_order.handicap,

                    current_order.market_id,

                    order_type,

                    persistence_type,

                    current_order.placed_date,

                    current_order.selection_id,

                    current_order.side,

                    current_order.size_cancelled,

                    current_order.size_lapsed,

                    current_order.size_matched,

                    current_order.size_remaining,

                    current_order.size_voided,

                    current_order.status,

                    {'price': current_order.price_size.price, 'size': current_order.price_size.size},

                    current_order.regulator_code,

                    current_order.matched_date,

                    None,

                    customer_order_ref,

                    current_order.regulator_auth_code,

                    None)

                order_list.append(s)

            else:

                for t in order_list:

                    # seems to keep pulling in same order on repeat, makes no sense

                    if order_bet_id == t.bet_id:

                        t.average_price_matched = ((t.size_matched * t.average_price_matched) - t.size_matched) + \

                                                  ((current_order.average_price_matched * current_order.size_matched) - current_order.size_matched) \

                            if t.average_price_matched is not None and current_order.size_matched &gt; 0 else None

                        t.size_cancelled += current_order.size_cancelled

                        t.size_lapsed += current_order.size_lapsed

                        t.size_matched += current_order.size_matched

                        t.size_remaining += current_order.size_remaining

                        t.size_voided += current_order.size_voided

                        t.matched_date = current_order.matched_date

                        t.average_price_matched = 1 + (t.average_price_matched / t.size_matched) if t.size_matched &gt; 0 and t.average_price_matched is not None else None

                        t.price_size.price = t.average_price_matched # Given the order has been executed, the price is set to the average price matched



    return order_list```



*Tags: Deployment, Strategies*

---

**Newbie99** - *10:37:57*

The whole purpose of this is for long running markets, at some point flumine will have to shut down (rather than running 24/7 for days/weeks/months on end), so this aims to grab existing orders, roll up to calc live exposure and then grab any existing live orders (created previously in a flumine session) and pull them into the current blotter.

*Tags: Deployment*

---

**liam** - *10:41:37*

there is a bug here somewhere though I think as flumine should try and handle this better but I can't see it right now

*Tags: Errors Debugging*

---

**Newbie99** - *11:18:01*

Okay cool, will see if I can come up with a workaround for now and will post once done (in case it helps anyone else)

*Tags: General Technical*

---

**liam** - *11:25:45*

whats wrong with thousands of orders? flumine is heavily optimised for this

*Tags: General Technical*

---

**Newbie99** - *11:27:05*

potentially nothing tbh, I just thought for these types of markets that can go on forever it could be problematic down the road

*Tags: General Technical*

---

**liam** - *11:30:54*

premature optimization imho, keep it simple, 1-2k orders per market is normal for me (on every uk horse race)

*Tags: Performance, Strategies*

---

**Newbie99** - *11:35:25*

One question though, if there are no executable orders on startup, i.e. only execution_complete coming through the middleware. Why would the issue persist still for new orders created during the session?

*Tags: General Technical*

---

**Newbie99** - *16:24:11*

However I can only replicate if manually cancelling an order in the Betfair GUI. If I place an order, then cancel all within Flumine it appears to handle as expected.

*Tags: General Technical*

---

**liam** - *17:06:53*

Are you sure your not running two instances of a bot on this market? Because order 233925456353 appears from somewhere else after you cancel, I can see it was placed by your strategy and by flumine but it wasn't from this running instance

*Tags: Strategies*

---

**liam** - *17:26:26*

Yeah, is has no way to differentiate them as flumine uses the strategy name which isn’t unique, if you need two change the name on initialisation 

*Tags: Strategies*

---

**Newbie99** - *17:26:54*

the strategy names are unique

*Tags: Strategies*

---

**Newbie99** - *17:27:23*

strategy_x_back and strategy_x_y

*Tags: Strategies*

---

**Newbie99** - *17:27:38*

sorry strategy_x_lay for the second

*Tags: Strategies*

---

**Newbie99** - *17:27:57*

both orders have to have come from the lay strategy

*Tags: Strategies*

---

**liam** - *17:27:58*

It was from a different running instance of flumine 

*Tags: General Technical*

---

**Newbie99** - *17:32:22*

just replicated with the one strategy running, very odd. Just grabbing the logs...

*Tags: Strategies*

---

**liam** - *17:34:46*

Are you sure you have nothing else running? Try again but change the name of the strategy to confirm 

*Tags: Strategies*

---

**Newbie99** - *17:41:01*

I have a horse racing strategy on AWS running, that only looks at event_type_id = 7 though, I can kill it to see, but surely with these filters it couldn't possibly interfere could it?



```market_filter=streaming_market_filter(

    event_type_ids=s['7'],

    country_codes=['GB','IE','US'],

    market_types=['WIN','PLACE', 'EACH_WAY'],```



*Tags: Deployment, Strategies*

---

**Unknown** - *17:46:51*

Ok so:



strategy name changed

only 1 strategy running

only 1 instance running locally

AWS horse racing instance killed before running

*Tags: Deployment, Strategies*

---

**Newbie99** - *17:47:35*

(all those order not found in blotter are of course because there are live orders from the previous strategy name on this market)

*Tags: Deployment, Strategies*

---

**liam** - *18:14:41*

can you change the strategy name to name+os.process_id

*Tags: Strategies*

---

**Newbie99** - *18:21:24*

`{"id": "bf189146-ba58-11eb-91bf-2016d8944b85", "strategy": "politics_test20216", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138409103890878791"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 1.86, "size": 17.44, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 17.44, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Pending", "status_log": "Pending", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}`

INFO:flumine.order.order:Order status update: Pending

{"asctime": "2021-05-21 17:19:49,088", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.160683973", "selection_id": 25181943, "handicap": 0, "id": "138409103890878791", "customer_order_ref": "e6e7ee3f26f23-138409103890878791", "bet_id": null, "date_time_created": "2021-05-21 17:19:49.087879", "publish_time": "2021-05-21 17:19:47.488000", "trade": {"id": "bf189146-ba58-11eb-b280-2016d8944b85", "strategy": "politics_test10376

*Tags: Deployment, Strategies*

---

**Newbie99** - *18:21:55*

Ooops sorry didn't paste very well, but you can see the strategy_name + processid is different!

*Tags: Strategies*

---

**Unknown** - *20:12:19*

I suspect the problem occurs in the bit starting at line 157

*Tags: General Technical*

---

**Newbie99** - *20:42:54*

```import time

from datetime import timedelta, timezone, datetime

import logging

import betfairlightweight

import argparse

from betfairlightweight.filters import streaming_market_filter

from pythonjsonlogger import jsonlogger

import racing_functions as rf

import non_streaming_functions as nsf

from flumine import Flumine, clients, BaseStrategy, markets

import account_info as ai

from simple_book import simple_book

from flumine.worker import BackgroundWorker

from marketrecorder import MarketRecorder

from flumine.streams.datastream import DataStream

# from race_card import get_racecard

from price_comparison import get_price_comparison

from terminate import terminate

from cross_market import get_markets

from orders_worker import get_live_orders

from flumine.controls.loggingcontrols import LoggingControl

global snapshot



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = [logging.StreamHandler(), logging.FileHandler(ai.log_folder_path + '/' + datetime.now().strftime("%m-%d-%Y_%H_%M_%S") + '.log')]

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime



for l in log_handler:

    l.setFormatter(formatter)

    logger.addHandler(l)

# logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



rc = rf.open_json(ai.racing_config)



parser = argparse.ArgumentParser()

parser.add_argument("--c", default=None, type=int, help="Conflate messages in ms")

parser.add_argument("--s", "--strategy-list", nargs='+', default=[])

parser.add_argument("--p", default=False, type=bool, help="Paper or real world trading")



args = parser.parse_args()



paper = args.p

# paper = True

if paper == True:

    print('Paper Trading Enabled')

else:

    print('Live Trading Enabled')



market_recorder = False

if market_recorder is True:

    print('Market Recorder Enabled')



strategy_names = args.s

strategy_names = ['politics_test']

conflate = args.c



start_time = datetime.now(timezone.utc)



settings = [setting for setting in rc if setting['on'] == 'True' and setting['strategy_name'] in strategy_names]



trading = betfairlightweight.APIClient(ai.accname, ai.accpass, ai.acckey, certs=ai.path)

# min bet validation temporarily added to stop the min size replace issue

client = clients.BetfairClient(trading, paper_trade=paper) #,  min_bet_validation=False)



framework = Flumine(client=client)



for s in settings:

    country_codes = s['country_codes'] if nsf.true_or_false(s['country_codes']) != False else None

    market_types = s['market_types'] if nsf.true_or_false(s['market_types']) != False else None

    race_types = s['race_types'] if nsf.true_or_false(s['race_types']) != False else None

    venues_to_include = s['venues_to_include'] if nsf.true_or_false(s['venues_to_include']) != False else None

    print({'strategy_name': s['strategy_name'], 'strategy_type': s['strategy_type'], 'event_type_ids': s['event_type_ids'],

           'country_codes': country_codes, 'market_types': market_types, 'race_types': race_types, 'venues': venues_to_include})

    if s['strategy_type'] == 'simple':

        strategy = simple_book(start_time=start_time, settings=s,

            market_filter=streaming_market_filter(

                event_type_ids=s['event_type_ids'],

                country_codes=country_codes,

                market_types=market_types,

                # market_types=['WIN', 'OTHER_PLACE'],

                # country_codes=['AU'],

                # market_types=['WIN','PLACE', 'EACH_WAY'],

                race_types=race_types,

                venues=venues_to_include



            ),

            streaming_timeout=2,

            max_selection_exposure=s['max_selection_exposure'],

            max_order_exposure=s['max_order_exposure'],

            conflate_ms=conflate,

            name=s['strategy_name'],



        )



        framework.add_strategy(strategy)



worker_settings_list = [

    {'function_name': 'get_markets', 'function': get_markets, 'func_kwargs': {"stake": 2, "margin": 0, "exposure_limit": 60}, 'interval': 0.25, 'start_delay': 30},

    {'function_name': 'terminate', 'function': terminate, 'func_kwargs': {"today_only": True, "seconds_closed": 600}, 'interval': 60, 'start_delay': 60},

    {'function_name': 'get_price_comparison', 'function': get_price_comparison, 'func_kwargs': None, 'interval': 60 - rf.randomiser(15), 'start_delay': 30},

    # {'function_name': 'get_live_orders', 'function': get_live_orders, 'func_kwargs': {'snapshot':snapshot}, 'interval': 5, 'start_delay': 30},

    # {'function_name': 'get_racecard', 'function_name': get_racecard,'func_kwargs': {"event_type_ids": 7, 'market_types': 'WIN', 'source': 'Racecard'}, 'interval': 30, 'start_delay': 30}

]



for f in rf.get_worker_functions(settings):

    function_setting = [ws for ws in worker_settings_list if str(ws['function_name']) == f['function_name']]

    if len(function_setting) &gt; 0:

        function_setting = function_setting[0]

        print(f, function_setting)

        framework.add_worker(

            BackgroundWorker(

                framework,

                function_setting['function'],

                func_kwargs=function_setting['func_kwargs'],

                interval=function_setting['interval'],

                start_delay=function_setting['start_delay']

            ))



if market_recorder is True:

    recorder = MarketRecorder(

        name="WIN",

        market_filter=streaming_market_filter(

                event_type_ids=[7],

                country_codes=['GB','IE','US','CA'],

                market_types=['WIN','PLACE'],

            ),

        stream_class=DataStream,

        context={

            "local_dir": ai.unprocessed_data,

            "bucket": "fluminetest",

            "force_update": False,

            "remove_file": True,

        },

    )



    framework.add_strategy(recorder)



framework.run()```



*Tags: Data Quality, Deployment, Strategies*

---

## 2021-05-22

**Newbie99** - *09:51:44*

Playing around more, its appears the thread itself isn't an issue (i.e. if I start Flumine in a thread that behaves correctly, however if I start Flask it does not).



```from flask_socketio import SocketIO, emit

from flask import Flask, render_template

import time

import os

import threading

from startup import startup



run_flask = False



if __name__ == '__main__':



    print('Process ID_a' + str(os.getpid()))

    def f():        

        import time

        global snapshot

        time.sleep(0.1)

        lock = threading.Lock()

        with lock:

            snapshot = {}

            print('Process ID_b' + str(os.getpid()))

            ''' Initiates and runs all Flumine Framework elements '''

            startup()



    t1 = threading.Thread(target=f)

    t1.start()

    time.sleep(0.1)



    if run_flask is True:

        ''' When this runs it causes the problem (i.e. a new process which duplicates the above thread) '''

        app = Flask(__name__)

        app.config['SECRET_KEY'] = 'secret!'

        app.config['DEBUG'] = True



        # turn the flask app into a socketio app

        socketio = SocketIO(app, async_mode=None, logger=True, engineio_logger=True)



        @app.route('/')

        def index():

            # only by sending this page first will the client be connected to the socketio instance

            return render_template('index.html')



        @socketio.on('ping')

        def handle_message(*_args, **_kwargs):

            print(snapshot)

            emit('market_update', {'market_update': snapshot})



        @socketio.on('connect')

        def test_connect():

            print('Client connected')



        @socketio.on('disconnect')

        def test_disconnect():

            print('Client disconnected')



        socketio.run(app, debug=True, port=5678)```

I haven't figured it out yet, but clearly I need to change this approach somehow, will post if I figure it out (just in case it helps anyone else) and if anyone happens to have any suggestions, please shout (and appreciate the time you spent looking at this [@U4H19D1D2](@U4H19D1D2) , apologies if it was a bit of a wild goose chase)!

*Tags: Errors Debugging*

---

**Newbie99** - *10:01:45*

Ah I think I may have got it!



```socketio.run(app, debug=False, port=5678)```

If debug is set to True apparently that starts a concurrent process, so setting that to False appears to allow it to work correctly (well based on a very quick test anyway)!

*Tags: Errors Debugging*

---

**Newbie99** - *18:32:03*

[@U4H19D1D2](@U4H19D1D2) this may well be intended behaviour, but it seemed a bit odd.



Using your middleware example (as opposed to my adjusted one we spoke about previously): [https://github.com/liampauling/flumine/blob/5b0d3f24a3e27dc6d50d8de9f154df326d37924e/examples/middleware/orders.py](https://github.com/liampauling/flumine/blob/5b0d3f24a3e27dc6d50d8de9f154df326d37924e/examples/middleware/orders.py)



Line 63: `order = trade.create_order_from_current(current_order, order_id)`



This appears to reset the size_matched and size_remaining (presumably as it was never intended to be used for EXECUTION_COMPLETE orders).



So as an example, this quick test:



```print({'timeline': 'before trade.create_order_from_current', 'bet_id': current_order.bet_id, 'status': current_order.status,

       'size': current_order.price_size.size, 'size_remaining': current_order.size_remaining, 'size_matched': current_order.size_matched})

order = trade.create_order_from_current(current_order, order_id)

print({'timeline': 'after trade.create_order_from_current', 'bet_id': order.bet_id, 'status': order.status,

       'size': order.order_type.size, 'size_remaining': order.size_remaining, 'size_matched': order.size_matched})```

Produces:



```{'timeline': 'before trade.create_order_from_current', 'bet_id': '233585245155', 'status': 'EXECUTION_COMPLETE', 'size': 3.45, 'size_remaining': 0.0, 'size_matched': 3.45}

{'timeline': 'after trade.create_order_from_current', 'bet_id': '233585245155', 'status': None, 'size': 3.45, 'size_remaining': 3.45, 'size_matched': 0.0}

{'timeline': 'before trade.create_order_from_current', 'bet_id': '233997105844', 'status': 'EXECUTABLE', 'size': 16.67, 'size_remaining': 16.67, 'size_matched': 0.0}

{'timeline': 'after trade.create_order_from_current', 'bet_id': '233997105844', 'status': None, 'size': 16.67, 'size_remaining': 16.67, 'size_matched': 0.0}

{'timeline': 'before trade.create_order_from_current', 'bet_id': '233997105880', 'status': 'EXECUTABLE', 'size': 17.64, 'size_remaining': 17.64, 'size_matched': 0.0}

{'timeline': 'after trade.create_order_from_current', 'bet_id': '233997105880', 'status': None, 'size': 17.64, 'size_remaining': 17.64, 'size_matched': 0.0}```

So whilst for the EXECUTABLE bets it works as expected, for the first one, it presumably sets size_remaining == size, rather than validating against current_order.size_remaining and current_order.size_matched.



Obviously there is an easy enough work around, but if middleware is expected to be used for this purpose then could it be worth updating the functionality here (assuming you can replicate and its not just some weird quirk happening only to me of course)?

*Tags: General Technical*

---

**Newbie99** - *19:45:50*

No sorry, I mean in terms of the [http://flumine.order.xxx|flumine.order.xxx](http://flumine.order.xxx|flumine.order.xxx)

*Tags: General Technical*

---

**Newbie99** - *19:48:24*

Line 63, surely the same problem occurs as per my description, i.e. orders.response.current_order never gets populated and so the size_matched remains at 0?

*Tags: General Technical*

---

**liam** - *19:53:10*

[https://github.com/liampauling/flumine/blob/44ceeed0fa77b9d16dc8034d0935244a65ccc0b2/examples/middleware/orders.py#L38|https://github.com/liampauling/flumine/blob/44ceeed0fa77b9d16dc8034d0935244a65ccc0b2/examples/middleware/orders.py#L38](https://github.com/liampauling/flumine/blob/44ceeed0fa77b9d16dc8034d0935244a65ccc0b2/examples/middleware/orders.py#L38|https://github.com/liampauling/flumine/blob/44ceeed0fa77b9d16dc8034d0935244a65ccc0b2/examples/middleware/orders.py#L38)

*Tags: General Technical*

---

## 2021-05-25

**Tony** - *09:56:57*

Hi I was hoping that someone might be able to help or point me in the right direction. When I try to connect to the betfair stream I get the following error:

```"errorCode":"INVALID_SESSION_INFORMATION","errorMessage":"Session must be 'Bearer &lt;session&gt;' for a WebApp","connectionClosed":true,```



*Tags: Errors Debugging*

---

**liam** - *10:16:37*

Got any code? Any reason you aren’t using bflw? At a guess you are using the wrong endpoint 

*Tags: General Technical*

---

**Tony** - *10:33:53*

I get that error

*Tags: Errors Debugging*

---

**Tony** - *10:34:16*

I believe it is because I need to use our Vendor ID and the betfairlightweight doesn't use that

*Tags: General Technical*

---

**liam** - *10:47:45*

using python?

*Tags: General Technical*

---

## 2021-05-26

**Jorge** - *09:52:01*

Hi guys, how do you filter by country_codes = [None]? I know bflw takes care of this, but curious what Request do you send to filter those.

*Tags: General Technical*

---

**Jorge** - *10:40:29*

International games do not have a country_code, so adding None to the list of country_codes we pass in streaming_market_filter allows us to get data from these markets

*Tags: General Technical*

---

**Jorge** - *10:41:39*

This seems to be working for Streaming but not for the `market_filter` argument passed in `list_market_catalogue`

*Tags: General Technical*

---

**kieran** - *11:50:33*

Hi, Apologies I am getting the same issue. I'm a Python beginner.  I'm not fully sure what "var on the flumine client" means or what the fix is? Any guidance would be appreciated.

*Tags: Getting Started, Errors Debugging*

---

**liam** - *11:51:14*

Are you using flumine or just bflw?

*Tags: General Technical*

---

## 2021-05-27

**kieran** - *14:02:18*

I tried both and am getting the same error.

*Tags: Errors Debugging*

---

**liam** - *14:06:45*

so for bflw you would

```trading.login_interactive()```

as per the [https://liampauling.github.io/betfair/quickstart/|docs](https://liampauling.github.io/betfair/quickstart/|docs)



and for flumine its

```client = clients.BetfairClient(trading, interactive_login=True)```

*Tags: Strategies*

---

**kieran** - *15:05:19*

Ah, thank you, that solved it.

*Tags: General Technical*

---

## 2021-05-28

**Phil Anderson** - *16:15:59*

Hi. Can anyone help me with the MARKET_ON_CLOSE function? I did post before but never got a reply.

I have code set up to place bets, but if I switch persistence type from LAPSE or PERSIST to MARKET_ON_CLOSE, I get FAILURE. I thought it could be because i was using delayed key, but am using live key now and still same.



Code below:



```limit_order = filters.limit_order(

    price=12.5, size=2, persistence_type="MARKET_ON_CLOSE"

)

instruction = filters.place_instruction(

    order_type="LIMIT",

    selection_id=runner.selection_id,

    side="BACK",

    limit_order=limit_order,

)

place_orders = trading.betting.place_orders(

    market_id=j.market_id, instructions=[instruction], # list

)```



*Tags: Deployment, Strategies*

---

## 2021-06-01

**Newbie99** - *18:17:39*

[@U4H19D1D2](@U4H19D1D2), I've been using that middleware for a bit now and all seems to be good, all EXECUTION_COMPLETE orders come through as expected.



Additionally, Flumine was picking up all EXECUTABLE orders from previous sessions (if created in Flumine), however I noticed one order never gets picked up.



It was created by Flumine in a previous session and all other orders from previous sessions that remain executable are picked up.



The only thing I can see that is different about this one, is that the exposure is very small (LAY 33p @ 1.43 is the size_remaining), is the small size stopping it being picked up?



 I'm just checking if it exists as follows:



``` def process_orders(self, market, orders):



        if market.market_book is not None and \

                market.market_book.status not in ['CLOSED','SUSPENDED']:



            for order in orders:

                if str(order.bet_id) == '234892683410':

                    print(order.bet_id)```

*Tags: General Technical*

---

**liam** - *18:34:56*

Was it an order that was replaced by any chance? Can you create a strategy to replicate the issue

*Tags: Strategies*

---

**Newbie99** - *18:41:47*

If it helps, I can see the original bet_id for the original £3 bet was different to the bet_id above, so it has to have been replaced

*Tags: General Technical*

---

## 2021-06-02

**Newbie99** - *09:27:50*

[@U4H19D1D2](@U4H19D1D2) I am really struggling to replicate this! But the timeline is as follows (which may or may not help):



1. LAY order for £3 @ 1.39 created

2. 2.67 matched @ 1.39

3. Replace moves the price to 1.43 (so 33p now remains @ 1.43)

4. Flumine shutdown (as in killed by me, stopped overnight, not a socket error)

5. Flumine restarts and the trade no longer appears in the blotter

From what I can see, a trade simply being replaced shows up correctly, so although I can't prove it, it looks like its something to do with the size (possibly its failing a check somewhere and I haven't spotted where yet)?

*Tags: Errors Debugging*

---

## 2021-06-03

**James McKenzie** - *10:38:19*

Hi guys, I have a Betfair account that's been set up by a client who is based in Asia. I have been told that all betfair code needs to be ran from a Hong Kong server. I am running into connection problems when I run some flumine based price scraping code from an AWS server in HK. I see a huge ramp up in the latency and then a fairly nasty connection error message:



```{"asctime": "2021-06-02 12:37:54,900", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5828690528869629"}                                                                        

{"asctime": "2021-06-02 12:40:35,503", "levelname": "INFO", "message": "[MarketStream: 2001] 1.184035567 removed, 139 markets in cache"}                                                                    

{"asctime": "2021-06-02 12:45:32,223", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 5.051729917526245"}                                                                         

{"asctime": "2021-06-02 12:46:17,490", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 50.812371015548706"}                                                                        

{"asctime": "2021-06-02 12:46:55,148", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 88.5535352230072"}                                                                          

{"asctime": "2021-06-02 12:47:41,872", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 133.0834095478058"}                                                                         

{"asctime": "2021-06-02 12:48:34,090", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 182.7278220653534"}                                                                         

{"asctime": "2021-06-02 12:50:47,754", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 297.83341121673584"}                                                                        

{"asctime": "2021-06-02 12:56:28,947", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 664.3587987422943"}                                                                         

{"asctime": "2021-06-02 12:57:00,334", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 695.7359499931335"}                                                                         

{"asctime": "2021-06-02 12:58:46,348", "levelname": "ERROR", "message": "get_account_details error", "exc_info": "Traceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/urllib3/connec

tion.py\", line 159, in _new_conn\n    conn = connection.create_connection(\n  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 61, in create_connection\n    for res in socket.geta

ddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/usr/lib/python3.8/socket.py\", line 918, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gai

error: [Errno -3] Temporary failure in name resolution\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages

/urllib3/connectionpool.py\", line 665, in urlopen\n    httplib_response = self._make_request(\n  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 376, in _make_request\n    self._v

alidate_conn(conn)\n  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 996, in _validate_conn\n    conn.connect()\n  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", l

ine 314, in connect\n    conn = self._new_conn()\n  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 171, in _new_conn\n    raise NewConnectionError(\nurllib3.exceptions.NewConnectionEr

ror: &lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f7c3bde0c10&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution\n\nDuring handling of the above exception,

 another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/requests/adapters.py\", line 439, in send\n    resp = conn.urlopen(\n  File \"/usr/lib/python3/d

ist-packages/urllib3/connectionpool.py\", line 719, in urlopen\n    retries = retries.increment(\n  File \"/usr/lib/python3/dist-packages/urllib3/util/retry.py\", line 436, in increment\n    raise MaxRetr

yError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/account/json-rpc/v1 (Ca

used by NewConnectionError('&lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f7c3bde0c10&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n\nDuring handli

ng of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 

36, in request\n    response = [http://session.post|session.post](http://session.post|session.post)(\n  File \"/usr/lib/python3/dist-packages/requests/api.py\", line 116, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"/usr/l

ib/python3/dist-packages/requests/api.py\", line 60, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/usr/lib/python3/dist-packages/requests/sessions.py\", line 533, in 

request\n    resp = self.send(prep, **send_kwargs)\n  File \"/usr/lib/python3/dist-packages/requests/sessions.py\", line 646, in send\n    r = adapter.send(request, **kwargs)\n  File \"/usr/lib/python3/di

st-packages/requests/adapters.py\", line 516, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retrie

s exceeded with url: /exchange/account/json-rpc/v1 (Caused by NewConnectionError('&lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f7c3bde0c10&gt;: Failed to establish a new connection: [Errno -3] Te

mporary failure in name resolution'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages

/flumine/clients/betfairclient.py\", line 50, in _get_account_details\n    return self.betting_client.account.get_account_details()\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightwe

ight/endpoints/account.py\", line 54, in get_account_details\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/

betfairlightweight/endpoints/baseendpoint.py\", line 43, in request\n    raise APIError(None, method, params, e)\nbetfairlightweight.exceptions.APIError: AccountAPING/v1.0/getAccountDetails \nParams: {} \

nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/account/json-rpc/v1 (Caused by NewConnectionError('&lt;urllib3.connection.VerifiedHTTPSConnection o

bject at 0x7f7c3bde0c10&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))", "error": "AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: HTTPSConnection

Pool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/account/json-rpc/v1 (Caused by NewConnectionError('&lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f7c3bde0c10&gt;: F

ailed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"}             

{"asctime": "2021-06-02 12:58:46,360", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 801.6888477802277"}

Killed```

Does anyone have any ideas about the cause of the problem and how I might resolve it. Much appreciated.

*Tags: Errors Debugging, Performance, Deployment, Strategies*

---

**liam** - *10:41:32*

So the connection error is on the account details endpoint, whats the setup here in terms of number of markets?

*Tags: Getting Started, Errors Debugging*

---

**James McKenzie** - *10:44:30*

typically the latency from HK seems to be stable at around 0.5s

*Tags: Performance*

---

**James McKenzie** - *10:48:45*

I was going to ask about that as well. I have noticed that when I run my flumine code, or a previous betfairlightweight price scraper I have on the HK box I see the RAM usage slowly creep up until the process is killed. I had previously tried to flush the queue every 10 seconds (presuming it was the queue gathering data) and I still saw the RAM usage increase. The same code ran on a UK based AWS instance for my own use didnt have the memory problems.

*Tags: Performance, Deployment*

---

**liam** - *10:49:18*

there are no known memory leaks in bflw or flumine

*Tags: Performance*

---

**liam** - *10:51:05*

looks like it, the way the latency increases like that isn't good, why HK?

*Tags: Performance*

---

**Newbie99** - *14:54:24*

Being across 2 sessions (i.e. after a shutdown), this is a very tricky one to debug!



Will try to do a forced update of Flumine, although pretty sure I'm using the latest version.



Will work on trying to pinpoint the issue.

*Tags: Errors Debugging*

---

## 2021-06-04

**James McKenzie** - *10:58:45*

I removed the strategy that pushes to redis and just ran a market recorder. I got the following when scraping GB races:





```{"asctime": "2021-06-04 05:02:46,633", "levelname": "WARNING", "message": "_get_cleared_market StatusCodeError", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flumine/worker.py\", line 228, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 48, in request\n    check_status_code(response)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/utils.py\", line 34, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 503", "trading_function": "list_cleared_orders", "response": "Status code error: 503"}

{"asctime": "2021-06-04 05:03:01,545", "levelname": "ERROR", "message": "get_account_details error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flumine/clients/betfairclient.py\", line 50, in _get_account_details\n    return self.betting_client.account.get_account_details()\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/account.py\", line 54, in get_account_details\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 48, in request\n    check_status_code(response)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/utils.py\", line 34, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 503", "error": "Status code error: 503"}

{"asctime": "2021-06-04 05:03:02,638", "levelname": "ERROR", "message": "get_account_funds error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flumine/clients/betfairclient.py\", line 56, in _get_account_funds\n    return self.betting_client.account.get_account_funds()\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/account.py\", line 35, in get_account_funds\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 48, in request\n    check_status_code(response)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/utils.py\", line 34, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 503", "error": "Status code error: 503"}```

the process is currently hanging

*Tags: Data Quality, Errors Debugging, Strategies*

---

**James McKenzie** - *11:03:26*

seems a different problem to the one described earlier

*Tags: General Technical*

---

## 2021-06-08

**Lee** - *23:47:26*

Use this function [https://github.com/liampauling/betfair/blob/ee4488ddb4f4bee775450f7497c08ea0fb470e9b/betfairlightweight/filters.py#L68|https://github.com/liampauling/betfair/blob/ee4488ddb4f4bee775450f7497c08ea0fb470e9b/betfairlightweight/filters.py#L68](https://github.com/liampauling/betfair/blob/ee4488ddb4f4bee775450f7497c08ea0fb470e9b/betfairlightweight/filters.py#L68|https://github.com/liampauling/betfair/blob/ee4488ddb4f4bee775450f7497c08ea0fb470e9b/betfairlightweight/filters.py#L68)

*Tags: General Technical*

---

**rjj** - *23:58:04*

I've tried

```date_range = time_range(from_='20210607', to='20210608')```

But that throws an exception betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders

Params: {'betStatus': 'SETTLED', 'settledDateRange': {'from': '20210607', 'to': '20210608'}}

Exception: None

*Tags: Errors Debugging*

---

## 2021-06-09

**Unknown** - *23:27:05*

Hi, I started using the API, but I have no idea how to get the (lay and back) values ​​of a horse race. Does anyone have a basic example or a link so I can start this development?

*Tags: General Technical*

---

## 2021-06-10

**John** - *00:01:31*

[@U024BRSPXGD](@U024BRSPXGD) check this out [https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/examples/strategies/priceblockage.py#L40](https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/examples/strategies/priceblockage.py#L40)

*Tags: General Technical*

---

**John** - *00:02:31*

this is a good example [https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/examples/example.py](https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/examples/example.py)

*Tags: General Technical*

---

## 2021-06-15

**Andy B** - *07:40:08*

Hi All, I'm working my through the python API tutorial on [https://betfair-datascientists.github.io/api/apiPythontutorial/](https://betfair-datascientists.github.io/api/apiPythontutorial/) and I keep running into the same issue with the process_runner_books function.  Just wondering if I am missing something as more often than not I get an 'IndexError: list index out of range' error at this line:

best_back_prices = [runner_book.ex.available_to_back[0].price

                        if runner_book.ex.available_to_back[0].price

The odd thing for me is that it does work for some market_id's, so that has me wondering if there are specific market types that need to be filtered to prevent this error.  I've re-read the doco countless times, and I'm not seeing something I missed, although it is entirely likely\possible that I did.  Any chance someone has had the same issue and found a resolution?

*Tags: Errors Debugging*

---

**Jonjonjon** - *08:25:41*

This function was written to handle missing prices:



[https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/flumine/utils.py#L104](https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/flumine/utils.py#L104)

*Tags: General Technical*

---

**Andy B** - *09:54:24*

Cheers, I spent so long looking at the error that I lost of sight of some simple troubleshooting.

*Tags: Errors Debugging*

---

**thambie1** - *10:53:29*

[@UBS7QANF3](@UBS7QANF3), given you have your own tech stack, how do you know so much about bflw?

*Tags: General Technical*

---

**Mo** - *11:04:15*

I use bflw but not flumine 

*Tags: General Technical*

---

**Scott** - *11:18:46*

Morning all, is there any obvious reason why it appears bflw isn’t passing my key over to bf? I’m on a windows machine and certs folder is at the same level as bflw file.. created the cert and key on Linux following steps and uploaded to bf okay. Just can’t seem to log in. First time creating my own OpenSSL stuff so quite probable that I have messed up along that line although I appear to have the three files req 

*Tags: Getting Started*

---

**Mo** - *11:22:08*

It helps to have an actual error message

*Tags: Errors Debugging*

---

**Scott** - *11:22:59*

Sorry, assume I’m a moron.. where would I find the error message 

*Tags: Errors Debugging*

---

**Mo** - *11:28:34*

What exactly are you running? Are you entering commands into a Python console? Are you running a Python script?

*Tags: General Technical*

---

**Scott** - *11:32:33*

Just a script that logs in. So details into trading = bflw.api

trading.login

then print(trading.session_expired)

If this was false (log in successful) I would then use the shell just to get used to what commands give me what data 

*Tags: Strategies*

---

**Scott** - *11:50:35*

Thanks [@UBS7QANF3](@UBS7QANF3) it was a problem with the path. Changed to absolute and it’s logged in successfully! 

*Tags: General Technical*

---

**Newbie99** - *20:12:02*

[@U4H19D1D2](@U4H19D1D2) is there a tidy way to get current (executable) orders placed on a different host (with Flumine), presumably via middleware?



For example, I've placed orders with Flumine on my local machine and I'm moving this strategy onto AWS, but I want to pick up the existing live orders when I re-start the strategy on AWS.



I've been playing around, adapting your middleware example, trying to pull in ALL order types, but there's a step I'm missing, as it doesn't pick up the orders from the other host:



```order = self._create_order_from_current(current_order, market)

            if order:

                order.update_current_order(current_order)

                if current_order.status == "EXECUTION_COMPLETE":

                    order.execution_complete()

                else:

                    if order.bet_id not in market.blotter:

                        order.executable()```

*Tags: Deployment, Strategies*

---

**liam** - *20:14:57*

This is the filter stopping it [https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/examples/middleware/orders.py#L23|https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/examples/middleware/orders.py#L23](https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/examples/middleware/orders.py#L23|https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/examples/middleware/orders.py#L23)

*Tags: General Technical*

---

**liam** - *20:19:20*

You tried just using some bflw code to confirm the orders are returned? No reason that code wouldn’t work unless it’s greater then 1k

*Tags: General Technical*

---

## 2021-06-16

**Newbie99** - *09:44:34*

[@U4H19D1D2](@U4H19D1D2) it wasn't the 1000 orders (but have built a function to handle that now, based your BFLW example), but I added this line (under line 26 in your example) and it appears to work (have tried locally and on AWS and it seems to pick up orders placed on either and importantly not duplicate, which seemed to be happening previously, it appeared the middleware and flumine were both adding the orders placed via the current host without the line below):



```if current_order.customer_strategy_ref != config.hostname or current_order.status != 'EXECUTABLE':```

*Tags: Deployment, Strategies*

---

## 2021-06-22

**Betbot Coder** - *14:15:06*

Hi all! First off big thanks to Liam and all for writing and maintaining these functions, very much appreciated! So issue at the moment is, I'm trying to run the trading.historic.get_file_list function but getting a JSONDecodeError: Expecting value: line 2 column 1 (char 1). It has previously worked fine but I haven't run it for a few weeks and now it's just not working, and I can't see why from the documentation. I found [https://github.com/liampauling/betfair/issues/144|this page](https://github.com/liampauling/betfair/issues/144|this page) with comment from Liam saying it's when Betfair is playing up - is that still the case or am I doing something wrong on my code?

*Tags: Errors Debugging, Strategies*

---

**Betbot Coder** - *14:22:17*

InvalidResponse: Invalid response received:

[!DOCTYPE html](!DOCTYPE html)

&lt;html&gt;

&lt;head&gt;

&lt;meta name="viewport" content="width=device-width" /&gt;

&lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

&lt;div&gt;

Error

&lt;/div&gt;

&lt;script defer src="[https://static.cloudflareinsights.com/beacon.min.js](https://static.cloudflareinsights.com/beacon.min.js)" data-cf-beacon='{"rayId":"ASDASD","token":"XXX","version":"2021.5.2","si":10}'&gt;&lt;/script&gt;

&lt;/body&gt;

&lt;/html&gt;

*Tags: Errors Debugging*

---

**Mo** - *14:25:40*

It's _probably_ just the historic endpoint being flaky but the error messages are so cryptic you might also be using incorrect arguments

*Tags: Errors Debugging*

---

**Betbot Coder** - *14:28:00*

if anyone else has same or similar problem please let me know!

*Tags: General Technical*

---

**Betbot Coder** - *14:52:58*

[https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py|this example code](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py|this example code) from Liam appears to also generate same error so unless it's my login credentials, I guess yes it must be the API. Let me know if anyone else having same issue, ta

*Tags: Errors Debugging*

---

## 2021-06-23

**Newbie99** - *09:29:51*

[@U4H19D1D2](@U4H19D1D2) I've noticed something else about the Replace function (I'm guessing most people just cancel and place a new order, which perhaps I should do!), below the replace fails as the bet has already had an action on it, that error makes sense, however after this the order is never removed from the blotter and the status remains as OrderStatus.REPLACING until I kill the process. This of course means no further orders can be placed on this runner as the blotter thinks there is 1 order remaining. This is obviously a pretty rare occurrence, but I've noticed it a few times and I think the below shows the process flow, but at the end presumably a better outcome would be that the order is removed (i.e. set to EXECUTION_COMPLETE) instead?



This is going to be very tricky to replicate, but if you agree its a bug I'll raise an issue (this is in live btw not simulation).



```{"asctime": "2021-06-22 18:50:10,695", "levelname": "INFO", "message": "execute_replace", "trading_function": "replace", "elapsed_time": 0.05340576171875, "response": {"customerRef": "abcf9b20d38a11ebbbac02054918c7c6", "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.183248116", "instructionReports": [{"status": "FAILURE", "errorCode": "BET_TAKEN_OR_LAPSED", "cancelInstructionReport": {"status": "FAILURE", "errorCode": "BET_TAKEN_OR_LAPSED", "instruction": {"betId": "236404314713"}}, "placeInstructionReport": {"status": "FAILURE", "errorCode": "RELATED_ACTION_FAILED"}}]}, "order_package": {"id": "abcf9b20-d38a-11eb-bbac-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f148822e790&gt;", "market_id": "1.183248116", "orders": ["236404314713"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}

{"asctime": "2021-06-22 18:50:10,701", "levelname": "INFO", "message": "Trade status update: Pending", "id": "511443a4-d388-11eb-bbac-02054918c7c6", "strategy": "politics_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["236404314713"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Pending", "status_log": "Pending, Live, Pending, Live, Pending, Live, Pending"}

{"asctime": "2021-06-22 18:50:10,707", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.183248116", "selection_id": 5191378, "handicap": 0.0, "id": "236404314713", "customer_order_ref": "3203239236f2d-236404314713", "bet_id": "236404314713", "date_time_created": "2021-06-22 18:33:19.422805", "publish_time": null, "trade": {"id": "511443a4-d388-11eb-bbac-02054918c7c6", "strategy": "politics_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["236404314713"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Pending", "status_log": "Pending, Live, Pending, Live, Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 1000.0, "size": 0.09, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.09, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Executable", "status_log": "Executable, Replacing, Executable, Replacing, Executable, Replacing, Executable, Replacing, Executable", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}

{"asctime": "2021-06-22 18:50:10,718", "levelname": "INFO", "message": "Order status update: Replacing", "market_id": "1.183248116", "selection_id": 5191378, "handicap": 0.0, "id": "236404314713", "customer_order_ref": "3203239236f2d-236404314713", "bet_id": "236404314713", "date_time_created": "2021-06-22 18:33:19.422805", "publish_time": null, "trade": {"id": "511443a4-d388-11eb-bbac-02054918c7c6", "strategy": "politics_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["236404314713"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Pending", "status_log": "Pending, Live, Pending, Live, Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 1000.0, "size": 0.09, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.09, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Replacing", "status_log": "Executable, Replacing, Executable, Replacing, Executable, Replacing, Executable, Replacing, Executable, Replacing", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}

{"asctime": "2021-06-22 18:50:10,718", "levelname": "INFO", "message": "Trade status update: Live", "id": "511443a4-d388-11eb-bbac-02054918c7c6", "strategy": "politics_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["236404314713"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": "Pending, Live, Pending, Live, Pending, Live, Pending, Live"}

{"asctime": "2021-06-22 18:50:10,719", "levelname": "INFO", "message": "Thread pool submit", "trading_function": "execute_replace", "session": "&lt;requests.sessions.Session object at 0x7f144b600050&gt;", "latency": 0.0001, "order_package": {"id": "abdbd200-d38a-11eb-bbac-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f148822e790&gt;", "market_id": "1.183248116", "orders": ["236404314713"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}, "thread_pool": {"num_threads": 32, "work_queue_size": 1}}

{"asctime": "2021-06-22 18:50:10,719", "levelname": "CRITICAL", "message": "Execution unknown error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/execution/betfairexecution.py\", line 243, in _execution_helper\n    response = trading_function(order_package, http_session)\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/execution/betfairexecution.py\", line 214, in replace\n    instructions=order_package.replace_instructions,\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/orderpackage.py\", line 152, in replace_instructions\n    return [order.create_replace_instruction() for order in self]\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/orderpackage.py\", line 152, in &lt;listcomp&gt;\n    return [order.create_replace_instruction() for order in self]\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/order.py\", line 394, in create_replace_instruction\n    bet_id=self.bet_id, new_price=self.update_data[\"new_price\"]\nKeyError: 'new_price'", "trading_function": "replace", "exception": "'new_price'", "order_package": {"id": "abdbd200-d38a-11eb-bbac-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f148822e790&gt;", "market_id": "1.183248116", "orders": ["236404314713"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}

{"asctime": "2021-06-22 18:50:10,719", "levelname": "INFO", "message": "1 order packages executed in transaction", "market_id": "1.183248116", "order_packages": [{"id": "abdbd200-d38a-11eb-bbac-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f148822e790&gt;", "market_id": "1.183248116", "orders": ["236404314713"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}], "transaction_id": 10}

{"asctime": "2021-06-22 18:50:10,722", "levelname": "INFO", "message": "Deleting requests.Session", "sessions_created": 14, "session": "&lt;requests.sessions.Session object at 0x7f144b600050&gt;", "session_time_created": 1624387784.7466655, "session_time_returned": 1624387810.701893, "live_sessions_count": 0, "err": true}```



*Tags: Errors Debugging, Performance, Deployment, Strategies*

---

**liam** - *09:58:27*

I think there might be an issue already? If you can create a strategy to replicate would be helpful 

*Tags: Strategies*

---

**Newbie99** - *10:44:39*

I tried replicating, with the replacement price lower than the best back price, but that produces a 'BET_LAPSED_PRICE_IMPROVEMENT_TOO_LARGE' and it works fine, the above is slightly different, in that its a BET_TAKEN_OR_LAPSED error I need to replicate, which is tough! I'll create a placeholder issue and will add if I can come up with more/better info.

*Tags: Errors Debugging*

---

**Newbie99** - *10:48:44*

[https://github.com/liampauling/flumine/issues/455#issue-928070153](https://github.com/liampauling/flumine/issues/455#issue-928070153)



Will update once I've been able to replicate.

*Tags: General Technical*

---

## 2021-06-26

**Peter** - *07:32:31*

That said, 2 is very restrictive. I'd recommend dropping a note to [mailto:bdp@betfair.com|bdp@betfair.com](mailto:bdp@betfair.com|bdp@betfair.com), explaining that you're using BFLW with separate connections for markets and orders, and ask that they increase the number of connections that you can have.

*Tags: General Technical*

---

**Mo** - *07:38:51*

Maybe [@UUUAJQZ5J](@UUUAJQZ5J) can help

*Tags: General Technical*

---

**Peter** - *09:20:38*

An excellent question [@UQL0QDEKA](@UQL0QDEKA)! If it's pre-planned, you can fire a termination event from within the code, but if you're already running continuously and want to stop to tweak strategies, I don't know how you'd get the event in there. I wonder if [@U4H19D1D2](@U4H19D1D2) has any advice on this ...

*Tags: General Technical*

---

## 2021-06-27

**Ewan** - *13:27:01*

The AUS team are awesome, very helpful.

About ten years ago I tried a strategy on a delayed app key thinking it was mere seconds but it can be 30-90 seconds so what could have been a profitable strategy got shelved :cry:

*Tags: Strategies*

---

## 2021-06-28

**Adrian** - *07:20:10*

```order_type=LimitOrder(lay, self.context[\"stake\"]),\nKeyError: 'stake'"}```

I get this error when running lowest layer. Is "stake" supposed to be declared somewhere in the strategy?

*Tags: Errors Debugging, Strategies*

---

**liam** - *07:24:57*

Yes, in the context as per the example  [https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/examples/backtest.py#L28|https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/examples/backtest.py#L28](https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/examples/backtest.py#L28|https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/examples/backtest.py#L28)

*Tags: General Technical*

---

**liam** - *09:26:21*

[https://github.com/liampauling/betfair/blob/060f0fd2e8c4a975bac7a972941d54995a18e0fc/betfairlightweight/resources/bettingresources.py#L339](https://github.com/liampauling/betfair/blob/060f0fd2e8c4a975bac7a972941d54995a18e0fc/betfairlightweight/resources/bettingresources.py#L339)

*Tags: Strategies*

---

**liam** - *09:26:58*

ie `runner.sp.actual_sp` quick look at the resource using the debugger would tell you straight away

*Tags: Errors Debugging*

---

**liam** - *09:27:44*

:joy:  debugger is your friend!

*Tags: Errors Debugging*

---

## 2021-06-30

**Matthieu Labour** - *03:26:13*

Should the event_ids list be passed directly to get_scores? No need for the for loop I believe. [https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py#L16](https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py#L16)

*Tags: General Technical*

---

## 2021-07-02

**Rob (NZ)** - *05:24:38*

Just using the example.py  Flumine code  , updated it with my account and API key etc, I then just changed the amount from $2 to $10 (the $2 didnt seem to work)  but then it started loading multiple positions into the market...   im just using juypter notebook to start with ...   is that by design and I should code in some logic to do it only once?

*Tags: General Technical*

---

**Rob (NZ)** - *05:24:47*

sorry for the newbie question just trying to get my head around it

*Tags: General Technical*

---

## 2021-07-03

**Adrian** - *10:42:20*

Could someone tell me where would be the appropriate place to insert a resource intensive algo into flumine? I tried placing it in process_market_book but that led to this error: "WARNING", "message": "High latency between current time and MarketBook publish time". Thanks!

*Tags: Errors Debugging, Performance*

---

**Adrian** - *23:22:08*

[@U01DVUAE2G1](@U01DVUAE2G1) no i'm on the live key now.

[@UBS7QANF3](@UBS7QANF3) yeah that's what originally thought to do but i wanted to do it right

[@U4H19D1D2](@U4H19D1D2) are there any workers i can repurpose in bflw/flumine?

*Tags: Deployment*

---

**Adrian** - *23:27:56*

i found this. is it possible to call them manually rather than every x seconds?

[https://github.com/liampauling/flumine/blob/4924616d3764ab5ea861a21a72054dc93d812d61/docs/workers.md](https://github.com/liampauling/flumine/blob/4924616d3764ab5ea861a21a72054dc93d812d61/docs/workers.md)

*Tags: General Technical*

---

## 2021-07-07

**Mons___das** - *16:56:07*

Hey guys! I m rather new to flumine and am trying to wrap my head around everything. Amazing stuff from what i can see, big thanks to [@U4H19D1D2](@U4H19D1D2)

I am currently trying to build up a database with that i can do backtests and filter markets (for the backtest), and down the road maybe also track the orders i have placed per strategy. First step i wanted to get an idea of the general structure of how all of this is going to look like. I see flumine comes with a market_recorder (and an s3recorder on top) and a backtest function, so basically all i need is being provided, i just have to connect the puzzles pieces :smile: The s3recorder seems to throw out some zip files (1 per market), which i am supposed to store in a s3bucket. Are these the files i am supposed to feed into the backtest machinery? Assuming thats how its done, i need to know which files i throw into the backtest for a certain strategy, so i need a way to filter these markets. I was thinking that this one be one job of a database, which for example has basic information for each market_id, like what event_type it is, time of the event, runners, etcetc. How would i go about building such db? Can the market recorder also be used for this? or would i extract this info straight from the files in the s3 bucket?

*Tags: Getting Started, Data Quality, Strategies*

---

**Peter** - *17:24:41*

The market recorder script provides you with two files per market. A stream file which shows how offered prices, traded prices and matched volumes evolved over the life of the market and a market catalogue which has the meta information that you'd need to decide which markets to feed into your back testing.

*Tags: Data Quality*

---

**Peter** - *17:25:37*

You could of course import that catalogue data into a database if that's how you roll.

*Tags: General Technical*

---

**Mons___das** - *17:35:05*

I wasnt planning on recording every single market, but for example if i wanted horses, football and greyhounds, i would want to be able to choose which ones of those i put into my backtest? I also may want to filter between countries, leagues, or other things i may find important later on. Maybe that already very efficently doable without a db and i m overseeing something though, i m not very experienced with neither flumine or databases :smile:

*Tags: General Technical*

---

**liam** - *17:36:30*

So you would only pass into flumine what you want to backtest, have a look at the examples however you can filter market type 

*Tags: General Technical*

---

**Mons___das** - *17:38:30*

so i see the standard way would be no database but only a s3 bucket?

Yes i ve heared bets need to be placed, i will do so. Cant hurt to dip into the real thing anyway :smile:

*Tags: General Technical*

---

## 2021-07-08

**Jonjonjon** - *08:40:07*

I'm trying to debug my local version of the marketrecorder.

For 1.184990419, I only have 1 row of data. For other files, I usually get a zip file when they close. Do other uses running that script have more than 1 line for that market?

*Tags: Errors Debugging*

---

**Jonjonjon** - *08:44:21*

I'm trying to work out how to assess whether or not there's a bug in my code, or whether I genuinely only received a single update for that market.

*Tags: Errors Debugging*

---

**Matthieu Labour** - *14:47:47*

Hi, [https://github.com/liampauling/flumine/blob/master/flumine/utils.py#L50](https://github.com/liampauling/flumine/blob/master/flumine/utils.py#L50). Could we test for the case where `mc` does not exist and `marketDefinition` does not exist so that we ignore the line as opposed to throw an exception? Happy to contribute a PR if you are ok with the change.

*Tags: Errors Debugging*

---

**Matthieu Labour** - *14:52:36*

In my use case, i record inplay scores and market book data to the same market file to preserve the sequencing. Sure I could preprocess the file before re-playing them into flumine. But i was hoping flumine could ignore the lines it does not expect and can’t process.

*Tags: General Technical*

---

**Matthieu Labour** - *18:10:20*

Done. [https://github.com/liampauling/flumine/pull/462](https://github.com/liampauling/flumine/pull/462)

*Tags: General Technical*

---

## 2021-07-09

**D C** - *16:29:42*

Can't you use the market type filter? I don't use BFLW but the API itself allows you to filter by market types (win/place etc)

*Tags: General Technical*

---

## 2021-07-10

**Adrian** - *09:41:45*

In Flumine, is there any way of checking that a market no longer exists? It seems that once the market is closed and or removed from the market book that it won't be checked in `check_market_book` , so how does one refer to such a market. Or is there a better way to do it before the market disappears? Thanks

*Tags: General Technical*

---

**liam** - *09:49:36*

Currently no, check out the logic [https://github.com/liampauling/flumine/blob/4da58825ae529ddde2b3bfee2a434b20ed41ec3c/flumine/baseflumine.py#L144|here](https://github.com/liampauling/flumine/blob/4da58825ae529ddde2b3bfee2a434b20ed41ec3c/flumine/baseflumine.py#L144|here) 

*Tags: General Technical*

---

## 2021-07-11

**Mons___das** - *17:17:55*

I suspected that could be the case and opened the a few of the smallest files and they all looked like streaming updates to me with many updates and changing prices. A market catalogues should only hold one big json i think?

*Tags: General Technical*

---

**liam** - *17:27:54*

Are you looking in the catalogue key? [https://github.com/liampauling/flumine/blob/4da58825ae529ddde2b3bfee2a434b20ed41ec3c/examples/strategies/marketrecorder.py#L260|https://github.com/liampauling/flumine/blob/4da58825ae529ddde2b3bfee2a434b20ed41ec3c/examples/strategies/marketrecorder.py#L260](https://github.com/liampauling/flumine/blob/4da58825ae529ddde2b3bfee2a434b20ed41ec3c/examples/strategies/marketrecorder.py#L260|https://github.com/liampauling/flumine/blob/4da58825ae529ddde2b3bfee2a434b20ed41ec3c/examples/strategies/marketrecorder.py#L260)

*Tags: General Technical*

---

**liam** - *17:28:52*

All assuming you have passed True for the catalogue [https://github.com/liampauling/flumine/blob/4da58825ae529ddde2b3bfee2a434b20ed41ec3c/examples/strategies/marketrecorder.py#L40|context](https://github.com/liampauling/flumine/blob/4da58825ae529ddde2b3bfee2a434b20ed41ec3c/examples/strategies/marketrecorder.py#L40|context) 

*Tags: General Technical*

---

**Mons___das** - *18:07:04*

[@U4H19D1D2](@U4H19D1D2) oh jesus i m not thr brightest light out there :smile: I clicked in the streaming folder and never clicked out again. Respect to you for diagnosing such stupid mistake correctly :smile:

*Tags: General Technical*

---

## 2021-07-13

**Andy B** - *08:55:17*

I'm pretty sure I am just overlooking it, but does betfairlightweight have a method that returns the event start time, not the market open time?  Trying to work out how I can grab this without having to scrape it and I would be surprised if it wasn't an API value.  I have looked at the API doco, but if it is there, it didn't stand out to me.

*Tags: General Technical*

---

## 2021-07-15

**Unknown** - *12:26:23*

Hi everyone, may I ask a question here ? Following the git advice, I am setting up the account. It comes this error.

*Tags: Errors Debugging*

---

**Hamish Z** - *12:27:14*

May I know how to solve this problem? thanks

*Tags: General Technical*

---

**Mo** - *12:40:13*

Sorry I am not a Windows user so can’t help you with the specifics of the generation but the error message definitely suggests this is the problem. Hopefully someone else who has successfully generated certificates on Windows can help you further 

*Tags: Errors Debugging*

---

## 2021-07-16

**Hamish Z** - *10:37:09*

hi , the problem is solved now. Just in case someone have similar situation with XCA, the solution is updated here.

*Tags: General Technical*

---

**Jono** - *16:24:50*

im receiving an odd error when trying to place a LAY bet on an upcoming football game on the standard "MATCH_ODDS" market regarding its persistence type. Im getting this error: " 'errorCode': 'INVALID_PERSISTENCE_TYPE' " which is strange because im passing exactly this string "PERSIST" as the persistence parameter.  additionally the same code has successfully placed bets with this persistence type many times previously both today and the past few weeks. Any idea why this might be causing problems now?

*Tags: Errors Debugging*

---

## 2021-07-20

**Luka** - *11:21:19*

Hi there, just joined the Slack channel - but having been using betfairlight for some time now. I m having some good success with the bot that I have built, but my bets are only getting placed every now and then. I have just found out about `order.status` which is very helpful, as I previously had no visibility there.



I am getting a response of FAILURE on some of the bets that I am placing. I have double checked that the `market_id` is correct by checking the website for that market. I am not sure how to double check that the `selection_id` is correct though.



Does anyone else have any tips for debugging this FAILURE and figuring out why it is happening? The strange thing is that some of my bets are being placed, so the script definitely works some of the time.

*Tags: Errors Debugging*

---

**Jonjonjon** - *11:22:59*

Is there more error information order than FAILURE?

*Tags: Errors Debugging*

---

**Luka** - *13:44:43*

[@UPMUFSGCR](@UPMUFSGCR) Would this be related to the amount of money in the account? The bets I am placing are calculated as a percentage of my bankroll so they are not close in size to my account funding.

*Tags: General Technical*

---

**Jonjonjon** - *14:09:49*

It could be account related, or could be a Flumine constraint. When the system logs the failure, is there more detailed information available?

*Tags: General Technical*

---

**Jonjonjon** - *14:12:14*

Look at this for rounding to nearest price:



[https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/utils.py#L93-L103](https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/utils.py#L93-L103)

*Tags: General Technical*

---

**Luka** - *14:13:43*

So I am using `betfairlight` I still haven't quite understood how that interacts with `Flumine`

*Tags: General Technical*

---

**Luka** - *14:16:46*

[@UBS7QANF3](@UBS7QANF3) I have tried rounding the `price` to a single decimal place but this hasn't seemed to helped.

*Tags: General Technical*

---

**Luka** - *14:18:41*

[@UPMUFSGCR](@UPMUFSGCR) I am running it on AWS so the errors I am getting are just those things I create print statements for. I have a version of the code that I can run locally, which may help me with debugging

*Tags: Errors Debugging, Deployment*

---

**Jonjonjon** - *14:55:09*

Please install flumine, and then use the get_nearest_price function mentioned above.

*Tags: Getting Started*

---

**Hamish Z** - *22:28:29*

I think I followed the XCA page exactly, no need to alter.If not successful, also try OpenSSL using command line from windows. Hope this help.

*Tags: General Technical*

---

**Adrian** - *23:02:41*

Good morning. Could someone please enlighten me to what this message means?

&gt; "WARNING", "message": "Strategy not available to create order

it is often accompanied by this message:

&gt; "WARNING", "message": "Order .... not present in blotter"

It doesn't seem to be impacting my bots but just thought I'd ask incase it is is having some effect that I don't know about.

*Tags: Strategies*

---

## 2021-07-21

**Peter** - *03:15:55*

betfairlightweight is a thin wrapper around the Betfair API,  If you give it invalid prices or sizes it will simply pass them to Betfair which will reject the transaction if either is invalid.  There is no magical adjustment or correction.



I wouldn't recommend simply using the last traded price as a substitute, that will pick up va;ues on either side of the spread and may not correspond to what your startegy needs. Better would be to familiarise yourself with the parts of the Betfair documentation that explain what prices and sizes are valid where you are (prices are universal, but valid sizes can vary depending on your country).



I agree with [@UPMUFSGCR](@UPMUFSGCR) that moving onto Flumine is a naturally progression, though it can take some time to get your head around it. But the responsibility for ensuring that you are using legitimate prices and sizes will still rest with your code.

*Tags: General Technical*

---

**Aaron Smith** - *08:26:47*

[@U01S1VB9X9P](@U01S1VB9X9P) if the order is not present in the blotter, flumine tries to manually add the order to the blotter. For this, it needs to grab the strategy that placed this order (using the strategy_hash that is saved within the order)

*Tags: Strategies*

---

**Aaron Smith** - *08:27:20*

If it cant find that strategy, the 2nd warning is printed

*Tags: Strategies*

---

**Aaron Smith** - *08:27:56*

Do you have multiple instances of flumine running with 2 strategies from diffrent instances placing orders on the same market?

*Tags: General Technical*

---

**Adrian** - *08:54:35*

[@U01DVUAE2G1](@U01DVUAE2G1) yes i have 4 flumine instances, 2 with 2 strategies and 2 with one strategy. I'm not versed in how the blotter works. Maybe I have too much going at once? I'm also hitting 10 connection limit if there are too many dropouts

*Tags: Strategies*

---

**Adrian** - *08:59:24*

One each for market recorder - horses and greyhounds. One each for the strategies ofthose markets

*Tags: Data Quality*

---

**Adrian** - *09:02:01*

hmm the dropout error is too big

*Tags: Errors Debugging*

---

**Adrian** - *09:02:52*

&gt; \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/betting/json-rpc/v1 (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x7fc7002636a0&gt;: Failed to establish a new connection: [Errno 65] No route to host'))"}

*Tags: Errors Debugging, Strategies*

---

**liam** - *09:03:06*

looked like an error in the worker, thats handled

*Tags: Errors Debugging*

---

**liam** - *09:05:23*

Can you message me the full error?

*Tags: Errors Debugging*

---

**Adrian** - *09:13:52*

yes thanks, i've done that for the market recorders. i might just have to work at reducing everything down to 2 flumines and/or get uk server as suggested

*Tags: Data Quality, Deployment*

---

**liam** - *10:32:32*

Happy to look into this if an issue is created / strategy to replicate etc.

*Tags: Strategies*

---

## 2021-07-22

**Adrian** - *06:03:48*

ok got everythin down to just 2 flumine instances. one for market recorder one for strategies. alas, i am somehow ending up with 13 active connections and cannot reconnect. unless there is some way i can kill those old connections, there's literally nothing else I can do except get hosting in the UK

*Tags: Data Quality*

---

**liam** - *07:48:48*

If you can share more on the error / something, might be able to debug the issue but it seems like it’s your network 

*Tags: Errors Debugging*

---

## 2021-07-23

**Mo** - *08:04:50*

Shouldn't the type hint of this function be `Generator[List[dict]], None, None]`? [https://github.com/liampauling/betfair/blob/6991a6a51363bae5fe5940f647b5cf7a4e7113cb/betfairlightweight/streaming/betfairstream.py#L343](https://github.com/liampauling/betfair/blob/6991a6a51363bae5fe5940f647b5cf7a4e7113cb/betfairlightweight/streaming/betfairstream.py#L343)

*Tags: General Technical*

---

**Oliver Varney** - *08:16:11*

Union[Generator[List[dict]], None],None] ? Edit: actually maybe not as I guess the file opening is not handled and would just throw an error technically.

*Tags: Errors Debugging*

---

**Oliver Varney** - *08:25:59*

[https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose](https://stackoverflow.com/questions/19302530/python-generator-send-function-purpose)

*Tags: General Technical*

---

**liam** - *08:27:00*

the type hinting in bflw is a half arsed job tbh, needs to be cleaned up with mypy, I just cba

*Tags: General Technical*

---

## 2021-07-24

**Adrian** - *05:44:54*

What's the best way to run code asynchronously with Flumine? I have some blocking code that I cannot reduce anymore.

*Tags: General Technical*

---

**Adrian** - *05:46:34*

I've toyed with asyncio but i think that will screw up the flumine threads

*Tags: General Technical*

---

**Mo** - *08:17:04*

Do you currently use ZMQ? Do you use a Python package for it?

*Tags: General Technical*

---

**river_shah** - *09:08:45*

Try this: [https://zeromq.org/languages/python/|https://zeromq.org/languages/python/](https://zeromq.org/languages/python/|https://zeromq.org/languages/python/)

*Tags: General Technical*

---

**river_shah** - *09:09:20*

The author has moved on to nanomsg but that is for more ultra low latency stuff. 

*Tags: Performance*

---

**Mo** - *22:10:24*

Yeah it would be for performance reasons 

*Tags: Performance*

---

**azevedo** - *22:19:45*

[@UBS7QANF3](@UBS7QANF3) you won’t recommend using redis pub/sub for redistributing Betfair streaming messages to multiple processes? I assumed that’s what you had set up?



does redis streaming have better performance vs pub/sub for that sort of thing? [@ULDAVFDRP](@ULDAVFDRP) 

*Tags: Performance*

---

## 2021-07-25

**Adrian** - *01:53:49*

I managed to offload all the blocking code into a separate process all together. Slight loss of functionality but now Flumine is free to operate without obstacles

*Tags: General Technical*

---

**Oliver Varney** - *07:22:27*

I think it was billed as an alternative / replacement with more functionality. A stream is a different datastructure (has memory / storage) but communication functionality similar to pub/sub can be achieved easily.  Its sub milliseconds read from anywhere off the stream. Im not too sure of the scale of your sub/pub and whether that would have any effect performance as my use case I guess isnt that complex. Typically I use it for IPC communication. Its real strength is saving timestamped data such as analytics which can be retrieved between ranges in sub millisecond using timestamps.

*Tags: Performance*

---

**Mo** - *08:54:31*

In production I’ve measured an overhead of 300 microseconds between the publisher and subscriber. I’m purely thinking in terms of reducing that number 

*Tags: Deployment*

---

**Mo** - *09:05:59*

If you care about latency then that number is huge. If you don’t care about latency then :man-shrugging:

*Tags: Performance*

---

**Mo** - *09:13:55*

You seem to be talking about throughput rather than latency?

*Tags: Performance*

---

**azevedo** - *10:06:19*

[@UBS7QANF3](@UBS7QANF3) in your experience, do you see much competition for those sort of sub millisecond latencies? as in do you think you would make more money should you drop this latency from 300microseconds to say 30 microseconds?

*Tags: Performance*

---

## 2021-07-29

**Adrian** - *04:07:25*

Anyone know how I can check the market name? I put `market_data_filter = streaming_market_data_filter(`

        `fields=["EX_MARKET_DEF", "EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP"]`

    `)`

and tried to fetch it with

`market_book.market_definition.event_name`

but I am getting None error. What is the correct command to get the market name?

*Tags: Errors Debugging*

---

**Adrian** - *10:02:12*

[@UBS7QANF3](@UBS7QANF3) i am getting this error:

``` if \"Pace\" in market.market_catalogue.market_name:\nAttributeError: 'NoneType' object has no attribute 'market_name'"}```

*Tags: Errors Debugging*

---

## 2021-07-30

**Adrian** - *07:55:09*

Has anyone had issues getting two bets on horses on one pass of flumine? I can do it on greyhounds and other horses without a problem, i.e. back &amp; lay at the same time. But for some reason with some races it only like one at a time

*Tags: General Technical*

---

**liam** - *08:04:50*

? the logs will tell you the problem

*Tags: General Technical*

---

**Adrian** - *08:55:58*

ahhh that's probably the reason. i've seen those kind of markets before. i dont know how to check

*Tags: General Technical*

---

**liam** - *08:58:22*

marketCatalogue or in the [https://github.com/liampauling/betfair/blob/6991a6a51363bae5fe5940f647b5cf7a4e7113cb/betfairlightweight/resources/streamingresources.py#L131|marketDefinition](https://github.com/liampauling/betfair/blob/6991a6a51363bae5fe5940f647b5cf7a4e7113cb/betfairlightweight/resources/streamingresources.py#L131|marketDefinition)

*Tags: General Technical*

---

**Adrian** - *09:15:02*

in future, instead of asking silly questions, how do I find where a function lies in the flumine ecosystem? E.g. you share the bspMarket boolean, which is obviously in market_definition, but beyond that I have trouble tracing back where it lives

*Tags: Deployment*

---

**Andy B** - *09:17:24*

I had the same thing a couple of days ago.  Some markets don't have place betting and throw this same error when you try.  Is it possible that you tried to place a bet type that doesn't exist?

*Tags: Errors Debugging, Strategies*

---

**Peter** - *09:40:06*

It's a balance between searching in your editor / IDE and understanding the structure of the code so knowing where to look. As you work more with the code, you move progressively from the former to the latter. A good place to start to understand all the data available are the classes in BFLW's bettingresources.py script.

*Tags: Strategies*

---

**liam** - *13:05:12*

yeah use a proper IDE for strategy / dev and jupyter for modelling / data analysis

*Tags: Strategies*

---

**Adrian** - *13:06:17*

ok that's about 80% of my questions solved then :joy:

*Tags: General Technical*

---

**Adrian** - *13:16:29*

actually I didn't realise it could autocomplete bflw/flumine which is why i ignored it. I thought it was just generic autocomplete

*Tags: General Technical*

---

**James McKenzie** - *16:15:17*

getting:



```betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders 

Params: {'betStatus': 'SETTLED', 'eventTypeIds': ['7'], 'settledDateRange': {'from': '2021-07-30T15:00:17.112414', 'to': '2021-05-01T15:00:17.112415'}} 

Exception: None 

Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang29b-prd-05120754-009afb31a1', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang29b-prd-05120754-009afb31a1', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}```

*Tags: Errors Debugging*

---

**Dirk** - *16:24:16*

Hey guys. A couple of days ago I tried to login to the API for the first time. I am using Python on windows and used XCA to make the certificates. At the moment of logging in, using the following code, I get an error:



`trading = betfairlightweight.APIClient(username=my_username,`

                                          `password=my_password,`

                                          `app_key=my_app_key,`

                                          `certs=certs_path)`

`trading.login()`



The error I get is (this is only the last part of the error code, it is way bigger than this):

`APIError: None` 

`Params: None` 

`Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4022)')))`



I've heard from others that it might have to do with the certificates, but I redid the full process like it is prescribed on the manual. Is there anyone with any tips/followup questions?

*Tags: Getting Started, Errors Debugging, Strategies*

---

**Dirk** - *16:33:36*

I'm using this tutorial: [https://betfair-datascientists.github.io/api/apiPythontutorial/](https://betfair-datascientists.github.io/api/apiPythontutorial/)

*Tags: General Technical*

---

**Dirk** - *17:05:00*

Yes I saw that and asked some people but either they also still had the error or they didn't use windows

*Tags: Errors Debugging*

---

**Dirk** - *17:06:10*

I was trying to google and saw someone that got the exact same error in 2019 but no one replied to it

*Tags: Errors Debugging*

---

**Dirk** - *17:20:48*

It doesn't return anything, but also no error. Is there a way to check if it works?

*Tags: Errors Debugging*

---

## 2021-07-31

**Jonjonjon** - *09:04:44*

There might be a variable along the lines of strategy_selection_orders in the blotter, which could be faster than looping over all orders.

*Tags: Strategies*

---

**Jonjonjon** - *09:08:44*

[https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/markets/blotter.py#L47|https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/markets/blotter.py#L47](https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/markets/blotter.py#L47|https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/markets/blotter.py#L47)

*Tags: General Technical*

---

## 2021-08-01

**Jonjonjon** - *09:33:50*

To get your coding-fu up to scratch, you could look through the flumine source code on GitHub. That will give you the answer to your question above. The link above will take you to the module of interest.

*Tags: General Technical*

---

**Jonjonjon** - *09:41:01*

[https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/order/order.py#L35|https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/order/order.py#L35](https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/order/order.py#L35|https://github.com/liampauling/flumine/blob/a7aff28371b1a7a30122dfd76a1effcee4ddc127/flumine/order/order.py#L35)

*Tags: General Technical*

---

## 2021-08-02

**liam** - *08:04:07*

If you want it added to the `runner_context` create an issue on github and I can add it, never seen the value so there are currently no helper functions for it

*Tags: General Technical*

---

## 2021-08-03

**Mons___das** - *09:55:35*

Hey guys! I am trying to put the marketCatalogue you get from the MarketRecorder in a DB. For one column, i just want to dump the whole marketCatalogue json in. Somehow this doesnt work. For hounds, when overwriting the "rules" in the marketCatalogue, it then worked. Now for horses, it still doesnt work. I wondered if there is any special character in the marketCatalogue that could cause this problem?

*Tags: General Technical*

---

**liam** - *10:57:06*

that bottom line is the problem, don't think f strings work correctly try:



```cursor.execute(f"INSERT INTO {table} {columns} VALUES %s" % values)```

*Tags: General Technical*

---

**liam** - *11:01:40*

and what python library are you using to communicate with the db?

*Tags: General Technical*

---

**Mons___das** - *11:06:16*

i can use % all the way, thats no problem

*Tags: General Technical*

---

**Unknown** - *23:03:46*

Trying to get a file list of historic data and I keep getting the following error as well as JSON decode error. Is there any reason? I copied the code from the examples?

*Tags: Errors Debugging*

---

## 2021-08-06

**Adrian** - *12:36:35*

When I get this: ""You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s)", how does Flumine know how many connections I have?

*Tags: General Technical*

---

**thambie1** - *12:40:49*

Flumine may not, Betfair certainly does! This is an error that the Betfair API would return, and flumine would surface

*Tags: Errors Debugging*

---

**Mo** - *12:45:53*

The problem is your internet connection

*Tags: General Technical*

---

**Mo** - *12:49:12*

AWS, eu-west-1

*Tags: Deployment*

---

## 2021-08-09

**admiral** - *18:34:43*

Hi all, I'm trying to use historic data I've downloaded using the BASIC plan for soccer with FlumineBacktest and running into encoding errors, is this an issue other people have seen?

*Tags: Errors Debugging*

---

**Aaron Smith** - *18:54:08*

[@U02AEDQ2KB8](@U02AEDQ2KB8) not sure if this is what causes the error, but a BASIC plan seems insufficient for backtesting. You would need pro data to simulate a real market

*Tags: Errors Debugging*

---

**Aaron Smith** - *18:57:04*

If i recall correctly, basic data doesnt have volume information, which would be needed for a backtest, so that would surely thorw some errors

*Tags: Data Quality, Errors Debugging*

---

**liam** - *19:37:13*

Have you uncompressed the file or are you using something smart_open to read? But like Aaron has said the basic data is useless and you won’t be able to use all of flumines features 

*Tags: Data Quality, Feature Engineering*

---

## 2021-08-11

**liam** - *09:01:31*

Its the same as in `process_market_book` all orders are in the blotter which you can get from `market.blotter` a few helper functions in there as well so worth reading the [https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/markets/blotter.py#L43|code](https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/markets/blotter.py#L43|code)

*Tags: General Technical*

---

**birchy** - *13:49:02*

Ok, so let's say that someone (not me) was developing a semi-automatic strategy where they initiate trades manually and then have a Flumine/bflw strategy hedging their bets, would there be a way for them to also load the manually placed orders?

*Tags: Strategies*

---

**liam** - *14:06:26*

So flumine uses the machines hostname as a filter, this allows multiple flumine instances to run on the same markets without impacting each other. Tbh its not really setup for this so you better option would be some bflw code to hedge

*Tags: Getting Started*

---

**birchy** - *17:30:40*

Although I agree that gambling addiction is a problem for some, this is potentially damaging for us: "_Maximum stakes may also be imposed"_

*Tags: General Technical*

---

## 2021-08-14

**thambie1** - *14:26:56*

Does anyone know if there's a delay between transferring between wallets and having the money accessible to trade? I made a transfer almost an hour ago, yet still get INSUFFICIENT_FUNDS errors from the api when I go below the pre-transfer account value

*Tags: Errors Debugging*

---

## 2021-08-15

**AR** - *01:38:27*

Hi

I am trying to place my first set of bets through the API, using  BFLW, and am getting a failure response. The error code is:

placeBackBet(trading, market_id, selection_id, 5, min_odds)

Bet Place on selection 22511750 is FAILURE

```{'elapsed_time': 0.7760229110717773, '_datetime_created': datetime.datetime(2021, 8, 14, 22, 19, 1, 765910), '_datetime_updated': datetime.datetime(2021, 8, 14, 22, 19, 1, 765910), '_data': {'status': 'FAILURE', 'errorCode': 'BET_ACTION_ERROR', 'marketId': '1.186418033', 'instructionReports': [{'status': 'FAILURE', 'errorCode': 'INVALID_ODDS', 'instruction': {'selectionId': 22511750, 'limitOnCloseOrder': {}, 'orderType': 'LIMIT_ON_CLOSE', 'side': 'BACK'}}]}, 'market_id': '1.186418033', 'status': 'FAILURE', 'customer_ref': None, 'error_code': 'BET_ACTION_ERROR', 'place_instruction_reports': [&lt;betfairlightweight.resources.bettingresources.PlaceOrderInstructionReports object at 0x00000150A20C8DC0&gt;]}```

seems the error is INVALID_ODDS - however I have used code from the  github to do the rounding, and I can physically place bets on the

website using the price increments I have rounded to. Also, I can run this as a LIMIT order with no issues - so seems I am doing something wrong in specifying a Limit On Close. Does anyone have some example code of placing a LIMIT_ON_CLOSE order?

*Tags: Errors Debugging, Strategies*

---

**ThomasJ** - *04:55:41*

(I am running Flumine over Historical Data.)



Is the runner traded volume for live streaming different to historical data? I ask because this code `runner.total_matched = new_data["tv"]` in BFLW  `Class MarketBookCache &gt; def update_cache` seems to store only the traded volume at a single price (sometimes for more than 1 price) and not the accumulated volume for all price points.



In "Betfair Developer Program  Exchange API  Historical Data FAQ's - How is traded volume represented within the PRO Historical Data files?" ([https://support.developer.betfair.com/hc/en-us/articles/360002401937-How-is-traded-volume-represented-within-the-PRO-Historical-Data-files-|link](https://support.developer.betfair.com/hc/en-us/articles/360002401937-How-is-traded-volume-represented-within-the-PRO-Historical-Data-files-|link)) it explains that "The runner tv (“tv”) represents the cumulative traded amount at the last price traded (ltp) or cumulative amount of all ‘trd’ amounts in the update if multiple prices are included."



Anyway, regardless of the details of the calculation of `runner.total_matched`, at any point in time should not its value be equal to the sum of all volumes at all prices?



I am digging into this because in Flumine's `class RunnerAnalytics &gt; def _calculate_matched`, the code `return round(total_matched - prev_total_matched, 2)` seems to assume that `total_matched` is always increasing in value when it's not. Numerous times the returned value is a negative (and by large amounts as I recorded them) which is not possible in real life.

*Tags: Data Quality, Deployment*

---

**mandelbot** - *05:41:23*

Are you using BFLW to place bets or Flumine? You have to specify a liability and some maximum odds you want to be matched at for a LimitOnCloseOrder. Some sample code if placing a bet in BFLW



                     `limit_on_close_order = filters.limit_on_close_order(`

                            `liability=500, price=100)`

                     `instruction = filters.place_instruction(`

                            `order_type="LIMIT_ON_CLOSE",`

                            `selection_id=runner.selection_id,`

                            `side="LAY",`

                            `limit_on_close_order=limit_on_close_order,`

                        `)`

                     `place_orders = trading.betting.place_orders(`

                            `market_id=market_id, instructions=[instruction]  # list`

                        `)`

*Tags: Strategies*

---

**AR** - *05:42:38*

Awesome! Doing it in BFLW

*Tags: General Technical*

---

**liam** - *07:28:20*

Can you create a GitHub issue? Needs to be handled although why they decided to do this for historical data is infuriating 

*Tags: Data Quality*

---

**ThomasJ** - *08:32:37*

I will create a GitHub issue. I'm thinking that it might be best in Flumine issues as total_matched is most likely to be used in Flumine where it can be easily calculated only when it is required. Rather than wasting CPU cycles in BFLW. Perhaps just add a comment in BFLW at `runner.total_matched = new_data["tv"]`

So I presume when live streaming `new_data["tv"]` value is sum of volumes of all prices?

*Tags: Deployment*

---

**AR** - *10:43:34*

Thanks for your help, this solved the issue :)

*Tags: General Technical*

---

**liam** - *11:27:52*

It’s a bflw issue but changes might need to be added to flumine, I can look at this tomorrow 

*Tags: General Technical*

---

**ThomasJ** - *11:52:31*

Sorry, already added issue to Flumine.

But given the confusion caused by Betfair perhaps just ditch the recording of total_matched on every update in BFLW.

ie drop the the thing entirely - it's not used anywhere other than Flumine AFAIK. And if someone needs to know runner total traded then `sum([vol['size'] for vol in runner.ex.traded_volume])` suffices.

Anyway no need to reply just throwing my thoughts in.

*Tags: General Technical*

---

**liam** - *11:57:25*

This problem is due to the historical data only so certainly wouldn’t remove the field, just needs to be handled correctly, likely to add a flag to the listener `shitty_betfair_data=False`

*Tags: Data Quality*

---

## 2021-08-16

**liam** - *10:51:18*

[@U01U24AG35W](@U01U24AG35W) this is now fixed in the latest releases, depending on the data package used, bflw:

```listener = StreamListener(

    calculate_market_tv=True,

    cumulative_runner_tv=True,

)```

flumine:

```strategy = LowestLayer(

    market_filter={"markets": markets, "listener_kwargs": {"calculate_market_tv": True, "cumulative_runner_tv": True}},

)```

*Tags: Errors Debugging, Strategies*

---

**George** - *11:04:08*

I've started getting a lot of 'Connection reset by peer' errors this morning. I am using a script that logs in to the API at the start. Is it because I am failing to log-out when the script terminates? Or is it just a bad day at the BF servers

*Tags: Errors Debugging, Deployment*

---

**liam** - *14:36:19*

Spoken to Neil and seems to be a known issue due to a security release this morning, not sure on when it will be fixed but it seems to be random (I haven't had any issues)

*Tags: Errors Debugging*

---

**ShaunW** - *15:02:20*

I've had similar connection issues today (briefly in the early hours of the morning, ie 8am:slightly_smiling_face:) . but OK now. I mention it because I don't use bflw etc so that isn't where any issues lie although [@U4H19D1D2](@U4H19D1D2) probably knows that already.

*Tags: General Technical*

---

**Will** - *15:04:38*

Thanks Liam. Seems better now. It does raise the problem (my problem) of not having a timeout in place for `trading.login()` - curious to know what others do in these situations

*Tags: Strategies*

---

## 2021-08-17

**Jack** - *12:27:17*

Hi everyone, I hope that this is the right place for this question.



I believe that my backtests are running much slower than they are supposed to after reading some of the posts here. [@U4H19D1D2](@U4H19D1D2) mentioned that Flumine is capable of running 1000's markets a minute out of the box, and I am getting something more like 1 market per second or worse.



To check what was is going on I am running a slightly modified flumine example `backtest.py` (added `"listener_kwargs"` and removed logging to speed things up).



```import time



from flumine import FlumineBacktest, clients

from strategies.lowestlayer import LowestLayer



client = clients.BacktestClient()



framework = FlumineBacktest(client=client)

markets = ['data/1.181018785', 'data/1.181018790', 'data/1.181018780', 'data/1.181018795']



strategy = LowestLayer(

    market_filter={"markets": markets,

	"listener_kwargs": {"inplay": False, "seconds_to_start": 600}},

    max_order_exposure=1000,

    max_selection_exposure=105,

    context={"stake": 2},

)



framework.add_strategy(strategy)



start = time.process_time()

framework.run()

end = time.process_time()



print("time taken: ", end-start)```

Output:

`time taken:  10.760373999999999`



I have run this on two machines now, one is a 2017 Macbook Pro, the other is a pretty beefy Desktop rig with an intel 9600k CPU and 16GB of RAM. Both have similar results.



Appreciate if anyone knows whether this is expected or if I am not set up correctly. Thanks!

*Tags: Performance, Strategies*

---

**Jack** - *12:52:35*

On another note I did notice some odd behaviour when adding multiple strategies to one framework. If I run the below code and call `add_strategy()` twice, it seems to only run the first strategy that is added.

```...

# first strat should take longer

strategy = LowestLayer(

    market_filter={"markets": markets},

    max_order_exposure=1000,

    max_selection_exposure=105,

    context={"stake": 2},

)

# second strat should be faster

strategy2 = LowestLayer(

    market_filter={"markets": markets,

	"listener_kwargs": {"inplay": False, "seconds_to_start": 600}},

    max_order_exposure=1000,

    max_selection_exposure=105,

    context={"stake": 2},

)



# add both strats

framework.add_strategy(strategy)

framework.add_strategy(strategy2)



# run framework

start = time.process_time()

framework.run()

end = time.process_time()

...```

when adding the strategies in this order it takes 20seconds (same time as only running ‘strategy’)

```framework.add_strategy(strategy)

framework.add_strategy(strategy2)```

however in this order it takes 10seconds (same time as only running ‘strategy2’)

```framework.add_strategy(strategy2)

framework.add_strategy(strategy)```

*Tags: Strategies*

---

**Lee** - *12:58:53*

I'm guessing that's probably something todo with the listener_kwargs from whichever strategy is first

*Tags: Strategies*

---

**Jack** - *13:12:59*

[https://github.com/liampauling/flumine/issues/478](https://github.com/liampauling/flumine/issues/478)

*Tags: General Technical*

---

**Unknown** - *13:27:38*

Got it [@U01LD279D16](@U01LD279D16) thanks - [https://betfairlightweight.slack.com/files/UPMUFSGCR/F013J0H5F3M/backtest_multi.py](https://betfairlightweight.slack.com/files/UPMUFSGCR/F013J0H5F3M/backtest_multi.py)

*Tags: General Technical*

---

## 2021-08-18

**Van** - *16:20:04*

Hitting an `ngErrorRedirect` when trying to using historic data API, anyone seen this?

*Tags: Errors Debugging*

---

**thambie1** - *16:32:59*

Website downloads can be flaky too in my experience. And it's quite painful when you're midway through a 5gb download and it fails. I'd suggest sticking with the API. I implemented some automated error catching and retries, which after many iterations works pretty flawlessly

*Tags: Errors Debugging*

---

**Mo** - *16:49:27*

You got the error trying to download that much through the API? If so, try a smaller date range, like one month at a time

*Tags: Errors Debugging*

---

## 2021-08-19

**Rach** - *10:08:50*

I am using betfairlightweight for Order Streaming, all working fine, but today I am not able to get the bets I place in 1 specific market... Has this happened to any of you? or should I dig in case I have a bug

*Tags: Errors Debugging*

---

**Mo** - *15:55:30*

Your sample size is 1. I'm running the same strategy now as in 2018

*Tags: Strategies*

---

**Atho55** - *19:00:14*

[@UBS7QANF3](@UBS7QANF3) Your strategy must be too Gouda to be true

*Tags: Strategies*

---

**Michael** - *19:50:24*

It's not like [@UBS7QANF3](@UBS7QANF3)'s saying anything outlandish that's how it works. If your operation is well designed and you don't hit any exceptional circumstances you can expect it to last a long time.



As far as markets changing goes - yes they change but usually gradually. There are occasional step changes like the introduction of cross-matching (I struggle to thing of a second example) and you get weird situations like the pandemic but generally it's a slow evolution.

*Tags: Errors Debugging, Performance*

---

**Mo** - *20:27:44*

I recently resurrected a strategy I started using in 2010. It’s looking good, on course for multiple six figures this year

*Tags: Strategies*

---

## 2021-08-20

**Van** - *03:05:03*

&gt; I recently resurrected a strategy I started using in 2010. It’s looking good, on course for multiple six figures this year 

Wow! You trade racing I presume?

*Tags: Strategies*

---

**Van** - *07:10:16*

Thanks.. interesting maybe I’ll look at tennis models instead of football.. I’m sure they both equally competitive markets by now.

*Tags: Strategies*

---

**Unknown** - *08:10:01*

Hi



I've written a program that imports flumine. However, when I try to run it, I get an error message:



*Traceback (most recent call last):*

  *File "C:\Bet-Project-Code\backtest.py", line 9, in &lt;module&gt;*

    *from flumine import BaseStrategy*

*ModuleNotFoundError: No module named 'flumine'*



I definitely have flumine installed, as when I go 'pip install flumine' via CMD, I get told that I have (see screenshot). Also, I've checked my Python version number using the powershell, and I am on version 3.8.10 (in case that's relevant).



What do you guys suggest?



Thanks in advance.



Jeff

*Tags: Getting Started, Errors Debugging, Strategies*

---

**mandelbot** - *08:21:27*

If your code isn't in the flumine bin I think you will have to import flumine?

*Tags: General Technical*

---

**Jeff Waters** - *08:36:05*

Thanks Mandelbot.



What is the flumine bin?



I've just added 'import flumine' to my code, but I now get told:



  File "C:\Bet-Project-Code\backtest.py", line 9, in &lt;module&gt;

    import flumine

ModuleNotFoundError: No module named 'flumine'

*Tags: Errors Debugging*

---

**Jonjonjon** - *08:36:58*

How are you trying to execute your code? There's a chance that you are running a different Python installation, to the one where you installed flumine.

*Tags: Getting Started*

---

**Jeff Waters** - *09:45:41*

Thanks Jon



That's probably it. I've set up a virtual environment in the folder where my code is located. To run the code, I just get IDLE to execute it.



Is it the case that I need to install flumine into my virtual environment?



Jeff

*Tags: Getting Started*

---

**Jonjonjon** - *10:10:15*

Yes, that could be the problem. Unfortunately, I always fail when I try to install stuff in virtual environments. Hopefully someone else here knows the correct commands.

*Tags: Getting Started*

---

**Jeff Waters** - *10:38:59*

Fair enough, thanks Jon.



I think I've now managed to successfully install flumine within the virtual environment. However, I'm still having the same error message as before.



I'm probably overlooking something blindingly obvious, but if anyone has any suggestions, they would be much appreciated. :slightly_smiling_face:

*Tags: Getting Started, Errors Debugging*

---

**George** - *10:41:40*

Yeah, the issue only lasted a few hours, not that this really helps you now that it's Friday...

*Tags: General Technical*

---

**Jeff Waters** - *11:08:34*

I've just deleted my previous virtual environment, and set up a new one using Conda. I then tried to install flumine in it, but it thinks that it's already been installed:



*(flum) C:\Bet-Project-Code&gt;pip install flumine*

*Collecting flumine*

  *Using cached flumine-1.19.9-py3-none-any.whl (115 kB)*

*Collecting python-json-logger==2.0.2*

  *Using cached python_json_logger-2.0.2-py3-none-any.whl (7.4 kB)*

*Requirement already satisfied: requests in c:\users\water\anaconda3\envs\flum\lib\site-packages (from flumine) (2.25.1)*

*Collecting tenacity==8.0.1*

  *Using cached tenacity-8.0.1-py3-none-any.whl (24 kB)*

*Collecting betfairlightweight==2.13.1*

  *Using cached betfairlightweight-2.13.1-py3-none-any.whl (63 kB)*

*Requirement already satisfied: idna&lt;3,&gt;=2.5 in c:\users\water\anaconda3\envs\flum\lib\site-packages (from requests-&gt;flumine) (2.10)*

*Requirement already satisfied: certifi&gt;=2017.4.17 in c:\users\water\anaconda3\envs\flum\lib\site-packages (from requests-&gt;flumine) (2021.5.30)*

*Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in c:\users\water\anaconda3\envs\flum\lib\site-packages (from requests-&gt;flumine) (4.0.0)*

*Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in c:\users\water\anaconda3\envs\flum\lib\site-packages (from requests-&gt;flumine) (1.26.6)*

*Installing collected packages: tenacity, python-json-logger, betfairlightweight, flumine*

*Successfully installed betfairlightweight-2.13.1 flumine-1.19.9 python-json-logger-2.0.2 tenacity-8.0.1*



Also, I'm still getting the same error message. Any suggestions appreciated.

*Tags: Getting Started, Errors Debugging*

---

**Mo** - *11:46:01*

Yes but flumine is not a requirement of flumine. You have several requirements already satisfied (installed) (requests, idna, certifi, chardet, urllib3) and then several more get installed along with flumine (tenacity, python-json-logger, betfairligthweight)



When you say



&gt; I've written a program that imports flumine. However, when I try to run it

How exactly are you running it?

*Tags: Getting Started*

---

**Jeff Waters** - *11:51:54*

I have written a .py file, which I am trying to run.



I took the import statements from sample code on GitHub:



from flumine import BaseStrategy

from flumine.order.trade import Trade

from flumine.order.order import LimitOrder, OrderStatus

from flumine.markets.market import Market

from betfairlightweight.filters import streaming_market_filter

from betfairlightweight.resources import MarketBook

from flumine import FlumineBacktest, clients



I've also tried adding 'import flumine' to the top of that list, but that makes no difference.



I'm running the file by opening it using IDLE and then going Run &gt; Run Module.



Thanks

*Tags: Strategies*

---

**Jeff Waters** - *12:08:08*

No - unless it notices there is a virtual environment and does so automatically. I've tried running it without a virtual environment and get the same error message.



I wonder whether there is a gremlin somewhere on my computer that's causing this issue. It might be worth me using Google Colaboratory and see if I have any more joy running the program on their servers?

*Tags: Errors Debugging, Deployment*

---

**Jeff Waters** - *12:32:24*

Thanks Mo. I think that fixed it.



I followed those instructions. I wasn't able to run the program using the shell in IDLE:



&gt;&gt;&gt; python backtest.py

SyntaxError: invalid syntax



However, when I run the program by running 'powershell' in cmd, I now no longer get that error message.



Thanks also to everyone who has replied.

*Tags: Errors Debugging*

---

**Jeff Waters** - *13:32:08*

In the flumine example code at [https://github.com/liampauling/flumine](https://github.com/liampauling/flumine), what is it that calls the _'process_orders(self, market: Market, orders: list)'_ method in the ExampleStrategy class?



I have created a strategy object as shown in the example, and tried to call the method using:



strategy.process_market_book(market, market_book)



However, I get told that 'market is not defined'. How do I create Market and MarketBook objects from the JSON data files that I'm using, so that I can pass them to this method?



Thanks



Jeff

*Tags: Strategies*

---

**Jack** - *15:38:33*

On a `MARKET_BOOK` event, Flumine calls `_process_market_books()`  [https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/flumine.py#L26](https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/flumine.py#L26)



Then this calls `process_market_book()`  through an error handling function here as best I can tell [https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/backtest/backtest.py#L145](https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/backtest/backtest.py#L145)

*Tags: Errors Debugging*

---

**Jeff Waters** - *16:46:00*

Thanks Jack - Much appreciated.



I am currently inheriting from BaseStrategy, but I think that inheriting from FlumineBacktest could work (though I could be wrong - Python isn't my forte, to put it mildly! :slightly_smiling_face:).

*Tags: Strategies*

---

**Jack** - *16:51:08*

I think you are better off looking at this file:

[https://github.com/liampauling/flumine/blob/master/examples/backtest.py](https://github.com/liampauling/flumine/blob/master/examples/backtest.py)



This is where you kick off your backtesting. You pass your markets into the market filter (line #25) as a list of filepaths.



You don’t need to manually call the process_orders() function. It’s going to get called for you as flumine does it’s thing and detects updates to the market stream (whether that is simulated from a file in this case, or from a real stream if you are live)



Try running that backtest file with a market file of your own as a starting point.

*Tags: Deployment*

---

**PeterLe** - *19:22:37*

[@U013K4VNB6D](@U013K4VNB6D) I just read the posts above; if you're not using Pycharm, Id recommend it. Im new to python too, but it just seems easier to use, debug and visually more pleasing (its free too)

*Tags: Getting Started, Errors Debugging*

---

**Jack** - *20:26:14*

That would be in the strategy Class. Example here of the order being created [https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/examples/strategies/lowestlayer.py#L57](https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/examples/strategies/lowestlayer.py#L57)

Your conditions will go in `process_market_book()` and it's up to you to bring into that whatever you need for your logic.

I'd recommend just taking a look at the LowestLayer example and if you know how, use the debugger in VSCode or Pycharm (other IDE's are available) to step through the code line by line. It's the best way to get a feel for what's actually happening.

*Tags: Errors Debugging, Strategies*

---

## 2021-08-21

**Unknown** - *12:25:15*

Hi



I've tried installing flumine and Betfair Lightweight to my virtual directory via Pycharm, but I got error messages (see attached).



I'm using Python 3.8.



I'm just flagging this up in case it isn't a known issue.

*Tags: Getting Started, Errors Debugging*

---

**Mo** - *12:36:26*

It’s impossible to ask this without sounding like an asshole but: did you read the error message?

*Tags: Errors Debugging*

---

**Jeff Waters** - *12:49:01*

Yes, I did, but the fact that there was a problem with the SSL didn't really give me much of a clue as to how to fix the problem (or indeed if I could fix it). :slightly_smiling_face:



Incidentally, I've tried re-creating the project using Conda as the virtual environment (as per [https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003511399-SSL-module-not-available-unable-to-install-packages?page=1#community_comment_360001528719|https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003511399-SSL-module-not-available-unable-to-install-packages?page=1#comm[…]28719](https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003511399-SSL-module-not-available-unable-to-install-packages?page=1#community_comment_360001528719|https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003511399-SSL-module-not-available-unable-to-install-packages?page=1#comm[…]28719)), but now Betfair Lightweight and flumine don't appear in the list of available packages.



I'll also try your suggestion of installing the SSL package.



As I mentioned yesterday, I can run my code by going into the virtual environment via powershell, but it would be nice if I could find a way of running it directly from an IDE.



Cheers

*Tags: Getting Started, Errors Debugging*

---

**Jeff Waters** - *12:56:32*

PS Just found a workaround. I've uninstalled flumine, and then reinstalled it in my Conda virtual environment. That seems to have done the trick (touch wood! :smile:).



Cheers

*Tags: Getting Started*

---

**Jeff Waters** - *20:02:32*

I've created a backtest script for historical data: [https://github.com/JeffW12345/betfair-backtester](https://github.com/JeffW12345/betfair-backtester).



My file returned zero profit for every single market, so to test if it was working I've added 'print(len(market.blotter))' to line 43 of runbacktests.py. It gives a blotter list length of zero for every market, suggesting that nothing is being added to the blotter.



Could someone take a look and tell me where I'm going wrong, please?

*Tags: Data Quality*

---

**Lee** - *20:30:26*

Try adding the `check_market` method to the strategy

*Tags: Strategies*

---

**Jeff Waters** - *20:53:47*

Thanks Lee.



Do you mean adding it to the bottom of the process_market_books method, as in this example? [https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/flumine/backtest/backtest.py#L141](https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/flumine/backtest/backtest.py#L141)



I've just tried doing that - I've updated [https://github.com/JeffW12345/betfair-backtester/blob/master/teststrategy.py](https://github.com/JeffW12345/betfair-backtester/blob/master/teststrategy.py) - but I'm still having the same issue.

*Tags: Strategies*

---

**Lee** - *20:55:30*

No, like this in the strategy class [https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/examples/strategies/lowestlayer.py#L19|https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/examples/strategies/lowestlayer.py#L19](https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/examples/strategies/lowestlayer.py#L19|https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/examples/strategies/lowestlayer.py#L19)

*Tags: Strategies*

---

**Jeff Waters** - *21:05:38*

Thanks for clarifying, Lee. I've just tried that - I've updated my repository - but I'm still getting the same problem.



I've considered creating a Blotter object and adding orders to it, but I suspect that would be the wrong approach, as I get the impression that should happen without me having to explicitly invoke it.

*Tags: General Technical*

---

**Beeblebrox** - *21:08:47*

Have you run it under the debugger to see what's happening?  I suspect one of the problems is because you're checking if `market.seconds_to_start == 60` and it never actually equals exactly 60.  I think there are probably other issues with what you've currently got, but that would be the first thing to look at using the debugger.

*Tags: Errors Debugging*

---

**Jeff Waters** - *22:23:14*

Hi Beeblebrox



There were bugs in the code in the process_market_book method, including the one you mentioned. Thanks for flagging that up.



However, it seems that the code in that method is not actually being called from anywhere. When I put a print command on the top line of that method, the print statement doesn't appear.



I'll have a look at it in the morning - I suspect this is a case where looking at things with fresh eyes would help! :slightly_smiling_face:

*Tags: Errors Debugging*

---

**Jack** - *23:11:52*

Hey Jeff, this could be happening because you don’t have the `check_market_book()`  function. The role of that function is to decide whether or not you want to run the strategy over that market. If it returns True, `process_market_book()`  will execute and you will see your print statements; if it returns False, then it’s not going to execute.

It might be returning False by default so by not implementing it in your strategy you are saying no to each and every market that gets passed through.

*Tags: Strategies*

---

**Jeff Waters** - *23:37:13*

Thanks Jack.



That's a valid point, but since I wrote my original code, I have added the check_market_book() method, after Lee pointed out that it was missing: [https://github.com/JeffW12345/betfair-backtester/blob/master/teststrategy.py#L26](https://github.com/JeffW12345/betfair-backtester/blob/master/teststrategy.py#L26). Thanks for the suggestion, though.



I wonder whether I need to invoke the FlumineBacktest class, given that it contains an error handling method that calls process_market_book? [https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/flumine/backtest/backtest.py#L141](https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/flumine/backtest/backtest.py#L141)



I'm going to head in. Thanks for your help and patience, guys. :slightly_smiling_face: Night.

*Tags: Errors Debugging, Strategies*

---

## 2021-08-23

**Adrian** - *07:17:56*

Is there an easy way to check if the market data recorded files are whole and complete? With all my connection dropouts there's probably more incomplete markets that I can filter out manually



Also, when backtesting, is this normal? ""Order has violated: MARKET_VALIDATION Error: Market is not open" this seems to be breaking it

Thanks

*Tags: Errors Debugging*

---

**liam** - *08:36:53*

Is that giving you a critical error? I (and many) separate data recording and strategy instances to prevent this, regarding the dropouts just get a better connection :wink:

*Tags: Errors Debugging, Strategies*

---

**Adrian** - *08:59:40*

[@U4H19D1D2](@U4H19D1D2) its not critical, just warning but its "Order status update: Violation" so it's not placing bets, from what I can tell.

And i'm working on the better connection :wink::laughing: just want to salvage the data i have

&gt; {"asctime": "2021-08-23 07:23:18,428", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.186624929", "selection_id": 35921733, "handicap": 0, "id": "138489961984286210", "customer_order_ref": "c6e3b6551008c-138489961984286210", "bet_id": null, "date_time_created": "2021-08-22 07:20:46.819000", "publish_time": null, "trade": {"id": "fd07dc9a-03e2-11ec-9864-1e0062368792", "strategy": "Backtest", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138489961984286210"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 6.8, "size": 5.0, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 5.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}

*Tags: Deployment, Strategies*

---

**Adrian** - *11:06:19*

thanks for helping me find the problem

*Tags: General Technical*

---

## 2021-08-26

**liam** - *08:59:35*

Good spot, this is a bug that I am fixing now

*Tags: Errors Debugging*

---

## 2021-09-03

**Adrian** - *09:54:29*

My csv export from the logging control example keep maxing out before the strategy has finished. Any idea what's causing the limit?

*Tags: Strategies*

---

**Adrian** - *10:08:59*

I don't know how to make the logs work for both so I can only see what the logging control creates

*Tags: General Technical*

---

**liam** - *10:15:08*

the logs will tell you the problem, all the examples have logging enabled, whats the problem?

*Tags: General Technical*

---

**Adrian** - *10:25:48*

Ok i got the logs working on both strat and loggingcontrol (sorry for confusion, i thought it only worked on one at a time). There is an apparent "max transaction count" error. But that should only last 1 hour. These markets span 2 months. Its seems once it hits that limit it never clears, so the csv export stops there

*Tags: Errors Debugging*

---

**Adrian** - *10:39:02*

Obviously it's never going to clear if it keeps triggering, so best to never trigger it hey. Sorry for the stupid question!

*Tags: General Technical*

---

**liam** - *10:56:18*

impossible for me to debug without some code tbh but I (and many others) use this all the time with no issues so its likely to be your code

*Tags: Errors Debugging*

---

**mandelbot** - *13:51:34*

I had this problem and it turned out it was an issue with how I was recording the markets. Did you change that code at all?

*Tags: General Technical*

---

**Jonjonjon** - *21:09:03*

I keep getting this error:



MAX_CONNECTION_LIMIT_EXCEEDED



Is it easy to get increased?

*Tags: Errors Debugging*

---

**liam** - *21:22:48*

Are you using latest version of bflw 

*Tags: General Technical*

---

**Jonjonjon** - *21:27:10*

I fixed it for now by killing a few stray jobs. I guess I need to be more careful.

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:27:53*

can a single flumine sessions use more than one connection?

*Tags: General Technical*

---

**Lee** - *22:30:14*

do you have different market filters for each strategy?

what do your logs say for how many streams when you start flumine?

*Tags: Strategies*

---

**Lee** - *22:51:53*

If you’re using flumine id look into what’s using so many connections, using a wide market filter thats the same for all strategy’s will reuse the same connection

*Tags: Strategies*

---

## 2021-09-04

**Adrian** - *03:30:34*

No haven't touched it but more than a few of my markets are incomplete due to dropouts so maybe it's that. Anyway I am trying a different approach with regard to how many bets i place so if I see the same problem then i'll know it's something else

*Tags: General Technical*

---

**Adrian** - *03:37:37*

that's a good idea actually, then just adding conditions within the strategy to separate markets

*Tags: Strategies*

---

**Peter** - *06:19:04*

My error logs this morning are full of errors like this:



`ERROR:flumine.worker:_get_cleared_market error`

`Traceback (most recent call last):`

  `File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/worker.py", line 232, in _get_cleared_market`

    `group_by="MARKET",`

  `File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/endpoints/betting.py", line 434, in list_cleared_orders`

    `(response, response_json, elapsed_time) = self.request(method, params, session)`

  `File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 55, in request`

    `self._error_handler(response_json, method, params)`

  `File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 81, in _error_handler`

    `raise self._error(response, method, params)`

`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders`

`Params: {'betStatus': 'SETTLED', 'marketIds': ['1.187240733'], 'customerStrategyRefs': ['ip-172-31-5-190'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'}`

`Exception: None`

`Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-09020828-000312861c', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}`

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-09020828-000312861c', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`



Latest version of Fumine (1.19.12) and BFLW (2.13.2), and the trades are working fine.



I'm wondering whether anybody else has any idea what could be triggering these "unexpected errors" in the __get__cleared_market() method.



It might be connected to the from and to dates not being set in the API call, but as this is happening internally to Flumine, I'm don't know how to ensure that they get set.

*Tags: Errors Debugging, Deployment, Strategies*

---

**Peter** - *06:29:19*

Hmm. Could be a problem resurfacing at the Betfair end: [https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/34290-getaccountstatement-unexpected-error](https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/34290-getaccountstatement-unexpected-error)

*Tags: Errors Debugging*

---

**Mo** - *07:13:24*

I get these errors pretty regularly when scraping the account statement. They go away after a while

*Tags: Errors Debugging*

---

**Ke** - *21:10:11*

The current_transaction_count_total seems to be accumulating all the time. I'm running back testing for 1 month data. The first 20 days are all ok and starts to throw error as current_transaction_count_total&gt;5000, while my strategy should not generate more than 200 orders every hour. Therefore, I'm wondering does current_transaction_count_total only count the transaction in last 1 hour in the simulation?

*Tags: Errors Debugging, Strategies*

---

**infinite digital** - *22:47:00*

Hello,



I am seeing the following error:



```MarketStream 2007 run error

Traceback (most recent call last):

  File "D:\apps\programming\python\lib\site-packages\flumine\streams\marketstream.py", line 44, in run

    self._stream.start()

  File "D:\apps\programming\python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 60, in start

    self._read_loop()

  File "D:\apps\programming\python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 219, in _read_loop

    self._data(received_data)

  File "D:\apps\programming\python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 260, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 206-040921214509-3414396, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"206-040921214509-3414396"}```

I can access other API methods using BFLW.



What is wrong?



Thank you!

*Tags: Errors Debugging*

---

## 2021-09-05

**Adrian** - *00:33:12*

I am having the same problem. I've been looking into the code to try and learn how it works after Liam said it shouldn't be happening, but knowing it's probably my code that's wrong

*Tags: General Technical*

---

**Adrian** - *07:23:47*

So, sorting my list of markets before adding them to the strategy changed the behaviour a bit. It nearly doubled the time it took to hit max transactions. But it's still not clearing

*Tags: Strategies*

---

**Ke** - *08:38:43*

Do you add all your market in one go? I'm backtesting one month data. Everytime i only run strategy for one day and one track, same file structure as betfair historic data. Maybe it caused the issue? Not sure what is the proper way to load historic data for back testing. I have a feeling maybe my way is not right

*Tags: Strategies*

---

## 2021-09-06

**Adrian** - *10:34:58*

I am getting this weird error while backtesting and it is halting the script when it occurs

```{"asctime": "2021-09-06 09:28:44,051", "levelname": "CRITICAL", "message": "Trade error in 081dd302-0ef4-11ec-a5d6-1e0062368792", "exc_info": "Traceback (most recent call last):\n  File \"/Users/adrian/opt/anaconda3/envs/betfair/lib/python3.8/site-packages/flumine/execution/simulatedexecution.py\", line 142, in execute_replace\n    place_instruction_report = replacement_order.simulated.place(\n  File \"/Users/adrian/opt/anaconda3/envs/betfair/lib/python3.8/site-packages/flumine/backtest/simulated.py\", line 68, in place\n    self.size_voided += self.size_remaining\n  File \"/Users/adrian/opt/anaconda3/envs/betfair/lib/python3.8/site-packages/flumine/backtest/simulated.py\", line 379, in size_remaining\n    self.order.order_type.size\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'int'"}```

*Tags: Errors Debugging*

---

**Oliver Varney** - *10:41:43*

that error translates to your adding/taking away  None and a integer together i.e. None - 5. So it looks self.order.order_type.size is None or one of the other variable it takes away in that property. Have you created an order with size None by accident (if thats possible)?

*Tags: Errors Debugging*

---

**Oliver Varney** - *10:48:05*

yes but the process of replacing the order looking at that error stack uses the property size_remaining, which in turn uses self.order.order_type.size

*Tags: Errors Debugging*

---

**Oliver Varney** - *10:48:44*

[https://github.com/liampauling/flumine/blob/f0e7e6542942d00685ceb6d72951456684998739/flumine/backtest/simulated.py#L376](https://github.com/liampauling/flumine/blob/f0e7e6542942d00685ceb6d72951456684998739/flumine/backtest/simulated.py#L376)

*Tags: General Technical*

---

**Oliver Varney** - *11:00:14*

same applies without looking deeply id stick a break point in or wrap that property with a try and except and catch the exception and find out what is None and why. Can you not isolate that market and step through the process of creating the order then replacing it

*Tags: Errors Debugging*

---

## 2021-09-07

**Peter C** - *11:03:53*

Sorry for the basic question but I am having trouble understanding how to use some middleware. I'd like to get execution.complete orders on start up. I've got the example file in a file of my own, and can import the ordersMiddleware class into the file which starts the flumine process. I have tried getting the orders like this:

`framework.add_strategy(strategy)`

`order_middleware = OrdersMiddleware(framework)`

`get_orders = order_middleware.add_market()`

`framework.run()`

but this doesn't work because add.market needs to be passed the market, and I don't know how to do this. I'm not even sure whether this is the correct time to try and get the orders. Please would someone help me work this out?

*Tags: Strategies*

---

**liam** - *11:03:55*

Quick fix for your example would be



```client = clients.BacktestClient(

    transaction_limit=None,

)```

*Tags: Errors Debugging*

---

**liam** - *11:04:58*

The add_market func gets called by flumine itself so you just have to..



```framework.add_strategy(strategy)

framework.add_middleware(OrdersMiddleware(framework))

framework.run()```

*Tags: Strategies*

---

**Ke** - *11:05:17*

It works for me perfectly. Trying to add middleware to plug in my model now...

*Tags: Strategies*

---

**Peter C** - *11:19:42*

[@U4H19D1D2](@U4H19D1D2) sorry I now get the error

`AttributeError: 'Flumine' object has no attribute 'add_middleware'`

Do I need to import the add_middleware function from somewhere?

*Tags: Errors Debugging*

---

**Peter C** - *11:34:09*

That's got it (I hope!). Thank you for your help

*Tags: General Technical*

---

## 2021-09-08

**Mons___das** - *12:58:13*

Hi ppl,

I ve been running the s3MarketRecorder for a while now and it seemed to be doing its job (havent worked with the data a lot yet, so cant confirm its all correct). I just realized i ve got a tmp folder with 4.4gb worth of files. Some of these are unpacked streaming data, some are randomly named directories filled with unpacked and packed streaming data and maybe some market catalogues. Anyone knows how these stacked up there ?

*Tags: General Technical*

---

**Peter** - *13:09:35*

That's the where the market recorder keeps the data, executes the compression and from where it will upload the files when finished. There are two parameters that you can pass into the market recorder: "remove_file" and "remove_gz_file" which by default are set to False. To stop these /tmp subfolders from growing until you run out of disk, you're going to want to set them to True when you start the recorder. For example:



`strategy = S3MarketRecorder(`

    `name="Golf Market Recorder",`

    `market_filter=betfairlightweight.filters.streaming_market_filter(`

        `event_type_ids=["3"],`

    `),`

    `stream_class=DataStream,`

    `context={`

        `"local_dir": "/tmp",`

        `"bucket": "*************",`

        `"force_update": True,`

        `"remove_file": True,`

        `"remove_gz_file": True,`

    `},`

`)`

*Tags: Data Quality, Strategies*

---

**Mons___das** - *13:33:16*

As i am testing a lot of stuff (and surely not always following best practice :grimacing: ), the market recorder has been terminated rather frequently. Could this lead to files being left there ?

*Tags: Data Quality*

---

**liam** - *13:49:32*

Should now be fixed in 1.19.13 can you check?



The issue is due to the ordering of the market files, I do this before processing which is why I hadn't seen it before. Full commit [https://github.com/liampauling/flumine/commit/0e94dd0a00533c52176746c56c7610ec698da6a2|here](https://github.com/liampauling/flumine/commit/0e94dd0a00533c52176746c56c7610ec698da6a2|here) where you can see the ordering and slight logic change to handle any long running markets

*Tags: Errors Debugging*

---

**Peter C** - *14:09:46*

I started using middleware to add execution.complete orders to market.blotter on stream restart with liam's help yesterday. The middleware is working (which is really great), but it appears to be effecting my logging, which relies on the trade notes. Looking through the provided code I can't tell whether the middleware should be picking up order.trade.notes and adding them to the blotter. Should the notes be collected, and if not is there a way of picking them up?

*Tags: General Technical*

---

**liam** - *14:11:36*

Notes/context are all local objects so you would need to store them elsewhere, simple fix is don't restart

*Tags: Errors Debugging*

---

**Ke** - *19:30:28*

seems to work for me. no longer see the error now

*Tags: Errors Debugging*

---

## 2021-09-09

**Unknown** - *04:12:03*

Hi All, I'm an API newbie and am having trouble getting the non-interactive login working.  I have followed the instructions on Betfair for generating certificates using XCA, I have deleted and started over numerous times to ensure exact instructions were followed, but each time I run login code I get the below exception:

*Tags: Errors Debugging*

---

**JFP** - *04:18:17*

Sure this is very basic problem, if there are posts about this it would be great if someone could point me in the right direction. Thanks

*Tags: General Technical*

---

**JFP** - *16:00:12*

Kept playing around, figured out the problem and got it working, very simple when you have the correct instructions. The betfair "Certificate Generation with XCA" tutorial is good enough up until the export part. The export instructions do not align with the current available XCA version. The first part of the current export instructions says to export .pem from priviate key tab (IGNORE THIS INSTRUCTION). The next part of the instructions is correct, export .crt file (perm*.crt, latest edition) from certificates tab (this is the file to be uploaded to betfair security settings). The next step (not in instructions) is to stay on the certificates tab and export 'pem + key (*.pem)' file, this is the file that needs to be stored in your certs_path directory. The non-interactive login worked using this process.

*Tags: General Technical*

---

## 2021-09-11

**ricky** - *09:53:39*

This morning my betfair API return error message SUBSCRIPTION_LIMIT_EXCEEDED,  my max allowed number changed from 2000 to 1000 now? Anyone have the same issue?

*Tags: Errors Debugging*

---

## 2021-09-15

**mandelbot** - *07:30:36*

Any reasons why I wouldn't get matched on a `MarketOnCloseOrder` during a backtest? I'm getting quite a few of these orders return empty in the market.blotter after market closure, even though they were placed. For example:

```{"asctime": "2021-09-15 06:19:58,132", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.184881012", "selection_id": 40031632, "handicap": 0, "id": "138509795981320640", "customer_order_ref": "2caf09fd8c57f-138509795981320640", "bet_id": "100000000002", "date_time_created": "2021-07-01 11:44:50.042000", "publish_time": "2021-07-01 11:44:50.042000", "trade": {"id": "f360e1bf-15ec-11ec-917f-5c969d7d9766", "strategy": "strategy", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138509795981320640"], "notes": "", "market_notes": "85,95,100", "status": "Pending", "status_log": "Pending"}, "order_type": {"order_type": "Market on close", "liability": 103.5}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-07-01 11:44:50.194000", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Executable", "status_log": "Pending, Executable", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}}```

*Tags: Strategies*

---

**liam** - *08:03:56*

upgrade flumine

*Tags: General Technical*

---

**mandelbot** - *13:57:09*

I've been backtesting some IP horse racing strategies and found that when I add a condition for InPlayTimeElapsed &gt; X it would place the same bets as without that condition but they would be at slightly different `order.responses.date_time_placed` and different odds also. ie different from when I filter the results on the general strategy for InPlayTimeElapsed &gt; X. Why this would be the case?

*Tags: Strategies*

---

**mandelbot** - *14:01:38*

So I have a general strategy and one where I'm conditioning elapsed in play time to be &gt; than some number. When I compare the filtered results from the general strategy (ie elapsed time &gt; than some number) they would be different from the results conditioned strategy. Same runners, but at different odds and slightly different `date_time_placed`

*Tags: Strategies*

---

**Aaron Smith** - *15:36:09*

Hey ppl, i want to access the last_traded_price, however it returns None (while backtesting).

I use:

```market_data_filter = betfairlightweight.filters.streaming_market_data_filter(

        fields=["EX_BEST_OFFERS", "EX_MARKET_DEF", "EX_LTP"], ladder_levels=1)```

*Tags: General Technical*

---

**Aaron Smith** - *15:51:13*

ah, i think i solved it :smile: Obviously adding EX_LTP into the market_data_filter wont help if i didnt have it in there when recording :clown_face:

*Tags: General Technical*

---

**liam** - *15:51:57*

tbh I didn't understand why you where asking about backtesting but sharing a streaming filter?

*Tags: General Technical*

---

**liam** - *15:56:20*

flumine isnt that good :joy:

*Tags: General Technical*

---

## 2021-09-16

**liam** - *09:37:24*

anyone else getting a lot of connection errors?

*Tags: Errors Debugging*

---

**birchy** - *11:20:44*

Regarding backtesting, is there a way to access the runner status ('WINNER', 'LOSER', etc) _after_ the backtest is complete? I know it can be processed via `process_closed_market()` in the strategy itself, but I'm trying to access it after the event, e.g:

```framework.run()



for market in framework.markets:

    print(market.closed)

    results = {r.selection_id: r.status for r in market.market_book.runners}

    print(results)```

which results in:

```True

{38432986: 'ACTIVE', 28095515: 'REMOVED', 38235043: 'ACTIVE', 26817710: 'ACTIVE', 36775362: 'ACTIVE', 37487570: 'ACTIVE', 27207443: 'ACTIVE', 10138440: 'ACTIVE', 38648845: 'ACTIVE', 14037512: 'ACTIVE', 36753881: 'ACTIVE', 12829452: 'ACTIVE', 24075586: 'ACTIVE'}```

*Tags: Strategies*

---

**liam** - *11:41:54*

hmm this is because `market.market_book` isn't updated when the status is closed (`market()` not called), open to a PR to change this, logic [https://github.com/liampauling/flumine/blob/ec060b7d98a9f15ec229fab73644d5ad970e05fe/flumine/backtest/backtest.py#L118|here](https://github.com/liampauling/flumine/blob/ec060b7d98a9f15ec229fab73644d5ad970e05fe/flumine/backtest/backtest.py#L118|here)

*Tags: Deployment*

---

**birchy** - *12:20:56*

[@U4H19D1D2](@U4H19D1D2) maybe I'm missing something here, but is the `market_book` in `process_closed_market()` different to the one in `market.market_book` ? I thought it was the same object?



Have implemented a workaround in my strategy:

```def process_closed_market(self, market, market_book):

    market.market_book = market_book```

*Tags: Strategies*

---

**Robbie Bennett** - *13:13:54*

hi guys, I am having an issue seperating out thoroughbred and trots races using the betfairlightweight interface and underlying betfair API and wondering if someone can help, this morning there were a bunch of trots races for AUS that came through and I was pretty sure the event type Ids should be separate. Many thanks in advance and heres some code I thought might help answer:



```trading = betfairlightweight.APIClient(

        username=bf_config["username"],

        password=bf_config["password"],

        app_key=bf_config["app_key"]

    )

    trading.login_interactive()





    # create queue

    output_queue = queue.Queue()



    # create stream listener

    listener = betfairlightweight.StreamListener(

        output_queue=output_queue, lightweight=True

    )

    # create stream

    stream = trading.streaming.create_stream(listener=listener)



    # create filters (Horse Racing Win markets)

    filter = streaming_market_filter(

        event_type_ids=["7"],

        country_codes=[COUNTRY_CODE],

        market_types=["WIN"],

    )

    market_data_filter = streaming_market_data_filter(

        fields=["EX_BEST_OFFERS", "EX_MARKET_DEF"], ladder_levels=1

    )

    # subscribe

    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=filter, market_data_filter=market_data_filter,

    )```

*Tags: Strategies*

---

**Robbie Bennett** - *14:20:00*

ok appreciate the help

*Tags: General Technical*

---

**Newbie99** - *14:48:55*

Yeah, basically if you just want thoroughbred racing then the way to do it is (if using Flumine) in check_market_book just return races with Trot or Pace not in the name

*Tags: General Technical*

---

**Dado** - *14:56:25*

ok, I had a python script that works since 5 month ago, it was stopped till today and now it doesn't work anymore...

*Tags: General Technical*

---

**Dado** - *14:58:49*

everythings was as always but now I got this error:

*Tags: Errors Debugging*

---

**Dado** - *14:59:07*

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue

Params: {'filter': {'marketIds': [{'1.187040331': u'30849498'}, {'1.187056991': u'30851394'}, {'1.186998604': u'30845997'}, {'1.186998738': u'30845996'}, {'1.186998872': u'30845995'}, {'1.186999006': u'30845994'}, {'1.186998336': u'30845998'}, {'1.186998470': u'30845999'}, {'1.186997502': u'30845827'}, {'1.186997636': u'30845826'}, {'1.186997770': u'30845825'}, {'1.186997100': u'30845844'}, {'1.186997368': u'30845828'}, {'1.172966865': u'30009984'}, {'1.187019793': u'30847722'}, {'1.187051669': u'30850656'}]}, 'maxResults': 1000, 'marketProjection': ['EVENT', 'RUNNER_DESCRIPTION']}

Exception: None

Error: {u'message': u'DSC-0018', u'code': -32602}

Full Response: {u'jsonrpc': u'2.0', u'id': 1, u'error': {u'message': u'DSC-0018', u'code': -32602}}

*Tags: Errors Debugging*

---

**Beeblebrox** - *16:36:18*

I thought they were the same too and have often wondered why the market_book needed to be passed to the strategy functions since you could just get it from the market object. Are they different [@U4H19D1D2](@U4H19D1D2)?

*Tags: Strategies*

---

**Dado** - *16:40:03*

MO, do you know how to request event details from an id like: 1.186997100

*Tags: General Technical*

---

**Dave** - *19:24:27*

attribute access causes latency

*Tags: Performance*

---

**Jonjonjon** - *20:55:42*

My Flumine is broken due to the MarketBookCache update earlier today.

*Tags: General Technical*

---

**liam** - *20:59:56*

It won’t work (yet) with latest version of bflw but the requirements are correct 

*Tags: General Technical*

---

**Jonjonjon** - *21:01:34*

This fixed it:

git checkout 1898838431a74fde504d8eb0fe017ab61a3556bc

*Tags: Errors Debugging*

---

**liam** - *21:10:29*

pip, requirements will always be correct and working for flumine, can only assume you have ignored?

*Tags: General Technical*

---

**Jonjonjon** - *21:18:54*

I'm on my dev machine, and for some reason it pulled the latest master version when I logged in this evening. I didn't think I'd done any pulling of bflw or flumine. Maybe I pressed the wrong button.

*Tags: General Technical*

---

## 2021-09-17

**liam** - *09:25:37*

Now fixed

*Tags: Errors Debugging*

---

**liam** - *09:28:32*

Odd, the only way you could get this is if you somehow pulled the latest bflw (2.14)

*Tags: General Technical*

---

**Peter** - *22:41:26*

Have today had some bets confirmed by my logging control as being placed as order type LIMIT with persistence type MARKET_ON_CLOSE be treated by Betfair as order type MARKET_ON_CLOSE. It's a fairly small number (8 out of 10,000+ placed today), but it does screw up my strategy somewhat. Wondered whether anybody else had encountered this.

*Tags: Strategies*

---

## 2021-09-18

**Aaron Smith** - *17:33:58*

since updating to the newest flumine version i keep getting:

```{"asctime": "2021-09-18 16:12:16,204", "levelname": "WARNING", "message": "Order 124457853944 not present in blotter", "bet_id": "124457853944", "market_id": "1.187784281", "customer_strategy_ref": "ip-172-31-34-22", "customer_order_ref": "702e0a7cf78ee-113851274335983961"}

{"asctime": "2021-09-18 16:12:16,204", "levelname": "WARNING", "message": "Strategy not available to create order 113851274335983961", "bet_id": "1244578539445", "market_id": "1.187784281", "customer_strategy_ref": "ip-172-31-34-22", "customer_order_ref": "702e0a7cf78ee-113851274335983961", "strategy_name_hash": "702e0a7cf78ee"}```

any ideas?

*Tags: Strategies*

---

**Aaron Smith** - *17:36:43*

Also at the same time i tried installing betfairlightweight[speed], which failed at the ciso8601 package, so i only have the orjson one

*Tags: Getting Started, Errors Debugging, Performance*

---

**Aaron Smith** - *18:13:15*

I have 2 flumine instances running, it seems the orders it cant are coming from the other instance, so it makes sense it cant find those. However, i didnt have this problem before, did anything change with the update?

*Tags: General Technical*

---

**Aaron Smith** - *18:20:53*

[@ULDAVFDRP](@ULDAVFDRP) thanks, but i already changed those manually for each instance (this is what fixed it last time :smile: )

*Tags: Errors Debugging*

---

**Aaron Smith** - *18:21:48*

i have

```flumine.config.hostname = "name"```



*Tags: General Technical*

---

**Beeblebrox** - *18:23:45*

customer_strategy_ref isn't it?

*Tags: Strategies*

---

## 2021-09-19

**birchy** - *09:05:30*

Upgraded Flumine last night and implemented the latest marketrecorder as I wasn't previously using the gzip format. Can't fathom out what's going on here.

*Tags: General Technical*

---

**Oliver Varney** - *09:07:18*

that error suggest your accessing a dictionary with like its an attribute of a class

*Tags: Errors Debugging*

---

**birchy** - *09:07:52*

Yeah, but it's in the Flumine code

*Tags: General Technical*

---

**birchy** - *09:11:40*

debug breakpoints here: [https://github.com/liampauling/flumine/blob/40d82ec69c333afa034c12763acc07ba3e76be31/flumine/markets/market.py#L118](https://github.com/liampauling/flumine/blob/40d82ec69c333afa034c12763acc07ba3e76be31/flumine/markets/market.py#L118)

Where `self.market_book` is actually a `dict` ?

*Tags: Errors Debugging*

---

**Mo** - *09:14:27*

When creating the bflw client

*Tags: General Technical*

---

**Oliver Varney** - *09:19:09*

[https://github.com/liampauling/flumine/blob/ec060b7d98a9f15ec229fab73644d5ad970e05fe/flumine/clients/baseclient.py#L32](https://github.com/liampauling/flumine/blob/ec060b7d98a9f15ec229fab73644d5ad970e05fe/flumine/clients/baseclient.py#L32)

*Tags: Deployment*

---

**Oliver Varney** - *09:20:11*

double check but I think its that as it should error if thats the case

*Tags: Errors Debugging*

---

**Mo** - *09:21:58*

[@U016TGY3676](@U016TGY3676) have you make any modifications to the market recorder example?

*Tags: Data Quality*

---

**liam** - *09:23:27*

That fix for your issue birchy has introduced this

*Tags: Errors Debugging*

---

**liam** - *09:46:57*

1.20.1 deploying now [https://github.com/liampauling/flumine/actions/runs/1250358231](https://github.com/liampauling/flumine/actions/runs/1250358231)

*Tags: Deployment*

---

**Alessio** - *19:00:56*

brilliant, i come back after some hiatus, and there's a new flumine version. nice ! :wink:

*Tags: General Technical*

---

## 2021-09-21

**Jorge** - *08:19:40*

Hey guys, everytime I place a bet I am providing a *customerStrategyRef* parameter. But when calling *list_cleared_orders*, something like 5% of my bets have customerStrategyRef=NaN. Has anyone had this problem before?

*Tags: Strategies*

---

**Jorge** - *08:21:59*

I am only using letters at the moment. And in this case I would get an error when placing the bet as far as I know

*Tags: Errors Debugging*

---

**Jorge** - *08:33:51*

It happens rarely but when it occurs, all bets in the marketId have customerStrategyRef=NaN

*Tags: Strategies*

---

**Jorge** - *08:53:23*

I found something even weirder: If I call

`trading.betting.list_cleared_orders(bet_status="SETTLED", group_by="MARKET", customer_strategy_refs=['A', 'B'])` , I get some marketIds with customerStrategyRef=NaN and these are different subset than if I call with

`trading.betting.list_cleared_orders(bet_status="SETTLED", group_by="MARKET", customer_strategy_refs=['C', 'D'])`

*Tags: Strategies*

---

**Jorge** - *08:55:24*

Ah, the problem is I am grouping by MARKET, and I have different strategies in the same market, so they group to NaN :smile:

*Tags: General Technical*

---

**gbettle** - *21:32:24*

Evening all. I have hacked-together a bit python to fetch Horse Racing today\tomorrow - see attached.



It's been working for several weeks. Until tonight, when I'm suddenly getting the following error. Is 503 an issue with my network?



PS C:\Users\garry\betfair\examples&gt;  &amp; 'C:\Users\garry\AppData\Local\Programs\Python\Python38\python.exe' 'c:\Users\garry\.vscode\extensions\ms-python.python-2021.9.1246542782\pythonFiles\lib\python\debugpy\launcher' '51302' '--' 'c:\Users\garry\betfair\examples\temp_racecards.py'

2021-09-22 1300 Redcar Try Racing Tv For Free Now Nursery Handicap (4) £9500.00 1 Gnat Alley, 2 Pneumatic, 3 Iur Cinn Tra

2021-09-22 1315 Goodwood Ryan Canter Club Future Stayers' Ebf Maiden Stakes (2) £20000.00 1 Age Of Sail, 2 War Horse, 3 Schmilsson

2021-09-22 1330 Redcar Free Month Of Racing Tv Nursery Handicap (6) £6200.00 1 Sweet Madness, 2 Bro, 3 Sunsets Dreamers

Traceback (most recent call last):

  File "c:\Users\garry\betfair\examples\temp_racecards.py", line 84, in &lt;module&gt;

    race_cards = trading.race_card.get_race_card(market_ids=[market_id])

  File "C:\Users\garry\AppData\Local\Programs\Python\Python38\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 64, in get_race_card

    (response, response_json, elapsed_time) = self.request(

  File "C:\Users\garry\AppData\Local\Programs\Python\Python38\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 118, in request

    check_status_code(response)

  File "C:\Users\garry\AppData\Local\Programs\Python\Python38\lib\site-packages\betfairlightweight\utils.py", line 34, in check_status_code

    raise StatusCodeError(response.status_code)

betfairlightweight.exceptions.StatusCodeError: Status code error: 503

*Tags: Errors Debugging, Strategies*

---

**liam** - *21:36:20*

Best practice would be to have any bflw calls in a try/except 

*Tags: General Technical*

---

## 2021-09-23

**Peter C** - *15:13:37*

I'm a bit unsure of how to add multiple strategies to a single instance of flumine and would appreciate going over it. I'm under the impression that I can import my two strategy files, set up two strategy objects as such:

```strategy_1 = strategy_1(

  market_filter=streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["GB", "IE"],

        market_types=["WIN"],

    ),

      market_data_filter=streaming_market_data_filter(fields=["EX_MARKET_DEF", "EX_ALL_OFFERS", "EX_TRADED"]),

      max_order_exposure=1,

      max_selection_exposure=1,

      max_live_trade_count=1,

      conflate_ms=0,

      context={"stake": 2},

)```

     and then call:

```framework.add_strategy(strategy_1)

framework.add_strategy(strategy_2)

framework.run()```

Then I am under the impression these two strategies will run independently on the same market stream. Is this right, and are there any gotchas? Thanks!

*Tags: Deployment, Strategies*

---

## 2021-09-24

**Aaron Smith** - *11:25:03*

I am doing a backtest on InPlay horses and i am getting weird results. I m placing terrible bets on purpose to check its sanity, but i m barely getting matched. I had this strategy running live (with more reasonable prices) and i was getting matched more. Anyone has an idea in what direction to look here?

*Tags: Deployment, Strategies*

---

## 2021-09-27

**Newbie99** - *17:21:21*

[https://github.com/liampauling/flumine/blob/cd1e981c57baef58a529b624a17a7877cc67c676/flumine/execution/baseexecution.py#L127](https://github.com/liampauling/flumine/blob/cd1e981c57baef58a529b624a17a7877cc67c676/flumine/execution/baseexecution.py#L127)



Just re-visiting an issue from a while back, that I was never able to solve (related to [https://github.com/liampauling/flumine/issues/455](https://github.com/liampauling/flumine/issues/455)).



For the above, I get stuck in some infinite loops when using replace, so I'm just thinking out loud, whether as a sort of hacky quick fix, if I were to create a custom event when the instruction_report.bet_id attribute does not exist, I could presumably pick this up with a logging control and handle the logic there. Does that sound plausible (I don't see anywhere else in the source code where the error is captured, so there's no obvious other way to go about this currently)?



Also as a side note, for the replace element, should there be a check to ensure the order does exist (i.e. should line 151 be the same as line 142/143)?

*Tags: Errors Debugging*

---

## 2021-10-01

**Finn** - *08:52:55*

With MarketRecorder as my strategy, yes

*Tags: Strategies*

---

**liam** - *08:54:37*

So this uses the raw data stream where we don't create the books, you need a normal strategy if you want access to the book

*Tags: Strategies*

---

**Finn** - *08:59:50*

This might again be pointing to a misuse of flumine altogether.

*Tags: General Technical*

---

**liam** - *09:00:02*

If you want the book you would need another dummy strategy which isn't a recorder, why do you want the book?

*Tags: Strategies*

---

**Finn** - *09:07:05*

I want the book to send out of flumine for processing and storage in a db. I want the recorder so I can replay and develop that process.

*Tags: General Technical*

---

**Finn** - *09:09:01*

Performance isn’t really an issue if you can’t tell  haha

*Tags: Performance*

---

**Finn** - *09:13:52*

Is the best place to access marketbooks as they come in a strategy?

*Tags: Strategies*

---

**liam** - *09:16:35*

but if you are going to be doing slow io/network request in `process_market_book` you will have latency issues as its blocking

*Tags: Performance*

---

**liam** - *09:17:35*

best practice is



flumine -&gt; market_recorder -&gt; store in s3 (or similar cloud provider)



s3 -&gt; bflw historic data stream -&gt; db/file/analysis etc

*Tags: General Technical*

---

**liam** - *09:18:38*

the reason you split is because the second part is slow and very likely to be repeated when you realise you have forgotten to parse something, raw bflw is also very quick at processing the files

*Tags: Performance*

---

**Jonjonjon** - *10:03:45*

My Pycharm take 1 minute to load on Ubuntu even though I have a Samsung Evo 970 nvme.



It even loads faster if I do it from within a Lubunty virtual box on the same machine.



Does anyone have this problem?

*Tags: General Technical*

---

**Peter C** - *13:35:24*

If I add two strategies to one flumine instance, is market.context per strategy or do the two strategies share one context?

*Tags: Strategies*

---

**liam** - *13:36:14*

Same, `strategy.context` is what you would want

*Tags: Strategies*

---

**Peter C** - *13:37:29*

Thanks! This resolves a problem I've been experiencing since I added a second strategy

*Tags: Strategies*

---

**Jack** - *16:52:18*

Hi all :wave:



I am still having issues bringing my live strategy back up. Logs are telling me that I have too many connections open (10 apparently).

I know that I shouldn't be using any more than 4 (5 with this strategy) but old unused connections seem to be persisting forever.



Does anyone know of a way to see what connections are open and terminate them manually?

Is manual termination of connections something that people do when they pull strategies/streams down?

*Tags: Deployment, Strategies*

---

**Jack** - *16:53:09*

I should note I am on to support already and I've been asked to provide a connection IDs for an existing connections which I don't know how to get.

*Tags: General Technical*

---

**Jack** - *17:03:47*

Betfair have temporarily upped my connections to 15 so I can get my strategy running over the weekend.



I don't see how I could have - I even destroyed my old digital ocean server yesterday and moved everything over to AWS so it should all be in one place now. :confused:

*Tags: Deployment, Strategies*

---

## 2021-10-05

**JC** - *17:20:21*

Hi everyone, what's the recommended approach for working with the official atp/wta scores endpoint within flumine? Background worker that writes to market context? Is there a faster way, or one that would allow an immediate reaction to a score update rather than waiting for the next marketbook to process? Cheers

*Tags: General Technical*

---

**liam** - *19:52:56*

Worker and CustomEvent [https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py|https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py](https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py|https://github.com/liampauling/flumine/blob/master/examples/workers/inplayservice.py)

*Tags: General Technical*

---

## 2021-10-08

**EJono** - *11:02:42*

Im experiencing high latency warnings at ~100 markets on flumine. I was wondering best practices broadly speaking for strategy logic so I can improve what I have in my thus far so I can best scale up 



Should not in use market id stand be removed from the strategy?



Is the best way of timing a strategy simply a datetime time stamp comparison at the beginning and end of the process market book function?



I currently have all long running requests executing in workers, but do these effect runtime if executing too often. I have 5 running polling various APIs every 20-30 second. 



For code executing in process market book and process orders should the length of this be limited to 100 lines for example after which conflation is necessary?



Sorry for question dump, any other general pointers to improve speed would be also be greatly appreciated. Cheers!

*Tags: Performance, Strategies*

---

**Aaron Smith** - *11:32:08*

I m getting a lot of

```{"asctime": "2021-10-08 10:15:59,227", "levelname": "WARNING", "message": "High latency between current time and OrderPackage creation time, it is likely that the thread pool is currently exhausted", "trading_function": "place", "session": "&lt;requests.sessions.Session object at 0x7f6c242e3450&gt;", "latency": 0.128, "order_package": {"id": "bb7959ae-2820-11ec-8a2b-0a13a1974215", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f6c4037dc90&gt;", "market_id": "1.188799555", "orders": ["138529809590672740"], "order_count": 1, "package_type": "Place", "customer_strategy_ref": "run_dogs", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}, "thread_pool": {"num_threads": 32, "work_queue_size": 0}}```

today

*Tags: Performance, Strategies*

---

**Aaron Smith** - *11:43:52*

So to many bets placed at once is the issue? This could make sense with the new strategy i added. Any solutions for this?

*Tags: Strategies*

---

**Mo** - *11:45:20*

A couple of thoughts bearing in mind I have no idea of the flumine internals:



1. Increase the thread pool size (looks like it's 32)

2. Group the bets so you're placing multiple per placeOrders call and minimising the number of calls you're making

*Tags: General Technical*

---

**Oliver Varney** - *11:46:51*

[https://liampauling.github.io/flumine/markets/#transaction](https://liampauling.github.io/flumine/markets/#transaction)

*Tags: General Technical*

---

**Aaron Smith** - *11:47:31*

Thanks Mo. 2. sounds very reasonable in this scenario, however if i recall correctly liam already included something like that into flumine, i ll have to look into that area.

*Tags: General Technical*

---

**Lee** - *11:54:12*

Unless you're placing 50 from the same update then the thread pool should be fine. Just for context i usually have a latency, of &lt; 0.001

*Tags: Performance*

---

**Aaron Smith** - *12:01:48*

of those 50 maybe 5 match, so it probs would be a problem :smile:

*Tags: General Technical*

---

**liam** - *12:24:19*

It will handle the batching to go under the limit, using a transaction will fix this 

*Tags: Errors Debugging*

---

**Aaron Smith** - *12:48:19*

just tested, everything seems to be working fine. Thanks guys! Also this is now only a single transaction? (regarding my 5k transaction limit per hour) ? If so, thats pretty neat, both problems solved in one

*Tags: General Technical*

---

**Oliver Varney** - *12:49:09*

betfair transactions and flumine transactions

*Tags: General Technical*

---

**Aaron Smith** - *12:49:11*

mh, thats sad, but still nice i solved the main issue :smile:

*Tags: General Technical*

---

**Aaron Smith** - *12:52:56*

Yea i dont act on to many updates, so its fine for now.

Also, i completely buried [@U0154JA98TH](@U0154JA98TH)’s unanswered question, so i ll bring that back up:

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1633687362253900](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1633687362253900)

*Tags: General Technical*

---

**liam** - *13:59:30*

So few things,



• the market / order streams are in separate threads and main handles the market updates/processing so a slow strategy won’t cause conflation

• workers are also threads so don’t impact anything else (unless they are CPU heavy / bound)

• 100 markets is small and will be very light on cpu 

• check your clock is correct 

• lines are meaningless, it will be what you are doing 

• what are you doing?

• cprofilev is very good at finding slow code 

*Tags: Performance, Strategies*

---

**Oliver Varney** - *14:38:20*

this is a typical use:

```def check_market_book(self, market: Market, market_book: MarketBook) -&gt; bool:

    if market.market_type == self.strategy_market_type:

        if (market.seconds_to_start &lt;= self.max_seconds_to_off) and (market.seconds_to_start &gt;= self.min_seconds_to_off):

            if market_book.status == "OPEN":

                return True

    return False```



*Tags: Strategies*

---

## 2021-10-11

**JC** - *10:00:10*

I am wanting to place a bet in the CustomEvent callback function and need the strategy argument for the Trade object, how do I get this? Would it be more standard to update the context and have a trigger in the process marketbook function?

*Tags: Strategies*

---

**liam** - *10:19:28*

this not work?



```def callback(flumine, event):

    for market in flumine.markets:

        for strategy in flumine.strategies:

            # do something```

*Tags: Strategies*

---

## 2021-10-13

**rjj** - *14:51:42*

Anyone getting latency issues with bf streams api today? Or is it just me?

*Tags: Performance*

---

## 2021-10-14

**Paul** - *19:59:52*

The source code suggests I’m using a deprecated function anyway that will be reimplemented sometime in the future… in 2017… [https://github.com/liampauling/betfair/blob/master/betfairlightweight/endpoints/account.py#L116-L127|https://github.com/liampauling/betfair/blob/master/betfairlightweight/endpoints/account.py#L116-L127](https://github.com/liampauling/betfair/blob/master/betfairlightweight/endpoints/account.py#L116-L127|https://github.com/liampauling/betfair/blob/master/betfairlightweight/endpoints/account.py#L116-L127) :thinking_face::joy:

*Tags: General Technical*

---

## 2021-10-15

**Paul** - *18:59:07*

I actually have a bit of history with the exchange games API. Word of warning to anybody going near it: the documentation is utter crap and contains many, many lies

*Tags: General Technical*

---

## 2021-10-16

**river_shah** - *15:22:25*

Sometimes I get these which cause engines to hang. `tenacity` keeps retrying indefinitely. What is best way to detect and kill the framework after N retires if such a situation arises?



```python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 225, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "/usr/lib/python3.7/ssl.py", line 1037, in recv

    return self.read(buflen)

  File "/usr/lib/python3.7/ssl.py", line 913, in read

    return self._sslobj.read(len)

socket.timeout: The read operation timed out```



*Tags: General Technical*

---

**liam** - *15:23:50*

What version of bflw?

*Tags: General Technical*

---

**river_shah** - *15:24:14*

`betfairlightweight==2.12.1`

*Tags: General Technical*

---

## 2021-10-18

**JC** - *13:33:14*

Hi liam, one more question relating to this - what would be the recommended way to call a background worker function only once i.e. have the interval parameter to be None (or extremely large) and the while loop in the actual worker function?

*Tags: General Technical*

---

## 2021-10-19

**JC** - *12:27:54*

Sorry - another issue that has come up in backtesting is that if I add custom Middleware that retrieves scores data from S3, I get: `'An error occurred (RequestTimeTooSkewed) when calling the GetObject operation: The difference between the request time and the current time is too large.'`

I think this might be because of flumine monkeypatching datetime?

*Tags: Errors Debugging*

---

**JC** - *13:32:55*

hmm damn, let me know if you think of an easy/quick way around this!! Or how to pass a different datetime to AWS

*Tags: Deployment*

---

## 2021-10-20

**Laing Clark** - *13:01:15*

Hey guys, im new and trying to jump into this betfairlightweight module. I have successfully plugged in the right data to the initial  python code provided by betfair with the command trading.login() successfully loging into my account and returning the expected LoginResource response. However, my issue is that If I do anything else, such as use the code provided in the next step of the tutorial I get an error code to the affect of INVALID_APP_KEY. Not what I was expecting considering the bindings to the variable 'trading' work with the initial login function. I know I'm a noob but can somebody point my in the right direction.

*Tags: Errors Debugging, Strategies*

---

**Laing Clark** - *13:04:29*

```trading = betfairlightweight.APIClient(username=my_username,

                                       password=my_password,

                                       app_key=my_app_key,

                                       certs=certs_path)



print(trading.login())```



*Tags: Strategies*

---

**Laing Clark** - *13:09:58*

The exact error is:

*Tags: Errors Debugging*

---

**Laing Clark** - *13:10:00*

Error: {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie1-ang27a-prd-09020828-006d651ee0', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie1-ang27a-prd-09020828-006d651ee0', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}

*Tags: Errors Debugging*

---

## 2021-10-22

**river_shah** - *06:42:00*

[@U4H19D1D2](@U4H19D1D2) some open source packages I am using are dependent on `tenacity (&lt;=7.0.0)` is `tenacity (==8.0.1)` a hard requirement for flumine or can we relax please? getting dependency resolution issues and want to fix. thanks

*Tags: Errors Debugging*

---

**liam** - *08:23:36*

[@U01B8031PM1](@U01B8031PM1) [https://github.com/liampauling/flumine/pull/514|1.20.5](https://github.com/liampauling/flumine/pull/514|1.20.5) building now

*Tags: General Technical*

---

**Robbie Bennett** - *11:09:49*

betfair streaming problems for anyone else? getting socket timeout errors this morning

*Tags: Errors Debugging*

---

## 2021-10-24

**river_shah** - *15:51:17*

To confirm, this works, dependency resolution error goes away

*Tags: Errors Debugging*

---

## 2021-10-27

**JC** - *16:03:04*

Just been trying to run a backtest by patching open with smart_open and passing a list of s3 market file paths into the market filter. On every file after the first I get RequestTimeTooSkewed error again. Think this is because of _readloop() in FlumineHistoricalGeneratorStream using the SimulatedDateTime object when it tries to open the file?

*Tags: Errors Debugging*

---

**JC** - *16:58:31*

managed to get it to work by adding the context manager in source code before line `for event in stream_gen():` in backtest.py. Using more standard context manager, e.g.

```with framework.simulated_datetime.real_time():

    with mock.patch("builtins.open", smart_open.open):

        framework.add_strategy(strategy)

        framework.run()```

, results in errors.

*Tags: Errors Debugging, Strategies*

---

## 2021-10-28

**liam** - *09:08:50*

Ah, it temporary converts the datetime back to the 'real' datetime rather than the backtest datetime, I am not sure if you can use an s3 path because of this unless smart open caches the file, does this work?



```with mock.patch("builtins.open", smart_open.open):

    with framework.simulated_datetime.real_time():

        framework.add_strategy(strategy)

    framework.run()```

*Tags: Strategies*

---

**JC** - *10:38:22*

Running that gives AttributeError: 'NoneType' object has no attribute 'utcnow'. It did fix it by adding the context manager in source but this may mess up other things? Seems ok for just generating dataframes but not sure about simulated orders etc.

*Tags: Errors Debugging, Feature Engineering*

---

**liam** - *14:19:34*

Can you create an issue, I think this could be fixed with a code change in flumine

*Tags: Errors Debugging*

---

## 2021-10-29

**liam** - *10:33:10*

Same problem with that market, starts suspended and then goes straight inplay

*Tags: General Technical*

---

**mandelbot** - *10:38:44*

Is this a problem with the market itself or how I'm recording them?

*Tags: General Technical*

---

**liam** - *12:07:09*

Simple fix [https://github.com/liampauling/flumine/pull/520/files](https://github.com/liampauling/flumine/pull/520/files)

*Tags: Errors Debugging*

---

## 2021-10-31

**Ruben** - *09:22:26*

Good morning, whenever I try to place a passive limit order, I am getting the following error `"ERROR": "Execution error": nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0: {'code': -32602, 'message': 'DSC-0018'}`

*Tags: Errors Debugging*

---

**Ruben** - *09:22:49*

In the documentation, it sais that this error means "Problem parsing the parameters, or a mandatory parameter was not found"

*Tags: Errors Debugging*

---

**Dave** - *09:53:42*

Maybe bflw ought to have a these constants built in :eyes:

*Tags: General Technical*

---

## 2021-11-03

**Peter C** - *07:35:11*

Is anyone else getting api errors this morning? I have some errors I don't usually see on one of my connections

*Tags: Errors Debugging*

---

**Peter C** - *07:47:47*

Thanks for checking. I'm getting socket read operation timed out/connection reset by peer which is leading to max connection limit exceeded errors on the market/order stream. Seems ok after a restart, but it's not behaviour I've seen before

*Tags: Errors Debugging*

---

**Peter C** - *07:56:18*

Fair enough, thanks Liam. I see the socket errors regularly, but it's unusual for them to appear to lead to max connection errors and require a restart. Seems ok after a restart though

*Tags: Errors Debugging*

---

**liam** - *08:01:48*

bflw version?

*Tags: General Technical*

---

**V** - *18:56:46*

Remind me what the play is when you hit a SUBSCRIPTION_LIMIT_EXCEEDED error? Email Betfair to have it bumped or add more processes?

*Tags: Errors Debugging*

---

## 2021-11-07

**Jimmy** - *20:03:02*

Hello. Still getting to grips with python and wondered if anyone one could help?



```datetime,marketid,selectionid,back,lay,selection_matched```

*Tags: General Technical*

---

## 2021-11-09

**Oliver Varney** - *13:47:54*

lol quite funny as I got sent a survey/ questionnaire from betfair this morning and these were the kind of questions they had on them. something like "have you been effected by markets not turning in play" and how do you feel

*Tags: General Technical*

---

## 2021-11-11

**captainonionhead** - *10:15:00*

Morning, I have a market recorder based upon the flumine example.  It keeps receiving `INVALID_SESSION_INFORMATION` errors from the market-catalogue polling thread after it has been running for a while.

Is this expected - do I simply need to catch the exception and login again or is there something more fundamentally wrong with my setup?

Thanks!

*Tags: Getting Started, Data Quality, Errors Debugging*

---

**captainonionhead** - *10:18:12*

Sorry, do you mean how am I adding the recorder strategy to the framework?

*Tags: Strategies*

---

**liam** - *10:19:24*

flumine will keep the session active via the worker

*Tags: General Technical*

---

**liam** - *10:19:32*

you getting any other errors in the logs before this?

*Tags: Errors Debugging*

---

**captainonionhead** - *10:20:51*

Yes, I thought the keepalive thread should stop this...  My client init looks like:

```  trading = betfairlightweight.APIClient(

    creds["username"],

    creds["password"],

    creds["app_key"],

    creds["certs"]

  )



  client = clients.BetfairClient(

    trading,

    order_stream=False,

    market_recording_mode=True

  )



  framework = Flumine(client=client)```



*Tags: Deployment, Strategies*

---

**captainonionhead** - *10:21:45*

This is the first error in the logs and it is a UK account

*Tags: Errors Debugging*

---

**captainonionhead** - *10:24:48*

I don't see any error messages from the market streams so it only seems to apply to the market-catalogue polling?

*Tags: Errors Debugging*

---

**liam** - *10:25:03*

yeah streaming still works even if the session expires

*Tags: General Technical*

---

**liam** - *10:45:54*

what version of flumine are you using?

*Tags: General Technical*

---

**captainonionhead** - *10:55:27*

flumine: 1.20.8

betfairlightweight: 2.15.0

*Tags: General Technical*

---

**captainonionhead** - *11:00:43*

It's a fresh install a few days ago in a newly built VPS whilst I work out how to get AWS up and running so I thought I was up-to-date with everything.

*Tags: Getting Started, Deployment*

---

**liam** - *11:19:22*

so bumping that should fix it

*Tags: Errors Debugging*

---

**captainonionhead** - *11:30:57*

I can't see anything in the accounts API documentation :confused:

*Tags: General Technical*

---

**captainonionhead** - *12:59:13*

Just to follow up - having restarted, it has just passed the 2 hour mark with no errors yet, so looks like that was the issue.  Thanks again!

*Tags: Errors Debugging*

---

## 2021-11-12

**Paul** - *19:25:07*

I'm trying to lay to a payout as per [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders#placeOrders-BettoPayoutorProfit/Liability](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders#placeOrders-BettoPayoutorProfit/Liability) but getting an error I can't see through

*Tags: Errors Debugging*

---

**Paul** - *19:26:17*

`Params: {'marketId': '1.190674050', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 20216110, 'side': 'LAY', 'limitOrder': {'price': '23', 'size': '10', 'betTargetType': 'PAYOUT'}}]}` results in:

```Exception: None

Error: {'code': -32099, 'message': 'ANGX-0002', 'data': {'APINGException': {'requestUUID': 'ie2-ang26a-prd-11021016-0015bdce7c', 'errorCode': 'INVALID_INPUT_DATA', 'errorDetails': 'One or more inputs to the operation were invalid'}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0002', 'data': {'APINGException': {'requestUUID': 'ie2-ang26a-prd-11021016-0015bdce7c', 'errorCode': 'INVALID_INPUT_DATA', 'errorDetails': 'One or more inputs to the operation were invalid'}, 'exceptionname': 'APINGException'}}, 'id': 1}```



*Tags: Errors Debugging*

---

**Beeblebrox** - *19:41:54*

No problem. Been there done that! :joy:

*Tags: General Technical*

---

## 2021-11-15

**C0rnyFlak3s** - *21:17:39*

I have a problem with the Historical API downloading my historical data. I am communicating via the requests lib in python and commands like ‘GetMyData’ or ‘GetCollectionOptions’ work fine, however once I try to run ‘DownloadListOfFiles’ with my filter as input the API returns with an error which is not specified. I am currently using the Delay Application Key and try to download free historical Data which I already “purchased” (in reality it was a free data set). Any ideas?

*Tags: Data Quality, Errors Debugging*

---

**Mo** - *21:23:10*

And why aren’t you using betfairlightweight?

*Tags: General Technical*

---

**C0rnyFlak3s** - *21:30:17*

oh wow I just figured the problem. I was using a start date which was 1 day prior to where my free data started. this start date didn’t cause any problem with the other calls and filtering and everything worked fine, however with the download list request there must be some parsing problem on the betfair backend, since I change the start date to a date within the free data range it now works

*Tags: General Technical*

---

## 2021-11-20

**John** - *23:12:33*

Hi folks, I am new to this forum. I have an issue very similary to the *[https://app.slack.com/team/U02KWHK2H89|C0rnyFlak3s](https://app.slack.com/team/U02KWHK2H89|C0rnyFlak3s)* one.  However, I use the betfairlightweight library and the code from the examples.  Here is the code snippet and the error I get:

*Tags: Getting Started, Errors Debugging*

---

**John** - *23:13:16*

```JSONDecodeError: expected value at line 2 column 1: line 2 column 1 (char 1)```



*Tags: Errors Debugging*

---

## 2021-11-21

**John** - *12:37:21*

I have narrowed down from March 30 2017 to March 31 2017 and still got the same error

*Tags: Errors Debugging*

---

**John** - *12:45:39*

Also get

```InvalidResponse: Invalid response received: 

&lt;title&gt;ngErrorRedirect&lt;/title&gt;```

Is it related to the purchase of data?

*Tags: Errors Debugging*

---

## 2021-11-22

**AP** - *21:26:29*

Hi all, I am trying to run [@U4H19D1D2](@U4H19D1D2)'s data collection example from a little while back. But I'm getting some issues where the code is setting up the client and adding the strategy but not actually running the data collection.

*Tags: Strategies*

---

**AP** - *21:26:48*

```import csv

import logging

import os

from flumine.strategy.strategy import BaseStrategy

from flumine.utils import get_sp, get_price

from inplay_bot.util import calculate_vwap_runner_book



logger = logging.getLogger(__name__)



FIELDNAMES = [

    "publish_time",

    "market_id",

    "market_venue",

    "market_name",

    "market_seconds_to_start",

    "market_total_matched",

    "active_runners",

    "selection_id",

    "selection_back",

    "selection_lay",

    "selection_wom_one",

    "selection_wom_two",

    "selection_wom_three",

    "selection_vwap",

    "selection_ltp",

    "selection_total_matched",

    "selection_status",

    "selection_actual_sp",

]





class DataCollectWOM(BaseStrategy):

    """

    Collect market/runner data every

    x update_seconds.

    """



    def __init__(self, *args, **kwargs):

        BaseStrategy.__init__(self, *args, **kwargs)

        self.local_dir = "/home/antonypapadimitriou/betfair_data_collection"



    def add(self) -&gt; None:

        self.context["_data"] = []

        self.context["pt"] = 0

        # check local dir

        if not os.path.isdir(self.local_dir):

            raise OSError("File dir %s does not exist" % self.local_dir)



    def check_market_book(self, market, market_book) -&gt; bool:

        if market_book.status != "OPEN":

            return False

        if market_book.inplay:

            return False

        if "data" not in market.context:

            market.context["data"] = {}

        # check update seconds

        update_seconds = self.context["update_seconds"]

        pt = self.context["pt"]

        if market_book.publish_time_epoch - pt &gt; (update_seconds * 1000):

            self.context["pt"] = market_book.publish_time_epoch

            return True

        return False



    def process_market_book(self, market, market_book) -&gt; None:

        for runner in market_book.runners:

            if runner.status == "ACTIVE":

                # get prices

                back, lay = self._get_back_lay(runner)

                # calculate WOM

                wom_one = self._calculate_wom(runner, 1)

                wom_two = self._calculate_wom(runner, 2)

                wom_three = self._calculate_wom(runner, 3)

                # calculate VWAP

                vwap = calculate_vwap_runner_book(runner.ex.traded_volume)

                # store data in context

                data = {

                    "publish_time": market_book.publish_time,

                    # market

                    "market_id": market.market_id,

                    "market_venue": market_book.market_definition.venue,

                    "market_name": market_book.market_definition.name,

                    "market_seconds_to_start": market.seconds_to_start,

                    "market_total_matched": market_book.total_matched,

                    "active_runners": market_book.market_definition.number_of_active_runners,

                    # selection

                    "selection_id": runner.selection_id,

                    # current state

                    "selection_back": back,

                    "selection_lay": lay,

                    "selection_wom_one": wom_one,

                    "selection_wom_two": wom_two,

                    "selection_wom_three": wom_three,

                    "selection_vwap": vwap,

                    "selection_ltp": runner.last_price_traded,

                    "selection_total_matched": runner.total_matched,

                    # after

                    "selection_status": None,

                    "selection_actual_sp": None,

                }

                self.context["_data"].append(data)



    def process_closed_market(self, market, market_book):

        # get runner status (status and BSP)

        status = {}

        for runner in market_book.runners:

            status[runner.selection_id] = (runner.status, get_sp(runner))

        # write data to csv

        filename = os.path.join(self.local_dir, f"{market_book.market_id.split('.')[-1]}.csv")

        is_new = not os.path.exists(filename)

        with open(filename, "a", newline="") as f:

            writer = csv.DictWriter(f, delimiter=",", fieldnames=FIELDNAMES)

            if is_new:

                writer.writeheader()

            for d in self.context["_data"]:

                _status = status.get(d["selection_id"])

                d["selection_status"], d["selection_actual_sp"] = _status

                writer.writerow(d)

        self.context["_data"].clear()



    @staticmethod

    def _get_back_lay(runner_book, level: int = 0) -&gt; tuple:

        if runner_book is None:

            return None, None

        back = get_price(runner_book.ex.available_to_back, level)

        lay = get_price(runner_book.ex.available_to_lay, level)

        return back, lay



    @staticmethod

    def _calculate_wom(runner_book, depth: int) -&gt; float:

        total_atb, total_atl = 0, 0

        for i in range(0, depth):

            # back

            p = runner_book.ex.available_to_back[i]

            total_atb += p["size"]

            # lay

            p = runner_book.ex.available_to_lay[i]

            total_atl += p["size"]

        if total_atb + total_atl &gt; 0:

            return round(total_atb / (total_atb + total_atl), 4)

        else:

            return 0```

*Tags: Errors Debugging, Strategies*

---

**AP** - *21:26:58*

That's the strategy

*Tags: Strategies*

---

**AP** - *21:28:27*

Here are some logs, there are no errors:

```{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding market middleware &lt;flumine.markets.middleware.SimulatedMiddleware object at 0x7f81a8794640&gt;"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding market middleware &lt;flumine.markets.middleware.SimulatedMiddleware object at 0x7f81a8794730&gt;"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding market middleware &lt;flumine.markets.middleware.SimulatedMiddleware object at 0x7f81a8794820&gt;"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding client control MAX_TRANSACTION_COUNT"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding strategy DataCollectWOM"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}```

*Tags: Errors Debugging, Strategies*

---

**AP** - *21:28:59*

This is the script I am using to kick it off if it helps

*Tags: General Technical*

---

**AP** - *21:29:05*

```import smart_open

import os

import time

import logging

from unittest.mock import patch

from concurrent import futures

from pythonjsonlogger import jsonlogger

from flumine import FlumineBacktest, clients



from inplay_bot.backtest.strategies.data_collection import DataCollectWOM

from inplay_bot.backtest import MARKET_IDS



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))





def run_backtest(market):

    client = clients.BacktestClient()

    client.min_bet_validation = False

    framework = FlumineBacktest(client=client)



    strategy = DataCollectWOM(

            market_filter={

                "markets": [market],

                "listener_kwargs": {

                    "seconds_to_start": 600,

                    "calculate_market_tv": True,

                    "cumulative_runner_tv": True,

                },

            },

            context={

                "update_seconds": 5,

            }

    )



    framework.add_strategy(strategy)



    with patch("builtins.open", smart_open.open):

        framework.run()





if __name__ == "__main__":

    path = "/home/antonypapadimitriou/betfair"

    markets = []

    win_market_ids = MARKET_IDS



    for root, dirs, files in os.walk(path):

        for file in files:

            if file.split(".bz2")[0] in win_market_ids:

                markets.append(os.path.join(root, file))



    with futures.ProcessPoolExecutor(max_workers=48) as pool:

        all_futures = [

            pool.submit(

                run_backtest,

                market=market

            )

            for market in markets

        ]



    for i, future in enumerate(futures.as_completed(all_futures)):

        try:

            print('Future %i of %i completed' % (i + 1, len(all_futures)))

        except:

            print('Error %i of %i' % (i + 1, len(all_futures)))```

*Tags: Errors Debugging, Strategies*

---

**liam** - *21:29:42*

That strategy isn’t coded for multi processing 

*Tags: Strategies*

---

**AP** - *21:37:34*

What would be the required changes to that strategy to allow it to use multi processing?

*Tags: Strategies*

---

## 2021-11-23

**mandelbot** - *07:03:51*

So it seems MarketOnCloseOrders aren't being cleared properly on flumine because no price

`{"asctime": "2021-11-23 06:57:50,183", "levelname": "ERROR", "message": "_process_cleared_orders_meta: 'MarketOnCloseOrder' object has no attribute 'price'", "order": "Order 251408671038: Execution complete", "error": "'MarketOnCloseOrder' object has no attribute 'price'"}`

Maybe this is why they aren't making it to the logging control?

*Tags: Errors Debugging*

---

**AP** - *20:27:49*

If anyone is interested, changing this:



```with futures.ProcessPoolExecutor(max_workers=48) as pool:

        all_futures = [

            pool.submit(

                run_backtest,

                market=market

            )

            for market in markets

        ]



    for i, future in enumerate(futures.as_completed(all_futures)):

        try:

            print('Future %i of %i completed' % (i + 1, len(all_futures)))

        except:

            print('Error %i of %i' % (i + 1, len(all_futures)))```

*Tags: Errors Debugging*

---

## 2021-11-26

**Tom** - *00:53:48*

Recently tried deploying a flumine strategy (which works well locally) to an AWS machine and was experiencing some of the same latency warnings I've seen posted above: `"... High latency between current time and MarketBook publish time", "market_id": "...", "latency": 53.55.."` which sort of continually escalates to the point the strategy was acting on market book updates from 30 seconds prior. CPU utilization was pretty high (40-50%) on a EC2 t3a.medium but not enough to cause this huge bottleneck I thought but i tried it on a EC2 t3a.2xlarge and experienced the same behaviour.



Took the advice to profile the code using cProfile and the biggest difference was the `process_orders` calls [ `baseflumine.py:220(_process_current_orders)` and `process.py:33(process_current_orders)` ] were completing in approx 10ms per call locally but 350ms on the AWS machine. Any ideas why this might be happening? Or anything i can do to clean out + speed up `process_orders` generally? Strategy is pretty order heavy so the partial fills and price updates etc start adding up to a big order list for each market but flumine seems to barely feel it locally.

*Tags: Performance, Deployment, Strategies*

---

**liam** - *07:08:25*

Are you able to share the full cprofile from ec2? How many orders? CPU seems very high 

*Tags: Deployment*

---

**liam** - *11:43:21*

I assume this in your strategy somewhere, can you remove it or refactor?

*Tags: Strategies*

---

**liam** - *11:44:32*

[https://github.com/liampauling/flumine/blob/545ae68f20fc44b6a5d5abeb7c11a22380363498/flumine/markets/blotter.py#L31](https://github.com/liampauling/flumine/blob/545ae68f20fc44b6a5d5abeb7c11a22380363498/flumine/markets/blotter.py#L31)

*Tags: General Technical*

---

**C0rnyFlak3s** - *14:29:15*

Providing ‘market_types’ to the market_filter of a strategy seems to not have any effect in the FlumineBacktest framework. I tried to filter the multi-market file of the historical PRO data from betfair for specific market_types, however without success. Anyone experiencing similar issues?

*Tags: Strategies*

---

**liam** - *14:30:38*

what flumine version?

*Tags: General Technical*

---

**Unknown** - *14:34:37*

Here is a minimal example. Flumine version 1.20.7 used

*Tags: General Technical*

---

**liam** - *14:39:32*

yeah this is a limitation, flumine will read the first md it finds, so this all falls down if you have an event file

*Tags: General Technical*

---

**C0rnyFlak3s** - *14:46:15*

Alright, deleting the event file from the data folder, yielded desired result. However one more problem remains. having the ‘event_processing’ set to True in the market_filter, doesn’t yield any marketBook updates. Why could that be?

*Tags: General Technical*

---

**C0rnyFlak3s** - *14:57:35*

alright I get it now. Thanks this was very helpful.

*Tags: General Technical*

---

**liam** - *15:41:44*

Flumine sorts the order 

*Tags: General Technical*

---

**C0rnyFlak3s** - *16:00:46*

Weirdly flumine does not recognize the new file as either Market file nor event file, but it runs with both ‘event_processing’ True and False.

*Tags: General Technical*

---

**Aaron Smith** - *16:00:49*

I ve been reconstructing some things and have been offline for a few days. Now i tried to get things running again, but the log in fails. Its the same code as before. How would i go about debugging this?

*Tags: Errors Debugging*

---

**C0rnyFlak3s** - *16:05:17*

Apparently in order to be recognized as either a Market file or an Event file the naming of given file, has to match the usual betfair naming convention. This helped me getting my merged file being recognized as event file, however it still doesn’t give me the concurrent updates for both markets, but only a sequential update

*Tags: General Technical*

---

**Aaron Smith** - *16:57:57*

I am using certs to log in, i dont get any error message, even though it looks like i should.

*Tags: Errors Debugging*

---

**Lee** - *16:59:37*

Have you tried logging using bflw and making any api call?

*Tags: General Technical*

---

**birchy** - *17:01:54*

[@U01DVUAE2G1](@U01DVUAE2G1) presuming you haven't changed the login code, SSL paths, etc it _might_ be that your certs have expired at Betfair's end. I had to rebuild &amp; reload mine earlier this year.

For debugging, if using pycharm, you can set a breakpoint and step into the Flumine code to follow the rabbit hole. :rabbit:

*Tags: Errors Debugging*

---

**Aaron Smith** - *17:04:34*

[@U016TGY3676](@U016TGY3676) did you get any error msg when your certs expired?

*Tags: Errors Debugging*

---

**Aaron Smith** - *17:10:45*

i just checked and on my local pc i actually can log in (same code), its just on my aws ec2 where it fails.

*Tags: Deployment*

---

**birchy** - *17:13:29*

Weird, something must be different on the AWS setup. Probably something simple like a slightly different directory structure. Can you ping the API server from AWS? Or even load the website with `wget`?

*Tags: Getting Started, Deployment*

---

**Aaron Smith** - *17:18:41*

```def get_betfair_client():

    client = betfairlightweight.APIClient(BETFAIR_USER_EMAIL,

                                           BETFAIR_PASSWORD,

                                           app_key=BETFAIR_APP_KEY,

                                           cert_files=CERT_PATHS,

                                           lightweight=False)

        client.login()

    except:

        try:

            time.sleep(1)

            client.login()

        except:

            try:

                time.sleep(1)

                client.login()

            except:

                logging.warning('log in failed')

                return

            

    return client



client = get_betfair_client()

assert client```

*Tags: Errors Debugging*

---

**Aaron Smith** - *17:19:56*

client.login() fails on aws but succeeds locally

*Tags: Deployment*

---

**birchy** - *17:20:30*

What about the curl command via AWS?

*Tags: Deployment*

---

**Mo** - *17:21:01*

It's going to be more useful than some Python code where you discard both the return value and the exception...

*Tags: Errors Debugging*

---

**Mo** - *17:21:31*

Are you running Linux in AWS?

*Tags: Deployment*

---

**Aaron Smith** - *17:22:14*

yeah, i wanted to check the return value, but shouldnt the error still show for the client.login() or does it not because its in an try/except?

*Tags: Errors Debugging*

---

**Aaron Smith** - *17:36:47*

on aws i get:

url: (58) could not load PEM client certificate, OpenSSL error error:140AB18E:SSL routines:SSL_CTX_use_certificate:ca md too weak, (no key found, wrong pass phrase, or wrong file format?)

*Tags: Errors Debugging, Deployment*

---

**Lee** - *17:37:58*

sounds like you have a newer ssl version on aws

*Tags: Deployment*

---

**birchy** - *17:42:07*

Ah, yessss, that was the issue I had. It was OpenSSL being newer on AWS. Update your local OpenSSL, regenerate the certs and upload to Betfair.

Actually, update OpenSSL first and run the code as-is to prove that's the issue.

*Tags: Deployment*

---

**Mo** - *17:42:10*

And you will generate them on AWS using the newer version of OpenSSL

*Tags: Deployment*

---

**birchy** - *17:59:16*

And then I discovered Flumine. Been downhill ever since. :joy:

*Tags: General Technical*

---

**C0rnyFlak3s** - *19:04:17*

Any idea what the problem may be? [@U4H19D1D2](@U4H19D1D2)

*Tags: General Technical*

---

## 2021-11-27

**mandelbot** - *15:50:17*

I am trying to open a new connection but keep getting "MAX_CONNECTION_LIMIT_EXCEEDED" errors. I only have two instances of flumine running and 1 connection via website. What could be causing this issue?

*Tags: Errors Debugging*

---

**D C** - *16:52:04*

Don't use flumine so can't say for sure but when I  used to get this message it was because of multiple consecutive reconnection/connection attempts without any throttling.

*Tags: General Technical*

---

**Martin Karlsson** - *23:15:41*

How do I stream both order and market updates at the same time?



I've tried to modify the example in [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py) but I'm too much of a novice to get it right... =(



My approach has been to create two separate Streaming classes like the one in the above example – one for markets and one for orders. These classes share the same output_queue.



I then check if the output received is of instance MarketBook or CurrentOrders to separate the workflow.



```# Getting market stream

market_streamer = MyMarketStreamer(

  client=self.connection.trading,

  cm_queue=cm_queue,

  market_filter=market_filter,

  market_data_filter=market_data_filter,

)



# Getting order stream

order_streamer = MyOrderStreamer(

  client=self.connection.trading,

  cm_queue=cm_queue,

)



# Starting the streams

market_streamer.start()

order_streamer.start()



# Receiving the stream

while True:

   outputs = cm_queue.get()



   for output in outputs:

      if isinstance(output, MarketBook):

         self.handle_market_changes(mcm=output.streaming_update)

      elif isinstance(output, CurrentOrders):

         self.handle_order_changes(ocm=output.streaming_update)```

This seems to be working just fine except for when it comes to the error handling: then it just stops without retrying.



Maybe this should be done in a completely different manner?



Any help would be greatly appreciated!

*Tags: Errors Debugging, Strategies*

---

## 2021-11-28

**Martin Karlsson** - *09:50:16*

Ok, so something like this?



*# 1. Setting up two connections*

connection_for_markets = betfairlightweight.APIClient(…)

connection_for_orders = betfairlightweight.APIClient(…)



*# 2. Creating one queue for both outputs*

my_combined_queue = queue.Queue()



*# 3. Creating the market streamer*

market_streamer = MyMarketStreaming(

	client=connection_for_markets.trading,

	cm_queue=my_combined_queue,

	...

)



*# 4. Creating the order streamer*

order_streamer = MyOrderStreaming(

	client=connection_for_orders.trading,

	cm_queue=my_combined_queue,

	...

)



*# 5. Starting the streams*

market_streamer.start()

order_streamer.start()



*# 6. Receiving the streams*

while True:

	outputs = my_combined_queue.get()

*Tags: Strategies*

---

**liam** - *17:57:41*

Yep that will work but you have no error handling and fairly sure .start is blocking from memory 

*Tags: Errors Debugging, Performance*

---

## 2021-11-29

**Martin Karlsson** - *20:57:26*

The error handling is done in MyMarketStreaming() and MyOrderStreaming(). These two classes are variants of the example in [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py |examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py |examplestreamingerrhandling.py).



I have been running it for a day now and it seems to be working as I hoped. One typical error occured in market streaming (read time out) and the connection retried and successfully reconnected.

*Tags: Errors Debugging*

---

**Martin Karlsson** - *21:07:50*

But I did encounter a new error that I have not noticed before:



ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1129)



For some reason this particular error broke the error handling and did not lead to a reconnect.



I searched for the error here on Slack and it seems like more people have encountered it but I could not find any solution?



By the way: I really appreciate your work with Betfairlightweight!

*Tags: Errors Debugging*

---

**Martin Karlsson** - *21:11:47*

The EOF error suddenly occured when the bot tried to cancel an order. Before that, the same type of action had been performed multiple times flawlessly and I can’t figure out what was different this time.

*Tags: Errors Debugging*

---

## 2021-11-30

**C0rnyFlak3s** - *12:15:55*

Has anyone experienced issues with purchasing data from betfair so far? I am currently running into a problem where on the last step (confirming the purchase) I get an error code: 0x05479P . Unfortunately the support response either doesn’t help or is slow to begin with. They for now just told me to clear the cache and cookies, but without success. Any ideas? :slightly_smiling_face:

*Tags: Errors Debugging, Performance*

---

**Aaron Smith** - *20:43:27*

Hey ppl, last few days i m getting flooded with both

```"WARNING", "message": "[MarketStream: 2001]: Latency high: 9.45749306678772"}```

and

```"WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.191643732", "latency": 13.961846351623535, "pt": "2021-11-30T18:37:48.781000"}```

First, i would like to understand the difference between the two. Both compare current time to publish time, but i recall them being different in some way.

Also any leads on how to approach this problem are appreciated. I ve got flumine running on aws (eu-west-1b), newly set up the servers (but also was on aws before). I m running t2-micro instances. CPU utilization seemingly never goes higher than 6%. The strategies are also very light in terms of computing time. Could the internet connection/bandwidth of the ec2-instances be a limiting factor?

Also, i realized, instead of piling up latency (as in getting more and more behind on each update), it seems to jump from 0 to 20 seconds (and then gradually gets lower), which seemed like an odd behaviour to me.

*Tags: Performance, Deployment*

---

**liam** - *20:45:59*

Top one is from bflw itself and second is from flumine, the fact you have the top one means it’s either network or CPU as opposed to something blocking in flumine 

*Tags: General Technical*

---

**Aaron Smith** - *20:56:45*

so, given cpu is at 6%, its got to be network which i would have to solve on aws level? get an instance with better bandwidth?

*Tags: Deployment*

---

**Tom** - *21:32:18*

Thanks Liam. Turns out that `get_order_from_bet_id` bottleneck was *a* bottleneck but not *the* bottleneck that was causing my issues. I managed to get my `process_market_book` step down to an average of 1-5ms from 10-40ms by removing some pandas objects and using blotter exposures rather than calculating the matched exposures from the orders myself. Seems to have done the trick runs only like 10% CPU utilisation on a 2vCpu 4 Gb ram machine now and none of these accumulating latency issues

*Tags: Feature Engineering, Performance*

---

**liam** - *21:36:22*

First try rotating, do you get a network spike or drop during the time of the errors?

*Tags: Errors Debugging*

---

**Tom** - *21:37:20*

If i wanted to minimise the `get_order_from_bet_id`  impact would i just have to write a custom _`_process_current_orders`_  function and replace this bit?[https://github.com/liampauling/flumine/blob/545ae68f20fc44b6a5d5abeb7c11a22380363498/flumine/order/process.py#L59](https://github.com/liampauling/flumine/blob/545ae68f20fc44b6a5d5abeb7c11a22380363498/flumine/order/process.py#L59)

*Tags: General Technical*

---

**Aaron Smith** - *21:45:00*

Network out in bites has some spikes, but rather than spikes i d say its "spikey" all over with rather consistent spike height, doesnt seem to correlate with the latency times

*Tags: Performance*

---

## 2021-12-01

**liam** - *07:57:28*

Hmm, do you have lots of orders in the market and you are restarting flumine numerous times?

*Tags: General Technical*

---

**Peter C** - *13:59:29*

I'm running a new strategy file today on inplay horses. It uses the field

```runner.last_price_traded```

but I'm running into trouble because this is always None. Below is the streaming filter I'm using

```market_data_filter=streaming_market_data_filter(fields=["EX_MARKET_DEF", "EX_ALL_OFFERS", "EX_TRADED"])```

I can't for the life of me work out why runner.last_price_traded never has a value when live (worked in backtests) - Does anyone know why this might be?

*Tags: Deployment, Strategies*

---

## 2021-12-03

**liam** - *09:01:44*

I was wrong (forgot how this worked), flumine will handle this correctly, for example you just pass the market files:



```strategy = ExampleStrategy(

    market_filter={

        'markets': ["match_odds.txt", "correct_score.txt", ...],

       'listener_kwargs': {'inplay': False, 'seconds_to_start': 600},

       'calculate_market_tv': True,

       'cumulative_runner_tv': True,

       'event_processing': True

    }

)```

The event professing flag will then force flumine to process the files sequentially per eventId

*Tags: Strategies*

---

**liam** - *10:51:26*

I also added a regression by mistake on the validation, 1.20.13 will fix this

*Tags: Errors Debugging*

---

## 2021-12-06

**birchy** - *07:45:41*

Bit of a weird problem this morning. Went to restart my marketrecorder that's been running for months and am getting this on startup:

`Traceback (most recent call last):

  File "data_recorder.py", line 118, in &lt;module&gt;

    framework.run()

  File "/home/ubuntu/.local/lib/python3.6/site-packages/flumine/flumine.py", line 29, in run

    self._process_raw_data(event)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/flumine/baseflumine.py", line 203, in _process_raw_data

    strategy.process_raw_data(clk, publish_time, datum)TypeError: process_raw_data() takes 3 positional arguments but 4 were given`

Not on my pc, so unable to debug ATM.

Flumine: 1.20.13

Bflw: 2.15.2

*Tags: Errors Debugging, Strategies*

---

**Newbie99** - *20:24:05*

This error has come up a few times recently, when the market cleared event is processed:



```

{"asctime": "2021-12-06 14:30:14,617", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/worker.py\", line 234, in _get_cleared_market\n    group_by=\"MARKET\",\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.192009763'], 'customerStrategyRefs': ['ip-172-31-4-105'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-10290844-0055b9d69e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-10290844-0055b9d69e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.192009763'], 'customerStrategyRefs': ['ip-172-31-4-105'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-10290844-0055b9d69e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-10290844-0055b9d69e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

All I'm doing is the following (using the Closed Market Logging example):



```    def _process_cleared_markets(self, event):

        for market in event.event.orders:

            market_id = market.market_id

            file_path = market_closed_report_path + '/' + str(market_id) + '_cleared_market_data.json'

            cleared_market_data = {'market_id': market_id,

                                  'market_profit': market.profit,

                                  'market_com': market.commission

                                 }



            check_and_create_json(file_path, cleared_market_data)```

But the error looks like Flumine is making an incorrectly constructed API call to Betfair if I'm reading that correctly?

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2021-12-07

**liam** - *08:09:35*

[@UFTBRB3F1](@UFTBRB3F1) unless there is a persistent problem and/or flumine is restarted the code will continue to try and get a response, code [https://github.com/liampauling/flumine/blob/bdd46e21b4015779bdccc30bbd5c0f1f86c90d79/flumine/worker.py#L182|here](https://github.com/liampauling/flumine/blob/bdd46e21b4015779bdccc30bbd5c0f1f86c90d79/flumine/worker.py#L182|here)

*Tags: General Technical*

---

## 2021-12-08

**Tom** - *03:02:19*

yep that looks to have completely fixed it. Thanks heaps liam

*Tags: Errors Debugging*

---

## 2021-12-15

**Ruben** - *14:18:44*

Looking at the S3MarketRecorder from the flumine repo, I can't seem to find where are credentials/keys passed to the class for it to authenticate. I see that you can pass the bucket name to it as part of the context though, but no credentials. What am I missing?

*Tags: General Technical*

---

**Ruben** - *14:24:25*

maybe is it supposed to be run from an ec2 instance that has been given access to the bucket and hence nothing else is needed?

*Tags: Deployment*

---

**Mo** - *14:26:18*

bflw defaults to looking for the credentials in your .bashprofile

*Tags: General Technical*

---

**Peter** - *14:27:16*

boto3 can also pick them up automatically from

```.aws/credentials```

*Tags: Deployment*

---

**Peter** - *14:28:57*

Or if you want to make it more explicit, you could start your S3MarketRecorder like this:

```class S3MarketRecorder(MarketRecorder):

    def __init__(self, *args, **kwargs):

        MarketRecorder.__init__(self, *args, **kwargs)

        self._bucket = self.context["bucket"]

        self._data_type = self.context.get("data_type", "marketdata")

        self.s3 = boto3.Session(

            aws_access_key_id=os.getenv("AWS_ACCESS_KEY"),

            aws_secret_access_key=os.getenv("AWS_SECRET")

        ).client("s3")

        transfer_config = TransferConfig(use_threads=False)

        self.transfer = S3Transfer(self.s3, config=transfer_config)```

*Tags: Deployment*

---

**birchy** - *18:13:01*

Interestingly, I use `.aws/credentials` and also `.betfair/credentials`, which is something I setup when I first started using Flumine ~12 months ago. I've never used the environment variables for username, password, etc. Just wondering how you guys normally SET these values? I know it can be done from the terminal but am wondering if you're automating it or entering manually?

*Tags: Getting Started, Deployment*

---

**Mo** - *18:31:18*

If using environment variables I will set them as part of running the command a la `AWS_PROFILE=xxx python -m ...`

*Tags: Deployment*

---

**KG** - *22:40:04*

[!here](!here) *outage notification* :rotating_light: related to yesterday’s unplanned outage, there will be two planned *one minute outages* this morning; during each minute any bets placed will return errors, so please be aware that this might be a test of your error handling! apologies for this, hopefully the bad run finishes soon! :confounded:



*the two one minute outages will happen between 6:45 - 7:45 BST Thursday, 16 December* 

*Tags: Errors Debugging*

---

## 2021-12-16

**Jonjonjon** - *21:43:31*

Is there anything obviously wrong with this market filter? When I use it, I get back markets with country code GB, and marketTypeCode WIN. I'm aware that this is probably a user error, but I can't work out what my error is:



`{'eventTypeIds': [7], 'marketCountries': ['AU', 'NZ'], 'marketTypeCodes': ['PLACE']}`

*Tags: Errors Debugging*

---

**Newbie99** - *21:52:38*

```market_filter=streaming_market_filter(

                    event_type_ids=[7],

                    country_codes=['AU','NZ'],

                    market_types=['PLACE'],

                ),```

*Tags: General Technical*

---

**Jonjonjon** - *21:53:25*

Thanks guys. I was using `filters.market_filter`, not `filters.streaming_market_filter:man-facepalming::skin-tone-6:`

*Tags: General Technical*

---

## 2021-12-17

**Bradley** - *21:24:12*

Good evening. I is new to this and am is having issue with running this most excellent code. Please could you suggest what I should do to make this function?



`Traceback (most recent call last):`

  `File "/home/xxxx/PycharmProjects/flumine_client/venv/lib/python3.8/site-packages/flumine/streams/marketstream.py", line 44, in run`

    `self._stream.start()`

  `File "/home/xxxx/PycharmProjects/flumine_client/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 60, in start`

    `self._read_loop()`

  `File "/home/xxxx/PycharmProjects/flumine_client/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 207, in _read_loop`

    `received_data_raw = self._receive_all()`

  `File "/home/xxxx/PycharmProjects/flumine_client/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 229, in _receive_all`

    `raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))`

`betfairlightweight.exceptions.SocketError: [Connect: 2009]: Socket The read operation timed out`

*Tags: Getting Started, Errors Debugging*

---

**birchy** - *22:36:55*

[@UBS7QANF3](@UBS7QANF3), I presume that if you try to connect from a banned country, that Betfair allow a connection but throw back an error message?

*Tags: Errors Debugging*

---

**thambie1** - *22:40:22*

I've accidentally done it, you get an error message that clearly tells you that the connection is being refused due to location

*Tags: Errors Debugging*

---

## 2021-12-18

**Bradley** - *21:14:51*

I is based in Essex, UK. I can surf the internet from my computer and can log into Betfair. Does this streaming technology use a port other than 80?

*Tags: General Technical*

---

## 2021-12-19

**Peter** - *06:58:54*

Yes. Streaming via Betfairlightweight is done over port 443, the standard https port. That port will also be used when you log in to Betfair, confirming that it is available to you in Essex :wink:

*Tags: General Technical*

---

**Peter** - *06:58:59*

[https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py)

*Tags: General Technical*

---

## 2021-12-20

**Martin Chambers** - *10:21:34*

Hi all,  Just working the examples given and am having an issues placing a bet.  Am getting the error code below.



Error: {'code': -32602, 'message': 'DSC-0018'}



Any ideas from the code below what I am not doing right?  Appreciate the help.



```# update for test

market_id = "1.192536055"

selection_id = 14884478



def place_order():

    # placing an order

    limit_order = filters.limit_order(size=2.00, price=5.00, persistence_type="LAPSE")

    instruction = filters.place_instruction(

        selection_id=selection_id,

        handicap=0,

        side="WIN",

        order_type="LIMIT",

        limit_order=limit_order,

    )

    place_orders = trading.betting.place_orders(

        market_id=market_id, instructions=[instruction]  # list

    )



    print(place_orders.status)

    for order in place_orders.place_instruction_reports:

        print(

            "Status: %s, BetId: %s, Average Price Matched: %s "

            % (order.status, order.bet_id, order.average_price_matched)

        )



place_order()```

*Tags: Errors Debugging, Strategies*

---

**Ruben** - *19:22:17*

I am getting a flumine error when trying to reduce the size of an order. The available size is 0.88 (verified on the webpage), but internally, flumine thinks it is 0.879999999..... and hence throws the "Size reduction too large!" error when trying to reduce the size by 0.88. Is there any way to avoid these numerical issues?

*Tags: Errors Debugging*

---

**Ruben** - *20:21:51*

from what I have seen so far, on my end the value is correctly stored as 0.88. The thing is that the order.remaining_size (which I don't control) is 0.879999, and this is what flumine checks

*Tags: General Technical*

---

**Martin Chambers** - *20:30:30*

Working now [@UBS7QANF3](@UBS7QANF3). Appreciate the help.

*Tags: General Technical*

---

**Aaron Smith** - *20:33:42*

i wouldnt worry much about it. Given how many ppl use flumine without having any issue with this, i d assume there wont be any. If there are, you can always create an issue on github and liam will probably be happy to fix it

*Tags: Errors Debugging*

---

**Aaron Smith** - *20:38:59*

the rounding error you are seeing probably has nothing to do with flumine either, but with float types in python in general. You can read up on floating point arithmetic for more about this (i myself didnt bother though :smile: )

*Tags: Errors Debugging*

---

**Ruben** - *20:45:54*

I think so as well, no real way to fix it

*Tags: Errors Debugging*

---

**Bradley** - *22:48:09*

Hacking into Liam's beautiful code and make it print stuff, it now tells me:



betfairlightweight.streaming.betfairstream b'{"op":"status","id":2003,"statusCode":"SUCCESS","connectionClosed":false,"connectionsAvailable":1}\r\n'

betfairlightweight.streaming.betfairstream b'{"op":"status","id":2002,"statusCode":"FAILURE","errorCode":"SUBSCRIPTION_LIMIT_EXCEEDED","errorMessage":"trying to subscribe to 208 markets whereas max allowed number was: 200","connectionClosed":false,"connectionId":"207-201221224727-809762"}\r\n'

*Tags: Errors Debugging*

---

**birchy** - *23:06:18*

Is the limit only 200 nowadays? I started off with 1000 but have been using the Betfair API since the beginning, so maybe the limits have been changed recently...

*Tags: General Technical*

---

## 2021-12-21

**liam** - *07:24:42*

I’m confused, if the size remaining is 0.88, if you try and reduce it by that you will get an error anyway 

*Tags: Errors Debugging*

---

**Ruben** - *07:40:00*

maybe I explained it wrong; so, in the flumine BetfairOrder, order.size_remaining is 0.8799999 instead of 0.88 (which is what the webpage shows as remaining). So when I execute the cancel with size_reduction=0.88, I get the error, since flumine thinks the size remaining is 0.879999

*Tags: Errors Debugging*

---

**liam** - *08:00:08*

I think you would get an error anyway trying to do that instead of cancel_order with no reduction 

*Tags: Errors Debugging*

---

**Unknown** - *08:42:11*

Hi all, I am new to Flumine and am backtesting a strategy using betfair pro data. I have followed the examples and started running backtests but have noticed an issue with simulated profit. Removed runners are returning a simulated profit (please refer to output image below)(Note: this is a backing strategy, it seems odd that the simulation would see a removed runner as winner). Would be greatly appreciated if someone could point out what I’m doing wrong.

*Tags: Getting Started, Strategies*

---

**JFP** - *08:46:19*

Here is my backtest code



```client = clients.BacktestClient()



framework = FlumineBacktest(client=client)



root_folder = 'C:/BF_PRO_DATA/Nov/'

folders = os.listdir(root_folder) #list of folders

markets = []



for folder in folders:

    folder = os.path.join(root_folder, folder) #dir to open folder in list of folders

    _markets = os.listdir(folder) # list of files inside folder inside list of folders

    _markets = [x for x in _markets if x.endswith('.bz2')] #adds file names to list

    _markets = [os.path.join(folder, x) for x in _markets] #adds file names to a dir string

    markets.extend(_markets) #adds exact dir for each file to market list





spList=[]



class Test1(BaseStrategy):





    def check_market_book(self, market, market_book):

        if (market.seconds_to_start &lt;= 360) and (market_book.status != "CLOSED") and not market_book.inplay and market.market_type == "WIN":

            return True



    def process_market_book(self, market, market_book):

        

        if (ABC):



            for runner in market_book.runners:

                

                runner_context = self.get_runner_context(market.market_id, runner.selection_id, runner.handicap)

                

                back1 = get_price(runner.ex.available_to_back, 0)

                back2 = get_price(runner.ex.available_to_lay, 0)

                

                #exit current selection itteration if back1 = None

                if back1 == None or back2 == None:

                    continue



                

                if (XYZ):

                        

                    trade = Trade(

                        market_id=market_book.market_id, 

                        selection_id=runner.selection_id,

                        handicap=runner.handicap,

                        strategy=self

                    )

                    

                    order = trade.create_order(

                        side= Side, 

                        order_type=LimitOrder(price=back1, size= sizeB1),

                        notes=OrderedDict(market_vol=round(totalVol, 4), sel_volume = selTradedVol, event_details = market_book.market_definition.name, order_num = 1)

                    )

                    

                    market.place_order(order)

                        

    def process_closed_market(self, market, market_book) -&gt; None:



        for runner in market_book.runners:

            spList.append([runner.selection_id, runner.status, runner.sp.actual_sp])





with mock_patch("builtins.open", smart_open.open):

    strategy = Test1(

        market_filter={"markets": markets,"listener_kwargs": {"seconds_to_start": 360}, "market_types":["WIN"]},

        max_trade_count = 4,

        max_live_trade_count = 4,

        max_order_exposure = 10000,

        max_selection_exposure = 20000

    )

    framework.add_strategy(strategy)

    framework.run()



dfList=[]



for market in framework.markets:



    for order in market.blotter:

        dfList.append(

        [

            market.venue,

            market.country_code,

            market.event_name,

            market.market_start_datetime,

            order.market_id,

            order.selection_id,

            order.notes['event_details'],

            order.notes['market_vol'],

            order.notes['sel_volume'],

            order.notes['order_num'],

            order.responses.date_time_placed,

            order.status,

            order.order_type.price,

            order.average_price_matched,

            order.size_matched,

            order.simulated.profit,

        ]

        )



df = pd.DataFrame(dfList, columns = ['market_venue', 'country_code', 'event_name', 'market_start_datetime', 'market_id', 'selection_id', 'event_details', 'market_vol', 'sel_volume', 'order_num', 'time_placed', 'status', 'price', 'average_price_matched', 'size_matched', 'simulated_profit'])

df['weekday'] = df['time_placed'].dt.dayofweek

df['month'] = df['time_placed'].dt.month



#add bsp

df['bsp']=df['selection_id']

df['selection_status'] = df['selection_id']



for L in spList:

    df.loc[df['selection_id'] == L[0], 'bsp'] = L[2]

    df.loc[df['selection_id'] == L[0], 'selection_status'] = L[1]```

*Tags: Feature Engineering, Deployment, Strategies*

---

**mandelbot** - *09:08:40*

So I'm trying to place a limit back bet to a target payout, but I am getting the following error `"Unknown error __init__() missing 1 required positional argument: 'size' in process_market_book"` my order looks like this :

```order = trade.create_order(

    side="BACK",

    order_type=LimitOrder(price=get_price(runner.ex.available_to_back,0), bet_target_type="BACKERS_PROFIT", bet_target_size=50)

)```

Not sure why I have to give a 'size' if I'm betting to a target payout. The relevant betfair documentation doesn't seem to require a size parameter [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders#placeOrders-BettoPayoutorProfit/Liability](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders#placeOrders-BettoPayoutorProfit/Liability)

*Tags: Errors Debugging, Strategies*

---

**liam** - *09:58:01*

Probably another bug in flumine :man-facepalming:

*Tags: Errors Debugging*

---

**Aaron Smith** - *18:22:29*

(not directly bflw/flumine related): does anyone have a clue why i would be able to download s3objects from local, but running same code on ec2 gives a FileNotFoundError ?

*Tags: Errors Debugging, Deployment*

---

**Mo** - *18:23:16*

Because your credentials are correctly configured locally but not on the EC2 instance?

*Tags: Deployment*

---

**Aaron Smith** - *20:10:45*

[@U4H19D1D2](@U4H19D1D2) you mean the path where its supposed to put the file? the path to the file in the s3bucket is the same.  I dont think it ever gets to the part where it checks the path to where its supposed to download to, but those are also the same (locally its mac, ec2 is ubuntu, path exists on both as its all within the project)

*Tags: Deployment*

---

## 2021-12-22

**JFP** - *01:41:28*

Found the issue, it is error in assembly of dataframe. It occurs when adding runner status and bsp from spList.



The spList is created for all runners in def process_closed_market. I have added status and bsp to df based on selection_id match:

```for L in spList:

    df.loc[df['selection_id'] == L[0], 'bsp'] = L[2]

    df.loc[df['selection_id'] == L[0], 'selection_status'] = L[1]```

*Tags: Errors Debugging, Feature Engineering*

---

**Unknown** - *01:42:12*

I run the script for one month block of racing data, therefore error occurs when selection runs more than once for the month. Please see screenshot attached, runner '25754300' ran 3 times, the first run it won, this explains my output of removed runners having simulated_profit.

*Tags: Errors Debugging*

---

**JFP** - *01:46:23*

Found the issue, it is not a Flumine one, it is my error in assembly of dataframe. It occurs when adding runner status and bsp from spList.



The spList is created for all runners in def process_closed_market. I have added status and bsp to df based on selection_id match:

```for L in spList:

    df.loc[df['selection_id'] == L[0], 'bsp'] = L[2]

    df.loc[df['selection_id'] == L[0], 'selection_status'] = L[1]```

*Tags: Errors Debugging, Feature Engineering*

---

**Unknown** - *01:47:08*

I run the script for one month block of racing data, therefore error occurs when selection runs more than once for the month. Please see screenshot attached, runner '25754300' ran 3 times, the first run it won, this explains my output of removed runners having simulated_profit.

*Tags: Errors Debugging*

---

**foxwood** - *15:30:14*

Possible expected behaviour, but, as a flumine noob, been exploring with marketRecorder and found that the data file saved (the one with all the mcm blocks and deltas etc) is seen by Json viewers as badly formed. Had to edit the file, inserting commas between the mcm blocks and wrapping the whole thing in {"all":[ mcm_blocks ]} to be able to view it "nicely".

*Tags: General Technical*

---

**foxwood** - *17:19:04*

Ok - my bad - hadn't considered that it has to match the historical data files BF provide. Will just use a script to wrap files I want to view. Didn't know there was a lines-only standard - thanks for that :slightly_smiling_face:

*Tags: Data Quality*

---

**Paul** - *19:42:41*

Dumb question. Am I safe to assume if I'm seeing this when trying to use the market recorder example, I'm using a key for which streaming hasn't been enabled?

```ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 206-221221193700-982041, data: {\"op\":\"status\",\"id\":1004,\"statusCode\":\"FAILURE\",\"errorCode\":\"NOT_AUTHORIZED\",\"errorMessage\":\"AppKey is not configured for service\",\"connectionClosed\":true,\"connectionId\":\"206-221221193700-982041\"}"}```



*Tags: Data Quality, Errors Debugging*

---

**Paul** - *19:58:06*

So now i'm confused. I have a live key. I've placed bets with it using BFLW but without streaming. First time I've used streaming - is there a further activation step for streaming?

*Tags: Getting Started, Deployment*

---

**Mo** - *20:05:02*

Yeah I think nowadays they activate streaming at the same time as the app key 

*Tags: General Technical*

---

**birchy** - *20:24:35*

Just as an FYI, I have an account from ~2001 and had to ask Neil to enable streaming.

*Tags: General Technical*

---

## 2021-12-24

**Unknown** - *05:41:39*

Recently I've started getting the same error. When I run the model in debug the errorenous unrounded amount is even showing up in the betfair message.

*Tags: Errors Debugging, Strategies*

---

**Jimmy** - *18:53:14*

Hello! I’m using a LoggingControl for live but realised I’ve left the orders profit as simulated as per the backtest example. I’ve gone to change it and thought removing the simulated would do it but it’s not a property on the object. I’m certain I’m being a bit daft and missing the obvious — can anyone steer me towards what I’m missing and how to record the order profit? Thanks in advance and Merry Christmas! :slightly_smiling_face:

*Tags: Deployment*

---

## 2021-12-26

**Jimmy** - *22:11:00*

Follow up question on the above LoggingControl — is there any obvious reason why I’d be ending up with duplicates in my db from this code?

*Tags: General Technical*

---

**Jimmy** - *22:21:08*

Getting this in the logs _sometimes_.



```{"asctime": "2021-12-26 12:21:57,626", "levelname": "CRITICAL", "message": "'NoneType' object has no attribute 'profit' exception raised in 'NoneType' object has no attribute 'profit'", "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/flumine/controls/loggingcontrols.py\", line 34, in run\n    self.process_event(event)\n  File \"/usr/local/lib/python3.8/dist-packages/flumine/controls/loggingcontrols.py\", line 65, in process_event\n    self._process_cleared_orders_meta(event)\n  File \"/home/strategies/loggingcontrol.py\", line 14, in _process_cleared_orders_meta\n    mydb.insert_cleared_order(order.bet_id, order.trade.strategy, order.market_id, order.selection_id, order.trade.id, order.responses.date_time_placed, order.order_type.price, order.average_price_matched, order.order_type.size, order.size_matched, order.cleared_order.profit, order.side, order.elapsed_seconds_executable, order.status.value, order.trade.market_notes, order.trade.notes_str, order.notes_str, False)\nAttributeError: 'NoneType' object has no attribute 'profit'", "event": "&lt;CLEARED_ORDERS_META [LOGGING]&gt;"}```

*Tags: Errors Debugging, Strategies*

---

## 2021-12-27

**Jimmy** - *10:32:02*

Thanks. Will take a look. 



This strategy doesn't cancel any orders though so I'm a little confused. Will take a look :+1::skin-tone-2:

*Tags: Strategies*

---

**Jimmy** - *14:02:13*

Weird one. Trying to spot it — the bet was placed at betfair so it wasn’t cancelled or expired but it caused that error above…

*Tags: Errors Debugging*

---

**Jimmy** - *14:04:11*

Thanks — but given it was matched, not sure it’ll stop the error.

*Tags: Errors Debugging*

---

**Jimmy** - *15:54:22*

Thanks [@U4H19D1D2](@U4H19D1D2) - I’ve debug logging on this afternoon to try capture some info but will tweak from the _meta. What's the difference? Can't find it in the docs/comments (sorry)

*Tags: Errors Debugging*

---

## 2021-12-28

**mandelbot** - *06:12:38*

Sometimes the official start times for events may change (for example AUS racing), does flumine refresh these times?

*Tags: General Technical*

---

**mandelbot** - *07:14:11*

They do, at least for the AUS stuff. Would flumine get an update for a new starting time if betfair were to change it?

*Tags: General Technical*

---

**mandelbot** - *14:22:35*

So my strategy placed hedging bets at BSP but there were no bets matched to hedge in the first place

*Tags: Strategies*

---

## 2021-12-29

**thambie1** - *17:58:06*

Getting errors on the listClearedOrders endpoint

*Tags: Errors Debugging*

---

## 2021-12-30

**nthypes** - *13:16:46*

`EX_BEST_OFFERS` is not working with Flumine?

*Tags: General Technical*

---

**nthypes** - *13:30:10*

```strategy = SomeStrategy(

    market_filter=streaming_market_filter(

        market_ids=["1.192827234"]

    ),   market_data_filter=streaming_market_data_filter(fields=["EX_BEST_OFFERS"])

)

)```

*Tags: Strategies*

---

**nthypes** - *13:32:46*

This is what I added:



```market_data_filter=streaming_market_data_filter(fields=["EX_BEST_OFFERS"])```

*Tags: General Technical*

---

**Aaron Smith** - *13:44:30*

```"EX_BEST_OFFERS"```

works fine with flumine. How did you come to the conclusion its not? Can you show any errors/logs?

*Tags: Errors Debugging*

---

**nthypes** - *14:14:09*

How can I enable debug logging? Could find in the docs.

*Tags: Errors Debugging*

---

**birchy** - *14:33:44*

Top half of this:

[https://github.com/liampauling/flumine/blob/master/examples/backtest.py|https://github.com/liampauling/flumine/blob/master/examples/backtest.py](https://github.com/liampauling/flumine/blob/master/examples/backtest.py|https://github.com/liampauling/flumine/blob/master/examples/backtest.py)

*Tags: General Technical*

---

## 2022-01-02

**Paul** - *10:30:41*

Already an issue for this at [https://github.com/liampauling/flumine/issues/541|https://github.com/liampauling/flumine/issues/541](https://github.com/liampauling/flumine/issues/541|https://github.com/liampauling/flumine/issues/541) I think

*Tags: General Technical*

---

**Paul** - *13:45:25*

On the back side, the backer's stake remains fixed so the 2.22 being asked for at 4.0 would not be increased to 3.33 if the BSP is 3.0

*Tags: Errors Debugging*

---

**Paul** - *13:46:04*

Short version: the person creating the order has their liability fixed and the amount matched on the other side adjusts. Which if you think about it, is the only sensible thing they can do there

*Tags: Errors Debugging*

---

**mandelbot** - *14:01:31*

Great I will try. Your fix won't work in this case however because your payout will be calculated based on price requested not bsp. I think you would have to send the call in the appropriate format

*Tags: Errors Debugging*

---

## 2022-01-05

**Aaron Smith** - *09:46:40*

[@UBS7QANF3](@UBS7QANF3)

```            "bet_id BIGINT," \

            "strategy_name TEXT," \

            "market_id TEXT," \

            "selection_id INT," \

            "date_time_placed TEXT," \

            "price NUMERIC," \

            "price_matched NUMERIC," \

            "size NUMERIC," \

            "size_matched NUMERIC," \

            "side TEXT," \

            "elapsed_seconds_executable NUMERIC," \

            "order_status TEXT," \

            "market_note TEXT," \

            "order_notes TEXT," \

            "PRIMARY KEY (bet_id, market_id, selection_id));"```

*Tags: Strategies*

---

**Aaron Smith** - *09:48:15*

oh okay, but wouldnt that result in a "int out of range" error rather than "bigint out of range" ?

*Tags: Errors Debugging*

---

## 2022-01-07

**river_shah** - *11:00:04*

How do I gracefully generate a `TerminationEvent` if any of my code causes an error? Problematic code is not necessarily in a try / except `CRITICAL flumine.utils:utils.py:233`

*Tags: Errors Debugging*

---

**liam** - *11:15:13*

There isn't a graceful way of doing it right now, wondering if we gracefully handle any unhandled errors regardless instead

*Tags: Errors Debugging*

---

**river_shah** - *11:18:40*

Not sure what the best design here is, but despite plenty of unit testing I have noticed a few of my strategies rarely generate unhandled exceptions. Ideally, a callback if that happens so user code has a chance to log a bunch of state / dump any files etc and then terminate

*Tags: Errors Debugging*

---

**liam** - *11:23:00*

Just realised I have already designed for this, run function uses self as a context manager, so exit gets called on any error, and you can see a few things are already called however `process_end_flumine` isn't. With this added you can add any callbacks in your strategy in the `finish` function

*Tags: Errors Debugging, Strategies*

---

**C0rnyFlak3s** - *13:52:48*

Is there a way to extract soccer competition information from the historical streaming data from Betfair? As far as I am concerned no information regarding league/competition is directly given by the hist data. The only thing that can be extracted is the team names and time of the game. However I also struggle with extracting competition information when I search for the historic marketIds in the exchange API. It seems as if I can only extract current end future competition information, hence my question if there is any way at all to know which competitions historic soccer games come from. I quite stuck here… :disappointed:

*Tags: General Technical*

---

**C0rnyFlak3s** - *14:55:40*

That would be pretty amazing tbh. Would save me a ton of time linking my data to external sources for soccer fixture information. :slightly_smiling_face:

*Tags: Errors Debugging*

---

**Unknown** - *16:20:56*

I only from June and random countries, maybe its helpful

*Tags: General Technical*

---

**C0rnyFlak3s** - *16:22:15*

Thanks liam, this really helps :heart:

*Tags: General Technical*

---

**Ke** - *17:57:08*

anyway to get my orders' latest status by force during process_market_book? I'm calling market.blotter.strategy_selection_orders(self, runner.selection_id, runner.handicap), but the order's remain_size/matched_size seem to be wrong

*Tags: Strategies*

---

**Ke** - *18:02:44*

not sure if market.blotter.strategy_selection_orders(self, runner.selection_id, runner.handicap) is the correct way to get the live status of my order. The order i get from this method is telling me that my order still 100% unfilled, but it is actually filled already when i check on web

*Tags: Deployment, Strategies*

---

## 2022-01-08

**Aaron Smith** - *12:33:08*

not impossible, but i doubt it seeing that others are having the same problem at the same time. Also, when trying to redo the withdrawal (i use alternative methods -&gt; bank transfer), i get "No available payment options"), so somehow betfair erased my bank details and i cant seem to find how to add them again

*Tags: General Technical*

---

**Peter** - *12:55:16*

It's a problem between Betfair and Worldpay, so the transactions are being bounced back before they get to the banks. they hope to have it resolved by Monday.

*Tags: General Technical*

---

**river_shah** - *13:59:35*

[@U01DVUAE2G1](@U01DVUAE2G1) I have the exact same problem

*Tags: General Technical*

---

**Aaron Smith** - *14:01:22*

[@U01B8031PM1](@U01B8031PM1) nice to hear i m not alone, i guess if this hits multiple ppl, chances are this will be resolved more quickly

*Tags: General Technical*

---

**river_shah** - *15:44:09*

Just got a call from betfair, nothing new to add except they are working on fixing for Monday. Payment options will come back automatically (i.e they have not been deleted)

*Tags: Getting Started, Errors Debugging*

---

**AndyL** - *19:04:18*

[@U4H19D1D2](@U4H19D1D2) fyi, periodically seeing an error during backtests, with KeyError: new_price, ive raised #548

*Tags: Errors Debugging*

---

## 2022-01-09

**Ruben** - *10:04:50*

on that same topic, if I wanted to cancell all unmatched orders when a `TerminationEvent` occurs (such as unhandled exception), would `finish()` of the strategy be the right spot?

*Tags: Errors Debugging, Strategies*

---

**Ruben** - *14:45:55*

how could one access the orders from the strategy there? I cant seem to figure it out, there is no market object (so no blotter), only the strategy `self`

*Tags: Strategies*

---

## 2022-01-10

**liam** - *09:16:55*

Fixed in [https://github.com/liampauling/flumine/pull/550|1.21.1](https://github.com/liampauling/flumine/pull/550|1.21.1) with `strategies.finish` now called on `__exit__` and self passed to `strategy.finish` so you have access to market/blotter objects

*Tags: Errors Debugging, Strategies*

---

**Mo** - *15:23:35*

Any update on the withdrawal problems?

*Tags: General Technical*

---

## 2022-01-11

**Andy B** - *22:14:24*

Morning all, (cross posting here with the Betfair Quants slack channel) I'm getting an error in a script that hasn't given me issues previously and I was wondering if there was a data error causing anyone else grief? I am getting the list of todays greyhound markets and runner ID's but it is getting stuck on Capalaba greys with the following error:

Traceback (most recent call last):

  File "c:\Users\andy\OneDrive\Punting\Scripts\FastTrack\GetAllRaces.py", line 318, in &lt;module&gt;

    Races = market_catalogue_filter(Events['Event ID'][ind], Track)

  File "c:\Users\andy\OneDrive\Punting\Scripts\FastTrack\GetAllRaces.py", line 99, in market_catalogue_filter

    market_catalogues = trading.betting.list_market_catalogue(

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\betting.py", line 233, in list_market_catalogue

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 55, in request

    self._error_handler(response_json, method, params)

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue

Params: {'filter': {'eventIds': ['31170555'], 'marketCountries': ['AU', 'NZ'], 'marketTypeCodes': ['WIN']}, 'marketProjection': ['MARKET_START_TIME', 'RUNNER_DESCRIPTION'], 'sort': 'FIRST_TO_START', 'maxResults': '1 00'}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}

PS C:\Users\andy&gt;

*Tags: Errors Debugging, Strategies*

---

## 2022-01-13

**Ruben** - *08:27:40*

good morning everyone, for flumine users, is it possible that `process_closed_market` is being called twice once without the cleared orders, and once with the cleared orders? context: I am logging some KPIs after every market closes such as profit/loss, number of bets and the like, and I notice that for every event I generate two logs, and the first one does not have any profit info (due to order.cleared_order objects not being populated)

*Tags: General Technical*

---

## 2022-01-14

**Colin** - *04:04:50*

Hi All. I've tried searching for this and found similar occurrences, but extending the read and connect timeout values didn't seem to help. Any ideas?



Error:

Traceback (most recent call last):

  File "/Users/xxx/Documents/Personal/Python/learn/betfair.py", line 143, in &lt;module&gt;

    trading.login_interactive()

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/betfairlightweight/endpoints/logininteractive.py", line 30, in __call__

    (response, response_json, elapsed_time) = self.request(

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/betfairlightweight/endpoints/logininteractive.py", line 53, in request

    raise APIError(None, exception=e)

betfairlightweight.exceptions.APIError: None

Params: None

Exception: HTTPSConnectionPool(host='[http://identitysso.betfair.com|identitysso.betfair.com](http://identitysso.betfair.com|identitysso.betfair.com)', port=443): Read timed out. (read timeout=3.05)



Source:

trading = betfairlightweight.APIClient(username=my_username,

                                       password=my_password,

                                       app_key=my_app_key)



    trading.betting.read_timeout = 30

    trading.betting.connect_timeout = 30

    trading.login_interactive()

*Tags: Errors Debugging, Strategies*

---

**west** - *04:47:22*

I have been following the tutorial and I cant seem to be able to get the runner names. Saw a question on here but couldnt understand how to apply that to the example in the docs.

```# Create a price filter. Get all traded and offer data

price_filter = betfairlightweight.filters.price_projection(

    price_data=['EX_BEST_OFFERS']

)



# Request market books

market_books = trading.betting.list_market_book(

    market_ids=['1.193314179'],

    price_projection=price_filter

)



# Grab the first market book from the returned list as we only requested one market 

market_book = market_books[0]



runners_df = process_runner_books(market_book["runners"])```

At which part of the code/example do I make changes to ensure the horse names come through? Thanks

*Tags: Strategies*

---

**west** - *05:01:45*

Okay thanks. I saw a previous question that got this data in market catalogue by adding this `market_projection=["RUNNER_DESCRIPTION","EVENT_TYPE","EVENT","COMPETITION","RUNNER_METADATA","MARKET_START_TIME"].` This worked but where exactly can I find this info? I couldnt seem to find it in the docs or in the source code.

*Tags: General Technical*

---

**Finn** - *05:04:19*

you can find that biz in the betfair documentation

*Tags: General Technical*

---

**Colin** - *08:21:12*

This appears to be the instigating exception,



Traceback (most recent call last):

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py", line 382, in _make_request

    self._validate_conn(conn)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn

    conn.connect()

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connection.py", line 411, in connect

    self.sock = ssl_wrap_socket(

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket

    ssl_sock = _ssl_wrap_socket_impl(

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl

    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py", line 500, in wrap_socket

    return self.sslsocket_class._create(

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py", line 1040, in _create

    self.do_handshake()

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py", line 1309, in do_handshake

    self._sslobj.do_handshake()

socket.timeout: _ssl.c:1112: The handshake operation timed out

*Tags: Errors Debugging, Deployment*

---

**Peter** - *08:49:54*

Betfairlightweight is a wrapper around the Betfair API, so understanding Betfair's many, many idiosyncracities and occasional limitations really helps in getting strategies up and running. Good luck.

*Tags: General Technical*

---

## 2022-01-15

**Colin** - *07:49:35*

Strangely, my script appears to be working much better today. No errors yet. I didn't make any changes that I am aware of that would have addressed the source of the fault.

*Tags: Errors Debugging*

---

**Jonjonjon** - *20:58:17*

My flumine script logs to syslog. I'm using Ubuntu. How can I stop it?

*Tags: General Technical*

---

## 2022-01-17

**liam** - *21:05:54*

Yeah, only reason you would be missing a response is if there is an unhandled exception in the thread but fairly sure we handle all 

*Tags: Errors Debugging*

---

## 2022-01-20

**Ruben** - *08:11:27*

I am using one of the example controls from flumine, and noticed that in `_process_cleared_markets`  the profit of a market is `None`, for a market in which `baseflumine.py:_process_cleared_market` has correctly logged the profit just before. Does this mean that `_process_cleared_market` from my control will be executed again later with the correct values?

*Tags: General Technical*

---

**Ruben** - *09:32:40*

quite sure, in fact I noticed because I got an error because I was trying to round the profit. `{"asctime": "2022-01-19 22:56:20,772", "threadName": "MARKET_LOGGING_CONTROL", "levelname": "CRITICAL", "message": "type NoneType doesn't define __round__ method exception raised in MARKET_LOGGING_CONTROL", "exc_info": .... +\nTypeError: type NoneType doesn't define __round__ method", "event": "&lt;CLEARED_MARKETS [HANDLER]&gt;"}`

*Tags: Errors Debugging*

---

**Ruben** - *09:36:26*

could be different markets, I assumed they were the same because the logging control was executed with almost no time difference (1ms) from `baseflumine.py:_process_cleared_market`

*Tags: General Technical*

---

**liam** - *09:51:57*

`the_event_id` * make lightweight requests if you want the raw data rather than using `_data` however to answer your question I am not sure

*Tags: General Technical*

---

**liam** - *10:44:16*

this is python, joined_lower on var names, event_ids should be working

*Tags: General Technical*

---

**Newbie99** - *11:32:49*

I've reported numerous issues to them about nonsensical P&amp;L on that page, I think they just ignore it and hope it fixes itself :slightly_smiling_face:



I think 'under the hood' the numbers are correct, its just the Betfair GUI p&amp;l that comes up with randomness at times!

*Tags: Errors Debugging*

---

## 2022-01-22

**Aaron Smith** - *16:32:42*

Hi ppl, i m getting this bad boy today:

```"ERROR", "message": "[MarketStream: 2002]: MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s)."}```

I am not using that many connections (should be 4 i think?) So i assume some connections just dont get closed? Any idea how to approach this?

*Tags: Errors Debugging*

---

**mandelbot** - *17:22:33*

Send mail to bdp@betfair with the connection ID and error

*Tags: Errors Debugging*

---

## 2022-01-24

**Jorge** - *10:11:48*

Question related with the Python logging library: If my process is writing a .log file that is 20 MB big, does that mean that the process will consume 20 MB worth of RAM memory? Is this how it works?

*Tags: Performance*

---

**Jorge** - *11:00:53*

Is it normal for a python process to take 68 MB of RAM (Resident) ? (It takes 22 MB of Shared Memory)

*Tags: Performance*

---

**birchy** - *21:55:24*

While on the subject of RAM, how do you guys handle "big" backtests/signal processing with Flumine? I've found that if I run a strategy that produces 200k+ bets, the Framework eventually falls over because my 4GB AWS machine falls over with OOM errors. I know that increasing the amount of RAM is a solution (as is running on my local 8GB machine), but am wondering if there's a way to break up the framework into smaller chunks so that it can run on lower spec hardware?

*Tags: Errors Debugging, Deployment, Strategies*

---

**AP** - *23:44:36*

Not sure if this helps you [@U016TGY3676](@U016TGY3676) 



[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1637699269108700|https://betfairlightweight.slack.com/archives/C4H05ML2E/p1637699269108700](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1637699269108700|https://betfairlightweight.slack.com/archives/C4H05ML2E/p1637699269108700)

*Tags: General Technical*

---

## 2022-01-25

**liam** - *08:04:45*

I do this, you should certainly look at chunking the markets due to memory leaks and performance reasons [https://liampauling.github.io/flumine/performance/#multiprocessing](https://liampauling.github.io/flumine/performance/#multiprocessing)

*Tags: Performance*

---

## 2022-01-26

**Jorge** - *08:16:56*

Just my 2 cents, I finally understood what is consuming my RAM memory. Just by the packages I import in my bot, it consumes 68MB. `import pandas` alone consumes 36 MB. This is a bit of a problem when I run 100x bots :smile:

*Tags: Feature Engineering, Performance*

---

**liam** - *08:33:54*

Premature optimisation here, the real problem is your plan to run 100x python processes

*Tags: General Technical*

---

**liam** - *08:43:17*

your number one problem is betfair being down, having 100x programs makes this 100x worse, trust me

*Tags: General Technical*

---

**liam** - *08:48:26*

you use flumine don't you?

*Tags: General Technical*

---

**Jorge** - *08:50:37*

I use betfairlightweight to stream the orders and data. My live bots use this data but they do not trade with flumine

*Tags: Deployment*

---

**liam** - *08:58:39*

Ah, unless you have experience in building a trading system I recommend having a read of some code. Few schools of thought on how one should be built but the central idea is to consume market/order data and make decisions. 



flumine uses a FIFO queue with strategies, threads for streams and workers and a thread pool for execution. Its lightweight and fast whilst still being adapted per use case, as well as being very easy to get started.



Mo's design gives you a highly available / scalable (complicated) system that can do whatever you want and at a guess very easy to deploy upgrades etc. But I wouldn’t recommend this to someone starting out.

*Tags: Deployment, Strategies*

---

**Unknown** - *09:03:09*

This is 3 instances of flumine on all racing/greyhound markets running on a t2.micro placing around 20k orders a day

*Tags: General Technical*

---

**Jorge** - *09:14:57*

Makes sense [@U4H19D1D2](@U4H19D1D2), thanks for your help as always! I started trading some time ago without multiprocessing knowledge and without flumine so I chose Mo's approach. I'll read about it and think if it's worth the update!

*Tags: Strategies*

---

**liam** - *09:27:08*

yeah it creates a lot of problems that need to be solved at a time where you should be focussing on strategies

*Tags: General Technical*

---

**foxwood** - *09:37:34*

You'd be totally snookered trying to do anything like HFT but could be possible if not time critical at all. Personally I think it duplicates the baggage each program has to carry around. Now if bflw ran as an efficient shared service ie almost as part of the os so you just call into one master instance (not COM though which is snail like) ... :rolling_on_the_floor_laughing:

*Tags: General Technical*

---

**foxwood** - *09:40:36*

Don't know if it's common but had a couple of these overnight on OrderStream which rebuilt connection ok "betfairlightweight\\streaming\\betfairstream.py\", line 242, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 1003]: Connection closed by server" -  anything to worry about ?

*Tags: Errors Debugging, Deployment*

---

**D C** - *10:18:30*

What mechanism is used to share the stream info with the strategies? As my own stuff uses async TPC socket components I get away without using threading but only because I only focus on a small number of markets (relatively speaking). I would prefer to see what other architectures are available though as you mention a "few schools of thought" about building the trading system. Any recommended sources of reading or codebases other than flumine?

*Tags: Strategies*

---

**Unknown** - *10:24:16*

I really need to do a doc on it, but flumine follows this design but with a queue for updates where every strategy gets a call

*Tags: Strategies*

---

**D C** - *10:28:28*

OK that is good to know.  Probably best for me to go through the flumine code to see exactly how it works. What I have works well at present but in scaling up to event types other than horses I do feel I will need a more thoughtful approach so this is all very useful.

*Tags: General Technical*

---

**foxwood** - *13:34:39*

Much more suitable for your architecture than WIndows. You can do IPC on Win but not trivial if you want quick performance

*Tags: Performance*

---

## 2022-01-28

**Lee** - *13:33:01*

Has anyone seen an increase in errors on the execution endpoints this last week or so? (Place, cancel etc) Mainly timeouts and connection reset.

*Tags: Errors Debugging*

---

**AndyL** - *19:42:45*

If I try and start a strategy subscribing to say uk greyhounds and it tries to get over 200 markets i get the subscription limit exceeded error, is there a parameter to say just subscribe to the next 200 ?

*Tags: Errors Debugging, Strategies*

---

## 2022-01-30

**Jonjonjon** - *14:04:07*

How many strategies are attached to each Flumine instance? I'm at about 60 strategies on one of my instances and it's using a lot more CPU, but I have a feeling my moving average implementation might be non-optimal.

*Tags: Feature Engineering*

---

**birchy** - *16:24:07*

Has something changed in the Flumine order validation, because, for example, a LAY bet of £1@10.0 is now throwing:

`Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency`

This is a 6+ months running strategy (live) which is still working ok, but fails when backtesting.

If I change the size to £2, validation passes.

FYI: live is running on Flumine 1.20.13 and backtesting is 1.21.2

Ok, so this seems to be related to PR #546:

[https://github.com/liampauling/flumine/blob/770fcf967dab590cba63350dd2ee46839363f8d1/flumine/controls/tradingcontrols.py#L71|https://github.com/liampauling/flumine/blob/770fcf967dab590cba63350dd2ee46839363f8d1/flumine/controls/tradingcontrols.py#L71](https://github.com/liampauling/flumine/blob/770fcf967dab590cba63350dd2ee46839363f8d1/flumine/controls/tradingcontrols.py#L71|https://github.com/liampauling/flumine/blob/770fcf967dab590cba63350dd2ee46839363f8d1/flumine/controls/tradingcontrols.py#L71)

As far as I can tell, £1@10.0, £0.10@100, etc should still be valid?

[https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=3833942#placeOrders-Abilitytoplacelowerminimumstakesatlargerprices|https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=3833942#placeOrders-Abilitytoplacelowerminimumstakesatlargerprices](https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=3833942#placeOrders-Abilitytoplacelowerminimumstakesatlargerprices|https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=3833942#placeOrders-Abilitytoplacelowerminimumstakesatlargerprices)

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2022-01-31

**KG** - *06:47:02*

they’re having some issues un-splashing too, hopefully it will be resolved shortly :crossed_fingers:

*Tags: General Technical*

---

**Mo** - *09:20:27*

Thanks [@U01335QG2G3](@U01335QG2G3) and [@U01B8031PM1](@U01B8031PM1). To be clear, I'm not (just) trying to prove a point here, I am trying to understand if it's reasonable for a customer like myself to be unaware of a planned maintenance window. Is it poor communication on Betfair's part or a failing on my part?



I'm aware that the developer forum exists and that posts are created there about planned maintenance. However, I think we can all agree that aside from the official Betfair communication, the quality of posts on that forum is poor and there is no reason to use that resource other than to receive the official Betfair communication.



Is it too much to expect that one of the several Betfair employees that are members of this Slack also let us know about planned maintenance windows here?



Should Betfair be paying megabucks for consultants to tell them how to grow the exchange before sorting out some basic community engagement? Why don't we have our own [@UUUAJQZ5J](@UUUAJQZ5J)?

*Tags: General Technical*

---

**river_shah** - *09:32:27*

All great points, there are plenty of premium customers here, if someone from Betfair operating out of the UK could engage more here, it would be very helpful

*Tags: General Technical*

---

**Aaron Smith** - *12:23:05*

anyone else getting some stream errors?

*Tags: Errors Debugging*

---

**Jonjonjon** - *22:19:55*

I had some voided bets today.



I know the market id, and from the Flumine logs the id, customer_order_ref. Which API calls do I need to use to look up it's status? At the moment, I only know about it from my logs.

*Tags: General Technical*

---

**Jonjonjon** - *23:08:03*

Were there any non-runners on the 19:56 Doncaster Win Market? Apologies for the novice question, but I don't know how to read a race card or understand the results from racing websites.

*Tags: General Technical*

---

## 2022-02-01

**Paul** - *07:48:16*

The last race at Doncaster on Saturday was 15:55 - so your question is quite confusing. But yes, two non-runners in there. Not sure if that helps. :-)

*Tags: General Technical*

---

## 2022-02-03

**foxwood** - *12:24:13*

Puzzled by differences between live and backtest that I'm not expecting. Yesterday recorder and live betting were running on same VPS as separate processes under PyCharm.  Placed 28 live bets. Running the backtest later on it came up with bets on different runners on 4 of the races compared to what the live had done - sufficient to show a significantly different PL.



Looked at one in detail - no latency issues in log - recorder saw bet placed 187ms after logged by bet process. EX_BEST.. not used. Strategy source code the same for backtest/live. Betting triggering on EX_ALL.. price movements.



I expected the backtest to trigger on the same runner at the same time as the live did.



The recorder packets seem to be 4, 5 or 6 per second - could it be dropping packets that the live betting is seeing ? I thought they were all kept and cached if the app couldn't keep up ie excess latency compared to "pt" - ie not possible to miss any packets that BF push out ?



Any suggestions as to cause or where to look next ?

*Tags: Performance, Deployment, Strategies*

---

**foxwood** - *16:14:05*

Solved - bit brain bendy. In check_market_book I was using market.seconds_to_start to ignore unwanted early packets. When used in backtest that field is calculated using the packet "published time" but for live usage is calculated using "now". Since live always has some latency, at the time it considered it needed to start, the current packet to be processed was actually timestamped 200ms earlier than the wanted start time. Proved it by winding the stream back by 1 packet and it did exactly as the live did and eventually bet on the same runner. QED



My solution is therefore to use the "published time" as the processing trigger and not market.seconds_to_start which is a true real time value. The backtest and live "should" then be in sync I hope.



Be interesting to find out if we do all get the same timestamps - thanks for comments [@UBS7QANF3](@UBS7QANF3)

*Tags: Performance, Deployment*

---

## 2022-02-04

**D C** - *13:42:58*

But how do you run a company at a profit with no product? Sorry if these are naive questions

*Tags: General Technical*

---

**James T** - *13:51:46*

If you have a 18 month gap on your CV but have been doing something productive, which you will have been, then I don't see that as a problem at all. 

*Tags: General Technical*

---

**D C** - *13:56:12*

OK thanks for that. Very helpful indeed.

*Tags: General Technical*

---

## 2022-02-06

**Peter** - *10:14:18*

Having difficulty subscribing the the race stream:



```2022-02-06 10:09:25,303 - DEBUG - Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

2022-02-06 10:09:25,667 - DEBUG - [https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

2022-02-06 10:09:25,691 - INFO - [Register: 1]: raceSubscription

2022-02-06 10:09:25,694 - INFO - [RaceStream: 1]: "RaceStream" created

2022-02-06 10:09:25,795 - DEBUG - [Subscription: 2] Sending: b'{"op": "authentication", "id": 2, "appKey": "redacted", "session": "redacted"}\r\n'

2022-02-06 10:09:25,798 - DEBUG - [Subscription: 2] Sending: b'{"op": "raceSubscription", "id": 1}\r\n'

2022-02-06 10:09:25,811 - INFO - [RaceStream: 1]: connection_id: 201-060222100925-406302

2022-02-06 10:09:25,844 - INFO - [RaceStream: 2]: SUCCESS (14 connections available)

2022-02-06 10:09:25,847 - ERROR - [RaceStream: None]: INVALID_INPUT: Failed to un-marshall: '{"op": "raceSubscription", "id": 1}'```

*Tags: Errors Debugging*

---

**Peter** - *10:15:15*

Wondered if anybody else has had this and has any suggestions. To me the message that erroring appears to be exactly what the documentation suggests the service is expecting.

*Tags: Errors Debugging*

---

**liam** - *10:16:40*

```2022-02-06 10:16:11,801 | DEBUG | Starting new HTTPS connection (1): [http://identitysso.betfair.com:443|identitysso.betfair.com:443](http://identitysso.betfair.com:443|identitysso.betfair.com:443)

2022-02-06 10:16:12,072 | DEBUG | [https://identitysso.betfair.com:443](https://identitysso.betfair.com:443) "POST /api/login HTTP/1.1" 200 None

2022-02-06 10:16:12,073 | INFO | [Register: 1]: raceSubscription

2022-02-06 10:16:12,073 | INFO | [RaceStream: 1]: "RaceStream" created

2022-02-06 10:16:12,206 | DEBUG | [Subscription: 2] Sending: b'{"op": "authentication", "id": 2, "appKey": "poo", "session": "loo"}\r\n'

2022-02-06 10:16:12,206 | DEBUG | [Subscription: 2] Sending: b'{"op": "raceSubscription", "id": 1}\r\n'

2022-02-06 10:16:12,208 | INFO | [RaceStream: 1]: connection_id: 102-060222101612-211789

2022-02-06 10:16:12,328 | INFO | [RaceStream: 2]: SUCCESS (9 connections available)

2022-02-06 10:16:12,328 | INFO | [RaceStream: 1]: SUCCESS (9 connections available)

2022-02-06 10:16:12,328 | DEBUG | [RaceStream: 1]: SUB_IMAGE: {'op': 'rcm', 'id': 1, 'initia```

*Tags: Errors Debugging*

---

**Peter** - *10:17:59*

Yes first time. Is the json library determined when I install Flumine?

*Tags: Getting Started*

---

**Peter** - *10:23:31*

Very basic:



```import os

import logging

import queue

import threading



import betfairlightweight



# setup logging

# logging.basicConfig(level=logging.DEBUG)  # change to DEBUG to see log all updates

logging.basicConfig(

    level=logging.DEBUG,

    filename='tpd/race-subscription.log',

    filemode="a",

    format='%(asctime)s - %(levelname)s - %(message)s',

)



# create trading instance (app key must be activated for streaming)

workspace_prefix = os.getenv("WORKSPACE_PREFIX")

trading = betfairlightweight.APIClient(os.getenv("BETFAIR_USERNAME"), os.getenv("BETFAIR_PASSWORD"), app_key=os.getenv("BETFAIR_LIVE_KEY"), certs=workspace_prefix + "certs")



# login

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener)



# subscribe

streaming_unique_id = stream.subscribe_to_races()



# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)

t.start()



# check for updates in output queue

while True:

    update = output_queue.get()

    print(update)```

*Tags: Getting Started, Errors Debugging, Deployment, Strategies*

---

**liam** - *10:24:26*

```stream = trading.streaming.create_stream(host="race", listener=listener)```

basic with one thing missing :wink:

*Tags: Strategies*

---

**liam** - *10:31:59*

payment is for the secret bflw functions

*Tags: General Technical*

---

## 2022-02-07

**birchy** - *17:39:19*

[@U4H19D1D2](@U4H19D1D2) are there plans to update Flumine bet validation to adopt the new £1 minimum stake? I'm assuming that this now applies to all betfair customers?

*Tags: General Technical*

---

**liam** - *17:40:15*

Its half way there with bflw now updated, just need to bump the version in flumine [https://github.com/liampauling/betfair/blob/master/HISTORY.rst#2153-2022-01-07](https://github.com/liampauling/betfair/blob/master/HISTORY.rst#2153-2022-01-07)

*Tags: General Technical*

---

## 2022-02-08

**river_shah** - *11:01:05*

Just hit this error:

```2022-02-08 10:48:12.425 CRITICAL[flumine.utils:call_strategy_error_handling:233] Unknown error 'Market' object has no attribute 'blotter' in process_market_book```

Any idea why it may occur? Prod only, let me know what further debug I can provide (although I have very little aside from this `CRITICAL`message)

*Tags: Errors Debugging, Strategies*

---

**liam** - *11:11:22*

`BaseFlumine._remove_market` kicks it off and then `markets.markets.remove_market`

*Tags: General Technical*

---

## 2022-02-09

**liam** - *10:02:08*

lots of connection errors this morning, anyone else?

*Tags: Errors Debugging*

---

**Jorge** - *10:20:53*

Yeah, I placed a bet 15 mins ago and it is not appearing in the Order Streaming

*Tags: General Technical*

---

## 2022-02-11

**foxwood** - *15:43:25*

[@U016TGY3676](@U016TGY3676) It's on a Windows server so was easier to replicate my devenv and run it that way for now rather than setting up for command line. Early days with flumine and it has helped with some needed debugging and quick fixes. PyCharm is certainly a memory hog though which with other stuff that runs is pushing the hardware.

*Tags: Errors Debugging, Performance, Deployment*

---

**Jonjonjon** - *23:40:03*

One thing to be careful of, if doing calculations with numpy, is that if your code returns float64 objects, it can't be converted with json.loads

*Tags: General Technical*

---

**Jonjonjon** - *23:40:39*

`x = np.float64(123)`

`import json`

`json.dumps({"A":x})`

`Out[8]: '{"A": 123.0}'`

`import orjson`

`orjson.dumps({"A":x})`

`Traceback (most recent call last):`

  `File "/home/jon/miniconda3/envs/betfair/lib/python3.8/site-packages/IPython/core/interactiveshell.py", line 3418, in run_code`

    `exec(code_obj, self.user_global_ns, self.user_ns)`

  `File "&lt;ipython-input-10-801def5f984d&gt;", line 1, in &lt;module&gt;`

    `orjson.dumps({"A":x})`

`TypeError: Type is not JSON serializable: numpy.float64`

*Tags: Errors Debugging*

---

**Jonjonjon** - *23:52:31*

Specifically, it will break this bit of BFLW, though I don't think tests will pick it up:



[https://github.com/liampauling/betfair/blob/f76f60bf887dbbac156a7ed5f7a759b4194ae844/betfairlightweight/endpoints/baseendpoint.py#L58-L67](https://github.com/liampauling/betfair/blob/f76f60bf887dbbac156a7ed5f7a759b4194ae844/betfairlightweight/endpoints/baseendpoint.py#L58-L67)

*Tags: General Technical*

---

**Jonjonjon** - *23:53:50*

It accidentally popped up in my code after I un-commented some `numba` decorators that I'd commented out for debugging purposes many moons ago.:disappointed:

*Tags: Errors Debugging*

---

## 2022-02-12

**Nacho Uve** - *19:15:12*

I find a lot these errors in the log using "marketrecorder.py":



{"asctime": "2022-02-12 18:08:02,572", "levelname": "ERROR", "message": "poll_market_catalogue error", "exc_info": "Traceback (most recent call last):\n  File \"c:\\users\\myuser\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\flumine\\worker.py\", line 128, in poll_market_catalogue\n    market_catalogues = client.betting_client.betting.list_market_catalogue(\n  File \"c:\\users\\myuser\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\betfairlightweight\\endpoints\\betting.py\", line 233, in list_market_catalogue\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"c:\\users\\myuser\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"c:\\users\\myuser\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue \nParams: {'filter': {'marketIds': ['1.194430217', '1.194430009', '1.194553817', '1.194429905', '1.194430113', '1.194441740']}, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'maxResults': 25} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang11a-prd-02010955-99993c3ac9', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang11a-prd-02010955-99993c3ac9', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_market_catalogue", "response": "SportsAPING/v1.0/listMarketCatalogue \nParams: {'filter': {'marketIds': ['1.194430217', '1.194430009', '1.194553817', '1.194429905', '1.194430113', '1.194441740']}, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'maxResults': 25} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang11a-prd-02010955-99993c3ac9', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang11a-prd-02010955-99993c3ac9', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}



More lines of example here:

[https://pastebin.com/2VutqGi8](https://pastebin.com/2VutqGi8)



So, it returns a errorCode: 'INVALID_SESSION_INFORMATION'.   It is strange because the program continues with the recording, and the files stream files are OK, makes the gzip, etc.

*Tags: Errors Debugging, Strategies*

---

## 2022-02-13

**Mo** - *09:01:27*

To be clear, you're getting the error when trying to scrape the market catalogues. So your prices files may continue to be scraped OK but you'll be missing the corresponding market catalogues

*Tags: Errors Debugging*

---

**Brøndby IF** - *18:04:12*

```import datetime

import pandas as pd

import betfairlightweight

import time



username = 'AAAAAAAAAAAAAAAAAAAAAA'

pw = 'BBBBBBBBBBBBBBBBBB'

app_key = 'CCCCCCCCCCCCCC'



trading = betfairlightweight.APIClient(username, pw, app_key=app_key, cert_files=('./certs/myAppBetfair1.crt','./certs/client-2048.key'))

trading.login()



df_final = pd.DataFrame()

for i in range(0,1):

    order_filter = betfairlightweight.filters.ex_best_offers_overrides(

        best_prices_depth=3

    )



    price_filter = betfairlightweight.filters.price_projection(

        price_data=['EX_BEST_OFFERS'],

        ex_best_offers_overrides=order_filter

    )



    # Obtendo odds para o mercado

    market_books = trading.betting.list_market_book(

        market_ids=['1.190674822'],

        price_projection=price_filter

    )



    #Lista de runners

    runners = market_books[0].runners



    back = []

    for i in range(0,3):

        try:

            back.append([runner_book.ex.available_to_back[i].price

                                    if runner_book.ex.available_to_back

                                    else 1.01

                                    for runner_book

                                    in runners])

        except:

            back.append([1.01,1.01])



    df_back = pd.DataFrame(back,columns=['Casa','Visitante','Empate'])

    df_back['data'] = datetime.datetime.now()

    df_final = df_final.append(df_back)

    time.sleep(2)```

To collect the odds offered in back I use this code, could someone help me and show me how the code would look if I wanted to collect the lastPriceTraded instead of the offered odds?



The person who helps me with codes is on vacation and I really need help to do this, unfortunately I can't do it alone.

*Tags: Feature Engineering, Strategies*

---

**Brøndby IF** - *18:10:48*

Hi [@UBS7QANF3](@UBS7QANF3) Thank you very much for your help, I appreciate you making yourself available to help!

*Tags: General Technical*

---

**Brøndby IF** - *20:16:31*

```order_filter = betfairlightweight.filters.ex_best_offers_overrides(

    best_prices_depth=3

)



price_filter = betfairlightweight.filters.price_projection(

    price_data=['EX_BEST_OFFERS'],

    ex_best_offers_overrides=order_filter

)



# Obtendo odds para o mercado

market_books = trading.betting.list_market_book(

    market_ids=jogo_betfair_exchange_mercados['IDMercado'],

    price_projection=price_filter

)



#Lista de runners

runners = market_books[0].runners```

hi guys, please help me understand why this error is occurring and what should I do to solve it?



The error is:



```betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook

Params: {'marketIds': '1.194661463', 'priceProjection': {'priceData': ['EX_BEST_OFFERS'], 'exBestOffersOverrides': {'bestPricesDepth': 3}, 'virtualise': True, 'rolloverStakes': False}}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}```



*Tags: Errors Debugging, Strategies*

---

**Brøndby IF** - *20:22:54*

```jogos_betfair_exchange_mercados = json.load(open('jogos_betfair_exchange_mercados.json'))

    for jogo_betfair_exchange_mercados in jogos_betfair_exchange_mercados:

        id_market = jogo_betfair_exchange_mercados['IDMercado']```

[@UBS7QANF3](@UBS7QANF3) Thanks again for being willing to help, next, the values are in a `JSON` file, the value of id_market I find in this path, I couldn't understand what I should modify, because I manually write the market, it works.

*Tags: General Technical*

---

## 2022-02-14

**Paul** - *16:23:18*

I'm going to be dreaming of `betfairlightweight.exceptions.InvalidResponse: Invalid response received: [{'eventType': {'id': '7'}, 'marketCount': 357}]` all night. It's like a special valentine's day treat...

*Tags: Errors Debugging*

---

**Paul** - *16:25:10*

Card from Betfair in the post: Roses are red, violets are blue, this Valentine's Day `Invalid response received` is my exception for you!

*Tags: Errors Debugging*

---

**Laybot McBackbot** - *16:37:42*

I am getting a lot of errors!!

*Tags: Errors Debugging*

---

**mandelbot** - *16:37:54*

Same here. 503 errors

*Tags: Errors Debugging*

---

**D C** - *16:45:48*

Is there a best practice for what to do with a 503 error? I just have an alert that tells me I need to kill my bots but this seems a bit excessive.

*Tags: Errors Debugging*

---

**liam** - *16:48:55*

You don't need to kill, you can just wait for it to fix itself and then carry on

*Tags: Errors Debugging*

---

**Paul** - *16:51:21*

that's with betfairlightweight. flumine just does the right thing, it seems :-)

*Tags: General Technical*

---

**D C** - *16:51:54*

OK ill see how flumine deals with it.

*Tags: General Technical*

---

**liam** - *16:52:55*

its in bflw, it does nothing [https://github.com/liampauling/betfair/blob/0dd9c151d58ef1cfa065fa12dccd69e52104bc74/betfairlightweight/streaming/listener.py#L218](https://github.com/liampauling/betfair/blob/0dd9c151d58ef1cfa065fa12dccd69e52104bc74/betfairlightweight/streaming/listener.py#L218)

*Tags: General Technical*

---

**liam** - *17:04:25*

You just wait, they close the socket completely on a problem but if 503 is given you just have to wait

*Tags: General Technical*

---

**D C** - *17:05:43*

So basically all you need to make bet placement logic aware so that things don't try to act. Have to say that is a lot cleaner solution than I expected it to be. I've always just killed things and reset when it looks to be resolved.

*Tags: General Technical*

---

**Aaron Smith** - *23:09:54*

i never care and let flumine run whatever happens #trustliam

*Tags: General Technical*

---

## 2022-02-16

**river_shah** - *11:24:18*

What are the reasons why this may occur?

```WARNING[betfairlightweight.streaming.stream:on_update:68] [OrderStream: 1001]: Latency high: 1.75960373878479```

Not seeing high latency warnings on `MarketStream` so strategy is definitely keeping up with market data

*Tags: Performance, Strategies*

---

**liam** - *11:25:10*

Lots of orders? Regular? Latency constant or increasing? Can't say I have ever had this with the order stream

*Tags: Performance*

---

**Aaron Smith** - *11:30:09*

Had this when placing lots of orders on a single market_book, chunking them together in a single transaction solved it for me.

*Tags: General Technical*

---

**Aaron Smith** - *11:41:04*

[@U4H19D1D2](@U4H19D1D2) mh, actually not super sure, i know i ve had the latency warning on the orderStream, but not 100% sure if it was the case in this particular case. My logs dont reach far back enough to check it.

*Tags: Performance*

---

## 2022-02-17

**Stefan** - *09:12:08*

[@U02QDJCK3NW](@U02QDJCK3NW) Betfair rest api offers CompetitionIds, UEFA Champions League has 228 CompetitionId. I do not know why betfair did not implemented the same filter to streaming api. In the streaming api we have got Venues filter, but that works only for horse racing.



 [@UUUAJQZ5J](@UUUAJQZ5J) you work for betfair, please put to your list of suggestions implementing all features of rest api filter to streaming api, or at least extending functionality of venues to all events, in this case venue would be competition name, like UEFA Champions League.



Here is my test code. My code implementation uses Subscribe function that can take streaming filter, or markets, so it this case, I have queried markets by:



let filter = [ CompetitionIds [| 228 |]; MarketTypeCodes [| "MATCH_ODDS" |] ]



and then subscribed to streaming api, lines from 74 to 78:



[https://github.com/StefanBelo/Bfexplorer-BOT-SDK/blob/master/TestStreamingAPI/Program.fs](https://github.com/StefanBelo/Bfexplorer-BOT-SDK/blob/master/TestStreamingAPI/Program.fs)



As my code implements 2 Subscribe function, I can call first Subscribe to:



let filter = [ BetEventFilterParameter.BetEventTypeIds [| 1 |]; BetEventFilterParameter.Countries [| "GB" |]; BetEventFilterParameter.MarketTypeCodes [| "MATCH_ODDS" |] ]



and the next call to Subscribe by using markets, re-subcribers all already open markets plus new ones.



If you are .net developer you can use my bot sdk, if not you can reengineer my solution to your code.



Here is short video from my test:



[https://youtu.be/EGsYN0RXtNw](https://youtu.be/EGsYN0RXtNw)

*Tags: Feature Engineering*

---

**Mo** - *09:20:54*

[@UNW8Q88EL](@UNW8Q88EL) is the appropriate person to tag. But this is a very well known limitation, if it was easy to fix I'm sure they would have

*Tags: Errors Debugging*

---

**Stefan** - *09:52:20*

Thanks [@UNW8Q88EL](@UNW8Q88EL) for clarification, but as you implemented venues to streaming api you can at least extend this functionality as I suggested. Well, I have no problems with current implementation as you can see from my code I implemented workaround for such use case scenarios, but for new comers to betfair api it would be helpful to directly filter by "meta text" any betfair events offer.

*Tags: General Technical*

---

**Aaron Smith** - *22:24:33*

Lately my market_recorder is throwing some of those bois below over the day. Often times the market_recorder fails to put the market files into the s3 bucket (at any step, all i know for now is they are not in the bucket at the end of the day). For a single day/run cycle of the market recorder, either all or none of markets that have orders in them makes it into the bucket. Anyone having an idea whats going on here?

```{"asctime": "2022-02-16 19:08:14,104", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):

  File \"/path/prod_market_recorder/venv/lib/python3.10/site-packages/flumine/worker.py\", line 230, in _get_cleared_market

    cleared_markets = betting_client.betting.list_cleared_orders(

  File \"/path/prod_market_recorder/venv/lib/python3.10/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File \"/path/prod_market_recorder/venv/lib/python3.10/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request

    self._error_handler(response_json, method, params)

  File \"/path/prod_market_recorder/venv/lib/python3.10/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.194823061'], 'customerStrategyRefs': ['ip-xxx-xx-xx-x'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} 

Exception: None 

Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-02011018-001f0d3c34', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-02011018-001f0d3c34', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders 

Params: {'betStatus': 'SETTLED', 'marketIds': ['1.194823061'], 'customerStrategyRefs': ['ip-xxx-xx-xx-x'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} 

Exception: None 

Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-02011018-001f0d3c34', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-02011018-001f0d3c34', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

*Tags: Data Quality, Errors Debugging, Strategies*

---

**Aaron Smith** - *22:26:13*

Note: i m not confident that the missing data in the s3 bucket is directly connected to this error message, as this error is not thrown for all market ids, but only a few. Thanks to anyone taking the time to have a look :blush:

*Tags: Errors Debugging*

---

## 2022-02-18

**liam** - *07:13:06*

Standard error 

*Tags: Errors Debugging*

---

## 2022-02-21

**AndyL** - *18:12:10*

Last night bot got numerous error: peer reset connection failures followed by you have exceeded your 10 subscriptions limit error...anyone seen that before?

Seemed to resolve itself after a few mins, but one consequence seemed to be that flumine lost track of an order, or maybe thought it had failed when it hadn't... so bot ended up hedging incorrectly...

*Tags: Errors Debugging*

---

## 2022-02-22

**Jonjonjon** - *08:41:38*

One Flumine instance uses one connection per instance for orders, plus one per market filter.

*Tags: General Technical*

---

**AndyL** - *19:02:23*

[@UPMUFSGCR](@UPMUFSGCR) i only restart scripts when needed for strategy upgrade

I think its betfair server glitches as [@UEA14GBRR](@UEA14GBRR) is seeing them at exactly same times

*Tags: Deployment, Strategies*

---

**AndyL** - *19:05:08*

[@UGV299K6H](@UGV299K6H) going a lot better thanks, some things have become clearer and potentially learning how to find value and how to execute to get it, but ill let you know in a month or so...!

*Tags: General Technical*

---

## 2022-02-23

**Nacho Uve** - *12:16:43*

I've made a dummy strategy to get familiarized with the framework and backtesting.

I feed it with just one market file that I recorded, and it is just configured to place a back bet at a specific price when the match starts.



I see the order is placed correctly in the logs.



That price is reached after some minutes and log shows that the order is matched [EXECUTION_COMPLETED].

But when I summarized using the blotter, it looks like it was nothing there. No winning or losses.



&gt; marketId      sel_id  date_time_placed	   Order.status			price  avg_price_matched  size_matched    profit

&gt; 1.193102045   56085   2022-01-26 19:48:55    EXECUTION_COMPLETE 	1.6    0.0                0.0             -0.0



Where is my error?



Strategy Code here: [https://pastebin.com/amQPbdKN](https://pastebin.com/amQPbdKN)

*Tags: Errors Debugging, Strategies*

---

**Nacho Uve** - *12:18:38*

The strategy is initialized like that:

```    strategy = Dummy_Strategy(

        market_id = '1.193102045',

        selection_id = 56085,

        market_filter={

            "markets": markets,

            "market_types":["MATCH_ODDS"],

            "listener_kwargs": {"seconds_to_start": 600},

        }

    )

    framework.add_strategy(strategy)```

Do you need the market file? Is it right to share it?

*Tags: Strategies*

---

**liam** - *12:29:10*

Try copying this [https://github.com/liampauling/flumine/blob/bc4d18a941778f41087b055c5c8d3f00ccd63201/examples/controls/backtestloggingcontrol.py#L65|https://github.com/liampauling/flumine/blob/bc4d18a941778f41087b055c5c8d3f00ccd63201/examples/controls/backtestloggingcontrol.py#L65](https://github.com/liampauling/flumine/blob/bc4d18a941778f41087b055c5c8d3f00ccd63201/examples/controls/backtestloggingcontrol.py#L65|https://github.com/liampauling/flumine/blob/bc4d18a941778f41087b055c5c8d3f00ccd63201/examples/controls/backtestloggingcontrol.py#L65)

*Tags: General Technical*

---

## 2022-02-24

**Rob** - *06:11:16*

So I’ve been working on creating a historic/recorded parser for bflw objects, and im just testing the output now, and I have a difference in ladders I cant explain

*Tags: General Technical*

---

**Rob** - *06:12:30*

after about 15k updates on a market, out ladders diverge like this (new 1, bflw 2)

```Previous state (match)

1 [2.32, 23.96] [2.3, 53.6] [2.28, 123.69] [2.26, 65.64] [2.24, 63.93] [2.22, 0.4] [2.2, 23.12] [2.18, 131.73] [2.16, 62.74] [2.14, 23.73] [2.12, 7.96] [2.1, 686.0] [2.08, 21.54] [2.06, 10.2] [2.04, 79.39] [2.02, 35.0] [2.0, 552.09] [1.99, 120.44] [1.98, 10.2] [1.92, 13.02] [1.91, 66.76] [1.9, 240.0] [1.83, 24.09] [1.8, 40.5] [1.75, 376.0] [1.7, 45.5] [1.6, 20.5] [1.57, 529.82] [1.56, 12.0] [1.55, 86.36] [1.5, 4.5] [1.35, 6.0] [1.3, 3.72] [1.23, 9.0] [1.22, 2.0] [1.21, 50.0] [1.11, 10.0] [1.1, 393.49] [1.06, 50.0] [1.05, 20.0] [1.03, 1725.46] [1.02, 5169.35] [1.01, 1471.32]



2 [2.32, 23.96] [2.3, 53.6] [2.28, 123.69] [2.26, 65.64] [2.24, 63.93] [2.22, 0.4] [2.2, 23.12] [2.18, 131.73] [2.16, 62.74] [2.14, 23.73] [2.12, 7.96] [2.1, 686] [2.08, 21.54] [2.06, 10.2] [2.04, 79.39] [2.02, 35] [2, 552.09] [1.99, 120.44] [1.98, 10.2] [1.92, 13.02] [1.91, 66.76] [1.9, 240] [1.83, 24.09] [1.8, 40.5] [1.75, 376] [1.7, 45.5] [1.6, 20.5] [1.57, 529.82] [1.56, 12] [1.55, 86.36] [1.5, 4.5] [1.35, 6] [1.3, 3.72] [1.23, 9] [1.22, 2] [1.21, 50] [1.11, 10] [1.1, 393.49] [1.06, 50] [1.05, 20] [1.03, 1725.46] [1.02, 5169.35] [1.01, 1471.32]```

```After update (not match)



1 [2.32, 23.96] [2.3, 53.6] [2.28, 123.69] [2.26, 65.64] [2.24, 63.93] [2.22, 0.4] [2.2, 15.41] [2.18, 131.73] [2.16, 62.74] [2.14, 23.73] [2.12, 7.96] [2.1, 686.0] [2.08, 21.54] [2.06, 10.2] [2.04, 141.39] [2.02, 35.0] [2.0, 552.09] [1.99, 120.44] [1.98, 10.2] [1.92, 13.02] [1.91, 66.76] [1.9, 240.0] [1.83, 24.09] [1.8, 40.5] [1.75, 376.0] [1.7, 45.5] [1.6, 20.5] [1.57, 529.82] [1.56, 12.0] [1.55, 86.36] [1.5, 4.5] [1.35, 6.0] [1.3, 3.72] [1.23, 9.0] [1.22, 2.0] [1.21, 50.0] [1.11, 10.0] [1.1, 393.49] [1.06, 50.0] [1.05, 20.0] [1.03, 1725.46] [1.02, 5169.35] [1.01, 1471.32]



2 [2.3, 53.6] [2.28, 123.69] [2.26, 65.64] [2.24, 63.93] [2.22, 0.4] [2.2, 15.41] [2.16, 62.74] [2.14, 23.73] [2.12, 7.96] [2.1, 686] [2.08, 21.54] [2.06, 10.2] [2.04, 141.39] [2.02, 35] [2, 552.09] [1.99, 120.44] [1.98, 10.2] [1.92, 13.02] [1.91, 66.76] [1.9, 240] [1.83, 24.09] [1.8, 40.5] [1.75, 376] [1.7, 45.5] [1.6, 20.5] [1.57, 529.82] [1.56, 12] [1.55, 86.36] [1.5, 4.5] [1.35, 6] [1.3, 3.72] [1.23, 9] [1.22, 2] [1.21, 50] [1.11, 10] [1.1, 393.49] [1.06, 50] [1.05, 20] [1.03, 1725.46] [1.02, 5169.35] [1.01, 1471.32]



diff: [2.32, 23.96] and [2.18, 131.73] are missing from bflw```

*Tags: General Technical*

---

**Rob** - *06:21:58*

but the update doesnt say to remove 2.32 or 2.18, so is bflw doing something clever here and merging suspended market updates or something.

I read through the bflw code that handles ladders, and I cant see anything.



And this is 1 ladder different in like 200k updates, so i doubt theres anything wrong with either parsing code. More likely something extra is happening in bflw that i havent replicated (or python is doing weird things with floats)

*Tags: General Technical*

---

**Rob** - *07:26:16*

looks like that fixed it!, i wasnt handling img properly all the time. thanks [@UBS7QANF3](@UBS7QANF3)

*Tags: Errors Debugging*

---

**river_shah** - *09:11:53*

```Anyone seeing this:



  File "/usr/local/lib/python3.9/site-packages/flumine/flumine.py", line 48, in run

    del event

  File "/usr/local/lib/python3.9/site-packages/flumine/baseflumine.py", line 399, in __exit__

    self._process_end_flumine()

  File "/usr/local/lib/python3.9/site-packages/flumine/baseflumine.py", line 354, in _process_end_flumine

    self.strategies.finish(self)

  File "/usr/local/lib/python3.9/site-packages/flumine/strategy/strategy.py", line 242, in finish

    s.finish(flumine)

TypeError: finish() takes 1 positional argument but 2 were given```



*Tags: Errors Debugging, Strategies*

---

**liam** - *09:16:58*

`strategy.finish` was [https://github.com/liampauling/flumine/blob/master/HISTORY.rst#1211-2022-01-10|updated](https://github.com/liampauling/flumine/blob/master/HISTORY.rst#1211-2022-01-10|updated) to take `flumine` as a variable, looks like you have strategy that looks like this



```def finish(self) -&gt; None:

    # called before flumine ends

    return```

instead of this



```def finish(self, flumine) -&gt; None:

    # called before flumine ends

    return```

*Tags: Strategies*

---

**river_shah** - *09:26:31*

Perfect, problem found. The offending strategy did indeed override `finish`

*Tags: Strategies*

---

**liam** - *13:21:38*

a simple integration tests where you simulate/process a market or two would have caught this, most valuable tests I have in production

*Tags: Deployment*

---

**Newbie99** - *18:35:29*

By chance is anyone having issues with listClearedOrders?



I keep getting this (seems to affect orders from 13:00 today onwards only), but everything seems to be operational:



```Params: {'betStatus': 'SETTLED', 'eventTypeIds': ['4339'], 'settledDateRange': {'from': '2022-02-24T13:00:00', 'to': '2022-02-24T14:00:00'}, 'includeItemDescription': True, 'fromRecord': 0} 

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)```

Or is it just a case of try a bit later, as its just a standard betfair timeout issue?

*Tags: Errors Debugging*

---

## 2022-02-25

**dont** - *16:37:34*

Hi folks, I'm trying to run the example from here: [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py) The login works fine and also the fileCount is retrieved ok, but the `get_list_files` fails and the error is not necessarily clear:

[https://gist.github.com/erikseulean/827218ab95ddd13f519505aed839b142](https://gist.github.com/erikseulean/827218ab95ddd13f519505aed839b142)



I did try to do a POST directly and I'm getting the same issue. I think there might be a misconfiguration on my side but I'm not entirely sure what exactly the issue is. Anybody had the same issue by any chance ?

*Tags: Errors Debugging*

---

## 2022-02-28

**William** - *20:07:24*

What would be causing 'NOT_AUTHORIZED: AppKey is not configured for service' errors?

*Tags: Errors Debugging*

---

**William** - *20:07:46*

```   # setup logging

    logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updat



    # create trading instance

    trading = betfairlightweight.APIClient(user, password, app_key=appKey, certs='/certs')



    # login

    trading.login_interactive()

    # create queue

    output_queue = queue.Queue()



    # create stream listener

    listener = betfairlightweight.StreamListener(

        output_queue=output_queue

        # lightweight=True

    )

    # create stream

    stream = trading.streaming.create_stream(

        host="race",

        listener=listener

    )

    # create filters (GB WIN racing)



    market_filter = streaming_market_filter(

        # event_type_ids=['7'],

        # country_codes=['AU'],

        # market_types=['WIN'],

        market_ids=market_id

    )

    market_data_filter = streaming_market_data_filter(

        # fields=['EX_LTP', "EX_ALL_OFFERS", 'EX_MARKET_DEF', 'EX_TRADED_VOL', 'EX_TRADED'],

        # fields=['EX_ALL_OFFERS', 'EX_MARKET_DEF'],

        # ladder_levels=9,

    )

    # subscribe

    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=100,  # send update every 1000ms

    )

    stream.start()

    return trading, output_queue, listener```

*Tags: Getting Started, Errors Debugging, Strategies*

---

**Mo** - *20:09:14*

Is your app key old? Is this your first time using streaming?

*Tags: Getting Started*

---

**Mo** - *20:10:29*

Older app keys need to have streaming separately activated

*Tags: General Technical*

---

**Mo** - *20:19:23*

To be honest I'm surprised that one you previously used for streaming would no longer work but the message is crystal clear. You need to get the app key activated for streaming

*Tags: General Technical*

---

**William** - *23:18:37*

Yes. It was something I added when trying to fix the issue

*Tags: Errors Debugging*

---

## 2022-03-02

**Aaron Smith** - *09:08:29*

Hey ppl, my market_recorder (from flumine) creates a bunch of folders with random unique names (like "	7d7eb804"). Inside are (mostly) unpacked streaming_data and market_catalogue files. They dont get deleted. What is the purpose of these folders?

*Tags: General Technical*

---

**Aaron Smith** - *09:47:53*

the way i understand it, after the market closes, the streaming_data is put into the recorder_id_folder, where it gets compressed, uploaded and cleaned. But i dont understand why i m stil left with all these files in those folders, shouldnt they be cleaned up?

*Tags: General Technical*

---

**liam** - *09:57:42*

[https://github.com/liampauling/flumine/blob/0f12a0f9d200b4a4c36c8bd26c9f4fbe82f8cce1/examples/strategies/marketrecorder.py#L24](https://github.com/liampauling/flumine/blob/0f12a0f9d200b4a4c36c8bd26c9f4fbe82f8cce1/examples/strategies/marketrecorder.py#L24)

*Tags: General Technical*

---

**Aaron Smith** - *10:15:47*

goal is restart once a day. Here i m also not sure if maybe i skip markets, because the main reason i ended up investigating this area is because some days no data ends up in the s3_bucket, which i thought may be due to how i initiate my market_recorder. i use this terminate function:

```def terminate_if_all_markets_closed(context: dict, flumine, today_only: bool = True, seconds_closed: int = 600) -&gt; None:



    markets = list(flumine.markets.markets.values())



    if today_only:

        markets_today = [m for m in markets if m.market_start_datetime.date() == datetime.datetime.utcnow().date() and

                         (m.elapsed_seconds_closed is None or m.elapsed_seconds_closed and m.elapsed_seconds_closed &lt; seconds_closed)]

        market_count = len(markets_today)

    else:

        market_count = len(markets)



    if market_count == 0:

        [http://logger.info|logger.info](http://logger.info|logger.info)("No more markets available, terminating framework")

        flumine.handler_queue.put(TerminationEvent(flumine))```

and add the terminator like this:

```terminator = flumine.worker.BackgroundWorker(flumine=framework,

                                                 function=base_functions.terminate_if_all_markets_closed,

                                                 func_kwargs={"today_only": True, "seconds_closed": 1200},

                                                 interval=300,

                                                 start_delay=600)```

*Tags: General Technical*

---

**foxwood** - *12:42:15*

Not sure you end up with anything useful with both remove_file and remove_gz_file set to True as shown in your code. I think that will delete any compressed file and also it's raw parent. The only thing that might be left will be tomorrow's uncompressed files for markets that haven't closed but are opened the night before by BF.

Edit: Thats MarketRecorder _clean_up behaviour - S3MarketRecorder doesn't appear to make a local .gz which _clean_up needs to trigger the market catalogue delete. Explains catalogues being left and also streaming files for tomorrow's events. I think !

*Tags: General Technical*

---

**liam** - *19:43:00*

meta gives you the blotter (flumine) `Order` as opposed to betfair cleared orders response

*Tags: General Technical*

---

## 2022-03-04

**Ruben** - *08:33:51*

I have adapted the example backtest logging control from the flumine repo to be used to log orders after a market closes. To use the real profit of the order I replaced the profit field with

```"profit": 0 if not order.cleared_order else order.cleared_order.profit```

so that the profit is only accessed if there is a ClearedOrder object. However, I am seeing that the profit being stored is always 0, even for orders from markets that have some size matched. Any ideas about what I'm doing wrong?

*Tags: General Technical*

---

## 2022-03-05

**ThomasJ** - *10:03:50*

[@U011VL3CA2Y](@U011VL3CA2Y) Yes Excel does 'things' to data and it's a damn nuisance and I trip over it all the time.



So whilst on the subject of looking at data visually...

I program in Python for Betfair stuff (relatively newish) and of course use Pandas DataFrames extensively.

I often dump the DataFrame to disk as '.csv'.

To look at this '.csv' file in a 'raw' (unaltered way) I use Notepad++, but of course it's hard to see things columnar wise.

Is there any way I can look at data in columns with headings in it's raw state?

*Tags: Feature Engineering*

---

**Ruben** - *10:23:22*

yes, what I do to look at data in a columnar way is use jupyter notebooks (is installed automatically if you install the python anaconda environment). With that you can directly read a csv with pandas, and then look at as many rows of the dataframe you want

*Tags: Getting Started, Feature Engineering*

---

**Stefan** - *12:09:24*

[@U011VL3CA2Y](@U011VL3CA2Y), [@U9JHLMZB4](@U9JHLMZB4) I do this for data strategy visualization: [https://youtu.be/FM79mZWkfxI?t=56](https://youtu.be/FM79mZWkfxI?t=56)



Basically there are 3 types of data: scalar,  object, collection. And so to visualize them I use property browse, grid view and chart view.

*Tags: Strategies*

---

## 2022-03-07

**Aaron Smith** - *19:21:41*

can anyone help me on this one? I feel like this should be easy but somehow i m stuck anyway :smile: Goal is to not overwrite what liam has produced

*Tags: General Technical*

---

**Ruben** - *19:31:31*

where are you seeing these files? I don't think my market recorder creates them

*Tags: Data Quality*

---

**mandelbot** - *19:33:35*

That's where the files are saved. You can name it yourself by setting a recorder_id. it defaults to a random [https://github.com/liampauling/flumine/blob/0f12a0f9d200b4a4c36c8bd26c9f4fbe82f8cce1/examples/strategies/marketrecorder.py#L29](https://github.com/liampauling/flumine/blob/0f12a0f9d200b4a4c36c8bd26c9f4fbe82f8cce1/examples/strategies/marketrecorder.py#L29)

*Tags: General Technical*

---

**Mo** - *19:35:53*

[https://github.com/liampauling/flumine/blob/0f12a0f9d200b4a4c36c8bd26c9f4fbe82f8cce1/examples/strategies/marketrecorder.py#L29](https://github.com/liampauling/flumine/blob/0f12a0f9d200b4a4c36c8bd26c9f4fbe82f8cce1/examples/strategies/marketrecorder.py#L29)

*Tags: General Technical*

---

**Aaron Smith** - *19:37:05*

[@UBS7QANF3](@UBS7QANF3) how is changing the dir name helping?

*Tags: General Technical*

---

**Aaron Smith** - *19:39:02*

i used to, now it doesnt restart and from what i can see basically all streaming files end up in the tmp/recorder_id folder (only the uncompressed file)

*Tags: General Technical*

---

**Aaron Smith** - *19:42:04*

s3_recorder is on the newest version, only difference is my add function:

```    def add(self) -&gt; None:

        [http://logger.info|logger.info](http://logger.info|logger.info)("Adding strategy %s with id %s" % (self.name, self.recorder_id))

        # check local dir

        if not os.path.isdir(self.local_dir):

            os.makedirs(self.local_dir)  # added by smiffy

            # raise OSError("File dir %s does not exist" % self.local_dir) &lt;- original by liam

        # create sub dir

        directory = os.path.join(self.local_dir, self.recorder_id)

        if not os.path.exists(directory):

            os.makedirs(directory)```

Trying to fix the problem i restarted the recorder from scratch and got tired of manually making the local file each time :smile:

*Tags: Errors Debugging, Strategies*

---

**Aaron Smith** - *21:20:17*

This is my s3 market_recorder, i d appreciate if someone can confirm he uses something simular and is not endlessly stacking up on streaming data in the recorder_id-folder, just so i know its gotta be at my end somehwere (whereever that may be, its kinda all liams code, but i m sure i m missing something... )

```S3MarketRecorder(

        name="MarketRecorder_horses",

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        stream_class=DataStream,

        context={

            "local_dir": "./tmp",

            "force_update": False,

            "bucket": "mybucket",

            "remove_file": True,

            "remove_gz_file": True,

            "market_expiration": 300,

        },

    )```

*Tags: General Technical*

---

**Aaron Smith** - *21:24:11*

eventually it creates space problems with the files piling up, also i was having missing files in the s3_bucket, so i m trying to get it working properly. It just feels like there isnt much where i could go wrong. I get it from flumine and run it, but somehow it still wont work properly

*Tags: General Technical*

---

## 2022-03-08

**J** - *09:24:55*

UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 82: character maps to &lt;undefined&gt; &lt;--Does anyone hit this a lot in Flumine when loading stored markets on disk (like historic files)? I'm hitting it often but somewhat randomly. Hitting it in both historic files and also marketrecorded files



Ful trace: Traceback (most recent call last):

  File "c:\Users\heari\Desktop\flumine\bfbulk v2.py", line 537, in &lt;module&gt;

    *framework.add_strategy(strategy2)*

  File "C:\Users\heari\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\baseflumine.py", line 90, in add_strategy

    self.streams(strategy)  # create required streams

  File "C:\Users\heari\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\streams\streams.py", line 45, in __call__

    market_type = get_file_md(market, "marketType")

  File "C:\Users\heari\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\utils.py", line 67, in get_file_md

    first_line = f.readline()

  File "C:\Users\heari\AppData\Local\Programs\Python\Python39\lib\encodings\cp1252.py", line 23, in decode

    return codecs.charmap_decode(input,self.errors,decoding_table)[0]

*UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 82: character maps to &lt;undefined&gt;*

*Tags: Errors Debugging, Strategies*

---

**Unknown** - *09:42:56*

Anyone ever had its amazon ec2 instance run out of CPU credits? I think that is making one of my instance checks fail, curious to see if anyone had it happen. I can no longer SSH into the instance

*Tags: Deployment*

---

**Beeblebrox** - *10:36:55*

I had the same thing happen to me the other day - no cpu spikes or anything, but only 1/2 checks passed.  Stopping and restarting was the only thing that fixed it for me.

*Tags: Errors Debugging*

---

## 2022-03-09

**Brøndby IF** - *00:00:36*

Good evening everyone, is there any way I can make a call and find out all the possible paths of data I can collect? For example, in football by `trading.betting.list_events` I collect: `event.name, event.id, event.open_date`  and I would like to know if in Python there is any way to pull all the other paths to make it easier because I have difficulty understanding the way through the Betfair mapping, their site is very messy.

*Tags: Strategies*

---

**Brøndby IF** - *00:01:50*

Not that I want to collect all the data, but I just wanted a way to make it easier to map the data I want, seeing which way to go to get there, would help me a lot.

*Tags: General Technical*

---

**Dave** - *20:43:24*

Use a debugger after making the call, or just print(dir(response)) to see all its attributes

*Tags: Errors Debugging*

---

## 2022-03-10

**Brøndby IF** - *14:13:10*

Hi guys, today I'm getting this response when running the code, is it a one-time glitch or should I change something in my code? If necessary, I'll send you the complete code here. The error is this: `betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue`

`Params: {'filter': {'eventIds': ['31291900']}, 'marketProjection': ['RUNNER_METADATA'], 'sort': 'FIRST_TO_START', 'maxResults': '100'}`

`Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)`

*Tags: Errors Debugging*

---

**Brøndby IF** - *14:13:58*

I just sent the error to know if it's something that sometimes happens or if it's because of some code failure.

*Tags: Errors Debugging*

---

**Brøndby IF** - *14:20:57*

The error now wasn't in a specific eventid, it didn't even load the call data:



`betfairlightweight.exceptions.APIError: None`

`Params: None`

`Exception: HTTPSConnectionPool(host='[http://identitysso.betfair.com|identitysso.betfair.com](http://identitysso.betfair.com|identitysso.betfair.com)', port=443): Read timed out. (read timeout=3.05)`

*Tags: Errors Debugging*

---

**Brøndby IF** - *14:22:36*

Hi [@U4H19D1D2](@U4H19D1D2) I work with python and I'm making the call directly from Visual Studio Code, can I send my code, would it be useful?

*Tags: General Technical*

---

**liam** - *14:28:16*

that error normally points to a bad connection to betfair

*Tags: Errors Debugging*

---

## 2022-03-11

**LM** - *07:21:49*

Hey All,

What's the best way to extract the race distance (for Aus horse racing) from the Flumine stream.

*Tags: General Technical*

---

**LM** - *07:23:47*

Which worked fine in back testing, but in production this afternoon

*Tags: Deployment*

---

**LM** - *07:24:13*

Any help appreciated!

*Tags: General Technical*

---

**LM** - *07:26:10*

Is the catalogue easily accessible through flumine? Or best to pull using bflw

*Tags: General Technical*

---

**LM** - *07:36:18*

Another stupid question:

When using the streaming_market_filter to get just the Aus racing market (filter below) this afternoon I ran into issues of "trying to subscribe to over 200 streams" (something along those lines).



```market_filter=streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["WIN"],

        turn_in_play_enabled=True

    )```

Are there any common design patterns used to get around this?

*Tags: General Technical*

---

**Paul** - *14:20:15*

Possibly stupid question: is it possible to use the DataStream and `process_raw_data` with data recorded with the market recorder? I tried to throw it in there to debug something around what I'm doing in `process_market_book` and it didn't seem to fire.

*Tags: Data Quality, Errors Debugging*

---

**liam** - *14:22:03*

you can however see the raw data with `market_book.streaming_update`

*Tags: General Technical*

---

**Dave** - *14:38:27*

Hi all, I'm hoping for some help from experts. I've been trying to get to grips with the API using Python so that I don't have to outsource it but I'm running in to the following error:



raise APIError(None, exception=e)

betfairlightweight.exceptions.APIError: None

Params: None

Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3932)')))



I'm pretty green so my apologies if this is something obvious - I saw this was asked on the Betfair Developer Forum and the OP was directed here as Liam said it had been answered - it was over a year ago though so I can't find the thread.....

*Tags: Errors Debugging*

---

**Dave** - *14:49:47*

My end goal is to populate a poisson model with betfair odds and fixtures

*Tags: Errors Debugging, Strategies*

---

**Mo** - *14:52:10*

Looks to me the problem is with the certificate

*Tags: General Technical*

---

## 2022-03-14

**Mo** - *06:05:17*

What version of Python?

*Tags: General Technical*

---

**Ruben** - *18:33:17*

is there any way to monitor RAM usage of an ec2 instance? in the same way we can see graphs with cpu &amp; network usage

*Tags: Deployment*

---

**liam** - *20:34:37*

Are you using bflw?





```    @staticmethod

    def create_race_card_req(market_ids: list, data_entries: str) -&gt; dict:

        if not data_entries:

            data_entries = "RACE, TIMEFORM_DATA, RUNNERS, RUNNER_DETAILS"

        return {"dataEntries": data_entries, "marketId": ",".join(market_ids)}



```

*Tags: General Technical*

---

**Mo** - *20:45:38*

Still does not work with the same error code?

*Tags: Errors Debugging*

---

## 2022-03-15

**Paul** - *08:27:31*

It's not turned on by default as it means giving AWS visibility of OS level metrics rather than host level metrics, but this should help you get it moving: [https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html|https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html|https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html)

*Tags: Deployment*

---

**Tiago Rigo** - *23:22:14*

seems to be a problem with the certificate

*Tags: General Technical*

---

## 2022-03-16

**Tiago Rigo** - *00:49:19*

ok I found out. my problem was using a different Signatura algorithm (default was SHA 256, and it goes with SHA 512)

*Tags: General Technical*

---

## 2022-03-17

**Nacho Uve** - *12:39:04*

I don't understand something I'm seeing when backtesting a very simple strategy.



My strategy backs a selection at price @1.71. The order is placed and it has  status "Executable".  Ok.



Then the price of that selection is rising and at some point it is greater that @1.71. But it is not matched, although it has enough "size" to do it.



What do you think could bt the problem here?

*Tags: Strategies*

---

## 2022-03-18

**Nacho Uve** - *08:59:33*

Sorry, I have no time yesterday to send them.



Here there are the logs with one of the cases.



The strategy places some orders with prices greater than the current ones.



So, here is what happens:



- Order 100000000001: Back 2.00€ - @1.41 is matched when [back 1.37 - lay 1.42] at the price @1.41  (Better than the best back market_book price for that selection. Is it part of the backtesting to simulate the behaviour of the real market?)

- Order 100000000002: Back 2.67€ - @1.47 is matched when [back 1.49 - lay 1.56] at the price @1.47. (It does not match the best price )

- Order 100000000003: Back 1.00€ - @1.60 is matched when [back 1.55 - lay 1.61] at the price @1.60. (Case 1)

- Order 100000000004: Back 1.00€ - @1.66 is matched when [back 1.64 - lay 1.77] at the price @1.66. (Case 1)



The zip includes:

• file with the regular logs

• file some prints with extra info with the market_book prices and other state of the strategy

• the recorded stream file (it is recorded with the delayed api key)

*Tags: Strategies*

---

**liam** - *11:08:40*

That is your problem 

*Tags: General Technical*

---

**Nacho Uve** - *11:45:06*

I'm taking a look at `flumine/backtest/simulated.py` to try to understand...

But I only see ``best_price_execution`` in the function `place()`, but not in `_process_price_matched()`or `_update_matched()` .



Could that be a problem?

*Tags: General Technical*

---

## 2022-03-24

**liam** - *16:06:16*

From Neil



```The service has now been restarted.  The problem was caused by an issue at our side with the related server, apologies for the inconvenience caused!```

*Tags: Deployment*

---

## 2022-03-26

**Jonjonjon** - *10:43:15*

In the order logs that Flumine places for me, I see that I placed some orders 8 days ago. However, they aren't in my cleared orders on the website. So Iel assume they were voided. But voided orders only go back 7 days. I think my strategy might be subject to this problem quite a lot as my live bet count is a lower than what I get if I subsequently run the same market through a backtest.



What is the best way to monitor this situation?

*Tags: Deployment, Strategies*

---

**mandelbot** - *16:18:49*

So I'm trying to use the example to login to the betconnect staging area but get the following error

```    return cls.parse_obj(d)

  File "pydantic\main.py", line 511, in pydantic.main.BaseModel.parse_obj

  File "pydantic\main.py", line 331, in pydantic.main.BaseModel.__init__

pydantic.error_wrappers.ValidationError: 1 validation error for AccountPreferences

building

  none is not an allowed value (type=type_error.none.not_allowed)```

How do i pass this `AccountPreference`  in?

*Tags: Errors Debugging, Strategies*

---

**Peter** - *16:43:44*

I have a very vague recollection of something similar happening to me on the staging site, when I started using it. It was unrelated to this wrapper (which didn't exist then) but was due to something missing from my account preferences.



I cured by manually editing my account preferences, but it would be helpful if we could trap what it is so that a warning can be added to the wrapper.

*Tags: General Technical*

---

**mandelbot** - *16:44:56*

Yes I've had a look at my account preferences on the site but am not seeing anything relevant. I did change odds to decimal and the error seems to have changed to



value is not a valid integer (type=type_error.integer)



rather than none is not an allowed value

*Tags: Errors Debugging*

---

**Oliver Varney** - *16:52:13*

Basically pedantic is very strict so if it'd told to accept a value and none is passed it will throw an error

*Tags: Errors Debugging*

---

**Peter** - *16:56:02*

I'd be disappointed if pedantic was anything but ... However, I didn't have that in my code, so I suspect that pedantic is simply catching early a problem that would have happened anyway when the request hit the BetConnect server.

*Tags: Deployment*

---

**mandelbot** - *17:17:38*

That seems to have resolved things. Thanks [@U02KNTX2Z7X](@U02KNTX2Z7X)

*Tags: General Technical*

---

**PeterLe** - *20:57:05*

The feed via betangel was fine, I wondered why I'd had a good night. The feed direct from Betfair API was there during the early part of the day as mine placed some bets that way too. 

*Tags: General Technical*

---

## 2022-03-28

**Kunal Maneck** - *07:55:04*

Any ideas how I can address lagging issues on my Linux ec2 instance? I have a 8cpu instance but still very slow when using Microsoft Remote Desktop on my Mac 

*Tags: Performance, Deployment*

---

**Kunal Maneck** - *08:05:38*

Thanks Mo! Can I get a Linux box on Aws?

*Tags: Deployment*

---

**Unknown** - *08:14:29*

Just for your reply :grin: Yes I am using a Remote Desktop to connect to a Linux ec2 instance but it’s very slow and lags 

*Tags: Performance, Deployment*

---

**Mo** - *08:17:37*

You mentioned vCPUs but those are going to be largely irrelevant for a lagging GUI. Network bandwidth/latency is much more important

*Tags: Performance*

---

**Mo** - *08:18:00*

The important question is why do you need a desktop environment on a remote server?

*Tags: Deployment*

---

## 2022-03-29

**Jonjonjon** - *21:47:39*

Suppose I have added 52 strategies to a single Flumine instance. They are all subscribed to the same market filter. Are there any conditions under which all 52 strategies' `check_market_book` / `process_market_book` functions won't be called?

*Tags: General Technical*

---

**Jonjonjon** - *21:50:49*

I'm still trying to debug the problem of missing bets (I'm getting lots of placed bets in the backtest, but they're not being place when live). After checking my live latency is fine, and then increasing the backtest latency to 1 second (where it still has lots of placed bets) I'm totally flumoxed.:disappointed:

*Tags: Errors Debugging, Performance, Deployment*

---

## 2022-03-30

**liam** - *07:36:14*

Very tricky for me to debug this, are you simulating with the same data you placing live, something must be different 

*Tags: Errors Debugging, Deployment*

---

**Jonjonjon** - *09:35:25*

I worked it out. It was a typical case on user error. In my check_market_book I was excluding NSW markets for live trading. But not for backtesting. Apologies for wasting everyone's time.:face_palm::skin-tone-6:

*Tags: Errors Debugging, Deployment, Strategies*

---

**Javier Martín Pérez** - *12:32:26*

Oh, so if I didn´t record it there is no way back directly with Betfair, am I right? I wasn´t recording any of the data as at first I didn´t care about the venue, but it seems that it has an impact on results. It´s Greyhounds where there it seems to be a big discrepancy on UK vs AU with my current strategy.

*Tags: Strategies*

---

**Javier Martín Pérez** - *12:35:34*

I guess than in a similar fashion to your mapping I could get the data from the historical data but that will take a while :disappointed: . Thanks for the help!

*Tags: Data Quality*

---

**Aaron Smith** - *12:59:51*

Suppose I have a flumine MarketRecorder running, recording all horse and greyhound markets. How much disk space should this roughly occupy? Also, suppose i want to filter by market_base rate for the market_recorder, does filtering in `check_market_book`  work or is there a better option?

*Tags: General Technical*

---

**Aaron Smith** - *13:13:05*

```def init_mr_horses():

    market_filter = betfairlightweight.filters.streaming_market_filter(event_type_ids=["7"],)

    market_data_filter = betfairlightweight.filters.streaming_market_data_filter(fields=["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"],

                                                                                 ladder_levels=2)

    return S3MarketRecorder(

        name="MarketRecorder_horses",

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        stream_class=DataStream,

        context={

            "local_dir": "./tmp",

            "force_update": False,

            "bucket": "mybucket",

            "remove_file": True,

            "remove_gz_file": True,

            "market_expiration": 300,

        },

    )```

*Tags: General Technical*

---

## 2022-04-04

**Jon K** - *13:23:24*

Hi, Just following some of the examples for Flumine and can place a bet ok (in fact, it places lots of bets...) but I'm struggling to see if a Runner already has a bet placed on it, so for example

Heres the simple Trade method

trade = Trade(

                    market_id=market_book.market_id,

                    selection_id=runner.selection_id,

                    handicap=runner.handicap,

                    strategy=self

                )

                order = trade.create_order(

                    side="BACK",

                    #order_type=LimitOrder(price= one_tick_higher(runner.sp / 2), size=2.00)

                    order_type=LimitOrder(price= 1000, size=2.00)

                )

                print (trade.status)

                market.place_order(order)

                print (trade.status)



But next time when I'm going through the Runners I try and use

runner.matches

runner.matches_by_strategy



but can't see anything obvious, they just show as 0 or [ ]

I've tried len(runner.matches_by_strategy) as I'm assuming its a list but I get 0.

I think I need to be calling runner.matches_by_strategy with a strategy name ("self") maybe ? But I don't understand how.

Simply put, I don't want it to place any bets on a Runner that already has a bet on it.

*Tags: Strategies*

---

**liam** - *13:31:11*

[https://github.com/betcode-org/flumine/blob/049caf051593d301e0ae6eaba64aed5e9e489f26/examples/strategies/lowestlayer.py#L43|runner_context](https://github.com/betcode-org/flumine/blob/049caf051593d301e0ae6eaba64aed5e9e489f26/examples/strategies/lowestlayer.py#L43|runner_context) is the easy way to see live trades 

*Tags: Deployment*

---

**liam** - *13:37:39*

the reason it doesn't work is because betfair doesn't provide order data in the market stream so `matches_by_strategy` will always be empty

*Tags: Strategies*

---

**Jon K** - *15:03:16*

[https://githubmemory.com/repo/liampauling/flumine/issues/487](https://githubmemory.com/repo/liampauling/flumine/issues/487)

*Tags: Performance*

---

**Jon K** - *15:06:27*

And the output comes out as

starting strategy 'ExampleStrategy'

0

Windsor 4th Apr

Placing bet on  24244533

TradeStatus.LIVE

TradeStatus.LIVE

0

Windsor 4th Apr

Placing bet on  24244533

TradeStatus.LIVE

TradeStatus.LIVE

*Tags: Deployment, Strategies*

---

**liam** - *15:07:35*

you are just checking the live_trade_count so once matched or cancelled or it will place another, the logs will tell you exactly what it's doing.



You should be simulating or paper_trading as well if coding up a strategy

*Tags: Deployment, Strategies*

---

**liam** - *15:10:36*

yep, use your debugger and you can see what you have available or read the code :wink:

*Tags: Errors Debugging*

---

**Jon K** - *15:13:53*

Sorry, new to this and not used Python much before.

Thanks for the help

*Tags: Getting Started*

---

## 2022-04-06

**Iván Gómez** - *08:31:08*

No, there is no problem running the code for Bundesliga, the problem is running the same code for other leagues like "Spanish Segunda División `competition_ids = [12204313]` ", where I am not getting any Event. During the weekend I have tried the same code and I was only able to see events (matches) in play or that were going to be played in two hours maximum.



In order to avoid misunderstandings, I have updated the previous code, changing the competition_id to the "Spanish Segunda División `competition_ids = [12204313]` " one and commeting the Bundesliga competition_id variable.

*Tags: General Technical*

---

**Mo** - *08:38:09*

I ran your code for both Bundesliga and Spanish Segunda Division



Segunda Division ran fine, I got the list of market catalogues back



Bundesliga had an API error because there are too many markets on the exchange



I hope that is clearer

*Tags: Errors Debugging*

---

**Iván Gómez** - *11:32:56*

Ok thank you so much for your help. I'm trying to extrapolate the probabilities of WIN/DRAW/LOSE from the odds. In your personal opinion, where do you think that the probabilities of WIN/DRAW/LOSE are better identified? In the Sportsbook or in the Exchange?

*Tags: General Technical*

---

**Iván Gómez** - *11:36:21*

I understand that the odds that Betfair is setting in their Sportsbook are the result of the execution of complex models in real time and that the average odds that we can see in the Exchange is like the opinion of the persons that are betting (as its a per-to-per betting platform)

*Tags: Strategies*

---

**ShaunW** - *16:08:51*

Sportbook/bookmaker prices are still subject to pressures from opinion as their objective is to maintain a balanced book. eg ideally not more than half the money accepted at evens etc.  That's one of the bigger differences between an open exchange and a single entity counterparty such as a bookmaker.  And the hive mind is a match for any model so no doubt a consideration if not the whole story.

*Tags: Strategies*

---

## 2022-04-13

**Brøndby IF** - *00:58:38*

I've been trying to understand how I could filter the games that were starting up to a maximum of 2 hours from now, but it also returns the games that have already started too, is there any way to remove the games that have already started directly in this call that lists the games that will be collected? Thanks in advance for all the support!



`filtros_mercado = betfairlightweight.filters.market_filter(`

        `event_type_ids=['1'],`

        `market_start_time={`

            `'to': (datetime.datetime.utcnow() + datetime.timedelta(hours=2)).strftime("%Y-%m-%dT%TZ")`

        `}`

    `)`

*Tags: General Technical*

---

**Jorge** - *08:23:15*

Hi, my streaming_market_data process is suddenly using a lot of memory RAM. For the first couple of days it is completely OK but then suddenly it starts accumulating more RAM and in a couple of days it takes all the available RAM in the Server, making the process freeze. Yesterday it took 80MB RAM (normal) and today it went up to 250MB RAM. Has anyone experienced something similar? This is basically my code for the process:



```trading = betfairlightweight.APIClient(... , lightweight=True)

trading.login()



market_filter = streaming_market_filter(event_type_ids=event_type_ids, market_types=market_type_codes, turn_in_play_enabled=True, country_codes=country_codes)

market_data_filter = streaming_market_data_filter(fields=["EX_BEST_OFFERS_DISP", 'EX_TRADED_VOL', "EX_MARKET_DEF"], ladder_levels=1)

streaming = Streaming(trading, market_filter, market_data_filter)

streaming.start()



while True:

    try:

        new_market_books = streaming.output_queue.get()

        publish_to_redis(db_0, new_market_books)

        log_debug('Total markets saved in Redis: {}'.format(len(db_0.keys())))



    except Exception as e:

        log_exception(e)```

I don't see any ERROR logs. Only some WARNINGs here and there about "Latency high", but I had those long time ago and the same process did not accumulate RAM memory...

*Tags: Errors Debugging, Performance, Deployment, Strategies*

---

**Jorge** - *08:29:26*

I think it does use it. Anyway, I can and will remove that line, it was there for debuggin purposes

*Tags: Errors Debugging*

---

**Jorge** - *08:31:28*

This is my code to push the markets to Redis, but I don't see how the problem could be here...

```def get_runner_data_dict(market_book, runner_book):

    return {'market_id': market_book.market_id,

            'runner_id': runner_book.selection_id,

            'back_odd': runner_book.ex.available_to_back[0].price if runner_book.ex.available_to_back else 0,

            'back_liquidity': runner_book.ex.available_to_back[0].size if runner_book.ex.available_to_back else 0,

            'lay_odd': runner_book.ex.available_to_lay[0].price if runner_book.ex.available_to_lay else 0,

            'lay_liquidity': runner_book.ex.available_to_lay[0].size if runner_book.ex.available_to_lay else 0,

            'total_matched': runner_book.total_matched if runner_book.total_matched else 0,

            'runner_number': [x.sort_priority - 1 for x in market_book.market_definition.runners if x.selection_id == runner_book.selection_id][0]}





def publish_to_redis(r_database, market_books):

    """

    Saves the content of market_books to the Redis database r_database.



    """

    market_data_dictdict = {m.market_id: {r.selection_id: get_runner_data_dict(m, r) for r in m.runners} for m in market_books}



    # Adding market level parameters:

    for market in market_books:

        market_data_dictdict[market.market_id].update({'market_data': {'inplay': market.inplay,

                                                                       'status': market.status,

                                                                       'total_matched': market.total_matched if market.total_matched else 0}})



    with r_database.pipeline() as pipe:

        for market_id, price_dict in market_data_dictdict.items():

            pipe.set(market_id, json.dumps(price_dict))

        pipe.set('last_update', now().strftime('%Y-%m-%d %H:%M:%S.%f'))

        pipe.execute()```



*Tags: General Technical*

---

**liam** - *08:45:13*

What is `Streaming`?

*Tags: General Technical*

---

**Unknown** - *08:48:39*

```from betfairlightweight import StreamListener



class Streaming(threading.Thread):

    """

    Streaming example to handle timeouts or connection errors, with reconnect. Code uses 'tenacity' library for retrying.

    Streaming class inherits threading module to simplify start/stop.

    """

    def __init__(

            self,

            client: betfairlightweight.APIClient,

            market_filter: dict,

            market_data_filter: dict,

            conflate_ms: int = None,

            streaming_unique_id: int = 1000,

    ):

        threading.Thread.__init__(self, daemon=True, name=self.__class__.__name__)

        self.client = client

        self.market_filter = market_filter

        self.market_data_filter = market_data_filter

        self.conflate_ms = conflate_ms

        self.streaming_unique_id = streaming_unique_id

        self.stream = None

        self.output_queue = queue.Queue()

        self.listener = StreamListener(output_queue=self.output_queue)



    @retry(wait=wait_exponential(multiplier=1, min=2, max=20))

    def run(self) -&gt; None:

        log_info("Starting MarketStreaming")

        self.client.login()  # this is needed in case of reconnection so the session is started again

        self.stream = self.client.streaming.create_stream(

            unique_id=self.streaming_unique_id, listener=self.listener

        )

        try:

            self.streaming_unique_id = self.stream.subscribe_to_markets(

                market_filter=self.market_filter,

                market_data_filter=self.market_data_filter,

                conflate_ms=self.conflate_ms,

                initial_clk=self.listener.initial_clk,  # supplying these two values allows a reconnect

                clk=self.listener.clk,

            )

            self.stream.start()

        except BetfairError:

            log_exception("MarketStreaming run error")

            raise

        except Exception:

            log_exception("MarketStreaming run error")

            raise

        log_info("Stopped MarketStreaming {0}".format(self.streaming_unique_id))



    def stop(self) -&gt; None:

        if self.stream:

            self.stream.stop()```

*Tags: Errors Debugging*

---

**liam** - *08:50:45*

Hang on 250MB? Why is that a problem

*Tags: General Technical*

---

**Jorge** - *08:51:35*

250MB is not a problem, but it starts growing and in 2/3 days reaches 6GB and freezes :sweat_smile:

*Tags: General Technical*

---

**liam** - *08:54:39*

What do the logs look like before it crashes? I can confidently say it won't be bflw causing this, whats the memory use of redis?

*Tags: Performance*

---

**Jorge** - *08:56:46*

Nothing special in the logs before it freezes... Yes, very strange because I am using this same code for a year and just having problems this last month

*Tags: General Technical*

---

**Jorge** - *08:57:32*

It may be my crappy server provider, I also observed higher "Latency high" logs in general

*Tags: Performance, Deployment*

---

**Oliver Varney** - *09:33:50*

Are you trying to use redis as a cache or primary database?

*Tags: General Technical*

---

**Jorge** - *09:52:48*

That's very true. Very simple to flush the database once per day and stop/start the StreamListener

*Tags: General Technical*

---

**foxwood** - *12:17:24*

I'm running 2 live frameworks on same server for the first time - one for "ok" strategies and another for suspect ones and debugging.



As they both place bets it ends up with cross-talk warnings in the other framework's log log saying "Strategy not available to create order" and "Order %s not present in blotter". Was a bit worrying at first sight lol.



Presume this is in part caused by both frameworks having the socket hostname as the customer order ref since this does not happen when running the two frameworks on separate machines.



Suggestions: if the common hostname is the cause then extend the hostname with python PID (poss problems with multi proc) or an instance specific framework uuid property (logging does a short uuid for example) ?

*Tags: Getting Started, Errors Debugging, Deployment, Strategies*

---

**Beeblebrox** - *12:50:38*

You can override the default by setting `config.customer_strategy_ref` to something else

*Tags: Strategies*

---

**Beeblebrox** - *16:08:09*

I think customerRef or customerOrderRef can have 32 characters, customerStrategyRef is limited to 15.

*Tags: Strategies*

---

**Brøndby IF** - *16:24:42*

I'm trying to find in the mapping how I can collect the value that shows me what was the last match update, because the free version of the Betfair API has a delay, correct?



When trying to collect like this:

`'DateTimeUpdate': [obj_evento._datetime_updated for obj_evento in soccer_events]`



It delivers the value of the moment I made the call, could someone tell me if there is a way to get the time of the last update of the match itself so I can follow how much is updated?

*Tags: Deployment*

---

## 2022-04-14

**foxwood** - *18:33:31*

worked a treat - set it in the top module to use the file name so (for me) ends up different for each framework:

```config.customer_strategy_ref = os.path.basename(__file__).split(".")[0][-15:]```



*Tags: Strategies*

---

## 2022-04-16

**thambie1** - *18:15:29*

I'm not using flumine of bflw. The bug was on Betfair's side, but I haven't seen it happen again since I made this comment

*Tags: Errors Debugging*

---

## 2022-04-17

**Ruben** - *09:31:06*

good morning everyone; hoping you can give me some pointers with this...basically every saturday my aws instance (t3.small) has a spike in CPU usage and after that it dies. When that happens, I'm usually subscribed to about 50 soccer markets which doesn't seem like that much compared to what I often hear around here. Around that time I often hit the 5000 max transaction limit as well. Only running 1 strategy, which admittedly is quite CPU intensive since after every update it has to do work to keep a clear picture of the market book

*Tags: Deployment, Strategies*

---

## 2022-04-19

**liam** - *21:29:16*

Why not fix the real problem?

*Tags: Errors Debugging*

---

**liam** - *21:35:00*

Yeah, can you fix that? Are you actually going over enough that you are paying the charges? I think I have mine set at 20k per account and just pay if required 

*Tags: Errors Debugging*

---

**Ruben** - *21:36:09*

atm I am developing my first strategy with small stakes, so maybe I can go above the 5k but not much beyond that. Maybe I should look at being more selective with the tx that I post

*Tags: Strategies*

---

**liam** - *21:39:01*

Yeah if you can, you can call the check_hour function but it’s not very clean to be calling it from a strategy and not very efficient on strategy/execution 

*Tags: Strategies*

---

## 2022-04-21

**Brøndby IF** - *20:50:33*

Good afternoon everyone, in relation to the error that I showed below, does anyone know the limits for not have the risk of this happening?



I believe that it will be impossible for this happen to me because nothing I use needs to do multiple logins, I only use one for several calls to collect data odds and then I log out.

But anyway, it would be interesting to know this for future knowledge.



`TEMPORARY_BAN_TOO_MANY_REQUESTS → The limit for successful login requests per minute has been exceeded. New login attempts will be banned for 20 minutes`

*Tags: Errors Debugging*

---

**Brøndby IF** - *20:51:49*

In case it's of interest, it's listed on this documentation page:



[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login)

*Tags: General Technical*

---

## 2022-04-23

**Unknown** - *15:58:00*

I keep getting a BET_TAKEN_OR_LAPSED error when cancelling, my cancel logic is as follows:

```orders = [order for order in market.blotter.strategy_orders(self) if

        (order.selection_id, order.handicap) == (runner.selection_id,runner.handicap)]```

```for order in orders:

    runner_exposure = get_runner_exposure(self, market, selected_runner=order)

    if order.status == OrderStatus.EXECUTABLE:

        if order.side == 'BACK':

            if positive_runner_exposure &lt; runner_exposure['if_win']:

                logging.info('Cancelling {0} due to positive exposure breach, runner exposure is: {1} and limit is: {2}.'.format(order.bet_id, runner_exposure, negative_runner_exposure))

                market.cancel_order(order)

            elif validate_current_order(order, time_to_cancel_orders) is True:

                logging.info('Cancelling {0} as order has been live for {1} seconds.'.format(order.bet_id, time_to_cancel_orders))

                market.cancel_order(order)

        else:

            if negative_runner_exposure &gt; runner_exposure['if_win']:

                [http://logging.info|logging.info](http://logging.info|logging.info)('Cancelling {0} due to negative exposure breach, runner exposure is: {1} and limit is: {2}.'.format(order.bet_id, runner_exposure, negative_runner_exposure))

                market.cancel_order(order)

            elif validate_current_order(order, time_to_cancel_orders) is True:

                [http://logging.info|logging.info](http://logging.info|logging.info)('Cancelling {0} as order has been live for {1} seconds.'.format(order.bet_id, time_to_cancel_orders))

                market.cancel_order(order)```

I don't understand how this error could (repeatedly) happen when I check to ensure the order is EXECUTABLE before cancelling (logs for one example attached, I have had multiple instances of this today)?



(I do appreciate it will be an error on my side, I'm just completely stumped as to what it could be), so any clues would be greatly appreciated!

*Tags: Errors Debugging, Deployment, Strategies*

---

**Newbie99** - *16:01:31*

Absolutely, but would that not correct within a few seconds, once Flumine receives the order update?

*Tags: General Technical*

---

**Newbie99** - *16:02:16*

What you describe is what is happening, but it somehow appears Flumine never acknowledges the order status has changed and seems to get stuck in a perpetual loop trying to cancel an order that has already been matched.

*Tags: General Technical*

---

**Ruben** - *16:03:52*

okay, but if you have already sent the cancellation, you will receive the error "BET_TAKEN_OR_LAPSED" because the order is no longer there; eventually as you say flumine should receive the corresponding update and no longer see it as executable

*Tags: Errors Debugging*

---

## 2022-04-24

**John Foley** - *13:35:47*

Hi folks, quick question on the historical API. Does anyone know why we can have a situation where there was definitely money traded on a runner, but the bsp is null? Perhaps the reason is simply an oversight e.g. betfair haven’t provided it, but just wanted to make sure there isn’t some other reason that I’m missing? An example would be Exeter 13:40 on  2021-01-01, market id = 1.177450945

*Tags: General Technical*

---

## 2022-04-25

**Jorge** - *09:25:17*

Hi, I had an issue Friday night. I placed a bet and then cancelled it, this order_id never appeared in the Order Streaming. The Order Streaming status was 503 around that time

*Tags: General Technical*

---

**Jorge** - *09:26:18*

I have a check that all the bets that I place need to appear in the Order Streaming, otherwise I wait until they appear and stop execution...

*Tags: General Technical*

---

**Jorge** - *09:44:00*

Alternative question, do you guys cancel your unmatched orders when you see Order Streaming status is 503 or is it better to wait until the listener status is back to None (ok)?

*Tags: General Technical*

---

**Jorge** - *09:46:30*

Aha, maybe the issue is that I both placed and cancelled the bets while the status was 503 so they never made it to the streaming... I will share it with bdp

*Tags: General Technical*

---

## 2022-04-26

**Beginner** - *15:29:18*

Guys, hello! I have a very beginner question but maybe you with very advanced knowledge can help me.



Is there a way to send API Client login data to a separate function? For example, I have the `trading.login()` in the `main()` function and I'm trying to send this data to be able to work with a separate function::



`def matches(trading):`

    `trading = trading`

    `id_event = '12345'`



    `filter_catalog_market = betfairlightweight.filters.market_filter(`

        `event_ids=[id_event],`

        `market_type_codes = [`

            `'MATCH_ODDS'`

            `]`

        `)`



    `catalog_market = trading.betting.list_market_catalogue(`

        `filter=filter_catalog_market,`

        `max_results='100',`

        `sort='FIRST_TO_START',`

        `market_projection=['RUNNER_METADATA']`

    `)`



`def main():`

    `trading = betfairlightweight.APIClient(username, pw, app_key=app_key, cert_files=('blablabla.crt','blablabla.key'))`

    `trading.login()`

    `matches(trading)`



The error that appears is:



`TypeError: cannot pickle 'module' object`



Is there any way to send this API Client login data to a separate function?

I'm sorry for the question that I know is simple, but I'm really struggling to understand.

*Tags: Getting Started, Errors Debugging, Strategies*

---

**Unknown** - *16:07:24*

Okay, here's the full file. I need to leave `trading.login` inside `main()` because I call this function from another Python code like this → `API_Betfair.Betfair_API()`

*Tags: Strategies*

---

**Beginner** - *16:26:49*

I collect data from football matches, game information and odds. But when I tried to use pool multiprocessing to fetch multiple games at once, I got the problem of not being able to send `trading = ...` data.

*Tags: Strategies*

---

**Ruben** - *16:33:14*

I think streaming is exactly what you need to receive game and odds information from several games at the same time

*Tags: General Technical*

---

**Beginner** - *16:37:29*

Hi [@U011VL3CA2Y](@U011VL3CA2Y) , I'm going to research about streaming, because my idea is to get the games data and send it to a spreadsheet. Thank you!

*Tags: General Technical*

---

**Ruben** - *16:41:38*

if you want to monitor odds 24/7 and do stuff with odds then I would recommend streaming with flumine

*Tags: General Technical*

---

**Beginner** - *16:48:17*

I still have a lot of difficulty getting the data from all the games, I couldn't understand how to do it more effectively. I end up using an archaic way that collects game by game in each competition and so on.

*Tags: General Technical*

---

**D** - *17:31:21*

My understanding is that when you use multiple-processing, any objects passed across the boundary are pickled before being sent, that's why the error message is coming up - it can't pickle something you're trying to share across multiple processes.

*Tags: Errors Debugging*

---

## 2022-04-28

**Vadym Zh** - *17:54:39*

Hey! My client runs the bot on Australian VPS and it works well. But then he decided to change the server (location - UK) and started getting an error 'MULTIPLE_USERS_WITH_SAME_CREDENTIAL'. He runs only 1 bot simultaneously, not both servers. Interactive login. Are there any methods to 'reset' the session? Or what would you recommend to fix this error? The goal is to just run it on the UK server.

*Tags: Errors Debugging, Deployment*

---

## 2022-04-29

**Mo** - *08:12:57*

This is not broadly correct. Like many users I live in the UK but use AWS servers in Ireland

*Tags: Deployment*

---

**Jorge** - *08:14:48*

Ah, I would love to be able to use AWS servers in Ireland. I may be wrong, I will contact Betfair

*Tags: Deployment*

---

**foxwood** - *09:31:06*

[@UBS7QANF3](@UBS7QANF3) considered that and made an AWS in Ireland but never used it yet - use Tagadab currently. Keep seeing comments elsewhere about traffic routing first through London servers (Cloudflare ?) for front end protection. Just checked my desktop connection and the BF connection is to a Cloudflare server at 104.16.x.x. 9 hops (!) and 7-8ms ping time

*Tags: Deployment*

---

**foxwood** - *10:15:58*

Ah ok - had a look at Cloudflare and they have a data centre in Dublin so presume that's where I must have been connecting to. Out of interest, any idea what sort of ping time and hop count you are getting from your Dublin based AWS ?

*Tags: Deployment*

---

## 2022-05-02

**Rudeger Jamison** - *05:40:11*

Hey, wondering if someone can help me debug, I am following the `QuickStart` in the Flumine docs, but not having much luck...details in :thread:

*Tags: Errors Debugging*

---

**Rudeger Jamison** - *05:41:26*

```from flumine import Flumine, clients

from flumine import BaseStrategy

from betfairlightweight.filters import (

    streaming_market_filter, 

    streaming_market_data_filter,

)

trading = betfairlightweight.APIClient(

    username=Ssm.get_secret(f"/betfair/username/{account}"),

    password=Ssm.get_secret(f"/betfair/password/{account}"),

    app_key=Ssm.get_secret(f"/betfair/app_key/{account}"),

    # lightweight=True,

)



client = clients.BetfairClient(trading)



framework = Flumine(

    client=client,

)



class ExampleStrategy(BaseStrategy):

    def start(self):

        # subscribe to streams

        print("starting strategy 'ExampleStrategy'")



    def check_market_book(self, market, market_book):

        print("checking market book")

        # process_market_book only executed if this returns True

        if market_book.status != "CLOSED":

            return True



    def process_market_book(self, market, market_book):

        # process marketBook object

        print(market_book.status)







strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["WIN"],

        # race_types=["Flat"]

        

    ),

    market_data_filter=streaming_market_data_filter(fields=["EX_ALL_OFFERS"], ladder_levels=3)

)



framework.add_strategy(strategy)



framework.run()```

*Tags: Strategies*

---

**Rudeger Jamison** - *05:41:37*

*Then all I see printed is `starting strategy 'ExampleStrategy'` and it seems I am in an infinite loop.... not sure where to go from here!?*

*Tags: Strategies*

---

**Rudeger Jamison** - *05:55:47*

I am obviously expecting to see *`check_market_book` entered at somepoint, but it appears as though it is never entered.*



*I also used the bflw streaming implementation with all the same parameters, and it all seems to work fine* :shrug: 

*Tags: General Technical*

---

**liam** - *06:41:18*

Look at the flumine example dir and add some logging to see what it’s doing 

*Tags: General Technical*

---

**John Foley** - *13:14:23*

So I’ve just twigged that “last traded price” in the historical data (basic files) is not what I thought it was…

1. If I want to see what the best available prices were available at a given timestamp, then I actually need the “Best Available to Back/Lay” fields, is that correct?

2. Seeing now that these are only available in Advanced/Pro files. I was wondering if anyone could share any thoughts on reliability of the advanced files for backtesting? If I’m looking to see what prices were available at a given timestamp (to the nearest minute is fine), is the advanced data good enough? Just interested to hear about others experiences before I go making any bulk purchases

3. I’ve found the basic files can sometimes be missing random events. E.g. a race meeting with 7 races but the basic data seems to only have the win market for 4 of them, stuff like that. Is this a known trait of the basic data? Are the gaps filled in for advanced/pro?



*Tags: Data Quality*

---

**John Foley** - *13:19:49*

Thanks a mil. So the problem that I’ve described - can it only be done with Pro? Or is self collection the way to go?

*Tags: General Technical*

---

**John Foley** - *13:21:55*

Or how else are people doing this? I see there is some stuff people have built e.g. the time machine. But are they using the same data so have the same problems?

*Tags: General Technical*

---

**Unknown** - *18:32:09*

Guys, this code is to analyze if everything is ok in both markets and if it is, it responds with `'Approved to invest'`



This file is called `Betfair.py`, so in my main code I call it like this:



`import Betfair`

`print(Betfair.match_data(31410834))`



This id `31410834` is from an example game that has open markets and everything is ok.



Perfect, you guys who have advanced knowledge in Python and have been using betfairlightweight for a long time... As can see, in this place in the code:



`for _ in range(3):`

        `for _, market in markets.iterrows():`

            `odds_search(trading,market)`



I'm asking to generate a loop for 3 times in the analysis of the filtered markets, calling the `odds_search` function.



It works perfectly, but as you can see, I add the login data to the api (`trading`) when calling the function, but when I try to use basic multiprocessing or pool, I can't send `trading` as an argument, this error appears: `TypeError: cannot pickle 'module' object`.



When someone has some spare time, could help me out and show me how I could edit this code to make it work with multiprocessing so that these 3 loops are done at the same time to increase speed to colect the data?



I can create a question on stackoverflow if want. Any help will be most welcome!

*Tags: Errors Debugging, Performance, Strategies*

---

**Beginner** - *18:40:20*

And I'm sorry it's a basic knowledge question, but I'm just starting out in this world and I have a really hard time understanding some things.

*Tags: General Technical*

---

**Alessio** - *18:48:38*

Have you considered using flumine and the event loop it includes?

*Tags: General Technical*

---

**Beginner** - *18:54:55*

Hello [@U01C12ZEADQ](@U01C12ZEADQ) , I use Visual Studio Code, I don't know Flumine, honestly I have no idea if it's a module or a program, anyway I'll research to better understand your tip. Thank you very much for your attention!

*Tags: General Technical*

---

## 2022-05-03

**Rudeger Jamison** - *00:35:31*

```{"asctime": "2022-05-02 23:33:50,466", "levelname": "INFO", "message": "[OrderStream: 1001]: connection_id: 102-020522233350-5969716"}

{"asctime": "2022-05-02 23:33:50,607", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["AU"], "raceTypes": ["Flat"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_MARKET_DEF"], "ladderLevels": 3}, "conflate_ms": null, "streaming_timeout": null}

{"asctime": "2022-05-02 23:33:50,609", "levelname": "INFO", "message": "Starting output_thread (MarketStream 2000)"}

{"asctime": "2022-05-02 23:33:50,610", "levelname": "INFO", "message": "[Register: 2001]: marketSubscription"}

{"asctime": "2022-05-02 23:33:50,611", "levelname": "INFO", "message": "[MarketStream: 2001]: \"MarketStream\" created"}

{"asctime": "2022-05-02 23:33:50,755", "levelname": "ERROR", "message": "[OrderStream: 1002]: INVALID_SESSION_INFORMATION: DSC-0036"}

{"asctime": "2022-05-02 23:33:50,756", "levelname": "ERROR", "message": "OrderStream 1001 run error", "exc_info": "Traceback (most recent call last):\n  File \"/Users/benmuller/code/betfair-trading-bots/.venv/lib/python3.9/site-packages/flumine/streams/orderstream.py\", line 51, in run\n    self._stream.start()\n  File \"/Users/benmuller/code/betfair-trading-bots/.venv/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 67, in start\n    self._read_loop()\n  File \"/Users/benmuller/code/betfair-trading-bots/.venv/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 233, in _read_loop\n    self._data(received_data)\n  File \"/Users/benmuller/code/betfair-trading-bots/.venv/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 274, in _data\n    raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 102-020522233350-5969716, data: {\"op\":\"status\",\"id\":1002,\"statusCode\":\"FAILURE\",\"errorCode\":\"INVALID_SESSION_INFORMATION\",\"errorMessage\":\"DSC-0036\",\"connectionClosed\":true,\"connectionId\":\"102-020522233350-5969716\"}"}```

*Tags: Errors Debugging, Strategies*

---

**Rudeger Jamison** - *00:43:51*

thanks for listening to my rambling!! hope this helps someone else

*Tags: General Technical*

---

**Rudeger Jamison** - *11:07:48*

Last question! In the example-single.py, you provide the strategy with the kwarg `max_trade_count=1` and then you check in process_market_book for  ​`if​ ​runner_context​.​trade_count​ ​&gt;​ ​0​`.



Am I right in assuming that Flumine will handle not placing a trade if there's already one according to the kwarg argument? Or how is it handled in general with those safe guards?

*Tags: Strategies*

---

**Unknown** - *15:45:16*

Hello guys, updating my question, with the current code, the error `TypeError: cannot pickle 'module' object` of not being able to send `trading` as an argument disappeared, but the function `odds_search` that analyzes the odds is not being executed. When I go to look at the two lists, they are empty and `print('odds search run')` does not appear in the terminal, indicating that the function was not even called.

*Tags: Errors Debugging, Strategies*

---

**D** - *16:07:47*

Hi Test, I don't know the answer to your problem but have you tried making it work without multi-processing involved? It doesn't look like it's adding a lot of value to the overall process. Also, in your try....except clauses, it might be useful to print out any exceptions just in case there's something unexpected going on in there.

*Tags: Errors Debugging*

---

**Beginner** - *16:15:33*

Hi [@URMM9463X](@URMM9463X) thanks to help. Check it out, yesterday I sent the code here without using multiprocessing, it works perfectly because I can send `trading` as an argument without any difficulties. But, it generates a slowness that when using it on a day by day, I confess to you that it ends up getting in the way of making decisions in the market. So, if I could use multiprocessing to collect the information all at once without having to wait for an analysis to finish and move on to another, it would improve a lot for me.

*Tags: Performance, Strategies*

---

**D** - *16:21:30*

What is happening in the function odds_search that's so slow it needs a separate process for each market? Sorry if that's a dumb question but I'm not getting it.

*Tags: Performance*

---

**Beginner** - *16:28:35*

No problem [@URMM9463X](@URMM9463X), I can answer you calmly, it's just that I had to summarize the code a lot so it wouldn't get too complex and take the focus off the problem I'm trying to demonstrate, but this function does much more in there than just adding the data found. But the rest are really personal things to combine odds data and make sure there is value for me to invest in the market or not.

*Tags: General Technical*

---

**Mo** - *16:29:34*

I'm going to echo [@U01C12ZEADQ](@U01C12ZEADQ), you just need to switch to using flumine

*Tags: General Technical*

---

**Beginner** - *16:32:58*

Hello [@UBS7QANF3](@UBS7QANF3), yesterday after his indication I did a research on `flumine`, I started an attempt to carry out the work but I'm still far from being able to use it, but thank you very much, I'll keep test with it to get the necessary result. If I manage to generate an option with `flumine`, I'll send it here! :pray:

*Tags: General Technical*

---

**D** - *16:34:28*

That's fine, but the nature of that work affects my opinion of what you should be doing. Here's 3 suggestions for you to consider:

1. Log in inside the function that runs in the separate process so it has its own copy of a trading object - if you're work is really cpu-bound;

2. Use Threads instead of processes, then you can pass 'trading' to all threads - this would be useful if the work involves going out to other websites/APIs to collect information, i.e. IO-bound.

3. Do separate login as per option 1) but pass market ids in a queue so you don't have to keep logging in for many markets - if your work is cpu bound and you have many markets.

Unfortunately, without knowing more about the nature of the work it's hard to give a definitive answer. I think the correct answer may be 'Use Flumine' but I am not fluent enough with it to advise.

*Tags: Strategies*

---

**Mo** - *16:34:59*

I do not mean to be rude but your code is not very good and flumine does all of this boiler plate much better than what you've written. If you take the time to go away and learn how to use flumine you will be in a much better position and you will get more help here. Really you're just asking generic Python questions right now

*Tags: General Technical*

---

**Beginner** - *16:37:25*

I agree perfectly [@UBS7QANF3](@UBS7QANF3), you are correct on all points, I know that my knowledge is very limited and I have several difficulties to be resolved yet.

*Tags: General Technical*

---

**AndyL** - *19:14:47*

Had a weird issue on Aus Warwick 07:42 last night which end with bot not hedging .

I had a matched backbet and an unmatched Lay TakeSP bet, then market was suspended for a non runner at 111secs, then unsuspended, bot then matched another bet on same selection at 103secs, then tried to cancel previous takeSP to update with a new Back takeSP bet. At this point the cancel threw an exception, order status Completed!! How can the takeSP at 1.01 have completed 2mins before actual inplay???

My transaction log shows the bet completing at the point of the nonrunner suspension...weird?

Anyone seen this before?

*Tags: Errors Debugging*

---

**AndyL** - *19:49:47*

So ive placed a lay limit order market_on_close at 1.01  so normally that will get matched at inplay at SP. Buton this one occasion after a nonrunner suspension it got marked as complete by Flumine at 111 secs prior to scheduled start, actual start was at -94secs

*Tags: General Technical*

---

**AndyL** - *22:05:14*

I can only think either Flumine incorrectly completed the order, or Betfair nonrunner Lay SP order adjustment went rogue...

If i backtest over the recording it works fine, but  backtest simulation uses a middleware order non runner adjustment class, effectively emulating Betfair

*Tags: General Technical*

---

**AndyL** - *22:53:04*

At least i know how to handle it now live.

However I think Flumine simulation doesn't do that [@U4H19D1D2](@U4H19D1D2)? It adjusts order liability but it doesnt complete the order at the conversion point?

*Tags: Deployment*

---

## 2022-05-04

**foxwood** - *19:59:21*

Loads of latency issues recorded in logs on the market stream today at 2 different locations and different strategies - up to 15 seconds at times and then recovers - anybody else ?



Edit - 50 even ?!

Saw something similar the other day and thought it was just local connection issue

```{"asctime": "2022-05-04 18:04:15,828", "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 13.703663110733032"}

{"asctime": "2022-05-04 18:04:15,875", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.198672766", "latency": 50.026501417160034, "pt": "2022-05-04T17:03:25.849000"}```

Edit 2 - that PC was saving it's log to a NAS over wifi - very slow. Think a race developed between trying to log latency warnings and taking so long to do so it increased the latency more ! Switched to local PC now instead which will hopefully fix things.

*Tags: Errors Debugging, Performance*

---

## 2022-05-05

**Newbie99** - *12:00:20*

I'm still getting these perpetual cancel loops, which occur when a bet is (presumably) matched after I've sent the cancel request:



```{"asctime": "2022-05-05 10:56:32,246", "levelname": "INFO", "message": "execute_cancel", "trading_function": "cancel", "elapsed_time": 0.19069957733154297, "response": {"customerRef": "05f0b9cbcc6211eca0d32016d8944b85", "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.167249009", "instructionReports": [{"status": "FAILURE", "errorCode": "BET_TAKEN_OR_LAPSED", "instruction": {"betId": "267210054221"}}]}, "order_package": {"id": "05f0b9cb-cc62-11ec-a0d3-2016d8944b85", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x0000010E03500FA0&gt;", "market_id": "1.167249009", "orders": ["138710406780430137"], "order_count": 1, "package_type": "Cancel", "customer_strategy_ref": "BlueOcean", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}```

*Tags: Errors Debugging, Strategies*

---

**Newbie99** - *12:00:52*

So it seems logical the cancel would fail, but Flumine just goes on an infinite loop and the status doesn't seem to ever update

*Tags: General Technical*

---

**Newbie99** - *12:02:19*

As a quick fix, is there some easy way I can try to disable multiple cancels of the same bet (I can see a retry flag, but I suspect this isn't what I think it is)

*Tags: Errors Debugging*

---

**liam** - *12:19:43*

Hmm thought I had fixed this, do you know how to replicate?

*Tags: Errors Debugging*

---

**Oliver Varney** - *13:08:24*

probably nothing to do with this, but flumine operated at the time assuming befair response would be logical and it lead to my code trying to cancel a silly amount of times

*Tags: General Technical*

---

**Newbie99** - *13:11:31*

But I think we still need a way of flumine handling the situation, if it repeatedly finds an order shows up as BET_TAKEN_OR_LAPSED, then some kind of control that stops it looping like this?

*Tags: General Technical*

---

**Newbie99** - *13:12:20*

That could work as a stop gap fix I guess?

*Tags: Errors Debugging*

---

## 2022-05-06

**Oliver Varney** - *06:48:21*

im assuming I have to call _process_market_books in simulatedflumine?

*Tags: General Technical*

---

**liam** - *06:50:05*

Yeah, logic is [https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/simulation/simulation.py#L109|here](https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/simulation/simulation.py#L109|here)

*Tags: General Technical*

---

**liam** - *06:50:29*

gets [https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/simulation/simulation.py#L97|called](https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/simulation/simulation.py#L97|called) on each book update

*Tags: General Technical*

---

**liam** - *06:53:21*

when simulating the [https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/execution/simulatedexecution.py#L56|execution](https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/execution/simulatedexecution.py#L56|execution) code does it

*Tags: General Technical*

---

**liam** - *06:56:14*

that defaults to `Simulated` [https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/simulation/simulatedorder.py#L18|class](https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/simulation/simulatedorder.py#L18|class) when simulating

*Tags: General Technical*

---

**liam** - *06:59:20*

the responses are populated [https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/execution/simulatedexecution.py#L66|here](https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/execution/simulatedexecution.py#L66|here)

*Tags: General Technical*

---

**liam** - *07:56:37*

Have you seen this [https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/order/order.py#L189|property](https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/order/order.py#L189|property)?

*Tags: General Technical*

---

**Oliver Varney** - *07:56:53*

yer one sec im debugging the code ill get there

*Tags: Errors Debugging*

---

**liam** - *07:58:47*

what is `self._simulated` this works of a bool on the SimulatedOrder class which uses [https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/simulation/simulatedorder.py#L478|this](https://github.com/betcode-org/flumine/blob/5e6b8569a4238e361a3dda4e6b5cb0ada93c9723/flumine/simulation/simulatedorder.py#L478|this) which might be wrong in your code

*Tags: General Technical*

---

**Oliver Varney** - *08:12:09*

lol sorry mate found the problems was [@UBS7QANF3](@UBS7QANF3) Side enum from betfairutil is not fully upper case

*Tags: General Technical*

---

**Oliver Varney** - *08:16:30*

I used it on the trade and passed in down to the orders but flumine order.side is upper case

*Tags: General Technical*

---

**Mo** - *08:17:19*

We recently changed from an older internal Side enum definition to the betfairutil one and also had problems with the arbitrary capitalisation choice. Ideally you should be able to construct one from a string in a case insensitive way

*Tags: General Technical*

---

**Mo** - *08:44:52*

Was the capitalisation question directed at me?

*Tags: General Technical*

---

**Oliver Varney** - *08:45:48*

yes mo, but I guess it can work either way with flumine / bflw including some logic around the side attribute

*Tags: General Technical*

---

**Oliver Varney** - *08:49:12*

was there any thoughts about integrating betfairutil into bflw or is it preferable to be separate out of interest?

*Tags: General Technical*

---

**Oliver Varney** - *08:53:19*

cool, I guess flumine would be the place to have it as a install requirement if liam ever wanted to use parts

*Tags: Getting Started*

---

**Mo** - *08:53:53*

Yeah integration into flumine would make more sense but not something I have a strong opinion on

*Tags: General Technical*

---

**liam** - *08:54:11*

yeah, pandas install is the only thing stopping me doing it already tbh

*Tags: Getting Started, Feature Engineering*

---

**Oliver Varney** - *08:58:56*

the Side enum implementation is quite nice tbh with all the helper attributes, not sure if that would effect performance if flumine implemented that directly as the side

*Tags: Performance*

---

## 2022-05-07

**Marco** - *10:17:09*

Hello, how to reduce the number of subscriptions to the markets via flumine? I'm having this error: `ERROR:betfairlightweight.streaming.listener:[MarketStream: 2002]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 11311 markets whereas max allowed number was: 200` . I checked the filters but I didn't find a way to limit it

*Tags: Errors Debugging*

---

**Marco** - *10:29:11*

Thanks [@UFTBRB3F1](@UFTBRB3F1), I'm trying a combination of these:

```market_filter={

            # Use this when backtesting

            # "markets": market_files,

            "event_type_ids": ["1"],

            "listener_kwargs": {"seconds_to_start": -10, "inplay": True},

            "country_codes": ["IT"],

            "market_type_codes": ["OVER_UNDER_25"],



        },

        market_data_filter=streaming_market_data_filter(fields=["EX_ALL_OFFERS"]), ```

*Tags: General Technical*

---

**Marco** - *10:30:12*

But I still get this error `ERROR:betfairlightweight.streaming.listener:[MarketStream: 2006]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 11347 markets whereas max allowed number was: 200`  and then a timeout `betfairlightweight.exceptions.ListenerError: connection_id: 202-070522092912-6500674, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"202-070522092912-6500674"}`  probably related to the market limit

*Tags: Errors Debugging*

---

**Newbie99** - *10:35:57*

I think at the mo its trying to pull in all Italian football markets which is why you're getting the error

*Tags: Errors Debugging*

---

**Peter** - *10:48:40*

I think the problem may be more fundamental. You're creating a dictionary with snake case  keys, but Betfair is expecting camel case, so all your parameters are being ignored and you're trying to subscribe to every live market.

*Tags: Deployment*

---

**Peter** - *10:50:29*

I'd recommend either using the betfairlightweight streaming_market_filter() method to construct your market filter (it takes parameters in snake case and coverts them to camel case) or build your dictionary with camel case keys.

*Tags: General Technical*

---

**Peter** - *10:55:26*

Also, listener_kwargs are used internally by Flumine to make your backtesting more efficient. They shouldn't be used when communicating with Betfair.

*Tags: General Technical*

---

**Peter** - *15:38:42*

[@U03EF29QFS4](@U03EF29QFS4) You don't need to separate the strategies. One of the strengths of Flumine is that you can use the same strategy in production as you used in backtesting. It's only the market filter than changes.

*Tags: Deployment, Strategies*

---

**Marco** - *15:47:27*

Yeah, I agree with you: Flumine is very powerful! I wrote that phrase incorrectly; what I meant is I've changed the filters of the strategies based on the run-type (backtest or live)

*Tags: Deployment*

---

**moseley82** - *19:52:19*

Hi guys, randomly started getting CERT_AUTH_REQUIRED error this evening, not changed a thing my end. Is this a wider issue does anyone know?

*Tags: Errors Debugging*

---

## 2022-05-08

**Dave** - *08:27:24*

Is there a way to tell flumine not to log to the console? I presume this would also be a pre-requisite for being able to use tqdm to visualize progress when backtesting in parallel?

*Tags: General Technical*

---

## 2022-05-09

**Beginner** - *16:23:16*

Hi [@U01EZ613ZCZ](@U01EZ613ZCZ) I tried to do this, but unfortunately my knowledge is very scarce and I don't have time to learn, so I will need to outsource, unfortunately because I wanted to learn the correct form, but I couldn't.



My codes are huge, with several flaws and I didn't understand how to do it right.

*Tags: Deployment*

---

**Aaron Smith** - *16:30:17*

if i see this correct you only need the streaming data? so basically what the flumine market recorder does?

*Tags: Data Quality*

---

**Beginner** - *16:45:13*

[@U01DVUAE2G1](@U01DVUAE2G1) Honestly, I don't know the exact answer to this question, because I think streaming is used to collect updates non-stop all day (if I understand its use correctly). I don't need to collect the odds non-stop all day, I just call the code a few times a day, so when I go to analyze the odds on my spreadsheet, I have them updated.

*Tags: General Technical*

---

**Peter** - *18:26:22*

[@U03CZHR6HM0](@U03CZHR6HM0) Earlier you referred to BetConnect, but your data fields suggest that you're actually looking for Betfair data.



Since you're interested in infrequent polling rather than streamed data, you would use Betfairlightweight rather than Flumine and a single call to the list_market_catalogue method (subject to some limitations on response size, which might need to break it into multiple calls depending on the number of leagues you're after) followed by calls to the list_market_book methods and some response processing would get you all the data you want .



The whole process: call, response, and response processing should be measured in a (small) number of seconds if properly structured and there's already an example that's fairly close to what you want, but for horse racing in the Betfairlightweight examples folder (exampleone).

*Tags: General Technical*

---

**Unknown** - *18:35:21*

Hi [@U9JHLMZB4](@U9JHLMZB4), thanks for support and I'm sorry for my English, maybe I wasn't very correct. Earlier I quoted Betcode instead of BetConnect (With Betcode I meant it could be using betfairlightweight module, Flumine or some other I don't know yet), it was more saying that I was looking for an option between them.



I did my code with betfairlightweight, but on a Saturday it takes more than 10 minutes to roll the dice, unfortunately my knowledge blocked me from being able to do anything faster and correctly (and I don't have time to learn at the moment).



That's why I ended up asking if I can offer the work to a third party here in the chat.



Here is the way I did it and it takes as long time to collect data as I commented:

*Tags: General Technical*

---

**Peter** - *19:17:31*

Looking at your code, it's not easy to follow but you appear to be requesting data for 13 market types for every soccer match that Betfair has coming up in the next 24 hours. That part of the code seems to me to run fairly quickly.



You then prepare and load all that data into a Pandas dataframe, which doesn't look inefficient but it's a lot of data.



You then seem to be filtering out all the markets except the Match Odds and Over Under 2.5 markets, so I suspect that there's a saving to be had by not requesting data for the other .



Then you iterate over the dataframe, which is an inherently inefficient action and request market data for each market individually. You may want to consider pulling the market IDs column out as a series and requesting the data for multiple markets at the same time. (you may need to divide this into chunks, but it would still be much more efficient than making lots of individual requests)



When you make those requests, you ask for the three best offers on both side, but only seem interested in the best price.



Finally my suspicion as to what's really blowing up your processing time is that you iterate over your Matches_BetExchange dataframe (again an inherently inefficient action) to add each row to a list. Matches_BetExchange.values.tolist() would be hugely better. You then use a lambda function to sort the list (another CPU-intensive action) - much faster would be to sort the list in Pandas, taking advantage of it's built in indexing, before extracting the data.

*Tags: Feature Engineering*

---

**Peter** - *19:19:51*

Sorry one more. You use a lambda function to filter missing values in your exported list - much quicker to do that using Pandas drop function before exporting as that takes advantage of the indexes you've already created avoiding the need for more (implicit) iteration.



I hope these observations help. You are looking to work with a lot of data, but you also have a number of opportunities for doing so more efficiently.

*Tags: Feature Engineering*

---

**Beginner** - *19:43:38*

[@U9JHLMZB4](@U9JHLMZB4) I would like to thank you immensely for all the points brought by you, these indications are indications that with my knowledge, I can put into practice in the code, I really know that it is difficult to understand my code because it is very archaic and poorly made and yet you managed to fragment it and understand it.



Just being able to decrease the current time a little, it will help me a lot.

*Tags: General Technical*

---

## 2022-05-10

**Oliver Varney** - *13:01:53*

Struggling to get the datetime.utcnow() to patch to the publish time in flumine (2.0.5). Is there anything in particular I should be doing. Currently I just create a FlumineSimulation instance , add the strategy and then call the run(). I can see it set correctly in the config, just cant seem to call .utcnow() and get the publish_time back. Probably having a blonde moment or misunderstanding something basic here

*Tags: Strategies*

---

**liam** - *13:04:34*

utcnow will be the publish_time, what problem are you having?

*Tags: General Technical*

---

**liam** - *13:14:49*

ah the problem is when you import datetime like this



```from datetime import datetime```



*Tags: General Technical*

---

**liam** - *13:17:37*

I think a quick fix would be to patch both, not sure why it does this tbh

*Tags: Errors Debugging*

---

**Unknown** - *13:24:10*

error I got using trading.login() is displayed below . Any help will be greatly appreciated! Thank you :slightly_smiling_face: :cat2:

*Tags: Errors Debugging, Strategies*

---

**Mo** - *13:24:54*

What version of Python?

*Tags: General Technical*

---

**Mo** - *13:28:28*

So these messages are quite arcane but to try to get a sense of what they're referring to you can look in the CPython source. Here's the file and line it's referring to:



[https://github.com/python/cpython/blob/10bc004642786662324a2b0fc9a804e1110f582b/Modules/_ssl.c#L4029](https://github.com/python/cpython/blob/10bc004642786662324a2b0fc9a804e1110f582b/Modules/_ssl.c#L4029)



This suggests to me it's related to the certificate having a password - did you set one when you created the certificate?

*Tags: General Technical*

---

**Meow** - *13:32:30*

no I don’t think so. Only password I set was for the initial database creation Mo

*Tags: General Technical*

---

**Jorge** - *17:06:13*

Hi, has anyone experienced "Latency high" messages accumulating today?

*Tags: Performance*

---

## 2022-05-11

**Jorge** - *07:17:12*

How can I know if the "Latency high" messages that are accumulating are due to not having enough CPU's in my VM?

*Tags: Performance*

---

**Jorge** - *07:17:25*

The AWS CPU utilization plot looks OK, reaches 40% CPU utilization only.

I run 1 instance of flumine and 1 instance of betfairlightweight for market and order streaming + separate python processes for trading (around 5 processes).

*Tags: Deployment, Strategies*

---

**liam** - *07:28:49*

If the latency is constant then it’s probably a clock issue, if it increases in value it’s a CPU and if it does the latter but randomly it’s probably CPU but is then recovering Ie. The load is not constant 

*Tags: Performance*

---

**Rudeger Jamison** - *07:38:33*

Is this a typo in `loggingcontrols.py`



```

    def _process_cleared_markets(self, event):

        """

        :param event.event: betfairlightweight resources.ClearedOrders

        """

        logger.debug("process_cleared_markets: %s" % event)```

I think is would return a Market object or something? as `process_cleared_orders` returns the ClearedOrders object? or does it only return the cleared orders for the market that closed?

*Tags: Errors Debugging*

---

**Jorge** - *09:17:35*

It is randomly increasing in value. I see latency is measured in ms. What does a latency of 10 exactly mean? Does it just mean I get prices 10ms later than they are published?

*Tags: Performance*

---

**Jorge** - *09:21:23*

```def _calc_latency(publish_time: int) -&gt; float:

    return time.time() - publish_time / 1e3```

Isn't it ms?

*Tags: Performance*

---

**foxwood** - *09:27:27*

Seconds [https://docs.python.org/3/library/time.html#functions](https://docs.python.org/3/library/time.html#functions)

*Tags: General Technical*

---

**liam** - *09:32:18*

Which latency messages are you getting? Can you share as there are two types

*Tags: Performance*

---

**Jorge** - *10:04:34*

```2022-05-10 11:27:31,751 | WARNING | a | a | [MarketStream: 1002]: Latency high: 6.878550052642822

2022-05-10 11:27:31,752 | WARNING | a | a | [MarketStream: 1002]: Latency high: 6.872628688812256

2022-05-10 11:27:31,753 | WARNING | a | a | [MarketStream: 1002]: Latency high: 6.8602306842803955

2022-05-10 11:27:31,753 | WARNING | a | a | [MarketStream: 1002]: Latency high: 6.777828693389893```

*Tags: Performance*

---

**Jorge** - *10:06:38*

I just moved to AWS ireland so network should be OK. It must be the CPU, I only have 1 CPU

*Tags: Deployment*

---

**liam** - *10:09:00*

find out which process is causing the problems (probably the trading one) and then profile using cprofilev, 5 minutes later you will have some answers

*Tags: Strategies*

---

## 2022-05-12

**liam** - *09:07:38*

This is a lot more complicated than I thought it would be to fix it, I have created an [https://github.com/betcode-org/flumine/issues/584|issue](https://github.com/betcode-org/flumine/issues/584|issue) with some thoughts

*Tags: Errors Debugging*

---

**FrontRunner** - *11:29:22*

For the past 10 days I have been getting sporadic missing information from Betfair API's listMarketCatalogue, RUNNER_METADATA for GB horse racing.



• Nearly all the horse BRED code is missing

• Som of the SIRE_NAME, DAM_NAME, DAMSIRE_NAME are missing

• The OWNER_NAME is randomly missing off the last 1-3 characters

• Some of the BRED info for the horse, sire ... is using non standard code such as IRL instead of IRE, ITA instead of ITY.

This used to happen about once a year but now it's happened for about 6 of the last 10 days. What's going on?

*Tags: General Technical*

---

**foxwood** - *16:40:34*

Not worth changing imho even though it is a dirty fix - presumably been there a long time and not been a problem generally it seems. Use functions like I listed above if you need true local/event time - eg I used dateAsVenueTimezone() to get the correct hour after the UK clocks changed to avoid events at certain times. That worked without change on both backtest and live when checking "market.market_start_datetime". I think when I checked my recorded files they contained "naive" utc dates (not sure about official BF files ?). Changing may risk breaking too much proven code that people already working with ? My 2p for what it's worth  - you can always hide behind the Microsoft get-out of "feature - by design" :)

*Tags: Errors Debugging, Feature Engineering, Deployment*

---

## 2022-05-15

**Rudeger Jamison** - *05:48:37*

Hey I am getting several *`INVALID_SESSION_INFORMATION` Errors from the `list_cleared_orders` call in Flumine details in* :thread: 

*Tags: Errors Debugging*

---

**Rudeger Jamison** - *05:48:48*

```Traceback (most recent call last):\n File \"/usr/local/lib/python3.9/site-packages/flumine/worker.py\", line 229, in _get_cleared_market\n cleared_markets = betting_client.betting.list_cleared_orders(\n File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n (response, response_json, elapsed_time) = self.request(method, params, session)\n File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n self._error_handler(response_json, method, params)\n File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.199151822'], 'customerStrategyRefs': ['ip-10-2-10-44.e'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03b-prd-04211134-00307ff265', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03b-prd-04211134-00307ff265', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}",```

*Tags: Errors Debugging, Strategies*

---

**Rudeger Jamison** - *05:49:15*

any ideas on how to debug this?

*Tags: Errors Debugging*

---

**Rudeger Jamison** - *05:51:12*

It appears as though the session has lapsed and Flumine hasnt renewed it, when I run another local instance of Flumine the error does not occur and the bot starts betting again.



Is there a parameter to provide to make sure Flumine handles my session for me?

*Tags: Errors Debugging, Strategies*

---

**liam** - *06:13:20*

It’s the keep_alive worker [https://github.com/betcode-org/flumine/blob/master/flumine/worker.py|https://github.com/betcode-org/flumine/blob/master/flumine/worker.py](https://github.com/betcode-org/flumine/blob/master/flumine/worker.py|https://github.com/betcode-org/flumine/blob/master/flumine/worker.py)

*Tags: Deployment*

---

**liam** - *06:14:11*

Any errors would have keep_alive in them 

*Tags: Errors Debugging, Deployment*

---

**Rudeger Jamison** - *06:17:16*

```

Traceback (most recent call last):

File "/usr/local/lib/python3.9/site-packages/flumine/clients/betfairclient.py", line 44, in keep_alive

return self.betting_client.keep_alive()

File "/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/keepalive.py", line 30, in __call__

(response, response_json, elapsed_time) = self.request(session=session)

File "/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/keepalive.py", line 60, in request

self._error_handler(response_json)

File "/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/keepalive.py", line 67, in _error_handler

raise self._error(response)

betfairlightweight.exceptions.KeepAliveError: API keepAlive FAIL: NO_SESSION```

*Tags: Errors Debugging, Deployment, Strategies*

---

**Rudeger Jamison** - *06:34:40*

I deployed it yesterday to AWS and it appeared to work the whole day and then these errors started today, so after the container had been running for about 24 hrs

*Tags: Errors Debugging, Deployment*

---

**liam** - *06:35:23*

Can you find the first error, Ie is there any error that isn’t a no session  

*Tags: Errors Debugging*

---

**Rudeger Jamison** - *06:41:11*

nothing of note,



The closest error since the first `NO_SESSION` error was just a `STRATEGY_EXPOSURE` Warning, no actual errors.

*Tags: Errors Debugging, Strategies*

---

**Rudeger Jamison** - *23:30:24*

Hey mate, same error as before.



All I can see of note is another error before the `NO_SESSION` from `BetfairClient `account.get_account_details` error

*Tags: Errors Debugging*

---

**Rudeger Jamison** - *23:30:32*

any idea how to debug something like this ?

*Tags: Errors Debugging*

---

## 2022-05-16

**Rudeger Jamison** - *09:41:27*

ah right, I just have it as default.



Is that something Flumine will handle then Liam?



Or I can configure something to get around it?

*Tags: General Technical*

---

**liam** - *09:43:17*

give me 10 minutes and I will update bflw and flumine

*Tags: General Technical*

---

**liam** - *09:58:32*

this won't fix your problem though, as the code defaults to a minimum of 1200s hence why this hasn't been a problem for others, something else is going on here, are you aus?

*Tags: Errors Debugging*

---

**liam** - *10:01:30*

20mins after starting do you get any error or warnings logs from the keep_alive worker?

*Tags: Errors Debugging, Deployment*

---

**liam** - *10:09:52*

can you try the latest version of flumine 2.1.1 which will use the latest bflw, this might fix things

*Tags: Errors Debugging*

---

## 2022-05-18

**river_shah** - *08:31:05*

[@U4H19D1D2](@U4H19D1D2) just bumping this issue please: [https://github.com/betcode-org/flumine/issues/572](https://github.com/betcode-org/flumine/issues/572) I would be curious to see the recommended approach to recording sports_data / event market streams and then simulating

*Tags: General Technical*

---

**Neil T (Betfair)** - *10:15:49*

Morning [@UG03WDCHH](@UG03WDCHH) - please can you confirm what error is thrown by the Keep Alive request?  Is it still NO_SESSION?

*Tags: Errors Debugging, Deployment*

---

**Neil T (Betfair)** - *11:22:54*

Hi Liam, not easily and quickly as session related queries need to be raised with a separate team.  Assuming the sessions are being handled correctly by Flumine, likely cause (based on what I've mentioned above) is that the session is expiring before the Keep Alive call is made.  Its probably worth experimenting with a slightly shorter time period within which the keep alive call is made

*Tags: Deployment*

---

## 2022-05-20

**Mike Breen** - *07:17:24*

Hi There - I am running two strategies on an ECS Service in Ireland with 2 vCPU and 8Gb Memory and I am getting loads of `WARNING` logs saying :



```High latency between current time and OrderPackage creation time, it is likely that the thread pool is currently exhausted - "thread_pool": {"num_threads": 26, "work_queue_size": 0}```

Is this expected - I thought this would be a minimal number of strategies to cause such an issue?

*Tags: Performance*

---

**liam** - *08:23:42*

What is the latency? Are you placing a lot of orders? Average bet delay you are dealing with?



I bump to 64 anyway



```from flumine import config



config.max_execution_workers = 64```

*Tags: Performance*

---

**mandelbot** - *08:51:40*

Not sure why i get the following error when trying to stream FR horseracing markets

```{"asctime": "2022-05-20 07:50:39,625", "levelname": "ERROR", "message": "MarketStream 8006 run error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flumine\\streams\\marketstream.py\", line 44, in run\n    self._stream.start()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 67, in start\n    self._read_loop()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 226, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 256, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 8007]: Connection closed by server"}```

*Tags: Errors Debugging, Deployment*

---

**liam** - *09:58:51*

do you get any other errors? I subscribe to FR without issues, confident on the filter as it looks like it might be timeout related

*Tags: Errors Debugging*

---

## 2022-05-21

**George** - *08:38:54*

At API Login I'm getting the error "DUPLICATE_CARDS". The Betfair docs say that the description of this error is "duplicate cards". Very helpful. Does anyone know what it means?

*Tags: Errors Debugging*

---

**Brøndby IF** - *17:34:23*

Hello guys, happy Saturday everyone!



When the market is finished it gives `WINNER` or `LOSER` _status_, but after some time if try to pull that market it no longer exists.



Is there a standard time that the market remains available with this _status_ before it is possible to collect only from Historical Data?

*Tags: Data Quality*

---

**Brøndby IF** - *18:02:33*

I believe so, I will try to find this time limit available and share when I find it, so far 1.5 months previous remains available.

The question is more out of curiosity in case need to look for future values and define whether I go directly to Historic Data or not.



Good weekend to everyone!

*Tags: General Technical*

---

**Peter** - *18:18:00*

You can collect it from the historical data (or your streamed data). It can be found near or at the end of each market in the market close update.

*Tags: Data Quality*

---

**foxwood** - *18:44:36*

This may be a dumb question and my class design is wrong but where several strategies are working the same markets with identical streaming_market_filter and streaming_market_data_filter is it possible to share one stream across all these strategies. At the moment it seems that as each strategy is constructed it is opening it's own pair of sockets (order + market) and the connection limit of 10 means that only 5 strategies can be run ?

*Tags: Strategies*

---

## 2022-05-23

**mandelbot** - *07:32:32*

So I've recently ported my marketrecorder to a linux ec2 but it keeps getting shut down for some reason. Can someone shed light on this for me please?



```{"asctime": "2022-05-23 05:16:35,115", "levelname": "INFO", "message": "Market removed", "market_id": "1.199445646"}

{"asctime": "2022-05-23 05:16:35,119", "levelname": "INFO", "message": "Market closed", "market_id": "1.199439954", "clients": {"Betfair": {"d": {"username": "d", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7fcb7bddd190&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}}, "Simulated": {}, "BetConnect": {}}, "markets": {"market_count": 728, "open_market_count": 670}, "streams": ["&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140512124557120)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 140511835891456)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 140511825401600)&gt;", "&lt;Thread(WIN_load_processor, started daemon 140511814911744)&gt;", "&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"]}

{"asctime": "2022-05-23 05:16:35,123", "levelname": "INFO", "message": "Removing market 1.199445645", "clients": {"Betfair": {"d": {"username": "de", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7fcb7bddd190&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}}, "Simulated": {}, "BetConnect": {}}, "markets": {"market_count": 728, "open_market_count": 670}, "streams": ["&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140512124557120)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 140511835891456)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 140511825401600)&gt;", "&lt;Thread(WIN_load_processor, started daemon 140511814911744)&gt;", "&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"]}

{"asctime": "2022-05-23 05:16:35,123", "levelname": "INFO", "message": "BackgroundWorker keep_alive shutting down", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x7fcb7967f5f0&gt;"}

{"asctime": "2022-05-23 05:16:35,426", "levelname": "INFO", "message": "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199439954.gz successfully loaded to s3"}

{"asctime": "2022-05-23 05:16:35,452", "levelname": "INFO", "message": "1.199439954 successfully loaded marketCatalogue to s3"}

{"asctime": "2022-05-23 05:16:35,452", "levelname": "INFO", "message": "Removing: /home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199445646.gz, age: 3669.27s"}

{"asctime": "2022-05-23 05:16:35,453", "levelname": "INFO", "message": "Removing: /home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199445646, age: 3669.29s"}

{"asctime": "2022-05-23 05:16:35,453", "levelname": "INFO", "message": "Removing: /home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199445645.gz, age: 3659.23s"}

{"asctime": "2022-05-23 05:16:35,453", "levelname": "INFO", "message": "Removing: /home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199445645, age: 3659.26s"}

{"asctime": "2022-05-23 05:16:39,124", "levelname": "INFO", "message": "BackgroundWorker poll_market_catalogue shutting down", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x7fcb78031440&gt;"}

{"asctime": "2022-05-23 05:16:43,124", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

{"asctime": "2022-05-23 05:16:43,124", "levelname": "INFO", "message": "Shutting down Execution (BetfairExecution)"}

{"asctime": "2022-05-23 05:16:43,196", "levelname": "INFO", "message": "Client logout", "username": "d", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7fcb7bddd190&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}

{"asctime": "2022-05-23 05:16:43,197", "levelname": "INFO", "message": "Exiting flumine", "clients": {"Betfair": {"d": {"username": "d", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7fcb7bddd190&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}}, "Simulated": {}, "BetConnect": {}}, "markets": {"market_count": 727, "open_market_count": 670}, "streams": ["&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140512124557120)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 140511835891456)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 140511825401600)&gt;", "&lt;Thread(WIN_load_processor, started daemon 140511814911744)&gt;", "&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"]}

Traceback (most recent call last):

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/strategies/marketrecorder.py", line 54, in &lt;module&gt;

    framework.run()

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/flumine.py", line 43, in run

    self._process_close_market(event)

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/baseflumine.py", line 350, in _process_close_market

    self._remove_market(market)

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/baseflumine.py", line 211, in _remove_market

    self.markets.remove_market(market.market_id)

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/markets/markets.py", line 31, in remove_market

    self.events[market.event_id].remove(market)

ValueError: list.remove(x): x not in list```

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *07:33:35*

Latest flumine version?  

*Tags: General Technical*

---

**mandelbot** - *07:39:36*

Okay i'll update flumine and give it a shot

*Tags: General Technical*

---

## 2022-05-24

**liam** - *05:26:12*

Yeah you aren't asking for EX_TRADED_VOL so you aren't getting it, have a look at the betfair docs on streaming  

*Tags: General Technical*

---

**Jonjonjon** - *07:56:36*

I just pulled the latest version of Flumine. Prior version was a few months old. When running backtests, the results are different to what they were under the older version.



I see 'check_market_book' has been replaced by 'check_market', but have not had a chance to update that in my code. Is there anything else obvious that I might have missed?

*Tags: General Technical*

---

**Jonjonjon** - *08:01:48*

Ah good point. A mistake on my side. Though I did fix one of the breaks by changing my check_market_book function to check_market.

*Tags: Errors Debugging*

---

**Oliver Varney** - *08:04:22*

from the looks of the code check_market just wraps check_market_book with some aditional logic about streaming ids

*Tags: General Technical*

---

**Jonjonjon** - *08:04:42*

Yes, I had to rename a few things as things with Backtest in the name have been replace with Simulation. I updated those bits, so that things can run without throwing an error. I just hope I don't have to spend this evening going through the differences line by line.:disappointed:

*Tags: Errors Debugging*

---

**Jonjonjon** - *10:30:18*

I'll take a look this evening. Thanks for helping.

*Tags: General Technical*

---

**Jonjonjon** - *20:54:24*

Reverting to 1.9 fixed my tests. Thanks for the tips guys.

*Tags: Errors Debugging*

---

## 2022-05-25

**Jonjonjon** - *00:22:27*

I worked it out... In Flumine 2.0, strategy.process_orders only gets called if the strategy already has live orders. My code was relying on it being called more frequently.

*Tags: Deployment, Strategies*

---

**Jonjonjon** - *08:00:18*

Basically I have a  class that places my algo orders. It subclasses BaseStrategy, and is used by other strategies to place orders.



In Flumine 1.x, the algo trading class would always have it's process orders called.

*Tags: Strategies*

---

**mandelbot** - *08:37:13*

Seem to have a similar issue where my code is looking to cancel EXECUTABLE orders but getting "BET_TAKEN_OR_LAPSED" errors

*Tags: Errors Debugging*

---

**mandelbot** - *08:46:03*

```{"asctime": "2022-05-25 07:30:16,680", "levelname": "WARNING", "message": "Order has violated: MARKET_VALIDATION Error: Market is not open", "control": "MARKET_VALIDATION", "error": "Market is not open", "order": ```

even though I have `market_book.status not in ["CLOSED", "SUSPENDED"]`  in `check_market_book`

*Tags: Errors Debugging*

---

**Oliver Varney** - *08:46:44*

[https://github.com/betcode-org/flumine/blob/54eaa8be28a50aeaff1d1fb37087a793e75368bb/flumine/order/process.py#L94](https://github.com/betcode-org/flumine/blob/54eaa8be28a50aeaff1d1fb37087a793e75368bb/flumine/order/process.py#L94)

*Tags: General Technical*

---

**Oliver Varney** - *08:47:26*

Ill debug more today but im not sure why this is not being hit currently size remaining is zero and the current_order.status is equal to EXECUTION_COMPLETE

*Tags: Errors Debugging*

---

**mandelbot** - *09:41:53*

Is it expected to get a log message this long? (just an abridged sample of one)

```  {"asctime": "2022-05-25 08:37:27,870", "levelname": "INFO", "message": "Market removed", "market_id": "1.199544108", "event_id": "31480130", "events": {"31481118": ["&lt;flumine.markets.market.Market object at 0x7f4b93bf72d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9a7b10&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f94b3d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a650&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a490&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a190&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a7d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a710&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a850&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a590&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a810&gt;"], "31481103": ["&lt;flumine.markets.market.Market object at 0x7f4b8f90aa10&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a790&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90aad0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90a9d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90aa90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90ab90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90ad50&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90ac90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90add0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90ab10&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90ad90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90af90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f90ad10&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922050&gt;"], "31481164": ["&lt;flumine.markets.market.Market object at 0x7f4b8f922090&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922110&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922150&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922210&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922250&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9222d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922490&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9223d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922510&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9221d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9224d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9226d0&gt;"], "31481038": ["&lt;flumine.markets.market.Market object at 0x7f4b8f922450&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922790&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922690&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922750&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9227d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9228d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922a90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f9229d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922b10&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922850&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922ad0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922cd0&gt;"], "31481066": ["&lt;flumine.markets.market.Market object at 0x7f4b8f922a50&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922d50&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922ed0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc0d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bcc90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bcf50&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8d40d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8d4190&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8d4210&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bcd10&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8ee410&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8ee4d0&gt;"], "31481108": ["&lt;flumine.markets.market.Market object at 0x7f4b8f922d90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc310&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc450&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc410&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc4d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc850&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc750&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc910&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc6d0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc390&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bcb10&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc9d0&gt;"], "31481135": ["&lt;flumine.markets.market.Market object at 0x7f4b8f922c90&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f922dd0&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc090&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc150&gt;", "&lt;flumine.markets.market.Market object at 0x7f4b8f8bc190&gt;", " + 30k more chars```

*Tags: General Technical*

---

**liam** - *09:42:15*

Sorry on holiday at the moment so can't investigate but I was under the impression I had fixed this in the latest version and had pulled all releases that had this issue 

*Tags: Errors Debugging*

---

**liam** - *10:57:44*

I had the same issue so reverted it with [https://github.com/betcode-org/flumine/pull/588|this](https://github.com/betcode-org/flumine/pull/588|this) 

*Tags: General Technical*

---

**liam** - *11:00:04*

If it’s still present then it will be something in [https://github.com/betcode-org/flumine/pull/585|2.1.0](https://github.com/betcode-org/flumine/pull/585|2.1.0) that is causing it 

*Tags: General Technical*

---

**Jonjonjon** - *20:26:21*

Are you using the `sep` feature to tag your orders?



[https://github.com/betcode-org/flumine/blob/5f78864738c32eb0e59f9d8d8c498900b51a81a3/flumine/order/order.py#L66](https://github.com/betcode-org/flumine/blob/5f78864738c32eb0e59f9d8d8c498900b51a81a3/flumine/order/order.py#L66)

*Tags: Feature Engineering*

---

## 2022-05-26

**liam** - *05:38:35*

If you revert/patch the change in `baseflumine._process_orders` it should change this, simulation calls hints slightly differently 

*Tags: General Technical*

---

**Unknown** - *06:16:21*

for me its just confirmed that any order create with my style of strategy is not worth raising out of process_orders, only exposure calcs and cancels.

*Tags: Strategies*

---

**Oliver Varney** - *08:08:57*

very very early to bed, early up :joy: I think the use case is strategy specific, alot of my strategy is based of the process of making predictions then creating trades off the back, rather then specific signals that maybe is more conventional. I dont think theres a correct / best practice. The two bullet points youve described above are logical I believe, as they were my similar thoughts when having code in both sections.  have you confirmed that the code is doing what youve listed above in live?

*Tags: Deployment, Strategies*

---

**LM** - *11:58:05*

Any thoughts on below error. Seems to occur sporadically after flumine has been running for a while

```{"asctime": "2022-05-26 10:56:10,717", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ec2-user/.local/lib/python3.8/site-packages/flumine/worker.py\", line 229, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n  File \"/home/ec2-user/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ec2-user/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ec2-user/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.199541139'], 'customerStrategyRefs': ['ip-172-31-43-15'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03a-prd-05180823-000f838978', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03a-prd-05180823-000f838978', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.199541139'], 'customerStrategyRefs': ['ip-172-31-43-15'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03a-prd-05180823-000f838978', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03a-prd-05180823-000f838978', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *12:04:51*

Hmm [@UG03WDCHH](@UG03WDCHH) had this issue, any fixes?

*Tags: Errors Debugging*

---

## 2022-05-27

**Rudeger Jamison** - *00:49:27*

Actually upgrading to the latest version of Flumine seemingly did the trick

*Tags: General Technical*

---

## 2022-05-30

**Michael** - *21:23:29*

Hi, I'm getting the following error when trying to pull a file list (same code as example) `json.decoder.JSONDecodeError: Expecting value: line 2 column 1 (char 1)`



During handling of the above exception, another exception occurred:

*Tags: Errors Debugging*

---

**Newbie99** - *21:50:14*

Sounds like an invalid json file from that error?

*Tags: Errors Debugging*

---

**John Foley** - *23:08:44*

Im guessing probably invalid credentials/app key causing you to get an error message as a response (rather than a valid json response)

*Tags: Errors Debugging*

---

## 2022-05-31

**Rudeger Jamison** - *17:59:20*

Hey, Flumine seems to block LimitOrders less than $5 stake. My account actually allows these smaller bets...



Is there a setting I can change to allow Flumine to place these bets with out setting force=true?

*Tags: General Technical*

---

## 2022-06-01

**Ke** - *22:28:40*

Did you solve the problem?

*Tags: General Technical*

---

## 2022-06-03

**Beginner** - *16:33:08*

Hi guys, good afternoon. Do any of you have a model that reproduces the creation of the price/volume chart of the markets?

If have it, if can share I would greatly appreciate it!



I'm wanting to generate one with timeline (current match minute and local hour), it would help me a lot to save time on the project.

*Tags: Strategies*

---

## 2022-06-04

**Brøndby IF** - *17:58:34*

Please does anyone have the offline PDF of the Betfair API documentation?



I'm trying to access the site but it says it's unavailable and the team is working to resolve it.

*Tags: General Technical*

---

**thambie1** - *18:16:55*

If you're looking for the streaming documentation, here's a copy: [https://github.com/betfair/stream-api-sample-code/blob/master/stream-api-specification.pdf](https://github.com/betfair/stream-api-sample-code/blob/master/stream-api-specification.pdf)

*Tags: General Technical*

---

## 2022-06-06

**moseley82** - *08:16:46*

Hey guys anybody know if anything has changed with horse racing data? None of my Place data is streaming properly this morning, I usually use this link to troubleshoot - [https://docs.developer.betfair.com/visualisers/api-ng-account-operations/](https://docs.developer.betfair.com/visualisers/api-ng-account-operations/) but it's taking me to a maintenance page (possibly related?)

*Tags: General Technical*

---

**liam** - *09:02:26*

What do you mean by streaming properly? I haven't had any errors on my side

*Tags: Errors Debugging*

---

## 2022-06-10

**Rudeger Jamison** - *08:51:41*

Nope, but I am matching on bet_id.



I just get my "strategy" name in the meta orders

*Tags: Strategies*

---

**EJono** - *11:51:08*

Are pauses between streaming market books occasionally expected from time to time?

*Tags: General Technical*

---

**EJono** - *14:24:48*

Sorry liam this may be a dead I do not have the raw data just the timestamps of the PMB execution time and some custom teritary logs ie market_book latency, market suspended status, runner_exposure, back&amp;lay prices

*Tags: Performance*

---

**Brøndby IF** - *20:46:06*

Good afternoon everyone!

At certain times of the day, when I pull up the list of live football games ids that contain certain markets:



`markets_base = [`

        `'FIRST_HALF_GOALS_05','FIRST_HALF_GOALS_15','FIRST_HALF_GOALS_25',`

        `'OVER_UNDER_05','OVER_UNDER_15','OVER_UNDER_25','OVER_UNDER_35','OVER_UNDER_45','OVER_UNDER_55','OVER_UNDER_65','OVER_UNDER_75','OVER_UNDER_85'`

        `]`



`market_filter = betfairlightweight.filters.market_filter(`

        `event_type_ids=['1'],`

        `in_play_only=True,`

        `market_type_codes=markets_base`

    `)`

`soccer_events = trading.betting.list_events(filter=market_filter)`



Like for example: 31518957



And I immediately use these ids to collect the game's market data:



`filter_catalog_markets = betfairlightweight.filters.market_filter(`

            `event_ids=[event_id],`

            `market_type_codes = markets_base`

            `)`



        `catalog_markets = trading.betting.list_market_catalogue(`

            `filter=filter_catalog_markets,`

            `max_results='100',`

            `sort='FIRST_TO_START',`

            `market_projection=['EVENT','COMPETITION','MARKET_START_TIME','RUNNER_METADATA']`

            `)`



One or other sporadically returns `catalog_markets` as empty → `[]`.

Is this something 'normal' to happen?



When I say sporadically, I tested run every 1 minute all day and this happened 13 times, one time for each different games.



My question is just to know if this is common to analyze if I can just ignore such an empty return or if I should worry about some structural flaw in the way I'm researching.

*Tags: Deployment, Strategies*

---

## 2022-06-11

**liam** - *07:07:27*

Can you share some code that replicates? Very hard to debug without 

*Tags: Errors Debugging*

---

**Rudeger Jamison** - *09:20:55*

```    def _process_cleared_orders(self, event):

        if event.event.orders:

            client = boto3.client("kinesis", region_name="eu-west-1")

            orders = [json.dumps(o.__dict__, default=str).encode("utf-8") for o in event.event.orders]

            self._write_logs(client=client, data=orders, write_table="cleared_orders")



    def _process_cleared_orders_meta(self, event):

        orders = event.event

        updated_orders = []

        for order in orders:

            if order.order_type.ORDER_TYPE == OrderTypes.LIMIT:

                size = order.order_type.size

            else:

                size = order.order_type.liability



            if order.order_type.ORDER_TYPE == OrderTypes.MARKET_ON_CLOSE:

                price = None

            else:

                price = order.order_type.price



            order_data = {

                "bet_id": order.bet_id,

                "market_id": order.market_id,

                "selection_id": order.selection_id,

                "trade_id": order.trade.id,

                "date_time_placed": order.responses.date_time_placed,

                "price": price,

                "price_matched": order.average_price_matched,

                "size": size,

                "size_matched": order.size_matched,

                "side": order.side,

                "market_type": order.market_type,

                "elapsed_seconds_executable": order.elapsed_seconds_executable,

                "customer_strategy_ref": order.trade.strategy.name,

                "order_status": order.status.value,

                "market_note": order.trade.market_notes,

                "trade_notes": order.trade.notes_str,

                "order_notes": order.notes_str,

                "is_cleared_order": True if order.cleared_order else False,  # it is either None or True, so need to coerce

                **order.context,

            }

            updated_orders.append(json.dumps(order_data, default=str).encode("utf-8"))



        if updated_orders:

            client = boto3.client("kinesis", region_name="eu-west-1")

            self._write_logs(client=client, data=updated_orders, write_table="cleared_orders_meta")```

*Tags: Strategies*

---

**Rudeger Jamison** - *09:21:15*

```    def _write_logs(self, client, data: List[bytes], write_table: str):

        records = [{"Data": d, "PartitionKey": f"{self.log_prefix}{write_table}"} for d in data]

        for chunk in chunks(records, n=200):

            client.put_records(StreamName="LoggingStream", Records=chunk)```

*Tags: Errors Debugging*

---

**Brøndby IF** - *15:32:16*

[@UFTBRB3F1](@UFTBRB3F1) So, but in `trading.betting.list_events` I put a filter so that it only pulls event ids that contain at least some of the mentioned markets, correct?



So it wouldn't make sense for a game that started 0-0 or that is 2-1 to appear with a blank market return.



Detail, if I run every 1 second, for example, I think it would make more sense for failures of thousandths of difference to happen, but this happens by calling 1 time per minute, so it doesn't seem to me that it's a coincidence to always get it right at the time of the problem, must have some little detail that lasts for at least 1 minute or more (I think. Haha)



Or am I missing something because of my lack of knowledge?

*Tags: Strategies*

---

**Rudeger Jamison** - *21:46:09*

That code help?

*Tags: General Technical*

---

## 2022-06-12

**Rudeger Jamison** - *08:25:49*

I have a feeling it's an issue on my aws end. Sorry to bother you Liam. Leave it with me.

*Tags: Deployment*

---

## 2022-06-16

**Newbie99** - *13:37:27*

By chance is anyone else getting errors today (can't see anything showing as down):



```ERROR:flumine.clients.betfairclient:BetfairClient `login` error

Traceback (most recent call last):

  File "D:\Python38\lib\site-packages\urllib3\connection.py", line 169, in _new_conn

    conn = connection.create_connection(

  File "D:\Python38\lib\site-packages\urllib3\util\connection.py", line 96, in create_connection

    raise err

  File "D:\Python38\lib\site-packages\urllib3\util\connection.py", line 86, in create_connection

    sock.connect(sa)

socket.timeout: timed out



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:\Python38\lib\site-packages\urllib3\connectionpool.py", line 699, in urlopen

    httplib_response = self._make_request(

  File "D:\Python38\lib\site-packages\urllib3\connectionpool.py", line 382, in _make_request

    self._validate_conn(conn)

  File "D:\Python38\lib\site-packages\urllib3\connectionpool.py", line 1010, in _validate_conn

    conn.connect()

  File "D:\Python38\lib\site-packages\urllib3\connection.py", line 353, in connect

    conn = self._new_conn()

  File "D:\Python38\lib\site-packages\urllib3\connection.py", line 174, in _new_conn

    raise ConnectTimeoutError(

urllib3.exceptions.ConnectTimeoutError: (&lt;urllib3.connection.HTTPSConnection object at 0x0000022DED12BC40&gt;, 'Connection to [http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com) timed out. (connect timeout=3.05)')



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:\Python38\lib\site-packages\requests\adapters.py", line 439, in send

    resp = conn.urlopen(

  File "D:\Python38\lib\site-packages\urllib3\connectionpool.py", line 755, in urlopen

    retries = retries.increment(

  File "D:\Python38\lib\site-packages\urllib3\util\retry.py", line 574, in increment

    raise MaxRetryError(_pool, url, error or ResponseError(cause))

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x0000022DED12BC40&gt;, 'Connection to [http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com) timed out. (connect timeout=3.05)'))```

Interestingly Interactive login also doesn't work for me....however this is only when trying to connect from my local machines.



AWS appears to be chugging away happily (all the certs are obviously the same and Interactive login doesn't work locally, so I'm a bit perplexed).

*Tags: Errors Debugging, Deployment*

---

**Newbie99** - *13:48:24*

Actually I lie...Interactive login does actually appear to work now, odd. So it must be cert related (which makes sense of course from the error), odd it still works on AWS with certs though.

*Tags: Errors Debugging, Deployment*

---

**RMG** - *16:55:41*

n00b here also, struggling to login with Betfairlightweight.

*Tags: General Technical*

---

**RMG** - *16:57:04*

Have created keys with XCA, uploaded .crt to BF security, but when i try and use trading.login() I'm getting similar errors to above:  Max tries exceeded with url: /api/certlogin.

*Tags: Errors Debugging, Strategies*

---

**Mo** - *16:58:14*

Can you share the full error?

*Tags: Errors Debugging*

---

**RMG** - *17:00:01*

does the "interal name" in XCA have to match the Application name from the Betfair API-NG demonstration tool, where we App key is created?

*Tags: General Technical*

---

**RMG** - *17:02:57*

Final question, do, the .pem and .crt need to be created on the same machine as the that which the betfairlightweight codebase is run from?

*Tags: General Technical*

---

**Unknown** - *17:05:52*

Here's the full error:

*Tags: Errors Debugging*

---

**D C** - *17:06:37*

Have you recently  upgraded OS? I had problems with the SSL configuration when moving from Ubuntu 18.04 to 22.04 and had to modify some settings.

*Tags: General Technical*

---

**RMG** - *17:22:44*

btw, I had all this (code and certs) working before (2 years ago), but tried to login this week, and gave me the certs errors, so i've recreated them, but still receiving errors.

*Tags: Errors Debugging*

---

**Mo** - *17:26:54*

What version of Python?

*Tags: General Technical*

---

**Mo** - *17:27:30*

Connect timeout suggests it's just a local networking problem like something wrong at your ISP

*Tags: General Technical*

---

**Newbie99** - *17:28:27*

That would make sense given AWS was unaffected, but really odd that the Interactive login then seemed to work!

*Tags: Deployment*

---

**Jonjonjon** - *17:43:39*

If you have a small account it's easier to hard code the app key and login details into your python scripts.

*Tags: General Technical*

---

**Mo** - *17:47:45*

These certificate problems are always so frustrating

*Tags: General Technical*

---

**RMG** - *18:02:25*

and back to the same error. :shrug:

*Tags: Errors Debugging*

---

## 2022-06-18

**Brøndby IF** - *17:03:54*

Good afternoon everyone, I researched about this error but I didn't find anything to understand and work around it, has anyone gone through it?



`index                                      4`

`event_id                            31536297`

`event_name    Baltyk Gdynia v Jarota Jarocin`

`Name: 4, dtype: object`



`Traceback (most recent call last):`

`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': ['1.200293211'], 'priceProjection': {'priceData': ['EX_TRADED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}` 

`Exception: None` 

`Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': '...........', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': '..........', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`

*Tags: Errors Debugging*

---

**Mo** - *17:05:03*

Random error, nothing you can do about it. Just make the request again

*Tags: Errors Debugging*

---

**Unknown** - *17:06:14*

Thanks [@UBS7QANF3](@UBS7QANF3) just today I received 18 such errors, so I'll put a pass to ignore this.

*Tags: Errors Debugging*

---

**Brøndby IF** - *20:50:13*

I didn't find it directly in search bar on documentation ([https://docs.developer.betfair.com/](https://docs.developer.betfair.com/)), so I'll publish this list here because if in the future someone has a question with an error code and tries to search bar here in the slack community, they will find it without having to ask how I did it:



`ANGX-0001 → The operation requested too much data (TOO_MUCH_DATA)`

`ANGX-0002 → Invalid input data (INVALID_INPUT_DATA)`

`ANGX-0003 → The session token passed is invalid (INVALID_SESSION_INFORMATION)`

`ANGX-0004 → An application key is required for this operation (NO_APP_KEY)`

`ANGX-0005 → A session token is required for this operation (NO_SESSION)`

`ANGX-0006 → An unexpected internal error occurred that prevented successful request processing (UNEXPECTED_ERROR)`

`ANGX-0007 → The application key passed is invalid (INVALID_APP_KEY)`

`ANGX-0008 → There are too many pending requests (TOO_MANY_REQUESTS)`

`ANGX-0009 → The service is currently too busy to service this request (SERVICE_BUSY)`

`ANGX-0010 → Internal call to downstream service timed out (TIMEOUT_ERROR)`

`ANGX-0011 → The application key creation has failed (APP_KEY_CREATION_FAILED)`

`ANGX-0012 → The application name specified already exists (DUPLICATE_APP_NAME)`

`ANGX-0013 → The application name specified is too long (APP_CREATION_FAILED)`

`ANGX-0014 → The request has exceeded the maximum allowed size (REQUEST_SIZE_EXCEEDS_LIMIT)`

`ANGX-0015 → The access to this functionality is not allowed (ACCESS_DENIED)`

`ANGX-0016 → Provided market group id does not identify a known market group (INVALID_MARKET_GROUP)`

`ANGX-0017 → Unable to delete/update limit as it doesn't exist (EXPOSURE_LIMIT_NOT_EXIST)`

`ANGX-0018 → Unable to unblock market group after exposure limit breach, market group is not blocked (MARKET_GROUP_NOT_BLOCKED)`

*Tags: Errors Debugging*

---

## 2022-06-21

**thambie1** - *07:42:08*

This crash looks pretty bad, never seen "500 Internal Server Error" when going to [http://betfair.com|betfair.com](http://betfair.com|betfair.com)

*Tags: Errors Debugging, Deployment*

---

**Dave** - *07:48:44*

Yeah was just about to say the same, error page straight outta the 2000s

*Tags: Errors Debugging*

---

## 2022-06-24

**Aaron Smith** - *16:47:36*

Hi ppl!

I m trying to extract bsp (and result) from historic streaming files. Here is what i do:



```def get_selection_id_to_result(trading, streaming_file: str) -&gt; dict:

    stream = trading.streaming.create_historical_generator_stream(

        file_path=streaming_file,

        listener=StreamListener(

            max_latency=None, update_clk=False,

        ),

    )

    with patch("builtins.open", smart_open.open):

        g = stream.get_generator()

        selection_id_to_result = {}

        for market_book in g():

            market_book = market_book[0]

            if market_book.status == 'OPEN':

                continue

            for rb in market_book.runners:

                if rb.selection_id not in selection_id_to_result:

                    selection_id_to_result[rb.selection_id] = {'bsp': float('nan'), 'result': ''}

                sp = get_sp(rb)

                if isinstance(sp, float):

                    if not math.isnan(sp):

                        selection_id_to_result[rb.selection_id]['bsp'] = round(sp, 3)

                selection_id_to_result[rb.selection_id]['result'] = rb.status



    return selection_id_to_result```

`get_sp`  is liams function from flumine/utils.

Mostly it works, but sometimes it doesnt get the sp even though there is one. Does anyone have an idea what could be causing this?

*Tags: Performance, Strategies*

---

## 2022-06-25

**Beginner** - *16:55:53*

Hi everyone, good afternoon!

I created the SSL files and use them in full working order on my computer along with the betfairlightweight and flumine modules.



Now I want to put my code on Heroku to automate the daily runs task.



My question is: do I need to create new SSL certificates or can I use the same ones I currently use?



I preferred to ask before running the code on Heroku, I was afraid of generating a block on the betfair account.

*Tags: General Technical*

---

## 2022-06-26

**Beginner** - *13:39:18*

Yesterday I discovered that Heroku and several other code clouds don't have a path to tell the code where to find the certificate files: `cert_files=('./certs/bf_certs.pem')`



So I tried another approach, logging into my machine, saving a pickle file and uploading it to Google Drive:



```with open('betfair_login.pickle', 'wb') as handle:

    trading = betfairlightweight.APIClient('email', 'pssw', app_key='app_key', cert_files=('./certs/bf_certs.pem'),session=requests.Session())

    trading.login()

    pickle.dump(trading, handle, protocol=pickle.HIGHEST_PROTOCOL)```

And on Heroku use `urllib.request.urlopen` passing the url of the Drive file:



```from urllib.request import urlopen

    loaded_pickle_object = pickle.load(urlopen("[https://drive.google.com/file/d/xxxxxxxxxxxxxxxx/](https://drive.google.com/file/d/xxxxxxxxxxxxxxxx/)"))

    trading = loaded_pickle_object```

However, when trying to open it generates an error `invalid load key, '&lt;'.`



Could someone help me find an option to use the betfairlightweight when there is no way to pass the path where the certificates are?

Thank you in advance and happy Sunday to all!

*Tags: Errors Debugging, Strategies*

---

**Mo** - *13:57:14*

Use AWS EC2 instead?

*Tags: Deployment*

---

**Beginner** - *14:15:10*

[@UBS7QANF3](@UBS7QANF3) Ah ok, so it was definitely the wrong estimation model I looked at, now it makes perfect sense! Thank you very much!

*Tags: Strategies*

---

## 2022-06-29

**LM** - *10:30:24*

Do flumine backtests handle FILL_OR_KILL simulation?

*Tags: General Technical*

---

**Beeblebrox** - *14:47:36*

[https://github.com/betcode-org/flumine/blob/9307dd5a0084c3583207921a521a1c39e430220f/flumine/simulation/simulatedorder.py#L62](https://github.com/betcode-org/flumine/blob/9307dd5a0084c3583207921a521a1c39e430220f/flumine/simulation/simulatedorder.py#L62)

*Tags: General Technical*

---

## 2022-07-03

**mon mon** - *10:54:45*

Are there any conditions/controls that will cause Flumine to exit (gracefully) without prompting?  My instance is running fine for an hour or so but then shuts itself down. Simplified log below....

```19:01:03 | INFO     | Client update account details

19:02:31 | INFO     | Market 1.200669111 closed

19:02:31 | INFO     | Market closed

19:02:31 | INFO     | Removing market 1.200669107

19:02:31 | INFO     | BackgroundWorker Info Update shutting down

19:02:33 | INFO     | BackgroundWorker Market Filter Update shutting down

19:02:37 | INFO     | BackgroundWorker Exchange Rate Update shutting down

19:02:41 | INFO     | BackgroundWorker Market PandL DB  Update shutting down

19:02:45 | INFO     | BackgroundWorker Account History  Update shutting down

19:02:49 | INFO     | BackgroundWorker Order DB Update shutting down

19:02:53 | INFO     | BackgroundWorker DB Update from data scraping - horses shutting down

19:02:57 | INFO     | BackgroundWorker keep_alive shutting down

19:02:58 | INFO     | 1.200669111: 0 cleared orders found, more available: False

19:03:01 | INFO     | BackgroundWorker poll_market_catalogue shutting down

19:03:04 | INFO     | Client update account details

19:03:05 | INFO     | BackgroundWorker poll_account_balance shutting down

19:03:09 | INFO     | BackgroundWorker poll_market_closure shutting down

19:03:13 | INFO     | Stopped OrderStream 1002

19:03:13 | INFO     | Stopped MarketStream 3003

19:03:13 | INFO     | Stopped MarketStream 2006

19:03:13 | INFO     | Shutting down Execution (SimulatedExecution)

19:03:13 | INFO     | Shutting down Execution (BetfairExecution)

19:03:13 | INFO     | Shutting down logging control LOGGING_CONTROL

19:03:13 | INFO     | Stopped output_thread (OrderStream 1002)

19:03:14 | INFO     | Client logout

19:03:14 | INFO     | Exiting flumine```

*Tags: Deployment*

---

**Dave** - *14:38:22*

Haven't improved any models since Jan.  Worked a liiittle on execution, also tried quadrupling my stakes and got my arse handed to me so dialed it back to usual sizes.

*Tags: Strategies*

---

**mon mon** - *14:56:27*

That was just the console output....

```log_config = {

        'version':1,

        'disable_existing_loggers': False,

        'formatters':{

                'screen_text': {

                        'format': '%(asctime)s | %(levelname)-8s | %(message)s',

                        'datefmt':"%H:%M:%S"

                },

                "json_file": {

                        '()': 'pythonjsonlogger.jsonlogger.JsonFormatter',

                        'format': "%(asctime)s %(levelname)s %(name)s %(message)s",

                },

        },

        'handlers':{

                'consoleHandler':{

                        'formatter': "screen_text",

                        'class': "logging.StreamHandler",

                        'level': 'INFO',

                },

                'fileHandler':{

                        'formatter': 'json_file',

                        'class': 'logging.handlers.TimedRotatingFileHandler',

                        'filename': 'logs/flumine.log',

                        'when': 'midnight',

                        'interval': 1,

                        'backupCount':7,

                        'level': 'DEBUG',

                },

        },

        'root':{

                'level': 'DEBUG',

                'handlers' : ['consoleHandler','fileHandler'],

        },

}





logging.config.dictConfig(log_config)

logger = logging.getLogger()```

*Tags: Errors Debugging*

---

**mon mon** - *14:57:47*

I've trolled through the DEBUG level logs but can't see anything that hints as to why the program is deciding to shut down.

*Tags: Errors Debugging*

---

**Mo** - *15:18:53*

Debugger in PyCharm is good for this

*Tags: Errors Debugging*

---

**Mo** - *15:20:15*

Python built in function dir() also helpful

*Tags: General Technical*

---

**Mo** - *15:25:21*

Yeah it's helpful but not the complete solution. It tells you all of the properties and methods on an object but you still need to access them to get the values 

*Tags: General Technical*

---

## 2022-07-04

**Unknown** - *10:32:05*

Similar to [@UBS7QANF3](@UBS7QANF3)'s Pycharm suggestion. I use the debugger in vscode. It gives me a panel like the one below that I can use to drill down to any level in any of the data objects.

*Tags: Errors Debugging*

---

**Dave** - *12:40:16*

Pfft. print() is the OG debugger :laughing:

*Tags: Errors Debugging*

---

## 2022-07-06

**Jonjonjon** - *21:11:51*

I have a strategy that places bets exactly at scheduled off.



For some markets, the scheduled off can change. In my backtests, the bets get fired off at the correct time. But in live trading, sometimes my bets get placed at the prior market start time.



I believe this is because I use "seconds_to_start", which uses "market_start_datetime", which will come from the market_book's market_definition.



In live trading, the market_start_time will come from the market_catalogue. So I am guessing that in live trading, the process that updates the market_catalogue might be misbehaving.



What would be the cleanest way to solve this?

*Tags: Deployment, Strategies*

---

**liam** - *22:06:56*

I can have a look tomorrow, going forward I assume using the MarketBook for the start time in live (rather than cat) would fix things?

*Tags: Errors Debugging, Deployment*

---

**Jonjonjon** - *22:42:30*

Yes. Thanks Liam. I've just done a local change that does that, though that won't fix it for other users.

*Tags: Errors Debugging*

---

**Jonjonjon** - *23:22:27*

Thinking about it, I'm not sure if always using the market book will fix things. As I don't know if it definitely updates correctly. From looking at the way it currently updates the market catalogue, that should have happened every minute, though it didn't happen for me on atleast 2 occasions last month.:shrug::skin-tone-6:

*Tags: Errors Debugging*

---

## 2022-07-07

**mon mon** - *22:55:22*

I haven't spotted anything nefarious in the logs just before Flumine shuts itself down, but on the console the last message from python is

```Traceback (most recent call last):

  File "live_trade.py", line 717, in &lt;module&gt;

    framework.run()

  File "/usr/local/lib/python3.8/site-packages/flumine/flumine.py", line 57, in run

    self._process_close_market(event)

  File "/usr/local/lib/python3.8/site-packages/flumine/baseflumine.py", line 347, in _process_close_market

    self._remove_market(market)

  File "/usr/local/lib/python3.8/site-packages/flumine/baseflumine.py", line 211, in _remove_market

    self.markets.remove_market(market.market_id)

  File "/usr/local/lib/python3.8/site-packages/flumine/markets/markets.py", line 34, in remove_market

    self.events[event_id].remove(market)

ValueError: list.remove(x): x not in list```

*Tags: Errors Debugging, Deployment*

---

## 2022-07-08

**liam** - *07:00:53*

Flumine version?

*Tags: General Technical*

---

**liam** - *09:30:45*

damn, thought I had fixed this, will look into it today

*Tags: Errors Debugging*

---

**liam** - *09:30:59*

any logs before the error you can share?

*Tags: Errors Debugging*

---

**mon mon** - *12:39:23*

Here's the time before the error - let me know if you need a bigger time slice:

*Tags: Errors Debugging*

---

## 2022-07-11

**Gib** - *14:22:22*

hi, ive been using the streaming example below as basis for my app and it is working brilliantly. However, when i leave running for a long period, it does seem to time out. Ive tried adding the error handing code to overcome this but it seems to hang. Do i need to do anything special to get the errorhandling code to run? [https://betcode-org.github.io/betfair/streaming/](https://betcode-org.github.io/betfair/streaming/) i get the "Starting MarketStreaming" in my console about 7 times in a row then it just seems to stop. Any help appreciated

*Tags: Errors Debugging*

---

**Gib** - *14:49:18*

thanks for quick response liam, yes looks like i got an error when installing logging. will try to get that working...  Great job putting these resource together, really appreciate it.

*Tags: Getting Started, Errors Debugging*

---

**mon mon** - *15:19:42*

Today I tried running with a single market filter to see if that made any difference ( I usually run 2 or 3) - the instance ran for a bit longer but eventually ended up with the same "list.remove(x): x not in list" error.

*Tags: Errors Debugging*

---

**Gib** - *15:29:22*

[https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py)

*Tags: General Technical*

---

**Gib** - *15:33:26*

i think that worked, im now getting a certs error, so im guessing it will only work with trading.login() not trading.login_interactive()?

*Tags: Errors Debugging, Strategies*

---

**liam** - *15:35:38*

hence my question

*Tags: General Technical*

---

**Gib** - *15:38:07*

makes perfect sense, thank you again.... im streaming!

*Tags: General Technical*

---

**mon mon** - *15:39:30*

I used to have a worker which updated my time-limited market filters for the streams every few hours (as a way to get around the 200 market limit).

I was worried this might be causing the error so I have since got rid of it, and now use a standard market filter with no time limits.

Can post a new log if that helps.

*Tags: Errors Debugging*

---

## 2022-07-13

**liam** - *11:22:00*

Ah, no the market recorder will use a different stream, I have a fix [https://github.com/betcode-org/flumine/pull/594/commits/9895e827ea15aa51db74bd36ed957358c235c983|here](https://github.com/betcode-org/flumine/pull/594/commits/9895e827ea15aa51db74bd36ed957358c235c983|here) that I will push out today

*Tags: Data Quality, Errors Debugging*

---

## 2022-07-14

**liam** - *09:37:44*

[https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#221-2022-07-14|flumine 2.2.1](https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#221-2022-07-14|flumine 2.2.1) now released, let me know if you have any further issues

*Tags: General Technical*

---

**Mick** - *17:35:50*

I'm having a bash at using betfairutil... there doesn't seem to be any documentation for it (did I miss something?). But I think I am supposed to call betfairutil.prices_file_to_csv_file(filename_including_path_of_source,filename_including_path_of_destination_csv). However, I get KeyError: 'selection_id' - this is happening within pandas. The (randomly selected) input file I'm trying to process is "BASIC-1.117880714". Any ideas?

*Tags: Errors Debugging, Feature Engineering*

---

**Mo** - *17:38:07*

Documentation definitely needs some work. The closest things are the README and this GitHub comment: [https://github.com/mberk/betfairutil/issues/17#issuecomment-1055107228](https://github.com/mberk/betfairutil/issues/17#issuecomment-1055107228)



If you share the file I'll take a look

*Tags: General Technical*

---

**Mick** - *17:53:26*

I get the same error with either of these

*Tags: Errors Debugging*

---

**Mick** - *18:06:57*

Thanks for your help btw

*Tags: General Technical*

---

**Mo** - *18:08:09*

No worries, always helpful having more users of betfairutil

*Tags: General Technical*

---

## 2022-07-15

**mon mon** - *13:07:15*

Benn running for around 24hrs with no issues - thanks for you help [@U4H19D1D2](@U4H19D1D2)

*Tags: General Technical*

---

## 2022-07-16

**Andrew** - *06:41:31*

But what's the 1. purpose as the prefix of the market Id?

*Tags: Errors Debugging*

---

**Rudeger Jamison** - *09:14:25*

I have a feeling it's because I write every log directly to s3 as a parquet file, using pandas. Not very fast. Perhaps I need to collect multiple orders and write them in bulk as they're collected or a time period threshold is met?

*Tags: Feature Engineering*

---

**Rudeger Jamison** - *09:15:52*

Although each file atm seems to be one markets worth of orders.... I'm not exactly sure. Clutching at straws a bit. I have 4gb of memory and 1 vcpu.

*Tags: Performance, Deployment*

---

**Jonjonjon** - *11:31:23*

Afraid I've never used S3, so I can't comment on the performance of writing to it.

*Tags: Performance*

---

**birchy** - *15:59:47*

There's going to be latency writing direct to S3. Far better to save locally and then copy or move to S3 on a separate process.

*Tags: Performance*

---

**D** - *20:02:47*

Using pandas to create lots of small parquet files may not be performant. Have you tried plain csv or json instead? 

*Tags: Feature Engineering*

---

**Rudeger Jamison** - *20:40:48*

I have  and that resulted in files 30X the size, so that's what lead me down this path. Perhaps I try out [@U016TGY3676](@U016TGY3676)'s suggestion and write to local and then have a worker upload batch every 30 minutes. Feels problematic too though...

*Tags: General Technical*

---

**D** - *21:15:09*

The files may be larger but is the performance better or worse? I don't know but I don't think the answer is obvious. Anyway, birchy’s method sounds like a better approach.

*Tags: Performance*

---

**birchy** - *21:51:29*

[@UG03WDCHH](@UG03WDCHH) or you could crontab aws-cli cp/mv/sync or whatever

*Tags: Deployment*

---

## 2022-07-17

**Rudeger Jamison** - *00:40:01*

It's not an ec2 instance [@U016TGY3676](@U016TGY3676), it's a containerised service on ECS.

*Tags: Deployment*

---

## 2022-07-20

**D C** - *10:12:07*

Probably an idiot question but seen a lot of these things mentioned lately in a flumine context - can someone explain the difference (if any) between what you collectively refer to as back-testing, simulation and paper trading? In particular there seems to be an implied difference between back-testing and simulaton?

*Tags: Strategies*

---

**liam** - *10:19:33*

This is probably my fault;



*paper trading* is just forward testing, ie. testing on live markets but no real orders being placed



*backtesting* I see as applying a strategy on historical data



*simulation* is accurate play back of historical data as is if it was live using exactly the same code/integration



I changed the name in flumine as I found backtesting to be a bit vague as the simulation in flumine is far more powerful however I accept many will argue backtesting/simulation are the same. I will regularly 'backtest' outside of flumine using csv/pandas/jupyter before coding up properly and simulating in flumine. This allows quicker iterations without the heavy processing 'simulating' requires

*Tags: Data Quality, Feature Engineering, Deployment, Strategies*

---

## 2022-07-23

**Dave** - *14:56:39*

Worth checking if flumine clears the context on market closure (guessing not) and in that case clearing the context yourself?

*Tags: General Technical*

---

**foxwood** - *16:37:36*

I got caught in some confusion and determined that if one framework is running multiple strategies on the same markets then a single market.context is being shared across all strategies. This is obviously correct since it is a "market context" but that was not the way I was using it and was storing strategy specific data for that market in there ! So, since all my strats have my own common base above flumine, I patched things up by making a dict per strategy within the market context like this which was a simple refactor of "market.context" usage. Maybe you're in a similar rabbit hole ?

I also ended up having to solve unique strategy naming for "customer_order_ref" on orders so that the blotter could be parsed per strategy if needed.



```class myBaseStrategy(BaseStrategy):



    def add(self) -&gt; None:

        self.ctxname = self.__class__.__name__

        ...

    def check_market_book(self, market, market_book) -&gt; bool:

        ...

        if self.ctxname not in market.context:

            market.context[self.ctxname] = {}

            market.context[self.ctxname]["mktBetsThisStrategy"] = 0

            ...

        ...



class strategy_XYZ(myBaseStrategy):



    def add(self) -&gt; None:

        myBaseStrategy.add(self)

        ...```



*Tags: Strategies*

---

**Beginner** - *22:12:14*

I confess that I was a little confused when trying to automate my investments via `Betfairlightweight`, so my request for help is as simple as possible:



I have market id `1.201255552` and runner id `55270`, and I want to invest `210.00` in `Back`.



To login I already used:



```trading = betfairlightweight.APIClient(...)

trading.login()```

Now, to actually make the investment, how should I pass the arguments? As I understand it, I should use:



`betfairlightweight.endpoints.betting.place_orders()`



Could someone show me an example of how I should do it using this values?

I looked at the `flumine` examples on strategies but couldn't understand (*sorry for my lack of knowledge*).



I just really want to use an option to set the values and place the bet, I'm not generating a complex strategy or anything like that.

*Tags: Strategies*

---

## 2022-07-24

**mandelbot** - *05:29:31*

Thanks! But I actually use unique contexts per strategy already

*Tags: Strategies*

---

**Fab** - *07:53:00*

[@U03CZHR6HM0](@U03CZHR6HM0) Check this example out for placing bets: [https://github.com/betcode-org/betfair/blob/master/examples/exampletwo.py#L25|https://github.com/betcode-org/betfair/blob/master/examples/exampletwo.py#L25](https://github.com/betcode-org/betfair/blob/master/examples/exampletwo.py#L25|https://github.com/betcode-org/betfair/blob/master/examples/exampletwo.py#L25)

*Tags: General Technical*

---

**Gib** - *10:31:40*

hi, ive created a small app to record market data using streaming, however i have now decided to migrate to GCP on a linux box and having a few problems. ive set up my linux box, but i am getting an error logging in to betfair with logininteratice.py. im assuming this is in relation to firewall rules. can someone advise what ports i need to open? or point me to the right documentation so i can check?

*Tags: Errors Debugging*

---

**Gib** - *10:32:19*

Traceback (most recent call last):

  File "bflw_stream_v4.py", line 21, in &lt;module&gt;

    trading.login_interactive()

  File "/usr/local/lib/python3.8/dist-packages/betfairlightweight/endpoints/logininteractive.py", line 30, in __call__

    (response, response_json, elapsed_time) = self.request(

  File "/usr/local/lib/python3.8/dist-packages/betfairlightweight/endpoints/logininteractive.py", line 56, in request

    check_status_code(response)

  File "/usr/local/lib/python3.8/dist-packages/betfairlightweight/utils.py", line 34, in check_status_code

    raise StatusCodeError(response.status_code)

betfairlightweight.exceptions.StatusCodeError: Status code error: 403

*Tags: Errors Debugging, Strategies*

---

## 2022-07-26

**JFP** - *11:39:27*

Just wondering if someone could explain an issue I've been having with my automation over the past couple of weeks.

I turn my program on for the day via a text editor which contains my script, the python window pops up and I see all the races load up as normal. When I check in at end of day, I find that no bets have been placed, the dialog in the python window has not changed since I left it. When I hit enter, the python window dialog box is filled with a stream of high latency messages. It appears as though it somehow gets paused, has anyone experienced this?

Have been running the same program for months with no issues, but over the past 2 weeks this has happened 3 times. Am using Flumine 1.21.6.

*Tags: Performance*

---

**CL** - *15:52:04*

See eg here - [https://stackoverflow.com/questions/30418886/how-and-why-does-quickedit-mode-in-command-prompt-freeze-applications](https://stackoverflow.com/questions/30418886/how-and-why-does-quickedit-mode-in-command-prompt-freeze-applications). If you disable quick edit you should be fine. From memory Mo this happens if you launch via other means as it is a cmd.exe thing - if there is a visible process window then it can hang if you click in it.

*Tags: Performance*

---

**Newbie99** - *22:12:04*

This BET_TAKEN_OR_LAPSED issue has returned again (the full log won't help, its just a perpetual loop of Cancelling &amp; Executable):



```{"asctime": "2022-07-26 18:49:36,460", "levelname": "INFO", "message": "execute_cancel", "trading_function": "cancel", "elapsed_time": 0.0769505500793457, "response": {"customerRef": "b236ce8e0d1311ed95da02054918c7c6", "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.201257099", "instructionReports": [{"status": "FAILURE", "errorCode": "BET_TAKEN_OR_LAPSED", "instruction": {"betId": "275113850428"}}]}, "order_package": {"id": "b236ce8e-0d13-11ed-95da-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7fd0c9f06d10&gt;", "market_id": "1.201257099", "orders": ["138781504696928340"], "order_count": 1, "package_type": "Cancel", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}```

What does confuse me though, is that it says retry_count is 0 (and this always shows zero looking through), even though it attempts to cancel the order multiple times.



Appreciate this is a known issue, but I'm really struggling to come up with a stopgap solution as nothing I've tried works, does anyone have any sticking plaster suggestions for now?



Just in case anyone reading this hasn't seen this before, it occurs when Flumine tries to cancel an order that has already been matched, for some reason in some situations it gets stuck in an endless loop, trying to cancel the bet that no longer exists...but I can't figure out why. Even more strangely it seems to occur loads over a period and then stops for weeks or months on end!

*Tags: Errors Debugging, Strategies*

---

## 2022-07-27

**birchy** - *00:12:32*

I've not had this issue, so presumably your strategy repeatedly sees the order status as `EXECUTABLE` and then calls the cancel function in Flumine? If that's the case, then it seems logical that Flumine would need to handle `BET_TAKEN_OR_LAPSED` and update the order status to either `EXECUTION_COMPLETE` or flag it some other way. I'm assuming that this is actually an issue at Betfair's end and Flumine is simply relaying the received order status? If that's the case then all you can do is save the order id to market.context (or wherever) and ignore it in your cancellation call.

*Tags: Strategies*

---

**Newbie99** - *00:26:41*

It's a known issue: [https://github.com/betcode-org/flumine|https://github.com/betcode-org/flumine](https://github.com/betcode-org/flumine|https://github.com/betcode-org/flumine)



I was just hoping someone might have a workaround as I know a few others on here have experienced the same thing.



It's very odd how it comes and goes!

*Tags: General Technical*

---

**birchy** - *07:41:25*

So is it an issue with Flumine or the order stream from betfair not updating?

*Tags: General Technical*

---

**Newbie99** - *08:54:24*

Yes, in essence what happens is that in some situations, when Flumine sends a cancel request to Betfair and the order has already been completed on the exchange (e.g. most likely case is that it was matched a few milliseconds before the cancel request reached the exchange).



Flumine then correctly displays a BET_TAKEN_OR_LAPSED message, which makes sense and then for the most part thats the end of it....



But (seemingly randomly) every so often, it will get stuck in a perpetual loop where the status of the order never moves to EXECUTION_COMPLETE so flumine constantly tries to cancel an order that no longer exists.



The problem is, we've never been able to identify a sub-set of orders / scenarios where this occurs.



Initially I thought it could be when replacing an order, but I stopped using replace and it still happens...albeit its odd in the way it doesn't seem to happen for months, then just starts up again!

*Tags: General Technical*

---

**Alessio** - *09:20:18*

(a watchdog thread to mitigate the situation may also help though)

*Tags: General Technical*

---

**Newbie99** - *09:22:30*

No, as I can't figure out what specific conditions lead to this!



Somewhere, somehow it seems like Flumine misses a message and never recovers, but I can't prove that.



But the other confusing part is that it keeps retrying to cancel, but it always says retry_count = 0.



If this retry_count increased then presumably there is a way to limit retries and this could be a stop gap, but given the count remains at zero, not sure if this would work.

*Tags: General Technical*

---

**Alessio** - *09:34:16*

and when it starts looping you start seeing the same error of execute_cancel over and over, right?

*Tags: Errors Debugging*

---

**John Foley** - *10:00:03*

I found that no matter where I moved my server with GCP, I was still getting an IP address based in California. It seems to be a known thing:

[https://stackoverflow.com/questions/46205814/why-do-regional-google-cloud-ip-addresses-all-appear-to-be-in-the-us|https://stackoverflow.com/questions/46205814/why-do-regional-google-cloud-ip-addresses-all-appear-to-be-in-the-us](https://stackoverflow.com/questions/46205814/why-do-regional-google-cloud-ip-addresses-all-appear-to-be-in-the-us|https://stackoverflow.com/questions/46205814/why-do-regional-google-cloud-ip-addresses-all-appear-to-be-in-the-us)



I ended up buying a proxy in Dublin/UK and now route my requests through there instead

*Tags: Deployment*

---

**mandelbot** - *10:01:30*

Hey, I looked back at this a while back and it seemed like hacking process.py to below seems to have solved it for me. The addition is a check on size_remaining Give it a try?

```    if order.bet_id and order.status == OrderStatus.PENDING:

        if order.size_remaining == 0:

            order.execution_complete()

        elif order.current_order.status == "EXECUTABLE":

            order.executable()

        elif order.current_order.status in ["EXECUTION_COMPLETE", "EXPIRED"]:

            order.execution_complete()

    elif order.status == OrderStatus.EXECUTABLE:

        if order.current_order.status in ["EXECUTION_COMPLETE", "EXPIRED"]:

            order.execution_complete()```

*Tags: General Technical*

---

**Newbie99** - *10:22:18*

They only exist on the Flumine side

*Tags: General Technical*

---

**JFP** - *11:51:10*

Thanks [@U0174A50YKS](@U0174A50YKS), this should fix that issue.

*Tags: Errors Debugging*

---

**JFP** - *12:07:01*

[@UBS7QANF3](@UBS7QANF3) &amp; [@U016TGY3676](@U016TGY3676), is there a lot of changes required to get my windows Flumine scripts to run on Linux?

Originally planned to move to Linux and server, but once I got something up and running, have not put in the time to make the change.

*Tags: Deployment*

---

**Mo** - *12:08:14*

The Python code _should_ be runnable without any changes - I think the barrier is just getting familiar with the OS

*Tags: General Technical*

---

**JFP** - *12:12:48*

Thanks [@UBS7QANF3](@UBS7QANF3). When you mentioned something less clunky than using a text editor, what would be a better way to launch scripts? Apologises if these are basic questions, am not a developer, I just learn what I need to get the job done

*Tags: General Technical*

---

**Mo** - *12:13:40*

I guess I mean just run the Python script from the command line rather than an IDE

*Tags: General Technical*

---

**birchy** - *13:24:33*

[@UVB1RFEP5](@UVB1RFEP5) as [@UBS7QANF3](@UBS7QANF3) has said, understanding how Linux works is the biggest barrier but nowadays that's not a particularly steep learning curve. It would probably be worthwhile you playing around with Ubuntu by either installing on your machine as a dual boot or on an old pc/laptop/rasp pi. You can also boot most Linux's as a "live" image that runs off cd/dvd/usb stick without installing anything. They run as a full OS in ram but can be a bit slow as a result, however, it allows you to assess a Linux session without making any permanent changes. Alternatively, you could dive straight into an AWS Lightsail instance and learn how to administer it over SSH as that's what your end goal is. [@UQL0QDEKA](@UQL0QDEKA) has done this recently and said he found it much easier than expected and now has a handful of strategies running remotely.

*Tags: Getting Started, Performance, Deployment*

---

**PeterLe** - *13:31:09*

yea i decided to have a crack at Ubuntu as Lee mentioned it was a good way to go.

It was very easy to setup via Lightsail (I didn't know the first thing about Ubuntu Linux)

Python was vey easy to install too. (Run from the command line python3 file.py

I then moved four strategies and a couple of recorders over

I still dont know much about it, but it does what i need it to do, so 'good enough is good enough'! :grinning:

*Tags: Getting Started*

---

## 2022-07-28

**Michael** - *20:03:47*

Anyone got any advice on Certs? Mine from last year has expired, I've followed the XCA example to the letter on betfair but keep getting cert errors

*Tags: Errors Debugging*

---

**PeterLe** - *20:19:18*

There was a thread on here explaining an easy way to do this, but you probably wont be able to do a search on it now...

A lot of us newbies have problems with this...

If i remember correctly I followed this [http://www.betfairprotrader.co.uk/2015/08/creating-digital-certificate-for-betfair.html|http://www.betfairprotrader.co.uk/2015/08/creating-digital-certificate-for-betfair.html](http://www.betfairprotrader.co.uk/2015/08/creating-digital-certificate-for-betfair.html|http://www.betfairprotrader.co.uk/2015/08/creating-digital-certificate-for-betfair.html)

*Tags: General Technical*

---

**Michael** - *21:29:05*

Thanks, didn't know you could use it with Flumine

*Tags: General Technical*

---

**Brøndby IF** - *23:49:02*

Quick question guys, my server is in Ireland but I live in Brazil, so API access is in one country and my manual access is in another.

Is there any problem doing this?

*Tags: Deployment*

---

## 2022-07-29

**Gooat** - *00:00:35*

No problem

*Tags: General Technical*

---

**George** - *10:19:28*

When streaming market data I am getting a few messages saying "Latency high: [tel:06334546432|0.](tel:06334546432|0.)xxxx". They seem to come in a burst lasting a couple of milliseconds. Is that normal or is there something I could do to avoid it?

*Tags: Performance*

---

**mandelbot** - *13:24:31*

My strategies keep getting killed around the same time (10:23. Any idea why this might be the case?

```

[Fri Jul 22 10:23:45 2022] Out of memory: Killed process 23407 (python) total-vm:1645160kB, anon-rss:545988kB, file-rss:0kB, shmem-rss:0kB, UID:1000 pgtables:1588kB oom_score_adj:0

[Sat Jul 23 10:23:59 2022] Out of memory: Killed process 3568 (python) total-vm:1614732kB, anon-rss:584060kB, file-rss:0kB, shmem-rss:0kB, UID:1000 pgtables:1660kB oom_score_adj:0

[Fri Jul 29 10:23:44 2022] Out of memory: Killed process 28699 (python) total-vm:1633308kB, anon-rss:515668kB, file-rss:0kB, shmem-rss:0kB, UID:1000 pgtables:1524kB oom_score_adj:0```

*Tags: Performance*

---

**liam** - *14:23:45*

Out of memory, hard to debug without knowing what is running on the box or if it's the python process itself that has a leak, login at 10:20 and monitor will tell you straight away 

*Tags: Errors Debugging, Performance*

---

**George** - *15:36:46*

Thanks. I am in AWS Dublin. Could it really be crappy network?

*Tags: Deployment*

---

## 2022-07-31

**Alessio** - *15:03:58*

Btw, i just discovered one cool thing of python i didn't know: faulthandler

*Tags: General Technical*

---

**Alessio** - *15:04:15*

that may help you understand where things get stuck by dumping threads

*Tags: General Technical*

---

**Dave** - *19:11:53*

Anyone else seeing API errors?

*Tags: Errors Debugging*

---

**thambie1** - *19:14:13*

But still occasionally seeing API errors

*Tags: Errors Debugging*

---

**Dave** - *19:55:06*

Thanks guys, yeah seemed resolved fairly quickly.

*Tags: General Technical*

---

## 2022-08-06

**George** - *01:52:27*

Under some conditions, it doesn't seem to be possible to run a Flumine racing simulation with `SimulatedSportsDataMiddleware` across multiple markets.

The logic in the software appears to be as follows:

• `add_market` is called for race 1

• simulation begins to work normally taking in race 1 TPD data

• `add_market` is called for race 2

• simulation for race 1 continues abnormally, attempting to use race 2 TPD data

• race 1 finishes

• `remove_market` is called for race 1, but the TPD data was race 2 data, which is what is removed (the race 1 data was overwritten anyway)

• simulation for race 2 is attempted, but there is now no TPD data at all, so the code crashes

Now the question is - why would `add_market` be called for race 2, before race 1 has finished? I think this is occurring because I have `EX_MARKET_DEF` in my MarketRecorder script and, because the race status is SUSPENDED when these updates come around, they are not skipped. I'm not sure about this though, and in fact any update where the market is SUSPENDED would presumably cause this issue.



Tagging [@U4H19D1D2](@U4H19D1D2) as this appears to be a Flumine bug but I would rather be wrong and hoping it's just user error... please let me know either way!Thanks

*Tags: Errors Debugging*

---

**Mo** - *07:31:18*

This is a bit obscure but when backtesting using concurrent.futures i.e. multiprocessing I sometimes get a BrokenProcessPool because one of the worker processes has a segmentation fault. Using [https://docs.python.org/3/library/faulthandler.html|faulthandler](https://docs.python.org/3/library/faulthandler.html|faulthandler), the stack trace shows me the segmentation fault occurs when using betfairlightweight to read the prices file on [https://github.com/betcode-org/betfair/blob/master/betfairlightweight/streaming/cache.py#L83|this line in cache.py](https://github.com/betcode-org/betfair/blob/master/betfairlightweight/streaming/cache.py#L83|this line in cache.py):



```class Available:

...

    def serialise(self) -&gt; None:

-&gt;      self.serialised = [book[-1] for book in self.order_book.values()]```

Usually I can just restart the backtest and then everything works fine. In fact, it usually happens once or twice after booting and after that I can run as many backtests as I like without error. Anyone experienced anything similar?

*Tags: Errors Debugging*

---

**liam** - *07:43:16*

Never seen this, particular Python/os specific issue?

*Tags: General Technical*

---

**George** - *15:27:39*

Hi [@U4H19D1D2](@U4H19D1D2) here is the code I'm using:

```import smart_open

from mock import patch

from flumine import FlumineSimulation, clients, config

from flumine.markets.middleware import SimulatedSportsDataMiddleware

from flumine.strategy.strategy import BaseStrategy



if __name__ == '__main__':

    client = clients.SimulatedClient()

    framework = FlumineSimulation(client=client)

    sports_data_path = '/sports/data/path/'

    markets = ['/path/to/file/1.201463615.gz', '/path/to/file/1.201463621.gz']

    strategy = BaseStrategy(market_filter= {'markets': markets, 'listener_kwargs': {'seconds_to_start': 60, '    calculate_market_tv':False, 'cumulative_runner_tv':False}, 'event_processing': True})

    with patch('builtins.open', smart_open.open):

        framework.add_market_middleware(SimulatedSportsDataMiddleware('raceSubscription', sports_data_path))

        framework.add_strategy(strategy)

        with patch.object(config, 'raise_errors', True):

            framework.run()```

*Tags: Errors Debugging, Strategies*

---

**George** - *15:32:48*

I can upload the two Exchange market data files and the two TPD data files if it helps

*Tags: General Technical*

---

**George** - *15:45:03*

Clearer formatted code:

```import smart_open

from mock import patch

from flumine import FlumineSimulation, clients, config

from flumine.markets.middleware import SimulatedSportsDataMiddleware

from flumine.strategy.strategy import BaseStrategy



if __name__ == '__main__':

	client = clients.SimulatedClient()

 	framework = FlumineSimulation(client=client)

	markets = ['/path/to/file/1.201463615.gz', '/path/to/file/1.201463621.gz']

	strategy = BaseStrategy(market_filter= {'markets': markets, 'listener_kwargs': {'seconds_to_start': 60, '    calculate_market_tv':False, 'cumulative_runner_tv':False}, 'event_processing': True})

	with patch('builtins.open', smart_open.open):

 		framework.add_market_middleware(SimulatedSportsDataMiddleware('raceSubscription', '/sports/data/path'))

 		framework.add_strategy(strategy)

 		with patch.object(config, 'raise_errors', True):

 			framework.run()```

*Tags: Errors Debugging, Strategies*

---

**George** - *17:06:47*

OK, I'll try turning it off and see what happens. However, even if that fixes everything, I'd still be interested to see if there is an underlying issue as it seems odd that turning on event processing should completely break the simulation

*Tags: Errors Debugging*

---

**liam** - *17:09:24*

Agreed, I will fix regardless 

*Tags: Errors Debugging*

---

## 2022-08-07

**Beginner** - *17:14:35*

Guys, a question about API response if you can help because the link on the documentation page is broken:

Let's assume that the market opened now and two different people put money on the Back at odds 2.00



Person 1: 100 dollars

Person 2: 200 dollars



And someone comes to the market and buys in Lay these values.



Is there any API response that we were able to get the information from these specific matches instead of getting the total value matched from the market?



Example:



A response that shows the information that $100 was matched and $200 was matched, but separate and in the sequence in which they were matched.



I'm trying to generate a real-time chart with the chronology of values matched in the market.



On the `listRunnerBook` page ([https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/listRunnerBook](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/listRunnerBook)) I even tried to analyze the `matchProjection` to understand, but the link is broken, when I click it takes me to a non-existent page.

*Tags: General Technical*

---

**Peter** - *17:28:54*

Betfair works on 50ms cycles. So if you're streaming and something happened during the past 50ms, you'll get an update that contains the amounts matched from the market opening up to the latest cycle. So you can compare the changes in the amounts matched and the last price traded gives some clues as to which side of the spread the match may have occurred, but If two or more matches occurred in the last cycle, they'll be aggregated.

*Tags: General Technical*

---

## 2022-08-08

**liam** - *08:51:05*

I get no issues with event_processing off I assume you don't either? Simulating this data is tricky and I have tried to abstract it as much as possible however if you look at the [https://github.com/betcode-org/flumine/blob/fd527626accbddd7782477f420855f57e928dae9/flumine/simulation/simulation.py#L50|code](https://github.com/betcode-org/flumine/blob/fd527626accbddd7782477f420855f57e928dae9/flumine/simulation/simulation.py#L50|code) you can see why event_processing isn't going to work.

*Tags: General Technical*

---

**George** - *09:49:55*

Maybe you don't. I'm not sure. What I am thinking is this.

Let's say the TPD data has just picked up that Horse 1 has started to accelerate. So we want to back him on both the Win and the Place. Maybe the most efficient way to do that is to use a strategy with event processing and send an order to both markets from the same strategy.

*Tags: Strategies*

---

**George** - *09:53:56*

i can see how this might not be the top item on your to-do list, but if event_processing breaks the TPD simulation then could we at least have a FlumineError to tell us not to use event_processing with inplay simulation :slightly_smiling_face:

*Tags: Errors Debugging*

---

**liam** - *09:58:12*

live no problem, the issue is when simulating

*Tags: Deployment*

---

**liam** - *10:00:16*

event processing basically creates an ordered list (by PT) of marketBook's we then cycle through them, if you wanted TPD data to work as well you would need to do the same and then cycle through as well, I foresee all sorts of problems when it comes to delayed races / updates before a race has finished etc.



it's certainly possible but not worth it imho, I personally simulate marketTypes separately

*Tags: General Technical*

---

**liam** - *10:01:11*

regarding the error, not sure how we can get the stream filter talking to the middleware to raise the error

*Tags: Errors Debugging*

---

**George** - *10:02:31*

To fix event processing couldn't we just check whether the event details of the market book update matches the event details of the event that we are trying to simulate?

*Tags: Errors Debugging*

---

**liam** - *10:03:41*

although that is a symptom you are seeing, its not the problem

*Tags: General Technical*

---

**George** - *10:10:16*

Of course I've been looking at Flumine for a month but only wasted one day debugging this issue thankfully

*Tags: Errors Debugging*

---

**George** - *17:45:29*

Sorry [@U4H19D1D2](@U4H19D1D2) I'm having a lot more issues related to this. I would like to trigger off the TPD data and send an order.

To send the order at the right price and for the right size, I want to know what is the latest market book that the strategy has received.

I tried to set `process_market_book` to save the most recent market book as `self.current_market_book`, but it didn't work, because I'm seeing that the `self.current_market_book.market_id` is a different market ID to the `sports_data.market_id` .



I noticed that, in the cricket example in the repo, the strategy sends an order to BACK at 1.01 ...

*Tags: Strategies*

---

## 2022-08-09

**George** - *11:11:16*

if I wanted to simulate an inplay strategy on the place market, how would I do that, because the TPD files are named with the win-market's market ID...

*Tags: Strategies*

---

**Unknown** - *17:46:48*

Hi [@U9JHLMZB4](@U9JHLMZB4) if possible, help me understand:



At odds 1.34 we have 104.75 traded volume



I understand that in this case the total liability used on Back would be $78.17 and on Lay $26.58



Is that not correct?

*Tags: General Technical*

---

**Beginner** - *20:11:25*

[@U9JHLMZB4](@U9JHLMZB4) Thanks a lot for the explanation. So the total amount that is shown in the market is not the total amount traded, but only the total amount traded in Back.



Because the total value of the sum of the liability of Back and Lay would be 140.37 (104.75 + 35.62).



Am I correct?



(forgive me if I'm asking too many questions)

*Tags: General Technical*

---

## 2022-08-10

**Peter** - *09:51:14*

[@U03CZHR6HM0](@U03CZHR6HM0) Don't worry about asking questions. If it's confusing you, then it's probably confusing other people too.



I think that the root of your confusion is that you're conflating the amount traded (matched) with liability. But they're not the same thing. Although the backer's liability is always going to be the stake. The layer's liability will depend on the odds and will usually be greater (often substantially greater) than the stake. So the amount matched that Betfair reports is, in a simplified world with one backer and one layer, simply the stake the backer wanted and the layer agreed to take on.

*Tags: General Technical*

---

## 2022-08-12

**Johnny Boston** - *05:08:19*

Hey - I am trying to record the `last price traded` for a runner before the market goes in play.



The way I am doing this is by recording all the Market iterations to a csv and then when *`process_closed_market`* is called in my recording strategy, I find the last publish time from the csv. Problem is this is showing some very strange figures, with `last price traded` wildly different to `bsp`  so I am definitely doing something wrong.



Is there an easier way to do this after a market has closed? to find the `last_traded_price` before market goes in play? or do I just need to find a better solution to my problem ?

*Tags: Strategies*

---

**birchy** - *07:45:25*

It says `not` inplay. I presume you are using Flumine? That example is over simplified but in essence, you have to save it preplay because it doesn't exist after.

Alternatively, if you're saving the updates to your CSV, the LTP you want is the last one _before_ inplay==True.

*Tags: General Technical*

---

**Johnny Boston** - *07:51:12*

Yes, I'm using flumine and this is what I'm doing. Still getting strange figures

*Tags: General Technical*

---

**Evaldas** - *09:09:10*

So, I'm logging order placement latency with `order.responses.date_time_placed - order.date_time_created` For place orders this is as expected around 200ms, but replace orders are always less than 1ms, which is obviously not correct. What I'm doing wrong?

*Tags: Performance*

---

**Mo** - *09:12:29*

If he's really a friend you wouldn't let him access the Betfair API using R

*Tags: General Technical*

---

**liam** - *09:33:42*

Nothing, bug in how we created replacement orders, fix [https://github.com/betcode-org/flumine/pull/605|here](https://github.com/betcode-org/flumine/pull/605|here)

*Tags: Errors Debugging*

---

## 2022-08-16

**Ruben** - *15:04:56*

when backtesting a strategy and then printing orders placed, I am seeing orders with values of `elapsed_seconds_executable`  on the order of 10, 20, 30 and higher. However in the strategy I have the following code for `process_orders`, that shouldnt allow orders to exist for more than 2 seconds, what am I missing?

```    def process_orders(self, market, orders):

        for order in orders:

            if order.status == OrderStatus.EXECUTABLE:

                if order.elapsed_seconds and order.elapsed_seconds &gt; 2:

                    market.cancel_order(order)```

*Tags: Strategies*

---

## 2022-08-19

**EJono** - *16:10:16*

im not sure why but for some reason im no longer seeing any markets in flumine.markets when i execute framework.run() anymore. This is the strategy set up i have been using that has been bringing through football succesfuly for the past few months now. Any idea why all of a sudden no markets are coming through on the stream? Last time i succesfully saw things working as they should be was wednesday last week.

```strategy = Strategy(

    max_order_exposure=5,

    max_live_trade_count=5,

    max_selection_exposure=5,

    market_filter=streaming_market_filter(

        event_type_ids=["1"],

        country_codes=country_codes,

        market_types=["MATCH_ODDS"],

    ),

    name=STRAT_NAME,

    context={

        'max_liability': LIABILITY

    }

)```

Im using

```flumine==2.2.3

betfairlightweight==2.16.6```



*Tags: Deployment, Strategies*

---

**Newbie99** - *16:43:52*

Just one thought, but looking quickly it seems that there are over 1000 MATCH_ODDS markets, so unless you have unlimited markets per connection it would generate an error.



The only way to get around this (apart from asking nicely if you can get your limit increased, which may or may not happen) is to split things up by country so not all MATCH_ODDS markets are on one connection.

*Tags: Errors Debugging*

---

## 2022-08-22

**mandelbot** - *08:57:55*

I'm trying to run multiprocessing on backtests for the first time (I know right?) and i keep getting the following error:



```TypeError: don't know how to handle uri Ellipsis```



```concurrent.futures.process._RemoteTraceback: 

"""

Traceback (most recent call last):

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py", line 246, in _process_worker

    r = call_item.fn(*call_item.args, **call_item.kwargs)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/strategy/testmulti.py", line 41, in run_process

    framework.add_strategy(strategy)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/baseflumine.py", line 101, in add_strategy

    self.streams(strategy)  # create required streams

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/streams/streams.py", line 46, in __call__

    market_type = get_file_md(market, "marketType")

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/utils.py", line 66, in get_file_md

    with open(file_dir, "r") as f:

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/smart_open/smart_open_lib.py", line 224, in open

    binary = _open_binary_stream(uri, binary_mode, transport_params)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/smart_open/smart_open_lib.py", line 396, in _open_binary_stream

    raise TypeError("don't know how to handle uri %s" % repr(uri))

TypeError: don't know how to handle uri Ellipsis

"""



The above exception was the direct cause of the following exception:



Traceback (most recent call last):

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/strategy/testmulti.py", line 63, in &lt;module&gt;

    job.result()  # wait for result

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 439, in result

    return self.__get_result()

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result

    raise self._exception

TypeError: don't know how to handle uri Ellipsis```

Can't figure it out, anyone have any ideas?

*Tags: Getting Started, Errors Debugging, Strategies*

---

**Mo** - *08:58:57*

Looks like a problem in your code. Can you share it?

*Tags: General Technical*

---

**mandelbot** - *09:03:07*

Sure, I'm mostly just following the examples

```import os

import math

import smart_open

from smart_open import open as so

from concurrent import futures

from unittest.mock import patch as mock_patch

from flumine import FlumineSimulation, clients, utils

from flumine.examples.lowestlayer import LowestLayer



markets = []



path = "/Volumes/BF/Befairlightweight Data/test"





for r, d, f in os.walk(path):

    for file in f:

        markets.append(os.path.join(r, file))





def run_process(markets):

    client = clients.SimulatedClient()

    framework = FlumineSimulation(client=client)

    strategy = LowestLayer(

        market_filter={"markets": markets},

        context={"stake": 2},

    )

    with mock_patch("builtins.open", smart_open.open):

        framework.add_strategy(strategy)

        framework.run()





if __name__ == "__main__":

    all_markets = [...]

    processes = os.cpu_count()

    markets_per_process = 8  # optimal



    _process_jobs = []

    with futures.ProcessPoolExecutor(max_workers=processes) as p:

        chunk = min(

            markets_per_process, math.ceil(len(all_markets) / processes)

        )

        for m in (utils.chunks(all_markets, chunk)):

            _process_jobs.append(

                p.submit(

                    run_process,

                    markets=m,

                )

            )

        for job in futures.as_completed(_process_jobs):

            job.result()  # wait for result```

*Tags: Strategies*

---

**liam** - *09:11:39*

cryptic error as its not obvious that `...` is referred to an Ellipsis, that example is just left as `...` to make it simple

*Tags: Errors Debugging*

---

**liam** - *09:16:25*

haha...



```"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result

    raise self._exception

TypeError: don't know how to handle uri "PUT_YOUR_MARKET_IDS_HERE"```

*Tags: Errors Debugging*

---

## 2022-08-25

**Jimmy** - *14:22:20*

hi all – logging is on and running but it would be helpful if a new log was created daily. i’m certain i’ve seen this discussed before but can’t find it via the search (apologies). can anyone point me in the right direction please?

*Tags: General Technical*

---

**Beeblebrox** - *14:27:06*

[https://docs.python.org/3/library/logging.handlers.html#logging.handlers.TimedRotatingFileHandler](https://docs.python.org/3/library/logging.handlers.html#logging.handlers.TimedRotatingFileHandler)

*Tags: General Technical*

---

**Johnny Boston** - *23:44:17*

Does Flumine instantiate a new connection per strategy or does it identify if multiple strategies have similar filters and only use one connection per Flumine instance?



I am reaching my max active connections even though I have only 4 instances of Flumine running...

*Tags: Strategies*

---

## 2022-08-26

**Peter** - *08:26:42*

Each instance of Flumine will normally instantiate two connections: one for market books and the other for orders.



Closing Flumine will not normally close your connections immediately. I believe that what happens is that the connection is closed from the Betfair end when the buffer fills up and Betfair realises that you're no longer pulling data from it. But if there's not much going into the stream that can take some time.

*Tags: General Technical*

---

**Johnny Boston** - *08:29:05*

Thank you [@U9JHLMZB4](@U9JHLMZB4). Seems as though I'm in between a rock and a hard place then! I'll reach out to betfair. Would be great if they had an endpoint to query your active connection ids and close down the ones you no longer need. I should have 4 live ones but due to code deployments it looks like I have over 20!

*Tags: Deployment*

---

**liam** - *09:01:42*

What do you mean code deployments? They never last that long once you stop reading off them

*Tags: Deployment*

---

**liam** - *09:07:51*

pipe to aws cloudwatch and forgot about it till you need them

*Tags: Deployment*

---

**Johnny Boston** - *09:12:40*

I have containers running on ECS. When I deploy a new strategy, I pull down the container and start a new one. That's what I call a deployment.

*Tags: Deployment, Strategies*

---

**liam** - *09:16:50*

As peter has mentioned that will use at least 2 connections, its worth noting that flumine will share 'streams' if two strategies are running on the same instance using the same market filter

*Tags: General Technical*

---

**Johnny Boston** - *09:18:20*

Yeah, so it looks like I have open connections then. I found latency issues when I had multiple strategies (more than 5) in the same container.



I then split them up and that went away. The latency was mainly due to custom streams that were getting model odds on short intervals.

*Tags: Performance, Strategies*

---

**liam** - *09:19:43*

Looks like you need to profile your code, streams run in their own thread so wouldnt cause latency issues in the main thread unless they where very heavy

*Tags: Performance*

---

**Newbie99** - *11:18:28*

Actually this thread made me think, can I just check my understanding is correct?



Lets say I have 2 Horse Racing strategies strategy A &amp; Strategy B.



All streaming filters are identical, except as follows:



Strategy A:

countries ['GB', 'IE', 'AU', 'US']

market_types ['WIN', 'PLACE']



Strategy B:

countries ['GB', 'IE']

market_types ['PLACE']



Am I correct in saying, that although the markets are a subset of strategy A for strategy B this would create a new connection as the streaming filters are not a perfect match (I presume the logic looks at whether the exact filter is used again)?



So from a connection efficiency perspective, using the above example, the best course of action would be to use the streaming filters as per Strategy A and then filter within the strategy to only look at the relevant markets?

*Tags: Strategies*

---

**liam** - *11:21:01*

use strategy A market filter and add logic to `check_market_book` for strategy B, you can see in the logs if a new stream is created or not

*Tags: Strategies*

---

**liam** - *11:21:38*

logic [https://github.com/betcode-org/flumine/blob/e21cbebed9003cbc20ae46c8c756c4a0bd182076/flumine/streams/streams.py#L89|here](https://github.com/betcode-org/flumine/blob/e21cbebed9003cbc20ae46c8c756c4a0bd182076/flumine/streams/streams.py#L89|here)

*Tags: General Technical*

---

## 2022-08-28

**Alan Patterson** - *12:50:31*

I'm testing streaming historical data using betfairlightweight. I can't get smart_open to work to open the bz2 files.

If I unzip the files it works fine.

I am importing in my python script before doing anything, so I think the imported open should override the built in, but it is not working.

Any help on using smart_open when reading the historical bz2 files?



```from smart_open import open



import betfairlightweight

from betfairlightweight import StreamListener



...```

*Tags: Data Quality*

---

## 2022-08-30

**Evaldas** - *21:17:18*

[https://github.com/betcode-org/flumine/blob/master/flumine/strategy/strategy.py#L154](https://github.com/betcode-org/flumine/blob/master/flumine/strategy/strategy.py#L154)

Is this some new way to format string in Python? :)

*Tags: Strategies*

---

**Peter** - *21:38:12*

No. It's an older approach carried forward from python 2.  [https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting) and [https://docs.python.org/2/library/stdtypes.html#string-formatting-operations](https://docs.python.org/2/library/stdtypes.html#string-formatting-operations).

*Tags: General Technical*

---

**Evaldas** - *22:00:25*

Yeaa, there is way to many ways to format strings in python... 

That line and few bellow in flumine doesn't work. Should be "{0}".format(smth) not "(%s)".format(smth)

*Tags: General Technical*

---

## 2022-09-01

**AP** - *11:34:28*

Hi! I created an example strategy just to test some features of flumine but I'm struggling with a problem

```class ExampleStrategy(BaseStrategy):

    def start(self) -&gt; None:

        print("starting strategy 'ExampleStrategy'")



    def check_market_book(self, market: Market, market_book: MarketBook) -&gt; bool:

        return (market_book.status == "OPEN") and (not market_book.inplay)



    def process_market_book(self, market: Market, market_book: MarketBook) -&gt; None:

        for i in range(len(market_book.runners)):

            runner = market_book.runners[i]



            LPT = runner.last_price_traded



            if runner.status == "ACTIVE" and (LPT is not None):

                if LPT &lt; 2:

                    trade = Trade(

                        market_id=market_book.market_id,

                        selection_id=runner.selection_id,

                        handicap=runner.handicap,

                        strategy=self

                    )

                    order = trade.create_order(

                        side="BACK",

                        order_type=LimitOrder(price=LPT, size=2.00)

                    )



                    res = market.place_order(order)



                    if res:

                        print("Order placed: ", market_book.market_id, runner.selection_id, LPT)



    def process_orders(self, market: Market, orders: list) -&gt; None:

        if not((market.market_book.status == "OPEN") and (not market.market_book.inplay)):

            return



        for order in orders:

            if order.status == OrderStatus.EXECUTABLE:

                if order.size_remaining == 2.00:

                    market.cancel_order(order, 0.02)  # reduce size to 1.98



                if order.order_type.persistence_type == "LAPSE":

                    market.update_order(order, "PERSIST")



                if order.size_remaining &gt; 0:

                    market.replace_order(order, new_price=1.02)```

I had run this strategy on a specific market, but then the following error was raised:

```Traceback (most recent call last):

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulation.py", line 97, in run

    self._process_market_books(

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulation.py", line 117, in _process_market_books

    self._check_pending_packages(market_id)

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulation.py", line 189, in _check_pending_packages

    order_package.client.execution.handler(order_package)

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/execution/simulatedexecution.py", line 31, in handler

    func(order_package, http_session=None)

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/execution/simulatedexecution.py", line 142, in execute_replace

    place_instruction_report = replacement_order.simulated.place(

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulatedorder.py", line 70, in place

    return self._create_place_response(

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulatedorder.py", line 181, in _create_place_response

    if self.size_remaining == 0:

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulatedorder.py", line 395, in size_remaining

    size

TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'```

It seems that the execution is broken while the framework is trying to replace an order: first it tries to cancel the order, but then it discovers that the market.status is not OPEN and raise the error with

```return SimulatedCancelResponse(

                status="FAILURE",

                error_code="ERROR_IN_ORDER",

            )```

in flumine/simulation/simulatedorder.py, line 194. I don't understand why it is happening, because the check_market_book functions should already have checked that the market is OPEN. Also, in this specific case, the market is SUSPENDED before the race, Idk if it is an useful information. Can somebody help me with it?

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

**AP** - *13:15:07*

where can I add it in the strategy? Also, the problem is that the None shouldn't be present, as it is raised because the SUSPENDED status of the market was detected, or am I wrong?

*Tags: Strategies*

---

**AP** - *14:18:58*

I updated the code above, but I still get the same error

*Tags: Errors Debugging*

---

**AP** - *14:20:13*

the points 1,2,3 are correct, from what I explored, but the extra filter doesn't fix the problem

*Tags: Errors Debugging*

---

**AP** - *14:36:45*

on my side I was testing to substitute lines 194-197 in flumine.simulation.simulatedorder.py with

```return SimulatedCancelResponse(

                status="FAILURE",

                size_cancelled=0,

                error_code="ERROR_IN_ORDER",

            )```

and also changing line 389 (for example inverting the 2 arguments of the "or" operation worked, because (0 or None) != (None or 0))

*Tags: Errors Debugging*

---

## 2022-09-04

**sartux** - *07:54:03*

Good morning guys,

to make the account report I have always used the "get_account_statement" method and it has always worked.



```

dateStart = datetime.datetime(2022, 8,30,0,0)

acct_statement_date_filter = betfairlightweight.filters.time_range(from_=dateStart)



account_statement = trading.account.get_account_statement(item_date_range=acct_statement_date_filter)```

Since this morning instead I get this error



```TypeError: __init__() missing 1 required positional argument: 'fullMarketName'



   raise InvalidResponse(response=result)

betfairlightweight.exceptions.InvalidResponse: Invalid response received: {'accountStatement': [{'refId': '51365225816', 'itemD... ```

the script was working for 7 days without any problem

*Tags: Errors Debugging, Strategies*

---

## 2022-09-05

**sartux** - *09:18:34*

from the documentation on betfair you can retrieve up to 90 days previous, instead by launching

```account_statement = trading.account.get_account_statement(lightweight=True)```



I get at most up to 2 previous days, how come?

*Tags: Strategies*

---

**sartux** - *09:29:39*

the problem is that I don't see a pagination in the method, should I go back to the last id and subtract 100?

*Tags: General Technical*

---

## 2022-09-06

**Unknown** - *16:38:33*

here is one of the files showing this error

*Tags: Errors Debugging*

---

**Mona** - *17:27:58*

Hello guys, I am new to here.

I am working on some historical data for a particular market when events are inplay and trying to get the latest traded price time series. Has anyone have any experience with the Rust library they used on the tutorial? I have got to the point where all prices return within the Market.runner object is None, I am trying to understand whether it is the package problem or whether it is my understanding of the historical data structure that I need to do some modification?

Also the package is said to work with betfairlightweight as some of the functions can return MarketBook object, but I can't access its MarketBook._data attribute.

Thanks very much for help

*Tags: Getting Started, Data Quality*

---

**Mo** - *17:47:22*

You might have better luck here if you start just by using betfairlightweight

*Tags: General Technical*

---

**Mona** - *18:02:34*

yea betfairlightweight was initially my first option, though there is 2 years of data that I wanted to read in one .tar file, which takes a long time...

*Tags: General Technical*

---

**Mona** - *18:10:55*

is there a fast way to read and parse a .tar file and put them data into pandas DataFrame using betfairlightweight?

*Tags: Feature Engineering*

---

**Mo** - *18:54:05*

That could be a problem, I've only tested betfairutil on PRO data

*Tags: General Technical*

---

## 2022-09-07

**liam** - *09:02:42*

god I hate replaceOrders, its this [https://github.com/betcode-org/flumine/blob/4a3767e5083b6e1eb3cea59d7fba5ef26faf28a0/flumine/execution/simulatedexecution.py#L125|line](https://github.com/betcode-org/flumine/blob/4a3767e5083b6e1eb3cea59d7fba5ef26faf28a0/flumine/execution/simulatedexecution.py#L125|line) due to a replace occurring during market suspension

*Tags: General Technical*

---

**AP** - *10:00:23*

Thanks Liam, is it something that you think it's worth the effort in fixing or it's not a big deal?

*Tags: Errors Debugging*

---

**liam** - *10:22:24*

yeah it needs to be fixed, just need to work out how it should be handled correctly, can you copy all of this into an issue?

*Tags: Errors Debugging*

---

**Aaron Smith** - *13:26:14*

Latency issues:

My code has been running unchanged for a few months now. I do get an occasional latency warning (maybe like 1 or 2 a week), but thats it. One day to the other i suddenly get a bunch of latency warnings, (30+ a day) with unchanged code.

I know i should probably profile my code, and while that may help, it seems like something else is going on on top. Therefore i wanted to ask you guys:

• What are possible reasons for latency issues? (this would somewhat boil down to slow code or bad connection i guess, but especially for the latter i wonder if there are reasons for this to suddenly pop up.

• How to resolve them? 

*Tags: Performance*

---

**Aaron Smith** - *13:33:31*

CPU usage is generally below 10%. For network i dont really know how to interpret the numbers

*Tags: General Technical*

---

**liam** - *13:33:49*

and during the latency issues where was the CPU?

*Tags: Performance*

---

**liam** - *13:36:43*

which latency warning?

*Tags: Performance*

---

**liam** - *13:39:22*

without seeing your code its very tricky to debug

*Tags: Errors Debugging*

---

**Aaron Smith** - *13:41:48*

but can the code really be the problem here? i m sure there is a lot of room for improvement, but the same code has ran fine for months

*Tags: General Technical*

---

**Mo** - *13:51:44*

What's the latency warning based on? Local clock versus publish time? If so it could be your clock drifted/got synchronised to a source different enough from Betfair to start triggering the warnings

*Tags: Performance*

---

**Aaron Smith** - *13:55:30*

I use flumine, which i think compares local clock versus publish time. Its a linux ec2-instance that its running on (as if i recall correctly windows has a less precise local time?). This could be possible, how would i go about confirming/rejecting this thesis?

*Tags: Deployment*

---

**Unknown** - *16:02:24*

Hello everyone,



I'm facing a little problem with get_account_statement method.



As you can see from the attached screenshot, I'm requesting a specific timedate interval, but anyway I'm receiving much more data. Am I doing something wrong? :D

*Tags: General Technical*

---

**Unknown** - *20:28:08*

this is an example, when I use `betfairutil.read_prices_file` , the market_books objects returned are complete and have no problem at all.



however if I do the following using `bz2.open` and pass the `bz2` file object to `create_historical_generator_stream` function, there is only two `market_books`  returned.



```with tarfile.open(file) as archive:

     for file in archive:

         yield bz2.open(archive.extractfile(file))```

*Tags: General Technical*

---

## 2022-09-08

**Dario Scardina** - *08:40:24*

Morning everyone. I still facing problems with timeranges. Probably I'm missing something.

In order to get approx. soccer second half time matches I wrote:



```market_filter = betfairlightweight.filters.market_filter(

    event_ids=[event.event.id for event in events],

    market_type_codes=TARGET_MARKET_TYPE,

    in_play_only=True,

    turn_in_play_enabled=True,

    market_start_time={

        'from': (datetime.datetime.utcnow() - datetime.timedelta(minutes=120)).strftime("%Y-%m-%dT%TZ"),

        'to': (datetime.datetime.utcnow() - datetime.timedelta(minutes=60)).strftime("%Y-%m-%dT%TZ")

    }

)```

For 95% of times it works fine: I get exactly matches that are currently in the second half. But sometimes I get matches that are just started (e.g. 5'-10').

I'm doing it wrong or I have to consider I don't know something like Time Zones in my code? Are matches aligned with different time zones in Betfair? I hope is a clear question :smile:



Thanks.

*Tags: General Technical*

---

**Mo** - *08:43:22*

All times in the API are UTC so timezones shouldn't be a problem

*Tags: General Technical*

---

**liam** - *09:01:11*

Should now be fixed in v2.2.6

*Tags: Errors Debugging*

---

**Mo** - *09:08:21*

If you have something logging timestamps, you could look for a jump around the time the latency errors started. For example, if you log something that is typically around 100 milliseconds between messages and then you see a much larger gap and then a return to 100 milliseconds this might be evidence for this

*Tags: Errors Debugging, Performance*

---

**foxwood** - *09:45:41*

Because utc is used I got in a muddle even when the clocks changed in UK since couldn't match to other data. These two functions helped me and give an adjusted time of a utc date in venue terms (eg AUS) or in your PC's local time (depending on timezone PC is set to) ...

```def dateAsVenueTimezone(self, market, dt):

    # dates are in naive utc form - transform date into aware form for venue timezone

    tz = zoneinfo.ZoneInfo(market.market_book.market_definition.timezone)

    tzdt = dt + tz.utcoffset(dt)

    return dt.combine(tzdt.date(), tzdt.time(), tz)



def dateAsLocalTimezone(self, market, dt):

    # transform a naive utc date to the venue timezone and then to the local timezone

    return self.dateAsVenueTimezone(market,dt).astimezone(datetime.datetime.now().tzinfo)```



*Tags: General Technical*

---

**Alessio** - *09:56:05*

I mean, it's simple: BF put the wrong time, this may happen for a multitude of reasons (match delayed, human error, etc..)

*Tags: Errors Debugging*

---

**Dario Scardina** - *09:59:05*

[@UBS7QANF3](@UBS7QANF3) [@U01C12ZEADQ](@U01C12ZEADQ) Datetime is the nightmare of developers... I hope in your kindness looking for help :smile:

*Tags: General Technical*

---

**Dario Scardina** - *13:33:55*

*Solved*: from Betfair documentation

*Tags: General Technical*

---

**Aaron Smith** - *16:43:34*

checking through my latency warnings i see that 98% of them are this version:

```"WARNING", "message": "High latency between current time and OrderPackage creation time, it is likely that the thread pool is currently exhausted", "trading_function": "cancel", "session": "&lt;requests.sessions.Session object at 0x7f02236a0b20&gt;", "latency": 0.102, "order_package": {"id": "3f6818d6-2f8b-11ed-969e-257a4444e788", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f028fd7ba30&gt;", "market_id": "1.203111349", "orders": ["138819438430078669"], "order_count": 1, "package_type": "Cancel", "customer_strategy_ref": "prod_GH", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}, "thread_pool": {"num_threads": 25, "work_queue_size": 2}```

I get these on cancel and place. `work_queue_size` can be higher (last one it was at 19, this time 2 was highest for this chunk of latency errors (they generally come in chunks). What i m surprised by is `"num_threads": 25` , i can not really see why i would have 25 threads running?

*Tags: Errors Debugging, Performance, Strategies*

---

## 2022-09-09

**Mo** - *06:58:04*

OK so there's a problem to resolve around how you process the `tar` file but is that branch useful as far as generating a data frame which contains the LPT?

*Tags: General Technical*

---

**Jimmy** - *10:23:15*

Hi all — seeing the odd “Connection closed by server” error in my logs. Can’t find much around why it might occur online — anyone any tips/suggestions? :slightly_smiling_face:

*Tags: Errors Debugging, Deployment*

---

**rob smith** - *10:31:34*

Hi guys, I am trying to get Asian Handicap lines for specific events. I'm in the midst of newborn sleep deprivation but swear this filter was working a couple of weeks ago. Now it doesn't return a catalogue. Any help would be appreciated. Thanks

```# Get AH markets

market_catalogue_filter = betfairlightweight.filters.market_filter(event_ids=[31728932], market_type_codes=['ASIAN_HANDICAP_DOUBLE_LINE'])

print(market_catalogue_filter)



market_catalogues = trading.betting.list_market_catalogue(

    filter=market_catalogue_filter,

    max_results='100',

    sort='FIRST_TO_START',

    market_projection=["RUNNER_DESCRIPTION"]

)

print(market_catalogues)```



*Tags: Strategies*

---

## 2022-09-15

**Aaron Smith** - *09:42:00*

Hey ppl,

I am currently implementing the transaction class for placing orders (instead of market.place_order).

After the change, during simulation i get a lot of these errors:

`"Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failed: reset_elapsed_seconds (-0.188) &lt; reset_seconds (0.0)"`

Anyone have a clue on how that negative number comes to be?

*Tags: Errors Debugging, Strategies*

---

**Aaron Smith** - *09:45:00*

which part of the code? its a strategy and then put into flumine simulation

*Tags: Strategies*

---

**liam** - *09:45:23*

the code you added/changed to suddenly get the errors

*Tags: Errors Debugging*

---

**Aaron Smith** - *09:47:03*

during process_market_book i now place order via:

```@staticmethod

def place_orders(orders: list[BaseOrder], market: Market):

    with market.transaction() as t:

         for order in orders:

             t.place_order(order)```

and cancel them via

```    def process_orders(self, market: Market, orders: list[BaseOrder]) -&gt; None:

        with market.transaction() as t:

            for order in orders:

                if order.status == OrderStatus.EXECUTABLE:

                    if order.order_type.ORDER_TYPE == flumine.order.order.OrderTypes.LIMIT:

                        t.cancel_order(order)```

*Tags: General Technical*

---

**Aaron Smith** - *09:56:11*

mh, difficult. Those two are the only thing that changed and beside that its all strategy/figuring out which orders i want to place. Given its my most profitable strat i d rather not put that here :smile:

*Tags: Strategies*

---

**liam** - *09:57:08*

understood but it's something you aren't showing which is causing the issue, I can't fix what I can't see

*Tags: Errors Debugging*

---

**Aaron Smith** - *09:58:02*

mh okay. Good to know you dont get the problem from just those 2 functions i send. Thanks for checking :slightly_smiling_face:

*Tags: General Technical*

---

## 2022-09-17

**foxwood** - *16:41:30*

I save stats for a market in `process_closed_market`which works fine for backtest and live. In paper trade however many of the bets are doubled up. I think this is due to the blotter never being cleared and BF reopening and closing the market - sometimes even a few hours later - causing the closed market function to be called again. Is there a safe / proper way to wipe the blotter for a market  after I've saved the stats without crashing flumine which I expect would happen somewhere if I just zapped it with

```if self.client.paper_trade is True : market.blotter = None```



*Tags: Deployment*

---

## 2022-09-20

**Michael** - *08:40:02*

Is there a dictionary for error codes? I'm getting -32602 and I'm not sure what it means

*Tags: Errors Debugging*

---

**Mo** - *08:41:13*

[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions)



&gt; -32602	

&gt; 

&gt; Problem parsing the parameters, or a mandatory parameter was not found

*Tags: Errors Debugging, Strategies*

---

**TT** - *21:17:02*

I'm looking at the [https://betcode-org.github.io/flumine/performance/|multiprocessing code example in the docs](https://betcode-org.github.io/flumine/performance/|multiprocessing code example in the docs), which I've got working, but how do people usually assess the combined results? When running a single process you have a single framework and can [https://github.com/betcode-org/flumine/blob/master/examples/simulate.py#L34|iterate over the markets and orders](https://github.com/betcode-org/flumine/blob/master/examples/simulate.py#L34|iterate over the markets and orders), but it's less obvious how to do this when multiprocessing, (without looking at each framework in isolation.)

*Tags: Performance*

---

## 2022-09-24

**Newbie99** - *16:40:16*

I'm sure this will be something incredibly dumb, but why would the market recorder not always produce a .gz file when the market closes?



Here is my code:



```import time

import logging

import betfairlightweight

from pythonjsonlogger import jsonlogger

import account_info as ai

from flumine import Flumine, clients

from flumine.streams.datastream import DataStream

from marketrecorder import MarketRecorder

from flumine.worker import BackgroundWorker

from recorded_files_worker import sort_recorded_files

from flumine.streams.datastream import RaceDataStream



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



trading = betfairlightweight.APIClient(ai.accname, ai.accpass, ai.acckey, certs=ai.path)

client = clients.BetfairClient(trading, interactive_login=False)



framework = Flumine(client=client)



strategy = MarketRecorder(

    name="horse_racing",

    market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["GB", "IE", "US", "AU", "FR"],

        market_types=["WIN", "PLACE", "EACH_WAY", "OTHER_PLACE"],

    ),

    stream_class=DataStream,

    context={

        "local_dir": ai.market_recorder_path,

        "force_update": False,

        "remove_file": True,

        "remove_gz_file": False,

    },

)



framework.add_strategy(strategy)



strategy = MarketRecorder(

    name="football",

    market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["1"],

        market_types=["OVER_UNDER_05", "OVER_UNDER_15", "OVER_UNDER_25", "OVER_UNDER_35", "OVER_UNDER_45", "CLEAN_SHEET", "MATCH_ODDS", "MATCH_ODDS_AND_BTTS", "BOTH_TEAMS_TO_SCORE", "HALF_TIME",

                      "HALF_TIME_SCORE", "FIRST_HALF_GOALS_05", "FIRST_HALF_GOALS_15", "FIRST_HALF_GOALS_25", "CORRECT_SCORE", "DOUBLE_CHANCE", "DRAW_NO_BET"]

    ),

    stream_class=DataStream,

    context={

        "local_dir": ai.market_recorder_path,

        "force_update": False,

        "remove_file": True,

        "remove_gz_file": False,

    },

)



framework.add_strategy(strategy)

framework.run()```

The strange thing is, for horse racing, it creates a .gz file, but for football it just leaves the file unzipped (it records it correctly, just leaves it as the market name in the folder), why would this be?



Even more weirdly, it appears to correctly create the .gz files for the first x markets after startup, then stops...again just for football, which makes zero sense to me!

*Tags: Data Quality, Strategies*

---

**Mo** - *16:46:29*

Uncaught exception in the thread responsible for gzipping 

*Tags: Errors Debugging*

---

**foxwood** - *16:56:41*

Most exceptions seem to raise a critical error in the logs under flumine - worth checking ?

*Tags: Errors Debugging*

---

**Peter** - *20:10:16*

Not really. Each line is a valid json string, but there are newlines at the end of each, which is why the document overall isn't valid json. It's not a problem.

*Tags: General Technical*

---

**Newbie99** - *20:24:07*

Yes, but normally flumine automatically zips each completed market and its not doing that...only for football.



So whilst its easily solvable, it surely suggests there is some issue?

*Tags: General Technical*

---

**Newbie99** - *20:24:31*

(and for the avoidance of doubt, it was indeed the newline character causing the problem)

*Tags: General Technical*

---

**Peter** - *20:43:27*

You'll have more of a problem if you try to take the newlines out, as then Flumine won't be able to stream the files.



Also, the gzipping process doesn't care about them as it simply streams the file as a binary string, so they're a red herring for debugging your problem.

*Tags: Errors Debugging*

---

**Mo** - *21:01:38*

I think you mean the problem was you assuming the files were JSON format when they’re not… :wink:

*Tags: General Technical*

---

## 2022-09-26

**Newbie99** - *12:04:54*

Just to check, when you said put a try, except around load processing, you did mean here (from the marketrecorder.py file):

```    def _load_processor(self):

        # process compression/load in thread

        while True:

            try:

                market, file_dir, market_definition = self._queue.get(block=True)

                # check file still exists (potential race condition)

                if not os.path.isfile(file_dir):

                    logger.warning(

                        "File: %s does not exist in %s" % (market.market_id, file_dir)

                    )

                    continue

                # compress file

                compress_file_dir = self._compress_file(file_dir)

                # core load code

                self._load(market, compress_file_dir, market_definition)

                # clean up

                self._clean_up()

            except Exception as e:

                logging.critical(f'{e}')```

Interestingly (and confusingly) horse racing files are correctly being zipped, without any problems.



Football files are still not zipping...as a test I tried to GZIP a couple and it worked fine.



So whilst I'm not seeing anything unusual in the logs, the only difference is that I'm recording a significantly larger number of football markets on a single connection, than with horse racing. Is it worth cutting the number of market_types for a bit and seeing if that changes anything?

*Tags: Errors Debugging*

---

**liam** - *12:59:53*

So the `football_load_processor` is getting killed at some point around 2022-09-25 09:43:15,786, can you share the code you changed to catch the error?

*Tags: Errors Debugging*

---

**Newbie99** - *13:08:49*

If I'm understanding correctly, then for the larger file I had the try, except here:



```    def start(self) -&gt; None:

        # start load processor thread

        try:

            threading.Thread(

                name="{0}_load_processor".format(self.name),

                target=self._load_processor,

                daemon=True,

            ).start()

        except Exception as e:

            logging.critical(f'{e}')```

*Tags: Errors Debugging*

---

**Newbie99** - *13:09:04*

for the smaller file I moved it to here:



```   def _load_processor(self):

        # process compression/load in thread

        while True:

            try:

                market, file_dir, market_definition = self._queue.get(block=True)

                # check file still exists (potential race condition)

                if not os.path.isfile(file_dir):

                    logger.warning(

                        "File: %s does not exist in %s" % (market.market_id, file_dir)

                    )

                    continue

                # compress file

                compress_file_dir = self._compress_file(file_dir)

                # core load code

                self._load(market, compress_file_dir, market_definition)

                # clean up

                self._clean_up()

            except Exception as e:

                logging.critical(f'{e}')```

*Tags: Errors Debugging*

---

**Newbie99** - *13:28:27*

Market filter is big for football:



```        market_types=["OVER_UNDER_05", "OVER_UNDER_15", "OVER_UNDER_25", "OVER_UNDER_35", "OVER_UNDER_45", "CLEAN_SHEET", "MATCH_ODDS", "MATCH_ODDS_AND_BTTS", "BOTH_TEAMS_TO_SCORE", "HALF_TIME",

                      "HALF_TIME_SCORE", "FIRST_HALF_GOALS_05", "FIRST_HALF_GOALS_15", "FIRST_HALF_GOALS_25", "CORRECT_SCORE", "DOUBLE_CHANCE", "DRAW_NO_BET"]```

I'm recording on a NAS locally, so its not particularly powerful, 8GB RAM 4 cores.



I can absolutely cut that if the sheer scale is likely to be the problem, I don't need all those market types frankly!

*Tags: General Technical*

---

**Newbie99** - *15:18:50*

Ah sorry I see, yes quite possibly...it seems very likely I'm trying to ask too much of it with that many markets, I will let it run a bit as I want to try and capture the exception in the logs if possible, so dont want to restart just yet, but once I get that I can cut the market filter and hopefully it will be able to cope better

*Tags: Errors Debugging*

---

## 2022-09-27

**liam** - *14:35:13*

[https://superfastpython.com/thread-exception-handling/](https://superfastpython.com/thread-exception-handling/)

*Tags: Errors Debugging*

---

## 2022-09-29

**liam** - *08:42:53*

easy fix will be to change it to a warning

*Tags: Errors Debugging*

---

## 2022-10-01

**Aaron Smith** - *21:19:27*

today i m getting flooded with these bois today:

```"WARNING", "message": "[MarketStream: 2001]: Latency high: 0.5774619579315186"```

I get it correctly that these have nothing to do with code execution and all to do with connection to the betfair server?

Is anyone else experiencing this or is this only on my end?

*Tags: Performance, Deployment*

---

## 2022-10-04

**Michael McGarry** - *16:33:29*

[@U01BTD8FR3P](@U01BTD8FR3P) did you ever find a solution? I'm experiencing the exact same issue. login_interactive also isn't working for me as I get an error: API login: STRONG_AUTH_CODE_REQUIRED

*Tags: Errors Debugging*

---

**mp2003** - *21:05:07*

Hi all, I'm a beginner to betfairlightweight, although know a bit of Python. I've got an app key and SSL cert sorted, and managed to log in OK. When running the example code for 'Streaming' in Jupiter Notebook, I can run all the code OK except the last part, which just hangs on the egg timer and does not complete - no errors, resources on my machine are fine etc.



This is when running both the 'Streaming' example code in [https://betcode-org.github.io/betfair/streaming/](https://betcode-org.github.io/betfair/streaming/) (the '# check for updates in output queue' section) and also the streaming area in [https://github.com/betcode-org/betfair](https://github.com/betcode-org/betfair) (at the line 'betfair_socket.start()')



Have restarted python/web browser - at a bit of a loss! Any help would be really appreciated, thank you.

*Tags: Getting Started, Errors Debugging*

---

## 2022-10-05

**RMG** - *02:50:57*

Apologies for never replying here. I did indeed. 

BDP asked me to send them my certs and details and they would check. In parallel I had also found a resource somewhere about issues with generating the certs. (Let me dig out the link). And I created a brand new set of certs. I submitted these news certa and details to BDP. I played around with the code and tried non BetfairLightweight and then it just started working again. Then tried Betfair light weight and it started working again. I'm not sure if it was me and the new certs or BDP. But its all fine now.

*Tags: General Technical*

---

**Michael McGarry** - *10:43:14*

[@U02USNASPRD](@U02USNASPRD) did you ever find a solution to this? I'm copying the exact code from the example docs and getting the same error when searching for a file list. The files are definitely there since get_collection_options and get_data_size are both returning what I'd expect them to!

*Tags: Errors Debugging*

---

**Michael McGarry** - *11:22:47*

Hi, I'm trying to parse historical data with betfairlightweight and I'm encountering an issue with get_file_list that I can't seem to solve. I get an error every time stating:



```InvalidResponse: Invalid response received: 

[!DOCTYPE html](!DOCTYPE html)

&lt;html&gt;

&lt;head&gt;

&lt;meta name="viewport" content="width=device-width" /&gt;

&lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

&lt;div&gt;

Error

&lt;/div&gt;

&lt;script defer src="[https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194](https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194)" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"75556616acc7dc25","token":"d048f65d27954a24aa6b1d7d2ddcb256","version":"2022.8.1","si":100}' crossorigin="anonymous"&gt;&lt;/script&gt;

&lt;/body&gt;```

This happens even when trying to search for just a couple of days of data, so it isn't an issue of querying too much data. The files definitely exist as the get_collection_options and get_data_size are returning what I'd expect for the same parameters.

*Tags: Data Quality, Errors Debugging*

---

## 2022-10-11

**Mick** - *11:18:25*

Ahhh, yes. I no no doubt have ridlist all wrong, it was just literally a list of the race IDs... But now I've run into a problem with my lack of python skills (I'm a C programmer). I can't understand the syntax of what "meetingid.raceTime (hhmm)" means in practice. I dare say I could thrash around and get it in the end but if you or anyone has an example that would be fantastic.... does that dot in the middle mean there's a class involved?

*Tags: General Technical*

---

## 2022-10-13

**Liam Querido** - *01:12:35*

Hi there. I am trying to stream market data using the code below; however, I am getting an error when I run the subscribe_to_markets function. The error reads as follows: "TypeError: Object of type bytes is not JSON serializable."



I don't quite understand this error, as the market_filter and market_data_filters variables are dictionaries (not byte objects), so this error doesn't make sense to me intuitively.



Any help with resolving this issue would be much appreciated. Thanks in advance!



```from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



betfair_socket = trading.streaming.create_stream()



market_filter = streaming_market_filter(

    event_type_ids=['7'],

    country_codes=['IE'],

    market_types=['WIN'],

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_ALL_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3

)



betfair_socket.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

)



betfair_socket.start()  # blocking```

*Tags: Errors Debugging, Strategies*

---

**Liam Querido** - *07:28:44*

Hi Liam, thanks for your prompt response. Below is the traceback.



Traceback (most recent call last):



  File "&lt;ipython-input-3-131767784cbe&gt;", line 1, in &lt;module&gt;

    betfair_socket.subscribe_to_markets(



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 145, in subscribe_to_markets

    self._send(message)



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 285, in _send

    self.authenticate()



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 96, in authenticate

    self._send(message)



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 287, in _send

    message_dumped = json.dumps(message)



  File "C:\Users\liamq\anaconda3\lib\json\__init__.py", line 231, in dumps

    return _default_encoder.encode(obj)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 199, in encode

    chunks = self.iterencode(o, _one_shot=True)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 257, in iterencode

    return _iterencode(o, 0)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 179, in default

    raise TypeError(f'Object of type {o.__class__.__name__} '



TypeError: Object of type bytes is not JSON serializable

*Tags: Errors Debugging*

---

**Liam Querido** - *09:23:27*

Forgive me, I'm knew to Python, what exactly do you mean by logs?

*Tags: Getting Started*

---

**liam** - *09:59:57*

Not sure where you got that example from but in the [https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py|examples](https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py|examples) we have some logging setup, if you set to DEBUG it might show the issue

*Tags: Getting Started, Errors Debugging*

---

**Aaron Smith** - *13:00:21*

Hi people

I switched from using `market.place_order(order)`  to using

```with market.transaction() as t:

    for order in orders:

        t.place_order(order)```

This was done to chunk up orders and with that make for a smoother execution.

However sadly this has had the opposite effect. Since the change i m getting flooded with all possible latency warnings and higher delay than i ve ever seen before (60seconds+), so i assume i must ve messed up somewhere.

example warnings (just imagine an army of these):

```{"asctime": "2022-10-13 11:00:58,015", "levelname": "WARNING", "message": "[OrderStream: 1001]: Latency high: 62.55000066757202"}



{"asctime": "2022-10-13 10:59:20,992", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.204868412", "latency": 26.081366777420044, "pt": "2022-10-13T10:58:54.911000"}



{"asctime": "2022-10-13 10:59:20,987", "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 26.017338514328003"}```

The basic structure i use goes as follows:

All this happens within the strategy method `process_market_book` .

I create a bunch of orders for different runners using `trade.create_order` .

I collect these orders in a list. Then i call

```

    @staticmethod

    def place_orders(orders: list[BetfairOrder], market: Market):

        with market.transaction() as t:

            for order in orders:

                t.place_order(order)





    @staticmethod

    def cancel_orders(market: Market, orders: list[BetfairOrder]):

        with market.transaction() as t:

            for order in orders:

                if order.status == OrderStatus.EXECUTABLE:

                    t.cancel_order(order)```

to place and cancel orders.



Anyone having an idea whats going on here?

If no orders are collected for placing/cancelling, these 2 functions are still called with an empty list, can this cause any issues?



Thanks a lot to anyone taking the time :slightly_smiling_face:

*Tags: Performance, Strategies*

---

**liam** - *13:03:18*

the log with "High latency between current time and MarketBook publish time" normally points to something bad within a strategy, profiling will tell you straight away

*Tags: Performance, Strategies*

---

**Aaron Smith** - *13:04:33*

yea i have to admit i never did profiling before :sweat_smile: so maybe i ll have to look into that. But all the calculations are the same, its the same strategy only using a new way of placing orders..

*Tags: Strategies*

---

**Aaron Smith** - *13:05:55*

understandable, now that you point it out, i ll fix that aswell. Pretty doubtful that will solve my issue though :smile:

*Tags: Errors Debugging*

---

**liam** - *13:07:31*

you might be surprised, common error to pass in an incorrect var, anyway run [https://betcode-org.github.io/flumine/performance/#cprofile|this](https://betcode-org.github.io/flumine/performance/#cprofile|this) and share the output (dm if you want) and you will know the answer straight away

*Tags: Errors Debugging, Performance*

---

**Aaron Smith** - *13:08:41*

i always pass in keyword arguments, so besides from triggering the OCD, it cant really be a problem

*Tags: General Technical*

---

**Aaron Smith** - *15:52:25*

trying to profile my code turns out to be harder than expected. I already call my code with

`python -m bla.bla.bla` , and seemingly you cant give another `-m`  argument (which would be needed for `-m cprofilev` ). I tried to fix this some time ago to not have to use the `-m` , but it seems i m to dumb for imports in python :smile: I cant seem to find a solid solution that doesnt feel hacky

*Tags: Errors Debugging*

---

## 2022-10-14

**Aaron Smith** - *12:42:47*

sadly not, this results in an import error

*Tags: Errors Debugging*

---

**Aaron Smith** - *13:22:53*

just putting this out here for closure: not calling `market.transaction()`  on each market_book actually solved the latency issues (only change i made and havent gotten a single latency warning since).

Still gotta get profiling working for the future i guess :smile:

*Tags: Performance*

---

## 2022-10-15

**Liam Querido** - *02:52:06*

Hi Liam. I tried running the example code you shared with me, but I'm getting the same error = "TypeError: Object of type bytes is not JSON serializable."



Do you have any idea what could be causing it? Even with DEBUG I am still unsure. Thanks in advance for your help.

*Tags: Errors Debugging*

---

**liam** - *09:58:06*

Do you get the same error running it from python via console 

*Tags: Errors Debugging*

---

## 2022-10-16

**Liam Querido** - *23:48:35*

Unfortunately yes, I also tried running in Jupyter Notebook, but I am getting the exact same error. Do I perhaps need to update some packages?

*Tags: Errors Debugging*

---

## 2022-10-18

**Liam Querido** - *04:21:37*

Hi Liam, thanks for your help. Below are the logs and the traceback.



DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

Traceback (most recent call last):



  File "&lt;ipython-input-1-5f9601b88fb7&gt;", line 46, in &lt;module&gt;

    streaming_unique_id = stream.subscribe_to_markets(



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 145, in subscribe_to_markets

    self._send(message)



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 285, in _send

    self.authenticate()



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 96, in authenticate

    self._send(message)



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 287, in _send

    message_dumped = json.dumps(message)



  File "C:\Users\liamq\anaconda3\lib\json\__init__.py", line 231, in dumps

    return _default_encoder.encode(obj)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 199, in encode

    chunks = self.iterencode(o, _one_shot=True)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 257, in iterencode

    return _iterencode(o, 0)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 179, in default

    raise TypeError(f'Object of type {o.__class__.__name__} '



TypeError: Object of type bytes is not JSON serializable

*Tags: Errors Debugging*

---

**liam** - *07:42:29*

So this is something to do with your appKey or sessionToken, I know you can't share them but are you definitely giving the `betfairlightweight.APIClient` object a string for both?

*Tags: General Technical*

---

**liam** - *07:44:04*

There is a log that I assume you have stripped out that looks like this which might explain things



`DEBUG | [Subscription: 2] Sending: b'{"op": "authentication", "id": 2, "appKey": "test", "session": "test"}`

*Tags: Errors Debugging*

---

**Artiom Giz** - *12:52:57*

Hello!

I have an issue with *Java* code ([https://github.com/betfair/stream-api-sample-code](https://github.com/betfair/stream-api-sample-code))

• Cloned the code :white_check_mark:

Running `mvn install` :

• *Build worked* (after adding javax.annotation to pom.xml) :white_check_mark:

• *Tests fail* (mostly "StartStop", sometimes single test, sometimes two or three) :eyes:

Q1: Somebody might be met this issue? Or say something about it (fix/remove tests/...)?

Q2: Is this code widely used and supported?

Q3: Trying to understand the best way to combine my existing Java env with BF.  I see a lot of information about Python libs: *betfairlightweight* or *flumine*. Worth using them or it's the same (from support/problems POV)?



Thanks in advance, really appreciate!

*Tags: Getting Started, Errors Debugging*

---

**Mo** - *13:39:13*

We're not dogmatic here but the vast majority of us use Python and specifically the betfairlightweight and flumine packages

*Tags: General Technical*

---

## 2022-10-19

**Liam Querido** - *01:17:14*

Ahhh, you're a life saver. Yep, I was encoding the app key and that caused the problem. All working beautifully now. Thanks Liam!

*Tags: General Technical*

---

**Mick** - *12:31:04*

I just got a TOO_MUCH_DATA error when calling list_market_book() with a list of 40 races. So I can read less at once - but is there any way to know in advance whether or not I will get this error again? Using try/except feels kinda yucky.

*Tags: Errors Debugging*

---

**liam** - *12:40:04*

How come you aren't streaming? [https://github.com/betcode-org/betfair/blob/6b064a68c8d2afceda81b70d74b6a0ee9601f228/betfairlightweight/metadata.py#L44|lookup](https://github.com/betcode-org/betfair/blob/6b064a68c8d2afceda81b70d74b6a0ee9601f228/betfairlightweight/metadata.py#L44|lookup)

*Tags: General Technical*

---

**Mick** - *12:49:33*

I know almost nothing about streaming, other than somehow things happen faster - and generally speed is not an issue for me... So I'm concerned that I will have to learn a whole load of new things for not much benefit.

*Tags: Performance*

---

**D C** - *12:54:14*

The benefit is huge [@U01FQH5FA8M](@U01FQH5FA8M). It is not just speed - it is also about lower data transmissions and packet sizes but also greater precision when dealing with things like nonrunners and reduction factors and separating IP money from PE money at the race crossover. I realise that these things may not be directly important to you. I resisted for ages because things were working fine but I definitely noticed profit improvement after switching to streaming. It also makes analysing recorded data a lot easy because listMarketBook calls means you have to calculate the deltas yourself after every call. I guess it depends on your refresh rates and needs though so I get its a personal decision.

*Tags: Performance*

---

**D C** - *13:14:36*

inplay and pre-event. If you have a strategy only wanting to analyse inplay money traded and you use API-NG you have to poll with listMarketBook. You often get really short suspension period so you'll get one call that is when the market is inplay, and the one before is not. You also get 2 full market traded volume arrays - you have to manually calculate the delta, but because of the uncertainty between when the market was precisely turned inplay, you won't know exactly what money traded PE and what traded IP. Obviously this uncertainty gets worse as your polling frequency gets lower. It is a small thing and perhaps a trivial example

*Tags: Strategies*

---

**D C** - *13:18:23*

You also don't have to waste time sending polling requests, packet sizes will be much smaller (apart from the initial images), no need to use compression on the responses (although that is not compulsory) sent back. You've also seen the small number of markets you can obtain per call on the listMarketBook operation. Also, there is no "dead" data - 2 calls on illiquid markets 1 second apart could often result in NO change in market prices or traded volume - but you'll still get 2 full market traded arrays and full price ladders both of which will be identical. Streaming you only get sent stuff when it changes - and its all passive.

*Tags: General Technical*

---

## 2022-10-21

**EJono** - *11:17:40*

I am encountering an error every hour or so which I cant seem to repeat, stemming from a list_market_book request. The strategy runs every 2 minutes or so across ~100 markets. The traceback of the error appears to be timeout related but im not sure how to tackle whatever is causing it.



`market_books = trading.betting.list_market_book(`

  `File "/usr/local/lib/python3.10/site-packages/betfairlightweight/endpoints/betting.py", line 283, in list_market_book`

    `(response, response_json, elapsed_time) = self.request(method, params, session)`

  `File "/usr/local/lib/python3.10/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 45, in request`

    `raise APIError(None, method, params, e)`

`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': ['1.205155225'], 'priceProjection': {'priceData': ['EX_ALL_OFFERS'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}` 

`Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)`



 `SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': ['1.205155225'], 'priceProjection': {'priceData': ['EX_ALL_OFFERS'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}` 

`Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)`



On follow up runs  on the same market 2 mins later the issue no longer occurs. Anyone familiar with this problem or have encountered it before and know how to addres it? Cheers

*Tags: Errors Debugging, Strategies*

---

**liam** - *11:19:14*

Pretty standard to get these now and again tbh, are you making a separate request per market? / Why aren't you streaming?

*Tags: General Technical*

---

**EJono** - *11:22:41*

ah right ok i will bear that in mind when handling the error. I'm not as proficient with flumine and utilising the streaming api as I would like to be, at this stage. In the process of learning but not there yet

*Tags: Errors Debugging*

---

**liam** - *11:31:41*

don't need to use flumine to use streaming, you will find it will dramatically simplify everything

*Tags: General Technical*

---

## 2022-10-24

**Beeblebrox** - *19:59:59*

I'm paper trading a strat on a TOTAL_POINTS_LINE market, but I'm getting an ORDER_VALIDATION error:



```{"asctime": "2022-10-24 18:48:19,823", "name": "flumine.controls", "levelname": "WARNING", "message": "Order has violated: ORDER_VALIDATION Error: Order price is not valid", "control": "ORDER_VALIDATION", "error": "Order price is not valid", "order": {"market_id": "1.205496414", "selection_id": 105545, "handicap": 0, "id": "138859300988413659", "customer_order_ref": "354b9995c9ce8-138859300988413659", "bet_id": null, "date_time_created": "2022-10-24 18:48:18.842366", "publish_time": null, "market_version": null, "async": null, "trade": {"id": "6be453dd-53cc-11ed-a6ba-001b213a8a25", "strategy": "NBABackOvers", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138859300988413659"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 233.0, "size": 10, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 10.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: ORDER_VALIDATION Error: Order price is not valid", "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}}```

In these markets the back prices are the unders value and the lay prices are the overs value. The actual price is always 2.0.  So for the example above, I tried to place a bet on the overs at 233.0, but this trips up the order validation stuff here: [https://github.com/betcode-org/flumine/blob/b59a077e5e3d09e5042de5438677782e4be330f8/flumine/controls/tradingcontrols.py#L53](https://github.com/betcode-org/flumine/blob/b59a077e5e3d09e5042de5438677782e4be330f8/flumine/controls/tradingcontrols.py#L53)

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2022-10-26

**Beeblebrox** - *20:20:49*

Added an issue [https://github.com/betcode-org/flumine/issues/622#issue-1424580260](https://github.com/betcode-org/flumine/issues/622#issue-1424580260)

*Tags: General Technical*

---

## 2022-10-27

**liam** - *11:01:01*

Should now be fixed

*Tags: Errors Debugging*

---

**Beeblebrox** - *11:13:56*

Yeah saw that, thanks. Just need to update to the latest version now, I think I'm still on 1.20.1 :joy:.  I've just realised the other control that needs updating to deal with the LINE_RANGE ladder type is the strategy and selection exposure checks. It's using the points line as the price, rather than 2.0, e.g. a £10 bet on over 231.0 gives a liability of £2300.

*Tags: Strategies*

---

## 2022-10-30

**thambie1** - *05:41:46*

anyone seeing stream latency in the 100+ millisecond range?

*Tags: Performance*

---

## 2022-10-31

**Liam Querido** - *06:02:33*

Is the MarketRecorder under Flumine the best way to stream? I have seen lots of different .py files and many different approaches to streaming - which way is most effective (is there a file on github that I should refer to. I want to stream market data by entering a market ID)?

*Tags: General Technical*

---

**Mikkel** - *20:21:06*

Hi, can someone help with this error in the python API?



```Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4067)')))```



*Tags: Errors Debugging*

---

**Mo** - *20:24:56*

Probably a problem with your certificate. How did you generate it?

*Tags: General Technical*

---

**Mo** - *20:46:45*

Sorry I’m not a Mac user but I know others have had problems with this before 

*Tags: General Technical*

---

## 2022-11-01

**Muhammad Adeel Zahid** - *06:28:49*

Ok, when I try to run the following code

```trading = betfairlightweight.APIClient(username = my_username, password = my_password, app_key = my_app_key, certs=certs_path)

trading.login()

market_id = "1.199777126"

selection_id = 31484513

resources = trading.race_card.get_race_card(market_ids=[market_id])

print(resources)```

I get the exception

`Traceback (most recent call last):`

  `File "E:\Git\betfair\dailyracevenuedatagrabber.py", line 37, in &lt;module&gt;`

    `resources = trading.race_card.get_race_card(market_ids=[market_id])`

  `File "E:\Git\betfair\venv\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 59, in get_race_card`

    `raise RaceCardError(`

`betfairlightweight.exceptions.RaceCardError: You need to login before requesting a race_card`

`APIClient.race_card.login()`

when I change `trading.login()` to `trading.race_card.login()`

I get the following exception

`Traceback (most recent call last):`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen`

    `httplib_response = self._make_request(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request`

    `self._validate_conn(conn)`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connectionpool.py", line 1040, in _validate_conn`

    `conn.connect()`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connection.py", line 414, in connect`

    `self.sock = ssl_wrap_socket(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket`

    `ssl_sock = _ssl_wrap_socket_impl(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl`

    `return ssl_context.wrap_socket(sock, server_hostname=server_hostname)`

  `File "C:\Users\adeel\AppData\Local\Programs\Python\Python310\lib\ssl.py", line 512, in wrap_socket`

    `return self.sslsocket_class._create(`

  `File "C:\Users\adeel\AppData\Local\Programs\Python\Python310\lib\ssl.py", line 1070, in _create`

    `self.do_handshake()`

  `File "C:\Users\adeel\AppData\Local\Programs\Python\Python310\lib\ssl.py", line 1341, in do_handshake`

    `self._sslobj.do_handshake()`

`ssl.SSLError: [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\adapters.py", line 440, in send`

    `resp = conn.urlopen(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen`

    `retries = retries.increment(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\util\retry.py", line 592, in increment`

    `raise MaxRetryError(_pool, url, error or ResponseError(cause))`

`urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='[http://www.betfair.com|www.betfair.com](http://www.betfair.com|www.betfair.com)', port=443): Max retries exceeded with url: /exchange/plus/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)')))`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "E:\Git\betfair\venv\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 28, in login`

    `response = session.get(self.login_url)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\api.py", line 75, in get`

    `return request('get', url, params=params, **kwargs)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\api.py", line 61, in request`

    `return session.request(method=method, url=url, **kwargs)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\sessions.py", line 529, in request`

    `resp = self.send(prep, **send_kwargs)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\sessions.py", line 645, in send`

    `r = adapter.send(request, **kwargs)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\adapters.py", line 517, in send`

    `raise SSLError(e, request=request)`

`requests.exceptions.SSLError: HTTPSConnectionPool(host='[http://www.betfair.com|www.betfair.com](http://www.betfair.com|www.betfair.com)', port=443): Max retries exceeded with url: /exchange/plus/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)')))`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "E:\Git\betfair\dailyracevenuedatagrabber.py", line 34, in &lt;module&gt;`

    `trading.race_card.login()`

  `File "E:\Git\betfair\venv\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 30, in login`

    `raise APIError(None, self.login_url, None, e)`

`betfairlightweight.exceptions.APIError: [https://www.betfair.com/exchange/plus/](https://www.betfair.com/exchange/plus/)` 

`Params: None` 

`Exception: HTTPSConnectionPool(host='[http://www.betfair.com|www.betfair.com](http://www.betfair.com|www.betfair.com)', port=443): Max retries exceeded with url: /exchange/plus/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)')))`

Please note that my certificate setup and credentials are correct as I am able to use other API methods like `trading.betting.list_market_catalogue` . What could be the reason of this exception for this particular endpoint?

*Tags: Getting Started, Errors Debugging, Deployment, Strategies*

---

**Mo** - *06:36:11*

What do you get if you run the following Python code?



```import ssl

print(ssl.HAS_TLSv1_1)

print(ssl.HAS_TLSv1_2)

print(ssl.HAS_TLSv1_3)

print(ssl.OPENSSL_VERSION)```

*Tags: General Technical*

---

**Liam Querido** - *07:19:31*

Is the MarketRecorder under Flumine the best way to stream? I have seen lots of different modules and many different approaches to streaming - some use MarketRecorder, others don't. What do you suggest (and is there a specific streaming example you could refer me to)?



So far, I am able to obtain the market data I want, but not via streaming (just PIT query). Below is my code. What is the best way to adapt this for streaming?



Thanks in advance! This forum has already been extremely helpful!





def GetEventIDs():

    event_types = trading.betting.list_event_types()

    Result = pd.DataFrame({

        'Sport': [event_type_object.event_type.name for event_type_object in event_types],

        'ID': [event_type_object.event_type.id for event_type_object in event_types]

    }).set_index('Sport').sort_index()

    return Result



GetEventIDs()





def FilterMarkets(EventTypeID,MarketCountry,DaysUntilMarketStart):

    sport_event_filter = betfairlightweight.filters.market_filter(

        event_type_ids    =[EventTypeID],

        market_countries  =[MarketCountry],

        market_start_time ={

            'to': (datetime.datetime.utcnow() + datetime.timedelta(days=DaysUntilMarketStart)).strftime("%Y-%m-%dT%TZ")

        }

    )

    country_sport_events = trading.betting.list_events(

        filter=sport_event_filter

    )

    Result = pd.DataFrame({

        'Event Name': [event_object.event.name for event_object in country_sport_events],

        'Event ID': [event_object.event.id for event_object in country_sport_events],

        'Event Venue': [event_object.event.venue for event_object in country_sport_events],

        'Country Code': [event_object.event.country_code for event_object in country_sport_events],

        'Time Zone': [event_object.event.time_zone for event_object in country_sport_events],

        'Open Date': [event_object.event.open_date for event_object in country_sport_events],

        'Market Count': [event_object.market_count for event_object in country_sport_events]

    })

    return Result





def process_runner_books(runner_books,market_catalogues):

    '''

    This function processes the runner books and returns a DataFrame with the best back/lay prices + vol for each runner

    :param runner_books:

    :return:

    '''

    best_back_prices = [runner_book.ex.available_to_back[0]['price']

        if runner_book.ex.available_to_back

        else np.nan

        for runner_book

        in runner_books]

    best_back_sizes = [runner_book.ex.available_to_back[0]['size']

        if runner_book.ex.available_to_back

        else np.nan

        for runner_book

        in runner_books]



    best_lay_prices = [runner_book.ex.available_to_lay[0]['price']

        if runner_book.ex.available_to_lay

        else np.nan

        for runner_book

        in runner_books]

    best_lay_sizes = [runner_book.ex.available_to_lay[0]['size']

        if runner_book.ex.available_to_lay

        else np.nan

        for runner_book

        in runner_books]



    selection_ids = [runner_book.selection_id for runner_book in runner_books]

    statuses      = [runner_book.status for runner_book in runner_books]

    runners       = [market_catalogue.runner_name for market_catalogue in market_catalogues.runners]



    df = pd.DataFrame({

        'Runners': runners,

        'Selection ID': selection_ids,

        'Best Back Price': best_back_prices,

        'Best Back Size': best_back_sizes,

        'Best Lay Price': best_lay_prices,

        'Best Lay Size': best_lay_sizes,

        'Status': statuses,

    })

    return df





def GetMarketBook(MarketID,MarketCatalogue):

    price_filter = betfairlightweight.filters.price_projection(price_data=['EX_BEST_OFFERS'])

    # Request market books

    market_books = trading.betting.list_market_book(

    market_ids=[MarketID],

    price_projection=price_filter

    )

    # Grab the first market book from the returned list

    market_book = market_books[0]

    Result = process_runner_books(market_book.runners, MarketCatalogue)

    return Result

*Tags: Feature Engineering, Strategies*

---

**Liam Querido** - *08:12:43*

Okay cool, thanks Mo. I have the following code, which calls the MarketRecorder class. When I execute the code, the data is stored in a single file of type '.205772753'.



I have two questions from here. First of all, I'm not quite sure what this file type is - could you please help me understand what it is, and how I can convert to .csv (I'm assuming you're going to suggest calling market_book_to_dataframe and then saving to .csv).



Second question, is my code actually streaming? Even though the code keeps running, no new data seems to be recorded. If I leave the code running for 10 mins, I am left with the same file that was exported when I initially executed the code 10 mins ago.



Please let me know if logs would be any of use in solving this issue. Thanks again Mo

*Tags: Feature Engineering*

---

**Mo** - *08:20:30*

1. It's technically a JSONL or line delimited JSON file. It's the same format as what you get if you purchase the official Betfair historic data - one streaming API message per line

2. There is a prices_file_to_csv_file function in betfairutil

3. Probably. It depends on a couple of things: 1. is the market active? If there are no price changes in those 10 minutes then don't expect there to be any changes to the file 2. are you looking at the prices file or the market catalogue? The market recorder should be saving both. You wouldn't expect the market catalogue to change (much)

*Tags: Data Quality*

---

**Guy Incognito** - *11:47:12*

Anyone ever has this issue before? Using the simulation client in flumine using purchased data. Tested it out with a few data files and all had this issue. I've even checked if runner.status is active before placing any bets



2022-11-01 22:42:25,440:CRITICAL:198:Trade error in 416eae93-59da-11ed-8a6c-6c2b59d9baa8

 Traceback (most recent call last):

   File "C:\Users\VL\Documents\virtual_environments\backtest\lib\site-packages\flumine\execution\simulatedexecution.py", line 42, in execute_place

     simulated_response = order.simulated.place(

   File "C:\Users\VL\Documents\virtual_environments\backtest\lib\site-packages\flumine\simulation\simulatedorder.py", line 87, in place

     if runner.status == "REMOVED":

 AttributeError: 'NoneType' object has no attribute 'status'

*Tags: Errors Debugging*

---

**liam** - *11:47:51*

can you share the strategy code where you call place?

*Tags: Strategies*

---

**Guy Incognito** - *11:54:07*

if runner.status == "ACTIVE":

                        back_price = 5

                        back_size = 5



                        trade = Trade(

                            market_id=market_book.market_id,

                            selection_id=runner.selection_id,

                            handicap=runner.selection_id,

                            strategy=self

                        )



                        order = trade.create_order(

                            side="BACK",

                            order_type=LimitOrder(price=back_price, size=back_size)

                        )



                        market.place_order(order)

*Tags: Strategies*

---

**Liam Querido** - *12:54:30*

Perfect. One other thing, is it possible to adjust the frequency of the data that Flumine records. I believe that, for the delayed app key, the default is every 180 seconds. Is this able to be changed (or just for the live key)?

*Tags: Deployment*

---

**Liam Querido** - *13:21:20*

Where would I call the prices_file_to_csv_file function in the below code?



client = clients.BetfairClient(trading)



framework = Flumine(client=client)



strategy = MarketRecorder(

    market_filter=betfairlightweight.filters.streaming_market_filter(

        market_ids=[MarketID],

    ),

    stream_class=DataStream,

    context={"local_dir": r"C:\tmp", "force_update": False, "remove_file": True,},

)



framework.add_strategy(strategy)

framework.run()

*Tags: Strategies*

---

## 2022-11-02

**river_shah** - *11:13:53*

[@U4H19D1D2](@U4H19D1D2) this was asked a while ago but sorry I can't find answer in search. How do I force process termination if I hit something like this please?

```CRITICAL[flumine.utils:call_strategy_error_handling:246] Unknown error xxx```

*Tags: Errors Debugging, Strategies*

---

**liam** - *11:14:26*

```config.raise_errors = True```

*Tags: Errors Debugging*

---

**Mikkel** - *18:56:43*

Does anyone know if the API works from Denmark? I keep getting this..



```LoginError: API login: DANISH_AUTHORIZATION_REQUIRED```



*Tags: Errors Debugging*

---

## 2022-11-05

**Meow** - *10:33:25*

Hi, anyone know how to obtain deposit and withdrawal transactions please?

*Tags: General Technical*

---

**Meow** - *11:37:08*

Sorry i meant using the betfair API

*Tags: General Technical*

---

**Unknown** - *20:08:49*

I've written a back testing app: [https://github.com/JeffW12345/Basic-Betfair-Backtesting-App](https://github.com/JeffW12345/Basic-Betfair-Backtesting-App)



I get the attached error message. When I googled this message, I get this SO article: [https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character](https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character)



Following the article's advice, I tried changing line 66 of utils.py to:



```with open(file_dir, "r", encoding="utf8") as f:```

However, I then got a different error message: UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcd in position 10: invalid continuation byte



I'm using JSON files supplied by Betfair.



Any suggestions would be much appreciated.



Thanks

*Tags: Errors Debugging*

---

**liam** - *20:10:37*

Looks like you are giving it a compressed file, smart_open is the easy fix 

*Tags: Errors Debugging*

---

**liam** - *20:11:31*

[https://betcode-org.github.io/flumine/performance/#file-location|https://betcode-org.github.io/flumine/performance/#file-location](https://betcode-org.github.io/flumine/performance/#file-location|https://betcode-org.github.io/flumine/performance/#file-location)

*Tags: Performance*

---

**liam** - *20:45:47*

[https://betcode-org.github.io/flumine/quickstart/#listener-kwargs|https://betcode-org.github.io/flumine/quickstart/#listener-kwargs](https://betcode-org.github.io/flumine/quickstart/#listener-kwargs|https://betcode-org.github.io/flumine/quickstart/#listener-kwargs)

*Tags: General Technical*

---

## 2022-11-07

**Mikkel** - *22:03:11*

```ConnectionError: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x7ff2a218bee0&gt;: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))```

Can someone help with this error when trying to connect through the API?

*Tags: Errors Debugging*

---

## 2022-11-16

**Peter C** - *10:59:35*

I have an issue that sometimes appears after a `connection closed by server` error. When the flumine strategy reconnects, it can sometimes get stuck in a cancelling loop. My cancel logic checks whether an order has Executable status, and then cancels based on time executable. Sometimes after a reconnect the strategy attempts to cancel an order, and this transaction fails as `bet_taken_or_lapsed`. The strategy will continually try to cancel these orders, so I'm wondering what the best way to avoid this is.

*Tags: Errors Debugging, Deployment, Strategies*

---

**Lee** - *11:01:43*

What version of flumine are you running? I believe this was fixed in 2.2.3

*Tags: Errors Debugging*

---

**Peter C** - *11:07:17*

Yep, that's it - I updated flumine everywhere but the server where this problem occurs - sorry, I should have realised, thanks!

*Tags: Deployment*

---

## 2022-11-18

**Mikkel** - *21:57:10*

Is it possible to use betfairlight if I am from Denmark? I need to login with MitID and I can use the cookie when logging in through Betfair API, but it doesn't seem to work when logging in through betfairlight. Is there any work around on this?

*Tags: General Technical*

---

## 2022-11-19

**Charlie Daragon** - *15:20:44*

Hi I am getting a connection error when trying to use Betfair API - anyone know how to help?

*Tags: Errors Debugging*

---

**Charlie Daragon** - *15:20:48*

```HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x43c5d28&gt;: Failed to establish a new connection: [Errno 50] Protocol not available'))```



*Tags: Errors Debugging*

---

**Mo** - *15:31:55*

Sorry I’m not a windows user so can’t really help but I take the message to mean that your version of OpenSSL installed is incapable of meeting the minimum TLS version that the Betfair login server requires 

*Tags: Getting Started, Deployment*

---

**Charlie Daragon** - *15:39:32*

Anyone else with windows knowledge that can help - it seems like a lot of people have this issue

*Tags: General Technical*

---

## 2022-11-23

**EJono** - *11:10:44*

I am currently testing out a strat using flumine on several markets, one on the Morocco v Croatia MATCH_ODDS currently in play. market_id: 1.197092678



Im noticing large periods of time between successive process_market_book() executions up to ~10-20 minutes at some points before regular millisecond frequencies resume. I was wondering if anyone else is experiencing slow streamed market_books for this game even though its a very high volume world cup game, or if there is something else i am not aware of that is causing pmb to not execute ie market_book.status == "CLOSED"  (which is a filter i have in place during check_market_book). Any help greatly appreciated.

*Tags: Performance*

---

## 2022-11-25

**EJono** - *14:22:36*

Question regarding rugby union "WINNING_MARGIN" market type. I was wondering if there was a way to intrinsically link the the selection ids provided in via the market_book object from the following call: market_books = trading.betting.list_market_book(WINNING_MARGIN_ID) , to the actual wining margin buckets listed in the ui:

home 1-12

home 13+

away 1-12

away 13+

draw

in other markets ie MATCH_ODDS, the market_catalogue would give a list of runners with both selection_id and team name leaving little ambiguity to exactly the selection that the an order is going down on. However the runner list inside the catalogue for the winning_margin is empty so im not sure what selection_id corresponds to which points bucket. Also i cant find a sort priority field. I thought the index of the runners inside the market_book might be the way to ultimately determine the corresponding points bucket but this doesnt seem particularly safe as i have seen instances in the past of runners indexing not matching up with traditoinal home, away, draw ordering. Two currently listed rugby games which have this empty market_catalogue runners include



Harlequins v Gloucester,  eventId: 31925868,  WM marketID: '1.206774481'

Newcastle v Exeter,  eventId: 31925869,  WM marketID: '1.206774284'



Is there anyway of identifying wich selection_id corresponds to which win margin bucket through the information available from market_book or market_catalogue that i am missing?

Cheers

*Tags: Strategies*

---

## 2022-12-03

**Michael** - *16:28:23*

How do I find the reason for ERROR_IN_ORDER? Not sure what "The action failed because the parent order failed" means

*Tags: Errors Debugging*

---

**D C** - *16:35:35*

If you place bets with placeOrders operation and you place a batch of bets with a single call, if ANYTHING fails for any reason, none of those bets in that batch will place. Within the response you get a list of the orders and their individual status. Within there you will find a status codes for each order which should highlight the problem

*Tags: General Technical*

---

**D C** - *16:36:18*

Specifics are here at the API level if nobody can give you a BFLW one line answer

*Tags: General Technical*

---

**D C** - *16:47:59*

I'm not a BFLW user so not sure what the member variables would be called. You get a list of PlaceExecutionReports - iterate over that list and get the instruction report error code - that should contain details like INVALID_ODDS etc.

*Tags: Errors Debugging*

---

**D C** - *18:40:34*

I use my own stuff written in C++. Unfortunately I started a long time before I was aware of BFLW. If I were coming to the game fresh I would certainly be using BFLW.

*Tags: General Technical*

---

**D C** - *18:51:10*

Yeah. Would have loved to have found BFLW before I started.

*Tags: General Technical*

---

## 2022-12-09

**AP** - *19:47:51*

Has anyone got this error when running flumine simulation on py 3.11



`UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 115: character maps to &lt;undefined&gt;`

*Tags: Errors Debugging*

---

## 2022-12-11

**WaftyCrancker** - *10:53:32*

Does anyone know what might be causing the below error? It's when I try to back test using horse data. I have no issues when using greyhounds. Both are unzipped in the same way, I can't see anything obviously wrong with the files, I've tried re-unzipping them but still the same issues. Any help would be appreciated!

```File "C:\Users\Dave\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode

    obj, end = self.raw_decode(s, idx=_w(s, 0).end())

               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\Dave\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 355, in raw_decode

    raise JSONDecodeError("Expecting value", s, err.value) from None

json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)```

*Tags: Errors Debugging*

---

## 2022-12-13

**Liam Querido** - *04:06:12*

Hmmm, got the following error:



TypeError: prices_file_to_data_frame() got an unexpected keyword argument 'market_definition_fields'

*Tags: Errors Debugging*

---

**Liam Querido** - *12:47:09*

What documentation should I search for?

*Tags: General Technical*

---

**Mo** - *12:52:32*

I think you need to read up on how to switch branches on GitHub

*Tags: General Technical*

---

**Liam Querido** - *13:40:56*

I tried the following and it gives me an attribute error.



prices_file_to_data_frame(OutputFileMarketID,OutputFileCSV,market_catalogues={"marketName":"market_name"})

*Tags: Errors Debugging*

---

**Liam Querido** - *13:41:06*

This is the error:

*Tags: Errors Debugging*

---

**Liam Querido** - *13:41:07*

AttributeError: 'str' object has no attribute 'runners'

*Tags: Errors Debugging*

---

**Liam Querido** - *17:52:36*

Well that's interesting, but I still get the same error. It doesn't seem that market_definition_fields is an input -&gt; the help page doesn't show market_definition_fields



TypeError: prices_file_to_data_frame() got an unexpected keyword argument 'market_definition_fields'

*Tags: Errors Debugging*

---

**Liam Querido** - *17:58:38*

I don't quite understand how the same function has different branches, and how to use the different branches?

*Tags: General Technical*

---

**Liam Querido** - *18:03:46*

Okay, that makes sense. But how do you install the package in editable model? Is it a similar idea to pip install?

*Tags: Getting Started, Strategies*

---

**Liam Querido** - *18:04:00*

Sorry for the mass questions, but I'm at least following now

*Tags: General Technical*

---

**foxwood** - *18:46:36*

That looks interesting thanks. The market class call wraps `order.replace()` but then does useful stuff like putting the order back into pending - hopefully that will then lead to matching. Went down that rabbit hole jumping from BF docs to IDE helper which showed order methods lol. Will test later but consider this closed now.

*Tags: General Technical*

---

## 2022-12-14

**Liam Querido** - *11:15:16*

Thanks Mo. All is working perfectly now. Really appreciate your help, as always!

*Tags: General Technical*

---

## 2022-12-20

**Matthieu Labour** - *23:31:08*

Hi, I am running into the following error. I am looking for guidance. I run berfairlightweight = 2.17.0 and Flumine 2.3.1. Thank you for your help.

```2022-12-20 23:27:23 ERROR    [MarketStream: None]: INVALID_INPUT: Failed to un-marshall: '{"op": "marketSubscription", "id": 3003, "marketFilter": {"eventTypeIds": "2", "marketTypes": ["MATCH_ODDS"]}, "marketDataFilter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "initialClk": null, "clk": null, "conflateMs": 0, "heartbeatMs": null, "segmentationEnabled": true}'

2022-12-20 23:27:23 ERROR    MarketStream 3003 run error

Traceback (most recent call last):

  File "/home/xxx/.cache/pypoetry/virtualenvs/s7v-trader-QDeCTrzc-py3.8/lib/python3.8/site-packages/flumine/streams/marketstream.py", line 44, in run

    self._stream.start()

  File "/home/xxx/.cache/pypoetry/virtualenvs/s7v-trader-QDeCTrzc-py3.8/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 67, in start

    self._read_loop()

  File "/home/xxx/.cache/pypoetry/virtualenvs/s7v-trader-QDeCTrzc-py3.8/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 233, in _read_loop

    self._data(received_data)

  File "/home/xxx/.cache/pypoetry/virtualenvs/s7v-trader-QDeCTrzc-py3.8/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 274, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 209-201222232723-1629057, data: {"op":"status","statusCode":"FAILURE","errorCode":"INVALID_INPUT","errorMessage":"Failed to un-marshall: '{\"op\": \"marketSubscription\", \"id\": 3003, \"marketFilter\": {\"eventTypeIds\": \"2\", \"marketTypes\": [\"MATCH_ODDS\"]}, \"marketDataFilter\": {\"fields\": [\"EX_ALL_OFFERS\", \"EX_TRADED\", \"EX_TRADED_VOL\", \"EX_LTP\", \"EX_MARKET_DEF\", \"SP_TRADED\", \"SP_PROJECTED\"]}, \"initialClk\": null, \"clk\": null, \"conflateMs\": 0, \"heartbeatMs\": null, \"segmentationEnabled\": true}'","connectionClosed":true,"connectionId":"209-201222232723-1629057"}

2022-12-20 23:27:23 DEBUG    [OrderStream: 1001]: HEARTBEAT: {'op': 'ocm', 'id': 1001, 'clk': 'ADUAJwBSAGkAaw==', 'pt': 1671578843234, 'ct': 'HEARTBEAT'}```

*Tags: Errors Debugging*

---

## 2022-12-21

**R** - *08:57:46*

without code I can hazard a guess that your request to/from betfair is not formatted correctly (un-marshalling error)



But yeah, code plz

*Tags: Errors Debugging*

---

**Matthieu Labour** - *14:30:31*

Will send some code, although seems the error is coming from within flumine/betfairlightweight.

```2022-12-21 14:26:46 DEBUG    [Subscription: 3002] Sending: b'{"op": "marketSubscription", "id": 3001, "marketFilter": {"eventTypeIds": "2", "marketTypes": ["MATCH_ODDS"]}, "marketDataFilter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "initialClk": null, "clk": null, "conflateMs": 0, "heartbeatMs": null, "segmentationEnabled": true}\r\n'

2022-12-21 14:26:46 INFO     [MarketStream: 3001]: connection_id: 105-211222142646-1695898

2022-12-21 14:26:46 INFO     [MarketStream: 3002]: SUCCESS (4 connections available)

2022-12-21 14:26:46 ERROR    [MarketStream: None]: INVALID_INPUT: Failed to un-marshall: '{"op": "marketSubscription", "id": 3001, "marketFilter": {"eventTypeIds": "2", "marketTypes": ["MATCH_ODDS"]}, "marketDataFilter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "initialClk": null, "clk": null, "conflateMs": 0, "heartbeatMs": null, "segmentationEnabled": true}'

2022-12-21 14:26:46 ERROR    MarketStream 3001 run error```



*Tags: Errors Debugging*

---

## 2022-12-22

**D C** - *09:20:38*

Didn't notice at the time but after looking at logs today I can see a load of ERROR_IN_MATCHER bet placement failures around the time you sent that message.

*Tags: Errors Debugging*

---

## 2022-12-28

**Guy Incognito** - *13:13:52*

The problem for me is I manually have to go and press crtl c after it get stuck

*Tags: General Technical*

---

**liam** - *15:29:33*

yeah just don't do this, fix it

*Tags: Errors Debugging*

---

## 2023-01-02

**D** - *15:44:16*

Flumine question - creating a LAY order using trade.create_order()  with price=40.0, bet_target_type='PAYOUT', bet_target_size=40,



I get the following order violation message and the order isn't placed:



`"WARNING", "message": "Order has violated: STRATEGY_EXPOSURE Error: Order exposure (1560.0) is greater than strategy.max_order_exposure (400)"` 



Whereas I was expecting the exposure from this order to be counted as 40 and not 1,560 - is this correct?

*Tags: Errors Debugging, Strategies*

---

## 2023-01-03

**Brøndby IF** - *19:26:26*

Good afternoon everyone!



About streaming (specifically about soccer events).



In a normal filter `betfairlightweight.filters.market_filter` I use `in_play_only=True`, but in `streaming_market_filter` there is only `turnInPlayEnabled`.



What method do you recommend to handle the need for only inplay events using streaming for lower latency in data collection?

*Tags: Performance*

---

**Peter** - *21:41:40*

The [https://github.com/betcode-org/flumine/blob/master/flumine/markets/middleware.py|SimulatedSportsDataMiddleware](https://github.com/betcode-org/flumine/blob/master/flumine/markets/middleware.py|SimulatedSportsDataMiddleware) has a check that

`pt &gt; update.publish_time_epoch`

i.e. the market time is later than the timestamp for the sports data update. This means that, unless I’m misunderstanding something in the wider context, the strategy’s process_sports_data method assessments and trades are based on market data from the future.



If my reasoning is correct, is this a compromise necessary because when backtesting the sports stream is simulated by middleware that can only be triggered by the market update? Would this also mean that the comment in the [https://github.com/betcode-org/flumine/blob/master/examples/simulate-sportsdata.py|simulate-sportsdata.py](https://github.com/betcode-org/flumine/blob/master/examples/simulate-sportsdata.py|simulate-sportsdata.py) example’s process_sports_data() method that said method is “called on each update from sports-data-stream” is slightly off?

*Tags: Strategies*

---

## 2023-01-04

**Peter** - *09:12:33*

[@U016TGY3676](@U016TGY3676) If I were polling yes, but when streaming live the process_sports_data method receives both the current market book and the sports update making it possible (and probably preferable) to trade immediately if triggered.



However, when backtesting, the middleware is delivering the sports update with the next market update. In effect it delays delivering the sports update, until a market update triggers it, and indeed may delay several sports updates if it takes a while for the next market update to come along. In effect we have what data scientists would term a data leak as we're acting on the sports update with market data that wasn't available at the time it was supposedly received.



I realise now that I did know this, but whilst approaching the question from a different direction had a senior moment! :blush:

*Tags: Deployment*

---

## 2023-01-09

**Andrew** - *10:47:22*

Doesn’t customer_order_ref have a hash of the strategy name as a prefix, so they aren’t equivalent?

*Tags: Errors Debugging, Strategies*

---

## 2023-01-10

**Andrew** - *07:06:13*

I’m embarrassed to own up to my foolishness to open my report in Excel and it truncated trailing zeroes on order ids. But I do still note the code above where customer_order_ref has hash of strategy name prefixed to order I’d.



I’ve got my cancel and place working. Thinking of using async on that. Any experiences?

*Tags: Errors Debugging, Strategies*

---

**liam** - *07:09:53*

Yeah async will work with no issues, helps in freeing up the amount of threads used in the pool

*Tags: General Technical*

---

**Andy** - *09:41:47*

newbie question for login from the doc:



import betfairlightweight

trading = betfairlightweight.APIClient(

        "username", "password", app_key="app_key", certs="/certs"

    )

trading.login()



what should the app_key parameter be? Should I copy and paste out the 1592 character .pem file? (I've tried that and it doesn't seem to do anything)

*Tags: Strategies*

---

**liam** - *09:58:04*

What is the error? Do you actually have an appKey?

*Tags: Errors Debugging*

---

**Andy** - *09:59:59*

when I run the code, nothing happens, no error etc

*Tags: Errors Debugging*

---

**Andy** - *10:02:47*

and ran, and get this error



Traceback (most recent call last):

  File "c:\Users\Documents\Python - Problem Solving and Programming\Betfairlightweight.py", line 17, in &lt;module&gt;

    event_types = trading.betting.list_event_types()

                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\Python\Python311\Lib\site-packages\betfairlightweight\endpoints\betting.py", line 37, in list_event_types

    (response, response_json, elapsed_time) = self.request(method, params, session)

                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\Python\Python311\Lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 55, in request

    self._error_handler(response_json, method, params)

  File "C:\Users\Python\Python311\Lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listEventTypes

Params: {'filter': {}}

Exception: None

Error: {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie2-ang22a-prd-01051046-0009aa71d1', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie2-ang22a-prd-01051046-0009aa71d1', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}

*Tags: Errors Debugging, Strategies*

---

**Andy** - *10:04:26*

also question - should I have used the 1.0-DELAY or 1.0 app key?

*Tags: General Technical*

---

**Andy** - *10:05:26*

I just used the 1.0-DELAY one, and ran the code again. No error this time. But nothing happened again

*Tags: Errors Debugging*

---

**Andy** - *10:20:36*

Appreciate the help Liam but I have pretty basic knowledge and unless there's step by step instructions for all of this on YouTube or something it's probably out of my league. What I have is an excel file with data being refreshed into it e.g. (Event) Cheltenham Race 1, (Outcome) 12. Majed, (Price) 2.5 and I want to map this to placing automated BACK bets on the corresponding exchange market, outcome and price in real-time (ish). I'm a recreational gambler and just testing some things out, but if anybody wants to reach out with help with putting something together I'm happy something to pay for your time. Would ideally like to do screenshare sessions so I can learn something along the way

*Tags: General Technical*

---

**PeterLe** - *11:20:52*

Andy do you have two step?

If so you need to include that too

My Python knowledge is very basic (so this may not be the best way to do this...but it works :grinning:)

This is my code:



```myacc = str(input("please enter account name: "))

app_key = str(input("Please enter key: "))

mypass = str(input("Please enter Password and 2FA: "))

trading = betfairlightweight.APIClient(myacc,mypass, app_key, certs=r"C:\certs")```

so you just add your 2FA onto your password. As i say, there is prob a better way....good luck

*Tags: Strategies*

---

**Andy** - *11:41:49*

thanks Lawrence! This helps me get somewhere.... I can understand the code here but I still don't think I would have enough knowledge to implement my own workable code on top

*Tags: General Technical*

---

**Unknown** - *12:33:31*

one more for now please. Any documentation on what values are valid for some of these parameters?

*Tags: General Technical*

---

**D C** - *12:35:29*

You should check out the API documentation to get a feel for what is possible and the parameters required for each operation

*Tags: General Technical*

---

**D C** - *12:36:21*

Its a steep learning curve if you are new to these things but there are no shortcuts really. Just the existence of BFLW is the biggest shortcut you could possibly get

*Tags: Getting Started*

---

## 2023-01-11

**Peter** - *12:00:31*

[@U04J6LUGCFM](@U04J6LUGCFM) It is a poorer option. It's useful for testing things like log in and requesting fairly static data like competition ids and market catalogues, but will give you very strange results if you use it to request the really useful stuff like market odds. The delays appear to be pretty random and my suspicion is that they just snapshot the live data from time-to-time and then serve that up to delayed key users, so it often bears little relation to the true state of the market.

*Tags: Deployment*

---

**JFP** - *12:36:09*

Just noticed a significant discrepancy when backtesting with different versions of Flumine.

Original backtesting completed back in Dec 2021 with Flumine 1.19.14 showed consistent profit for a strategy that places a lot of passive bets.

Have been running this strat live with success.

Just reran the same data with latest version of Flumine 2.3.1 which gave approx. break even. Ran backtest against periods when it was running live and it gave negative results when my live results were positive.

Reinstalled 1.19.14 and rerun Backtest, got original positive results and also got positive results that roughly match my actual results for live trading periods.

Installed Flumine 1.21.0 (when smart matching was implemented) and get the same negative results as per 2.3.1.

The docs for smart matching says, for backtesting, it removes double counting of size for passive orders. Just after some more clarification on this, is this to remove double counting when running multiple strategies (ie: simulated middleware with live strat)?

*Tags: Getting Started, Deployment, Strategies*

---

**JFP** - *14:06:59*

Thanks Liam. The strategy giving different results does not have any simulated middleware. Is there anyway smart matching could be causing these discrepancies or do you think it could be some update in between versions 1.19.14 and 1.21.0, I noticed a couple of speed improvements for backtesting between these versions?

*Tags: Performance, Strategies*

---

**JFP** - *14:15:15*

Prob should clarify. I have a strategy that places bets live. Have been running this with profit. When I simulate this strat with historical data, I get negative results

*Tags: Data Quality, Deployment, Strategies*

---

**JFP** - *14:30:24*

horses Win market, &gt; $50000 matched, passive orders, one strategy, avg 80 orders per market

*Tags: Strategies*

---

**JFP** - *22:29:05*

```    # Get betfair data files

    data_folder = 'C:/Data/Data/File'

    data_files = os.listdir(data_folder,)

    data_files = [f'{data_folder}/{path}' for path in data_files]



    strategy = BookLayOrders(

        # market_filter selects what portion of the historic data we simulate our strategy on

        # markets selects the list of betfair historic data files

        # market_types specifies the type of markets

        # listener_kwargs specifies the time period we simulate for each market

        market_filter={

            "markets": data_files,  

            'market_types':['WIN'],

            'country_codes':["GB"],

            "listener_kwargs": {"seconds_to_start": 190},  

            },

        max_order_exposure=10000,

        max_selection_exposure=10000,

        max_live_trade_count=10000,

        max_trade_count=10000,

        multi_order_trades = True,

    )

    # Run our strategy on the simulated market

    framework.add_strategy(strategy)

    framework.add_logging_control(

        BacktestLoggingControl()

    )



    framework.run()```

*Tags: Deployment, Strategies*

---

## 2023-01-13

**Andy** - *09:32:09*

what's the best practice way of going about my use case -&gt;

For my strategy, I need to always have the marketID and selectionID readily available for all AU Horse Races. I see I can poll the API with a max of 100 results, which I have filtered by AU Horse Racing. This gets me the next 100 races in AU but it doesn't get me where I need to be.

Are Betfair marketIDs always sequential? Is it possible to use filters.market_filter() to return any marketID's &gt; the max(marketID) I polled? or

any better/working way to go about every so often retrieving the marketID's and selectionID's for any 'new' markets created

*Tags: Strategies*

---

**liam** - *10:12:02*

Why aren't you streaming?

*Tags: General Technical*

---

**liam** - *10:37:18*

[https://betcode-org.github.io/betfair/streaming/](https://betcode-org.github.io/betfair/streaming/)

*Tags: General Technical*

---

**liam** - *10:45:04*

are you using flumine yet?

*Tags: General Technical*

---

**Andy** - *10:56:34*

a question to get me moving



1. Do I use betfairlightweight streaming_market_filter and streaming_market_data_filter just to get market data  (IDs) and then I use flumine on another stream to get selection data or

2. Can I get everything with flumine and I don't need betfairlightweight

3. I should do something else

*Tags: General Technical*

---

**liam** - *10:57:54*

1. Streaming gives you everything a MarketBook request gives you (and more) so has the selection data

2. Flumine uses betfairlightweight under the hood 

*Tags: General Technical*

---

## 2023-01-14

**Guy Incognito** - *02:00:28*

Has anyone ever encountered the issue

`AttributeError: 'LimitOnCloseOrder' object has no attribute 'price_ladder_definition'`



When running simulations in flumine

*Tags: Errors Debugging*

---

**liam** - *06:40:30*

I think [@UUCD6P13J](@UUCD6P13J) fixed this in latest version 

*Tags: Errors Debugging*

---

**Guy Incognito** - *07:13:37*

Yep, that fixed it. Thanks

*Tags: Errors Debugging*

---

**Andy** - *08:09:18*

Struggling to get a lot of the selection data with streaming I was able to get before, basic stuff like selection name and saddlecloth number 

*Tags: General Technical*

---

**Andy** - *08:10:07*

Is this not accurate what it says about streaming here? 

*Tags: General Technical*

---

**Andy** - *08:11:51*

And if it is accurate, is there are way to get all ‘new’ market data by polling, even if there was currently 400 Aus horse races active on side. Right now I just know how to get the next 100 (max)

*Tags: General Technical*

---

**liam** - *10:05:43*

Thought you just wanted id’s? You will need to make catalogue requests for the names / metadata but you can use the marketIds received from streaming to do this or just use flumine and it does it all for you 

*Tags: General Technical*

---

**Andy** - *11:00:29*

Yea I actually need to match the clothnumber and selectionName to know which selectionID. All good with this now I think using flumine, thx 

*Tags: General Technical*

---

## 2023-01-16

**liam** - *11:10:46*

This is very tricky to isolate however the only regression I can find is that the simulation engine will now continue to match when an order is in a 'CANCELLING'/'REPLACING'/'UPDATING' state which is theoretically more accurate to live, can you try running `1.21` with the following patch to confirm this is what is causing the differences



```from flumine.markets.middleware import SimulatedMiddleware

from flumine.order.order import OrderStatus





def __process_simulated_orders(self, market, market_analytics: dict) -&gt; None:

    for order in market.blotter.live_orders:

        if order.status == OrderStatus.EXECUTABLE and order.simulated:

            runner_analytics = market_analytics[

                (order.selection_id, order.handicap)

            ]

            order.simulated(market.market_book, runner_analytics.traded)





SimulatedMiddleware._process_simulated_orders = __process_simulated_orders



# your code```

*Tags: Deployment*

---

## 2023-01-18

**James** - *10:24:53*

Making my first venture into flumine using the marketrecorder ([https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py|https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py](https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py|https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py)). I get a “no module named strategies” error even though I’ve installed all the dependencies. What am I doing wrong?

*Tags: Getting Started, Errors Debugging*

---

**D** - *10:30:31*

Do you have a folder called strategies that contains a marketrecorder python file?

*Tags: General Technical*

---

**D** - *10:55:20*

From what I can see, that is why you are getting the error, it is expecting to find a folder called strategies containing the marketrecorder file

*Tags: Errors Debugging*

---

**dont** - *13:55:25*

How did you get the code ? If you just pip installed flumine and tried to run the code, it won’t work as the examples are not part of the python package:



[https://github.com/betcode-org/flumine/blob/master/setup.py#L22](https://github.com/betcode-org/flumine/blob/master/setup.py#L22)



You can fork/pull and get the code locally after which you’ll be able to run it.

*Tags: Getting Started*

---

## 2023-01-19

**Unknown** - *12:19:14*

Hello.



I created a logic for place bet below to min size. It is work fine for market enter and for exit market in lay when the size reduction is below 4.2 (Brazilian currency). But when size reduction is above i receive the imagem error.



Is there any limit for price reduction in cancel_order method?



Many thanks for helping in this case.

*Tags: Errors Debugging*

---

## 2023-01-22

**foxwood** - *19:26:47*

Is the simulation supposed to delete completed bets when a non-runner / reserve is declared on uk dogs prior to the off ? Investigated a divide by zero bug of mine in a strategy which arose with a REMOVED runner that had an EXECUTION_COMPLETE order in market.blotter that predated the runner removal time - there were other runners bets also in the blotter from before the removal time. Confused about what should happen but current T&amp;Cs say "If a non-runner or reserve runner is declared, then all bets prior to the update of the market on Betfair will be void". Never checked what happens live !

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2023-01-23

**liam** - *09:28:26*

Unless I am misunderstanding the question, we do void [https://github.com/betcode-org/flumine/blob/4a52d52899de4ee153d4a1774e2e7384e043dff9/flumine/markets/middleware.py#L85|orders](https://github.com/betcode-org/flumine/blob/4a52d52899de4ee153d4a1774e2e7384e043dff9/flumine/markets/middleware.py#L85|orders)

*Tags: General Technical*

---

**liam** - *09:34:55*

I am suddenly getting a flumine instance dying at 04:55 almost every morning, from memory betfair do some currency calculations at around this time? Anyone else?

*Tags: Performance*

---

**foxwood** - *10:55:16*

Think it might have been a thread timing / sequence issue ? Did go through the blotter code (and checked latest version since am running 2.0.1 !). In `check_market_book` I walk the orders in `for order in market.blotter:` The order was in that set although the runner status was `REMOVED` Looking at the simulated packet time this situation arose on the first data packet milliseconds after the removal timestamp. My guess was that the order thread hadn't got round to dealing with this yet and that the strategy had got there first and saw this as a good order. Since [@U9JHLMZB4](@U9JHLMZB4) confirmed what should happen I put some defensive code `if not self.isActiveRunner(market_book, order.selection_id): continue` in the loop to check and this solved the issue.

*Tags: Strategies*

---

## 2023-01-27

**Jose Maquia** - *04:19:35*

Hi guys, I'm having a problem with a project I'm working on. I'm using Flumine to get information from greyhound and horse racing data. I was able to get the data available on the Stream API but when I try to stream both (horses and greyhounds) at once I get an error saying I have too many connections (MAX_CONNECTION_LIMIT_EXCEEDED). What's the right way to achieve this?

*Tags: Errors Debugging*

---

**Jose Maquia** - *04:21:10*

would appreciate some help :smile:

*Tags: General Technical*

---

**Andy** - *11:35:29*

I tried this myself the other day and it said max 2 connections allowed. One market filter with flumine uses 2 connections alone. When I tried to do 2 separate market filters (one for dogs and one for horses, same as Jose) the response came that that it wouldn’t start the other connection as I was already over the limit…

*Tags: General Technical*

---

## 2023-01-30

**Mikkel** - *20:47:39*

Does anyone know how I can use betfairlightweight as a Dane? I get this error: LoginError: API login: DANISH_AUTHORIZATION_REQUIRED



But can login in through Betfair API using SSOID

*Tags: Errors Debugging*

---

## 2023-02-07

**liam** - *09:46:15*

How do you normally access the API? From memory you are blocked from automating the actual login so you would have to:



```trading = betfairlightweight.APIClient("username", "password", app_key="appKey")



trading.set_session_token("SSOID")```

*Tags: Performance, Strategies*

---

**liam** - *09:47:51*

or maybe a dict? [https://github.com/betcode-org/betfair/blob/71c8fe2acdd20c9d65663e5a5af7692267489e81/examples/exampleone.py#L53](https://github.com/betcode-org/betfair/blob/71c8fe2acdd20c9d65663e5a5af7692267489e81/examples/exampleone.py#L53)

*Tags: General Technical*

---

**Paras Stefanopoulos** - *09:51:08*

Nope, errors if they’re not strings

*Tags: Errors Debugging*

---

**Paras Stefanopoulos** - *09:51:15*

v annoying! ty for help

*Tags: General Technical*

---

**Paras Stefanopoulos** - *09:52:04*

my devised strategy isn’t time bound so just trying to keep it simple to do some testing

*Tags: Strategies*

---

**Paras Stefanopoulos** - *10:41:53*

Will be purchasing a live key tomorrow so hopefully solves my problems

*Tags: Deployment*

---

**Mikkel** - *16:54:40*

Doing this still gives me the same error..



payload = 'username=' + my_username + '&amp;password=' + my_password

headers = {'X-Application': my_app_key, 'Content-Type': 'application/x-www-form-urlencoded'}

resp = [http://requests.post|requests.post](http://requests.post|requests.post)('[https://identitysso-cert.betfair.com/api/certlogin',data=payload,cert=('BetfairApp1.crt','BetfairApp1.pem'),headers=headers](https://identitysso-cert.betfair.com/api/certlogin',data=payload,cert=('BetfairApp1.crt','BetfairApp1.pem'),headers=headers))

json_resp=resp.json()

SSOID = "******"



but I can login using this?

*Tags: Errors Debugging*

---

## 2023-02-11

**Mikkel** - *16:50:25*

Hi all,



No matter what I do to try to connect to the API using Betfairlightweight I keep getting :



```LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE```

I have tried to change my password multiple times, but I get the same error?

*Tags: Errors Debugging*

---

**Mikkel** - *19:18:02*

Thanks Foxwood. I have read the BF docs and recovered the password, multiple times... still same issues.



Liam,



I am trying to login using the following:



username = "[mailto:mikkelwr@icloud.com|m](mailto:mikkelwr@icloud.com|m)y email address"



password = "***"



app_key = "***"









trading = betfairlightweight.APIClient(username = "username" , password = "password", app_key = "app_key", certs='/Applications/xca')



resp = [http://trading.session.post|trading.session.post](http://trading.session.post|trading.session.post)(

    url=trading.login_interactive.url,

    data={

        "username": trading.username,

        "password": trading.password,

        "redirectMethod": "POST",

        "product": trading.app_key,

        "url": "[https://www.betfair.com](https://www.betfair.com)",

        "submitForm": True,

    }

)



session_token = "****"















print(trading.betting.list_event_types())

*Tags: Strategies*

---

**Mikkel** - *19:39:49*

Correct, but I am using the approach outlined in betfairlightweight docs



[https://betcode-org.github.io/betfair/advanced/#nemid-login](https://betcode-org.github.io/betfair/advanced/#nemid-login)

*Tags: General Technical*

---

**liam** - *19:44:41*

I think it got blocked, hence the cryptic error message you are now getting 

*Tags: Errors Debugging*

---

## 2023-02-12

**Andy B** - *00:47:07*

Hi All,



I am trying to get to the bottom of Betfair connection issues which have cropped up in the last week.  I have a feeling it is because of the way I have implemented by strategies, because I am running 6 separate scripts which all do repeated logins to Betfair.  The error that has been randomly appearing this week is:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request

    self._validate_conn(conn)

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn

    conn.connect()

  File "C:\Python\lib\site-packages\urllib3\connection.py", line 414, in connect

    self.sock = ssl_wrap_socket(

  File "C:\Python\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket

    ssl_sock = _ssl_wrap_socket_impl(

  File "C:\Python\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl

    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)

  File "C:\Python\lib\ssl.py", line 500, in wrap_socket

    return self.sslsocket_class._create(

  File "C:\Python\lib\ssl.py", line 1040, in _create

    self.do_handshake()

  File "C:\Python\lib\ssl.py", line 1309, in do_handshake

    self._sslobj.do_handshake()

socket.timeout: _ssl.c:1105: The handshake operation timed out



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\requests\adapters.py", line 489, in send

    resp = conn.urlopen(

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen

    retries = retries.increment(

  File "C:\Python\lib\site-packages\urllib3\util\retry.py", line 550, in increment

    raise six.reraise(type(error), error, _stacktrace)

  File "C:\Python\lib\site-packages\urllib3\packages\six.py", line 770, in reraise

    raise value

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen

    httplib_response = self._make_request(

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 389, in _make_request

    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 340, in _raise_timeout

    raise ReadTimeoutError(

urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 36, in request

    response = [http://session.post|session.post](http://session.post|session.post)(

  File "C:\Python\lib\site-packages\requests\api.py", line 115, in post

    return request("post", url, data=data, json=json, **kwargs)

  File "C:\Python\lib\site-packages\requests\api.py", line 59, in request

    return session.request(method=method, url=url, **kwargs)

  File "C:\Python\lib\site-packages\requests\sessions.py", line 587, in request

    resp = self.send(prep, **send_kwargs)

  File "C:\Python\lib\site-packages\requests\sessions.py", line 701, in send

    r = adapter.send(request, **kwargs)

  File "C:\Python\lib\site-packages\requests\adapters.py", line 578, in send

    raise ReadTimeout(e, request=request)

requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Users\elmob\OneDrive\Punting\Scripts\Betfair\Model6.py", line 649, in &lt;module&gt;

    GetBFRunners()

  File "C:\Users\elmob\OneDrive\Punting\Scripts\Betfair\Model6.py", line 164, in GetBFRunners

    greyhounds_events = trading.betting.list_events(

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\betting.py", line 123, in list_events

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 45, in request

    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listEvents

Params: {'filter': {'eventTypeIds': [4339], 'marketCountries': ['AU', 'NZ'], 'marketStartTime': {'to': '2023-02-14T00:24:32Z'}}}

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)



To clarify how my scripts run, they all begin by creating the betfair login using:

trading = betfairlightweight.APIClient(username=my_username,

                                    password=my_password,

                                    app_key=my_app_key,

                                    certs=certs_path)



trading.login()



I then get my list of races and runners from Betfair using a custom function, and I suspect this is where it is falling over every time.  I've got a hunch that when I call the BFLW functions within betting.py, the fact that I am calling the same methods multiple times across the 6 scripts is causing it to timeout because it is too many attempts or too much data requested from Betfair.



Does this sound logical or is there something else in the error code that points to the issue?  If it is the problem, what is the best method of implementing my code to manage multiple different strategies with their own independent methods in my code?



Cheers

*Tags: Errors Debugging, Deployment, Strategies*

---

**Unknown** - *04:25:18*

Hmm now have the live api key, still problems using the api, unless I’m mis-interpreting the documentation. Essentially want to know the amount traded at each order level, not sure why orders and traded are coming back empty, regardless of the market. In this example I’ve picked a market with &gt;$50k traded, so should definitely have data for me :thinking_face:

*Tags: Deployment*

---

**liam** - *06:34:31*

Sounds like you are not catching errors, you will get errors.



Why aren’t you streaming? Why aren’t you using flumine?

*Tags: Errors Debugging*

---

**Andy B** - *06:48:55*

Thanks Liam, I knew that I needed to get across to Flumine at some point and this might be the clincher.  I have always prioritised worki g on building profitable models, but I do need to take a step back and take a more holistic view of my environment.

I do catch errors for most of my code, but I hadn't wrapped anything around this.  I think i'll do that as the first step while I look at how I migrate my code across to flumine and whatever changes that requires within my code.

*Tags: Errors Debugging, Strategies*

---

**liam** - *06:55:51*

It’s exactly what flumine is designed for, you can focus on the :moneybag: :moneybag: 

*Tags: General Technical*

---

## 2023-02-21

**Jose Maquia** - *21:52:13*

I am trying to get information from the Stream API and I'm getting no information from greyhounds when filtering for both horse racing and greyhound, also creating 2 connections in the same script (subscribing the stream twice (once per filter) with stream.subscribe_to_markets() only returns data for horse racing and when I tried just greyhound it didn't return any data)



My filters are:

    horse_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["WIN"]

    )

    greyhound_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["4339"],

        country_codes=["AU"],

        market_types=["WIN"]

    )



The second one doesn't receive any data to the queue

*Tags: General Technical*

---

**Lee** - *22:22:26*

How are you equating no data? Do you receive the snapshot or just no updates? Are you assigning both filters to a strategy? Greyhound markets hours before are thin, there can be a big gaps between updates

*Tags: Strategies*

---

## 2023-02-24

**Jose Maquia** - *02:09:28*

I'm not using flumine, I'm using betfairlightweight, so using stream.subscribe_to_markets(). Subscribing to both doesn't work. And creating 2 streams didn't work either

*Tags: General Technical*

---

**Jose Maquia** - *02:11:18*

I'm not sure if I can do that or I should start 2 streams, because I am pretty sure Flumine starts 2 streams

*Tags: General Technical*

---

**EJono** - *09:17:55*

I have a function set up to pull through cleared orders from record that started to fail on the 15th. Nothing has changed about the function which executes 3 times a day, depsite it working for weeks prior. This code executes in a loop with "iteration" being incremented from 0, 1, 2, 3, ... while the returned moreAvailable firled is True.



bet_status = 'SETTLED'

group_by = 'BET'

from_record = iteration *100

record_count = (iteration+1) *100



orders = trading.betting.list_cleared_orders(

            group_by=group_by,

            bet_status=bet_status,

            from_record=from_record,

            record_count=record_count,

            lightweight=True,



        )



The full exception is quite long but the final traceback handled states the following:



Traceback (most recent call last):

  File "/mnt/syndicate_middleware/adjustFunctions/betfairLadderOperations.py", line 1290, in getFilteredClearedOrders

    orders = trading.betting.list_cleared_orders(

             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/betting.py", line 434, in list_cleared_orders

    (response, response_json, elapsed_time) = self.request(method, params, session)

                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 45, in request

    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders

Params: {'betStatus': 'SETTLED', 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'BET', 'fromRecord': '0', 'recordCount': '100'}

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=16)



Ive tried messing with the parameters  ie reducing volume records requested in each call but nothing seems to be solving this issue. From docemunetation you should be able to retrieve up to 1000 records at a time. Current order requests still work fine. Anything obvious im missing for succesfully retrieving the cleared orders from record?

*Tags: Errors Debugging, Strategies*

---

**Mo** - *09:29:24*

Use the `read_timeout` attribute of `betting`: [https://github.com/betcode-org/betfair/blob/00e9abb2b4d228408eea1620cbeb55cbaed0e0c6/betfairlightweight/endpoints/baseendpoint.py#L15](https://github.com/betcode-org/betfair/blob/00e9abb2b4d228408eea1620cbeb55cbaed0e0c6/betfairlightweight/endpoints/baseendpoint.py#L15)

*Tags: Strategies*

---

**Newbie99** - *10:13:15*

This error just randomly seems to happen from time to time, normally if you try again later it’s fine.

*Tags: Errors Debugging*

---

**EJono** - *10:50:54*

[@UBS7QANF3](@UBS7QANF3) altering the time out value has worked in this scenario thank you for pointin me in towards the documentation!



[@UFTBRB3F1](@UFTBRB3F1) I have noticed this too from time to time and handle it appropraitely. In this case my requests were consistently failing over a number of different time frames and parameter submissions. Hence me retreating to this slack group where all is quickly explained :100:

*Tags: General Technical*

---

**Jose Maquia** - *17:53:28*

It does not return data for greyhounds that way, mind that I'm using betfairlightweight, I am not opening the stream with Flumine.

*Tags: General Technical*

---

## 2023-02-27

**thambie1** - *11:40:50*

Using AWS?

*Tags: Deployment*

---

**foxwood** - *13:18:30*

There's a level 2 in Dublin that might help [http://ntp.maths.tcd.ie|ntp.maths.tcd.ie](http://ntp.maths.tcd.ie|ntp.maths.tcd.ie) details at [https://support.ntp.org/Servers/PublicTimeServer000073](https://support.ntp.org/Servers/PublicTimeServer000073)

*Tags: Deployment*

---

**D C** - *13:53:00*

Suppose someone does not sync their clock - what problems arise? Is it simply a problem with being unable to identify streaming lag?

*Tags: General Technical*

---

## 2023-03-06

**jp** - *06:37:41*

A few times every week I have gotten the following exception when calling Betfair API lately:



The SSL connection could not be established, see inner exception.

 ---&gt; System.Security.Authentication.AuthenticationException: Authentication failed because the remote party sent a TLS alert: 'DecryptError'.

 ---&gt; System.ComponentModel.Win32Exception (0x80090326): The message received was unexpected or badly formatted.



I am not using Flumine/Betcode, but my own C# code. This happens when calling placeOrders or cancelOrders (and maybe others). I could send thousands of working requests before and after this, and ignoring it seems to work out ok. But it would be nice to understand what it is about. Anyone else seen it?

*Tags: Errors Debugging, Strategies*

---

## 2023-03-11

**Paul** - *18:10:25*

I have a newb-style question. I've used bflw a _lot_ in recent years and now moving to flumine (how about them API charges, huh?), and one of my strategies needs to know for each selection both the matched/`OrderStatus.EXECUTED` and live/`OrderStatus.EXECUTABLE` orders broken down by side of market (back/lay).  There's nothing I spotted in docs or examples about best way to access the blotter directly, just the middleware to enable filling out `OrderStatus.EXECUTED` on restart. It seems I can either build this info myself into new objects for each runner on `process_orders` and then access that when processing the market book, (which seems expensive and weird), or by iterating over `RunnerContext.trades` when inside `process_market_book` - this also seems a little weird. Can somebody ELI5 what I'm missing or advise on cheapest route?

*Tags: Deployment*

---

## 2023-03-12

**Sunken** - *11:53:34*

Hey, fairly new to working with betfairlightweight/flumine so this might be a dumb question, but I was looking at the difference in total_volume for each race calculated via totalling the price ladders you get from the runnerEX classes, vs just parsing the json files directly, and noticed they were pretty sizeable.



Looking closer, I realised part of the reason was that even if the market update stated that there was an amount traded, and both the runnerEX class and my dictionary parser would pick up on it, afterwards for certain updates the runnerEX class would drop those values. In other cases, it would pick up trades that were not there. Is there a reason for this? Dived into the source code for a few hours but not really any closer to a solution.

*Tags: Getting Started*

---

**foxwood** - *12:01:34*

Tracing back some oddball issues from the other day I discovered missing data for some markets. The logs showed connection issues with number of markets when BF published the next days GH races. I had 188 markets in the cache (rest of day + the next day). It looks like BF closed the connection for some reason (?) so Flumine automatically opened another stream but the number of markets ticked over the 200 limit. This kept repeating until 5 more markets had been closed and the count got down to 200. Any workaround for this ?



```{"asctime": "2023-03-09 19:30:47,754", "levelname": "INFO", "message": "[MarketStream: 1002] 1.211067730 removed, 188 markets in cache"}



{"asctime": "2023-03-09 19:32:40,581", "levelname": "INFO", "message": "Created marketCatalogue for 1.211115814", "market_id": ...}

{"asctime": "2023-03-09 19:32:40,581", "levelname": "INFO", "message": "Created marketCatalogue for 1.211115887", "market_id": ...}



{"asctime": "2023-03-09 19:37:27,776", "levelname": "ERROR", "message": "DataStream 1002 run error", "exc_info": "Traceback (most recent call last):\n  raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 1003]: Connection closed by server"}

{"asctime": "2023-03-09 19:37:29,784", "levelname": "INFO", "message": "Starting DataStream 1002", "stream_id": 1002, "market_filter": {"eventTypeIds": ["4339"], "marketTypes": ["WIN"], "countryCodes": ["GB"]}, "market_data_filter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "conflate_ms": null}

{"asctime": "2023-03-09 19:37:29,784", "levelname": "INFO", "message": "[Register: 1003]: Unique id updated on listener and stream"}

{"asctime": "2023-03-09 19:37:29,831", "levelname": "INFO", "message": "[FlumineStream: 1003]: connection_id: 208-090323193730-4882826"}

{"asctime": "2023-03-09 19:37:29,862", "levelname": "INFO", "message": "[FlumineStream: 1004]: SUCCESS (5 connections available)"}

{"asctime": "2023-03-09 19:37:29,894", "levelname": "ERROR", "message": "[FlumineStream: 1003]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 205 markets whereas max allowed number was: 200"}

{"asctime": "2023-03-09 19:37:29,894", "levelname": "INFO", "message": "[FlumineStream: 1003]: FAILURE (5 connections available)"}

{"asctime": "2023-03-09 19:37:45,417", "levelname": "ERROR", "message": "[FlumineStream: None]: TIMEOUT: Connection is not subscribed and is idle: 15000 ms"}

{"asctime": "2023-03-09 19:37:45,417", "levelname": "ERROR", "message": "DataStream 1003 run error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\PycharmProjects\\betfair1\\venv\\lib\\site-packages\\flumine\\streams\\datastream.py\", line 166, in run\n        raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 208-090323193730-4882826, data: {\"op\":\"status\",\"statusCode\":\"FAILURE\",\"errorCode\":\"TIMEOUT\",\"errorMessage\":\"Connection is not subscribed and is idle: 15000 ms\",\"connectionClosed\":true,\"connectionId\":\"208-090323193730-4882826\"}"}```

*Tags: Errors Debugging, Deployment*

---

**foxwood** - *12:50:18*

Done that thanks - seems to happen most days on uk dogs if the connection is lost or start a new strategy running around 19:30 - 20:00 ish. So many markets open at the same time.

*Tags: Strategies*

---

**Mo** - *13:41:44*

Live data? Self recorded? Betfair historic?

*Tags: Deployment*

---

## 2023-03-13

**Mo** - *08:34:39*

Are you setting the Listener arguments appropriately? [https://github.com/betcode-org/betfair/blob/4d7c38bd8b75183fbc46637abcabb8954ef00593/betfairlightweight/streaming/listener.py#L107-L108](https://github.com/betcode-org/betfair/blob/4d7c38bd8b75183fbc46637abcabb8954ef00593/betfairlightweight/streaming/listener.py#L107-L108)

*Tags: General Technical*

---

**Sunken** - *11:16:00*

Still having issues. Putting in some of the code I used to test the difference

```test_file_path=F'{start_path}PRO_2020_Apr_10_29766007_1.170279955.txt'

data_dump=open(test_file_path,"r")

json_dump=data_dump.readlines()



listener = betfairlightweight.StreamListener(max_latency=None,calculate_market_tv=True,cumulative_runner_tv=True)



stream = trading.streaming.create_historical_generator_stream(

    file_path=test_file_path,

    listener=listener,

)



gen =stream.get_generator()

market_booksList=list(gen())



total_traded=0



for i,update in enumerate(json_dump):

    if i == 0: # No price info

        continue

    betfair_dataDict=json.loads(update)

    trade_changeList=betfair_dataDict['mc'][0]['rc']



    for changeDict in trade_changeList:

            if 'trd' in changeDict:

                total_traded += changeDict['tv']

    total_traded_blw=market_booksList[i][0].total_matched

    if abs(total_traded - total_traded_blw) &gt;0.1:

         print(total_traded, "basic")

         print(total_traded_blw, "blw")

         print(i)```

*Tags: Performance, Strategies*

---

**Sunken** - *12:57:43*

Figured it out while I was going through the print statements. Basically comes down to me not understanding how betfair relays traded volumes, i.e. the json updates are cumulative for traded totals.



Thanks for your help on this

*Tags: General Technical*

---

## 2023-03-16

**D C** - *10:20:05*

I get the problem because I like an "open" stream where I respond to any new markets on the stream. I subsequently call listMarketCatalogue to get the market info - but I keep getting left with this solitary market that I can't update because the resulting listMarketCat call contains no markets (which makes sense)

*Tags: General Technical*

---

## 2023-03-17

**Kosta Pana** - *10:09:44*

Morning friends - has anyone tried to set up heartbeats on order streaming, using the betfair lightweight "subscribe_to_orders" method (with heartbeat_ms=500)?  I've set up a queue for receiving updates using the "get" method with a timeout of 2 seconds, and I receive order updates just fine, but never any heartbeats when there are no orders - instead I always timeout. Thanking in advance for any help!

*Tags: General Technical*

---

**Andrew** - *10:38:38*

Hi, I'm just trying to get started and I've been trying to get the ExampleStrategy on the flumine documentation to work



It seems to be getting to the start bit, but then gets stuck creating the streams (gets stuck on line 427 of baseflumine.py)



self.streams.start()



I thought it was because I had a delayed API key which didn't have streaming permissions, but betfair get me permissions, but it still isn't working



Does anyone know what might be the issue?



Thanks

*Tags: Strategies*

---

**liam** - *10:39:31*

Heartbeats aren't sent through the queue but if you set your logging to debug you should see them

*Tags: Errors Debugging*

---

**Andrew** - *10:45:39*

2023-03-16 20:59:02,419:INFO:Starting streams..

2023-03-16 20:59:02,419:INFO:Starting SimulatedOrderStream 1000

2023-03-16 20:59:02,419:INFO:Starting MarketStream 2000

2023-03-16 20:59:02,419:INFO:Starting output_thread (MarketStream 2000)

2023-03-16 20:59:02,419:INFO:[Register: 2001]: marketSubscription

2023-03-16 20:59:02,419:INFO:[MarketStream: 2001]: "MarketStream" created

2023-03-16 20:59:02,497:INFO:[MarketStream: 2001]: connection_id: 105-160323205902-5809353

2023-03-16 20:59:02,513:ERROR:MarketStream 2001 run error

*Tags: Errors Debugging*

---

**Kosta Pana** - *10:52:27*

Thanks very much Liam - I will have a try with setting logging to debug.



Do you know if setting logging to debug has any performance cost? Otherwise what is the best way to detect if a stream breaks down?

*Tags: Errors Debugging, Performance*

---

**Andrew** - *11:06:50*

Connected to pydev debugger (build 191.7479.30)

{"asctime": "2023-03-17 10:56:16,147", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2023-03-17 10:56:16,147", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2023-03-17 10:56:16,148", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}

{"asctime": "2023-03-17 10:56:16,148", "levelname": "INFO", "message": "Adding strategy back_strat_42"}

{"asctime": "2023-03-17 10:56:16,148", "levelname": "INFO", "message": "Creating new &lt;class 'flumine.streams.marketstream.MarketStream'&gt; (2000) for strategy back_strat_42"}

{"asctime": "2023-03-17 10:56:16,148", "levelname": "INFO", "message": "Starting flumine", "clients": {"username": "", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": null, "transaction_count_total": null, "trading_controls": [], "order_stream": true, "best_price_execution": true, "paper_trade": false}, "markets": {"market_count": 0, "open_market_count": 0}, "streams": ["&lt;OrderStream(OrderStream, initial daemon)&gt;", "&lt;MarketStream(MarketStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 18028)&gt;", "&lt;WriterThread(pydevd.Writer, started daemon 11888)&gt;", "&lt;ReaderThread(pydevd.Reader, started daemon 14476)&gt;", "&lt;PyDBCommandThread(pydevd.CommandThread, started daemon 8612)&gt;"]}

{"asctime": "2023-03-17 10:56:16,293", "levelname": "ERROR", "message": "BetfairClient `login` error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\clients\\betfairclient.py\", line 29, in login\n    return self.betting_client.login()\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\betfairlightweight\\endpoints\\login.py\", line 31, in __call__\n    self.url, session=session\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\betfairlightweight\\endpoints\\login.py\", line 57, in request\n    check_status_code(response)\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\betfairlightweight\\utils.py\", line 34, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 500", "client": "APIClient", "trading_function": "login", "response": "Status code error: 500"}

{"asctime": "2023-03-17 10:56:16,509", "levelname": "INFO", "message": "Adding worker keep_alive"}

{"asctime": "2023-03-17 10:56:16,509", "levelname": "INFO", "message": "Adding worker poll_market_catalogue"}

{"asctime": "2023-03-17 10:56:16,510", "levelname": "INFO", "message": "Adding worker poll_account_balance"}

{"asctime": "2023-03-17 10:56:16,510", "levelname": "INFO", "message": "Adding worker poll_market_closure"}

{"asctime": "2023-03-17 10:56:16,512", "levelname": "INFO", "message": "BackgroundWorker keep_alive starting", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x000001823546B268&gt;", "context": {}, "start_delay": 0, "interval": 1200, "func_args": [], "func_kwargs": {}}

{"asctime": "2023-03-17 10:56:16,513", "levelname": "ERROR", "message": "Error in BackgroundWorker keep_alive: 'Flumine' object has no attribute 'clients'", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 65, in run\n    self.context, self.flumine, *self.func_args, **self.func_kwargs\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 97, in keep_alive\n    for client in flumine.clients:\nAttributeError: 'Flumine' object has no attribute 'clients'", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x000001823546B268&gt;", "context": {}}

{"asctime": "2023-03-17 10:56:16,514", "levelname": "INFO", "message": "BackgroundWorker poll_market_catalogue starting", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x000001823546B378&gt;", "context": {}, "start_delay": 10, "interval": 60, "func_args": [], "func_kwargs": {}}

{"asctime": "2023-03-17 10:56:16,516", "levelname": "INFO", "message": "BackgroundWorker poll_account_balance starting", "worker_name": "poll_account_balance", "function": "&lt;function poll_account_balance at 0x000001823546B400&gt;", "context": {}, "start_delay": 10, "interval": 120, "func_args": [], "func_kwargs": {}}

{"asctime": "2023-03-17 10:56:16,518", "levelname": "INFO", "message": "BackgroundWorker poll_market_closure starting", "worker_name": "poll_market_closure", "function": "&lt;function poll_market_closure at 0x000001823546B488&gt;", "context": {}, "start_delay": 10, "interval": 60, "func_args": [], "func_kwargs": {}}

{"asctime": "2023-03-17 10:56:16,520", "levelname": "INFO", "message": "Starting streams.."}

{"asctime": "2023-03-17 10:56:16,521", "levelname": "INFO", "message": "Starting OrderStream 1000", "stream_id": 1000, "customer_strategy_refs": "LAPTOP-SDCL040E", "conflate_ms": null, "streaming_timeout": 0.25, "client_username": ""}

{"asctime": "2023-03-17 10:56:16,522", "levelname": "INFO", "message": "Starting output_thread (OrderStream 1000)"}

{"asctime": "2023-03-17 10:56:16,523", "levelname": "INFO", "message": "[Register: 1001]: orderSubscription"}

{"asctime": "2023-03-17 10:56:16,524", "levelname": "INFO", "message": "[OrderStream: 1001]: \"OrderStream\" created"}

{"asctime": "2023-03-17 10:56:16,590", "levelname": "INFO", "message": "[OrderStream: 1001]: connection_id: 209-170323105616-5848216"}

{"asctime": "2023-03-17 10:56:16,622", "levelname": "INFO", "message": "[OrderStream: 1002]: SUCCESS (1 connections available)"}

{"asctime": "2023-03-17 10:56:16,626", "levelname": "INFO", "message": "[OrderStream: 1001]: SUCCESS (1 connections available)"}

{"asctime": "2023-03-17 10:56:16,658", "levelname": "INFO", "message": "[OrderStream: 1001]: 0 oc added"}

{"asctime": "2023-03-17 10:56:16,780", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:16,781", "levelname": "INFO", "message": "Starting output_thread (MarketStream 2000)"}

{"asctime": "2023-03-17 10:56:18,785", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:20,794", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:24,811", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:26,530", "levelname": "ERROR", "message": "Error in BackgroundWorker poll_market_catalogue: 'Flumine' object has no attribute 'clients'", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 65, in run\n    self.context, self.flumine, *self.func_args, **self.func_kwargs\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 113, in poll_market_catalogue\n    client = flumine.clients.get_betfair_default()\nAttributeError: 'Flumine' object has no attribute 'clients'", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x000001823546B378&gt;", "context": {}}

{"asctime": "2023-03-17 10:56:26,531", "levelname": "ERROR", "message": "Error in BackgroundWorker poll_account_balance: 'Flumine' object has no attribute 'clients'", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 65, in run\n    self.context, self.flumine, *self.func_args, **self.func_kwargs\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 155, in poll_account_balance\n    for client in flumine.clients:\nAttributeError: 'Flumine' object has no attribute 'clients'", "worker_name": "poll_account_balance", "function": "&lt;function poll_account_balance at 0x000001823546B400&gt;", "context": {}}

{"asctime": "2023-03-17 10:56:26,532", "levelname": "ERROR", "message": "Error in BackgroundWorker poll_market_closure: 'Flumine' object has no attribute 'clients'", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 65, in run\n    self.context, self.flumine, *self.func_args, **self.func_kwargs\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 166, in poll_market_closure\n    for client in flumine.clients:\nAttributeError: 'Flumine' object has no attribute 'clients'", "worker_name": "poll_market_closure", "function": "&lt;function poll_market_closure at 0x000001823546B488&gt;", "context": {}}

{"asctime": "2023-03-17 10:56:32,822", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:48,827", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

*Tags: Errors Debugging, Deployment, Strategies*

---

**Andrew** - *11:09:52*

Yea I'm using the examples-single.py



Is it this line:



trading = betfairlightweight.APIClient("username")



?

*Tags: Strategies*

---

**liam** - *11:10:33*

[https://github.com/betcode-org/flumine/blob/master/examples/example-single.py#L66](https://github.com/betcode-org/flumine/blob/master/examples/example-single.py#L66)

*Tags: General Technical*

---

**liam** - *11:12:02*

actually, whats the version of flumine you are using?

*Tags: General Technical*

---

**liam** - *11:56:24*

Use [https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py|this](https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py|this) example but update to use the order stream

*Tags: General Technical*

---

**Kosta Pana** - *14:08:47*

Thank you very much... I got the heartbeats showing with the above template via setting logging to debug. But I wanted to be able to use the heartbeat in my code to handle if the stream disconnects/breaks, not sure how to use it via logging (other than watching it with my eyes lol)

*Tags: Errors Debugging*

---

**liam** - *14:09:53*

why do you want to handle it? setup and forgot [https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py|example](https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py|example)

*Tags: Getting Started*

---

**liam** - *14:16:43*

you found flumine yet?

*Tags: General Technical*

---

**Kosta Pana** - *15:32:18*

yes sir. but already have my own system... flumine probably much better.

*Tags: General Technical*

---

## 2023-03-24

**Greg** - *00:00:34*

Hi All.been away for a while.Hope you are all well. I have ben using a certain Ai engine to help teach me some python and seem to get the odd thing running. I am getting a subscription exceed error :"ERROR", "message": "[MarketStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 19639 markets whereas max allowed number was: 1000"} though, which I have noted has occurred once on this forum in the past I can find and that was referred to BF bdp. They have increases my allowed threshold to 1000 markets but have suggested I limit the market monitoring and/or increase connection threads. Here is the code snippet that looks relevant

```class BookmakerStrategy(BaseStrategy):

    market_filter = streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["GBR", "IRE", "AUS"],

        market_types=["WIN"],

    )



    def check_market_book(self, market, market_book):

        if self.seconds_to_start &gt; 600:  # 10 minutes

            return False

        if market_book.status not in ["CLOSED", "SUSPENDED"]:

            return False



    def __init__(self, market_filter=None):

        super().__init__(market_filter)

        self.race_time = 0

        self.race_started = False```

Any advice appreciated.Cheers

*Tags: Errors Debugging, Strategies*

---

**Lee** - *00:07:30*

Your market filter needs to be in the strategy instantiation 

*Tags: Strategies*

---

**Greg** - *00:18:53*

Added this but same error :

```strategy = BookmakerStrategy()

market_filter=streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["WIN"],

    )

framework.add_strategy(strategy)```



*Tags: Errors Debugging, Strategies*

---

**Lee** - *00:55:42*

Put the filter in the BookmakerStrategy brackets

*Tags: Strategies*

---

## 2023-03-25

**Andy B** - *10:53:04*

Hi All,

I have just created my first flumine strategy after a couple of years of hacking together bflw and my own custom code.  I copied the code from [https://betfair-datascientists.github.io/api/How_to_Automate_3/?h=iggy#scrape-todays-model-ratings](https://betfair-datascientists.github.io/api/How_to_Automate_3/?h=iggy#scrape-todays-model-ratings) and then modified it with my own strategy, which I think has worked successfully, but I have just noticed a lot of errors containing the following:



betfairlightweight.exceptions.ListenerError: connection_id: 102-250323104256-6797689, data: {"op":"status","id":2007,"statusCode":"FAILURE","errorCode":"MAX_CONNECTION_LIMIT_EXCEEDED","errorMessage":"You have exceeded your max connection limit which is: 2 connection(s).You currently have: 3 active connection(s).","connectionClosed":true,"connectionId":"102-250323104256-6797689"}



This is followed by a number of:



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\flumine\streams\orderstream.py", line 51, in run

    self._stream.start()

  File "C:\Python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "C:\Python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\Python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 248, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 1007]: Socket [WinError 10054] An existing connection was forcibly closed by the remote host

2023-03-25 21:13:30,779:INFO:Starting MarketStream 2006

2023-03-25 21:13:30,779:INFO:[Register: 2007]: Unique id updated on listener and stream

2023-03-25 21:13:31,771:INFO:[MarketStream: 2007]: connection_id: 108-250323104330-6863571

2023-03-25 21:13:32,096:ERROR:MarketStream 2007 run error

Traceback (most recent call last):

  File "C:\Python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 244, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "C:\Python\lib\ssl.py", line 1226, in recv

    return self.read(buflen)

  File "C:\Python\lib\ssl.py", line 1101, in read

    return self._sslobj.read(len)

ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host



I only have one instance running, so I am not sure what is generating these errors.  Just wondering if anyone else has experienced this or has some thoughts on what may cause it?

*Tags: Errors Debugging, Strategies*

---

**Lee** - *11:01:41*

the default connection limit for a live key is 10 and the delayed key has a limit of 2 which is the error you are getting so might be worth double checking

*Tags: Errors Debugging, Deployment*

---

**Beeblebrox** - *19:10:28*

I'm having an issue with the blotter function strategy_selection_orders() sometimes not returning any orders even though there have definitely been some orders placed by a strategy on the market. The majority of the time it works, but sometimes it just stops working and I can't work out why. Has anyone else had similar issues? For a bit of context I'm using it for a strategy that places bets on football markets from 12 hours before kick off up to kick off.

*Tags: Strategies*

---

**Beeblebrox** - *19:16:33*

I'm using Flumine v2.3.2

*Tags: General Technical*

---

## 2023-03-26

**Andy B** - *05:13:42*

I have my first flumine strategy running and I was going to test with small stakes, but I am getting the error "Order has violated: ORDER_VALIDATION Error: Order price is not valid for CLASSIC ladder".  I am only guessing that it has something to do with the stake size, which works quite fine in bflw, but I'm not 100% sure, so just wondering if this rings a bell with anyone else?

*Tags: Errors Debugging, Strategies*

---

**Andy B** - *05:16:12*

Ah rookie error, I'm passing an invalid price.

*Tags: Errors Debugging*

---

**birchy** - *13:03:29*

`get_nearest_price()` in Flumine utils is useful here. And also `price_ticks_away()`

*Tags: General Technical*

---

## 2023-03-27

**Andy B** - *23:35:56*

One more error I noted in my ogs: Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (5) or payout (30) for currency.  Is this configurable in Flumine as my minimum bet sizes have been lowered by Betfair?

*Tags: Errors Debugging*

---

## 2023-03-28

**liam** - *09:36:25*

You have `market_book.streaming_update` which is relatively easy to pull out the runners which have changed (simulated middleware does this)

*Tags: General Technical*

---

## 2023-04-02

**Will** - *11:05:01*

Hello. Any reason when placing a trade with flumine that the order would return None. 

The market id, selection id, price and stake are valid, the trade object is created but the order object is None and I get the error “Execution unknown error. 

*Tags: Errors Debugging*

---

**Derek C** - *20:57:46*

if you could share the snippet of code that's not working, it might be easier for people to help...

*Tags: General Technical*

---

## 2023-04-03

**Andy B** - *21:34:47*

I have had my first flumine strategy up and running for about a week and it seems to work well apart from one issue that happens inconsistently.  I'm not sure if it is relevant or not, but the strategy fires when the there is less than 5 seconds to start time and the event has not gone inplay.  I keep getting batches of the following somewhat generic error filling my log file, and I am wondering if this is a common issue that I should be handling in the code with try\catch.  I'd like to know why it happens though, rather than just ignoring it:

2023-04-03 22:02:21,329:CRITICAL:Unknown error '1.212248357' in process_market_book (1.212248357)

Traceback (most recent call last):

  File "C:\Python\lib\site-packages\pandas\core\indexes\base.py", line 3803, in get_loc

    return self._engine.get_loc(casted_key)

  File "pandas\_libs\index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc

  File "pandas\_libs\index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc

  File "pandas\_libs\hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item

  File "pandas\_libs\hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item

KeyError: '1.212248357'



The above exception was the direct cause of the following exception:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\flumine\utils.py", line 239, in call_strategy_error_handling

    return func(market, market_book)

  File "c:\Users\elmob\OneDrive\Punting\Scripts\Betfair\FluStrat.py", line 231, in process_market_book

    ratio_price = iggy_df.loc[market_book.market_id].loc[runner.selection_id].item() / runner.ex.available_to_back[0]['price']

  File "C:\Python\lib\site-packages\pandas\core\indexing.py", line 1073, in __getitem__

    return self._getitem_axis(maybe_callable, axis=axis)

  File "C:\Python\lib\site-packages\pandas\core\indexing.py", line 1312, in _getitem_axis

    return self._get_label(key, axis=axis)

  File "C:\Python\lib\site-packages\pandas\core\indexing.py", line 1260, in _get_label

    return self.obj.xs(label, axis=axis)

  File "C:\Python\lib\site-packages\pandas\core\generic.py", line 4049, in xs

    loc, new_index = index._get_loc_level(key, level=0)

  File "C:\Python\lib\site-packages\pandas\core\indexes\multi.py", line 3160, in _get_loc_level

    indexer = self._get_level_indexer(key, level=level)

  File "C:\Python\lib\site-packages\pandas\core\indexes\multi.py", line 3263, in _get_level_indexer

    idx = self._get_loc_single_level_index(level_index, key)

  File "C:\Python\lib\site-packages\pandas\core\indexes\multi.py", line 2849, in _get_loc_single_level_index

    return level_index.get_loc(key)

  File "C:\Python\lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc

    raise KeyError(key) from err

KeyError: '1.212248357'

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

**Lee** - *23:29:26*

This is something you’d need to handle, it looks like on line 231 you’re trying to access a market id in the data frame but it doesn’t exists. As it happens rarely it’s probably an edge case. You can use a try/catch with some logging to help you understand why this happens to fix the underlying issue.

*Tags: Errors Debugging*

---

## 2023-04-04

**Andy B** - *00:51:03*

Thanks Lee, I have done a bit of logging to trap the error, and it does appear at times that the marketID is non-existent even though I the market is live, but that really doesn't make sense.  I see the issue in both live scripts and back-testing of markets through flumine, so I guess I'll just have to find a market that doesn't work and step through it again.  I can check to see if the market consistently errors or if it is random, but it feels like a strange issue.

*Tags: Errors Debugging, Deployment*

---

## 2023-04-08

**Tom** - *04:31:25*

I'm having the same problem - I'm not sure how to fix it with client.min_bet_validation. Can we override or adjust that? How and where does it go into the code.



Part of this is learning OOP for me, I've almost got something functioning but it's still arcane

*Tags: Errors Debugging*

---

## 2023-04-10

**Unknown** - *11:04:00*

This issue occurred again over the weekend. Everything had been running fine for over a week and then on Saturday strategy_selection_orders() stopped returning any orders again. I stopped and restarted the flumine instance and it started working again. [@U4H19D1D2](@U4H19D1D2) any idea what could be going on here? I'm on holiday at the moment so can't really debug it or look at the logs, but will take a look again when I get back.

*Tags: Errors Debugging, Strategies*

---

## 2023-04-16

**alan fisher** - *10:42:19*

Hi there. I'm a newbie trying to use Betfairlightweight python examples for the first time. I've  succeeded  in getting passed the trading.login which generates a session token but then anything I then try with the Trading object results in this error



Error: {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie2-ang08a-prd-03211101-003751a790', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie2-ang08a-prd-03211101-003751a790', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}



Can anyone give me any pointers?

*Tags: Getting Started, Errors Debugging, Strategies*

---

**foxwood** - *17:05:27*

App key error as it says on the box. [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions)



Do you have a valid App key ? [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Application+Keys](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Application+Keys)

*Tags: Errors Debugging, Strategies*

---

**eugene brown** - *18:12:14*

There is a question on the developer forum here [https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/35113-connection-error-for-betfairlightweight](https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/35113-connection-error-for-betfairlightweight) about an issue that I am also experiencing and the author was directed here.



When logging in I am getting this error. Could anyone help resolve this?



```requests.exceptions.SSLError: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4044)')))```

*Tags: Errors Debugging*

---

## 2023-04-17

**Mo** - *08:44:25*

What version of Python are you running?

*Tags: General Technical*

---

**eugene brown** - *18:49:46*

This is with python 3.9.16 and betfairlightweight==2.17.1



The login is successful within a docker container locally however I am deploying this container within a custom training job on google cloud platform and that is where I'm experiencing this error.

*Tags: Errors Debugging, Deployment*

---

## 2023-04-20

**Mo** - *06:57:01*

Sorry, keep meaning to reply to this:



1. The GitHub repo for CPython is here: [https://github.com/python/cpython](https://github.com/python/cpython)

2. The tag for version 3.9.16 is here: [https://github.com/python/cpython/tree/v3.9.16](https://github.com/python/cpython/tree/v3.9.16)

3. The _ssl.c file referenced in your exception is here: [https://github.com/python/cpython/blob/v3.9.16/Modules/_ssl.c](https://github.com/python/cpython/blob/v3.9.16/Modules/_ssl.c)

4. The line referenced in your exception is here: [https://github.com/python/cpython/blob/595f9ccb0c059f2fb5bf13643bfc0cdd5b55a422/Modules/_ssl.c#L4044](https://github.com/python/cpython/blob/595f9ccb0c059f2fb5bf13643bfc0cdd5b55a422/Modules/_ssl.c#L4044)

5. All I can personally infer at this stage is that a) the problem is with your certificate b) the problem is NOT related to the certificate file's password c) the problem is NOT some OS error such as being unable to find the certificate file

*Tags: Errors Debugging*

---

## 2023-04-23

**Andy B** - *03:47:08*

Hi All, I am clearly missing something here as I am not gettting the strategy name passed through in my flumine strategies.  I thought that it used the name value e.g.

loc_strategy = FlatLOCModel(

    market_filter=streaming_market_filter(

        event_type_ids=["4339"], # Greyhound Racing

        country_codes=["AU"], # Australian Markets

        market_types=["WIN"], # Win Markets

    ),

    name = "LOC_1.07_3_3.80",

    max_order_exposure= 50, # Max bet sizes of $50

    max_trade_count=1, # Max of trade/bet attempt per selection

    max_live_trade_count=1, # Max of 1 unmatched Bet per selection

)



However, this just passes my machine name as the customer_strategy_ref.  Where should I be adding the customer_strategy_ref so that I can use it to filter my results?

*Tags: Deployment, Strategies*

---

**Dave** - *06:24:39*

customer_strategy_ref has always been set to the hostname and is not set anywhere else ([https://github.com/betcode-org/flumine/blob/9307dd5a0084c3583207921a521a1c39e430220f/flumine/config.py](https://github.com/betcode-org/flumine/blob/9307dd5a0084c3583207921a521a1c39e430220f/flumine/config.py) ). What I do is add a strategy identifier to order.notes, dump these orders (with notes) when market closes using the logging control.

*Tags: Strategies*

---

**Derek C** - *10:26:33*

you can also do this:

```flumine.config.customer_strategy_ref = 'strategy_code'```



*Tags: Strategies*

---

**Andy B** - *10:30:45*

I take it that the idea is to retrieve your historical results via flumine in that case?  Under BFLW I would always pass a customer_strategy_ref value and retrieve it either via the API or the website, so it looks like I need to change my approach now.

*Tags: Strategies*

---

**D** - *10:50:39*

I do the same with bflw and hence why for my flumine strategies I use the above code to override the default behaviour and replace host name with my custom code I can use later.

*Tags: General Technical*

---

**Dave** - *11:32:24*

[@U04NWADNCFR](@U04NWADNCFR) / [@URMM9463X](@URMM9463X) - presumably the override is only applicable if you run 1 strategy per flumine instance?

*Tags: Strategies*

---

## 2023-04-28

**Philip Joss** - *02:02:00*

Hi. I've followed the guide here to create the necessary certificate using the XCA tool: [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA). I've then uploaded it successfully to the Betfair site. When I try to login using the bflw client I get the following error `Exception: Certificates not found in directory: '&lt;path to certificates folder&gt;' (make sure .crt and .key pair or a single .pem is present)`. This is self explanatory but the guide above doesn't mention creating a `.key` file or a `.pem` file! Playing around with the XCA app I have found that I can create a `.pem` file  from either exporting the key or the certificate request. I've tried both of these but on both I get the following error: `Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3874)')))`. I've had a search through [#C4H05ML2E|issues](#C4H05ML2E|issues) and there's a similar post but that's for a `4044` error. Any ideas on where I could go from here?

*Tags: Errors Debugging*

---

**Mo** - *06:52:26*

What version of Python are you running?

*Tags: General Technical*

---

**JazzMan** - *14:00:34*

Anybody seen this Betfair error before “BET_LAPSED_PRICE_IMPROVEMENT_TOO_LARGE”

*Tags: Errors Debugging*

---

**Mo** - *17:52:17*

Same problem as here: [https://betcode-org.slack.com/archives/C4H05ML2E/p1681970221099299?thread_ts=1681665134.137979&amp;cid=C4H05ML2E](https://betcode-org.slack.com/archives/C4H05ML2E/p1681970221099299?thread_ts=1681665134.137979&amp;cid=C4H05ML2E), the line numbers are only different because you're running a different version of Python

*Tags: General Technical*

---

**Philip Joss** - *17:59:24*

Thanks for clarifying this is the same issue. However, I'm still not clear on the whole `.crt` plus `.key` versus a `.pem` file. The guide I reference only goes as far as generating a `.crt` file. However, bflw (well bf really) is looking for either a  `.crt` plus a `.key` OR a `.pem` file. Which option should I go for and how would I generate the `.key` or `.pem`  file?

*Tags: General Technical*

---

**Mo** - *19:08:40*

Sorry I’m not a Windows or XCA user. I believe the Betfair instructions generate a crt file? So you just need to work out how to get the key out of it

*Tags: General Technical*

---

## 2023-05-04

**Nick** - *07:44:48*

Hi All, I'm hoping you can help me. I'm new to flumine and I'm having trouble achieving what I'm trying to achieve for a backtest simulation.



I'm trying to run a simulation on soccer MATCH_ODDS market with the following conditions:



1. Record the odds of the favourite at 60secs before kick off

2. Place a BACK bet on the pre match favourite whilst match is in play and the odds of the favourite have increased by 20%

I'm not sure where it is going wrong or whether I am using the market.context correctly.



Code as per this:

def check_market_book(self, market, market_book):

        if (market_book.status == "OPEN") and market.seconds_to_start &lt; 60:

            # store favourite's starting price

            runners = sorted(

                market_book.runners, key=lambda r: r.ex.available_to_back[0]['price']

            )

            if runners:

                fav = runners[0]

                market.context["fav_starting_price"] = fav.ex.available_to_back[0]['price']

                market.context["market_start_time"] = market_book.market_definition.market_time

                return True



    def process_market_book(self, market, market_book):



        if "fav_starting_price" in market.context:

            # get favourite

            runners = sorted(

                market_book.runners, key=lambda r: r.ex.available_to_back[0]['price']

            )

            if runners:



                fav = runners[0]

                # calculate favourite's odds



                if market.seconds_to_start &lt; 60 and market.seconds_to_start &gt; 50:

                    fav_starting_price = fav.ex.available_to_back[0]['price']

                    fav_starting_price = market.context["fav_starting_price"]







                elif market_book.inplay == True:

                    if fav.ex.available_to_back[0]['price'] &gt; market.context["fav_starting_price"] * 1.2:

                        # place BACK bet on the favourite

                        runner_context = self.get_runner_context(

                            market.market_id, fav.selection_id, fav.handicap

                        )

                        if runner_context.live_trade_count == 0:

                            trade = Trade(

                                market.market_id, fav.selection_id, fav.handicap, self

                            )

                            order = trade.create_order(

                                side="BACK",

                                order_type=LimitOrder(

                                    get_price(fav.ex.available_to_back, 0),

                                    size=5,

                                ),

                            )

                            market.place_order(order)

*Tags: Getting Started, Deployment*

---

**liam** - *08:49:48*

Almost, does this make sense:



```class FootballFavBacker(BaseStrategy):



    def check_market_book(self, market, market_book):

        if "fav_selection_id" not in market.context:

            if market_book.status == "OPEN" and market.seconds_to_start &lt; 60:

                # store favourite's starting price

                runners = sorted(

                    market_book.runners, key=lambda r: get_price(r.ex.available_to_back, 0) or 1001

                )

                if runners:

                    fav = runners[0]

                    market.context["fav_selection_id"] = fav.selection_id

                    market.context["fav_starting_price"] = get_price(fav.ex.available_to_back, 0)

                    market.context["market_start_time"] = market_book.market_definition.market_time

                    print("Updated context:", market.context["fav_starting_price"], market.context["market_start_time"])



        # process when market open and inplay

        if market_book.status == "OPEN" and market_book.inplay:

            return True



    def process_market_book(self, market, market_book):

        fav_selection_id = market.context.get("fav_selection_id")

        if fav_selection_id:

            # get favourite

            runners = {r.selection_id: r for r in market_book.runners}

            if runners:

                fav = runners[fav_selection_id]

                # get favourite's odds from context

                fav_current_price = get_price(fav.ex.available_to_back, 0)

                fav_starting_price = market.context["fav_starting_price"]



                if fav_current_price &gt; fav_starting_price * 1.2:

                    # place BACK bet on the favourite

                    runner_context = self.get_runner_context(

                        market.market_id, fav.selection_id, fav.handicap

                    )

                    if runner_context.trade_count == 0:

                        trade = Trade(

                            market.market_id, fav.selection_id, fav.handicap, self

                        )

                        order = trade.create_order(

                            side="BACK",

                            order_type=LimitOrder(

                                get_price(fav.ex.available_to_back, 0),

                                size=5,

                            ),

                        )

                        market.place_order(order)```

*Tags: Strategies*

---

**Nick** - *09:28:49*

Yep I noticed you added the print there. Thanks for your help and tips.

*Tags: General Technical*

---

## 2023-05-11

**Michael** - *22:13:40*

When I’m trying to call list_market_catalogues, I get the following error: `betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue` 

`Params: {'filter': {'eventTypeIds': ['7'], 'marketCountries': ['GB', 'IRE'], 'marketTypeCodes': ['WIN', 'PLACE', 'E/W', 'OTHER_PLACE']}, 'marketProjection': ['RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'COMPETITION', 'EVENT', 'EVENT_TYPE', 'MARKET_DESCRIPTION', 'MARKET_START_TIME'], 'maxResults': 200}` 

`Exception: None` 

`Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie1-ang16b-prd-03210933-006fb19e72', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie1-ang16b-prd-03210933-006fb19e72', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`



The betfair API docs list that maxResults must be less than 1000 but when I change it to 100 it seems to work. Any ideas?

*Tags: Errors Debugging*

---

## 2023-05-13

**moseley82** - *09:45:54*

Anyone getting timeout errors this morning?

*Tags: Errors Debugging*

---

**Unknown** - *13:17:31*

When backtesting wth Flumine, I previously stored list of total volumes matched for each runner in a dictionary. I decided to store them in the RunnerBook objects instead, and wrote this method:



```def update_total_volume_list(self, runner: RunnerBook):

    if not hasattr(runner, "total_volume_list"):

        runner.total_volume_list = []

    runner.total_volume_list.append(runner.total_matched)

    # print(runner.total_volume_list)```

The method is called whenever process_market_book is refreshed.



However, when I run the commented out test print command, it reveals that the total_matched figure isn't increasing.  I don't expect it to increase on each refresh, but it not increasing at all.



Where am I going wrong, please?

*Tags: General Technical*

---

**Jeff Waters** - *13:46:41*

It's just a data update controller class (which, in its current form, I could easily get rid of).



```from betfairlightweight.resources import RunnerBook



from incoming_data_storage.raw_data_dictionary_update import RawDataUpdate



class DataUpdateController:

    def update_data(self, runner: RunnerBook):

        RawDataUpdate().update_raw_data(runner)```

The method it calls begins by calling the method I put in my message:



```def update_raw_data(self, runner: RunnerBook):

    self.update_total_volume_list(runner)```



*Tags: General Technical*

---

## 2023-05-15

**D C** - *21:01:12*

Has anyone else had lots of errors on the order stream this evening?

*Tags: Errors Debugging*

---

**D C** - *21:36:45*

OK thanks. Must be my end. Max connection limit errors even when my stream authentication message tells me I have connections available. Weird.

*Tags: Errors Debugging*

---

## 2023-05-16

**George** - *16:02:56*

I just started using betfairviz today. I am very frequently getting an exception and I wondered if anyone knows how I can avoid it. It looks like this:

```File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/iostream.py", line 182, in advance

    assert 0 &lt; size &lt;= self._size

  AssertionError```

*Tags: Errors Debugging*

---

**George** - *16:04:56*

```Exception in callback functools.partial(&lt;function ZMQStream._update_handler.&lt;locals&gt;.&lt;lambda&gt; at 0x107b25160&gt;)

  Traceback (most recent call last):

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/ioloop.py", line 738, in _run_callback

    ret = callback()

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 718, in &lt;lambda&gt;

    self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 634, in _handle_events

    self._handle_recv()

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 663, in _handle_recv

    self._run_callback(callback, msg)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 584, in _run_callback

    f = callback(*args, **kwargs)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 308, in stream_callback

    return callback(self, msg)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/notebook/services/kernels/handlers.py", line 572, in _on_zmq_reply

    super()._on_zmq_reply(stream, msg)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/notebook/base/zmqhandlers.py", line 256, in _on_zmq_reply

    self.write_message(msg, binary=isinstance(msg, bytes))

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/websocket.py", line 334, in write_message

    return self.ws_connection.write_message(message, binary=binary)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/websocket.py", line 1081, in write_message

    fut = self._write_frame(True, opcode, message, flags=flags)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/websocket.py", line 1056, in _write_frame

    return self.stream.write(frame)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/iostream.py", line 539, in write

    self._handle_write()

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/iostream.py", line 965, in _handle_write

    self._write_buffer.advance(num_bytes)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/iostream.py", line 182, in advance

    assert 0 &lt; size &lt;= self._size

  AssertionError```

*Tags: Errors Debugging*

---

**Mo** - *16:07:07*

It looks to me like it’s some jupyter error unrelated to betfairviz but I could be wrong

*Tags: Errors Debugging*

---

**George** - *16:09:07*

it definitely looks like a jupyter error but i'm wondering if anyone can suggest maybe a different version of a package that i should upgrade to for example?

*Tags: Errors Debugging*

---

**Mo** - *16:09:35*

And when the error occurs does the dashboard break or is it still usable?

*Tags: Errors Debugging*

---

**Mo** - *16:32:42*

This thread: [https://discourse.jupyter.org/t/jupyter-notebook-zmq-message-arrived-on-closed-channel-error/17869/17](https://discourse.jupyter.org/t/jupyter-notebook-zmq-message-arrived-on-closed-channel-error/17869/17) suggests you should try downgrading to 6.1

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:01:22*

My logs are full of TOO_MANY_REQUESTS errors when calling listClearedOrders. How do people avoid that?

*Tags: Errors Debugging*

---

**D C** - *21:33:50*

Probably not helpful to you as its not flumine related but I have a throttle on calls and call on a per market basis rather than using settled time intervals. The operation only gets settled orders and I don't need to get them in a rush as soon as market closes so I just force a minimum of 5 second delay between calls, and only once a market has been closed for at least 60 minutes. Then use the to/from records and the moreAvailable flag to pull them down until I've got them all. I also make seperate calls for each of the  VOIDED, LAPSED, CANCELLED and SETTLED betStatus types.

*Tags: General Technical*

---

## 2023-05-21

**George** - *22:13:14*

I believe this fixed it by the way. Thanks very much!

*Tags: Errors Debugging*

---

## 2023-05-22

**Jorge** - *09:07:47*

Hi, I keep getting this error after my flumine trader is running for ~ 1 day. I never get the error in the flumine market recorder script but I do in the trader. The error is gone after restarting the script.

INVALID_SESSION_INFORMATION: UnrecognisedCredentials. This is the full log:



```{"asctime": "2023-05-22 08:01:42,808", "levelname": "ERROR", "message": "[MarketStream: 6393]: INVALID_SESSION_INFORMATION: UnrecognisedCredentials"}

{"asctime": "2023-05-22 08:01:42,808", "levelname": "ERROR", "message": "MarketStream 6392 run error", "exc_info": "Traceback (most recent call last):\n  File \"/root/environments/flumine/lib/python3.8/site-packages/flumine/streams/marketstream.py\", line 44, in run\n    self._stream.start()\n  File \"/root/environments/flumine/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py\", line 67, in start\n    self._read_loop()\n  File \"/root/environments/flumine/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py\", line 233, in _read_loop\n    self._data(received_data)\n  File \"/root/environments/flumine/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py\", line 274, in _data\n    raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 101-220523080142-760501, data: {\"op\":\"status\",\"id\":6393,\"statusCode\":\"FAILURE\",\"errorCode\":\"INVALID_SESSION_INFORMATION\",\"errorMessage\":\"UnrecognisedCredentials\",\"connectionClosed\":true,\"connectionId\":\"101-220523080142-760501\"}"}```

*Tags: Data Quality, Errors Debugging*

---

## 2023-05-23

**Jorge** - *09:39:57*

They told me the session token has expired. I think this could be improved in flumine: [https://github.com/betcode-org/flumine/blob/master/flumine/clients/betfairclient.py#L46|keep_alive()](https://github.com/betcode-org/flumine/blob/master/flumine/clients/betfairclient.py#L46|keep_alive()) is logging an Exception but returns None, so in [https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#L100|worker.py](https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#L100|worker.py) it does not [https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#LL108C1-L108C23|client.login()](https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#LL108C1-L108C23|client.login())

*Tags: Errors Debugging, Deployment*

---

**liam** - *09:40:37*

Whats the error?

*Tags: Errors Debugging*

---

**Jorge** - *09:41:43*

It never reaches this line [https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#LL108C1-L108C23|client.login()](https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#LL108C1-L108C23|client.login()) so whenever it fails to keep alive, it does not try to login again to continue the execution

*Tags: Deployment*

---

**Jorge** - *09:45:09*

I think it's just a typo, because keep_alive() returns None for both the case where no keep_alive is required and when it is required but an Exception is raised (my case)

*Tags: Errors Debugging, Deployment*

---

**Jorge** - *09:46:43*

Apparently my session_token has expired but I do not understand why, because my [https://github.com/betcode-org/flumine/blob/master/flumine/flumine.py#L71|ka_interval](https://github.com/betcode-org/flumine/blob/master/flumine/flumine.py#L71|ka_interval) is correct.

{"levelname": "INFO", "message": "BackgroundWorker keep_alive starting", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x7f75951af3a0&gt;", "context": {}, "start_delay": 0, "interval": 600.0, "func_args": [], "func_kwargs": {}}

I see this log but then no mentions to keep_alive until it starts failing

*Tags: Deployment*

---

**Newbie99** - *15:37:09*

Last week I got this error:



```betfairlightweight.exceptions.LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE```

When trying to make REST API calls from my local machine, didn't think too much of it as its fairly self explanatory, so I changed my password and moved on.



However I've just received the same error again (less than a week after changing my password), which seems a bit odd as I can login via the GUI, I'm logged in via the streaming API (not seeing any errors in the logs currently), so is there any other reason why this might be happening?

*Tags: Errors Debugging*

---

## 2023-05-24

**Jeff Waters** - *09:01:13*

Hi



I've amended the error handling method to print the details of the errors:



```def call_strategy_error_handling(

    func: Callable, market, market_book: MarketBook

) -&gt; Optional[bool]:

    try:

        return func(market, market_book)

    except FlumineException as e:

        logger.error(

            "FlumineException %s in %s (%s)" % (e, func.__name__, market.market_id),

            exc_info=True,

        )

        print(e)

    except Exception as e:

        logger.critical(

            "Unknown error %s in %s (%s)" % (e, func.__name__, market.market_id),

            exc_info=True,

        )

        print(e)

        if config.raise_errors:

            raise

    return False```

How do I get it to print a full stack trace, please? Currently, the output is just telling me 'list index out of range', but it would be helpful to know which bit of my code was responsible for that error.



GPT suggested adding:



traceback_str = traceback.format_exc()  # Get the formatted traceback as a string

print(traceback_str)  # Print the stack trace



However, that had no effect.



Thanks

*Tags: Errors Debugging, Strategies*

---

**Jeff Waters** - *09:07:58*

OK, I'll look into how to do that, thanks.

*Tags: General Technical*

---

## 2023-05-25

**Jorge** - *14:59:55*

Done, it's very simple [https://github.com/betcode-org/flumine/pull/662](https://github.com/betcode-org/flumine/pull/662) :smile:

*Tags: General Technical*

---

## 2023-05-27

**Jeff Waters** - *12:10:55*

Hi



I'm doing back testing, and using market.cancel_order(order) to cancel orders, like so:



```def cancel_order(self, market: Market, order: BaseOrder):

    with market.transaction() as t:

        t.cancel_order(order)```

However, the logger shows that an exception was thrown:



  *File "C:\Users\User\Documents\New back test\venv\lib\site-packages\flumine\execution\transaction.py", line 101, in cancel_order*

    *order.cancel(size_reduction)*

  *File "C:\Users\User\Documents\New back test\venv\lib\site-packages\flumine\order\order.py", line 339, in cancel*

    *raise OrderUpdateError("Order does not currently have a betId")*

*flumine.exceptions.OrderUpdateError: Order does not currently have a betId*

*ERROR - FlumineException Order does not currently have a betId in process_market_book (1.145085632)*



I'm using the following code to create orders:



```order = OrderFactory().non_bsp_order(self, back_or_lay, target_price, stake, runner, market_book)

with market.transaction() as t:

    t.place_order(order)```

and this is what the OrderFactory method looks like:



```def non_bsp_order(self, strategy_object: BaseStrategy, back_or_lay: str, bet_price: float, stake_size: float,

                  runner: RunnerBook, market_book: MarketBook) -&gt; BetfairOrder:

    trade = Trade(

        market_book.market_id,

        runner.selection_id,

        runner.handicap,

        strategy_object,

    )

    return trade.create_order(

        side=back_or_lay, order_type=LimitOrder(price=bet_price, size=stake_size)

    )```

Where am I going wrong, please?

*Tags: Errors Debugging, Strategies*

---

**Derek C** - *15:09:54*

When I'm using Flumine, the bet_id isn't assigned immediately to the order object, otherwise the process would be waiting for that to happen. It's an asynchronous call and there will be a delay before Flumine receives the bet_id back from betfair and assigns it to the order. During this period the bet_id will be None.

*Tags: General Technical*

---

**Jeff Waters** - *15:13:26*

Thanks Derek. Does that delay even apply with simulated trading, using historical data?

*Tags: Data Quality, Strategies*

---

**Jeff Waters** - *15:23:43*

I'm wondering if I've missed a step by omitting execute(). From the documentation:



with market.transaction() as t:

    t.place_order(order)

    t.execute()  # above order executed



What is the effect of executing an order? I'd previously assumed that, if I'd placed an order, it was in the market and no further action was required.

*Tags: General Technical*

---

**Derek C** - *15:26:53*

my code uses market.place_order however going by the documentation, your execute statement isn't needed because it will execute automatically at the end of the context (with)

*Tags: General Technical*

---

**Adam Momen** - *19:02:00*

[@UUE6E1LA1](@UUE6E1LA1) would you mind sharing a code example of how would you add the throttle?



Would you recommend modifying the throttle through by accessing the background worker `flumine._workers[-1].interval = 300` ?

*Tags: General Technical*

---

## 2023-05-28

**D C** - *09:47:23*

I can't give a code example that would be any use to you because I have my own code base and don't use flumine (don't use python at all). Maybe someone else can help you out here.

*Tags: General Technical*

---

## 2023-05-31

**Stephen Shirley** - *20:24:11*

Hi I'm getting ssl.SSLError: [SSL] PEM lib (_ssl.c:3874) when I try to login using betfairlightweight. It's the same error I would get using the regular betfair api if my key was wrong but I have tried it using the regular api with the same key and it works. If anyone could help it would be much appreciated.

*Tags: Errors Debugging*

---

**Mo** - *20:30:39*

Probably a problem with your certificate

*Tags: General Technical*

---

**Stephen Shirley** - *20:55:07*

I mean by interfacing with the base betfair api without the nice betfairlightweight wrapping. Just using json and the requests module

*Tags: General Technical*

---

**Mo** - *21:01:47*

There’s only one API. There’s every chance the way you’ve generated the certificate is compatible with the way you’re using requests but not with betfairlightweight 



See this thread: [https://betcode-org.slack.com/archives/C4H05ML2E/p1682643720988399|https://betcode-org.slack.com/archives/C4H05ML2E/p1682643720988399](https://betcode-org.slack.com/archives/C4H05ML2E/p1682643720988399|https://betcode-org.slack.com/archives/C4H05ML2E/p1682643720988399) and this one: [https://betcode-org.slack.com/archives/C4H05ML2E/p1681665134137979|https://betcode-org.slack.com/archives/C4H05ML2E/p1681665134137979](https://betcode-org.slack.com/archives/C4H05ML2E/p1681665134137979|https://betcode-org.slack.com/archives/C4H05ML2E/p1681665134137979)

*Tags: General Technical*

---

**AI Trader** - *23:22:03*

[@U053U2PUK2M](@U053U2PUK2M) did you find out the reason? Im experiencing the same issue, ie, it works locally, but when deploying in the cloud (with the same requirements.txt and python version, i SOMETIMES get this error

*Tags: Errors Debugging, Deployment*

---

## 2023-06-01

**AI Trader** - *17:50:21*

Same. Did you amnage to fix [@U05AR7HNHUZ](@U05AR7HNHUZ)?

*Tags: Errors Debugging*

---

**Mo** - *18:07:01*

[@U055BSWEY7M](@U055BSWEY7M) fixed _his_ problem in one of the threads I linked to: [https://betcode-org.slack.com/archives/C4H05ML2E/p1682713756666659?thread_ts=1682643720.988399&amp;cid=C4H05ML2E](https://betcode-org.slack.com/archives/C4H05ML2E/p1682713756666659?thread_ts=1682643720.988399&amp;cid=C4H05ML2E). Perhaps it's the same as yours (although perhaps not)

*Tags: Errors Debugging*

---

**AI Trader** - *21:48:41*

[@UBS7QANF3](@UBS7QANF3) I have. It's weird because I manage to login thorugh the betfairlightweight api and place orders successfuly. But whenever I run my strategy, some time after I get the error below



```2023-06-01 20:46:58,742 - ERROR - executor.replace - ERROR REPLACE: SportsAPING/v1.0/replaceOrders 

Params: {'marketId': '1.214777671', 'instructions': [{'betId': '309396638021', 'newPrice': 4.3}]} 

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/betting/json-rpc/v1 (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:997)')))```

*Tags: Errors Debugging, Strategies*

---

**AI Trader** - *21:51:52*

I get this error every time I run the strategy. After a couple of minutes running the strategy, I get dozens of these messages in a couple of seconds (It's an HFT strategy), and from there no orders are placed anymore, only errors. Do you have any guesses on what could be happening?

*Tags: Errors Debugging, Strategies*

---

**AI Trader** - *22:34:54*

I am placing my orders through threads concurrently.  I can see that when the strategy starts, the first orders are placed successfully.

Are you aware of any limitations imposed by Betfair? I've found [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions|here](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions|here) that:



[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders|placeOrders](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders|placeOrders), [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/cancelOrders|cancelOrders.](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/cancelOrders|cancelOrders.) [https://docs.developer.betfair.com/pages/viewpage.action?pageId=2621600|updateOrders](https://docs.developer.betfair.com/pages/viewpage.action?pageId=2621600|updateOrders), [https://docs.developer.betfair.com/pages/viewpage.action?pageId=2621599|replaceOrders](https://docs.developer.betfair.com/pages/viewpage.action?pageId=2621599|replaceOrders) if the number of transactions (instructions) submitted exceeds 1000 in a single second causes an error. This is by far not my case (I am sending less than 100 requests per second surely).

*Tags: Errors Debugging, Strategies*

---

## 2023-06-02

**Andy** - *09:39:41*

Get this annoying error anytime I start my stream. It doesn't seem to cause any issues but just want to get to the bottom of it. All error handling attempts have failed

*Tags: Errors Debugging*

---

**Andy** - *09:39:46*

Mainloop Timer 3: 2023-06-02T08:29:03.045302

Exception in thread Thread-1 (start):

Traceback (most recent call last):

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\threading.py", line 1038, in _bootstrap_inner

    self.run()

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\threading.py", line 975, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 233, in _read_loop

    self._data(received_data)

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 274, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 105-020623082852-707950, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"103-020623082851-731897"}

*Tags: Errors Debugging*

---

**liam** - *09:40:20*

bflw is too quick

*Tags: General Technical*

---

**Andy** - *09:40:38*

def start_stream(bfl_trading, bfl_client, event_types=["horse", "greyhound"]):

    """Retrieves a json dictionary with the stream data from the specified event types."""

    for event in event_types:

        event_types[event_types.index(event)] = EVENT_TYPE_IDS[event]



    # create queue

    output_queue = queue.Queue()



    # create stream listener

    listener = betfairlightweight.StreamListener(output_queue=output_queue)



    # create stream

    streamH = bfl_trading.streaming.create_stream(listener=listener)

    streamG = bfl_trading.streaming.create_stream(listener=listener)



    # Create filters to get the events

    horse_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["WIN"]

    )

    greyhound_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["4339"],

        country_codes=["AU"],

        market_types=["WIN"]

    )



    market_data_filter = filters.streaming_market_data_filter(

        fields=["EX_BEST_OFFERS", "EX_MARKET_DEF"], ladder_levels=3

    )





    # subscribe

    horse_streaming_unique_id = streamH.subscribe_to_markets(

        market_filter=horse_market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=5000,  # send update every 1000ms

    )



    greyhound_streaming_unique_id = streamG.subscribe_to_markets(

        market_filter=greyhound_market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=5000,  # send update every 1000ms

    )



    # start stream in a new thread (in production would need err handling)

    tH = threading.Thread(target=streamH.start, daemon=True)

    tH.start()

    tG = threading.Thread(target=streamG.start, daemon=True)

    tG.start()



    return streamH, output_queue

*Tags: Deployment, Strategies*

---

**AI Trader** - *22:49:02*

Python. No, there is a single client for all threads (shared)

*Tags: General Technical*

---

**AI Trader** - *22:49:26*

I have managed to fix the issue with a simple hack (adding verify = False to every single request to betfair, which is not a good solution as defeats the purpose)

*Tags: Errors Debugging*

---

## 2023-06-04

**Alexander O'Reilly** - *00:29:17*

Betfairlightweight: How do I access near_price and far_price when iterating through runner of a market_book?

e.g.

…

for runner in market_book.runners:



Do something with runner.sp.near_price

*Tags: General Technical*

---

**Mo** - *14:03:26*

Not sure what the question is as your code already shows how to do it

*Tags: General Technical*

---

**Alexander O'Reilly** - *22:45:52*

runner.sp.near_price gives me an AttributeError: NoneType object has no attribute ‘near_price’



I can access other attributes such as runner.ex.available_to_back etc. but sp attribute gives me none response.



This is for win markets, horse racing AU, flat

*Tags: Errors Debugging*

---

**Alexander O'Reilly** - *23:24:48*

Solved it, thanks Mo :+1::skin-tone-2: 

*Tags: General Technical*

---

## 2023-06-05

**foxwood** - *23:16:51*

In `process_closed_market()` I walk the blotter and log all the bets marked as `EXECUTION_COMPLETE` For the first time today I found there were lots of unmatched lapsed bets that were not logged. From the live strategy log it seems that the market was closed and removed before `"Order status update: Execution complete"` was received for these bets ! Is this normal everyday stuff that I've not noticed before or was it just BF having a bad day ?



Edit: All the bets were `MARKET_ON_CLOSE` and less than £10 liability so guessing that's maybe what happens if not enough to make the SP draw. Wonder what the `OrderStatus` would be in that case ?

*Tags: Getting Started, Deployment, Strategies*

---

## 2023-06-06

**liam** - *09:44:08*

Haven't seen this one before?



```.. "statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"No available feeds to subscribe to","connectionClosed":true..```

*Tags: Errors Debugging*

---

## 2023-06-07

**Tom** - *11:32:42*

I'm having a nightmare of a time trying to use RaceCards; I want to call them to get results, bsp, market data e.t.c. - Wouldnt mind seeing the full functionality; there is something there that even has form related data (I presume it's not available for Australian horse racing?).



I've spun myself around enough times to not really know what to try next.



```def get_race_results(race_card: RaceCard, market_ids: List[str]):

    logging.debug(f"Getting race card for market_ids: {market_ids}")

    try:

        racecards = race_card.get_race_card(market_ids, data_entries="RACE")

        race_results = race_card.get_race_result(market_ids)

        print(f"race results are {race_results}")

        logging.debug(f"Received race card data: {racecards}")

    except Exception as e:

        logging.error(f"Failed to get race card data: {e}")

        return []



    result = []

    for race in racecards:

        logging.debug(f"Processing race: {race['raceName']}")

        for runner in race['runners']:

            runner_data = {

                "Market ID": race['marketId'],

                "Race Name": race['raceName'],

                "Race Time": race['raceTime'],

                "Runners": race['numberOfRunners'],

                "Distance": race['distance'],

                "Runner Name": runner['runnerName'],

                "Runner ID": runner['selectionId'],

                "Starting Price": runner['sp'],

                "Final Position": runner['finishingPosition'],

                "In-Play High Price": runner['inPlayHighPrice'],

                "BSP": runner['bsp'],

            }

            result.append(runner_data)

            logging.debug(f"Processing runner_data: {runner_data}")



    return result



def get_results(trading):

    date_str = datetime.date.today().strftime("%d-%m-%Y")

    file_path = f'data/market_trade_data/market_trade_data_{date_str}.pkl'

    market_trade_data = pd.read_pickle(file_path)

    logging.debug(f"Market trade data: {market_trade_data}")

    market_ids = refresh_market_ids(market_trade_data)



    race_card = trading.RaceCard.login()

    try:

        trading.race_card.login()

        print("Logged in successfully.")

    except Exception as e:

        print(f"Failed to log in: {e}")



    all_results = []

    for market_id in market_ids:

        logging.debug(f"Getting race results for market_id: {market_id}")

        all_results.extend(get_race_results(race_card, [market_id]))



    df_results = pd.DataFrame(all_results)

    df_results.to_csv(f"data/race_results/race_results_{date_str}.csv", index=False)

    logging.debug(f"Saved race results to 'data/race_results/race_results_{date_str}.csv'")```

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

**liam** - *11:37:32*

So whats the question?

*Tags: General Technical*

---

## 2023-06-12

**Paul** - *22:42:00*

If I call `market.place_order(…)` twice in a row (different orders, different trades), in `process_market_book`, only the first actually goes through. I tried it in a `with market.transaction as t` block and explicitly calling `execute` but that blew up complaining about `__enter__` missing and my 14 hour work day brain and crappy python internals knowledge gave up. In what way am I being a complete moron?

*Tags: General Technical*

---

## 2023-06-13

**foxwood** - *19:34:37*

Is cancel and change price function for an order supposed to work in simulation ? My code to play with this is basically

```for order in market.blotter:

	if order.size_remaining != 0.0 :

		price = ...

		order.replace(price)```

and that sets the order status to "Replacing" but as shown in log below it doesn't switch to "Execution complete" until 44 seconds later when the market closes and no matching done on the order. Originally placed lay bet at 7.4 none of which was matched then replaced asking for  8.8 which should have taken lower current lay price of which there were many trades less than that. Haven't found anywhere in the simulation code yet that seems to be aware of the replacing operation ?

Am I just using it wrong or it doesn't work as I think it should ?

EDIT: I am using a build from last April but still can't see any signs it would work looking at latest github ?

```......

{"asctime": "2023-06-13 18:23:50,367", "levelname": "DEBUG", "message": "Simulated order 139059698302594198 traded: 7.6 - 1.2"}

{"asctime": "2023-06-13 18:23:50,368", "levelname": "DEBUG", "message": "getSecondsToStart: 29.829"}

{"asctime": "2023-06-13 18:23:50,368", "levelname": "INFO", "message": "Order status update: Replacing" ...

	"status": "Replacing", "status_log": "Pending, Executable, Replacing", ...

{"asctime": "2023-06-13 18:23:50,368", "levelname": "DEBUG", "message": "Replacing odds for 53923661 from odds 7.4 to 8.8"}

{"asctime": "2023-06-13 18:23:50,368", "levelname": "DEBUG", "message": "getSecondsToStart: 29.62"}

{"asctime": "2023-06-13 18:23:50,369", "levelname": "DEBUG", "message": "getSecondsToStart: 29.517"}

{"asctime": "2023-06-13 18:23:50,369", "levelname": "DEBUG", "message": "Simulated order 139059698302594198 traded: 7.6 - 0.08"}

{"asctime": "2023-06-13 18:23:50,370", "levelname": "DEBUG", "message": "getSecondsToStart: 29.304"}

......

"asctime": "2023-06-13 18:23:50,509", "levelname": "DEBUG", "message": "Simulated order 139059698302594198 traded: 8 - 11.52"}

{"asctime": "2023-06-13 18:23:50,510", "levelname": "DEBUG", "message": "getSecondsToStart: -13.085"}

{"asctime": "2023-06-13 18:23:50,510", "levelname": "DEBUG", "message": "getSecondsToStart: -13.189"}

{"asctime": "2023-06-13 18:23:50,510", "levelname": "DEBUG", "message": "getSecondsToStart: -13.293"}

{"asctime": "2023-06-13 18:23:50,511", "levelname": "DEBUG", "message": "getSecondsToStart: -13.352"}

{"asctime": "2023-06-13 18:23:50,511", "levelname": "DEBUG", "message": "getSecondsToStart: -13.457"}

{"asctime": "2023-06-13 18:23:50,512", "levelname": "DEBUG", "message": "getSecondsToStart: -14.183"}

{"asctime": "2023-06-13 18:23:50,513", "levelname": "INFO", "message": "Order status update: Execution complete" ......

{"asctime": "2023-06-13 18:23:50,513", "levelname": "INFO", "message": "Trade status update: Complete"......

{"asctime": "2023-06-13 18:23:50,515", "levelname": "INFO", "message": "Market 1.215094455 closed" ......

......```

*Tags: Errors Debugging*

---

**Andy** - *23:07:02*

Are we able to get anything from Australian racing with either BFLW or Flumine any other way? Even just the BSP and/or whether the bet won or lost? 

*Tags: General Technical*

---

## 2023-06-16

**Aaron Smith** - *06:42:07*

hey guys! Yesterday i had my first bot going rogue. Looking at my terribly lazy workflow and messy code at times, its actually a miracle that this has been the first time in all these years. I know very well how to prevent this in the future, as i know what caused it (lazy workflow a la "why paper trade - cool kids go live" :smile: ). Knowing myself however, i could still be dumb enough to let it happen again, even after this incident.

Anyways, as i watched my rogue bot throw out 100% of my bankroll in a fraction of a second, i was wondering: how to best deal with this? I didnt want to just kill it, as then i d be left with thousands of bets (idk how many it was, it hit transaction limit, so whatever that limit is) all over betfair that are completely unattended and i d have to manually cancel them all via the betfair_webUI. As it was supposed to only be a test run, i had it set to only run for 1 hour, so i decided to just let it do its thing, as this way, while it may have broken any exposure limits imaginable, it still babysat my bets in a somewhat "smart" way.



However, after 1 hour, the bot did in fact stop, but not as gracefully as hoped. It just left all the bets up so i still had to manually go through the markets and cancel them.



This leaves me with 2 questions:

1. Is there a way to gracefully kill a rogue bot?

2. What went wrong when my bot was supposed to cancel all bets before stopping as planned?

regarding 2, here is the relevant code that terminated the bot and was supposed to cancel all bets left:

```def terminate(context: dict, framework) -&gt; None:

    for market in framework.markets:

        for order in market.blotter:

            if order.status == OrderStatus.EXECUTABLE:

                market.cancel_order(order)

    framework.handler_queue.put(TerminationEvent)





terminator = flumine.worker.BackgroundWorker(flumine=framework, function=helpers.terminate, interval=100, start_delay=60 * self.run_time_in_mins)  # termiante after run_time_in_mins



framework.add_worker(terminator)```



Also, i know you guys would ve loved for me to throw some cash at you, but luckily i didnt get punished as i should ve been. The bot actually made 10 pounds (minus what the other bots could ve made in that hour maybe, if they had any bankroll left to play with), enough to get me a well deserved pint after a productive day at "work".  But no worries, i m sure i ll unleash one of these bad boys again some time.

*Tags: Getting Started, Deployment*

---

**liam** - *07:50:32*

Did you remove all the controls that flumine has in place to stop this?



And to answer point 2 I imagine the program exited due to memory leak / CPU so the termination function could never run.

*Tags: Performance*

---

**Aaron Smith** - *09:17:16*

[@UBS7QANF3](@UBS7QANF3) thanks for the pointer, so i guess i could use this to shorten the terminate function? How would i call this in flumine?

Also, while this may be a better way to canceling all orders, can you see a reason why my original function fails to do its job?

*Tags: General Technical*

---

**Aaron Smith** - *09:20:45*

[@U4H19D1D2](@U4H19D1D2) i can be rather careless, but thats also why i would never remove any controls :smile: But i think there is only so much flumine can do in this case. Its not like any individual order broke the order exposure, but i didnt set any strategy exposure or a maximum amount of bets it could place, so flumine has no reason to assume i didnt want to put my whole bank roll out in one go there.

*Tags: Strategies*

---

**liam** - *09:21:33*

I think its best to solve the problem first, why no use of the strategy exposure / bets?

*Tags: Strategies*

---

**Aaron Smith** - *09:24:48*

[@U4H19D1D2](@U4H19D1D2) i totally agree and besides that, there were plenty of more occasions where the rational mind should kick in make sure things dont go wild when hitting that live button, i m totally aware of those solutions. However i m still curious about why my terminate function didnt do its job properly and how to act in case i send another one of these boys out there, even if its due to my own stupidity :smile:

*Tags: Deployment*

---

**Aaron Smith** - *09:29:22*

that will be the reason then. I thought once sent out, it will just complete even if i dont wait for the confirmation. Thank you, i ll check how to fix that

*Tags: Errors Debugging*

---

**liam** - *09:31:00*

At the end of the day its executing code in order, nothing complicated but the execution thread needs time to send the requests, in your example the functions get called but have no time to actually execute before the flumine main process completes

*Tags: General Technical*

---

**Aaron Smith** - *09:33:44*

is there the possibility of me sending the cancel request for all orders and while waiting for its completion, my strategy placing new bets that then will still be left out there? So basically i d have to:

1. stop framework from placing any new orders

2. send cancel request for all orders

3. wait for confirmation

4. put terminationEvent

?

*Tags: Strategies*

---

**liam** - *09:35:45*

Good point, that is possible, [https://github.com/betcode-org/flumine/blob/master/flumine/baseflumine.py#L429|this](https://github.com/betcode-org/flumine/blob/master/flumine/baseflumine.py#L429|this) is the exit code, easy fix is to stop the streams first and then call the workers

*Tags: Errors Debugging*

---

**Aaron Smith** - *09:58:08*

well, playing with fire certainly wasnt the goal, rather the opposite :smile:  So currently you guys also have no way of stopping flumine without leaving some trailing bets behind?

*Tags: General Technical*

---

**liam** - *11:24:04*

[https://github.com/betcode-org/flumine/issues/665](https://github.com/betcode-org/flumine/issues/665)

*Tags: General Technical*

---

**Aaron Smith** - *12:13:24*

test it, as in modify the `__exit__`  method? I d rather not, i m already more than capable of unleashing chaos without tinkering with the underlying frameworks :smile: I guess i could chunk together some hacky code that stops my strategies from placing orders without touching flumine, but i dont think thats the way to go. I d much rather if we had a generally accepted way to gracefully stop new bets, cancel all executable ones and terminate flumine. I dont mind writing some code and making a pull req myself, but i feel like i m the wrong guy for this particular job.

*Tags: General Technical*

---

**liam** - *12:14:23*

I mean fix your worker and test it, 2 second test will tell you if things are working, dw about the exit change, I can improve that

*Tags: Errors Debugging*

---

**Aaron Smith** - *14:20:06*

2 seconds for you maybe :smile:

so you want me to write the terminate function like this?:

```

def terminate(context: dict, framework: Flumine) -&gt; None:

# stop market streams

for market in framework.markets:

    for order in market.blotter:

        if order.status == OrderStatus.EXECUTABLE:

            market.cancel_order(order)

# wait for confirmation

    framework.handler_queue.put(TerminationEvent)```

if so, regarding "stop market streams", i cant see a clean way of doing this. Flumine seems to have one attribute "streams" which includes all streams. I could iterate over, check if isinstance(stream, FlumineMarketStream) and stop those, i guess.



Regarding "wait for confirmation" my lack of experience with threading may be the problem. I guess i d need to collect all bet_id's of the orders i just canceled, then open a listener_thread where i check for coming updates and wait until all bets that i have canceled have been confirmed to be cancelled? + some error handling when a bet failed to cancel.

*Tags: Errors Debugging*

---

**liam** - *16:27:57*

So I need to make changes to stop the streams correctly but I think you are better to place this code in the strategy itself, for example your worker:



```def terminate(context: dict, framework: Flumine) -&gt; None:

    # ... logic to terminate

    framework.handler_queue.put(TerminationEvent)```

This will trigger `BaseStrategy.finish` to be called which would contain



```    def finish(self, flumine) -&gt; None:

        # called before flumine ends

        for market in flumine.markets:

            for order in market.blotter.strategy_orders(self, order_status=[OrderStatus.EXECUTABLE]):

                market.cancel_order(order)



        while True:

            e_orders = []

            for market in flumine.markets:

                orders = market.blotter.strategy_orders(self, order_status=[OrderStatus.EXECUTABLE])

                e_orders += orders

                [http://logger.info|logger.info](http://logger.info|logger.info)(f"{len(orders)} orders executable in market {market.market_id}")

            if e_orders:

                [http://logger.info|logger.info](http://logger.info|logger.info)("Sleeping for 3s")

                time.sleep(3)

            else:

                break```

I just tested this and it works really well

*Tags: Strategies*

---

**Michael** - *16:53:32*

I keep getting _getclearedmarket error in Market recorder because of read time outs. Is Flumine handling these or is this an error on my part somewhere?

*Tags: Data Quality, Errors Debugging*

---

**liam** - *17:37:28*

This isn’t a simple problem 

*Tags: General Technical*

---

## 2023-06-17

**Aaron Smith** - *03:00:02*

I see. How about:

```def cancel_all(strat: BaseStrategy, framework: Flumine) -&gt; None:

    """cancels all executable orders of strat and waits for confirmation"""

    num_cancel_attempts = 5

    for _ in range(num_cancel_attempts):

        for market in framework.markets:

            orders = market.blotter.strategy_orders(strategy=strat, order_status=[OrderStatus.EXECUTABLE])

            cancel_orders(market=market, orders=orders)

        [http://logging.info|logging.info](http://logging.info|logging.info)('Sleeping for 3s')

        time.sleep(3)  # waiting for orders to be cancelled in another thread



        e_orders = []

        for market in framework.markets:

            orders = market.blotter.strategy_orders(strategy=strat, order_status=[OrderStatus.EXECUTABLE])

            e_orders += orders

            [http://logger.info|logger.info](http://logger.info|logger.info)(f"{len(orders)} orders executable in market {market.market_id}")

        if not e_orders:

            break

    else:

        logger.warning(f"failed to cancel {len(e_orders)} orders")```

this function would be called in BaseStrategy.finish()

downsides:

• If order takes longer than 3s to cancel, we d send out multiple cancelations for the same order (but maximum 5 and with 3s delay between attempts, so i guess that should be fine?)

upsides:

• if an order slips through, we try to cancel again

• giving up instead of infinte while loop (maybe not perfect either, but the lesser evil?)

*Tags: Errors Debugging, Strategies*

---

## 2023-06-18

**Michael** - *20:55:03*

Has anyone run into the following? I think its stemmed from a code change I implemented to write to a database but not sure why it is coming out as this error



```2023-06-17 22:27:22,654 - ERROR - _get_cleared_market error

Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn

    conn = connection.create_connection(

  File "/home/ubuntu/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 72, in create_connection

    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):

  File "/usr/lib/python3.8/socket.py", line 918, in getaddrinfo

    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):

socket.gaierror: [Errno -3] Temporary failure in name resolution



During handling of the above exception, another exception occurred:```

*Tags: Errors Debugging*

---

**Michael** - *21:21:37*

Also, nothing was written to S3 during this error period so I’ve basically got a full /tmp. Flumine doesn’t seem to have cleaned this up, can I force this somehow

*Tags: Errors Debugging*

---

## 2023-06-19

**Aaron Smith** - *10:54:53*

Just to double check:

I am getting a lot of these bois:

`"WARNING", "message": "Order has violated: MARKET_VALIDATION Error: Market is not open"`

I never really cared much about them, as i assume what happens is that the market is getting closed after my order has been sent out, but before its processed on betfairs end -  so there isnt much to do about it. In that case, i assume everyone is getting a bunch of these over the day?

*Tags: Errors Debugging*

---

## 2023-06-20

**Faye** - *13:40:41*

Could someone tell me if I am using selection_exposure correctly please as it is just returning 0.0 but I know bets have been matched (backtesting)

```blotter = Blotter(market_id=market.market_id)

strategy = Strategy1

lookup = (runner.selection_id, runner.handicap)

exposure = blotter.selection_exposure(strategy, lookup)```



*Tags: Strategies*

---

**liam** - *13:41:41*

More context needed, your strategy needs to be the object itself, is this how you are actually using it?

*Tags: Strategies*

---

**Faye** - *13:47:16*

I'm using it inside the strategy if that's what you mean? I just put that in as that's what I thought I needed to do.

Ha 54years, I think slack is a little confused today!

*Tags: Strategies*

---

**liam** - *13:47:51*

So if you are in a strategy it would be



```exposure = market.blotter.selection_exposure(self, lookup)```

*Tags: Strategies*

---

**liam** - *14:05:29*

follow the [https://github.com/betcode-org/flumine/blob/d2e7d8e6cbc65687d2a0fb41e8f24bf133081f59/flumine/markets/blotter.py#L172|code](https://github.com/betcode-org/flumine/blob/d2e7d8e6cbc65687d2a0fb41e8f24bf133081f59/flumine/markets/blotter.py#L172|code)

*Tags: General Technical*

---

**John Foley** - *17:28:26*

related somewhat to above question:

i’d like for `strategy.process_closed_market` to report my p&amp;l back to the logs once the market has settled. is there a one liner for this? or need to use some combination of the exposure functions from the blotter? wincing at the thought of handling edge cases, dead heats etc but `blotter.process_closed_market` is giving me some hope that stuff may already be handled..

*Tags: Strategies*

---

**liam** - *18:19:36*

ideally you are using a loggingcontrol instance and using the `_process_cleared_markets` function as this has the `betfairlightweight.resources.ClearedOrders` object

*Tags: General Technical*

---

**John Foley** - *18:26:26*

nice one - thats helpful :+1:

*Tags: General Technical*

---

**Jeff Waters** - *21:20:21*

Hi



I've been back testing a system that involves placing a lot of bets. I kept getting an 'ERROR - Transaction limit reached' message, which I presume is meant to prevent users from going over the 5000 (?) bets you can place per hour before you start paying a charge. However, it looks like it continues to apply when processing market activity that took place over an hour after the 5000 limit would have been hit.



Is there anything I can do to get around this, please, as the constant console output slows things down?

*Tags: Errors Debugging, Performance*

---

## 2023-06-23

**MrRob** - *11:54:43*

Hey 



Using R script for betfair and it’s not placing all the expected bets (i.e 1/2 or 2/3 of the bets that it should put on). Running the missing bets manually works, it’s only when the whole code is run at once it’s missing games, so some sort of looping issue? Not sure what part of the code I can send to assist in my issue but any help would be much appreciated :+1: 

*Tags: General Technical*

---

**thambie1** - *12:09:10*

Hey Rob, I doubt anyone here is using R. Most are using the python libraries bflw/flumine. If you haven't already invested heavily into your R framework, I'd suggest switching over.

*Tags: General Technical*

---

**Peter** - *16:26:57*

Personal addition - I switched from PHP when I realised that the tooling, especially betfairlightweight and Flumine, were way ahead of anything in my world ... haven't regretted it for an instant.

*Tags: General Technical*

---

## 2023-06-25

**Brøndby IF** - *20:57:46*

I'm trying to use the API and I get this error alert, but I've been using it for months. Could you help me, please?



If this has already been addressed, I apologize, but I couldn't find the solution.

*Tags: Errors Debugging*

---

## 2023-06-26

**Carl Nielsen** - *06:14:19*

I'm having trouble trying to get the Betfair Streaming API to respond to me..  I'm using Delphi INDY TCPClient and I have SSL set up. I can log in as I have been using the Polling API for years but I'm not having any success with the streaming API.  The endpoint URL's just result in "Host Not Found" and the integration url appears to open but doesn't respond with the connection message.



Anyone have any ideas ? I'm logged in I have a session token and I can't get a response from the streaming API end points

*Tags: General Technical*

---

**Mo** - *08:02:41*

Hate to be dogmatic but I have no idea why you'd be getting that error and I doubt you will find anyone who has the first clue about Delphi on here



I suggest you try `betfairlightweight` ([https://github.com/betcode-org/betfair](https://github.com/betcode-org/betfair)) instead. Streaming example in the documentation here: [https://betcode-org.github.io/betfair/streaming/#market](https://betcode-org.github.io/betfair/streaming/#market)

*Tags: Errors Debugging*

---

**Carl Nielsen** - *08:09:34*

Given that I've been programming in Delphi for around 40  years I'm not that keen to learn a new language and rewrite thousands of lines of code to solve what should be a simple problem. Delphi has always been one of the best programming languages ever produced, complex for sure but compiles directly to machine code not byte code like Python..

*Tags: General Technical*

---

**Mo** - *08:12:11*

I'm not asking you to rewrite your entire stack. Get it working with a software package that has almost a million downloads and 1800 users you can get help from right here. Such a learning exercise might reveal where you are going wrong with Delphi. Or stick with Delphi and get help from... zero? Other Betfair API users using Delphi

*Tags: General Technical*

---

**Mo** - *08:20:19*

Stated another way: we've done the obvious which is to confirm that you're using the right endpoints. So why would you get a "Host Not Found" error? It's not like you're doing something wrong with the message protocol. It can't even resolve the host name. So this has to be something Delphi specific. You're the one who has to solve that

*Tags: Errors Debugging*

---

**Carl Nielsen** - *08:32:05*

Thanks Mo, of the dozens of people and sites I've asked you're the first person (including from Betfair) to confirm the the endpoints are correct.   Surprisingly,  that is a start, when you get Host Not Found errors you tend to focus on the url, now I know that's correct so as you say the problem lies with the SSL settings or the Indy TCP client or settings I'm using..



Sorry if i was a bit sort before, I've been at this for over a week and haven't got of first base yet..

*Tags: Errors Debugging*

---

**Peter** - *08:42:10*

Just a thought. Have Betfair enabled your account for streaming? I’d validate that by using on of the Flumine example scripts to validate that as [@UBS7QANF3](@UBS7QANF3) suggests. Doesn’t need to lead to rewriting your Delphi scripts, but would narrow down the causes - maybe even to one!

*Tags: General Technical*

---

**James** - *11:09:58*

Has anyone running flumine in a container managed to get the exit method working?

I’ve found an example of catching SIGINT’s and SIGTERM’s and calling the baseflumine `__exit__` method, but I was wondering if anyone else has done it/any pitfalls you’ve come across before I dived in.

*Tags: General Technical*

---

**James** - *11:12:24*

I found this

[https://github.com/betcode-org/flumine/issues/665](https://github.com/betcode-org/flumine/issues/665)



And am happy to have a crack at it. Just curious if anyone has done any related interrupt handling in their own deployments?

*Tags: Deployment*

---

**Carl Nielsen** - *23:16:42*

Thanks Mo, yes the Delphi TCP Client uses the INDY components and the host is set to the right URL and Port number.  There are also several SSL settings all of which I've double checked.



Everything is as it should be so why I get the Host Not Found error is a mystery.



Thanks for your help.

*Tags: Errors Debugging*

---

**Carl Nielsen** - *23:20:15*

Thanks Peter, yes Betfair tell me that my AppKey is authorised for the streaming API..   I don't know how to confirm this though, the suggestion to use Flumine also leaves me with a dilemma, How do i use Flumine, I'll have to investigate that furhter.



Thanks also Peter for your help

*Tags: General Technical*

---

## 2023-06-30

**Andrey Luiz Malheiros** - *05:08:52*

Hey guys, I'm using Flumine and couldn't find the answers to these two questions:



1. I tried starting Flumine, and there were 300 markets available for subscription. However, I received an error notification stating that the maximum allowed number was 200 markets. Therefore, I would like to know if it is possible to increase the maximum number of subscriptions.

2. Additionally, I am curious to know if Flumine only performs subscriptions to markets upon initialization or if it continually searches for new markets to subscribe to.

Does anyone have any information on this?

*Tags: Errors Debugging*

---

**Mo** - *06:34:45*

1. Yes. Email BDP and ask them to increase

2. Yes. This is how Betfair streaming works rather than a function of flumine 

*Tags: General Technical*

---

**liam** - *07:29:18*

In addition you can give flumine a list of market filters if you want to split 

*Tags: General Technical*

---

**Lee** - *13:51:15*

It’s a known issue betfair end. I have the same problem where 7/10 attempts to connect to the stream return no markets

*Tags: General Technical*

---

**D C** - *13:52:18*

Thanks for that  - been digging away assuming its my code thats the problem

*Tags: General Technical*

---

**D C** - *14:12:29*

OK thanks thats very helpful

*Tags: General Technical*

---

## 2023-07-01

**Tom** - *02:32:25*

Is order.trade the only way to access the trade objects? I'm trying to save them to runner_context so I can access them (can't figure out how else to call them), and if the program restarts, runner_context.live_trades and trades just has the trade id's. I'm trying to manage multiple orders through a single Trade object, but the flow of logic seems to be strategy-market-blotter-orders-trade; where I want it to be strategy-strategies-runner_context-trade-order where strategies are notes in trade and order used to identify them.



Any suggestions gentlemen?

*Tags: Deployment, Strategies*

---

**Lee** - *10:37:07*

Surprised it’s taking so long to fix

*Tags: Errors Debugging*

---

## 2023-07-02

**Peter** - *11:04:05*

Probably a question(s) for [@U4H19D1D2](@U4H19D1D2), but if anybody else knows I'd love to hear from your.



I'm not hugely familiar with event handling in Python, but it looks to me as though Flumine has a single FIFO queue handled in the main thread. If so, I would speculate that this means that processing heavy custom events would be blocking and a source of latency.



Is there anything in Flumine that would allow custom events to be offloaded to a queue on a different thread, or better a different processor? Or would this basically require building a parallel event handling infrastructure in my strategy runner?

*Tags: Performance, Strategies*

---

**liam** - *12:31:31*

Yes that is all correct, the reason is to keep things simple and remove the potential for race conditions. Do you know that this a problem that needs solving? I.e have you profiled?



Any more context on these custom events? Do they result in order placement / cancellation? 

*Tags: General Technical*

---

**Peter** - *14:27:36*

Problem doesn't need to be solved. This was more a test of my understanding - so many thanks for the confirmation.



My use case is a bit out there. The bottleneck is an external API call, currently called on every price update, but I can push that to a worker and keep track of the results, and only call it within the custom event to validate freshness if a potential bet is to be placed, which is rare compared to price updates.



I can also reduce the frequency with which price updates are evaluated by reducing the ladder size to ignore those that aren't relevant or by conflating changes. So I expect to be able to achieve performance gains of order of magnitude 1000s with just a few tweaks to the data structure and process flow - no need to consider messing with Flumine's simplicity.

*Tags: Performance*

---

**liam** - *14:52:32*

Yeah nothing really to add there, conflation could help if you don't need ms updates

*Tags: General Technical*

---

## 2023-07-03

**Unknown** - *07:14:42*

In the latest copy of the [https://betcode-org.slack.com/files/UQL0QDEKA/F05F2L3UQAH/premium_newsletter_-_june_2023.pdf|Premium Newsletter](https://betcode-org.slack.com/files/UQL0QDEKA/F05F2L3UQAH/premium_newsletter_-_june_2023.pdf|Premium Newsletter), they mention new TPD tracks for 2023. One of these is Keeneland which had racing back in April but I can't see any data in the race stream for these races. A problem on my end or not?

*Tags: General Technical*

---

**Andrey Luiz Malheiros** - *16:10:38*

I'm having issues with the Betfair Historical API. Sometimes I receive the ngErrorRedirect error, and other times I get the correct response for the exact same API request. Does anyone know how to resolve this?

*Tags: Errors Debugging*

---

**Andrey Luiz Malheiros** - *16:23:21*

The worst part is that I've been retrying for a while. It seems like it keeps indefinitely responding with an error, so I think the solution is to wait and hope for it to come back

*Tags: Errors Debugging*

---

**Andrey Luiz Malheiros** - *16:38:41*

Thanks for help. I wanted a systematic way to retrieve historical data, on a daily basis or so. I guess the best approach will be to try several times a day.

*Tags: Data Quality*

---

## 2023-07-04

**Johnny** - *09:40:07*

Potentially a very basic question here.  I'm trying out the example marketrecorder.py and have changed only my login details and local_dir - it starts up and finds all the markets, and creates an empty folder with a UUID, but then all the workers stop.  The strategy continues to run though with no data being supplied.  Does anyone have what else I need to do to get the standard recorder working?



```{"asctime": "2023-07-04 08:31:24,036", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215758531 added, 53 markets in cache"}

{"asctime": "2023-07-04 08:31:24,036", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215758545 added, 54 markets in cache"}

{"asctime": "2023-07-04 08:31:24,037", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215758486 added, 55 markets in cache"}

{"asctime": "2023-07-04 08:31:24,037", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215758498 added, 56 markets in cache"}

{"asctime": "2023-07-04 08:31:24,038", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215727888 added, 57 markets in cache"}

{"asctime": "2023-07-04 08:31:24,039", "levelname": "INFO", "message": "[FlumineStream: 2001]: 57 mc added"}

{"asctime": "2023-07-04 08:31:24,039", "levelname": "INFO", "message": "Adding: 1.215727854 to markets", "client": {"id": "61ef3ddb", "exchange": "Betfair", "betting_client": "APIClient", "chargeable_transaction_count": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxOrderCount object at 0x7f014c174310&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}, "markets": {"market_count": 0, "open_market_count": 0, "live_orders": false, "markets": []}, "streams": ["&lt;OrderStream(OrderStream, started daemon 139643035035200)&gt;", "&lt;DataStream(DataStream, started daemon 139643026642496)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 139643610474304)&gt;", "&lt;Thread(Thread-2, started daemon 139643479651904)&gt;", "&lt;Heartbeat(Thread-3, started daemon 139643471259200)&gt;", "&lt;HistorySavingThread(IPythonHistorySavingThread, started 139643446081088)&gt;", "&lt;ParentPollerUnix(Thread-1, started daemon 139643437688384)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 139643076998720)&gt;", "&lt;BackgroundWorker(poll_account_balance, started daemon 139643068606016)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 139643060213312)&gt;", "&lt;BackgroundWorker(poll_cleared_orders, started daemon 139643051820608)&gt;", "&lt;Thread(TEST_load_processor, started daemon 139643043427904)&gt;", "&lt;OrderStream(OrderStream, started daemon 139643035035200)&gt;", "&lt;DataStream(DataStream, started daemon 139643026642496)&gt;", "&lt;Thread(OrderStream_output_thread, started daemon 139642540127808)&gt;"]}

{"asctime": "2023-07-04 08:31:24,042", "levelname": "INFO", "message": "Stopped DataStream 2001"}

{"asctime": "2023-07-04 08:31:24,042", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

{"asctime": "2023-07-04 08:31:24,042", "levelname": "INFO", "message": "Stopped OrderStream 1001"}

{"asctime": "2023-07-04 08:31:24,044", "levelname": "INFO", "message": "Shutting down Execution (BetfairExecution)"}

{"asctime": "2023-07-04 08:31:24,045", "levelname": "INFO", "message": "BackgroundWorker keep_alive shutting down", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x7f0144ce3670&gt;"}

{"asctime": "2023-07-04 08:31:24,235", "levelname": "INFO", "message": "Stopped output_thread (OrderStream 1001)"}

{"asctime": "2023-07-04 08:31:28,046", "levelname": "INFO", "message": "BackgroundWorker poll_account_balance shutting down", "worker_name": "poll_account_balance", "function": "&lt;function poll_account_balance at 0x7f0144ce3940&gt;"}

{"asctime": "2023-07-04 08:31:32,047", "levelname": "INFO", "message": "BackgroundWorker poll_market_catalogue shutting down", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x7f0144ce38b0&gt;"}

{"asctime": "2023-07-04 08:31:36,049", "levelname": "INFO", "message": "BackgroundWorker poll_cleared_orders shutting down", "worker_name": "poll_cleared_orders", "function": "&lt;function poll_cleared_orders at 0x7f0144ce39d0&gt;"}

{"asctime": "2023-07-04 08:31:40,172", "levelname": "INFO", "message": "Exiting flumine", "client": {"id": "61ef3ddb", "exchange": "Betfair", "betting_client": "APIClient", "chargeable_transaction_count": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxOrderCount object at 0x7f014c174310&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}, "markets": {"market_count": 1, "open_market_count": 1, "live_orders": false, "markets": ["1.215727854"]}, "streams": ["&lt;OrderStream(OrderStream, stopped daemon 139643035035200)&gt;", "&lt;DataStream(DataStream, stopped daemon 139643026642496)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 139643610474304)&gt;", "&lt;Thread(Thread-2, started daemon 139643479651904)&gt;", "&lt;Heartbeat(Thread-3, started daemon 139643471259200)&gt;", "&lt;HistorySavingThread(IPythonHistorySavingThread, started 139643446081088)&gt;", "&lt;ParentPollerUnix(Thread-1, started daemon 139643437688384)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 139643076998720)&gt;", "&lt;BackgroundWorker(poll_account_balance, started daemon 139643068606016)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 139643060213312)&gt;", "&lt;BackgroundWorker(poll_cleared_orders, started daemon 139643051820608)&gt;", "&lt;Thread(TEST_load_processor, started daemon 139643043427904)&gt;"]}

---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-2-ce727f3ddda0&gt; in &lt;module&gt;

     20 framework.add_strategy(strategy)

     21 

---&gt; 22 framework.run()



~/anaconda3/lib/python3.8/site-packages/flumine/flumine.py in run(self)

     27 

     28                 elif event.EVENT_TYPE == EventType.RAW_DATA:

---&gt; 29                     self._process_raw_data(event)

     30 

     31                 elif event.EVENT_TYPE == EventType.CURRENT_ORDERS:



~/anaconda3/lib/python3.8/site-packages/flumine/baseflumine.py in _process_raw_data(self, event)

    211             for strategy in self.strategies:

    212                 if stream_id in strategy.stream_ids:

--&gt; 213                     strategy.process_raw_data(publish_time, datum)

    214 

    215     def _process_market_catalogues(self, event: events.MarketCatalogueEvent) -&gt; None:



TypeError: process_raw_data() missing 1 required positional argument: 'data'```



*Tags: Errors Debugging, Deployment, Strategies*

---

**Mo** - *09:41:33*

Is this a fresh install of flumine? Looks like some kind of version conflict

*Tags: Getting Started*

---

## 2023-07-05

**Alex** - *10:50:31*

When running a strategy with pro data I encounter: `'list' object has no attribute 'put'` when calling `flumine.handler_queue.put`, i.e. the handler_queue has been replaced with a list while it should supposedly be a queue object. Anyone else encounter this before? To add some context: this happens in a worker thread not in the main flumine thread

*Tags: Strategies*

---

**liam** - *10:56:39*

Simulation doesn't use a [https://github.com/betcode-org/flumine/blob/d2e7d8e6cbc65687d2a0fb41e8f24bf133081f59/flumine/simulation/simulation.py#L27|queue](https://github.com/betcode-org/flumine/blob/d2e7d8e6cbc65687d2a0fb41e8f24bf133081f59/flumine/simulation/simulation.py#L27|queue) so this won't work, what are you trying to put in the queue?

*Tags: General Technical*

---

**Alex** - *11:04:45*

No particular reason, I wrote this a long time ago when I first started playing around with flumine.

*Tags: General Technical*

---

**Alex** - *11:08:39*

I saw there are a few examples in flumine

*Tags: General Technical*

---

**Alex** - *11:30:11*

Middleware doesn't seems to allow for a context object to get passed between different runs, unless I get this wrong. What's the best workaround around this? I could presumably add a context attribute to flumine. Or the strategy.

*Tags: Strategies*

---

**liam** - *11:31:08*

`market.context` or `strategy.context` or just store it in the middleware itself `self.myshit`

*Tags: Strategies*

---

## 2023-07-06

**John Foley** - *10:01:38*

yeah i am doing this (systematically collecting the data every day) and there’s no avoiding the random errors, just have to handle the retries in your code. For me, the program runs daily and if it keeps failing, after x number of failures just give up and try again tomorrow. 

*Tags: Errors Debugging*

---

**John Foley** - *10:05:19*

the historical data has a 5 day delay, so never been a big deal if I miss a day or two because of connection errors 

*Tags: Data Quality, Errors Debugging*

---

## 2023-07-08

**Andy** - *14:03:00*

# Create filters to get the events

    horse_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["PLACE", "WIN"]

    )

    greyhound_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["4339"],

        country_codes=["AU"],

        market_types=[“WIN"]

    )





Encountered an error (connection_id: 106-080723010256-1216805, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"101-080723010255-1157348"}) when starting or running the stream.





Getting this error when have tried to add both Win and Place to the market types filter. It works for Win and Place individually but won’t work with both for some reason? I have seen other peoples code having multiple market filters though?

*Tags: Errors Debugging*

---

## 2023-07-10

**Andy** - *08:39:49*

def start_stream(bfl_trading, bfl_client, event_types=["horse", "greyhound"]):

    """Retrieves a json dictionary with the stream data from the specified event types."""

    for event in event_types:

        event_types[event_types.index(event)] = EVENT_TYPE_IDS[event]



    # create queue

    output_queue = queue.Queue()



    # create stream listener

    listener = betfairlightweight.StreamListener(output_queue=output_queue)



    # create stream

    streamH = bfl_trading.streaming.create_stream(listener=listener)

    streamG = bfl_trading.streaming.create_stream(listener=listener)



    # Create filters to get the events

    horse_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["PLACE", "WIN"]

    )

    greyhound_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["4339"],

        country_codes=["AU"],

        market_types=["WIN"]

    )



    market_data_filter = filters.streaming_market_data_filter(

        fields=["EX_BEST_OFFERS", "EX_MARKET_DEF"], ladder_levels=3

    )





    # subscribe

    horse_streaming_unique_id = streamH.subscribe_to_markets(

        market_filter=horse_market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=5000,  # send update every 1000ms

    )



    greyhound_streaming_unique_id = streamG.subscribe_to_markets(

        market_filter=greyhound_market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=5000,  # send update every 1000ms

    )



    # start stream in a new thread (in production would need err handling)

    tH = threading.Thread(target=streamH.start, daemon=True)

    tH.start()

    tG = threading.Thread(target=streamG.start, daemon=True)

    tG.start()



    return streamH, output_queue

*Tags: Deployment, Strategies*

---

## 2023-07-11

**Andy** - *01:57:54*

Yea have seen the examples. My code is slightly different but I think basically doing the same thing. Thinking back to when I put the code together, I think S_cenario 2_ didn't work for me originally but S_cenario 6_ did/does - I assume that's your main concern with the code. The problem with the examples is that none of them have a scenario for passing multiple event ids or multiple market types codes and that's where I'm falling down

*Tags: General Technical*

---

**Andy** - *03:23:44*

• Wanting to get WIN and PLC markets for horse and greyhounds but currently it's impossible.

Ideally would have one filters.streaming_market_filter with event_type_ids=["7","4339"] and market_types=["WIN","PLACE"]



• Scenario 1) Using 1 streaming_market_filter with both of the above settings shows the following error multiple times and returns nothing:

Encountered an error (connection_id: 208-110723015800-1550840, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is

not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"208-110723015800-1550840"}) when starting or running the stream.



• Scenario 2) Using 1 streaming_market_filter with both of the above settings works for market_types=[WIN] only.

• *Scenario 3) Using 1 filter - event_type_ids=["7"] and market_types=["WIN", "PLACE"] works?? (only scenario with multiple parameters set where any place markets are received)*

• Scenario 4) Using 1 filter - event_type_ids=["4339"] and market_types=["WIN", "PLACE"] *does not work*. Same error as trying event_type_ids=["7","4339"] and market_types=["WIN","PLACE"]

Encountered an error (connection_id: 210-110723020837-1593171, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"210-110723020837-1593171"}) when starting or running the stream.



• Scenario 5) trying two streaming_market_filters (one with event_type_ids=["7"] and another one with event_type_ids=["4339"]) and market_types=["WIN","PLACE"] for both does not work, throws error:

Encountered an error (connection_id: 203-110723021056-1561190, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"203-110723021056-1561190"}) when starting or running the stream.



• *Scenario 6) trying two streaming_market_filters (one with event_type_ids=["7"] and another one with event_type_ids=["4339"]) and market_types=["WIN"] also works..*

• Scenario 7) Subscribing with 4 different streaming filters shows this error twice:

Encountered an error (connection_id: 210-110723013905-1590774, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is

not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"210-110723013905-1590774"}) when starting or running the stream.

Very ocassionally get this issue:

Encountered an error ([Connect: 5]: Socket [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:2546)) when starting or running the stream



Using Live API key which I'm told has 10 max connections by default

*Tags: Errors Debugging, Deployment*

---

**Harry Corrigan** - *19:52:28*

Hi, does anyone know why, in a very simple strategy implemented in flumine, the function 'process_raw_data' isn't being called

I have authenticated and the process_market_book function is pushing out data

however the process_raw_data function, on the same strategy, is never called

Is there more you need to do in order to get the raw data coming in, or is there some other issue?

*Tags: Strategies*

---

**liam** - *19:56:42*

Raw data is for when recording as it uses a different stream_class, are you after the raw data in process_market_book? It’s available in ‘MarketBook.streaming_update’

*Tags: General Technical*

---

**R** - *20:22:10*

Is there a way I can format order prices that I get from the SP near price (during simulation) so that I don't get the error:



`Order price is not valid for CLASSIC ladder`



I've dug around quickly in the codebase but nothing popped out to me that there was some handler to "squash" prices into the correct bracket of the ladder

*Tags: Errors Debugging*

---

**R** - *20:23:07*

also, second question: if during simulation this validation warning is thrown, will the order be thrown out also?

*Tags: General Technical*

---

**liam** - *20:24:20*

Yes, there is a function called nearest_price, it’s in utils either in bflw or flumine 

*Tags: General Technical*

---

## 2023-07-12

**Andy** - *00:54:02*

They haven't responded yet but very confident now the timeout is just too much data for it to handle. I can originally get 7 for WIN and PLACE and 4399 for PLACE for example, but then will just timeout on a future iteration after a minute or two. The question then becomes, how do we get around this? Surely just streaming AUS WIN and PLACE Racing markets shouldn't be outside the realms of what is reasonable. There's nothing inherently wrong with my connection, I'm on fast enough internet

*Tags: General Technical*

---

**Andrey Luiz Malheiros** - *02:29:49*

I am trying to save the updates of my executed orders in Flumine. As soon as I cancel an order, I save the information of that order. Then, in the `process_closed_market` function, I save the information of all the orders in `market.blotter`. However, for the orders that I canceled, the `size_remaining` remains unchanged and does not turn into `size_cancelled`. I suspect that the canceled orders are removed from the market before `process_closed_market` is executed. So, I would like to know at what point a canceled order is removed from the market?

*Tags: General Technical*

---

**Andy** - *02:34:30*

Betfair response:



Hi Andy,



Thanks for sending through the details of the error messages you’re getting. It looks like you’re hitting the market limit on your live key.



We’ll forward this to our API team in the UK and get them to increase the market limit. That should happen overnight tonight and we’ll confirm tomorrow.

*Tags: Errors Debugging, Deployment*

---

**Unknown** - *03:19:06*

:wave: Hello, team!   I am trying to get a API key but i get an error.  Any idea what I can do to fix this?

*Tags: Errors Debugging*

---

**liam** - *08:21:28*

Thats weird as you should get a subscription limit error rather than timeout

*Tags: Errors Debugging*

---

**Andrey Luiz Malheiros** - *13:19:45*

I first cancel the order using Flumine's market, then I save the order information in the database, such as size_matched, size_remaining, ...

*Tags: General Technical*

---

**Andrey Luiz Malheiros** - *16:52:55*

I seem to be having some latency issues. It was working fine until yesterday, but today it started consistently showing the following errors. Even if I terminate the execution of Flumine and start it again, the errors persist. I'll send the logs I'm receiving. These errors persist, and no orders are being placed, and the strategies are not being executed. Does anyone know how to resolve this or at least attempt to remedy it?

```[2023-07-12 14:20:07,894: INFO/ForkPoolWorker-2] Client update account details

[2023-07-12 14:21:07,795: INFO/ForkPoolWorker-2] Updated marketCatalogue for 1.215993597

[2023-07-12 14:21:18,819: INFO/ForkPoolWorker-2] Market 1.215993597 closed

[2023-07-12 14:21:42,401: WARNING/ForkPoolWorker-2] [MarketStream: 2001]: Latency high: 0.5233955383300781

[2023-07-12 14:53:35,502: WARNING/ForkPoolWorker-2] [MarketStream: 2001]: Latency high: 1505.3750047683716

[2023-07-12 15:30:03,086: WARNING/ForkPoolWorker-2] [MarketStream: 2001]: Latency high: 4085.18798494339```

*Tags: Errors Debugging, Performance*

---

**Peter** - *17:43:15*

Clearly something is going very wrong. the starting point would be to profile your code. See [https://betcode-org.github.io/flumine/performance/#strategy](https://betcode-org.github.io/flumine/performance/#strategy). Also are you experiencing any network issues at the location where you run your strategies?

*Tags: Performance, Strategies*

---

**Andrey Luiz Malheiros** - *20:47:01*

After much effort and debugging, I discovered that a function of mine that I applied in the `processed_closed_market` was in an infinite loop, and that was causing significant delays.

*Tags: Errors Debugging*

---

## 2023-07-14

**Andy** - *00:46:48*

[@U4H19D1D2](@U4H19D1D2)  the problem came back overnight…



I was previously getting this error 100% of the time within a minute when I tried to get all horses and dogs win and place for AU racing.



• After my live key was pumped up to 1k markets, the problem seemingly went away instantly and stayed away for ~14 hours. 

• Last night it came back. There were a lot of horse racing markets on site at the time (more than I’d probably ever received before). All of Fridays thoroughbred and trots meetings (15 meetings) and 5 of Saturdays thoroughbred already. But no greyhound racing at all as they hadn’t been loaded yet for the next day. This is the part that perplexes me. 

• I think it’s clear that whatever was done to pimp my API key the previous day had some desirable effect but in saying that, I wasn’t near 1k markets when the crash happened….



Now betfair have come back with the following:





Hi Andy,



I checked with the UK API team and got the response below overnight. Sounds like the issue is related to the socket handling outlined in this GitHub issue thread - [https://github.com/betcode-org/betfair/issues/11|https://github.com/betcode-org/betfair/issues/11](https://github.com/betcode-org/betfair/issues/11|https://github.com/betcode-org/betfair/issues/11)



If you could check those settings and see if it resolves the issue.



UK Response



A TIMEOUT error on a subscription request has a clear root cause – this is indicated by the error description and in our docs (":"Connection isnot subscribed and is idle: 15000 ms)  (see [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-TCP/SSLConnection|https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-TCP/SSLConnection](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-TCP/SSLConnection|https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-TCP/SSLConnection))



Avoiding TIMEOUT on connection

Once you have established a connection you should send a message within 15 seconds to avoid receiving a TIMEOUT error



Strange that he would receive this error in any other circumstances though, so yes, it could be related to socket handling as mentioned in that github issue thread.

*Tags: Errors Debugging, Deployment*

---

**Andy** - *11:49:21*

Now this :



Do they mean by this comment that flumine can only handle 1k markets or they don’t want to increase above 1k…?



Hi Andy,

 

We’re not experts with using Flumine, but I managed to recreate the error message using the same filters.

 

It triggered the SUBSCRIPTION_LIMIT_EXCEEDED, then the TIMEOUT error that you received.

 

We can’t increase the market limit again as appears you’ll need to adjust your strategy to filter the number of markets to below 1000 and see if that works.

 

You could see if Liam (betcode) has any suggestions on why you’re not seeing the SUBSCRIPTION_LIMIT_EXCEEDED?

 

 

Filters

 

strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["7","4339"],

        #country_codes=["GB"],

        market_types=["WIN","PLACE"],

    ),

 

 

Error Log

 

2023-07-14 16:32:54,606:ERROR:[MarketStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 1258 markets whereas max allowed number was: 1000

2023-07-14 16:32:54,607:INFO:[MarketStream: 2001]: FAILURE (4 connections available)

2023-07-14 16:33:03,126:INFO:Client update account details

2023-07-14 16:33:10,123:ERROR:[MarketStream: None]: TIMEOUT: Connection is not subscribed and is idle: 15000 ms

2023-07-14 16:33:10,124:ERROR:MarketStream 2001 run error

Traceback (most recent call last):

  File "c:\Users\DouglasB\GitHub\How-to-Automate-Public-Version\.venv\lib\site-packages\flumine\streams\marketstream.py", line 44, in run

    self._stream.start()

  File "c:\Users\DouglasB\GitHub\How-to-Automate-Public-Version\.venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "c:\Users\DouglasB\GitHub\How-to-Automate-Public-Version\.venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 233, in _read_loop

    self._data(received_data)

  File "c:\Users\DouglasB\GitHub\How-to-Automate-Public-Version\.venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 274, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 209-140723063254-1955531, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"209-140723063254-1955531"}

*Tags: Errors Debugging, Strategies*

---

**liam** - *12:30:36*

The latter, you can however give flumine a list of market filters to get around this if they won’t bump above 1k 

*Tags: General Technical*

---

**Andy** - *12:33:29*

I'm using BFLW though for my stream? I've had a lot of help with my code.... I'm not super well versed. I'm unsure how to proceed

*Tags: General Technical*

---

**liam** - *12:33:59*

Delete it all and use flumine 

*Tags: General Technical*

---

**Andy** - *12:39:38*

They are asking though if you have any idea why I didn't get *SUBSCRIPTION_LIMIT_EXCEEDED* message. Looking at their messages, is it just they have logging on for this? In their test, they get *SUBSCRIPTION_LIMIT_EXCEEDED* then they get Encountered an error (connection_id: 106-080723010256-1216805, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"101-080723010255-1157348"}) when starting or running the stream afterwards, same as me

*Tags: Errors Debugging*

---

## 2023-07-18

**Mo** - *07:05:27*

I'm not sure if there's a canonical way to get these into flumine; seems kind of annoying they're not included in the order stream

*Tags: General Technical*

---

**Nacho Uve** - *07:12:42*

Hi,



I'm stuck with a problem that I've encountered before when simulating football strategies.

Here are the steps:

1. I place an order at a price slightly higher than the current market price.

2. The order is marked as "EXECUTABLE," but

3. When the market reaches that price or a higher price, the bet remains unmatched (even though there is enough size available).

I've tried to check the simulation code in flumine to see what might be happening, but I can't find the source of the error. I suspect that for some reason, the order is no longer being evaluated during market_books stream updates. Am I understanding this correctly, or am I doing something wrong?



I have a recorded stream file and a simple strategy example that I can share if it would be helpful to review.



Thanks in advance!

*Tags: Errors Debugging, Strategies*

---

**Nacho Uve** - *07:31:05*

Here It is a simple dummy strategy to visualize the problem.

It use an example market  where this happens:

```import sys

import logging



from flumine import BaseStrategy



from flumine.order.trade import Trade

from flumine.order.order import OrderStatus

from flumine.order.ordertype import LimitOrder







MARKET_ID = "1.214780186"

SELECTION_ID = 676464



class Back_Dummy_Strategy(BaseStrategy):



    def check_market_book(self, market, market_book):

        if market.market_id != MARKET_ID:

            return False

        return market_book.inplay





    def process_market_book(self, market, market_book):



        if market_book.status == "SUSPENDED":

            import time

            print("SUSPENDED")

            try:

                import ipdb

                ipdb.set_trace()

            except Exception as e:

                print(e)



        if len(market.blotter):

            for oo in market.blotter:

                if oo.status == OrderStatus.EXECUTABLE:

                    print("Already one order... ")

                    self.available_to_back(market_book)

        else:

            trade = Trade(

                market_id=market.market_id,

                selection_id=SELECTION_ID,

                handicap=0,

                strategy=self

            )

            order = trade.create_order(

                side="BACK",

                order_type=LimitOrder(price=1.11, size=2),

                notes={1:f"My first dummy order"}

            )

            market.place_order(order)





    def available_to_back(self, market_book):

        print("== market_book available to back ==")

        print(f"Time: {market_book.publish_time}")

        for rr in market_book.runners:

            atb = rr.ex.available_to_back

            print(rr.selection_id, atb)

        print("==================================")



    def process_orders(self, market, orders):



        super().process_orders(market, orders)



        for i, oo in enumerate(orders):

            try:

                print("********** Orders *************")

                print(f"****  {i+1}/{len(orders)}")

                print(oo.status)

                print(f"@{oo.order_type.price} {oo.order_type.size}$")

                print(f"Matched: {oo.size_matched}$")

                print("*******************************")



            except Exception as e:

                print(e)```

Could I share the recorded stream file of example? or is there any restriction?

*Tags: Errors Debugging, Strategies*

---

**Mo** - *07:34:54*

There hasn't been a problem sharing such files in the past

*Tags: General Technical*

---

**Unknown** - *07:42:45*

Thanks [@UBS7QANF3](@UBS7QANF3)



Ok, there goes the file.



And here I put an extract of the output of the strategy where you can see how the order is waiting to be matched, but it seems that it is ignored during a lot of market_book updates, until the market is suspended.



```********** Orders *************

****  1/1

OrderStatus.EXECUTABLE

@1.11 2$

Matched: 0.0$

*******************************

Already one order... 

== market_book available to back ==

Time: 2023-06-04 16:47:11.895000

676464 [{'price': 1.15, 'size': 510.62}, {'price': 1.14, 'size': 3312.51}, {'price': 1.13, 'size': 7.62}]

60311 [{'price': 22, 'size': 69.49}, {'price': 21, 'size': 1.72}, {'price': 20, 'size': 6.89}]

58805 [{'price': 9.6, 'size': 64}, {'price': 9.4, 'size': 184.92}, {'price': 9, 'size': 18.95}, {'price': 8.8, 'size': 22.4}, {'price': 8.6, 'size': 4.07}, {'price': 7.8, 'size': 35.98}]

==================================

********** Orders *************

****  1/1

OrderStatus.EXECUTABLE

@1.11 2$

Matched: 0.0$

*******************************

Already one order... 

== market_book available to back ==

Time: 2023-06-04 16:47:12.792000

676464 [{'price': 1.15, 'size': 510.62}, {'price': 1.14, 'size': 3312.51}, {'price': 1.13, 'size': 7.62}]

60311 [{'price': 22, 'size': 69.49}, {'price': 21, 'size': 1.72}, {'price': 20, 'size': 6.89}]

58805 [{'price': 9.6, 'size': 64}, {'price': 9.4, 'size': 184.92}, {'price': 9, 'size': 18.95}, {'price': 8.8, 'size': 22.4}, {'price': 8.6, 'size': 4.07}, {'price': 7.8, 'size': 35.98}]

==================================

********** Orders *************

****  1/1

OrderStatus.EXECUTABLE

@1.11 2$

Matched: 0.0$

*******************************

Already one order... 

== market_book available to back ==

Time: 2023-06-04 16:47:14.425000

676464 [{'price': 1.15, 'size': 510.62}, {'price': 1.14, 'size': 3312.51}, {'price': 1.13, 'size': 7.62}]

60311 [{'price': 22, 'size': 69.49}, {'price': 21, 'size': 1.72}, {'price': 20, 'size': 6.89}]

58805 [{'price': 9.6, 'size': 62.28}, {'price': 9.4, 'size': 184.92}, {'price': 9, 'size': 18.95}, {'price': 8.8, 'size': 22.4}, {'price': 8.6, 'size': 4.07}, {'price': 7.8, 'size': 35.98}]

==================================

********** Orders *************

****  1/1

OrderStatus.EXECUTABLE

@1.11 2$

Matched: 0.0$

*******************************

Already one order... 

== market_book available to back ==

Time: 2023-06-04 16:47:15.100000

676464 [{'price': 1.15, 'size': 510.62}, {'price': 1.14, 'size': 3123}, {'price': 1.13, 'size': 7.62}]

60311 [{'price': 22, 'size': 69.49}, {'price': 21, 'size': 1.72}]

58805 [{'price': 9.6, 'size': 62.28}, {'price': 9.4, 'size': 184.92}, {'price': 8.6, 'size': 4.07}, {'price': 7.8, 'size': 35.98}]

==================================

********** Orders *************

****  1/1

OrderStatus.EXECUTABLE

@1.11 2$

Matched: 0.0$

*******************************

Already one order... 

== market_book available to back ==

Time: 2023-06-04 16:47:15.336000

676464 [{'price': 1.13, 'size': 7.62}]

60311 [{'price': 21, 'size': 1.72}]

58805 [{'price': 8.6, 'size': 4.07}, {'price': 7.8, 'size': 35.98}]

==================================

********** Orders *************

****  1/1

OrderStatus.EXECUTION_COMPLETE

@1.11 2$

Matched: 0.0$

*******************************

SUSPENDED```



*Tags: Strategies*

---

**liam** - *08:25:28*

Yeah nothing built into flumine as we are streaming only but would suit a worker to inject it into the context somewhere 

*Tags: General Technical*

---

**Nacho Uve** - *09:39:59*

Ahhh...



So... in this example of strategy, if I had made a real bet on betfair, yes, a match would take place, right? But when I'm in simulation mode a match will only be made if similar bets have been matched during recording, right?



I would like to test strategies over markets without so much "trade volume".

Do you think there would be a way to simulate that behavior of betfair where orders are matched when there is volume available for that price or higher?

*Tags: Strategies*

---

**liam** - *12:06:27*

Yes and yes but would need a code change or a slightly different middleware, question is to if we want this to be the default behaviour or not 

*Tags: General Technical*

---

**Nacho Uve** - *12:38:23*

Yes. I guess if no one has run into this, it's because for most users this isn't a problem. Maybe setting it to default will have some impact...



In any case, it would be great to add a new SimulatedMiddleware (or to be able to parameterize that option). If so, strategies could be addressed in this type of unpopular markets/events.



    I've been reviewing the code of the simulation part, and I find it a bit complex (for my level). Still, I'd like to try to achieve that behavior. [@U4H19D1D2](@U4H19D1D2) Could you give me some guidance on what changes I should make?

*Tags: General Technical*

---

## 2023-07-19

**Nacho Uve** - *12:44:08*

Hummm... paper_trade is using simulation engine, so I will find the same behaviour even connecting to live data stream to test this kind of strategies... Am I right?

*Tags: Deployment*

---

## 2023-07-20

**liam** - *13:08:24*

Race stream ‘unexpected error’ issues today or is it just me? 

*Tags: Errors Debugging*

---

**Alex** - *13:19:40*

I have the same issue, just a simple strategy placing a limit order and then checking its status. I believe it was previously mentioned that middleware has to be used somehow to make sure that limit orders moved to ‘complete’ status?

*Tags: Strategies*

---

## 2023-07-21

**foxwood** - *12:44:23*

Sorry, seem to have managed to break the shin() implementation [@UBS7QANF3](@UBS7QANF3) This was a backtest on a race with only 3 active runners. Occurred on only a couple of races in many thousands. Digging around, came up with the code below that crashes in console. Running latest v0.0.2 under Python 3.9. Think the maths is above my pay grade lol.



```import shin

odds = [2.08, 2.12, 3]	# back odds - works ok

shinDict = shin.calculate_implied_probabilities(odds)

print(shinDict)

odds = [5, 10, 20]	# lay odds - OverflowError (34, 'Result too large')

shinDict = shin.calculate_implied_probabilities(odds)

print(shinDict)```

*Tags: Errors Debugging*

---

**foxwood** - *12:54:52*

I think it was a BF issue at the time - the actual race had 6 dogs  and none were reserves. Only 3 were marked as ACTIVE in market_book.runners and 3 as REMOVED. Just a weird combo that crashes with exception though.

*Tags: Errors Debugging*

---

**Mo** - *12:55:48*

The package could definitely do with some better error handling

*Tags: Errors Debugging*

---

**foxwood** - *13:02:49*

I had wrapped it in a try call cos broke on back odds at some point. The exception was handled by just calling shin for the lay odds and no exception from that was allowed for lol. Will change my code to cope with the error.

*Tags: Errors Debugging*

---

## 2023-07-23

**Peter** - *11:37:33*

In that case yes, the bets should void (same reference). But I'm a little confused now. Are you saying that they did void at Betfair, but remained in the Flumine market blotter - I would expect this, but with the blotter entry updated to show the amount voided. Is that not what you saw?

*Tags: General Technical*

---

## 2023-07-24

**liam** - *08:37:04*

[https://github.com/betcode-org/betfair/issues/523|This](https://github.com/betcode-org/betfair/issues/523|This) is why open source sucks, not sure it even deserves a response tbh

*Tags: General Technical*

---

**Mo** - *08:50:03*

I think a simple response along the lines of:



&gt; If you are unable or unwilling to implement robust error handling in your code I suggest you look at flumine which is a fully featured trading framework sitting atop betfairlightweight

would go a long way

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

**liam** - *09:01:31*

Probably, just find it amazing that someone can go to the effort of writing all of that but not fix there shitty code

*Tags: Errors Debugging*

---

**Mo** - *09:10:58*

They're just clueless - sounds like they don't know about exception handling so rather than using try/except they are looking at sys.last_value which I have never heard of before?!

*Tags: Errors Debugging*

---

**foxwood** - *10:00:20*

Amazing lol. And to know of such a system field when the explanation of its use is for when an unhandled exception occurs :joy: `sys.last_type sys.last_value sys.last_traceback These three variables are not always defined; they are set when an exception is not handled and the interpreter prints an error message and a stack traceback.`

Edit: Never heard of it either and had to look it up

*Tags: Errors Debugging*

---

## 2023-07-26

**Harry Corrigan** - *10:17:29*

Hi, i'm having an issue placing basic trades from within a strategy using flumine

on proccess_market_book being called i attempt to place an order but when i run market.place_order i get a runtime error raised by `self._thread_pool.submit(func, order_package, http_session)`  the error says cannot schedule new futures after interpreter shutdown, i have a custom stream to pipe data into the strategy which may be causing it? wondering if anyone has seen this error before and if so how did you fix it

*Tags: Errors Debugging, Strategies*

---

**Harry Corrigan** - *10:21:25*

flumine shows no errors beforehand

*Tags: Errors Debugging*

---

**Harry Corrigan** - *10:55:52*

Solved the issue, the problem was the thread pool was closing with the main thread, after starting flumine the main thread exits which for some reason causes the ThreadPoolExecutor to shut down as well, the solution was to force the main thread to stay open with a while loop

*Tags: General Technical*

---

**Harry Corrigan** - *10:59:08*

not sure, it's probably cus the body of my application is running on it's own threads, including starting flumine, so it isn't blocking the main thread causing it to exit and im guessing the thread pool executor needs the main thread open for whatever reason (maybe cus it was started within the main thread?)

*Tags: General Technical*

---

**liam** - *11:01:14*

Run flumine in its own process, ideally main

*Tags: General Technical*

---

**Harry Corrigan** - *11:02:28*

It's started in its own thread for other reasons, literally just threading.Thread(target=flumine.start). start()

*Tags: General Technical*

---

**Harry Corrigan** - *11:06:27*

Yh flumine as a whole seems fairly sensitive to things I wouldn't automatically think of, but it works well when it does

*Tags: General Technical*

---

**liam** - *11:07:33*

'its fragile' is a comment on the way you are doing things not flumine

*Tags: General Technical*

---

## 2023-07-27

**Nacho Uve** - *07:58:56*

My Betfair account is in Spain. I was running Flumine on a server that I would like to cancel. I was completing the migration to an EC2 instance (region Paris), but when trying to connect from the server, it throws an error:

&gt; betfairlightweight.exceptions.LoginError: API login: BETTING_RESTRICTED_LOCATION

In Europe, EC2 offers regions: London, Dublin, Stockholm, Paris, or Frankfurt, none of which are in Spain.



Do you think any of these will work, or is there a way to operate from AWS with a Spanish account?

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2023-07-31

**foxwood** - *17:52:42*

I'm trying to match dogs' names to external data but falling over with reserves. The reserve selection is in the market and marked as active and the retired dog as removed. When I map the runner selectionID to the catalogue however there is no entry for the new runner ie the catalogue has not been updated (yet?). Any ideas of a way round this - happens on backtest - probably dependent on BF publishing new catalogue ? Maybe there is a way of forcing a catalogue update in flumine and suspending processing until completed without jamming the whole process waiting for BF ?

Edit: Looking at json catalogue no entry of the new runner at all - recording problem ? Not sure if this happens on live or not now.

*Tags: Deployment*

---

**AP** - *20:27:14*

Has anyone ever come across this error?

```Unknown error 'LimitOnCloseOrder' object has no attribute 'price_ladder_definition' in process_market_book```

*Tags: Errors Debugging*

---

**Lee** - *20:29:35*

Update flumine 

*Tags: General Technical*

---

## 2023-08-01

**foxwood** - *10:01:48*

I'm guessing it's something like that having slept on it - pretty sure the latest should work - BF manage to get the name plus "Res" suffix into their price data. Just used the flumine market recorder out of the box I think but will have a look and see if I managed to break it ! Assume this is not normal otherwise others would have fallen over it before ?

*Tags: Data Quality, Errors Debugging*

---

**foxwood** - *17:48:13*

Just did a quick mod of `BFLWexampleone.py` to dump current live GH catalogues - lots of runner in latest catalogues today with `"(res)"` suffix where reserve taking place of original dog. Therefore issue when recording doesn't appear to be a BF issue.

*Tags: Errors Debugging, Deployment*

---

**foxwood** - *19:35:18*

Market objects have a `__call()` method which flags a catalogue update needed when the `market_book.version` changes. That changes a few times when the reserve substitution takes place. Debugging the market recorder the `market_book` field for every event is set to `None` - is this the gotcha - no book when recording ?

*Tags: Data Quality, Errors Debugging*

---

**liam** - *19:40:24*

Ah good spot, can you create a github issue and I can see if we can fix 

*Tags: Errors Debugging*

---

**foxwood** - *22:12:33*

done - suggested dirty fix

*Tags: Errors Debugging*

---

## 2023-08-02

**foxwood** - *13:13:48*

Running it live today and will let you know if it works . Another issue that I've not looked at with this is that bets are voided - wondering what happens to orders in blotter for both simulation and live ? Market info for dogs : _If a non-runner or reserve runner is declared all bets with the exception of Betfair SP bets on unaffected traps, placed on the race prior to the update of the market on Betfair will be void._ I've been ignoring all this in the past and just accepting the swings and roundabouts this causes but having to look at it now matching to external data.

*Tags: Errors Debugging, Deployment*

---

**liam** - *13:20:36*

Should be [https://github.com/betcode-org/flumine/blob/ff71b2b92c4a6ae53fb9cf83ec3b1bdf30e7da97/flumine/markets/middleware.py#L56|handled](https://github.com/betcode-org/flumine/blob/ff71b2b92c4a6ae53fb9cf83ec3b1bdf30e7da97/flumine/markets/middleware.py#L56|handled) as I assume the `runner.status` becomes REMOVED

*Tags: General Technical*

---

**Riccardo Fresi** - *13:38:44*

hi, anyone can help on generating certificate?

seems that i can login but i cannot reach betting endpoint

*Tags: Strategies*

---

**Mo** - *13:39:18*

As I asked, what version of Python are you running

*Tags: General Technical*

---

**Mo** - *13:43:33*

```results = trading.betting.list_event_types()

print(results)



    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listEventTypes

Params: {'filter': {}}

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/betting/json-rpc/v1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1002)')))```

Well there appears to be some certificate somewhere in his certificate store that _is_ getting used on these requests

*Tags: Errors Debugging, Strategies*

---

**Mo** - *13:44:54*

It sounds pretty obvious from the error message that the problem is there's a self signed certificate in the certificate chain. The question is what certificate is it? I wonder if he's accidentally added his personal certificate to the store

*Tags: Errors Debugging*

---

**Mo** - *14:08:08*

That's helpful but there should also be a details tab where the certificate hierarchy is at the top

*Tags: General Technical*

---

**PeterLe** - *14:36:49*

Quick question please, if I wanted to alter the min_bet_size and min_bet_payout would I only have to change in currency_parameters ie does all other code refer back to that point? Thanks in advance

*Tags: General Technical*

---

## 2023-08-03

**Nacho Uve** - *08:41:03*

Yes, I had the same problem from Spain.

*Tags: General Technical*

---

**liam** - *09:42:36*

Fixed in 2.4.2

*Tags: Errors Debugging*

---

## 2023-08-04

**Guy Incognito** - *01:50:57*

Hi guys, looking at my log file I see this:



```2023-08-04 09:18:40:ERROR:53:OrderStream 1001 run error

Traceback (most recent call last):

  File "/usr/local/lib/python3.10/site-packages/flumine/streams/orderstream.py", line 51, in run

    self._stream.start()

  File "/usr/local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py", line 67, in start

    self._read_loop()

  File "/usr/local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

  File "/usr/local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py", line 256, in _receive_all

    raise SocketError(

betfairlightweight.exceptions.SocketError: [Connect: 1002]: Connection closed by server

2023-08-04 09:18:42:INFO:21:Starting OrderStream 1001

2023-08-04 09:18:42:INFO:23:[Register: 1002]: orderSubscription

2023-08-04 09:18:42:WARNING:25:[Listener: 1002]: stream already registered, replacing data

2023-08-04 09:18:42:INFO:115:[OrderStream: 1002]: "OrderStream" created 

```

Does anyone know what this means? My guess is that my connection gets closed but the flumine opens a new one afterwards?

*Tags: Errors Debugging, Deployment*

---

**Peter** - *09:17:55*

Exactly. Flumine has your back.

*Tags: General Technical*

---

**Mo** - *09:27:21*

Did you fix it or you used verify=False?

*Tags: Errors Debugging*

---

**Mo** - *09:39:09*

It's not a problem with the certificate you generated using XCA which works fine otherwise you would not be able to log in



Either you have some weird software installed or there is something about your network setup that means someone is man in the middle attacking you. Perhaps it's your ISP

*Tags: Getting Started*

---

## 2023-08-08

**Grant Allison-Young** - *03:16:01*

Hi there, last night I created my certificates and created a not-interactive function to login to Betfair.  All good :  {"sessionToken":"ZZZZZZZ=","loginStatus":"SUCCESS"}.  Today when I woke up and ran it again,without any changes I got  “The remote server returned an error: (500) Internal Server Error.”



I have no Idea what to check.  I ran the same process through Postman and it worked fine.  What end point should I be targeting?  When I did it last night i used  ("[https://identitysso-api.betfair.com/api/certlogin](https://identitysso-api.betfair.com/api/certlogin)") but the Postman version used  [https://identitysso-cert.betfair.com/api/certlogin](https://identitysso-cert.betfair.com/api/certlogin) - I get the same response with both....

*Tags: Errors Debugging, Deployment*

---

**Mo** - *06:41:02*

Doesn’t sound like a problem on your end

*Tags: General Technical*

---

## 2023-08-11

**Clive** - *16:42:57*

Is there a recommended way to plugin your own backtest data for a given event, and get it interleaved with the existing ordering?



I've played around with adding a CustomStream, that gives back a generator, however, it appears the "FlumineSimulation" class requires a MarketBook to be passed back, as that's all it appears to handle see L64 in simulation.py with the call to

```self._process_market_books```

Perhaps I'm barking up the wrong bush.

*Tags: General Technical*

---

**liam** - *16:44:38*

[https://github.com/betcode-org/flumine/blob/master/examples/simulate-sportsdata.py|example](https://github.com/betcode-org/flumine/blob/master/examples/simulate-sportsdata.py|example)



[https://github.com/betcode-org/flumine/blob/796ec51060328edac7e14678c6defd63a964d250/flumine/markets/middleware.py#L292|logic](https://github.com/betcode-org/flumine/blob/796ec51060328edac7e14678c6defd63a964d250/flumine/markets/middleware.py#L292|logic)

*Tags: General Technical*

---

**Clive** - *17:01:49*

Imagine I have a historical time series of the number of people on the 59 bus, or something else. It doesn't matter. Now I want to call my strategy in a backtest with this dataset:



```strategy.process_passengers(self, ...)```

I need to get my passenger data into the time priority queue derived from the BetFair data, to ensure it is processed in order.



Does it make sense?

*Tags: Strategies*

---

**George** - *21:33:22*

sometimes when I start a Flumine process, I get an error message saying "[MarketStream: None] TIMEOUT: Connection is not subscribed and is idle: 1500ms".

sometimes it's OrderStream instead of MarketStream.

i don't get it every time.



is this a problem at my end? how can i prevent this from happening?

*Tags: Errors Debugging*

---

**Mo** - *22:35:33*

I believe this happens when the subscription message gets sent before Betfair is ready for it, which can happen if your latency to Betfair is particularly low



I do this, which is a bit of hack:



```betfair_stream._connect()

time.sleep(3)

betfair_stream.authenticate()

betfair_stream.subscribe_to_orders(order_filter=betfairlightweight.filters.streaming_order_filter(order_filter))```

*Tags: Performance*

---

## 2023-08-12

**Andy** - *01:58:52*

[@UCQB6S222](@UCQB6S222) I used to get this error sporadically when I had a max market limit on the stream of 200 (default). Once they increased it to 1000 for me the issue went away. Another thing to try

*Tags: Errors Debugging*

---

**George** - *22:21:06*

Similar to the above - I've received an error with the message "MarketStream 2001 run error" - and further down it says "SocketError Connect 2002: Connection closed by server".



Does that mean I have to kill the flumine process and start again? Or is it all good?

*Tags: Errors Debugging, Deployment*

---

## 2023-08-13

**Lee** - *00:01:47*

Flumine will handle restarting it for you

*Tags: General Technical*

---

**Michael** - *19:53:38*

This might be basic but in Flumine, how do I restrict the market recorder to particular leagues with competition ids? Streaming_market_filter doesn’t seem to have competitons_id argumnt

*Tags: Data Quality*

---

**Michael** - *20:13:22*

Amazing thank you - is there any difference if I use market_filter over streaming_market_filter?

*Tags: General Technical*

---

**Lee** - *20:16:15*

You can’t use market_filter with streaming

*Tags: General Technical*

---

## 2023-08-14

**Johnny** - *09:37:29*

I had the same problem recently and found this question has been asked about 3 times in the last 90 days / slack channel history ... maybe time to add to the FAQs?

*Tags: General Technical*

---

## 2023-08-15

**Unknown** - *04:34:11*

It’s more BFLW than flumine (I think?) but I had a bet failure with no more context as to why. Is there any way I can find out what caused the failure?

There are successful orders going on around it. Any ideas where to look? Naturally it was the winning bet that failed. :disappointed:

*Tags: Errors Debugging*

---

**Neil T (Betfair)** - *12:11:30*

_for all the connections above in ESA logs we can see only connection being requested, but no authentication and subscription after that. Because of this, connection not having subscription, ESA runs an Idle check , sends error message on the socket and then closes connection.

Can you confirm  that after connection is created an authentication and marketSubscription/orderSubscription/operation are sent?_

*Tags: Errors Debugging*

---

**Mo** - *16:28:02*

[@U4H19D1D2](@U4H19D1D2) just reviewing our background to the issue when we first observed it and put in our workaround. I believe the issue is here: [https://github.com/betcode-org/betfair/blob/7118b471e61282d87630bcdc5d6de6b69a59cfa6/betfairlightweight/streaming/betfairstream.py#L284-L285](https://github.com/betcode-org/betfair/blob/7118b471e61282d87630bcdc5d6de6b69a59cfa6/betfairlightweight/streaming/betfairstream.py#L284-L285). I think we need to wait for the [https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=6094862#ExchangeStreamAPI-Connection/ConnectionMessage|connection message](https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=6094862#ExchangeStreamAPI-Connection/ConnectionMessage|connection message) before sending the authentication message

*Tags: General Technical*

---

**George** - *16:57:23*

does that mean we might be able to fix this in flumine soon? if so that would be great!

*Tags: Errors Debugging*

---

## 2023-08-16

**liam** - *08:46:53*

[@UBS7QANF3](@UBS7QANF3) does this PR make sense? I am obviously very wary of changing much of this as a lot hasn't been touched since 2016!



However the issue seems to be coming from sending requests but not waiting for the response. I still think there is a race condition on the betfair side but this should stop any issues.



[https://github.com/betcode-org/betfair/pull/532](https://github.com/betcode-org/betfair/pull/532)

*Tags: General Technical*

---

**liam** - *09:14:40*

Any volunteers?



[https://pypi.org/project/betfairlightweight/2.18.0/](https://pypi.org/project/betfairlightweight/2.18.0/)

*Tags: General Technical*

---

## 2023-08-17

**Guy Incognito** - *06:21:12*

Coding error smh

*Tags: Errors Debugging*

---

## 2023-08-18

**Harry Corrigan** - *09:43:38*

Hi, how would i get orders made before application start with flumine, i want orders on the market irrelavent of if flumine made them or not sent into process_orders function on my strategy, is their any way to do this?

*Tags: Strategies*

---

**Harry Corrigan** - *09:44:12*

Would like to avoid using list_market_book as it's slower &amp; also don't want to have to keep making requests for orders made outside of strategy

*Tags: Performance, Strategies*

---

**Peter** - *10:32:53*

[https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py](https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py)

*Tags: General Technical*

---

**Peter** - *10:36:18*

Non-complete orders will come through in the order stream, and should show up in the blotter, but not in `process_orders` as that only handles orders for the strategy wrapping the method.

*Tags: Strategies*

---

**Harry Corrigan** - *10:43:09*

i can't seem to get from blotter, i have an unmatched lay order at price 1.01 size 1

i'm reading from the blotter like this from within process_market_book

```            print("Reading from blotter")

            for order in market.blotter.client_orders(self.manager.flumine.clients.get_default()):

                print(order)

            for order in market.blotter.live_orders:

                print(order)```

both loops print nothing

*Tags: Deployment*

---

**Peter** - *11:42:35*

Ah sorry. I suspect that there's a rather subtle 2nd requirement lurking in there, namely that the orders were created with the same customer_strategy_ref that you're using when you run Flumine. this ref is nothing to do with the Flumine strategy - rather it's the ref that Betfair recognises and by default is [https://github.com/betcode-org/flumine/blob/master/flumine/config.py|based by Flumine on your hostname](https://github.com/betcode-org/flumine/blob/master/flumine/config.py|based by Flumine on your hostname). So order created by other methods e.g. via the webUI won't get picked up. Not normally a problem when an instance of Flumine is restarted, but not helpful if your starting a fresh instance and want to pick up orders created by other methods.



To get around that I'd recommend tweaking the order middleware liked to earlier to remove the config.customer_strategy_ref filter and EXECUTION_COMPLETE filters, though you may experience side effects if Flumine needs to restart.

*Tags: Strategies*

---

**Derek C** - *17:57:49*

I am slowly migrating stuff over to Flumine (from BFLW-based approaches). One issue I seem to have is that even when my market_data_filter specifies ladder_levels=5, the market_book has the whole ladder.



eg when I create the strategy I pass the following:





```market_data_filter=streaming_market_data_filter(

            fields=[

                "EX_ALL_OFFERS",

                "EX_LTP",

                "EX_TRADED",

                "EX_TRADED_VOL",

                "EX_MARKET_DEF",

            ], 

            ladder_levels=5,

    ),```

Yet  in market_book.runners[0].ex.available_to_back there are over 30 entries. What am I missing?

*Tags: Performance, Strategies*

---

**D C** - *18:04:52*

I can't speak for flumine but in stream terms I THINK that you can only request ladder levels on the virtual/display prices not nonvirtual (datb vs atb)

*Tags: General Technical*

---

**Derek C** - *18:16:10*

I think it's EX_ALL_OFFERS - includes everything. Your comment made me read the documentation more carefully :slightly_smiling_face:

*Tags: General Technical*

---

## 2023-08-23

**Harry Corrigan** - *10:34:29*

Hi, does flumine support cancelling multiple orders at once? if so how?

i want to size reduce multiple orders to a volume less then 1, however by the time i've cancelled one order the others have been matched

wondering if theres a better/faster way to do this?

*Tags: General Technical*

---

**liam** - *12:39:02*

Try using a single [https://betcode-org.github.io/flumine/markets/#transaction|transaction](https://betcode-org.github.io/flumine/markets/#transaction|transaction), this will mean all requests will be sent in one request



```with market.transaction() as t:

    for order in orders_to_cancel:

        t.cancel_order(order, size_reduction=1)```

*Tags: General Technical*

---

## 2023-08-25

**Rishab** - *02:32:39*

Hi all! Question regarding execution in flumine. I'm trying to backtest my strategy using fluminesimulation and stuck with how orders are executed. Market for a runner was at 1.65-1.66, I had a limit order @1.66 for 186. In the next tick market moved to 1.66-1.67 &amp; actual volume traded in market was 245.82 &amp; I got a fill @1.66 for 122 size. Firstly, how does flumine allocates size in case market moves through your price? 2. I changed the profit variable in the LoggingControl(the one available on git)  simply with order.profit as with the usual one was giving profit variable as 0 for all the orders &amp; this change actually worked. But for the order described above it assumes that I got full(186 size) fill &amp; then calculates the PnL.

*Tags: Strategies*

---

## 2023-08-29

**foxwood** - *19:08:10*

When a runner is removed on dogs, BF zap the market and a packet comes through with `market_book.total_matched == 0` all price lists in `market_book.runners.ex` are empty and there is no `'tv'` in `market_book.streaming_update`. Discovered some of my strategies do stupid things when this occurs. I can work around it in `check_market_book()` but wonder if there could/should be some flag set in flumine to indicate a market has been reset and/or that the book is empty for this packet ?

*Tags: General Technical*

---

## 2023-08-30

**George** - *15:00:13*

Yesterday I had a few "Execution errors" that I have not seen before. I get "SSLEOFError: EOF occurred in violation of protocol". Anyone know what that means?

*Tags: Errors Debugging*

---

**foxwood** - *16:14:51*

thought I'd try chatgpt on this - it didn't seem to know at first so I had to tell it that it was a known term ! However it's answer may help ...



I apologize for the confusion. It seems that "SSLEOFError" is indeed a known term related to SSL errors, though it might not be as commonly referenced as other SSL error types.



SSLEOFError stands for "SSL EOF Error," where "EOF" stands for "End of File." This error occurs when an SSL/TLS connection is unexpectedly terminated before completing the necessary handshake or data exchange. In simpler terms, it indicates that the connection was closed prematurely by one of the parties involved.



Common causes of SSLEOFError include:



1. **Network Issues:** Sudden network interruptions, packet loss, or connectivity problems between the client and the server can lead to an SSL EOF Error.



2. **Server Termination:** The server might have terminated the connection due to its own issues or misconfigurations.



3. **Client Termination:** The client might have intentionally or unintentionally closed the connection before the SSL handshake could complete.



4. **Firewall or Proxy Interference:** Intermediary devices like firewalls or proxies might interfere with the connection and cause premature termination.



5. **Resource Limitations:** The server or client might have encountered resource limitations, leading to a forced connection closure.



6. **Misconfigured SSL/TLS Settings:** Incorrect configurations of SSL/TLS settings on either the client or server side can also lead to this type of error.



7. **Protocol Version Issues:** Mismatched or incompatible SSL/TLS protocol versions can cause connection termination.



To troubleshoot and address an SSLEOFError, you should review server logs, client logs, and network logs to identify the underlying cause. It's also important to ensure that both the client and server are correctly configured to support the same SSL/TLS version and cipher suite. If the issue persists, examining network conditions and potential interference can help diagnose the problem.

*Tags: Errors Debugging, Deployment*

---

## 2023-08-31

**river_shah** - *11:03:11*

George, I am just guessing but likely you are on an extremely high bandwidth, low latency connection into BF. Your last two errors seem to suggest this. I think packets are getting dropped before BF handshakes properly.

*Tags: Errors Debugging, Performance*

---

**river_shah** - *11:07:57*

The network architecture of BF is not entirely well understood but if you queue too many packets due to your high bandwidth / low latency connection, reasonable chance packet drops occur and strange connection errors will pop up. I could be totally wrong on this, so please verify if indeed your connection matches said description.

*Tags: Errors Debugging, Performance*

---

## 2023-09-02

**mon mon** - *03:27:51*

Hi all - how can I monitor exceptions raised by the streams in Flumine?

I am getting them in my logs ok, but for selected exceptions I want to be able to monitor within my program and take actions when they are raised

(e.g.  [MarketStream: 3073]: SUBSCRIPTION_LIMIT_EXCEEDED, I would adjust the market filter on to limit the markets/dates etc).

*Tags: Errors Debugging*

---

## 2023-09-04

**foxwood** - *17:26:00*

In 2 dog races today a matched live bet was logged as being `OrderStatus.EXECUTABLE` (ie not matched) at `process_closed_market()`

From the live logs it appears that the update message for the bet `"Order status update: Execution complete"` came in about half a second AFTER the `"Market closed"` message.

I always thought everything was done and dusted at `process_closed_market()` ?

In simulation it works fine of course but how to handle this on live to avoid being misled as to what bets have really been matched ?

*Tags: Deployment*

---

**foxwood** - *21:32:44*

Extract from log for that market shown below from placing bet onwards -  think I've identified the origin of the log messages correctly ...



`{"asctime": "2023-09-04 13:12:30,255", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.217888463",`

`{"asctime": "2023-09-04 13:13:41,499", "levelname": "INFO", "message": "Updated marketCatalogue for 1.217888463"`

`{"asctime": "2023-09-04 13:15:41,582", "levelname": "INFO", "message": "Updated marketCatalogue for 1.217888463"`



	market.close_market() produces next line

`{"asctime": "2023-09-04 13:15:52,069", "levelname": "INFO", "message": "Market 1.217888463 closed", "market_id": "1.217888463"`

	mystrat.process_closed_market()	produces next line

`{"asctime": "2023-09-04 13:15:52,069", "levelname": "INFO", "message": "319679639999,stratXXXX,OrderStatus.EXECUTABLE"}`

	BaseFlumine._process_close_market() produces next line

`{"asctime": "2023-09-04 13:15:52,069", "levelname": "INFO", "message": "Market closed", "market_id": "1.217888463"`



`{"asctime": "2023-09-04 13:15:52,444", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.217888463"`

`{"asctime": "2023-09-04 13:16:27,594", "levelname": "INFO", "message": "1.217888463: 1 cleared orders found, more available: False"}`

`{"asctime": "2023-09-04 13:16:27,609", "levelname": "INFO", "message": "Market cleared", "market_id": "1.217888463", "order_count": 1`



Edit; the bet was a "take" and BF accounts show matched at asked odds. Also the "executable" line above shows fully matched at asking price - so the issue is that the bet was still showing as executable until after close market - I didn't see it since I only report execution complete orders when deriving PL etc - maybe that's my fault then ?

*Tags: General Technical*

---

## 2023-09-05

**foxwood** - *11:10:09*

Still puzzling over this since had some more last night and it's not something I've noticed before so trying to understand the flumine/bflw jigsaw - seems to be some sort of timing/threading issue maybe or is it incorrect BF responses ? As previous post the order definitely has the status `EXECUTABLE` when `process_closed_market()` is called.. Looking at the logs more carefully I see an entry arising from `BetfairExecution._execution_helper()` as shown below. This has the status set to `EXECUTION_COMPLETE` immediately  - as would be expected for a "take" bet. Can anyone explain why therefore later messages variously show Pending or Executable and the order fails to pick up the matched status as returned by the execution helper even when the market is closed ? Confused lol.

`{"asctime": "2023-09-04 13:12:30,255", "levelname": "INFO", "message": "execute_place", "trading_function": "place", "elapsed_time": 0.21911835670471191, "response": {"customerRef": "51e793094b1c11ee9720020000008598", "status": "SUCCESS", "marketId": "1.217888463", "instructionReports": [{"status": "SUCCESS", "instruction": {"selectionId": 42320105, "handicap": 0.0, "limitOrder": {"size": 1.75, "price": 7.0, "persistenceType": "MARKET_ON_CLOSE"}, "customerOrderRef": "stratxxxxxxxx-139131223500362504", "orderType": "LIMIT", "side": "LAY"}, "betId": "319679639999", "placedDate": "2023-09-04T12:12:31.000Z", "averagePriceMatched": 7.0, "sizeMatched": 1.75, "orderStatus": "EXECUTION_COMPLETE"}]}, "order_package": {"id": "51e79309-4b1c-11ee-9720-020000008598", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x0000003CAC713370&gt;", "market_id": "1.217888463", "orders": ["139131223500362504"], "order_count": 1, "package_type": "Place", "customer_strategy_ref": "xxxxxxxxxxxxxxx", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}`

*Tags: Strategies*

---

## 2023-09-06

**Troy Edwards** - *12:39:23*

Hi guys does the betfair Non-Interactive login required a self signed certificate as per [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login)????



I coded my login code back in 2014 which worked well and returned my Session ID (SSOID), however as I have continued to call the function Keep Betfair Alive [https://identitysso.betfair.com/api/keepAlive](https://identitysso.betfair.com/api/keepAlive) I believe this function has been keeping my SSOID current and maybe I have missed Betfair have increased their login security ??   I changed my password the other day and then when the betbot try to login I get Errors.









Also slightly unrelated but does anyone here use the Betfair Developer Forum [https://forum.developer.betfair.com/](https://forum.developer.betfair.com/) and can you login ?   I assume the login is your current betfair login but it just will not allow me to login to the forum yet I used to have access :disappointed:

*Tags: Errors Debugging, Deployment*

---

**Mo** - *12:48:52*

What is the error you get when logging in

*Tags: Errors Debugging*

---

**D C** - *14:57:02*

I've also had problems with older certificates and newer versions of SSL that decided that the encryption mechanism used to create the certificates is too weak. I had to make changes to ssl config files but ultimately ended up generating new certificates.

*Tags: General Technical*

---

**Troy Edwards** - *23:32:51*

Thanks for the replies.  DC this login function was coded in 2014 but I did update it to include TLS 1.2 in 2019.



I get this response atm and I have printed to the console window using debug.print

Debug.Print(thePage.ResponseUri.Query) = ?redirectMethod=POST&amp;errorCode=INPUT_VALIDATION_ERROR



I am also wondering whether this code is non-interactive OR is it interactive in that I am just passing in my login details and password however I am passing it through a HTTPWebRequest.  I guess once I received my session ID I have never had to look at this code again.





My code is below and thanks btw:

*Tags: Errors Debugging*

---

**Troy Edwards** - *23:32:54*

Public Function LoginSessionBetfair(username As String, password As String) As String

        Dim ssoid As String = [String].Empty

        Dim info As String()

        Dim sessToken As String = ""

        LoginSessionBetfair = ""



        Try

            ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12    'V0.40 12 March 2019 added as requested by Betfair



         Dim uri As String = String.Format("[https://identitysso.betfair.com/api/login?username={0}&amp;password=](https://identitysso.betfair.com/api/login?username={0}&amp;password=)                          {1}&amp;login=true&amp;redirectMethod=POST&amp;product=[http://home.betfair.int|home.betfair.int](http://home.betfair.int|home.betfair.int)&amp;url=[https://www.betfair.com/](https://www.betfair.com/)", username, password)

            Dim myRequest As HttpWebRequest = DirectCast(WebRequest.Create(uri), HttpWebRequest)



            myRequest.Method = "POST"

            myRequest.Timeout = 5000



            Dim thePage As WebResponse = myRequest.GetResponse()

            info = thePage.Headers.GetValues("Set-Cookie")

            Debug.Print(thePage.ResponseUri.Query) 'PRINT OUT WHY I MIGHT HAVE AN ERROR?





            Dim i As Integer = 0

            While ssoid = [String].Empty AndAlso i &lt; info.Length

                If info(i).Contains("ssoid=") Then

                    ssoid = info(i)

                End If

                i += 1

            End While



            sessToken = ssoid.Replace("ssoid=", "") 'Dump front string

            sessToken = sessToken.Replace("; Domain=.[http://betfair.com|betfair.com](http://betfair.com|betfair.com); Path=/; Secure", "")         'dump rear string



        Catch ex As System.Exception



        End Try



        Return sessToken '~~&gt; Should work ok if Login a success

    End Function 'Session Token and Login

*Tags: Errors Debugging*

---

## 2023-09-07

**Unknown** - *04:07:22*

When I go back to my Betfair login function which is similar to this [https://forum.developer.betfair.com/forum/sports-exchange-api/net/26471-recent-vb-login-code](https://forum.developer.betfair.com/forum/sports-exchange-api/net/26471-recent-vb-login-code), I still get the



thePage.ResponseUri.Query = ?redirectMethod=POST&amp;errorCode=INPUT_VALIDATION_ERROR



I also note that the INFO Variable contains 2 sort of sessions IDs and that it expires tomorrow?  However if looks different to the ssoid I had a few minutes ago which started  ssoid = PXVhiddenxxxxxxJI

*Tags: Errors Debugging*

---

## 2023-09-08

**Unknown** - *08:57:19*

hi guys,

i don't understand the reason of this error on streaming, any ideas?

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *09:04:11*

from here everything ok

```logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# login

trading.login()

# create queue

output_queue = queue.Queue()

output_queue

# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)

listener

# create stream

stream = trading.streaming.create_stream(listener=listener)

stream

# create filters (GB WIN racing)

market_filter = streaming_market_filter(

    event_type_ids=["1"]#, country_codes=["GB"], market_types=["WIN"]

)

market_data_filter = streaming_market_data_filter(

    fields=["MATCH_ODDS"], ladder_levels=3

)

# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)

# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)```

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created



from here i got the warning message

```t.start()```

after that the line "market_books = output_queue.get()" is endless

```streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=1000,  # send update every 1000ms

        initial_clk=listener.initial_clk,

        clk=listener.clk,

    )

# check for updates in output queue

while True:

    market_books = output_queue.get()

    print(market_books)



    for market_book in market_books:

        print(

            market_book,

            market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

            market_book.streaming_update,  # json update received

            market_book.market_definition,  # streaming definition, similar to catalogue request

            market_book.publish_time,  # betfair publish time of update

        )```



*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *09:05:22*

I think you are not sharing the real error here, which at a guess is a subscription limit as you are trying to subscribe to all eventTypeIds 1?

*Tags: Errors Debugging*

---

**liam** - *09:08:15*

What does the error tell you?

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *09:08:55*

this is the full error

Exception in thread Thread-12 (start):

Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1038, in _bootstrap_inner

    self.run()

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 975, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

                        ^^^^^^^^^^^^^^^^^^^

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 256, in _receive_all

    raise SocketError(

betfairlightweight.exceptions.SocketError: [Connect: 2]: Connection closed by server

*Tags: Errors Debugging, Deployment*

---

**Riccardo Fresi** - *09:20:36*

o gosh,, btw i've changed nothing changed

```market_filter = streaming_market_filter(

    event_type_ids=["1"], country_codes=["GB"]

    , market_types=["MATCH_ODDS"]

)

market_data_filter = streaming_market_data_filter(

    fields=["EX_BEST_OFFERS_DISP"], ladder_levels=3

)```

*Tags: General Technical*

---

**Riccardo Fresi** - *09:30:11*

copy from example, but the while at the end

```# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

trading = betfairlightweight.APIClient(BETFAIR_USER, 

                                       BETFAIR_PASSWORD, 

                                       app_key=BETFAIR_APPKEY, 

                                       certs=CERT_PATH, 

                                       locale='italy')



# login

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

    event_type_ids=["7"], country_codes=["GB"], market_types=["WIN"]

)

market_data_filter = streaming_market_data_filter(

    fields=["EX_BEST_OFFERS", "EX_MARKET_DEF"], ladder_levels=3

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)

t.start()```

same error



```INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

Exception in thread Thread-5 (start):

Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1038, in _bootstrap_inner

    self.run()

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 975, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

                        ^^^^^^^^^^^^^^^^^^^

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 256, in _receive_all

    raise SocketError(

betfairlightweight.exceptions.SocketError: [Connect: 2]: Connection closed by server```



*Tags: Getting Started, Errors Debugging, Deployment, Strategies*

---

**liam** - *09:38:02*

Can you set logging to debug and share (hide keys etc)

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *09:49:38*

```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.it:443|identitysso-cert.betfair.it:443](http://identitysso-cert.betfair.it:443|identitysso-cert.betfair.it:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.it:443](https://identitysso-cert.betfair.it:443) "POST /api/certlogin HTTP/1.1" 200 125

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"authentication","id":2,"appKey":"XXXX","session":"XXXXX/XX="}\r\n'

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"marketSubscription","id":1,"marketFilter":{"eventTypeIds":["7"],"marketTypes":["WIN"],"countryCodes":["GB"]},"marketDataFilter":{"fields":["EX_BEST_OFFERS","EX_MARKET_DEF"],"ladderLevels":3},"initialClk":null,"clk":null,"conflateMs":1000,"heartbeatMs":null,"segmentationEnabled":true}\r\n'

INFO:root:log point before t.start()```

*Tags: Errors Debugging*

---

**liam** - *09:51:02*

So your not getting any response from the stream, is streaming allowed in italy?

*Tags: General Technical*

---

**Riccardo Fresi** - *09:58:13*

should be, i cannot find anything from documentation

*Tags: General Technical*

---

**Austin Sacks** - *10:17:37*

thank you for your help

*Tags: General Technical*

---

**liam** - *10:18:05*

Thats what the code says, assuming this is in regards to flumine?

*Tags: General Technical*

---

**Austin Sacks** - *10:18:49*

i'm flumine and general coding noob

*Tags: General Technical*

---

**Austin Sacks** - *10:19:09*

i tired to look in documentation but i couldn't figure out how to find it

*Tags: General Technical*

---

## 2023-09-11

**Austin Sacks** - *00:02:23*

Hello sorry for another silly question. I have made my bot to make limit order when there are certain market conditions. How do I implement code do to cancel that order if market conditions change?

*Tags: General Technical*

---

**liam** - *06:35:07*

The above is assuming you are using flumine, which you probably want to be 

*Tags: General Technical*

---

## 2023-09-12

**Unknown** - *14:08:11*

Hi - a newbie question: I get an INVALID_APP_KEY error APINGException when trying to run trading.betting.list_event_types(). Any ideas here?

I think login is okay (can see session_token and expired=false)

Using python 3.10.6

*Tags: Errors Debugging, Strategies*

---

**Unknown** - *15:43:37*

No...

got ssoid from inspect element on logged in betfair tab.

My account was suspended (due to auth) for a bit but fixed, not sure if that's relavant.

*Tags: Errors Debugging*

---

## 2023-09-13

**Paras Stefanopoulos** - *06:25:39*

Anyone know what could be happening here? been getting this for months randomly from betfair stream:



```2023-09-11 08:09:43,688 ERROR [Connect: 37]: Socket [Errno 104] Connection reset by peer

Traceback (most recent call last):

  File "/home/ec2-user/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py", line 244, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "/usr/lib64/python3.9/ssl.py", line 1227, in recv

    return self.read(buflen)

  File "/usr/lib64/python3.9/ssl.py", line 1102, in read

    return self._sslobj.read(len)

ConnectionResetError: [Errno 104] Connection reset by peer



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "…", line 32, in wrapper

    result = await async_func(*args, **kwargs)

  File "…", line 108, in main

    raise betfair_streamer.error

  File "/usr/lib64/python3.9/threading.py", line 980, in _bootstrap_inner

    self.run()

  File "/usr/lib64/python3.9/threading.py", line 917, in run

    self._target(*self._args, **self._kwargs)

  File "…", line 50, in _start_stream

    raise e

  File "...", line 47, in _start_stream

    self.stream.start()

  File "/home/ec2-user/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py", line 67, in start

    self._read_loop()

  File "/home/ec2-user/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

  File "/home/ec2-user/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py", line 248, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 107]: Socket [Errno 104] Connection reset by peer```

*Tags: Errors Debugging, Deployment*

---

**Mo** - *07:31:25*

Looks like a random network error

*Tags: Errors Debugging*

---

**Ke** - *21:27:00*

I'm backtesting the strategy with locally recorded market data. i have market data saved in *.gz and catalogue data saved in *.json.gz file. How to load both market data and catalogue data at the same time?

*Tags: Strategies*

---

## 2023-09-14

**liam** - *05:58:35*

flumine?



[https://github.com/betcode-org/flumine/blob/master/examples/middleware/marketcatalogue.py](https://github.com/betcode-org/flumine/blob/master/examples/middleware/marketcatalogue.py)

*Tags: General Technical*

---

**liam** - *10:06:35*

What version of bflw?

*Tags: General Technical*

---

**liam** - *10:11:02*

Can you try 2.18.0, don't expect it to work but it should error at the issue

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *10:29:26*

different

```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.it:443|identitysso-cert.betfair.it:443](http://identitysso-cert.betfair.it:443|identitysso-cert.betfair.it:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.it:443](https://identitysso-cert.betfair.it:443) "POST /api/certlogin HTTP/1.1" 200 125

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"authentication","id":2,"appKey":"XXXXX","session":"XXXXXX="}\r\n'

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"marketSubscription","id":1,"marketFilter":{"eventTypeIds":["7"],"marketTypes":["WIN"],"countryCodes":["GB"]},"marketDataFilter":{"fields":["EX_BEST_OFFERS","EX_MARKET_DEF"],"ladderLevels":3},"initialClk":null,"clk":null,"conflateMs":1000,"heartbeatMs":null,"segmentationEnabled":true}\r\n'

Exception in thread Thread-14 (start):

Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1038, in _bootstrap_inner```

```'\nData can also be accessed by using the snap function in the listener, e.g:\n\n    market_books = listener.snap(\n        market_ids=[1.12345323]\n    )\n\nErrors need to be caught at stream.start, resubscribe can then be used to\nprevent full image being sent, e.g:\n\n    streaming_unique_id = stream.subscribe_to_markets(\n        market_filter=market_filter,\n        market_data_filter=market_data_filter,\n        conflate_ms=1000,  # send update every 1000ms\n        initial_clk=listener.initial_clk,\n        clk=listener.clk,\n    )\n\nThe streaming unique id is returned in the market book which allows multiple\nstreams to be differentiated if multiple streams feed into the same queue.\n'```

```    self.run()

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 975, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    return

^^^^^^^^^^^

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 226, in _read_loop

    if self._running:

                      

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 256, in _receive_all

    "[Connect: %s]: Connection closed by server"

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

betfairlightweight.exceptions.SocketError: [Connect: 2]: Connection closed by server```



*Tags: Errors Debugging, Deployment*

---

**liam** - *10:33:31*

That is very tricky to read, but I want to see the response from this



```DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"authentication","id":2,"appKey":"XXXXX","session":"XXXXXX="}\r\n'```

It seems like it just carries on?? which it shouldn't in v2.18

*Tags: Errors Debugging*

---

**liam** - *10:34:21*

Here is mine



```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso.betfair.com:443|identitysso.betfair.com:443](http://identitysso.betfair.com:443|identitysso.betfair.com:443)

DEBUG:urllib3.connectionpool:[https://identitysso.betfair.com:443](https://identitysso.betfair.com:443) "POST /api/login HTTP/1.1" 200 None

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[MarketStream: 1]: connection_id: 206-213456-64155124

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"authentication","id":2,"appKey":"/","session":"/"}\r\n'

INFO:betfairlightweight.streaming.listener:[MarketStream: 2]: SUCCESS (5 connections available)```

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *10:36:42*

seems totally missing

```INFO:betfairlightweight.streaming.listener:[MarketStream: 1]: connection_id: 206-213456-64155124```

maybe there is something in the listener, but i don't know how to check

*Tags: General Technical*

---

**liam** - *10:39:02*

Can you share the logs from this:



```# setup logging

logging.basicConfig(level=logging.DEBUG)  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

trading = betfairlightweight.APIClient("/")



# login

trading.login_interactive()



# create stream

stream = trading.streaming.create_stream()



stream._connect()

stream.authenticate()```



*Tags: Getting Started, Errors Debugging, Strategies*

---

**Riccardo Fresi** - *10:40:34*

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso.betfair.it:443|identitysso.betfair.it:443](http://identitysso.betfair.it:443|identitysso.betfair.it:443)

DEBUG:urllib3.connectionpool:[https://identitysso.betfair.it:443](https://identitysso.betfair.it:443) "POST /api/login HTTP/1.1" 200 None

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 1] Sending: b'{"op":"authentication","id":1,"appKey":"xxx","session":"xxx="}\r\n'

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *10:58:13*

something strange happens now. this on stream creation



```DEBUG:urllib3.connectionpool:[https://identitysso.betfair.it:443](https://identitysso.betfair.it:443) "POST /api/login HTTP/1.1" 200 None```

this on connect

```TimeoutError                              Traceback (most recent call last)

File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py:243, in BetfairStream._receive_all(self)

    242 try:

--&gt; 243     part = self._socket.recv(self.buffer_size)

    244 except (socket.timeout, socket.error) as e:



File C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\ssl.py:1296, in SSLSocket.recv(self, buflen, flags)

   1293         raise ValueError(

   1294             "non-zero flags not allowed in calls to recv() on %s" %

   1295             self.__class__)

-&gt; 1296     return self.read(buflen)

   1297 else:



File C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\ssl.py:1169, in SSLSocket.read(self, len, buffer)

   1168     else:

-&gt; 1169         return self._sslobj.read(len)

   1170 except SSLError as x:



TimeoutError: The read operation timed out



During handling of the above exception, another exception occurred:



SocketError                               Traceback (most recent call last)

c:\Users\riccardo.fresi\OneDrive - Accenture\Documents\Odds\betfair_sample_Stream.ipynb Cella 11 line 1

...

--&gt; 247     raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

    248 else:

    249     return  # 133, prevents error if stop is called mid recv



SocketError: [Connect: 0]: Socket The read operation timed out```

i also notice that this is endless

```# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)```

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *11:01:13*

no problem with that

```Ping statistics for 84.20.210.135:

    Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),

Approximate round trip times in milli-seconds:

    Minimum = 41ms, Maximum = 46ms, Average = 43ms```

*Tags: General Technical*

---

**Riccardo Fresi** - *11:06:36*

```&lt;ssl.SSLSocket fd=4780, family=2, type=1, proto=0, laddr=('127.0.0.1', 51863), raddr=('84.20.210.135', 443)&gt;



     10 s.connect((host, __port))

     12 print(s)

---&gt; 14 print(s.recv(1024))



File C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\ssl.py:1296, in SSLSocket.recv(self, buflen, flags)

   1292     if flags != 0:

   1293         raise ValueError(

   1294             "non-zero flags not allowed in calls to recv() on %s" %

   1295             self.__class__)

-&gt; 1296     return self.read(buflen)

   1297 else:

   1298     return super().recv(buflen, flags)



File C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\ssl.py:1169, in SSLSocket.read(self, len, buffer)

   1167         return self._sslobj.read(len, buffer)

   1168     else:

-&gt; 1169         return self._sslobj.read(len)

   1170 except SSLError as x:

   1171     if x.args[0] == SSL_ERROR_EOF and self.suppress_ragged_eofs:



TimeoutError: The read operation timed out```

*Tags: Errors Debugging*

---

**Mo** - *11:40:12*

In the last example isn't the problem you haven't sent anything?

*Tags: General Technical*

---

**Mo** - *11:45:13*

My guess is either streaming doesn't actually work in Italy or it's something to do with the way your company is fucking with your connection

*Tags: General Technical*

---

**Riccardo Fresi** - *11:47:42*

ok, i tried from colab, and seems working

```&lt;ipython-input-2-935b033c8602&gt;:8: DeprecationWarning: ssl.wrap_socket() is deprecated, use SSLContext.wrap_socket()

  s = ssl.wrap_socket(s)

&lt;ssl.SSLSocket fd=43, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('172.28.0.12', 60868), raddr=('84.20.208.166', 443)&gt;

b'{"op":"connection","connectionId":"109-140923104638-657055"}\r\n'```

indeed i don't understand, ping AND telnet are working

*Tags: General Technical*

---

**Riccardo Fresi** - *18:14:49*

for sure is something related to my connection or my firewall, i upload everything on ec3 aws (user, psw, app key, cert)

seems everything working properly



i don't know ho modify my local setup

*Tags: Getting Started, Deployment*

---

**Riccardo Fresi** - *18:43:10*

Yes, I’d like to move on cloud soon, but I want an stable “product” before; indeed I have also to consider the cost of cloud, I’ve tried with free tier aws

*Tags: Deployment*

---

**Riccardo Fresi** - *18:55:04*

no other laptop...i try to connect on hotspot from phone, same error, i think we can conclude that it's about the computer configuration, maybe

*Tags: Errors Debugging*

---

## 2023-09-15

**Pramod S** - *03:00:40*

Hi I am trying to use flumine for getting data stream to get horse racing complete data for GB

While using sample code i am getting error



starting strategy 'ExampleStrategy'

Traceback (most recent call last):

  File "&lt;pyshell#0&gt;", line 1, in &lt;module&gt;

    framework.run()

  File "C:\Python37\lib\site-packages\flumine\flumine.py", line 33, in run

    self._process_market_books(event)

  File "C:\Python37\lib\site-packages\flumine\baseflumine.py", line 151, in _process_market_books

    market = self._add_market(market_id, market_book)

  File "C:\Python37\lib\site-packages\flumine\baseflumine.py", line 204, in _add_market

    self.markets.add_market(market_id, market)

  File "C:\Python37\lib\site-packages\flumine\markets\markets.py", line 21, in add_market

    if market.event_id:

  File "C:\Python37\lib\site-packages\flumine\markets\market.py", line 133, in event_id

    return self.market_book.market_definition.event_id

AttributeError: 'NoneType' object has no attribute 'event_id'

*Tags: Errors Debugging, Strategies*

---

**H** - *15:11:30*

In case anyone is having issues where some of their Python scripts randomly die with 100% CPU usage, I think I've tracked this down to a bug in orjson which is fixed in the latest version (3.9.7) but present in a few previous versions (3.9.3-3.9.6).

[@U4H19D1D2](@U4H19D1D2) it might be worth merging this PR since it looks like all tests pass with `orjson==3.9.7`: [https://github.com/betcode-org/betfair/pull/538](https://github.com/betcode-org/betfair/pull/538)

Details of the problem in this GitHub issue: [https://github.com/ijl/orjson/issues/415](https://github.com/ijl/orjson/issues/415)

When the bug occurs it stops logging, and doesn't even respond to KeyboardInterrupts, so it was a real pain to track down :sweat_smile:

*Tags: Errors Debugging*

---

**Pramod S** - *15:22:32*

So you want to say we have to use only live key with flumine

*Tags: Deployment*

---

**liam** - *15:25:05*

All delayed key questions and use is banned 

*Tags: General Technical*

---

**H** - *16:06:58*

Haha yeah, at least they have a fix out though

*Tags: Errors Debugging*

---

## 2023-09-16

**Riccardo Fresi** - *11:17:46*

Today is not a good day! Internal error 500 both local machine and aws……you too?

*Tags: Errors Debugging, Deployment*

---

## 2023-09-21

**birchy** - *13:04:09*

[@U4H19D1D2](@U4H19D1D2) Quick question...bflw is on version 2.18.0 but flumine requires 2.17.3. Is that an oversight? I've only just noticed as I upgraded both and pip complained. Also, are there any plans to have a flumine[speed] version that uses bflw[speed] on non-windows platforms?

*Tags: Performance*

---

**liam** - *14:13:41*

It’s on purpose as 2.18 has a scary streaming change which I have been testing, it’s solid so will eventually upgrade flumine, lots of other PRs pending including a speed for flumine 

*Tags: Performance*

---

## 2023-09-25

**Software Engineer** - *08:44:35*

Hello Everyone, I am getting an issue with the Betfair api

I am retrieving horse racing data for every data with Live api key. I save the live races data ( almost 30-60 races a day ) and retrieve from frontend.

But the data saving is delayed as there are more races, ( 1 second per 1 race ) and I need to see them changed every 3-5 seconds.

I am using MongoDB and Python for the Backend to get data from Betfair api.  Thanks

*Tags: Deployment*

---

**Mo** - *08:54:27*

I assume from your code that you are:



1. Using the REST API

2. Serially scraping the set of races

So it's not surprising that you are experiencing delayed data when you have a lot of races to loop through



There is a lot else wrong with your code - mainly that you are saving only a small subset of the data



Best practice is to use the market recorder in flumine: [https://github.com/betcode-org/flumine/blob/master/examples/strategies/marketrecorder.py](https://github.com/betcode-org/flumine/blob/master/examples/strategies/marketrecorder.py) to save the raw price stream then you can analyse it after the fact any which way

*Tags: Data Quality*

---

**Mo** - *09:01:35*

I don't really understand the question

*Tags: General Technical*

---

**Mo** - *09:37:09*

flumine's market recorder will save both the price stream and the market catalogues

*Tags: Data Quality*

---

## 2023-09-27

**liam** - *12:26:21*

betfair themselves manage, you aren't answering my question though, I am assuming you want to store the raw book in mongo?

*Tags: General Technical*

---

## 2023-10-03

**Lee** - *08:47:49*

Did anyone have any flumine instances die during that outage?

*Tags: General Technical*

---

**Lee** - *10:47:59*

actually i think the issue i had in previous outages was fixed in [https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#223-2022-08-01|2.2.3](https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#223-2022-08-01|2.2.3) - the cancel race condition

*Tags: Errors Debugging*

---

**foxwood** - *21:25:48*

Log full of 503 errors on the streams from 6ish until it came back at about 08:05 then automatically sorted itself out and carried on as normal. Any fancy middleware ? My setup is just basic flumine and inheriting from BaseStrategy.

*Tags: Getting Started, Errors Debugging, Strategies*

---

## 2023-10-04

**liam** - *11:17:18*

You want to push code to everyone that fixes a problem that just impacts your work laptop?

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *11:25:16*

sorry liam, probably i explain myself very bad:

1. the problem with my laptop is fixed

2. there is something else that is not working properly, i don't think is it related to my laptop, i found that use context should be a best practice ([https://docs.python.org/3/library/ssl.html](https://docs.python.org/3/library/ssl.html)), so i said to myself that could be useful for everyone, so i ask to the community that have people more expert than me. if it's not useful, no problem

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *11:31:54*

just trying to be useful to the community, i think this is the purpose, help each other

*Tags: General Technical*

---

**liam** - *11:37:44*

But what problem is it solving and is it quicker / benchmark etc

*Tags: General Technical*

---

**Rishab** - *11:48:37*

Hey guys! I'm using Flumine to execute my orders &amp; noticing that for a few orders that are traded, in that tick itself the order.size_matched doesn't change. Don't see any bug in my code so far so wanted to confirm if the order details take some time to update or something?

*Tags: Errors Debugging*

---

**Rishab** - *12:07:25*

Its live. So lets say a new tick arrives &amp; streaming_update suggests that there's a trade in this tick. market in the last tick was 4.2@4.4 &amp; i was having a back order @4.4. Now in this tick, I check the order.size_remaining for my order &amp; it says its still the same(i.e I didn't get match) &amp; the market in this tick is 4.2@4.5. And my 4.4 order actually got matched

*Tags: Deployment*

---

**Unknown** - *12:42:59*

as written in the official documentation i linked

anyway leave the code as is, i had a problem and i solved ;)

*Tags: General Technical*

---

**Rishab** - *12:46:18*

Thanks Liam. That makes a lot more sense. Do you know any solution for this problem- if I want to put new orders in process_market_book based on what has happened to my existing orders?

*Tags: General Technical*

---

**Rishab** - *13:08:35*

Trying to wrap my head around the idea. The problem I'm facing at the moment is process_orders always gets called after process_market_book function ends &amp; that's the reason why I put everything in process_market_book(as my new orders are dependent on what has happened to my existing orders). As you have suggested process_orders is faster, but I can't call it as I need to know what has happened to my orders first &amp; then send orders based on that.

*Tags: General Technical*

---

**foxwood** - *17:11:50*

All the orders for the market are in the `blotter` so you can see their state from `process_market_book` Not sure exactly how/when the blotter is updated but the order data and market data are totally different BF streams coming from different systems and are not synced in time as far as I know so you can never be 100% sure of your true position at each packet. Middleware _may_ be something useful to consider in your design as shown after the blotter info at  [https://betcode-org.github.io/flumine/markets/#blotter](https://betcode-org.github.io/flumine/markets/#blotter)

*Tags: General Technical*

---

## 2023-10-05

**Andrey Luiz Malheiros** - *18:10:08*

Hi guys. I'm trying to use the market recorder from the examples on flumine, but it seems like the process_raw_data isn't being executed when I run the simulation. Do I need to adjust any settings to run the process_raw_data?

*Tags: Data Quality*

---

**liam** - *20:17:05*

The market recorder is for recording *live* data, what are you trying to do?

*Tags: Data Quality, Deployment*

---

## 2023-10-07

**Rishab** - *18:51:12*

Hi [@U4H19D1D2](@U4H19D1D2). Continuing on the last query I posted on the channel. I'm now using blotter in process_market_book for checking if my orders get traded and it seems to be working well in most of the cases. However, in one of the trades I got execution_complete status immediately, but it took a lot of time for size_remaining & matched_size to update(1 second). Could this exception happen sometimes? Just to note I also submitted a cancellation request for the same order as market moved through my quote in the tick & I didn't see any trade happen on that quote(because size_matched didn't update, so I pushed a cancellation request) & got an Execution_Complete status in the next tick(not sure if this was because of the trade happening in the last tick or my cancellation). So could it be that the cancellation request on a matched order is causing this delay or some sort of error at the exchange?

*Tags: Errors Debugging*

---

## 2023-10-09

**liam** - *14:44:42*

Just to update this, fix was released in 2.18.0 (we are now on 2.19.0) and I haven't seen any 'idle connection' errors since upgrading

*Tags: Errors Debugging*

---

**Riccardo Fresi** - *16:19:13*

Hi,



new error today, i had to downgrade python from 3.12 to 3.11, now on market recorded i got this, any idea?

Traceback (most recent call last):

  File "c:\Users\riccardo.fresi\OneDrive - Accenture\Downloads\Odds\streaming_soccer.py", line 61, in [module](module)

    framework.run()

  File "C:\Users\riccardo.fresi\AppData\Local\Programs\Python\Python311\Lib\site-packages\flumine\flumine.py", line 48, in run

    self._process_market_catalogues(event)

  File "C:\Users\riccardo.fresi\AppData\Local\Programs\Python\Python311\Lib\site-packages\flumine\baseflumine.py", line 263, in _process_market_catalogues

    market.market_book.streaming_unique_id in strategy.stream_ids

    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

AttributeError: 'NoneType' object has no attribute 'streaming_unique_id'

*Tags: Errors Debugging, Strategies*

---

**John Goodacre** - *16:44:56*

Hi - Sorry to dive in, I realise this was a month ago and so might be missed, but I was also interested in this question. I am not fully familiar with the flumine library, but am using it. I was looking to understand more fully how orders were matched in simulation and the parameters we have to play with, for example, sure traded value at that price, but also if prices at the touch moved through your asking price in simulation (thus assuming you would have been filled), and also the fact we do have information on net adds in the market book rather than trades themselves so potentially have a rough idea of where we might be in the queue?



Sorry to dive in, but I was also interested in how far you might have gone in these areas and if not, then what is doable/ planned. Finally if we set simulation_available_prices = True, then what is implemented thus far? For example, one simple test I was interested in was to trade and store a live game, then run the same game (or games) in backtest and see how closely they matched.

*Tags: Deployment*

---

**Gooat** - *17:05:50*

Flumine version? 2.5 working fine with python 3.11 here

*Tags: General Technical*

---

**Lee** - *18:07:23*

looks like it was fixed in [https://github.com/betcode-org/flumine/commit/06451c28252b87a94132dc1f29777cc696937f98#diff-28dd751aae21cc91cc5ad919ae03d17ecd9e6e3564b84b3c580798dc3a6b9a20L263|2.5.2](https://github.com/betcode-org/flumine/commit/06451c28252b87a94132dc1f29777cc696937f98#diff-28dd751aae21cc91cc5ad919ae03d17ecd9e6e3564b84b3c580798dc3a6b9a20L263|2.5.2)

*Tags: Errors Debugging*

---

**liam** - *19:02:30*

Yeah was a regression I fixed this morning 

*Tags: Errors Debugging*

---

**liam** - *19:44:00*

Reading the code will be the best way to understand this, happy to answer anything specific 



 [https://github.com/betcode-org/flumine/blob/06451c28252b87a94132dc1f29777cc696937f98/flumine/simulation/simulatedorder.py#L36|https://github.com/betcode-org/flumine/blob/06451c28252b87a94132dc1f29777cc696937f98/flumine/simulation/simulatedorder.py#L36](https://github.com/betcode-org/flumine/blob/06451c28252b87a94132dc1f29777cc696937f98/flumine/simulation/simulatedorder.py#L36|https://github.com/betcode-org/flumine/blob/06451c28252b87a94132dc1f29777cc696937f98/flumine/simulation/simulatedorder.py#L36)

*Tags: General Technical*

---

## 2023-10-12

**Riccardo Fresi** - *11:20:25*

new error, random during the recorder

```{"asctime": "2023-10-12 10:19:03,147", "levelname": "WARNING", "message": "_get_cleared_orders error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\riccardo.fresi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flumine\\worker.py\", line 195, in _get_cleared_orders\n    cleared_orders = betting_client.betting.list_cleared_orders(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\riccardo.fresi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\betfairlightweight\\endpoints\\betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\riccardo.fresi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"C:\\Users\\riccardo.fresi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.219555230'], 'customerStrategyRefs': ['C11-8C3Y06BQHRN'], 'settledDateRange': {'from': None, 'to': None}, 'fromRecord': 0} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang13b-prd-09131022-003f2bc994', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}```

any ideas?

*Tags: Errors Debugging, Strategies*

---

**Riccardo Fresi** - *11:37:02*

don't know, can i use keep alive in the market recorder?

*Tags: Data Quality, Deployment*

---

**liam** - *11:51:11*

any error logs

```"BetfairClient `keep_alive` error"```



*Tags: Errors Debugging, Deployment*

---

**Unknown** - *11:56:12*

i can set as below, i remember that without flumine i used to keep alive and session go well all night long

*Tags: Deployment*

---

**Riccardo Fresi** - *13:50:10*

my script was a loop with wait, basically a keep_alive every cycle; inddeed i used to make a try call for every api and a reconnect call in case of error

*Tags: Errors Debugging, Deployment*

---

**AndyL** - *17:45:08*

all my bots had "connection closed by server" errors at about 06:20 this morning, followed by numerous MAX_CONNECTIONS_EXCEEDED you have 11 max 10 ! Which meant several failed to instantiate the order stream I think, caused all sorts of mess !! Closed them all off now, will restart them later.

Anyone else have issues today?

*Tags: Errors Debugging, Deployment*

---

**liam** - *18:57:05*

Pretty standard, are you a flumine user or do you have exponential back off on reconnects?

*Tags: General Technical*

---

**AndyL** - *20:26:34*

Flumine user

*Tags: General Technical*

---

**AndyL** - *20:30:36*

[@U4H19D1D2](@U4H19D1D2) I think it's just me, i've got 4 Flumine processes, that consume 2 connections each, and a Recorder process consuming 2, so that should be the "10"

But for some reason, if I restart my Recorder it bombs loads of 10 connections exceeded error....

Not sure what i've done other than extend the some of the subscriptions to cover "PLACES" markets

*Tags: Errors Debugging*

---

**AndyL** - *20:54:42*

nope can't start my recorder... always fails:

```{"asctime": "2023-10-12 19:51:46,255", "levelname": "ERROR", "message": "[FlumineStream: 3002]: MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s)."}```

*Tags: Errors Debugging*

---

**foxwood** - *20:57:08*

The logs show you the number of connections still available after each connection - may help pin it down - at `INFO` level for logs

*Tags: General Technical*

---

## 2023-10-13

**AndyL** - *18:57:17*

[@U01MPC0GUK1](@U01MPC0GUK1) So yes i'm using those options for the BetfairClient, but I had 3 MarketRecorder instances, as I had various market_filter's, and it seems each MarketRecorder DataStream class creates 1 Connection, hence for my 3 recorder strategies it needed 3.... i've now reduced it to 2 and it start fine now.

I did not realise each MarketRecorder strategy used a connection

[@U4H19D1D2](@U4H19D1D2)

*Tags: Strategies*

---

**liam** - *19:12:57*

*Each market filter uses a connection (you can have multiple per strategy) 

*Tags: Strategies*

---

**AndyL** - *19:21:33*

so like say:

```market_filter=[

betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["GB", "IE"],

        market_types=["WIN","PLACE","OTHER_PLACE"],

    ),

betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["4339"],

        country_codes=["GB", "IE", "AU"],

        market_types=["WIN"],

    )

]```

*Tags: General Technical*

---

**AndyL** - *19:25:11*

So Subscription == streaming_market_filter ?

*Tags: General Technical*

---

**AndyL** - *19:38:30*

right, and a subscription is presumably equating to each streaming_market_filter above ?

So in theory although you've got 10 connections, you could have more Subscriptions than that, hence more than say 10,000 theoretical markets?

*Tags: General Technical*

---

## 2023-10-15

**PeterLe** - *15:43:37*

Im running four instances Liam on the same AWS instance, three were giving that error (if Ive checked it correctly and didnt miss it on the one I thought was OK..)

The one that looked ok -  I restarted that one yesterday after I changed some parameters? Not sure if that had something t do with it?

Anyway, all good now, been a good day so far :grinning:

*Tags: Errors Debugging, Deployment*

---

## 2023-10-16

**Andrey Luiz Malheiros** - *00:25:50*

I'm having trouble running the marketrecorder located at flumine/examples/strategies/marketrecorder.py within the flumine Git repository. It seems that the process_raw_data is not being executed. Do I need to make any changes to the marketrecorder (such as returning True in the check_market_book or passing the strategy's stream_class as DataStream instead of MarketStream)?

*Tags: Strategies*

---

**Andrey Luiz Malheiros** - *18:23:00*

I managed to solve it.

The issue was that I needed to pass the DataStream instead of the MarketStream to the stream_class parameter on strategy

*Tags: Strategies*

---

## 2023-10-17

**MMW** - *16:36:58*

Cancel Order single bet



[https://api.betfair.com/exchange/betting/rest/v1.0/cancelOrders/|https://api.betfair.com/exchange/betting/rest/v1.0/cancelOrders/](https://api.betfair.com/exchange/betting/rest/v1.0/cancelOrders/|https://api.betfair.com/exchange/betting/rest/v1.0/cancelOrders/)



{"params": {"marketId": "1.219815567", "instructions":[{"betId": "325032312929"}]}, "id": 1}



How to cancel a single bet I am trying to cancel a bet but cancel all bets back or lay kindly help me, please

*Tags: Strategies*

---

**MMW** - *16:42:19*

How to cancel single bet c# 

This method cancel all bets

*Tags: General Technical*

---

**MMW** - *17:14:09*

How to cancel .py language any idea

*Tags: General Technical*

---

**D C** - *17:22:50*

If this is the actual JSON you are sending then I can't see what is wrong with it. Maybe someone else can find an error in it.

*Tags: Errors Debugging*

---

## 2023-10-18

**D C** - *09:54:14*

You don't need to explicitly set to null [@U9JHLMZB4](@U9JHLMZB4) - just the absence of "sizeReduction" is sufficient. I don't have this field in my bets when I cancel them. What I did wonder is what would happen if you sent orders that are in a different market to the one specified in the request. Never tried it myself but I would suspect that you'd just get an error, but perhaps that could be an issue too. Not much to go on here though to be honest - could be a multitude of other things going on that we are not aware of.

*Tags: Errors Debugging*

---

**liam** - *10:13:24*

I am not sure, flumine should call keep_alive every 10 minutes for IT users

*Tags: Deployment*

---

**Riccardo Fresi** - *13:28:34*

there is no dependency from update frequency? if for a event there is no update for let's say 1 hour, flumine call keep_alive ?

*Tags: Deployment*

---

**Neil T (Betfair)** - *13:36:26*

Hi [@U4H19D1D2](@U4H19D1D2),  keep alive should work as expected for Italian users when requested within the session expiry time.  Regardless of this, clients should still handle INVALID_SESSION_INFORMATION errors by creating a new API login request

*Tags: Errors Debugging, Deployment*

---

## 2023-10-27

**George** - *13:43:08*

In a worker, I am executing the following code:

```for m in flumine.markets:

    do_stuff(m)```

My problem is that `do_stuff` is never called; python is never entering the `for` loop. I put a print statement in the code, to print the value of `len(flumine.markets)` , and I get 0, which explains why `do_stuff` is not getting called.



Then I go in with the debugger and print the value of `len(flumine.markets)` and it is 126.



Does anyone know what is happening? This is super weird to me.

*Tags: Errors Debugging*

---

**George** - *14:00:25*

I edited my post to answer that question while you were asking it, apologies

*Tags: General Technical*

---

**George** - *14:01:35*

it's almost like the version of `flumine.markets` which is passed to the thread is faulty, and then when I go in with the debugger it's picked up the correct version again

*Tags: Errors Debugging*

---

**Derek C** - *14:10:08*

I'm not a flumine expert, but I think to get quality assistance with this you would need to provide more concrete information about what you are doing - market filter, worker setup etc. It's quite hypothetical at the moment and you are asking people to guess what might be wrong with some code they can't see.

*Tags: Getting Started*

---

**George** - *14:14:31*

Actually, I think it is a race condition. Seems like the `flumine.markets` get added after the worker gets called the first time.

*Tags: Getting Started*

---

**liam** - *14:48:04*

[https://github.com/betcode-org/flumine/blob/06451c28252b87a94132dc1f29777cc696937f98/flumine/worker.py#L23|start_delay](https://github.com/betcode-org/flumine/blob/06451c28252b87a94132dc1f29777cc696937f98/flumine/worker.py#L23|start_delay)

*Tags: General Technical*

---

## 2023-10-29

**foxwood** - *13:15:37*

As I understand it the function definition `def selection_exposure(self, strategy, lookup: tuple) -&gt; float:` requires a tuple which I am presuming should contain one or more selection ids



That means (to me) that `market.blotter.selection_exposure(self,(mything.selection_id,))` should work ok. No matter what construct I use for the tuple it fails with an error of one sort or another.



Eventually I found that `market.blotter.selection_exposure(self,(0,mything.selection_id))` seems to work correctly.



If my understanding is right, cause of problem may be in `blotter.get_exposures() ... for order in self.strategy_selection_orders(strategy, *lookup[1:]):` which looks to me that it expects to start from subscript 1 and not 0.



Is something else expected in subscript position 0 ?

*Tags: Errors Debugging, Strategies*

---

**birchy** - *18:11:49*

`orders = market.blotter.strategy_selection_orders(strategy=self, selection_id=sel_id)

for o in orders:

    ...`

*Tags: Strategies*

---

## 2023-10-31

**Mikkel** - *16:54:29*

Has anyone else experience that not all BSP order goes through when using Flumine? From flumine I can see that the bet should be posted / executed but nothing shows up on Betfair?

*Tags: General Technical*

---

## 2023-11-03

**foxwood** - *13:54:20*

In `simulatedorder.py:_process_sp()` there can be occasions when `actual_sp` is in `'None','NaN','Infinity'` (last 2 are as per BF docs - think I've found `None` before since have something in my code testing that). Currently my backtest logs show an exception thrown `File "C:\\...\\flumine\\simulation\\simulatedorder.py", line 391, in _process_sp\n    size = round(remaining_risk / (actual_sp - 1.0), 2)\nTypeError: unsupported operand type(s) for -: 'str' and 'float'"` Have a sample recorded file with 'Nan' if would help ?



EDIT: raised a git issue for this

*Tags: Errors Debugging*

---

**liam** - *15:53:34*

Thanks for raising, we have a [https://github.com/betcode-org/flumine/blob/06451c28252b87a94132dc1f29777cc696937f98/flumine/utils.py#L168|function](https://github.com/betcode-org/flumine/blob/06451c28252b87a94132dc1f29777cc696937f98/flumine/utils.py#L168|function) for this so not sure why I haven't used it / why this hasn't been raised before :thinking_face:

*Tags: General Technical*

---

**liam** - *16:13:01*

Can you share the file so I can test [https://github.com/betcode-org/flumine/commit/0aa53dd45b6555a994b91b2938423f79b5b343df|this](https://github.com/betcode-org/flumine/commit/0aa53dd45b6555a994b91b2938423f79b5b343df|this)?

*Tags: General Technical*

---

## 2023-11-07

**liam** - *09:02:13*

I added, [https://github.com/betcode-org/flumine/pull/718|released](https://github.com/betcode-org/flumine/pull/718|released) yesterday if you can test?

*Tags: General Technical*

---

## 2023-11-09

**AndyL** - *19:24:32*

[@U4H19D1D2](@U4H19D1D2) had a bit of an issue with one of my Flumine processes that eventually crashed the VM, thought i'd pass it by you incase it looks familiar. My naive view it looks a bit like a run-away thread/resource issue..?

• Flumine 2.4.2 betfairlightweight 2.17.3

looking at the "logs", the issue looked to start gradually with periodic:

```High latency between current time and OrderPackage creation time, it is likely that the thread pool is currently exhausted", "trading_function": "cancel", "session": "&lt;requests.sessions.Session object at 0x7f70f376bc40&gt;", "latency": 0.381, "order_package": {"id": "xxxxx", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f7119b1b6a0&gt;", "market_id": "1.220926100", "orders": ["139188221331829894"], "order_count": 1, "package_type": "Cancel", "customer_strategy_ref": "XXXXX", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}, "thread_pool": {"num_threads": 26, "work_queue_size": 3}}```

then a few mins later got:

```"High latency between current time and MarketBook publish time", "market_id": "1.220920848", "latency": 2.08534836769104, "pt": "2023-11-09T11:37:19.521000"}```

this repeated then "continuously" with latency time steadily increasing... message being issued about 50/second

```{"asctime": "2023-11-09 11:40:30,227", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.220926100", "latency": 14.246732711791992, "pt": "2023-11-09T11:40:15.981000"}```

then about 150 warnings/second

```{"asctime": "2023-11-09 11:54:22,299", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.220920734", "latency": 176.0338258743286, "pt": "2023-11-09T11:51:26.266000"}```

eventually the increasing CPU usage killed the AWS VM which I had to reboot via the console

*Tags: Performance, Deployment, Strategies*

---

**Unknown** - *20:47:16*

yes the crash yes, although i've just been looking at my AWS CPU history and i've recently noticed periodic spikes in CPU. I recently added PLACE markets an am wondering if my VM is under powered....

*Tags: Deployment*

---

**liam** - *20:49:29*

It will be some dodgy code or the instance, the latter is a quick fix 

*Tags: Errors Debugging*

---

**AndyL** - *20:50:16*

yeah i've been looking through the code and logs... the one other thing i've noticed periodically is:

```Exception processing order for 1.220920786 : 54907 : Order does not currently have a betId"```

*Tags: Errors Debugging*

---

**AndyL** - *20:50:31*

happens more frequently when latency spikes

*Tags: Performance*

---

## 2023-11-10

**Unknown** - *01:59:43*

Has anyone else found that when running a simulation in Flumine that it'll match any price you give a MARKET_ON_CLOSE bet? Ignoring the lay bets, the initial back bet placed at 1 sec from start with market_on_close is getting matched far higher than the BSP

```trade = Trade(market_id=market_book.market_id,selection_id=runner['selection_id'],handicap=0,strategy=self,)

order = trade.create_order(side=strSide, order_type=LimitOrder(price=MoveMarketOdds(nAmount,100,1), size=1.0, persistence_type='MARKET_ON_CLOSE')) # MARKET_ON_CLOSE

market.place_order(order)```



*Tags: Strategies*

---

**PeterLe** - *10:19:51*

Andy Im running 6 flumine instances on an AWS Windows instance 4gb 2vcpus and never had any issues (lightsail) $40/month

(As Im expecting a few sick emojis re Windows, Ill mention I also have a few instances running on the same 4gb 2 vcpus ubuntu but thats only $20/month) :grinning:

*Tags: Deployment*

---

**liam** - *10:55:54*

Ok, latest version for flumine?

*Tags: General Technical*

---

**Brett Riley** - *11:52:58*

Yup confirmed it was a version problem/conflict, thanks for the assistance!

*Tags: General Technical*

---

**AndyL** - *18:06:51*

thanks [@UQL0QDEKA](@UQL0QDEKA) So i've moved to a AWS t4g, and no latency issues anymore,which is progress.

However, bot still having issues which looks like a coding bug of mine, it's interesting it's taking a while to develop given this version of the instance has been running a month, but this week my "hedging" is failing, and i'm getting loads of these exceptions:

```Order does not currently have a betId```

Which is odd, unfortunately it's in my hedging logic, I need to handle it better I think.

But [@U4H19D1D2](@U4H19D1D2) how does an Order not have a betId ?

*Tags: Errors Debugging, Performance, Deployment*

---

**liam** - *18:14:12*

Not sure but if it’s hedging it’s a problem you shouldn’t solve 

*Tags: General Technical*

---

**AndyL** - *18:27:14*

I think old_order is getting the exception...

*Tags: Errors Debugging*

---

**AndyL** - *18:38:46*

Hmm [@U4H19D1D2](@U4H19D1D2) not sure I can explain this order, it's a MARKET_ON_CLOSE placed at 30secondToStart, and immediately EXECUTION_COMPLETE, notice time elapsed: 1.3e-05

and notice "size_remaining\": 6.73 . It's a TakeSP bet completed, also orderId is None:

```1.220974195:32494174 size_matched 0.0 avg_price_matched: 0.0 req_size: 6.73 req_price: 1000.0 order : Order None: Execution complete : {\"market_id\": \"1.220974195\", \"selection_id\": 32494174, \"handicap\": 0, \"id\": \"1076299499178434720\", \"customer_order_ref\": \"653232d17db55-1076299499178434720\", \"bet_id\": null, \"date_time_created\": \"2023-11-10 17:19:30.003743\", \"publish_time\": \"2023-11-10 17:19:29.994000\", \"market_version\": null, \"async\": false, \"trade\": {\"id\": \"f2462edf-5e87-4e87-8f59-98259226e948\", \"strategy\": \"LiveHorseUK\", \"place_reset_seconds\": 0.0, \"reset_seconds\": 0.0, \"orders\": [\"1076299499178434720\"], \"offset_orders\": [], \"notes\": \"\", \"market_notes\": \"23,24,24\", \"status\": \"Complete\", \"status_log\": \"Pending, Live, Complete\"}, \"order_type\": {\"order_type\": \"Limit\", \"price\": 1000.0, \"size\": 6.73, \"persistence_type\": \"MARKET_ON_CLOSE\", \"time_in_force\": null, \"min_fill_size\": null, \"bet_target_type\": null, \"bet_target_size\": null, \"price_ladder_definition\": \"CLASSIC\"}, \"info\": {\"side\": \"BACK\", \"size_matched\": 0.0, \"size_remaining\": 6.73, \"size_cancelled\": 0.0, \"size_lapsed\": 0.0, \"size_voided\": 0.0, \"average_price_matched\": 0.0}, \"responses\": {\"date_time_placed\": \"2023-11-10 17:19:30.046825\", \"elapsed_seconds_executable\": 1.3e-05}, \"runner_status\": null, \"status\": \"Execution complete\", \"status_log\": \"Pending, Execution complete\", \"violation_msg\": null, \"simulated\": {\"profit\": 0.0, \"piq\": 0.0, \"matched\": []}, \"notes\": \"29,23.5,GB,WIN\", \"market_notes\": \"23,24,24\", \"client\": \"aaaa\"}"} ```

*Tags: Deployment, Strategies*

---

**liam** - *19:05:05*

Do you know when you are getting the exception? Placing and cancelling is async so there will be a delay before you get a response / betId which I assume is causing the issue here 

*Tags: Errors Debugging*

---

**AndyL** - *19:09:41*

so in the example above, the one being cancelled was active for 8mins, and was cancelled in the logic show above, here's the response on that one, which appears at the exact same time as the above placed order (completion!)

```{"asctime": "2023-11-10 17:19:30,301", "levelname": "WARNING", "message": "HEDGE_COMPLETE: BACK : 29 : 1.220974195:32494174 size_matched 0.0 avg_price_matched: 0.0 req_size: 7.36 req_price: 1000.0 order : Order 328103107234: Execution complete : {\"market_id\": \"1.220974195\", \"selection_id\": 32494174, \"handicap\": 0, \"id\": \"63929374292148811\", \"customer_order_ref\": \"653232d17db55-63929374292148811\", \"bet_id\": \"328103107234\", \"date_time_created\": \"2023-11-10 17:11:26.564031\", \"publish_time\": \"2023-11-10 17:11:25.635000\", \"market_version\": null, \"async\": false, \"trade\": {\"id\": \"acf023f5-f990-4a2e-ac25-2d9475cb5477\", \"strategy\": \"LiveHorseUK\", \"place_reset_seconds\": 0.0, \"reset_seconds\": 0.0, \"orders\": [\"63929374292148811\"], \"offset_orders\": [], \"notes\": \"\", \"market_notes\": \"21,22,22\", \"status\": \"Complete\", \"status_log\": \"Pending, Live, Pending, Live, Complete\"}, \"order_type\": {\"order_type\": \"Limit\", \"price\": 1000.0, \"size\": 7.36, \"persistence_type\": \"MARKET_ON_CLOSE\", \"time_in_force\": null, \"min_fill_size\": null, \"bet_target_type\": null, \"bet_target_size\": null, \"price_ladder_definition\": \"CLASSIC\"}, \"info\": {\"side\": \"BACK\", \"size_matched\": 0.0, \"size_remaining\": 0.0, \"size_cancelled\": 7.36, \"size_lapsed\": 0.0, \"size_voided\": 0.0, \"average_price_matched\": 0.0}, \"responses\": {\"date_time_placed\": \"2023-11-10 17:11:26.684107\", \"elapsed_seconds_executable\": 483.44282}, \"runner_status\": null, \"status\": \"Execution complete\", \"status_log\": \"Pending, Executable, Cancelling, Execution complete\", \"violation_msg\": null, \"simulated\": {\"profit\": 0.0, \"piq\": 0.0, \"matched\": []}, \"notes\": \"513,21.5,GB,WIN\", \"market_notes\": \"21,22,22\", \"client\": \"aaaa\"}"}```

*Tags: Deployment, Strategies*

---

**liam** - *19:11:12*

Without some code to replicate it’s impossible for me to debug 

*Tags: Errors Debugging*

---

**AndyL** - *19:12:38*

yeah now worries, i'm going to catch the cancel no OrderId exception within the inner bit of code, so at least my hedging can recover...

*Tags: Errors Debugging*

---

**liam** - *19:50:36*

What’s your latency like for place / cancel requests?

*Tags: Performance*

---

**liam** - *19:53:15*

Flumine logs it for you 

*Tags: General Technical*

---

## 2023-11-11

**Paul** - *15:07:42*

I'm using bflw to place some LIMIT orders as per below, but getting back INVALID_BET_SIZE errors on some bets - others formatted in the same way, with the same stake get executed fine. Ideas?

```{'orderType': 'LIMIT', 'selectionId': 22386662, 'side': 'BACK', 'handicap': '0', 'limitOrder': {'price': '55', 'persistenceType': 'PERSIST', 'betTargetType': 'PAYOUT', 'betTargetSize': '10'}}```



*Tags: Errors Debugging*

---

**Unknown** - *15:34:53*

[@U4H19D1D2](@U4H19D1D2) so found error from logging as to why my place_order is occaisionally failing:

```{"asctime": "2023-11-11 15:25:56,077", "levelname": "INFO", "message": "Order Place: FAILURE", "bet_id": null, "order_id": "1072113949238803678", "status": "FAILURE", "error_code": "INVALID_CUSTOMER_ORDER_REF"}```

:

```{"asctime": "2023-11-11 15:25:56,076", "levelname": "INFO", "message": "execute_place", "trading_function": "place", "elapsed_time": 0.04937458038330078, "response": {"customerRef": "a897131b2ef44081b9581b8d9d7d72bc", "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.221016025", "instructionReports": [{"status": "FAILURE", "errorCode": "INVALID_CUSTOMER_ORDER_REF", "instruction": {"selectionId": 49020468, "handicap": 0.0, "limitOrder": {"size": 47.18, "price": 1000.0, "persistenceType": "MARKET_ON_CLOSE"}, "customerOrderRef": "653232d17db55-1072113949238803678", "orderType": "LIMIT", "side": "BACK"}}]}, "order_package": {"id": "a897131b-2ef4-4081-b958-1b8d9d7d72bc", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0xffffb6d03c40&gt;", "market_id": "1.221016025", "orders": ["1072113949238803678"], "order_count": 1, "package_type": "Place", "customer_strategy_ref": "AAAAAA", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}```

This is happening about 25% of my hedge bets, and I am sure this was not happening a week ago...

*Tags: Errors Debugging, Strategies*

---

**AndyL** - *16:03:54*

Looks like this change: [https://github.com/betcode-org/flumine/commit/c9598216206bb9bf523e7721d412b1ef1f54e759](https://github.com/betcode-org/flumine/commit/c9598216206bb9bf523e7721d412b1ef1f54e759)

*Tags: General Technical*

---

**AndyL** - *16:04:51*

uuid4() from a quick python test returns sometimes &gt; 18 chars

*Tags: General Technical*

---

**AndyL** - *16:14:02*

[@U4H19D1D2](@U4H19D1D2) raised [https://github.com/betcode-org/flumine/issues/721](https://github.com/betcode-org/flumine/issues/721)

*Tags: General Technical*

---

**AndyL** - *16:18:05*

you've probably got better error handling than me...! i'm working on improving my handling of errors

*Tags: Errors Debugging*

---

**AndyL** - *16:18:28*

[https://github.com/betcode-org/flumine/issues/721](https://github.com/betcode-org/flumine/issues/721)

*Tags: General Technical*

---

**ShaunW** - *17:07:06*

Begs the question why do you need one that long anyway?

*Tags: General Technical*

---

**Derek C** - *17:19:33*

I'm quite superstitious about rounding errors so I would try a payout of £11, in case the intended bet of ~18.5 pence is causing a payout of 9.99 and being rejected as less than 10.00

*Tags: Errors Debugging*

---

**liam** - *19:18:51*

Mixture of legacy and UUID’s are quick in python (C) 

*Tags: General Technical*

---

## 2023-11-12

**JazzMan** - *15:29:21*

Does anyone know why I’m getting this error message when sending a REQUEST_AUTHENTICATION “Unable to write data to the transport connection: An established connection was aborted by the software in your host machine”, just happened today, been running for years, c# program 

*Tags: Errors Debugging*

---

**Mo** - *16:23:05*

Is this a Betfair API error message? An HTTP error message? An OS error message?

*Tags: Errors Debugging*

---

**JazzMan** - *16:26:26*

Thanks for your reply [@UBS7QANF3](@UBS7QANF3), the main point is it's been working for years then today the betfair api gives me an error, tried on different machines.

*Tags: Errors Debugging*

---

**Paul** - *18:01:57*

A quick google around suggests this could be a change in your environment, not Betfair's:



[https://stackoverflow.com/questions/30863059/unable-to-write-data-to-the-transport-connection-an-established-connection-was](https://stackoverflow.com/questions/30863059/unable-to-write-data-to-the-transport-connection-an-established-connection-was)



But then, maybe not:



[https://stackoverflow.com/questions/14304658/c-sharp-an-established-connection-was-aborted-by-the-software-in-your-host-machi](https://stackoverflow.com/questions/14304658/c-sharp-an-established-connection-was-aborted-by-the-software-in-your-host-machi)



One thing worth checking is whether you (or something between you and Betfair) is messing around with Content-Length headers:



[https://stackoverflow.com/questions/31931438/c-sharp-an-established-connection-was-aborted-by-the-software-in-your-host-mac](https://stackoverflow.com/questions/31931438/c-sharp-an-established-connection-was-aborted-by-the-software-in-your-host-mac)

*Tags: General Technical*

---

## 2023-11-13

**liam** - *09:03:58*

[https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#254-2023-11-13](https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#254-2023-11-13)

*Tags: General Technical*

---

**liam** - *10:12:33*

[https://github.com/betcode-org/flumine/blob/3d697cdb4d186b66af574afcf8001f18776f331d/flumine/streams/streams.py#L93|yes](https://github.com/betcode-org/flumine/blob/3d697cdb4d186b66af574afcf8001f18776f331d/flumine/streams/streams.py#L93|yes), logs will tell you

*Tags: General Technical*

---

## 2023-11-14

**Clive** - *09:21:11*

Will do. I’ll ideally fix it if I have time too. 

*Tags: Errors Debugging*

---

## 2023-11-16

**AndyL** - *17:45:57*

Hi [@U4H19D1D2](@U4H19D1D2) what does this mean in real terms please?

```{"asctime": "2023-11-16 11:55:48,259", "levelname": "WARNING", "message": "High latency between current time and OrderPackage creation time, it is likely that the thread pool is currently exhausted", "trading_function": "cancel", "session": "&lt;requests.sessions.Session object at 0xffff62401130&gt;", "latency": 0.29, "order_package": {"id": "14c7f3f3-8477-11ee-98e5-77b81b73792a", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0xffffb03a1ac0&gt;", "market_id": "1.221270586", "orders": ["139194285340131329"], "order_count": 1, "package_type": "Cancel", "customer_strategy_ref": "aaaa", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}, "thread_pool": {"num_threads": 18, "work_queue_size": 0}}```

followed by lots of these later on:

```{"asctime": "2023-11-16 13:28:46,316", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.221270587", "latency": 68.93769669532776, "pt": "2023-11-16T13:27:37.379000"}```

*Tags: Performance, Strategies*

---

**AndyL** - *17:48:31*

followed eventually by Flumine instance being OOM killed !!:

```[571936.357166] oom-kill:constraint=CONSTRAINT_NONE,nodemask=(null),cpuset=/,mems_allowed=0,global_oom,task_memcg=/user.slice/user-1000.slice/session-72.scope,task=python3,pid=18874,uid=1000

[571936.357231] Out of memory: Killed process 18874 (python3) total-vm:2811936kB, anon-rss:1657564kB, file-rss:0kB, shmem-rss:0kB, UID:1000 pgtables:3488kB oom_score_adj:0

[571937.565101] loop6: detected capacity change from 0 to 8```

*Tags: Performance*

---

**AndyL** - *17:50:31*

Hmm yeah, ok thanks, i'll do some debug

*Tags: Errors Debugging*

---

## 2023-11-17

**liam** - *06:25:12*

This won’t be the problem, you have something bad happening in your code, profile it 

*Tags: General Technical*

---

**Jimmy** - *13:37:37*

Just come back to Flumine and have been recording some data — trying to set up a simulation using the data. Based it off the WOM example [@U4H19D1D2](@U4H19D1D2) shared: [https://github.com/liampauling/flumine-strategy-development/blob/master/main.py](https://github.com/liampauling/flumine-strategy-development/blob/master/main.py)



Hits this error when I chuck a few files at it:



```  File "path removed", line 68, in &lt;module&gt;

    framework.run()

  File "/flumine/venv/lib/python3.11/site-packages/flumine/simulation/simulation.py", line 96, in run

    for event in stream_gen():

  File "/flumine/venv/lib/python3.11/site-packages/flumine/streams/historicalstream.py", line 224, in _read_loop

    if listener_on_data(update):

       ^^^^^^^^^^^^^^^^^^^^^^^^

  File "/flumine/venv/lib/python3.11/site-packages/flumine/streams/historicalstream.py", line 209, in on_data

    publish_time = data["pt"]



KeyError: 'pt'```

*Tags: Errors Debugging, Strategies*

---

**liam** - *13:38:29*

Can you share a file that errors?

*Tags: Errors Debugging*

---

**liam** - *13:39:43*

`FlumineBacktest`? How old is your version?

*Tags: General Technical*

---

**Jimmy** - *13:41:16*

```    client = clients.SimulatedClient()

    framework = FlumineSimulation(client=client)```

*Tags: General Technical*

---

**Jimmy** - *13:41:41*

flumine==2.5.2

*Tags: General Technical*

---

**liam** - *13:42:45*

`FlumineBacktest` was removed in Feb 22

*Tags: General Technical*

---

**liam** - *13:46:09*

looks like you are passing that in as per a market file which then gives the error

*Tags: Errors Debugging*

---

**liam** - *13:51:21*

np, if i remember I will put some error handling on this, FYI don't use version 2.5.2 as it has a bug when placing orders

*Tags: Errors Debugging*

---

**foxwood** - *14:08:31*

I keep the catalogue files in the same folder as the data files - seems simpler to me - you can build list of data files to be fed to strategy filtered out something like this

`for d in dataDir:`

    `files = listdir(d)`

    `for f in files:`

        `fullName = join(d, f)`

        `if isfile(fullName) and f.endswith(".gz") and f.find("json") == -1 :`

		        `marketFiles.append(fullName)`

*Tags: Strategies*

---

**AndyL** - *19:22:59*

[@U4H19D1D2](@U4H19D1D2) thanks Liam, yes, I think i've worked it out, it's not a memory leak per-se. Basically since I added PLACE to the listener, I am now subscribing GB,IE and WIN,PLACE for this one strategy, and it actively trades from 3hours out from startTime. What I see is a gradual increase in CPU towards mid-day when the main afternoon races fall within that 3hour window. I roughly calculated the market processing thread will be going around 50 markets, and my strategy code is probably not as efficient as it could be... My VM CPU then hits 50% in a 2vCPU box, which then starts to limit it, the affect it had was to cause the market update processing to lag the live updates, causing a steady progression of increase in latency, eventually towards a latency of 30mins!!! My trading  logic once the latency hit around 5mins was starting to put orders in for markets that were now closed! Thus getting lots of BF errors, and what made things worse for my hedge bets I was rather stupidly immediately re-placing the failed hedge causing yet more of a race......and eventually bang!

What i've learned:

1. I need to profile my strategy code more to try and make it more efficient. I've already done a good set of fixes...

2. I'm perhaps pushing my luck adding PLACE and doubling the number of active markets in that 3hour trade window, running on a single Flumine instance....

3. Importantly I need to monitor "latency" to prevent this sort of CPU race condition

I've done a set of fixes for 1 & 3 and I'm testing them now.....

*Tags: Errors Debugging, Performance, Deployment, Strategies*

---

**liam** - *19:28:36*

Yeah fixing your code is the easy fix, the warning logs normally hint at this but as you have found out things tend to escalate rather quickly 

*Tags: Errors Debugging*

---

**liam** - *19:29:11*

Do you need the full book? Limiting the data filter can sometimes help

*Tags: General Technical*

---

**AndyL** - *19:48:23*

[https://github.com/betcode-org/flumine/blob/3d697cdb4d186b66af574afcf8001f18776f331d/flumine/strategy/strategy.py#L13C1-L23C2](https://github.com/betcode-org/flumine/blob/3d697cdb4d186b66af574afcf8001f18776f331d/flumine/strategy/strategy.py#L13C1-L23C2)

*Tags: Strategies*

---

**Derek C** - *20:31:11*

I'm having a problem using middleware in Flumine. Based on the  example: _examples/middleware/marketcatalogue.py,_ I want to populate market catalogues in a simulation. The trouble is that I store the market catalogue files on AWS S3 and the calls to AWS get rejected because the API call is using the monkey-patched version  of datetime.utcnow() in the request, causing AWS to reject the request.



The AWS error message is:

>  _"botocore.exceptions.ClientError: An error occurred (RequestTimeTooSkewed) when calling the GetObject operation: The difference between the request time and the current time is too large."_

So my question is - how can I use a middleware class without the monkey-patch?



I've tried using the SimulatedDateTime class but I'm stumped.

*Tags: Errors Debugging, Deployment*

---

## 2023-11-18

**Peter** - *11:10:21*

The monkey patching is needed for the streaming so messing with it is likely to be challenging. The approach that I use is to include a block in my simulation runner script that identifies the files that will be needed, both catalogues and stream files, and then download them to a local cache before passing the local location into the Flumine instance.



There's no additional network traffic as I'm simply shifting the time when the data is streamed from S3, and usually there's a saving, as I often end up tweaking and re-running the simulation, but without the external network traffic on subsequent runs.

*Tags: General Technical*

---

**Derek C** - *11:25:49*

Thanks Peter, I wondered if that would be the solution. My reason for trying to get it to work the way I've coded it is because I run my simulation in the cloud (docker + fargate) and it would be more convenient if it could access AWS dynamically within middleware rather than download locally first. I take your point about the network traffic. Mental laziness on my part :slightly_smiling_face: Looking at the class "SimulatedDateTime" gives me the impression I should be able to switch modes.

*Tags: Deployment*

---

## 2023-11-19

**Rishab** - *06:03:03*

Hey guys! I'm struggling with an issue where for a few of my orders order_status changes directly from "PENDING" to "EXECUTION_COMPLETE" with the size_remaining unchanged. It's frustrating cause in some cases it takes more than a minute for size_remaining to change to 0.  Only in roughly 2% of such cases order_status changes because my order actually traded, in the rest of the cases it just goes to execution_complete(not sure why). I have to wait for size_remaining to change to 0(or a different number than what I've placed) to actually place a new order as otherwise I can't be confident if my previous order got filled &amp; this is a huge problem as sometimes it might take &gt;1 min. Has anyone had this problem in the past? I'm a flumine user.

*Tags: General Technical*

---

**liam** - *07:07:51*

Impossible to help without some code to replicate 

*Tags: General Technical*

---

**AndyL** - *09:25:00*

[@U05KECSV68N](@U05KECSV68N) if the bet "status log" shows "Pending, ExecutionComplete", that sounds like the error I was getting which has now been fixed. Whereby the place_trade actually failed... Check what version of Flumine you are using...?

*Tags: Errors Debugging*

---

**Rishab** - *09:59:04*

[@U4H19D1D2](@U4H19D1D2), I'll share it. just digging if there's some pattern in it. [@U01PJ5YMFBJ](@U01PJ5YMFBJ) I'm on '2.5.3', I think it's the same issue u are talking about. I'll quickly check and confirm. How did it fix for you?

*Tags: Errors Debugging*

---

**AndyL** - *10:24:33*

[@U05KECSV68N](@U05KECSV68N) yes, 2.5.3 will have the issue.... Liam fixed it in 2.5.4

*Tags: Errors Debugging*

---

## 2023-12-01

**liam** - *10:25:53*

Suddenly got lots of errors coming through, maybe it was me..

*Tags: Errors Debugging*

---

**CL** - *10:39:38*

betfairlightweight.exceptions.InvalidResponse: Invalid response received

*Tags: Errors Debugging*

---

**Mo** - *11:29:58*

Nevermind, user error

*Tags: Errors Debugging*

---

## 2023-12-03

**Unknown** - *16:15:09*

Has anyone been getting an increase of errors on list_cleared_orders endpoint over the last 3 days?

*Tags: Errors Debugging*

---

**AndyL** - *18:57:18*

[@UUCD6P13J](@UUCD6P13J) you mean these ?

```{"asctime": "2023-12-02 22:49:10,557", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flumine/worker.py\", line 229, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.222016636'], 'customerStrategyRefs': ['AAAA'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00ae6c3413', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00ae6c3413', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.222016636'], 'customerStrategyRefs': ['AAAA'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00ae6c3413', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00ae6c3413', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

*Tags: Errors Debugging, Strategies*

---

## 2023-12-05

**Neil T (Betfair)** - *10:10:25*

Hi [@UFTBRB3F1](@UFTBRB3F1) - I can confirm that listClearedOrders returned to normal service yesterday morning. We haven't found any underlying issues with the service itself but believe the errors were caused by a network issue.

*Tags: Errors Debugging*

---

**ChrisM** - *15:59:24*

Wonder if anyone can help, just started to play with streaming, ive started by using the example '[https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py|examplestreamingerrhandling.py](https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py|examplestreamingerrhandling.py)'  running it locally or on a linode instance it seems to hang/timeout after initial connecting/subscribing correctly

*Tags: General Technical*

---

**ChrisM** - *16:00:36*

ive previously built applications using the rest betfair api, so not coming in completely green

*Tags: General Technical*

---

**liam** - *16:03:35*

thats your problem, all delayed key use is banned on here, send me a message with your live key and i can get it activated if not already

*Tags: Deployment*

---

**ChrisM** - *16:06:05*

ah ok, the live key is the one you pay the £299 fee for? which is not a problem i was just hoping to get setup in testing first

*Tags: Getting Started, Deployment*

---

## 2023-12-10

**Pietro Perrone** - *16:03:10*

Hello all! I am new to the channel, and I want to first thank all of you for putting up such a great collaborative community.

I am looking to download historical data odds using the historical data methods provided by betfairlightweight.

2 questions on this:

• I need to retrieve all the odds for tennis matches from 2015. Do you think it is better to use `get_my_data` or `create_historical_stream` ?

• I really need to differentiate between pre-match and in-play odds. Is there an easy way of doing so?

Thanks in advance!

*Tags: Getting Started, Data Quality*

---

## 2023-12-12

**JazzMan** - *00:15:18*

It's not liquidity, if anything there seems to be less being matched these day. I have an old database from 2015, which I have just looked at. Its the fact that my strategies from a few years ago no longer work, and it's always been like that. The prices just don't move the same way. The prices get stuck at 6.00, and rotate around 5.9 6.0 6.2, in the past there was more movement . My personal view is that strategies that worked a few years ago don't now.

*Tags: General Technical*

---

**Mo** - *09:08:40*

My bread and butter tennis strategy has been working for 8 years

*Tags: Strategies*

---

## 2023-12-14

**Outthebox sports trading** - *02:43:20*

What’s the strategy? Not had much success on the tennis

*Tags: Strategies*

---

## 2023-12-22

**NAS** - *00:18:40*

Flumine defaults to GBP, is there a way to change this when setting up the clients? Also, where does the conversion to my local account currency happen if sending orders with flumine?



Edit: seems like my personal orders are denominated and executed in local currency, but the data from the streams shown in GBP. currently storing and using the currency rate in flumine context but if there's a better way to automatically convert stream data into my currency i'd be happy to hear about it. Thanks! :)

*Tags: General Technical*

---

**Mo** - *08:16:07*

[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-CurrencySupport](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-CurrencySupport)



Not sure if there is any automatic support in flumine for carrying out the conversion

*Tags: General Technical*

---

**Peter** - *12:31:03*

Betfairlightweight has a list_currency_rates method, so that would be available to the Betfair client that you pass into Flumine, but Flumine doesn't attempt to make any use of it. You'd need to implement according to your use case.

*Tags: General Technical*

---

## 2023-12-27

**Alejandro Pablos Sánchez** - *12:27:24*

Hi, is anybody facing API Error issues today? The place_order method is not working for me today :smiling_face_with_tear:

*Tags: Errors Debugging*

---

**Mo** - *13:45:13*

What error are you getting?

*Tags: Errors Debugging*

---

**Alejandro Pablos Sánchez** - *13:45:42*

It's already solved, thanks ! [@UBS7QANF3](@UBS7QANF3)

*Tags: General Technical*

---

## 2024-01-04

**NAS** - *15:20:55*

when i launch my flumine instance, it runs correctly for a while (30-60 mins) but then starts throwing invalid session errors when performing account operations



flumine.clients.betfairclient - ERROR - BetfairClient `account.get_account_funds` error

flumine.clients.betfairclient - ERROR - BetfairClient `account.get_account_details` error



Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}



guess there's a problem in the keep-alive updating?

*Tags: Errors Debugging, Deployment*

---

## 2024-01-05

**Jimmy** - *09:43:13*

Daft question alert: What’s the most Flumine-y way of checking for unmatched orders in check_market_book?

*Tags: General Technical*

---

**NAS** - *17:35:11*

Yep, seems to have solved it, thanks

*Tags: General Technical*

---

**Mo** - *17:36:47*

[@UNW8Q88EL](@UNW8Q88EL) can you clarify what the session timeout is for Sweden as this behaviour would seem to contradict the documentation

*Tags: General Technical*

---

**birchy** - *21:47:44*

[@U02CYRC190R](@U02CYRC190R) there are also a few functions in `market.blotter` that I use... [https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/markets/blotter.py#L74|https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/markets/blotter.py#L74](https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/markets/blotter.py#L74|https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/markets/blotter.py#L74)

*Tags: General Technical*

---

## 2024-01-08

**George** - *09:50:52*

I'm getting 'TIMEOUT_ERROR' this morning - is it me or is there a BF issue?

*Tags: Errors Debugging*

---

**George** - *10:01:01*

Seems like they might have fixed it

*Tags: Errors Debugging*

---

## 2024-01-11

**liam** - *17:49:09*

User error?

*Tags: Errors Debugging*

---

## 2024-01-14

**foxwood** - *13:37:04*

Call strategy.placeOpenBets() once from process_market_book() - example to lay 10p at current lay price on every runner - not Asian since hcap forced



    `def placeOpenBets(self, market, market_book):`

        `for r in range(len(market_book.runners)) :`

            `if market_book.runners[r].status != "ACTIVE": continue`

            `trade = Trade(market.market_book.market_id, market_book.runners[r].selection_id, 0, self, )`

            `o = BetfairOrder( trade=trade, side="LAY",`

                                `order_type=LimitOrder(price=1.10, size=1.00),`

                                `notes=OrderedDict(`

                                    `required_size=0.10,`

                                    `required_price=market_book.runners[r].ex.available_to_lay[0]["price"],`

                                `),`

                            `)`

            `market.place_order(o)`



    `def process_orders(self, market, orders):`

        `for order in orders:`

            `if order.trade.strategy != self : continue`

            `if order.status != OrderStatus.EXECUTABLE: continue`

            `# completed order - change stake or odds if needed`

            `if "required_size" in order.notes:`

                `if order.notes["required_size"] != 0.00:`

                    `size_reduction = 0.90`

                    `market.cancel_order(order, size_reduction=size_reduction)`

                    `order.notes["required_size"] = 0.00`

                `elif order.notes["required_price"] != 0.00:`

                    `# ensure size reduction has gone through - if not leave it at £1 @ 1.10`

                    `if order.size_cancelled == 0.90:`

                        `market.replace_order(order, new_price=order.notes["required_price"])`

                        `order.notes["required_price"] = 0.00`

*Tags: Strategies*

---

**Derek C** - *15:01:05*

Does anybody else experience this error with Flumine 2.5.6?



>  line 182, in _process_sports_data

>     event_id = sports_data.event_id

> AttributeError: 'Race' object has no attribute 'event_id'

It seems a genuine error when I inspect in the debugger - there is no 'event_id' in the Race object. If I switch to Flumine 2.5.4 then the error doesn't occur because the code references market_id instead of event_id in 2.5.4.



My sample code to reproduce the error:



```

class ExampleStrategy(BaseStrategy):

    def process_sports_data(self, market, sports_data) -> None:

        # called on each update from sports-data-stream

        print('***',market, sports_data)



client = clients.BetfairClient(trading)



framework = Flumine(client)



strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["7"], market_types=["WIN"],

            country_codes=['GB' ],

    ),

    sports_data_filter=['raceSubscription'],  

)

framework.add_strategy(strategy)



framework.run()```

*Tags: Errors Debugging, Strategies*

---

**Mo** - *15:08:22*

Surely also depends on what version of bflw you’re running?

*Tags: General Technical*

---

**Derek C** - *15:10:05*

2.19.1

But the way I created the test was to just pip install flumine. I didn't specifically install the dependencies

*Tags: Getting Started*

---

**Derek C** - *15:14:18*

The reason I am at this point is because I do not see any TPD data via Flumine, only via non-Flu mine strategies and I'm trying to track down the root cause of that.

*Tags: General Technical*

---

**Derek C** - *15:31:12*

Possibly related issues: I do not see TPD data coming through Flumine from version 2.3.0 onwards. I've been upgrading from old versions so could have missed some steps.



> pip3 install flumine==2.2.7

I see output from "process_sports_data"



> pip3 install flumine==2.3  # or 2.5.4, 2.5.6

no output from following example:



```

class ExampleStrategy(BaseStrategy):

    def process_sports_data(self, market, sports_data) -> None:

        # called on each update from sports-data-stream

        print('***',market, sports_data)



client = clients.BetfairClient(trading)



framework = Flumine(client)



strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["7"], market_types=["WIN"],

            country_codes=['GB' ],

    ),

    sports_data_filter=['raceSubscription'],  "raceSubscription"

)

framework.add_strategy(strategy)



framework.run()```



*Tags: Getting Started, Strategies*

---

## 2024-01-15

**liam** - *08:45:29*

Fixed in 2.5.7

*Tags: Errors Debugging*

---

**foxwood** - *10:05:02*

doh ! wood for trees - thank you. Think it is the issue since Trade will not have the order in it's list.

At least my normal stuff does it properly. I was trying to work out a way of placing multiple bets in a single call to BF - the API supports list of orders it seems but can't see a way of doing that in flumine since the Trade is tied to a single selection.

Arose trying to save processing time and get the bets back asap after strategy requirement seen.

*Tags: Strategies*

---

**liam** - *10:06:17*

When it comes to placing orders, flumine is smart, it uses the transaction class, see the [https://betcode-org.github.io/flumine/markets/#transaction|docs](https://betcode-org.github.io/flumine/markets/#transaction|docs) on how you can send all orders at once

*Tags: General Technical*

---

**liam** - *10:36:00*

Yes but do it like this, use `get_price` as it might be None/empty list and your code will error and you can loop `runners` which makes things 10x easier to read



```        with market.transaction() as t:

            for runner in market_book.runners:

                if runner.status != "ACTIVE":

                    continue

                lay_price = get_price(runner.ex.available_to_lay, 0)

                trade = Trade(

                    market_book.market_id, 

                    runner.selection_id, 

                    0, 

                    self

                )

                order = trade.create_order(

                    side="LAY",

                    order_type=LimitOrder(price=1.10, size=1.00),

                    notes=OrderedDict(

                        required_size=0.10,

                        required_price=lay_price,

                    ),

                )

                t.place_order(order)```

*Tags: Errors Debugging*

---

**Gooat** - *16:56:20*

Trying to get Flumine to handle/see orders on the stream not placed by it and with no customerStrategyRefs on those bets. If I subscribe to the orderstream without a ref then add the bets to blotter like the middlewear example will anything catch on fire?

*Tags: Strategies*

---

**foxwood** - *18:11:44*

Funnily enough just noticed that today - bets placed from another system show up in the log as not being in the blotter. Looking at the code I think flumine then tries to recreate the order and finally gives up when it can't find the strategy. So, if you know what the alien bets are you should be able to plug in and add them to your strategy as if you made them ? Top level function `create_order_from_current()` in flumine.order.py  tries to recreate - that's as far as I got - may help,

*Tags: Strategies*

---

**Gooat** - *19:48:23*

Sweet. I need to learn how to monkey patch now. (orderstream, customer_strategy_refs=[] and current_order.customer_order_ref = blah if "")

*Tags: Strategies*

---

## 2024-01-16

**Derek C** - *18:05:40*

just to 'fess up here in case it helps somebody else. When upgrading Flumine versions I had missed the introduction of 'check_sports_data' defaulting to return 'False' - without creating a new method that returns 'True' no TPD data gets through to the process method :grimacing:

*Tags: General Technical*

---

## 2024-01-20

**NAS** - *14:15:50*

Hi



I have a 23hr/day login limit on my account, have been in touch with customer service and they claim it's impossible to remove... Seems weird that everyone in here should be capped at 23 hours of trading/day, if someone knows how to get around it please let me know! :slightly_smiling_face:

*Tags: Strategies*

---

## 2024-01-24

**Creepto** - *20:42:20*

Hello, 



I am trying to stream historical data using the python client betfairlightweight, with create_historical_generator_stream(), as in the examples. But I got the error: 'charmap' codec can't decide byte 0x88 in position xy: character maps to &lt;undefined&gt;.

However, when I just open the file with bz2 lib I can read the file. What am I missing?

*Tags: Data Quality, Errors Debugging*

---

**liam** - *21:32:14*

Bflw won’t uncompressed the file, use smart open 

*Tags: General Technical*

---

## 2024-01-25

**Lee** - *20:22:31*

what flumine version are you running?

*Tags: General Technical*

---

**Ralegh** - *20:28:04*

2.5.0, I’ll upgrade and see if that fixes tomorrow

*Tags: Errors Debugging*

---

**Lee** - *20:28:58*

Yep upgrade, that’s fixed in 2.5.4

*Tags: Errors Debugging*

---

## 2024-01-27

**Adrian** - *04:27:48*

I am getting a strange error that is preventing me from logging in. It's "Attribute error: module 'ssl' has no attribute 'wrap_socket'"

Any ideas what's causing this? I'm using python 3.12

There is also "INVALID_SESSION_INFORMATION" error that comes before it but I don't know which one is causing which

*Tags: Errors Debugging*

---

**birchy** - *11:29:10*

If you open a python console and enter `from ssl import wrap_socket` do you get the same error? Sounds like your ssl library is somehow different. Maybe you've inadvertently overridden it with a silly mistake like `ssl = 1234`

*Tags: Errors Debugging*

---

## 2024-01-28

**Adrian** - *03:42:14*

Thanks birchy, i'll try this tonight when i get home. It's just a fresh Linux install so I haven't changed anything other than installing the default python that comes with miniconda

*Tags: Getting Started*

---

## 2024-02-01

**Brian Morton** - *12:51:43*

Guy's I am not new to trading but I am new to Flumine and I am now starting to follow the instructions in 'How To Automate 1' in Betfair

*Tags: Getting Started, Strategies*

---

**Brian Morton** - *12:53:59*

Guy's I am not new to trading but I am new to Flumine and I am now starting to follow the instructions in 'How To Automate 1' in Betfair



What is your take on the paragraph



You can use the Flumine package with or without certificates. There have been quite a lot of discussions of how useful the security certificates are on the [https://betcode-org.slack.com/ssb/redirect|Betcode (formerly Betfairlightweight) slack group](https://betcode-org.slack.com/ssb/redirect|Betcode (formerly Betfairlightweight) slack group), but the general consensus is that its not too useful. Considering it is an extreme hassle to create the certificates and there is no really added benefit I prefer to log in without the certificates.



Do you guys use certificates or not.

*Tags: Getting Started, Strategies*

---

**D C** - *13:14:16*

It's odd because I've never worked out how to login without a certificate (other than manually to the website of course)

*Tags: General Technical*

---

**PeterLe** - *14:37:34*

I use certificate's too, although it must have been pure luck getting it working :grinning:

from memory I think I used the instructions here ; [http://www.betfairprotrader.co.uk/2015/08/creating-digital-certificate-for-betfair.html](http://www.betfairprotrader.co.uk/2015/08/creating-digital-certificate-for-betfair.html)



you will need to add something like this in your code too :

```trading = betfairlightweight.APIClient(myacc, mypass, app_key, certs=r"C:\certs")```



*Tags: Performance, Strategies*

---

**D C** - *18:13:31*

No I'm not overly concerned. When I say "plain text" I mean spread across multiple string literals that get contatenated at when the login stuff is called. Probably makes it a bit harder anyway but you have to draw the line and accept defeat at some point. If your server is compromised then you've got a problems regardless.

*Tags: Deployment*

---

## 2024-02-02

**PeterLe** - *13:37:10*

Anyone seeing any issues this afternoon like this ;

AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)", "client": "APIClient", "trading_function": "account.get_account_details", "response": "AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)"}



Thanks



edit : Seems fine again now :+1:

*Tags: Errors Debugging, Strategies*

---

## 2024-02-04

**Jeff Waters** - *18:58:17*

I've been experimenting with the Betfair Lightweight sample code at [https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py](https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py).



I've tried changing the event type id field from "9" to "4339" like so ("4339" being the event type id for greyhounds - [https://betfair-datascientists.github.io/api/apiPythontutorial/](https://betfair-datascientists.github.io/api/apiPythontutorial/)):



```market_filter = streaming_market_filter(

    event_type_ids=["4339"], country_codes=["GB"], market_types=["WIN"]

)```

However, the app pauses for about 30 seconds, and I then get this error message:



betfairlightweight.exceptions.ListenerError: connection_id: [deleted], data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"deleted"}



Where am I going wrong, please?

*Tags: Errors Debugging*

---

**Jeff Waters** - *19:42:20*

Hi Peter



Thanks for taking a look.



I'm not using logging. This is the stack trace, though:



*Exception in thread Thread-1:*

*Traceback (most recent call last):*

  *File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\threading.py", line 973, in _bootstrap_inner*

    *self.run()*

  *File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\threading.py", line 910, in run*

    *self._target(*self._args, **self._kwargs)*

  *File "C:\Users\User\Documents\golive\venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 60, in start*

    *self._read_loop()*

  *File "C:\Users\User\Documents\golive\venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 232, in _read_loop*

    *self._data(received_data)*

  *File "C:\Users\User\Documents\golive\venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 273, in _data*

    *raise ListenerError(self.listener.connection_id, received_data)*



This is my full code:



```import betfairlightweight

import queue

import threading

import json



from betfairlightweight.filters import streaming_market_filter, streaming_market_data_filter

from log_in import log_in_and_get_API_client_object



# [https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py](https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py)



trading = log_in_and_get_API_client_object()

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

    event_type_ids=["4339"], country_codes=["GB"], market_types=["WIN"]

)

market_data_filter = streaming_market_data_filter(

    fields=["EX_BEST_OFFERS", "EX_MARKET_DEF"], ladder_levels=3

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)

t.start()



"""

Data can also be accessed by using the snap function in the listener, e.g:



    market_books = listener.snap(

        market_ids=[1.12345323]

    )



Errors need to be caught at stream.start, resubscribe can then be used to

prevent full image being sent, e.g:



    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=1000,  # send update every 1000ms

        initial_clk=listener.initial_clk,

        clk=listener.clk,

    )



The streaming unique id is returned in the market book which allows multiple

streams to be differentiated if multiple streams feed into the same queue.

"""



# check for updates in output queue

while True:

    market_books = output_queue.get()

    print(market_books)



    for market_book in market_books:

        print(

            json.dumps(market_book.streaming_update),  # json update received

        )```

If I change the event type id back from "4339" to "7", the app works fine.

*Tags: Errors Debugging, Deployment, Strategies*

---

**Jeff Waters** - *20:15:50*

It's now working, with the exact same code as I posted above! Bizarre. I can only assume it was a server side issue that's now been resolved? Either that or there was something stuck in the cache locally that was causing issues?



Anyway, thanks guys.

*Tags: Deployment*

---

**Jeff Waters** - *20:32:45*

Fair point, Peter, and working out how to do logging that is more useful than the basic  logging.DEBUG("message") stuff is on my to do list.



My situation at the moment is that I have a system that I've back tested, which I'd like to try applying on automated betting on. However, before I can do that, I need to properly investigate how this stuff works, and then build a bet placement app that also keeps track of how my bets fare. At the moment, I'm just at the research/exploration phase (which I'm finding really interesting, by the way! :slightly_smiling_face: ).



Thanks.

*Tags: Errors Debugging, Strategies*

---

## 2024-02-05

**Derek C** - *08:34:27*

Are you not using Flumine? It might save you a lot of time if you are planning to build your own bet placement app.

*Tags: General Technical*

---

**Jeff Waters** - *08:43:04*

Hi Derek



I've been investigating what Flumine and what Better Lightweight can do, but for the bet placement at least, I think I will use Flumine. I've used it for back testing, and found it really useful. I think it will be fairly straightforward to adapt my back testing code to implement the system I want to go live with.



Thanks

*Tags: Deployment*

---

**PeterLe** - *09:18:05*

Jeff thats the beauty of Flumine. You can create a strategy, backtest it and then just uncomment a few lines and you can then run it live. Testing to live in 10 seconds

Liam has wriiten the code for everything you need to do. There no point writing your own.

Ill send you a couple of files to get you started

*Tags: Deployment, Strategies*

---

## 2024-02-13

**Derek C** - *21:33:20*

Am I right in thinking that the flumine historical stream (RaceStream) doesn't like races that started early? For example, if the race id ends in, ".1924" then these hours and minutes will be taken as the race_cache.start_time. If, however, the race started early then the updates will have a 'pt' publish time before this and be ignored. I'm trying to track down an elusive issue in my simulation setup. In my example, the updates in the historical stream file all have a 'pt' value earlier than the expected start time embedded in the race id and this seems to cause the whole file to be ignored by FlumineRaceStream._process()

*Tags: Getting Started*

---

## 2024-02-14

**liam** - *08:46:15*

Oversight by myself on an optimisation to reduce func calls, fix [https://github.com/betcode-org/flumine/pull/737|here](https://github.com/betcode-org/flumine/pull/737|here)

*Tags: Errors Debugging*

---

**Peter** - *12:48:58*

Look at the [https://github.com/betcode-org/flumine/blob/master/examples/strategies/pricerecorder.py|price recorder](https://github.com/betcode-org/flumine/blob/master/examples/strategies/pricerecorder.py|price recorder) example strategy and adapt it to record the specific field that you want.

*Tags: Strategies*

---

**Al** - *13:01:08*

I didn't quite understand how this solves my problem. I already have the data, but I need to use a ready-made csv with the above fields, not the files that are in the tests/resources directory/

*Tags: General Technical*

---

**Al** - *14:55:30*

and if you add a custom function that will convert the csv file to json format, which is the case in the examples for the simulated client, the main data of which will be filled in, will this solve my problem?

*Tags: General Technical*

---

**liam** - *15:01:36*

You don't have the data, its crap, why do you have this and not streaming data?

*Tags: General Technical*

---

## 2024-02-15

**Al** - *09:35:14*

Hi. I have a question. Is it possible to add the same strategy to flumine several times, only in one case side= back, in the second = back. and maybe there is an example for this. or you need to create 2 strategies with different sides separately. thanks

*Tags: Strategies*

---

**liam** - *09:38:18*

Yeah thats fine, just give them different names to make things easier to untangle



```framework.add_strategy(

    MakeMoney(name="a", context={"side": "BACK"})

)

framework.add_strategy(

    MakeMoney(name="b", context={"side": "LAY"})

)```

*Tags: Strategies*

---

**Al** - *14:05:00*

Please tell me what condition should be prescribed in the strategy so that when the max_trade_count = 1 parameter is set, the strategy stops and does not continue to try to create new orders and does not issue "message": "Order status update: Violation", "violation_msg": "strategy.validate_order failed: trade_count (1) &gt;= max_trade_count (1)". Thanks

*Tags: Errors Debugging, Strategies*

---

**liam** - *14:06:44*

Copy the [https://github.com/betcode-org/flumine/blob/d9b729d79af68042e859511be968bf649a938dc8/examples/strategies/lowestlayer.py#L46|example](https://github.com/betcode-org/flumine/blob/d9b729d79af68042e859511be968bf649a938dc8/examples/strategies/lowestlayer.py#L46|example) to handle it but change to `trade_count`

*Tags: General Technical*

---

**Unknown** - *20:54:43*

Hi



I'm trying to set up market recording. I copied and pasted the code from [https://github.com/betcode-org/flumine/blob/master/examples/strategies/marketrecorder.py](https://github.com/betcode-org/flumine/blob/master/examples/strategies/marketrecorder.py) into a module. I also created a strategy as shown in the example at [https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py](https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py) and added it to my framework. However, although a folder appears in the tmp directory I created, it's empty.



What am I doing wrong, please?



Thanks



Jeff

*Tags: Strategies*

---

**Jeff Waters** - *23:45:46*

Hi Derek



I literally copied all of the code in the page relating to the first link, and pasted it into its own module. I then imported that module into another module, and added the relevant code from the other page:



`strategy = MarketRecorder(`

    `name="WIN",`

    `market_filter=betfairlightweight.filters.streaming_market_filter(`

        `event_type_ids=["7"],`

        `country_codes=["GB", "IE"],`

        `market_types=["WIN"],`

    `),`

    `stream_class=DataStream,`

    `context={`

        `"local_dir": "/tmp",`

        `"force_update": False,`

        `"remove_file": True,`

        `"remove_gz_file": False,`

    `},`

`)`



`framework.add_strategy(strategy)`



`framework.run()`

*Tags: Strategies*

---

## 2024-02-16

**PeterLe** - *06:46:41*

Jeff, the consensus from the guys on here is to have a standalone recorder. This is one I use:

```import time

import logging

import betfairlightweight

from pythonjsonlogger import jsonlogger



from flumine import Flumine, clients

from flumine.streams.datastream import DataStream

from marketrecorder import MarketRecorder

# from flumine import MarketRecorder



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



myacc = str(input("uk horses please enter account name: "))

app_key = str(input("Please enter key: "))

mypass = str(input("Please enter Password and 2FA: "))

trading = betfairlightweight.APIClient(myacc,mypass, app_key, certs=r"/home/ubuntu/certs")



client = clients.BetfairClient(trading, order_stream=False)



framework = Flumine(client=client)



strategy = MarketRecorder(

    name="WIN",

    market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["GB", "IE"],

        market_types=["WIN"],

    ),

    stream_class=DataStream,

    context={

        "local_dir": "/home/ubuntu/flumine",

        "force_update": False,

        "remove_file": True,

    },

)



framework.add_strategy(strategy)



framework.run()```



*Tags: Strategies*

---

**Al** - *07:33:44*

Hi. What kind of reporting can I receive as a result of strategy execution? Where to look. I kind of found this. Is it possible to get something else from the simulation results? `for market in framework.markets:`

    print("Profit: {0:.2f}".format(sum([o.profit for o in market.blotter])))

    for order in market.blotter:

        print(

            order.selection_id,

            order.responses.date_time_placed,

            order.status,

            order.order_type.price,

            order.average_price_matched,

            order.size_matched,

            order.profit,

        )

*Tags: Strategies*

---

**liam** - *08:10:52*

Use loggingcontrol as per the [https://github.com/betcode-org/flumine/tree/master/examples/controls|examples](https://github.com/betcode-org/flumine/tree/master/examples/controls|examples)

*Tags: General Technical*

---

**liam** - *08:12:28*

Is it a valid order size? Logs will tell you or there are some helper [https://github.com/betcode-org/flumine/blob/d9b729d79af68042e859511be968bf649a938dc8/flumine/utils.py#L133|functions](https://github.com/betcode-org/flumine/blob/d9b729d79af68042e859511be968bf649a938dc8/flumine/utils.py#L133|functions)

*Tags: General Technical*

---

**Al** - *08:53:18*

live data

*Tags: Deployment*

---

**Al** - *08:58:12*

I am not being given historical data from betfair, but data recorded as a result of the stream. maybe I don't quite understand the question... this is basic data using best_of_book

*Tags: Data Quality*

---

**Al** - *09:08:04*

data from betfair live streaming that is recorded by other team members

*Tags: Deployment*

---

**Al** - *09:17:44*

the stream is recorded using the betfair parser, without using flumine, some data is missing, I do not know Win or place, market_id = 1.214016755, country = GB. That's all there is

*Tags: General Technical*

---

**Peter** - *10:50:30*

Hi [@U06KEECDXBJ](@U06KEECDXBJ) The exchange can be confused at first, but it's vitally important to get to understand it at a fairly deep level, as there are lots of very smart people, including in this Slack, waiting to take your money if you get it wrong.



If you want to back at 280, you're asking somebody to accept a lay that would cost them 280 - 1 = 279 per unit if they get it wrong. If the best back price is 1.1, then the layer willing to take the biggest risk is only prepared to risk 1.1 - 1 = 0.1 unit. The gap between 0.1 and 279 is sooo big, that it's not surprising that the bet is not matched.



Conversely if you try to lay at 280, when the best lay price is 560, that tells us that the least aggressive backer wants a potential profit of 559 before risking his hard earned points. But you're only offering him (or her) 279, so again no surprise that the bet isn't matched.



This is a simulation based on what actually happened, so the market never got to see your bets at 280. It is possible that had they been made in the live market, that would have caused the market to move and even get one or other of these bets matched, but realistically they're so far from the prices at that stage in the market's formation that it's very unlikely.



[@U4H19D1D2](@U4H19D1D2)’s cheat code allows you to test whether your strategy would be profitable if you were matched. It's useful for testing whether, over a large number of markets, your strategy is fundamentally profitable (or not). However, as you'll quickly find it's not that difficult to uncover strategies that would be profitable if somebody else were willing to take the bets, but a lot more difficult to find strategies with counter parties whose view of the market is sufficiently different to yours that you can get those matches.

*Tags: Deployment, Strategies*

---

**Jeff Waters** - *19:34:53*

I just tried to subscribe to all UK greyhound markets, and got told:



*{"asctime": "2024-02-16 19:32:46,796", "levelname": "ERROR", "message": "[MarketStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 230 markets whereas max allowed number was: 200"}*

*{"asctime": "2024-02-16 19:32:46,796", "levelname": "INFO", "message": "[MarketStream: 2001]: FAILURE (9 connections available)"}*



Is there any way around this, apart from asking Betfair to increase my subscription limit?



Thanks



Jeff

*Tags: Errors Debugging*

---

**Jeff Waters** - *19:47:08*

In terms of connections, how does that work? If I open another instance of Flumine and run the same strategy, does it split the markets between the connections?

*Tags: Strategies*

---

**Ralegh** - *19:56:47*

You can pass a list of streaming_market_filters with different criteria and I believe each of those gets mapped onto a separate connection. I think you should be able to share them but only within the same script and you’d use one instance of flumine with multiple strategies added.

*Tags: General Technical*

---

## 2024-02-21

**Al** - *13:49:48*

I want to see the price of the model (for example, the average) and be able to adjust it at the Simulated client level to see how the model behaves

*Tags: Strategies*

---

**Al** - *14:08:31*

if the framework allows you to add your own execution, then it doesn't matter what I want to do in my execution. I just don't quite understand how to make a child class from BaseExecution with its init, which accepts the price, look at self.flumine, which is in the parent class

*Tags: General Technical*

---

**liam** - *14:56:27*

Like you would with any python class, however I don't understand why / what you are doing as there is very likely a better option



```class MentalExecution(BetfairExecution):

    def __init__(self, flumine, max_workers: int = MAX_EXECUTION_WORKERS):

        super(MentalExecution, self).__init__(flumine, max_workers)

        self.custom_price = None





client = clients.SimulatedClient(simulated_full_match=True, execution_cls=MentalExecution)

client.execution.custom_price = 911```

*Tags: General Technical*

---

**liam** - *14:57:43*

Any price should be done in the strategy, the execution class is for different exchanges / http libraries it is *not* for changing the price

*Tags: Strategies*

---

**Unknown** - *15:17:14*

repeated code, received error. why?

*Tags: Errors Debugging*

---

**liam** - *15:18:26*

```framework = FlumineSimulation()



client = clients.SimulatedClient(simulated_full_match=True, execution_cls=MentalExecution)

framework.add_client(client)



client.execution.custom_price = 911```

*Tags: General Technical*

---

**liam** - *15:19:40*

I imagine you will want to inherit `SimulatedExecution` instead however just stop, this isn't what you want to do so I am not going to help any further

*Tags: General Technical*

---

## 2024-02-22

**liam** - *12:57:28*

Where is the strategy code that uses the context?



`self.context["price"]`

*Tags: Strategies*

---

**Al** - *13:03:25*

class ExampleStrategy(BaseStrategy):



    def tuning_price(self, runner, ret_model_price):

        if strategy.context['price'] == "price1":

            runner.ex.target_price = ret_model_price

        elif strategy.context['price'] == "price2":

            runner.ex.target_price = get_nearest_price(ret_model_price * 1.5)

        elif strategy.context['price'] == "price3":

            runner.ex.target_price = get_nearest_price(ret_model_price * 0.5)

        elif strategy.context['price'] == "price4":

            runner.ex.target_price = get_nearest_price(ret_model_price * 0.9)

*Tags: Strategies*

---

**liam** - *13:04:10*

Open up your debugger and you would see this

*Tags: Errors Debugging*

---

**Al** - *13:06:20*

def process_market_book(self, market, market_book):

        # get context

        for runner in market_book.runners:

                    if runner.selection_id == 19221310:

                        if self.get_runner_context(market.market_id,runner.selection_id).trade_count == 0:

                            trade = Trade(

                                            market_id=market_book.market_id,

                                            selection_id=runner.selection_id,

                                            handicap=runner.handicap,

                                            strategy=self,

                                        )



                            order = trade.create_order(

                                            side="BACK",

                                            order_type=LimitOrder(

                                                price=runner.ex.target_price,

                                                size=2,

                                                persistence_type="PERSIST"

                                            ),

                                        )

                            market.place_order(order)

*Tags: Strategies*

---

**liam** - *13:09:49*

No don't put things in `runner.ex` that is not to be touched, keep things simple:



```    def process_market_book(self, market, market_book):

        for runner in market_book.runners:

            if runner.selection_id == 19221310:

                if self.get_runner_context(market.market_id, runner.selection_id).trade_count == 0:



                    price = self.get_price(ret_model_price)



                    trade = Trade(

                        market_id=market_book.market_id,

                        selection_id=runner.selection_id,

                        handicap=runner.handicap,

                        strategy=self,

                    )

                    order = trade.create_order(

                        side="BACK",

                        order_type=LimitOrder(

                            price=price,

                            size=2,

                            persistence_type="PERSIST"

                        ),

                    )

                    market.place_order(order)



    def get_price(self, ret_model_price):

        price = self.context["price"]

        if price == "price1":

            return ret_model_price

        elif price == "price2":

            return get_nearest_price(ret_model_price * 1.5)

        elif price == "price3":

            return get_nearest_price(ret_model_price * 0.5)

        elif price == "price4":

            return get_nearest_price(ret_model_price * 0.9)```

*Tags: Strategies*

---

## 2024-02-23

**Pietro Perrone** - *23:16:04*

Hello all, I am trying to analyse odd movement (under/over) over time in the main European league’s football games.

I managed to run a script that produced many bz2 files corresponding to the games of Jan 2024.

Does anyone have experience on how to then open/clean/analyse the odds in Python?

I am only working with over/under 2.5 right now!

Thanks in advance

*Tags: General Technical*

---

**Pietro Perrone** - *23:31:57*

Yes I would like to extract the 2 teams name and then create a pandas dataframe with 3 columns representing the bet (so under or over), the volume and the price

*Tags: Feature Engineering*

---

## 2024-02-24

**Pietro Perrone** - *20:00:26*

I managed guys, the only thing I need it was betfairlightweight/endpoints/historic.py

*Tags: General Technical*

---

## 2024-02-25

**foxwood** - *19:47:52*

Probably doing something stupid but I'm getting an exception `Execution unknown error` thrown live (ok on backtest) using `market.replace_order()` called from within override of `stratBase.process_orders()` From the log the exception is thrown because the dictionary item `new_price` is missing from `update_data` although generated solely by `order.replace()` as part of the normal flow.

The scenario is playing with sub £1 bets by laying at very low odds, changing the size (works ok every time) and then replacing the order with a new price - which fails on about 2% of bets - I have a workaround that ensures the size/price combo doesn't hit `INVALID_PROFIT_RATIO` error.

All seems to happen on different thread - sample stack trace below. Can't reproduce at will. Feels like could possibly be python assign/copy issue around the "lost" dictionary item. Any clues / ideas welcome



`{"asctime": "2024-02-25 18:26:59,554", "levelname": "CRITICAL", "message": "Execution unknown error", "exc_info": "Traceback (most recent call last):`

  `File \"\\flumine\\execution\\betfairexecution.py\", line 251, in _execution_helper  response = trading_function(order_package, http_session)`

  `File \"\\flumine\\execution\\betfairexecution.py\", line 222, in replace  instructions=order_package.replace_instructions,`

  `File \"\\flumine\\order\\orderpackage.py\", line 164, in replace_instructions  return [`

  `File \"\\flumine\\order\\orderpackage.py\", line 165, in &lt;listcomp&gt;  order.create_replace_instruction()`

  `File \"\\flumine\\order\\order.py\", line 425, in create_replace_instruction  return {\"betId\": self.bet_id, \"newPrice\": self.update_data[\"new_price\"]}`

  `KeyError: 'new_price'", "trading_function": "replace", "exception": "'new_price'", "order_package": {"id": "4baba968-543d-49d4-84b4-a75355ab6a94", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x000001FE966E3EB0&gt;", "market_id": "1.225213820", "orders": ["139281784190412005"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "stratXX", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}`

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2024-02-26

**foxwood** - *09:50:46*

flumine or me ?

*Tags: General Technical*

---

**liam** - *09:51:04*

flumine, it will retry on a betfair error

*Tags: Errors Debugging*

---

**foxwood** - *09:51:36*

no sign of BF error in the logs run at DEBUG level

*Tags: Errors Debugging*

---

**foxwood** - *10:18:16*

ok - had 9 versions yesterday trying to work around it so clean start today running under debug with debug logging - more later

*Tags: Errors Debugging*

---

**Al** - *13:56:14*

Hi, I have a question. Should the profit that is calculated in the model from the order execution price be considered as net_pnl or gross?

*Tags: Strategies*

---

## 2024-02-27

**foxwood** - *12:27:12*

[@U4H19D1D2](@U4H19D1D2) workaround seems to have solved the issue so raised on github #742

*Tags: General Technical*

---

## 2024-02-28

**foxwood** - *11:47:43*

Anybody else seeing latency issues on market stream. I've been getting 0.5 seconds off almost continuously since I started about an hour ago. Have reset the clock so not that. BF issue, BF smacking my legs for some reason, poor connection (is HS fibre) AWS server seems ok recording - just local ?

*Tags: Performance, Deployment*

---

**foxwood** - *12:25:45*

Thanks [@U4H19D1D2](@U4H19D1D2) - cleared itself about 12:10 - log shows BF closed order stream and new one working properly now - market stream latency disappeared at same time but connection not remade weirdly.

*Tags: Performance*

---

## 2024-02-29

**Paul** - *13:37:46*

Only just saw this, but if it persists, don’t rule out your ISP messing about if it’s from a box at home. I used to work in ISPs and it was quite normal to “sin bin” customers (throttling, increasing latency, and so on) using more bandwidth than seemed reasonable based on contention needs. Normally triggered if they were torrenting, but could be an issue if you’re streaming a lot of market updates…

*Tags: Performance*

---

## 2024-03-02

**Jeff Waters** - *21:08:45*

Hi



I've just tried placing a bet with a persistence of 'PERSIST'. This was my code:



```trade = Trade(

    market_id=market_book.market_id,

    selection_id=runner.selection_id,

    handicap=runner.handicap,

    strategy=self,

    reset_seconds=3,

    place_reset_seconds=3

)

order = trade.create_order(

    side="BACK",

    order_type=LimitOrder(price=10, size=2.00, persistence_type="PERSIST"),

)

market.place_order(order)```

The JSON response suggested that the bet had been submitted successfully:



"order_type":{

      "order_type":"Limit",

      "price":10,

      "size":2.0,

      "persistence_type":"PERSIST",

      "time_in_force":null,

      "min_fill_size":null,

      "bet_target_type":null,

      "bet_target_size":null,

      "price_ladder_definition":"CLASSIC"

   },

   "info":{

      "side":"BACK",

      "size_matched":0.0,

      "size_remaining":2.0,

      "size_cancelled":0.0,

      "size_lapsed":0.0,

      "size_voided":0.0,

      "average_price_matched":0.0

   },

   "responses":{

      "date_time_placed":null,

      "elapsed_seconds_executable":null

   },

   "runner_status":null,

   "line_range_result":null,

   "status":"Pending",

   "status_log":"Pending",



I was told in a subsequent message that:



   "message":"1 order packages executed in transaction",



The selection was a favourite, so I wasn't expecting it to be matched before being converted to a BSP bet. However, my bet was not displaying as pending on the Betfair site, and it wasn't converted to BSP.



What was I doing wrong, please?

*Tags: Strategies*

---

**liam** - *21:23:35*

That isn’t a response, it’s a flumine log telling you the order is pending, where is the rest of the logs? 

*Tags: General Technical*

---

**Jeff Waters** - *21:51:20*

Hi Paul.



I've just tried it again, and it worked this time. No idea what went wrong last time. Thanks for your help. :slightly_smiling_face:



EDIT:



I've just realised that the reason it's working is because, following your post, I changed my persistence type:



```order = trade.create_order(

    side="BACK",

    order_type=LimitOrder(price=10, size=2.00, persistence_type="MARKET_ON_CLOSE"),

)```

Cheers

*Tags: General Technical*

---

## 2024-03-05

**RiskTaker5555** - *01:12:44*

Hello,

Just quick one:

How to end flumine framework ?

Once it started using framework.run(), and then framework.stop() it continue streaming data and not stopping.

*Tags: General Technical*

---

**river_shah** - *09:38:01*

Try this:

```from flumine.events.events import TerminationEvent

...

framework.handler_queue.put(TerminationEvent(framework))```

*Tags: General Technical*

---

## 2024-03-07

**foxwood** - *14:46:54*

Had an issue last week with a test strategy running live. It was going through the runners placing bets and then hit an outlier not allowed for that resulted in a divide by zero. Flumine neatly ate the exception and fed the next `mc` to the strategy which placed bets, hit the outlier again and crashed again - rinse and repeat.



The impact of this was to start draining the bank rather quickly - fortunately I was monitoring it but it still took a big bite. After investigating, I discovered that flumine ate non-flumine exceptions due to `config.raise_errors = False` Taken 2+ years to fall down that hole. I know all the guff about testing and defensive code etc but the reality is that most of us are in permanent beta and things slip through.



I think this should default to `True` which would stop any runaways like mine and, more importantly, would be the expected behaviour for people new to flumine. In the meantime all my flumine wrappers set it to `True` right at the start.

*Tags: Getting Started, Errors Debugging, Deployment, Strategies*

---

**foxwood** - *18:05:12*

You are right on exposure - the selection limit was too high. It would have stopped the bets eventually but I was testing and caught it manually before too much damage was done.

Even so, would have preferred that the program aborted rather than "ignore" a standard language exception.

I understand there are situations where the "ignore" approach is valid but that is not the default behaviour one would expect. I have it covered now but more a thought for the benefit/safety of new users.

*Tags: Errors Debugging*

---

**liam** - *18:07:30*

This sounds like user error regarding lack of controls 

*Tags: Errors Debugging*

---

**foxwood** - *23:41:28*

Certainly it is - as with any bug - not worried about that. Just found it unusual that a package would consume standard language exceptions so suggesting that a different safety default might be better and more in line with new user expectations.

*Tags: Errors Debugging*

---

## 2024-03-09

**liam** - *09:42:58*

I am willing to change it but it could work the other way where by erroring on an exception would result in the instance stopping completely and potentially leave unwanted exposure.



Understand your frustration but you removed all of the other controls which to me is the problem

*Tags: Errors Debugging*

---

**foxwood** - *12:20:41*

Yup it is a subjective decision since you can get caught both ways and could also win hugely in both ways. Just my take on what I expected. Prob best left as is to avoid upgrade issues with existing user base - maybe make the point in intro docs that system / python  exceptions are eaten by default but can be turned on if wanted.

*Tags: Errors Debugging*

---

## 2024-03-10

**Newbie99** - *14:11:21*

I just updated flumine and now I can't get it to start (looks like an issue with BFLW if I'm interpreting this correctly):



```  File "/home/ec2-user/trading/env/projects/startup.py", line 4, in &lt;module&gt;

    import betfairlightweight

  File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/__init__.py", line 3, in &lt;module&gt;

    from .apiclient import APIClient

  File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/apiclient.py", line 6, in &lt;module&gt;

    from . import endpoints

  File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/endpoints/__init__.py", line 10, in &lt;module&gt;

    from .streaming import Streaming

  File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/endpoints/streaming.py", line 2, in &lt;module&gt;

    from ..streaming import (

  File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/streaming/__init__.py", line 1, in &lt;module&gt;

    from .betfairstream import BetfairStream, HistoricalStream, HistoricalGeneratorStream

  File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 10, in &lt;module&gt;

    from .listener import BaseListener

  File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/streaming/listener.py", line 5, in &lt;module&gt;

    from .stream import BaseStream, CricketStream, MarketStream, OrderStream, RaceStream

  File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/streaming/stream.py", line 116

    if (cache := self._caches.get(market_id)) is not None and cache.active```

*Tags: Deployment, Strategies*

---

**liam** - *14:24:26*

Bflw and flumine versions?

*Tags: General Technical*

---

**PeterLe** - *14:37:39*

Python 3.7?  Do you not need to upgrade that first? (3.11 has some benefits as i recall)

*Tags: General Technical*

---

**Newbie99** - *15:38:34*

Okay (had to go for 3.9 as 3.11 wouldn't work for some reason), now oddly I get this (which I think some people mentioned before, but I am UK based):



```{"asctime": "2024-03-10 15:36:14,413", "levelname": "ERROR", "message": "OrderStream 1000 run error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flumine/streams/orderstream.py\", line 40, in run\n    self.stream_id = self._stream.subscribe_to_orders(\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 180, in subscribe_to_orders\n    self._send(message)\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 284, in _send\n    self.authenticate()\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 92, in authenticate\n    self._data(received_data)\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 273, in _data\n    raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 107-100324153614-1292830, data: {\"op\":\"status\",\"id\":1002,\"statusCode\":\"FAILURE\",\"errorCode\":\"INVALID_SESSION_INFORMATION\",\"errorMessage\":\"DSC-0036\",\"connectionClosed\":true,\"connectionId\":\"107-100324153614-1292830\"}\r\n"}```

*Tags: Errors Debugging, Deployment*

---

**Newbie99** - *15:45:07*

Interestingly changing my password resolved that

*Tags: General Technical*

---

## 2024-03-11

**Paul** - *14:13:48*

I think this default behaviour might be surprising behaviour to most. I think order controls in flumine in general can be a little surprising (selection exposure is not related to P&amp;L, only net exposure of trades on that selection, correct?), and in live trading these surprises could get expensive. I think defaults could defer to risk minimisation and that might make more sense: a dead bot that crashed out due to an exception can’t win big, but it also critically can’t lose big either. You can’t say that about a faulty live one…

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *14:15:37*

I agree there are some nuances but the controls are there to prevent issues, the simulation / paper trading is also there as a way to test (integration) but obviously there is a limit when it comes to betfair exceptions / edge cases etc.

*Tags: Errors Debugging, Strategies*

---

**foxwood** - *16:35:27*

I think [@U012XF5CNPN](@U012XF5CNPN) explains it well and encapsulates the reasons I have turned the "feature" off. There are a mass of issues that can cause Python to throw concrete excpetions and they are not just related to Python, flumine or flumine strategy code. They include exceptions from the operating system and bugs in any of the host of python packages used - all of which would be ignored by flumine. Imho the probability of an exception arising is real and I favour the dead bot theory rather than the faulty live one.

*Tags: Errors Debugging, Feature Engineering, Deployment, Strategies*

---

## 2024-03-25

**Chris Pudney** - *00:10:04*

I'm using the Flumine SimulatedClient to test a strategy on recorded data (Flumine MarketRecorder) and am experiencing odd behaviour. The strategy simply places a back bet at price P for amount W. Run the sim client on a recorded event and it is not matched. Repeat the simulation this time at a _higher_ price, e.g. 2P and it gets matched. No other change just the increase back price. Any suggestions?

*Tags: Strategies*

---

## 2024-03-26

**Mo** - *07:25:13*

I'm having trouble with flumine's patching of `datetime` when simulating; essentially I need to run a line of code with the patching undone. I think maybe this is possible using `SimulatedDateTime.real_time` as a context manager? Anyone got an example of this?

*Tags: General Technical*

---

**liam** - *08:16:09*

Missing docs on [https://github.com/betcode-org/flumine/issues/512|this](https://github.com/betcode-org/flumine/issues/512|this)



```with framework.simulated_datetime.real_time():

    print(datetime.datetime.utcnow())```

*Tags: General Technical*

---

**Mo** - *09:02:44*

Basic question but what's the canonical way of accessing framework from inside a strategy or should I be saving a reference myself in... `add()`?

*Tags: Strategies*

---

**liam** - *09:04:01*

I use `market.flumine` but this probably needs to be changed to have a solid reference available

*Tags: General Technical*

---

**liam** - *12:58:42*

its only in the simulation [https://github.com/betcode-org/flumine/blob/bfaa5def6dc66794f088d9e4fed539c3c3043926/flumine/simulation/simulation.py#L26|class](https://github.com/betcode-org/flumine/blob/bfaa5def6dc66794f088d9e4fed539c3c3043926/flumine/simulation/simulation.py#L26|class)

*Tags: General Technical*

---

**Derek C** - *17:45:58*

I put something into the strategy context to flag whether it's a simulation or not, but I wouldn't claim that's canonical.

*Tags: Strategies*

---

## 2024-03-28

**Adrian** - *08:35:23*

Does anyone know what this means?

```Traceback (most recent call last):

  File "/Users/adrian/Projects/betfair/valbet/simulation.py", line 137, in &lt;module&gt;

    framework.add_strategy(strategy)

  File "/Users/adrian/miniconda3/envs/flumine/lib/python3.11/site-packages/flumine/baseflumine.py", line 98, in add_strategy

    self.streams(strategy)  # create required streams

    ^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/adrian/miniconda3/envs/flumine/lib/python3.11/site-packages/flumine/streams/streams.py", line 44, in __call__

    market_definition = get_file_md(market)

                        ^^^^^^^^^^^^^^^^^^^

  File "/Users/adrian/miniconda3/envs/flumine/lib/python3.11/site-packages/flumine/utils.py", line 76, in get_file_md

    first_line = f.readline()

                 ^^^^^^^^^^^^

  File "&lt;frozen codecs&gt;", line 322, in decode

UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte```

*Tags: Errors Debugging, Strategies*

---

**Adrian** - *08:44:19*

``` File "&lt;frozen codecs&gt;", line 322, in decode

UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte```

*Tags: Errors Debugging*

---

**Adrian** - *08:44:29*

Same error different file

*Tags: Errors Debugging*

---

**Adrian** - *08:47:14*

MacOS Sonoma

Flumine is 2.5.3 (2023-11-06)

*Tags: General Technical*

---

**Adrian** - *08:49:04*

[https://stackoverflow.com/questions/38518023/unicodedecodeerror-utf8-codec-cant-decode-byte-0x80-in-position-3131-invali](https://stackoverflow.com/questions/38518023/unicodedecodeerror-utf8-codec-cant-decode-byte-0x80-in-position-3131-invali)

*Tags: Errors Debugging*

---

**Mo** - *12:41:45*

OK, this is what I've done if anyone is interested:



```cm = (

    market.flumine.simulated_datetime.real_time()

    if config.simulated

    else contextlib.nullcontext()

)

with cm:

    ...```

*Tags: General Technical*

---

## 2024-03-29

**Paul** - *09:08:11*

I'm trying to do something very basic with betfairlightweight's streaming (long story, I don't want flumine for this). Here is some of my code based on [https://github.com/betcode-org/betfair/blob/f730238df65a9e0f86f3fe9690bf5a7ecff77715/examples/examplestreaming.py|the streaming example](https://github.com/betcode-org/betfair/blob/f730238df65a9e0f86f3fe9690bf5a7ecff77715/examples/examplestreaming.py|the streaming example) in the repo:

```trading = betfairlightweight.APIClient([...])

trading.login()

output_queue = queue.Queue()

listener = betfairlightweight.StreamListener(output_queue = output_queue)

stream = trading.streaming.create_stream(listener = listener)

market_filter = filters.streaming_market_filter(

    event_type_ids          = ["7"],

    market_types            = ["WIN"],

)

market_data_filter = filters.streaming_market_data_filter(

    fields=["EX_BEST_OFFERS, EX_MARKET_DEF"], ladder_levels=1

)



streaming_unique_id = stream.subscribe_to_markets(market_filter = market_filter, market_data_filter=market_data_filter, conflate_ms = 200)

t = threading.Thread(target=stream.start, daemon = True)

t.start()```

This ^^ is obviously not very exotic. I'm asking for single ladder level and the market definition for all WIN horse racing market, with conflation at 200ms. Straight out of the box...

```2024-03-29 08:52:35: [Register: 1]: marketSubscription

2024-03-29 08:52:35: [MarketStream: 1]: "MarketStream" created

2024-03-29 08:52:35: [MarketStream: 1]: connection_id: XXX-XXXXXXXXXXXXX-XXXXXXX

2024-03-29 08:52:35: [MarketStream: 2]: SUCCESS (7 connections available)

2024-03-29 08:52:35: [MarketStream: None]: INVALID_INPUT: Failed to un-marshall: '{"op": "marketSubscription", "id": 1, "marketFilter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"]}, "marketDataFilter": {"fields": ["EX_BEST_OFFERS, EX_MARKET_DEF"], "ladderLevels": 1}, "initialClk": null, "clk": null, "conflateMs": 200, "heartbeatMs": null, "segmentationEnabled": true}'```

My understanding is the `INVALID_INPUT` is from the API as per [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-ErrorCode|the docs](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-ErrorCode|the docs), but there isn't much else to go on. :thinking_face: Only thing obvious is that there are extra attrs in there that I didn't create that could be confusing it, but I expect that this is normal bflw behaviour.



While I go and get some caffeine to see if that helps, any Idiot Adjustments you can offer to my obviously feeble brain would be welcome. :slightly_smiling_face:

*Tags: Errors Debugging, Strategies*

---

**Leo** - *09:14:45*

Using a linter is helpful for stuff like that 

*Tags: General Technical*

---

**Ammar** - *13:05:07*

Hi guys - first time Flumine user, bit stuck, can’t see what I’ve done wrong :thread:

*Tags: Getting Started*

---

**Ammar** - *13:05:41*

this is my code:



```import os

from flumine import Flumine, BaseStrategy, clients

from flumine.order.trade import Trade

from flumine.order.order import LimitOrder, OrderStatus

from flumine.markets.market import Market

import betfairlightweight

from betfairlightweight.filters import streaming_market_filter, market_filter

from betfairlightweight.resources import MarketBook







trading = betfairlightweight.APIClient(

        username=os.environ["BETFAIR_USER"],

        password=os.environ["BETFAIR_PASS"],

        app_key=os.environ["BETFAIR_APP_KEY"],

        # certs="../certs"

    )

client = clients.BetfairClient(trading, paper_trade=True, interactive_login=True)

print(client.login())



framework = Flumine(client=client)



class ExampleStrategy(BaseStrategy):

    def start(self) -&gt; None:

        print("starting strategy 'ExampleStrategy'")



    def process_new_market(self, market: Market, market_book: MarketBook) -&gt; None:

        # called when a market is newly added to the framework

        print(market_book.market_definition)

        return super().process_new_market(market, market_book)



    def process_sports_data(

        self, market: Market, sports_data

    ) -&gt; None:

        # called on each update from sports-data-stream

        print(market, sports_data)



    def check_market_book(self, market: Market, market_book: MarketBook) -&gt; bool:

        # process_market_book only executed if this returns True

        print(market_book.market_definition)

        return True



    def process_market_book(self, market: Market, market_book: MarketBook) -&gt; None:

        # process marketBook object

        for runner in market_book.runners:

            print(runner.selection_id)



strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["1"],

        event_ids=["33115229"],

        # market_types=["WIN"],

        # country_codes=["GB"],

    )

)



framework.add_strategy(strategy)



framework.run()```

*Tags: Strategies*

---

**Ammar** - *13:06:59*

this is the console output (same when running via jupyter)



```&lt;bf&gt; ~/workspace/bf/lib *[master] » python -m bot2

/Users/bromar/.virtualenvs/bf/lib/python3.11/site-packages/pydantic/_internal/_config.py:322: UserWarning: Valid config keys have changed in V2:

* 'allow_population_by_field_name' has been renamed to 'populate_by_name'

* 'allow_mutation' has been removed

  warnings.warn(message, UserWarning)

None

starting strategy 'ExampleStrategy'```



and then nothing happens …

*Tags: Strategies*

---

**Lee** - *13:12:52*

add logging like in the [https://github.com/betcode-org/flumine/blob/master/examples/example.py#L14|examples](https://github.com/betcode-org/flumine/blob/master/examples/example.py#L14|examples), it will reveal the error

*Tags: Errors Debugging*

---

**Ammar** - *13:15:02*

that helps thanks!

*Tags: General Technical*

---

**Ammar** - *13:15:39*

does flumine work with the non-production app key?

*Tags: Deployment*

---

**Ammar** - *13:22:25*

or is it that streaming doesn’t work with the non-production api key?

*Tags: Deployment*

---

**Paul** - *13:29:00*

It was a valid string in a nest of valid objects, but the string wasn't valid API input. Without a Streaming API linter it wasn't going to be obvious. The thing I missed was the "," wasn't syntax highlighted as out of the string. Needed more cups of tea, clearly...

*Tags: General Technical*

---

**Ammar** - *13:29:05*

ahhh i have an old api key, so streaming access needs to be requested :shrug:

*Tags: General Technical*

---

**Peter** - *18:07:27*

Hopefully that clears things up for you. But if you need further help, please confirm that you are using a live key with streaming enabled. The delayed key is useful for nothing other than confirming that you can connect, but beyond that just causes problems.

*Tags: Deployment*

---

**Ammar** - *19:45:41*

yeh, noted - thanks.



literally my first attempt to use flumine today so hopefully will be ok once they enable streaming on the key :+1:

*Tags: General Technical*

---

## 2024-04-03

**Ammar** - *18:19:15*

Hi - me again — I’ve had confirmation my live key is streaming enabled, but I am getting this error back on the API when trying to run a simple strategy to just test the connection



`{"op":"status","id":2002,"statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"Unknown error authenticating","connectionClosed":true,"connectionId":"204-030424170351-166509"}`



I’ve raised a ticket to BDP, but wondering if anyone has any insight?

*Tags: Errors Debugging, Deployment, Strategies*

---

**Ammar** - *18:19:33*

```trading = betfairlightweight.APIClient(

        username=os.environ["BETFAIR_USER"],

        password=os.environ["BETFAIR_PASS"],

        app_key=os.environ["BETFAIR_APP_KEY"],

        certs="certs"

    )

client = clients.BetfairClient(trading, paper_trade=True)



framework = Flumine(client=client)



strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["1"],

        event_ids=["33135839"],

        # market_types=["WIN"],

        country_codes=["GB"],

    ),

    market_data_filter=streaming_market_data_filter(fields=["EX_ALL_OFFERS"]),

)



framework.add_strategy(strategy)



framework.run()```



*Tags: Strategies*

---

**Derek C** - *21:29:42*

you could try using an absolute file path for 'certs' to rule out that being the problem. For example, mine is:



``` '/home/ec2-user/certs'```



*Tags: Deployment*

---

**liam** - *21:37:42*

Code looks fine, assuming the logs have no errors regarding login it looks to be a betfair issue 

*Tags: Errors Debugging*

---

## 2024-04-04

**Ammar** - *09:20:07*

thanks both



yeh - confirmed as a betfair issue, they have fixed it now.



certs path was fine, but I have moved it to an absolute just to avoid that being an issue in future :+1:

*Tags: Errors Debugging*

---

## 2024-04-08

**Johnnb** - *08:25:55*

Hi everyone, I'm new here so might be missing something obvious. I'm running an s3marketrecorder in a lightsail instance. I started it yesterday morning and it still seems to be recording ok, but yesterday afternoon it stopped removing the txt and gz files after the markets closed. I got this error at about the time it stopped :

```{"asctime": "2024-04-07 15:06:28,467", "levelname": "ERROR", "message": "DataStream 2001 run error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/flumine/streams/datastream.py\", line 172, in run\n    self._stream.start()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 60, in start\n    self._read_loop()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 228, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 258, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 2002]: Connection closed by server"}```

The gz files are still being sent to the bucket and there's nothing else in the log apart from a few latency warnings

*Tags: Errors Debugging, Performance, Deployment*

---

**Johnnb** - *08:53:32*

That's the only log I've got sorry. I'm pretty new to linux and aws. I ran the code from the command line in a detached shell. Could that have caused the issue?

*Tags: Getting Started, Deployment*

---

**Johnnb** - *09:08:00*

This is the code that sets up the logging :

```logger = logging.getLogger()

custom_format = "%(asctime) %(levelname) %(message)"

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_file_name = 'multi_recorder.log'

log_handler_file = logging.FileHandler(log_file_name)

log_handler_file.setFormatter(formatter)

log_handler_file.setLevel(logging.WARNING)

logger.addHandler(log_handler_file)```

and this is the whole contents of the log file :

```{"asctime": "2024-04-07 12:06:30,768", "levelname": "WARNING", "message": "[FlumineStream: 4001]: Latency high: 0.5309743881225586"}

{"asctime": "2024-04-07 12:22:38,592", "levelname": "WARNING", "message": "[FlumineStream: 3001]: Latency high: 0.5384097099304199"}

{"asctime": "2024-04-07 12:38:51,513", "levelname": "WARNING", "message": "[FlumineStream: 3001]: Latency high: 0.618567705154419"}

{"asctime": "2024-04-07 13:22:52,309", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.7499873638153076"}

{"asctime": "2024-04-07 13:22:52,309", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.7483816146850586"}

{"asctime": "2024-04-07 13:22:52,309", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.6966326236724854"}

{"asctime": "2024-04-07 13:22:52,309", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5819070339202881"}

{"asctime": "2024-04-07 13:22:52,310", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5760924816131592"}

{"asctime": "2024-04-07 13:32:00,671", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.6668083667755127"}

{"asctime": "2024-04-07 14:21:34,134", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5454201698303223"}

{"asctime": "2024-04-07 14:21:34,135", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5427672863006592"}

{"asctime": "2024-04-07 14:29:44,438", "levelname": "WARNING", "message": "[FlumineStream: 3001]: Latency high: 0.5154736042022705"}

{"asctime": "2024-04-07 15:04:02,227", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.7697350978851318"}

{"asctime": "2024-04-07 15:04:02,229", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.669356107711792"}

{"asctime": "2024-04-07 15:04:02,229", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.5565588474273682"}

{"asctime": "2024-04-07 15:04:02,229", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.5507323741912842"}

{"asctime": "2024-04-07 15:04:02,229", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.452915906906128"}

{"asctime": "2024-04-07 15:04:02,230", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.3592793941497803"}

{"asctime": "2024-04-07 15:04:02,230", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.3554434776306152"}

{"asctime": "2024-04-07 15:04:02,230", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.2436447143554688"}

{"asctime": "2024-04-07 15:04:02,230", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.1467902660369873"}

{"asctime": "2024-04-07 15:04:02,231", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.142089605331421"}

{"asctime": "2024-04-07 15:04:02,231", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.0893239974975586"}

{"asctime": "2024-04-07 15:04:02,231", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.9845194816589355"}

{"asctime": "2024-04-07 15:04:02,231", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.8789470195770264"}

{"asctime": "2024-04-07 15:04:02,232", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.8751261234283447"}

{"asctime": "2024-04-07 15:04:02,232", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.7643704414367676"}

{"asctime": "2024-04-07 15:04:02,241", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.7685585021972656"}

{"asctime": "2024-04-07 15:04:02,242", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.6691379547119141"}

{"asctime": "2024-04-07 15:04:02,242", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.574512243270874"}

{"asctime": "2024-04-07 15:06:28,467", "levelname": "ERROR", "message": "DataStream 2001 run error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/flumine/streams/datastream.py\", line 172, in run\n    self._stream.start()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 60, in start\n    self._read_loop()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 228, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 258, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 2002]: Connection closed by server"}

{"asctime": "2024-04-07 15:15:02,315", "levelname": "WARNING", "message": "[FlumineStream: 3001]: Latency high: 0.6098229885101318"}```

*Tags: Errors Debugging, Performance, Deployment*

---

## 2024-04-11

**Matthew Lawrence** - *22:50:53*

Hi, trying to use flumine for the first time. I'm starting off by testing an adjusted version of betfair data scientists: how to automate 2. I can see from the logging that the bets are never being matched, although they are being requested at the correct price and size. Any help would be appreciated.

```trading = betfairlightweight.APIClient('...','...!',app_key='...')

client = clients.BetfairClient(trading, interactive_login=True)



# Login

client = clients.SimulatedClient()

framework = FlumineSimulation(client=client)



# Logging

logger = logging.getLogger()

custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # Set to logging.CRITICAL to speed up simulation



class BackFavStrategy(BaseStrategy):



    # Defines what happens when we start our strategy i.e. this method will run once when we first start running our strategy

    def start(self) -&gt; None:

        print("starting strategy 'BackFavStrategy'")



    def check_market_book(self, market: Market, market_book: MarketBook) -&gt; bool:

        # process_market_book only executed if this returns True

        if market_book.status != "CLOSED":

            return True



    def process_market_book(self, market: Market, market_book: MarketBook) -&gt; None:



        # Collect data on last price traded and the number of bets we have placed

        snapshot_last_price_traded = []

        snapshot_runner_context = []

        for runner in market_book.runners:

                snapshot_last_price_traded.append([runner.selection_id,runner.last_price_traded])

                # Get runner context for each runner

                runner_context = self.get_runner_context(

                    market.market_id, runner.selection_id, runner.handicap

                )

                snapshot_runner_context.append([runner_context.selection_id, runner_context.executable_orders, runner_context.live_trade_count, runner_context.trade_count])



        # Convert last price traded data to dataframe

        snapshot_last_price_traded = pd.DataFrame(snapshot_last_price_traded, columns=['selection_id','last_traded_price'])

        # Find the selection_id of the favourite

        snapshot_last_price_traded = snapshot_last_price_traded.sort_values(by = ['last_traded_price'])

        fav_selection_id = snapshot_last_price_traded['selection_id'].iloc[0]

        [http://logging.info|logging.info](http://logging.info|logging.info)(snapshot_last_price_traded) # logging



        # Convert data on number of bets we have placed to a dataframe

        snapshot_runner_context = pd.DataFrame(snapshot_runner_context, columns=['selection_id','executable_orders','live_trade_count','trade_count'])

        [http://logging.info|logging.info](http://logging.info|logging.info)(snapshot_runner_context) # logging



        for runner in market_book.runners:

            if runner.status == "ACTIVE" and market.seconds_to_start &lt; 60 and market_book.inplay == False and runner.selection_id == fav_selection_id and snapshot_runner_context.iloc[:,1:].sum().sum() == 0:

                trade = Trade(

                    market_id=market_book.market_id,

                    selection_id=runner.selection_id,

                    handicap=runner.handicap,

                    strategy=self,

                )

                order = trade.create_order(

                    side="BACK", order_type=LimitOrder(price=runner.last_price_traded, size=5)

                )

                market.place_order(order)



# Fields we want to log in our simulations

FIELDNAMES = [

    "bet_id",

    "strategy_name",

    "market_id",

    "selection_id",

    "trade_id",

    "date_time_placed",

    "price",

    "price_matched",

    "size",

    "size_matched",

    "profit",

    "side",

    "elapsed_seconds_executable",

    "order_status",

    "market_note",

    "trade_notes",

    "order_notes",

]



# Log results from simulation into csv file named sim_hta_2.csv

# If the csv file doesn't exist then it is created, otherwise we append results to the csv file

class BacktestLoggingControl(LoggingControl):

    NAME = "BACKTEST_LOGGING_CONTROL"



    def __init__(self, *args, **kwargs):

        super(BacktestLoggingControl, self).__init__(*args, **kwargs)

        self._setup()



    def _setup(self):

        if os.path.exists("sim_hta_2.csv"):

            [http://logging.info|logging.info](http://logging.info|logging.info)("Results file exists")

        else:

            with open("sim_hta_2.csv", "w") as m:

                csv_writer = csv.DictWriter(m, delimiter=",", fieldnames=FIELDNAMES)

                csv_writer.writeheader()



    def _process_cleared_orders_meta(self, event):

        orders = event.event

        with open("sim_hta_2.csv", "a") as m:

            for order in orders:

                if order.order_type.ORDER_TYPE == OrderTypes.LIMIT:

                    size = order.order_type.size

                else:

                    size = order.order_type.liability

                if order.order_type.ORDER_TYPE == OrderTypes.MARKET_ON_CLOSE:

                    price = None

                else:

                    price = order.order_type.price

                try:

                    order_data = {

                        "bet_id": order.bet_id,

                        "strategy_name": order.trade.strategy,

                        "market_id": order.market_id,

                        "selection_id": order.selection_id,

                        "trade_id": order.trade.id,

                        "date_time_placed": order.responses.date_time_placed,

                        "price": price,

                        "price_matched": order.average_price_matched,

                        "size": size,

                        "size_matched": order.size_matched,

                        "profit": order.simulated.profit,

                        "side": order.side,

                        "elapsed_seconds_executable": order.elapsed_seconds_executable,

                        "order_status": order.status.value,

                        "market_note": order.trade.market_notes,

                        "trade_notes": order.trade.notes_str,

                        "order_notes": order.notes_str,

                    }

                    csv_writer = csv.DictWriter(m, delimiter=",", fieldnames=FIELDNAMES)

                    csv_writer.writerow(order_data)

                except Exception as e:

                    logger.error(

                        "_process_cleared_orders_meta: %s" % e,

                        extra={"order": order, "error": e},

                    )



        [http://logger.info|logger.info](http://logger.info|logger.info)("Orders updated", extra={"order_count": len(orders)})



    def _process_cleared_markets(self, event):

        cleared_markets = event.event

        for cleared_market in cleared_markets.orders:

            [http://logger.info|logger.info](http://logger.info|logger.info)(

                "Cleared market",

                extra={

                    "market_id": cleared_market.market_id,

                    "bet_count": cleared_market.bet_count,

                    "profit": cleared_market.profit,

                    "commission": cleared_market.commission,

                },

            )



# Searches for all betfair data files within the folder sample_monthly_data_output

data_folder = r"C:\Users\matth\OneDrive\Documents\output_2022_02"

data_files = os.listdir(data_folder,)

data_files = [f'{data_folder}/{path}' for path in data_files]



# Set Flumine to simulation mode

client = clients.SimulatedClient()

framework = FlumineSimulation(client=client)



# Set parameters for our strategy

strategy = BackFavStrategy(

    # market_filter selects what portion of the historic data we simulate our strategy on

    # markets selects the list of betfair historic data files

    # market_types specifies the type of markets

    # listener_kwargs specifies the time period we simulate for each market

    market_filter={

        "markets": data_files,

        'market_types':['MATCH_ODDS', 'BOTH_TEAMS_TO_SCORE'],

        "listener_kwargs": {"inplay": False, "seconds_to_start": 80},

        },

    max_order_exposure=1000,

    max_selection_exposure=1000,

)

# Run our strategy on the simulated market

framework.add_strategy(strategy)

framework.add_logging_control(

    BacktestLoggingControl()

)

framework.run()```



*Tags: Getting Started, Errors Debugging, Feature Engineering, Performance, Deployment, Strategies*

---

## 2024-04-12

**Matthew Lawrence** - *09:11:52*

So i'd have to pay for all the data to simulate via flumine

*Tags: General Technical*

---

## 2024-04-16

**A** - *06:49:00*

If I’m receiving `[MarketStream: 2001]: Latency high: 0.516402006149292` warnings in my console, does that suggest my `process_market_book` function is inefficient? I don’t think it’s network latency. Might need to dig into python threading.

*Tags: Performance*

---

**Clive** - *07:35:10*

During a simulation, what would be the cause of messages such as:



`flumine.strategy.runnercontext - WARNING - Trade 'a5fb009a-fb61-11ee-bde9-eb5357042996' not present in RunnerContext live_trades on reset`

*Tags: Deployment, Strategies*

---

**Peter** - *09:22:20*

Yep. [https://betcode-org.github.io/flumine/performance/#cprofile](https://betcode-org.github.io/flumine/performance/#cprofile)

*Tags: Performance*

---

## 2024-04-17

**Ammar** - *09:22:50*

maybe a silly q (and hopefully I’ve not missed something in docs); but can you add strategies after flumine has started running, or does it have to be done before the `run()` call?



this works as usual:

```# main thread only

for s in strategies:

    framework.add_strategy(s)



framework.run()```



doesn’t seem to work - debug logging isn’t showing files being written to (but it’s just been a quick spike this morning)

```# run() on background thread

framework_thread = threading.Thread(

    name="Flumine Main",

    target=framework.run,

)

framework_thread.start()



# add strategy via main thread

for s in strategies:

    framework.add_strategy(s)```

(the strategies are just MarketRecorder from the examples with custom market filters based on relevant events, countrycodes and market_types to avoid hitting the 200 makret subscription limit which betfair seem to have)



I’ve not tried adding strategies from a background thread yet, but will do that later today.



reason for this is that I want to have one flumine instance running on my ec2, with a trickling in of football events as they are 2hours from start.



so I’ll have the events stored in RDS (which are periodically refreshed) and then have a loop which grabs relevant event_id’s to construct the market_filter going into flumine



is there a better pattern to use for something like this?

*Tags: Errors Debugging, Deployment, Strategies*

---

**Ammar** - *09:57:41*

running multiple flumines from different threads seems to work …

*Tags: General Technical*

---

**liam** - *11:05:21*

The benefits of [https://betcode-org.github.io/betfair/streaming/|streaming](https://betcode-org.github.io/betfair/streaming/|streaming), reading between the lines it seems you are trying to solve the 200 market limit? Ask betfair for a raise, record everything, don't add markets and don't add strategies when running

*Tags: General Technical*

---

## 2024-04-22

**Dario Scardina** - *15:03:18*

I'm facing the same problem today. It has never happened to me before.

*Tags: General Technical*

---

## 2024-04-23

**Dario Scardina** - *15:48:47*

Hello everyone,

for a couple of days I've been encountering issues during API login.

betfairlightweight.exceptions.APIError: None

Params: None

Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.it|identitysso-cert.betfair.it](http://identitysso-cert.betfair.it|identitysso-cert.betfair.it)', port=443): Max retries exceeded with url: /api/certlogin (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x71de1340&gt;, 'Connection to [http://identitysso-cert.betfair.it|identitysso-cert.betfair.it](http://identitysso-cert.betfair.it|identitysso-cert.betfair.it) timed out. (connect timeout=3.05)'))

This has never happened to me before, but these days I'm getting this message almost 80% of the time. What can I check to resolve it?

*Tags: Errors Debugging*

---

## 2024-04-25

**Ammar** - *10:54:32*

I think there’s a bug in the keep alive worker where it’s not logging in properly



Traceback in thread



I’ve been getting this for a couple of days wheen leaving the stream running for a long while (to build up local data as discussed  elsewhere) but also logging into betfair from other devices to look at things or manually execute.



The fix should be relatively straightforward, happy to open a PR into the flumine repo if that’s the done thing?

*Tags: Errors Debugging, Deployment*

---

**Ammar** - *10:54:44*

```

{"asctime": "2024-04-24 21:20:22,236", "levelname": "ERROR", "message": "BetfairClient `keep_alive` error", "exc_info": "Traceback (most recent call last):

File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/clients/betfairclient.py\", line 44, in keep_alive

return self.betting_client.keep_alive()

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/keepalive.py\", line 30, in __call__

(response, response_json, elapsed_time) = self.request(session=session)

                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

                           File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/keepalive.py\", line 60, in request

                               self._error_handler(response_json)

                                 File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/keepalive.py\", line 67, in _error_handler

                                     raise self._error(response)

                                     betfairlightweight.exceptions.KeepAliveError: API keepAlive FAIL: NO_SESSION", "client": "APIClient", "trading_function": "keep_alive", "response": "API keepAlive FAIL: NO_SESSION"}





{"asctime": "2024-04-24 21:20:22,240", "levelname": "ERROR", "message": "Error in BackgroundWorker keep_alive: 'NoneType' object has no attribute 'status'", "exc_info": "Traceback (most recent call last):

File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/worker.py\", line 66, in run

self.function(

File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/worker.py\", line 106, in keep_alive

if resp is True or resp.status == \"SUCCESS\":

^^^^^^^^^^^

AttributeError: 'NoneType' object has no attribute 'status'", "worker_name": "keep_alive", "function": "[function keep_alive at 0x1041e99e0](function keep_alive at 0x1041e99e0)", "context": {}}```



---

raw json format from the logger

```{"asctime": "2024-04-24 21:02:11,658", "levelname": "ERROR", "message": "BetfairClient `account.get_account_details` error", "exc_info": "Traceback (most recent call last):\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/clients/betfairclient.py\", line 84, in _get_account_details\n    return self.betting_client.account.get_account_details()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/account.py\", line 54, in get_account_details\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: None \nError: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}", "client": "APIClient", "trading_function": "account.get_account_details", "response": "AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: None \nError: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}"}

{"asctime": "2024-04-24 21:02:11,762", "levelname": "ERROR", "message": "BetfairClient `account.get_account_funds` error", "exc_info": "Traceback (most recent call last):\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/clients/betfairclient.py\", line 98, in _get_account_funds\n    return self.betting_client.account.get_account_funds()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/account.py\", line 35, in get_account_funds\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: AccountAPING/v1.0/getAccountFunds \nParams: {} \nException: None \nError: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}", "client": "APIClient", "trading_function": "account.get_account_funds", "response": "AccountAPING/v1.0/getAccountFunds \nParams: {} \nException: None \nError: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}"}```

*Tags: Errors Debugging, Deployment, Strategies*

---

**foxwood** - *21:00:31*

Not sure there is a bug there - runs for weeks on end 24/7 for me and others using flumine. Suggest you look at your usage of flumine and other things you are doing that may interfere. Once you come up with proof of how to cause the supposed error or the repeatable actions that make it happen then that's the time to consider a PR.

*Tags: Errors Debugging*

---

**Ammar** - *21:18:05*

It looks to me like there’s an unexpected response type (as `None`) which is coming thru from the call stack — which looks entirely plausible as I read thru the code all the way back to `betfairlightweight`



to be clear, this isn’t impacting the data stream; but it does look like very unhappy noise in the logs, which is never nice :)



steps to replicate:

• leave the market recorder going on one machine — this is _all_ I’m using flumine for, it’s a single process which I kick off each day.  (currently on a laptop, behind expressVPN, which may be a noteworthy point) 

• use betfair to manually execute and check markets via the mobile app, and other computers

• over the course of 8-10 hours the error will start to present



the fix could be very light in the keepalive (similar to how it’s handling a failure already)





```def keep_alive(context: dict, flumine) -&gt; None:

    """Attempt keep alive if required or

    login if keep alive failed

    """

    for client in flumine.clients:

        if client.EXCHANGE == ExchangeType.BETFAIR:

            if client.betting_client.session_token:

                resp = client.keep_alive()



                # start change

                if resp is None:  # this is the unexpected response type I'm seeing

                    client.login()

                # end chage



                if resp is True or resp.status == "SUCCESS":

                    continue

        elif client.EXCHANGE == ExchangeType.BETCONNECT:

            resp = client.keep_alive()

            if resp:

                continue

        # keep-alive failed lets try a login

        client.login()```

*Tags: Data Quality, Errors Debugging, Deployment, Strategies*

---

## 2024-04-26

**Derek C** - *09:06:55*

This problem isn't affecting me and I run Flumine market recorder 24/7. What do you think decides who is affected by this?

*Tags: Data Quality*

---

**Ammar** - *09:15:16*

Well I’m seeking guidance on that. 



It does look like there is an unexpected None being returned in a situation which I’ve hit (rightly or wrongly), and that shows in the logs with errors. 



It’s not stopping streaming data, but it may impact other operations (which I’m not doing via flumine as yet)



But I do seem to be in a small minority here, so I will do more digging and share info on the root cause when I have time in the coming days 

*Tags: Errors Debugging*

---

**foxwood** - *11:19:03*

It implies you may get a different IP for each outgoing request you make so that could invalidate your session. Just a thought though. Good luck with your debugging.

*Tags: Errors Debugging*

---

## 2024-04-29

**Shashi Khaya** - *15:03:52*

Hi folks, is there anything in flumine that handles updating scores in tennis (via the poll inplay service example) or do I need to write that logic out myself? And if the latter is true, how should the logic be structured in flumine?

*Tags: General Technical*

---

**Shashi Khaya** - *15:12:54*

the background worker callback overwrites the score :

def callback(flumine, event):

    # update market context

    score = event.event

    for market in flumine.markets:

        if market.event_id == str(score.event_id):

            logger.debug(

                "Updated market %s with event %s scores data",

                market.market_id,

                market.event_id,

            )

            market.context["score"] = score

*Tags: Errors Debugging*

---

**liam** - *15:29:14*

Is that a question or are you happy?

*Tags: General Technical*

---

**Shashi Khaya** - *15:31:59*

I would like to see if there is anything readily available to extend this callback function to update the score rather than replace it. And if I need to write this logic, any guidance on how it would look in flumine would be greatly appreciated

*Tags: General Technical*

---

**Shashi Khaya** - *15:45:18*

I had thought that, I just wanted to check whether there was a more sophisticated way to do this, but I guess this can be done in post processing. Is it possible to get score data for tennis via streaming? or is polling the inplayservice API the best way to obtain this data from betfair?

*Tags: General Technical*

---

## 2024-05-07

**Adrian** - *07:47:04*

Is this supposed to do something other than load up the Jupyter launcher screen?

[https://github.com/betcode-org/flumine/blob/master/examples/controls/jupyterloggingcontrol.py](https://github.com/betcode-org/flumine/blob/master/examples/controls/jupyterloggingcontrol.py)

I put it in my backtest like this:

```control = jupyterloggingcontrol.JupyterLoggingControl()

...

framework.add_strategy(strategy)

framework.add_logging_control(control)



framework.run()

control.launch()```

The backtest runs fine but when control.launch() opens up JL it just sits at the launcher screen doing nothing. There is no /tmp/orders.json output anywhere either

*Tags: Strategies*

---

**Adrian** - *09:32:59*

Ok yep, got it to the next step. It runs the first cell but encounters KeyError: 'name' in the second cell :

`df = pd.merge(df, df_strategies, left_on="trade__strategy", right_on="name", how="left")`

There's no 'name' column in any of the dataframes

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

**liam** - *09:35:34*

Did that get renamed to `strategy_name`?

*Tags: Strategies*

---

**Adrian** - *09:38:07*

df_strategies['strategy_name']

df['trade__strategy']

*Tags: Strategies*

---

**Ammar** - *09:41:14*

here’s where I’ve got to for anyone who was interested in this:



• running the suggested hotfix locally did suppress the initial error I was getting (to handle the `None` return case)

• but i then got other errors coming from betfair (invalid session on polling the account details endpoint; and one other)

• that’s when i tried another background worker to do some more session management - but the issue persisted

• I was seeing this on a totally “vanilla” run (no vpn, no other sessions, small number of events on the filter) after about 4-5 hours of the stream being up

• I’ve got a ticket open with BDP now to get more insight

*Tags: Errors Debugging*

---

**liam** - *09:53:11*

strategy__name or similiar

*Tags: Strategies*

---

## 2024-05-09

**NAS** - *15:33:14*

my bots went down earlier today due to the maintenance and when this happens flumine fails to reconnect, seems there's an issue with the keep_alive worker? checking code seems to suggest it should always attempt a new login if theres an issue with the sessions?



`2024-05-09 13:23:24,033 - flumine.clients.betfairclient - ERROR - BetfairClient `keep_alive` error`

`Traceback (most recent call last):`

  `File ".../flumine/clients/betfairclient.py", line 44, in keep_alive`

    `return self.betting_client.keep_alive()`

           `^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^`

  `File ".../betfairlightweight/endpoints/keepalive.py", line 30, in __call__`

    `(response, response_json, elapsed_time) = self.request(session=session)`

                                              `^^^^^^^^^^^^^^^^^^^^^^^^^^^^^`

  `File ".../betfairlightweight/endpoints/keepalive.py", line 60, in request`

    `self._error_handler(response_json)`

  `File ".../betfairlightweight/endpoints/keepalive.py", line 67, in _error_handler`

    `raise self._error(response)`

`betfairlightweight.exceptions.KeepAliveError: API keepAlive FAIL: NO_SESSION`

`2024-05-09 13:23:24,038 - flumine.worker - ERROR - Error in BackgroundWorker keep_alive: 'NoneType' object has no attribute 'status'`

`Traceback (most recent call last):`

  `File ".../flumine/worker.py", line 66, in run`

    `self.function(`

  `File "..../flumine/worker.py", line 106, in keep_alive`

    `if resp is True or resp.status == "SUCCESS":`

                       `^^^^^^^^^^^`

`AttributeError: 'NoneType' object has no attribute 'status'`

*Tags: Errors Debugging, Deployment, Strategies*

---

**NAS** - *21:17:39*

did you fix it/get any help?

*Tags: Errors Debugging*

---

**NAS** - *21:21:51*

my understanding of the logic:

(1) if theres an issue with the current session, try to refresh it/keep it alive

(2) if this for some reason fails, run a new login instead



as you mentioned it looks like there are unexpected responses coming through that throws exceptions and never lets (2) come into play

*Tags: Errors Debugging, Deployment*

---

**Ammar** - *21:24:24*

yeh.  I ran in the fix which is in the thread, and it seemed to resolve that specific issue.  I’m petitioning to get it into flumine, happy to open a PR, but some discussion around the criteria for doing so in the original thread

*Tags: Errors Debugging*

---

**Ammar** - *21:26:08*

&gt;  replacing the ‘or’ with an ‘and’ fixes it?

it’s what’s highlighted in the code block inside the message linked above.  if keep alive returns a `None` then force a login; that’s it

*Tags: Errors Debugging, Deployment*

---

**Ammar** - *21:29:31*

:+1:  lmk if that fixes if for you locally; can then create a PR and see what the repo owner group have to say

*Tags: Errors Debugging*

---

## 2024-05-10

**ShaunW** - *19:25:26*

Check your sim latency vs live? Sounds like you're getting in too far in front of your live orders. Its hard retesting something you're present in.

*Tags: Performance, Deployment*

---

**JL** - *20:00:11*

thank you, I'll do some further testing. The strategy is executing a limit order on the best available back/lay

*Tags: Strategies*

---

## 2024-05-13

**liam** - *10:13:29*

Anyone else getting 404 errors on the account endpoint?

*Tags: Errors Debugging*

---

**Johnny** - *10:32:06*

```"/home/xxx/anaconda3/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 47, in request\n    check_status_code(response)\n  File \"/home/xxx/anaconda3/lib/python3.11/site-packages/betfairlightweight/utils.py\", line 37, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 404", "client": "APIClient", "trading_function": "account.get_account_funds", "response": "Status code error: 404"}```

*Tags: Errors Debugging, Strategies*

---

**Adrian** - *10:40:33*

Soo, I don't know if this is intended behaviour or not, but it seems like market.context is shared across all strategies? Reason i ask is, when I set a flag on strategy one after placing a bet (market.context['bet_placed'] = True), my other strategies can access that flag (they stop placing bets if market.context['bet_placed']). Is that to be expected?

*Tags: Strategies*

---

**liam** - *10:40:52*

Yes, use `strategy.context`

*Tags: Strategies*

---

**liam** - *10:44:03*

flumine tries to be consistent so strategy stuff in `strategy.context` and market stuff in `market.context` allowing you to share if required

*Tags: Strategies*

---

**Adrian** - *10:46:43*

Yep makes sense! Quite handy actually. The market stuff shared across markets has been working flawlessly. Now i know where to put the strategy specific stuff. I was going crazy all day thinking it had something to do with the multiprocessing

*Tags: Strategies*

---

**Unknown** - *19:27:11*

I noticed a couple of errors earlier (Status Code error 520 and 404)

(Out of interest, If i had this setting :



```logging.getLogger().setLevel(logging.CRITICAL)```

Would I see the errors you see Lee?

*Tags: Errors Debugging*

---

## 2024-05-16

**Jorge** - *08:24:00*

Hey guys, I recently started Simulating 2 strategies in the same flumine instance, with the goal of running them live. Until now, I was running both strategies in different scripts. This is my code:



```client = clients.SimulatedClient()

framework = FlumineSimulation(client=client)



control = BacktestLoggingControl(logs_dir=logs_dir)

framework.add_logging_control(control)



with patch("builtins.open", smart_open.open):

    framework.add_strategy(strategy_1)

    framework.add_strategy(strategy_2)

    framework.add_market_middleware(MarketCatalogueMiddleware(strategy_2.market_filter["markets"]))

    framework.run()```

My issue is with the [https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py](https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py) , I noticed that in my orders.txt, the orders from strategy_1 are duplicated. The same happens with the markets.txt (cleared_markets), I get double the amount of cleared_markets and the last half is the correct one which includes both strategies. How could I fix this so the [https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py](https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py) works when running multiple strategies in the same instance?

*Tags: Errors Debugging, Deployment, Strategies*

---

**Jorge** - *09:29:51*

Seems to be working well using the simulate.py example. I noticed that in my simulation it runs first the strategy_1 in the 100 markets and then runs the strategy_2 in the 100 markets, as opposed to the simulate.py which runs them in the same market at the same time. So in the simulate.py I only see 1 log of "Cleared market" and no duplicates...

*Tags: Strategies*

---

**Jorge** - *10:44:13*

Found my issue, the strategies were using different listener_kwargs and that caused the problem. They were using different markets too but that works well

*Tags: General Technical*

---

## 2024-05-21

**Jorge** - *14:35:56*

Hi, when running 2 strategies in the same flumine instance, is it possible to give different customer_strategy_ref values to the orders placed by each Strategy? So that later I can analyze the results of each Strategy calling the `trading.betting.list_cleared_orders` endpoint.



In the flumine instance I save my own cleared_orders.txt which separates the orders using a "strategy_name" column as the example [https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py](https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py) . But I like to analyze the results calling Betfair directly in case the script was down.

*Tags: Strategies*

---

## 2024-05-28

**Jorge** - *09:07:42*

I do use notes, the issue is not separating the orders internally, I can do that. The issue is when calling the `trading.betting.list_cleared_orders` endpoint, it is only possible to separate orders by the customer_strategy_ref value. When running 2 strategies in the same flumine instance it's not possible to give different values to each strategy unfortunately. I'd like to "mark" the orders in Betfair's side so that later when analyzing results by calling the API in 1 month I can separate the orders and attribute the P&L to each Strategy.

*Tags: Strategies*

---

## 2024-06-03

**George** - *12:42:51*

It seems like order logging in flumine simulation suffers from an inherent problem with race-conditions. Essentially I believe that the simulation loop is fast, but the logging-control loop is slow, and they run in parallel.



This means, by the time the logging-control comes to log any particular order, that order might have changed its status or properties potentially multiple times.



To resolve this, potentially the easiest option would be to pass dictionaries into the logging-control, rather than Order objects. Is that something that people are already doing / aware of / interested in? Is it already possible to achieve somehow without making changes to the internals of flumine?

*Tags: Performance*

---

**George** - *12:45:42*

Agreed, but that requires me to maintain an alternative 'personal' version of flumine which seems like a bad idea?

*Tags: General Technical*

---

## 2024-06-08

**Elliot A** - *19:41:46*

Hi guys I have a strategy that uses Process New Market to wait for new markets to appear on Betfair and then do some stuff. The code runs 24hrs a day but seems to just stop processing markets after a few hours. Have not changed the default workers so it should be kept alive, any ideas whats happening? 

*Tags: Deployment, Strategies*

---

## 2024-06-13

**Rodolfo** - *18:03:03*

hey, I am not a pro coder but I managed to create a script that places bets. Works fine. But I am helping a friend that lives in Sweden, he gets a AUTHORIZED_ONLY_FOR_DOMAIN_SE error. How can I ask betfairlightweight to try the SWEDEN exchange?



trading = betfairlightweight.APIClient(EMAIL, PASSWORD, app_key=API_KEY_DELAYED)

trading.login_interactive()



Thank you.

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2024-06-14

**James** - *08:20:25*

Hi everyone!

I am running Flumine simulations and have an issue with cancelled orders still being matched, long after they were cancelled. To be specific, I placed an order for $50 and after five seconds I cancelled it. Looking through extensive logging, I saw that it was cancelled with $10 partially matched, and its status had turned to “CANCELLING”. Over the course of the next 20 or so seconds, the order.size_matched value progressively increased to $50 (status was still “CANCELLING” all the way through). Once the order was fully matched, the status went to “EXECUTION_COMPLETE”. I am very confused as to why a cancelled order continued being matched. Any ideas would be much appreciated, thanks!

*Tags: General Technical*

---

**Unknown** - *13:11:50*

Attached is a zip folder containing a simple flumine script, a historical data file and the log file. To avoid problems, open the folder as a whole in the IDE and run the files from there. Hope this helps and please let me know if you need me to explain! Thanks!

*Tags: Data Quality*

---

## 2024-06-15

**A** - *09:16:04*

Hello. Does it sometimes take a while for an order to transition to the  `EXECUTION_COMPLETE` state? I’ve been experiencing some orders being placed and matched pretty much straight away (according to the Betfair website UI), and then up to hours later it appears as complete in Flumine. Most orders behave as I expect, just occasionally see these delays on some order states.

*Tags: General Technical*

---

## 2024-06-18

**Cian Ryan** - *23:51:12*

Hi all, I am following the betfairlightweight tutorial using Colab notebook. When I call the API however i get a HTTP 403 error. Could this be due to the server potentially being in the US? Same code works fine on local drive, although i have to use the less secure login_interactive() in both cases as I couldn't get it to authenticate my certs.



is there any way around this?

*Tags: Errors Debugging, Deployment*

---

## 2024-06-19

**Derek C** - *08:57:57*

it's because your ip address indicates that you are in the US, even if you're not. The same problem occurs when accessing betfair with other Google cloud infrastructure as well.

*Tags: General Technical*

---

**A** - *10:44:32*

I run Flumine on GCP. Just need to set your zone.

*Tags: General Technical*

---

**Cian Ryan** - *17:35:10*

thanks both for the info. I will look into Flumine



I am now trying to run in my local drive but its not reading my certs despite being saved in the path. I have tried to save it as .crt and .pem (both pem + key and pem *all. PEM + PKCS#8 brings me to Enter PEM pass phrase: but I don't recall setting any. What should I type for here?

*Tags: General Technical*

---

**Cian Ryan** - *18:13:47*

EDIT: the PEM pass just turned out to be my password for the database after I tried it in the cmd.



I am getting a new error, however:

betfairlightweight.exceptions.LoginError: API login: CERT_AUTH_REQUIRED



My login details are correct as they work in the websites (both exchange and API). What else causes this issue? login_interactive() works but .login() does not so it should be an issue with my credentials.

*Tags: Errors Debugging*

---

**foxwood** - *19:19:09*

complete write-up and instructions for testing  may help [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login)

*Tags: General Technical*

---

## 2024-06-23

**Jared King** - *12:43:04*

Liam will probably spit out his coffee, but i do this:

```from flumine import config

config.customer_strategy_ref = 'strat_name'```

*Tags: Strategies*

---

## 2024-06-24

**Mo** - *17:15:44*

In flumine is there a canonical way to stop processing a market when in the middle of simulating it?

*Tags: General Technical*

---

**liam** - *17:55:36*

No but welcome some ideas on how to do it as I can see a few reasons why you would want to 

*Tags: General Technical*

---

**foxwood** - *17:58:57*

I do a fiddle in `check_market_book()` where I initially set a default of 999999

```if market.context[self.ctxname]["skipToSeconds"] != 999999 \

        and realSecsToGo > market.context[self.ctxname]["skipToSeconds"] :

    # after start time and asked need to skip

    return False```

and in the strategy when finished set it with

```market.context[self.ctxname]["skipToSeconds"] = -9999```

*Tags: Strategies*

---

**liam** - *19:04:45*

I think we need to trigger something as low as possible so the books stop getting processed by bflw 

*Tags: General Technical*

---

## 2024-06-25

**foxwood** - *10:47:50*

The reason for my fix was to stop wasting time running my code but let the underlying bet matching simulation take place as each packet came through so I got to closed market asap. That reason came to me in the night lol. So, yes there are two cases, stop calling user code and also an abandon (with / without calling closed_market ? - variations grow !)

*Tags: Errors Debugging*

---

## 2024-06-28

**Peter** - *12:13:13*

I'm trying to use betfairviz to visualise market books from self recorded files. I'm using the create_dashboard function but getting a recursion depth error. Not quite sure where I'm going wrong, please could someone point me in the right direction?

*Tags: Errors Debugging*

---

## 2024-06-29

**Unknown** - *01:50:48*

Hi Guys,

Strange thing is happening. I moved my hosting from my home lab in Australia to Ireland. My latency has improved drastically, however for some strange reason my bet matching has become worse. Here are two graphs, the first one shows the total elapsed seconds of all my bets. You can see the huge jump in the last lot to the right where virtually nothing is being matched straight away. The second graph shows all bets that were matched under one second. You can see the huge spike where it doesn't even touch zero seconds elapsed whereas it was sitting on the x axis most of the time before. The decrease in performance is showing in my results.. my ev and my profit is flatlining. What the hell is happening?

*Tags: Performance*

---

**Unknown** - *02:06:12*

here's the latency on my new server. you can see it's not high. I should add that i'm only taking bets not offering them, so the matching should be near instant, but definitely not worse than from the other side of the planet

*Tags: Performance, Deployment*

---

**Adrian** - *05:57:18*

This log for one of the bets. If I'm reading correctly, it's cancelling the matched, execution complete bet? How is that possible

```{"asctime": "2024-06-29 00:26:34,373", "levelname": "INFO", "message": "execute_place", "taskName": null, "trading_function": "place", "elapsed_time": 0.31791043281555176, "response": {"customerRef": "cfca0e5e66bb42aca58660e4d5d04156", "status": "SUCCESS", "marketId": "1.230213698", "instructionReports": [{"status": "SUCCESS", "instruction": {"selectionId": 63123802, "handicap": 0.0, "limitOrder": {"size": 0.9, "price": 6.0, "persistenceType": "LAPSE"}, "customerOrderRef": "10486de05a131-139389135940498137", "orderType": "LIMIT", "side": "LAY"}, "betId": "352983020564", "placedDate": "2024-06-29T00:26:34.000Z", "averagePriceMatched": 6.0, "sizeMatched": 0.9, "orderStatus": "EXECUTION_COMPLETE"}]}, "order_package": {"id": "cfca0e5e-66bb-42ac-a586-60e4d5d04156", "client": "[flumine.clients.betfairclient.BetfairClient object at 0x7f08e2a6a540](flumine.clients.betfairclient.BetfairClient object at 0x7f08e2a6a540)", "market_id": "1.230213698", "orders": ["139389135940498137"], "order_count": 1, "package_type": "Place", "customer_strategy_ref": "7b7f8aff23d6", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}



{"asctime": "2024-06-29 00:34:28,149", "levelname": "INFO", "message": "Order status update: Cancelling", "taskName": null, "market_id": "1.230213698", "selection_id": 63123802, "handicap": 0, "id": "139389135940498137", "customer_order_ref": "10486de05a131-139389135940498137", "bet_id": "352983020564", "date_time_created": "2024-06-29 00:26:34.049894", "publish_time": "2024-06-29 00:26:34.048000", "market_version": null, "async": false, "trade": {"id": "b7996cca-1057-482b-8cde-05d1cd654818", "strategy": "laying", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["139389135940498137"], "offset_orders": [], "notes": "", "market_notes": "4.6,6,None", "status": "Live", "status_log": "Pending, Live"}, "order_type": {"order_type": "Limit", "price": 6, "size": 0.9, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null, "price_ladder_definition": "CLASSIC"}, "info": {"side": "LAY", "size_matched": 0.9, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 6}, "responses": {"date_time_placed": "2024-06-29 00:26:34.374398", "elapsed_seconds_executable": null}, "runner_status": null, "line_range_result": null, "status": "Cancelling", "status_log": "Pending, Executable, Cancelling", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "6.5993862158248975,1105.950219", "market_notes": "4.6,6,None", "client": ""}```

my orders file shows the bet was matched and resulted in a loss with 474 seconds elapsed executable. even though it was matched instantly

*Tags: Deployment, Strategies*

---

**Adrian** - *06:22:35*

the problem's not as bad on my UK server. Maybe the IE server is so fast it's breaking Flumine? :sweat_smile:

*Tags: Deployment*

---

**foxwood** - *09:08:22*

Given the bet cancellation is 8 minutes later could be some code running at suspension / close of market - although no idea what type of markets you are on ? If sure it is not your code doing / causing the cancel then try comparing the server/home code and package versions. Losses due to improved latency quite possible - now getting matched on bad value bets that were just too late from Aus so not being matched from home but are now.

*Tags: Performance, Deployment*

---

**Joe** - *10:02:39*

When did the problem start, did it exactly coincide with you moving the server? Could just be coincidence say if someone else has started taking the bets you were taking.

*Tags: Deployment*

---

**Mo** - *10:04:25*

I can't speak to the cancelling behaviour you've observed but:



Reduced latency is going to affect how quickly you receive the triggers as well as how quickly you send your bets to Betfair. It's not impossible that acting too quickly is deleterious. Have you tried running backtests with different simulated latencies and comparing results?

*Tags: Performance*

---

**Adrian** - *10:23:33*

[@U05L8PZD2FM](@U05L8PZD2FM) yep happened the second i moved it over.

[@UBS7QANF3](@UBS7QANF3) i haven't tried doing the backtest with lower latency. I'll give it a crack. Thanks for the idea!

It's probably my bad coding that was being cushioned with a higher latency

*Tags: Performance*

---

**foxwood** - *16:01:25*

Raised similar a few months ago [https://github.com/betcode-org/flumine/issues/743](https://github.com/betcode-org/flumine/issues/743)  Suggest check size_remaining rather than rely on status - that seems to get correctly knocked down to zero even though order not set as execcomplete - test with minimum stake

Edit: cancel from process_orders will take place after 427secs since status wrong

*Tags: General Technical*

---

## 2024-07-01

**Lee** - *10:09:50*

what happens in the “…” section? Any errors? any logs showing an attempt to change the status?

*Tags: Errors Debugging*

---

**liam** - *15:15:53*

Can you confirm the flumine version you run locally and the one on the server? Would ideally need some (minimal) code to replicate this as that will be where the problem is

*Tags: Deployment*

---

## 2024-07-02

**Adrian** - *04:06:35*

[@UUCD6P13J](@UUCD6P13J) no nothing related to that bet at all, which is why I omitted it, just hundreds of max_live_trade count >= 1 strategy violation messages while fumine tries to place a second bet

*Tags: Deployment, Strategies*

---

## 2024-07-04

**liam** - *06:35:23*

Do you know what your latency is when receiving data ie. Publish time vs your clock / do you get any data conflated? 



Unless you are betting into a highly volatile market such as inplay racing I am not sure this would be latency tbh 

*Tags: Performance, Strategies*

---

## 2024-07-05

**Unknown** - *01:12:50*

[@U016TGY3676](@U016TGY3676) sorry i misread 'counterparty' as counterplay. I get what you mean now, thanks. You could be right, i'm not cancelling for many minutes though so i dont see how thats could be a factor

[@U4H19D1D2](@U4H19D1D2) That is time - mb publish time epoch. i literally took your formula straight from baseflumine.py

`latency = time.time() - (market_book.publish_time_epoch / 1e3)`

here is the full screenshot

the order shown is latency | time.time() | market_book.publish_time_epoch | market_book.publish_time_epoch / 1e3

*Tags: Performance*

---

**Adrian** - *08:42:40*

If you notice its all rounding errors

*Tags: Errors Debugging*

---

**Adrian** - *08:47:47*

Yes. WHen you calculate latency by dividing market epoch by 1e3 you get 1000s of a second errors. Because the numbers are exactly the same up to the decimal point

*Tags: Errors Debugging, Performance*

---

**Unknown** - *08:57:29*

here is the exact same setup on England server. this is probably what an AWS setup looks like

*Tags: Getting Started, Deployment*

---

**Adrian** - *08:58:10*

its more stable because it's higher latency. But still swings around just as much per tick

*Tags: Performance*

---

**liam** - *09:02:33*

Agreed, but why do you think the UK server should have higher latency?

*Tags: Performance, Deployment*

---

**liam** - *09:21:45*

You honestly think you are getting 0.0001s latency from betfair and it's only 'possible' that your clock is wrong?

*Tags: Performance*

---

**Unknown** - *10:06:59*

i updated the clock. rounding errors went away but still sub 1ms

*Tags: Errors Debugging*

---

**Unknown** - *10:15:27*

yeah, slower here but similar to the backtest latency preset

*Tags: Performance*

---

**birchy** - *16:27:10*

Lesson 1: if it ain't broke, don't fix it.

Lesson 2: make sure you have NTP running on your server

*Tags: Errors Debugging, Deployment*

---

## 2024-07-06

**Unknown** - *09:30:25*

i got it fixed, after synching ntp the server time still wasn't adjusted until i rebooted the VPS. Strange that it doesn't fix itself until reboot. Even docker gave wrong times after reboot too, so that threw me off. Anyway, thanks for everyone's help. It's a long pain in the arse but it's finally fixed

*Tags: Errors Debugging, Deployment*

---

## 2024-07-15

**Derek C** - *07:56:59*

If I see messages in Flumine that it's "likely that the thread pool is currently exhausted", what should I look for to fix this, i.e.

1. increase the parameter in flumine config to allow more threads

2. buy a bigger machine

3. look for a bug in my code?

I tried doubling the parameter in Flumine "flumine.max_execution_workers" but it didn't cure the problem.

*Tags: Errors Debugging*

---

**birchy** - *13:59:06*

So presumably, at strategy level you're checking the blotter for pending bets before firing in the next lot? Obviously there's an advantage to NOT waiting for the order stream to pick them up, but I assume you use other mechanisms to prevent the same bets being placed multiple times?

*Tags: Strategies*

---

**liam** - *19:40:04*

It should always improve your latency as you will use less threads thus less sessions active 

*Tags: Performance*

---

## 2024-07-16

**D C** - *11:32:58*

Does flumine work on a login session PER thread then?

*Tags: General Technical*

---

**liam** - *11:36:02*

threads in python share memory so flumine only requires a single login

*Tags: Performance*

---

## 2024-07-17

**Herugrim** - *08:03:11*

How can I add a worker to a Flumine instance to refresh a dataframe every 60 seconds?



I've created a dataframe before starting the framework and loaded it into the framework, but I'm going to asynchronously refresh the dataframe every 60 seconds, and need the Flumine instance to update with this new dataframe

*Tags: Feature Engineering*

---

**liam** - *08:26:22*

```from flumine.worker import BackgroundWorker





def update_df(context: dict, flumine) -&gt; None:

    df = get_df_data()

    # store df in market context?

    for market in flumine.markets:

        market.context["df"] = df

    # store df in strategy context?

    for strategy in flumine.strategies:

        strategy.context["df"] = df





framework.add_worker(

    BackgroundWorker(

        framework,

        update_df,

        interval=60,

        start_delay=4,

    )

)```

*Tags: Strategies*

---

## 2024-07-22

**A** - *17:26:59*

Hey. Recently getting `SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 221 markets whereas max allowed number was: 200` just trying to subscribe to UK hounds. First I’ve seen of this. Wondering if it’s trying to subscribe to tomorrows races too?



Code (was working great until this last hour):



```MyStrategy(

  market_filter=betfairlightweight.filters.streaming_market_filter(

    event_type_ids=["4339"],

    country_codes=["GB"],

    market_types=["WIN"]

  )

)```

Any way to get it to subscribe to the day’s racing?

*Tags: Strategies*

---

## 2024-07-23

**Jared King** - *10:25:58*

[@U4H19D1D2](@U4H19D1D2), would you be willing to share an example of how to use transactions? I'm trying to write some code that enforces an order flow for one runner, only one workflow allowed for that runner at a time ie trigger-&gt;place open trade-&gt;open trade matched-&gt;place close trade-&gt;close trade matched-&gt;waiting (and handle cancelling etc) but if this can help...

*Tags: General Technical*

---

**liam** - *10:38:29*

Sounds like you just want to use a trade / multiple orders and limit using `max_live_trade_count` on the strategy

*Tags: Deployment, Strategies*

---

**liam** - *10:52:09*

[https://github.com/betcode-org/flumine/blob/master/flumine/strategy/runnercontext.py](https://github.com/betcode-org/flumine/blob/master/flumine/strategy/runnercontext.py)

*Tags: Strategies*

---

**Jared King** - *10:52:39*

rgr that. fixed your code:

```runner_context = self.get_runner_context(market_id, selection_id, handicap)

if runner_context.live_trade_count == 0:

    lose money```

*Tags: Errors Debugging, Deployment*

---

## 2024-07-27

**Derek C** - *16:25:29*

I'm having some new issues lately where Flumine isn't enforcing exposure limits on selections and I am getting exposures that are a multiple of what I would like them to be. I recently made the following changes, could these somehow cause the exposure limits to be breached?

• started setting the config parameter to make orders 'async' 

• adding 'force=True' on cancellations (because I often hit the hourly transaction limit)

Another symptom that may or may not be related is I get a lot of unmatched orders hanging around, even though my 'process_orders' function cancels after n seconds.



My assumption/understanding is that if I stop Flumine and re-start it will recalculate exposures for all outstanding strategy orders, so stop/restart shouldn't be the issue.



Is there something I should be logging that would help track this down?

*Tags: Strategies*

---

**Ralegh** - *16:28:48*

Not a flumine user but if you’re creating orders async then potentially you could exceed exposure if you sent multiple orders in quick succession (though flumine might handle that), could log your orders with place/create times to check that

*Tags: General Technical*

---

**Derek C** - *16:36:17*

thanks [@U03FS7KM2NL](@U03FS7KM2NL) but i think Flumine is controlling that I only have 1 open order at a time (according to my settings) and if I look at the orders, there are dozens of small-exposure bets, it isn't that I have a few large ones making up the total.

*Tags: General Technical*

---

**Lee** - *16:58:36*

are you using the [https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py|orders](https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py|orders) middleware? If not the restarts will probably be the issue

*Tags: General Technical*

---

**Lee** - *17:35:38*

you’ll probably need to put a debugger on it and see what’s happening

*Tags: Errors Debugging*

---

**Derek C** - *19:28:16*

I think the problem I'm having is that the middleware is calling 'list_current_orders' each time a new market comes onto the stream, which at startup is quite a heavy workload in my particular setup. I changed it to only list orders for the market that was being added and that got me past my blocker.

*Tags: Getting Started*

---

**Derek C** - *19:54:31*

yeah, definitely room for some optimisations there! Thanks again for your help, I was totally stuck earlier.

*Tags: General Technical*

---

## 2024-08-01

**Jorge** - *09:49:14*

Hi, I'm getting these errors in a Flumine Simulation: Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failed: reset_elapsed_seconds (-0.99) &lt; reset_seconds (0.0).

What does [https://github.com/betcode-org/flumine/blob/master/flumine/strategy/runnercontext.py#L60|reset_elapsed_seconds](https://github.com/betcode-org/flumine/blob/master/flumine/strategy/runnercontext.py#L60|reset_elapsed_seconds) mean?

*Tags: Errors Debugging, Strategies*

---

**liam** - *11:07:56*

`reset_elapsed_seconds` seconds since trade was reset, ie order has become execution_complete



`placed_elapsed_seconds` seconds since an order was placed (per strat)



These are all strategy level settings per init

*Tags: Strategies*

---

## 2024-08-04

**Unknown** - *07:08:15*

Hi guys; I've noticed lately that my marketbooks are not being updated - I'm not sure what the problem is exactly, but in the log file the price is 11.5 where the actual price is 15.5.  It's the whole book, and it happened the other day as well. On a reboot of the program it's done the same thing again. Log files are showing old prices, with the book just not being updated.  What do I need to check to analyse the problem / what should I be on the lookout for?



I am running a beta version of my script to add untested strategy on the same ec2 instance, so there are multiple scripts pulling the data with the same address or whatever. I don't think there are any memory problems because it's happened again after I've checked that.



The prices on the other script running look fine - different strategy names if it helps.

*Tags: Performance, Deployment, Strategies*

---

**liam** - *09:29:36*

Live key? XM? What are you using for this? Bflw?

*Tags: Deployment*

---

**Tom** - *10:59:51*

Yeah live key; been running the script for quite a while without this problem. It's Flumine

*Tags: Deployment*

---

**Tom** - *12:19:03*

So if I am collecting prices on betfairlightweight (I have a bunch of data) would it have picked up the XM prices or just the user prices?



Then flumine would always be user prices without specifically changing it?



I've only just started working within the last sort of 30 minute period so hadn't seen this before or noticed discrepancies. Seems quite wild now this is a huge difference

*Tags: General Technical*

---

**Tom** - *12:47:26*

Yeah got it, was just confirming the default is also off for bflw.



Presume crossing spreads that you just get filled at the best price as well at all times?

*Tags: General Technical*

---

## 2024-08-11

**Dave** - *10:34:07*

just got caught out by flumine's patching of BFLW runner books to use dicts rather than PriceSize - imported flumine in a module which is shared by both my flumine and bflw-only strategies, forgot I did this import and spent a while figuring out why suddenly my bflw-only strategies were getting back [dict]

*Tags: General Technical*

---

**liam** - *11:40:48*

Sorry, it’s lazily patched but it’s worth the performance as it’s super slow creating all the PriceSize objects 

*Tags: Performance*

---

## 2024-08-19

**NAS** - *12:31:52*

having issues with cancelling certain orders despite setting force = True



the order status seems to be a flumine-thing and i thought setting force = True would avoid all checks against current logged status within the flumine instance, but this doesnt seem to be the case



any ideas?

`... - strategies - ERROR - OrderUpdateError - Issue while trying to cancel order ..., order status log: [&lt;OrderStatus.PENDING: 'Pending'&gt;, &lt;OrderStatus.EXECUTABLE: 'Executable'&gt;, &lt;OrderStatus.REPLACING: 'Replacing'&gt;], more info: Traceback (most recent call last):`

  `File "...", line 655, in process_orders`

    `market.cancel_order(order, force=True)`

  `File ".../site-packages/flumine/markets/market.py", line 97, in cancel_order`

    `return t.cancel_order(order, size_reduction, force)`

           `^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^`

  `File ".../site-packages/flumine/execution/transaction.py", line 101, in cancel_order`

    `order.cancel(size_reduction)`

  `File ".../site-packages/flumine/order/order.py", line 345, in cancel`

    `raise OrderUpdateError("Current status: %s" % self.status)`

`flumine.exceptions.OrderUpdateError: Current status: OrderStatus.REPLACING`

*Tags: Errors Debugging*

---

**NAS** - *13:12:02*

yess, but this replace was executed (i think successfully) long before this call. i get a similar error message over and over again for each update in the order stream from bf, with no other logic than the repeated retry of "cancel order" being applied to the particular order

*Tags: Errors Debugging*

---

**NAS** - *14:56:35*

fyi had equivalent/similar issues before setting force=True everywhere, was basically a quick-fix attempt

*Tags: Errors Debugging*

---

**Jorge** - *16:30:12*

Hi, am I correct that no login is required to be able to access the inplay_service, following the [https://github.com/betcode-org/betfair/blob/master/examples/exampleinplayservice.py|exampleinplayservice.py](https://github.com/betcode-org/betfair/blob/master/examples/exampleinplayservice.py|exampleinplayservice.py) ?

*Tags: General Technical*

---

## 2024-08-20

**Jorge** - *07:57:30*

Okay thanks. There is a [https://github.com/betcode-org/betfair/blob/master/examples/exampleinplayservice.py#L18|trading.login()](https://github.com/betcode-org/betfair/blob/master/examples/exampleinplayservice.py#L18|trading.login()) in the example so that's why I was not sure

*Tags: Strategies*

---

## 2024-08-23

**Unknown** - *04:43:16*

Hi, I have an issue regarding the total matched amount on a runner.

For whatever reason, some runners have a total matched volume of 0, whilst having a last price traded. I am not sure how this works given that for a last price traded to exist, a trade must have taken place and therefore the total matched must not be zero.

I am using runner.total_matched with the listener kwarg "cumulative_runner_tv": True

I have attached a zip folder containing a python file, sample market and log file that highlights the issue. Please have a look at the log file (LPT, total_matched columns) to see that some runners have total_matched = 0, and a non zero LPT value.

Thanks!

*Tags: General Technical*

---

**James** - *12:05:13*

I didn't use a key for the simulation. This is all I used to login:



client = clients.SimulatedClient()

framework = FlumineSimulation(client=client)

*Tags: General Technical*

---

**James** - *12:28:33*

I got it from Betfair Pro Historical data, AUS Greyhounds July 2024

*Tags: Data Quality*

---

## 2024-08-27

**Brøndby IF** - *21:04:40*

Good afternoon everyone, the same code that I have been using for a long time that works with `betfairlightweight`, today started generating this error (`'Retry' object has no attribute 'backoff_max'`) and I am unable to understand exactly what it means, could you help me with this?



```betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook 

Params: {'marketIds': ['1.232273246', '1.232273382', '1.232273176', '1.232273175', '1.232273174', '1.232354831', '1.232324555', '1.232273308', '1.232324557', '1.232326330'], 'priceProjection': {'priceData': ['EX_BEST_OFFERS', 'EX_TRADED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}} 

Exception: 'Retry' object has no attribute 'backoff_max'```

*Tags: Errors Debugging*

---

## 2024-08-28

**liam** - *09:01:47*

python version / what versions of requests/urllib3?

*Tags: General Technical*

---

## 2024-08-29

**Brøndby IF** - *14:23:03*

Hi [@U4H19D1D2](@U4H19D1D2) → Python 3.10.4 ||| requests==2.32.3 ||| urllib3==2.2.2

*Tags: General Technical*

---

**casper** - *15:33:23*

[@U4H19D1D2](@U4H19D1D2) I’m using poetry and when going from 2.20.1 to the latest 2.20.2 version it uninstalls ciso8601 module. I have the following line:

```betfairlightweight = { version = "2.20.2", extras = ["speed"], source = "pypi-store" }```

So simply bumping the version here uninstalls ciso8601 for me (one of the “speed” requirements). Going back to 2.20.1 installs ciso8601 again. Any ideas what might be happening?

*Tags: Getting Started, Performance*

---

**river_shah** - *15:47:10*

Some have drunk the koolaid and love it but it stung sufficient times to be removed with great joy:

[https://news.ycombinator.com/item?id=34005203](https://news.ycombinator.com/item?id=34005203)

```Somehow I became the "poetry guy" at work, and I spend a meaningful amount of time debugging shit for people because the environment somehow got corrupted or something. If there's no issues I guess it's fine (dependency resolution time notwithstanding), but when you experience a persistent bug or environment issue, it takes nothing short of expertise to figure out how to sort it out without losing half a day.```



*Tags: Errors Debugging*

---

## 2024-08-30

**Rob** - *19:21:51*

Probably something dumb that I've done, but moved working flumine strategy simulation code from my linux laptop to a windows desktop and I'm now getting the following error:



```  File "C:\Users\xxx\anaconda3\envs\bfai\lib\site-packages\flumine\simulation\simulation.py", line 34, in run

    with self:

  File "C:\Users\xxx\anaconda3\envs\bfai\lib\site-packages\flumine\baseflumine.py", line 450, in __enter__

    self.strategies.start(self)

  File "C:\Users\xxx\anaconda3\envs\bfai\lib\site-packages\flumine\strategy\strategy.py", line 279, in start

    s.start(flumine)

TypeError: EarlyBackLay.start() takes 1 positional argument but 2 were given```

where `EarlyBackLay` is strategy I've created. The exact same code (e.g. reverted back to the github branch on both) is still working fine on linux, all I've done is update the path for the stored market data  to be the location  on the windows machine.



Anyone got any ideas?

*Tags: Errors Debugging, Strategies*

---

**Lee** - *19:26:02*

you are running different versions of flumine 

*Tags: General Technical*

---

## 2024-09-01

**Dave** - *09:49:12*

Seeing some instances in flumine simulation where order remains "stuck" in Pending and eventually gets matched by the simulation engine. pending for > 60s of simulated time in some cases. Is this a known issue? Will try and dig deeper to see why but thought I'd ask first...



update: all good - misinterpretation of behaviour on my part. Didn't check closely enough so it looked like I had an order in Pending for many seconds, but actually I had just replaced at the same price and I was now inspecting an entirely new order. No issue with flumine :ok_hand:

*Tags: General Technical*

---

**Dave** - *13:18:08*

[@UPMUFSGCR](@UPMUFSGCR) good point, even though the simulation enters _process_market_book multiple times following placement of the order, the order.elapsed_seconds remains None and order state remains in Pending. Maybe there is some quirk in the recording such that flumine didn't consider placing the order into the book.



[@U4H19D1D2](@U4H19D1D2) yes I am, in this case setting a value for seconds_to_start and inplay=False.



I'll check how much the market has evolved between me placing an order, and e.g. 10s later when order is still "Pending"

*Tags: General Technical*

---

**Dave** - *17:14:39*

all good - misinterpretation of behaviour on my part. Didn't check closely enough so it looked like I had an order in Pending for many seconds, but actually I had just replaced at the same price and I was now inspecting an entirely new order. No issue with flumine :ok_hand:

*Tags: General Technical*

---

## 2024-09-11

**foxwood** - *19:38:40*

Trying to place a lot of bets all together using a transaction. Involves iterating through own runner data stored in market context and calling various functions which also refer to the market context. All that results in a run time error

```    with market.transaction as t: TypeError: 'method' object does not support the context manager protocol```

Is there any easy way of working around this without removing all context usage from the loop (tried removing context for top level of loop and worked ok but fails due to context use in deeper function calls which would be complex to refactor) - presume strategy context would have the same issues ?

*Tags: Errors Debugging, Strategies*

---

## 2024-09-14

**Unknown** - *06:47:52*

As a step in this direction, I have created the following PR: [https://github.com/betcode-org/flumine/pull/765|https://github.com/betcode-org/flumine/pull/765](https://github.com/betcode-org/flumine/pull/765|https://github.com/betcode-org/flumine/pull/765)



This adds a new listener kwarg `max_inplay_seconds` which caps the number of seconds after turning in play that updates will be processed. An example use case would be running a football strategy as part of CI only on the first 10 minutes of the match to minimise testing time

*Tags: Strategies*

---

## 2024-09-16

**Herugrim** - *02:41:42*

Question: If a Keep Alive is used and connections are not closed correctly, will they remain active until the Keep Alive duration expires? (And therefore increase the risk of MAX_CONNECTION_LIMIT_EXCEEDED errors? And if so, is there a function to end all active sessions?

*Tags: Errors Debugging, Deployment*

---

**liam** - *09:03:20*

[@UBS7QANF3](@UBS7QANF3) are you now a flumine user? (looking into this PR now)

*Tags: General Technical*

---

**Jemima Cecil** - *15:55:03*

Anyone have any issues with the Betfair API today?

*Tags: General Technical*

---

**liam** - *15:56:05*

One message is probably enough



Yeah looks like a listMarketBook issue which shouldn't be a problem for most :wink:



[https://status.developer.betfair.com/](https://status.developer.betfair.com/)

*Tags: General Technical*

---

## 2024-09-17

**Thomas Conti** - *02:45:39*

Hi everyone,

The issue arises when I try to dynamically add `market_ids` to the market stream. When I try to add new markets, the stream doesn't automatically refresh to include these new `market_ids`. Consequently, my strategy stops processing once the initially subscribed markets close. I need help with ensuring that the stream updates correctly with new markets during runtime.



 Any advice on how to add market_ids dynamically would be appreciated.

*Tags: Strategies*

---

**Mo** - *05:58:22*

That's not how streaming works. Use an appropriate filter, not specific market IDs

*Tags: General Technical*

---

**Thomas Conti** - *07:00:17*

When I do this without restricting market IDs, I get the error. What should I use to restrict the number of markets without picking market_ids?

Appreciate your help.



2024-09-17 15:14:34,927:ERROR:[MarketStream: 2006]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 206 markets whereas max allowed number was: 200



```strategy = LayStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["4339", '7'],  # Greyhound and Horse Racing

        country_codes=["AU", "NZ"],  # Australia and New Zealand

        market_types=["WIN"],  # Win markets

    )

)```



*Tags: Errors Debugging, Strategies*

---

**Mo** - *07:01:25*

Ask Betfair to increase your streaming limit to 1000 markets

*Tags: General Technical*

---

**Mo** - *07:03:21*

Alternatively, use 2 separate filters. For example:



```market_filter=[

    streaming_market_filter(

        event_type_ids=["4339"],  # Greyhounds

        country_codes=["AU", "NZ"],  # Australia and New Zealand

        market_types=["WIN"],  # Win markets

    ),

    streaming_market_filter(

        event_type_ids=["7"],  # Horse Racing

        country_codes=["AU", "NZ"],  # Australia and New Zealand

        market_types=["WIN"],  # Win markets

    ),

]```

*Tags: General Technical*

---

**Thomas Conti** - *07:04:27*

Thank you for your help. I will try this.

*Tags: General Technical*

---

**Thomas Conti** - *07:27:51*

Awesome. Thank you for clearing that up.

Thanks for your help again :+1:

*Tags: General Technical*

---

## 2024-09-18

**sartux** - *15:09:48*

good morning, I'm back to programming with betfairlightweight, but I wanted to ask you if the API policies have changed because I can no longer download the live odds

*Tags: Deployment*

---

**liam** - *15:27:46*

[https://github.com/betcode-org/betfair/blob/master/examples/exampleone.py](https://github.com/betcode-org/betfair/blob/master/examples/exampleone.py)

*Tags: General Technical*

---

## 2024-09-21

**Phydeaux** - *11:04:27*

£1k apparently… and that was the problem [@UUE6E1LA1](@UUE6E1LA1)! Thank you!



Don’t recall that setting existing, let alone setting it to such a figure! :woman-shrugging:  

*Tags: General Technical*

---

## 2024-10-03

**Matthew Lawrence** - *18:56:22*

Hi, I'm trying to login to betfair api. i have previously been using the interactive login. when I created a docker and access all files and parameters from amazon AWS, this login stops working and gives me ssl error. I'm a bit confused by this as i believed interactive login didnt require certs and ssl. i have since tried using the non interactive login but no matter what i get this error: Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3900)'))). Any help or advice would be greatly appreciated.

*Tags: Errors Debugging, Deployment*

---

**Derek C** - *20:07:19*

Hi Matthew, I don't know the answer to your problem, but if you shared the code you use to login and the dockerfile I think you'd have more chance of getting a response.

*Tags: General Technical*

---

**Matthew Lawrence** - *21:30:12*

I'm using this to test my login and it's not working:

```with open(r"C:\Users\matth\OneDrive\Documents\docker_scripts\Certs\credentials.json") as f:

    cred = json.load(f)

    my_username = cred["username"]

    my_password = cred["password"]

    my_app_key = cred["app_key"]



# Create an instance of the Custom Betfair API client

trading = betfairlightweight.APIClient(my_username, my_password, app_key=my_app_key,certs=r"C:\Users\matth\OneDrive\Documents\docker_scripts\Certs"

)



response = trading.login()

print("Login successful.")



# Get account information

balance = trading.account.get_account_funds(wallet="UK")

BANK = balance.available_to_bet_balance

print(f"Available to Bet Balance: {BANK}")```



*Tags: Strategies*

---

## 2024-10-04

**A** - *08:57:54*

This was my thought too.



You’ll probably want the certs path to be relative using `os` and ensure that the directory is somewhere relative in your flumine project and added in the container.

*Tags: General Technical*

---

## 2024-10-17

**NT** - *09:21:58*

Rookie question, is there a limit to how many times you can call trading.keep_alive()?



I am trying to keep my session alive to both: 1) read price data, and 2) make trades.



My strategy for doing this has been to: 1) call the keep alive endpoint and 2) use trading.keep_alive().



I'm pretty new to the betfairlightweights library, so sorry if I've missed something obvious on where to find this information!

*Tags: Getting Started, Deployment, Strategies*

---

**NT** - *09:24:34*

Perfect, thank you. I think my issue was calling it much more frequently than that. I really appreciate the help (and the incredibly fast reply!)

*Tags: General Technical*

---

**D C** - *09:27:25*

No worries. If you become familiar with the actual API operations that the flumine/bflw calls are a wrapper for, you can directly look up info for that within the BF docs or elsewhere.

*Tags: General Technical*

---

**D C** - *09:32:02*

I mean it's not compulsory as flumine/bflw does the hard work for you. Never hurts to understand what's going on at the betfair interface though.

*Tags: General Technical*

---

**NT** - *09:38:59*

Thanks. I've struggled to get the detail I wanted from those docs, but I'll give a close review along with the BFLW wrapper. Hopefully this solves my keep alive function issues!

*Tags: Deployment*

---

**liam** - *11:00:31*

Have you found [https://github.com/betcode-org/flumine|flumine](https://github.com/betcode-org/flumine|flumine) yet NT?

*Tags: General Technical*

---

**NT** - *11:32:30*

I have, I'm just not the greatest coder and need some time to figure out how to use it appropriately in my algorithm. Lack of coding skill is honestly probably the root cause of my keep alive issues too. Thankfully, other than the keep alive, the code is running quite well and generating profit.



It is definitely on my to do list to learn how to use flumine to get a stream reading of prices to a dataframe for use on my algorithm. It would save me having to call the BFLW API on a loop.

*Tags: Feature Engineering, Deployment*

---

**liam** - *11:33:30*

Ok, might be time to step back, why are you not [https://betcode-org.github.io/betfair/streaming/|streaming](https://betcode-org.github.io/betfair/streaming/|streaming)?

*Tags: General Technical*

---

**NT** - *11:44:15*

I simply just hadn't figured out how to yet. I'll have a look at this reference as it looks very detailed, and hopefully should be able to explain it. Getting streaming to work would be a huge help. Thanks for sharing this reference.

*Tags: General Technical*

---

## 2024-10-21

**NAS** - *21:19:41*

```betfairlightweight.exceptions.SocketError: [Connect: 1002]: Connection closed by server```

```2024-10-21 13:05:15,865 - flumine.streams.marketstream - INFO - Starting MarketStream 2001

2024-10-21 13:05:15,866 - betfairlightweight.streaming.listener - INFO - [Register: 2002]: Unique id updated on listener and stream

2024-10-21 13:05:15,985 - flumine.streams.marketstream - ERROR - MarketStream 2001 run error```

```2024-10-21 13:05:17,057 - flumine.streams.orderstream - INFO - Starting OrderStream 1001

2024-10-21 13:05:17,057 - betfairlightweight.streaming.listener - INFO - [Register: 1002]: orderSubscription

2024-10-21 13:05:17,057 - betfairlightweight.streaming.listener - WARNING - [Listener: 1002]: stream already registered, replacing data

2024-10-21 13:05:17,057 - betfairlightweight.streaming.stream - INFO - [OrderStream: 1002]: "OrderStream" created

2024-10-21 13:05:17,166 - flumine.streams.orderstream - ERROR - OrderStream 1001 run error```

idk if i've seen them before, but got a lot of them today? someone else? connections available.

*Tags: Errors Debugging, Deployment*

---

## 2024-10-22

**NAS** - *00:07:59*

tried launching the two instances on another computer & it worked



this was thrown during startup



```2024-10-22 01:05:17,751 - flumine.streams.streams - INFO - Starting streams..

2024-10-22 01:05:17,751 - flumine.streams.orderstream - INFO - Starting OrderStream 1000

2024-10-22 01:05:17,752 - flumine.streams.orderstream - INFO - Starting output_thread (OrderStream 1000)

2024-10-22 01:05:17,752 - betfairlightweight.streaming.listener - INFO - [Register: 1001]: orderSubscription

2024-10-22 01:05:17,752 - betfairlightweight.streaming.stream - INFO - [OrderStream: 1001]: "OrderStream" created

2024-10-22 01:05:17,910 - flumine.streams.orderstream - ERROR - OrderStream 1000 run error



ConnectionResetError: [Errno 54] Connection reset by peer



betfairlightweight.exceptions.SocketError: [Connect: 1001]: Socket [Errno 54] Connection reset by peer

2024-10-22 01:05:19,925 - flumine.streams.orderstream - INFO - Starting OrderStream 1000

2024-10-22 01:05:19,926 - betfairlightweight.streaming.listener - INFO - [Register: 1001]: orderSubscription

2024-10-22 01:05:19,926 - betfairlightweight.streaming.listener - WARNING - [Listener: 1001]: stream already registered, replacing data

2024-10-22 01:05:19,926 - betfairlightweight.streaming.stream - INFO - [OrderStream: 1001]: "OrderStream" created```

*Tags: Errors Debugging*

---

## 2024-10-24

**jp** - *13:40:36*

Good question, I was looking at the PT field for price updates, and comparing with the local time at my server

*Tags: Deployment*

---

## 2024-10-29

**Mo** - *16:03:35*

I think it would be helpful if you gave details on what these markets are

*Tags: General Technical*

---

**liam** - *16:40:01*

Why is this a problem / why are you mixing closed markets with live?

*Tags: Deployment*

---

## 2024-10-31

**frank** - *12:08:06*

Hi, I'm trying to login to betfair api. but this code, gives me an ssl error. :  `# Import libraries`

`import betfairlightweight`

`from betfairlightweight import filters`

`import pandas as pd`

`import numpy as np`

`import os`

`import datetime`

`import json`



`# Change this certs path to wherever you're storing your certificates`

`certs_path = r'C:\certs'`



`with open('credentials.json') as f:`

    `cred = json.load(f)`

    `my_username = cred['username']`

    `my_password = cred['password']`

    `my_locale= cred['locale']`

    `my_app_key = cred['app_key']`



`trading = betfairlightweight.APIClient(username=my_username,`

                                       `password=my_password,`

                                       `locale=my_locale,`

                                       `app_key=my_app_key,`

                                       `certs=certs_path)`



`trading.login()`   errorse is the following: `Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(524297, '[SSL] PEM lib (_ssl.c:3905)')))`  any help would be very appreciated. Thanks

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

**WilliamR** - *16:21:10*

I'm getting this exact issue with flumine Version: 2.6.6 sample code and betfairlightweight Version: 2.20.4 any tips on how I can resolve would be gratefully received!

*Tags: General Technical*

---

**WilliamR** - *16:26:28*

[https://betcode-org.github.io/flumine/](https://betcode-org.github.io/flumine/)

*Tags: General Technical*

---

**liam** - *16:27:05*

damn that is wrong, use the real examples



[https://github.com/betcode-org/flumine/tree/master/examples](https://github.com/betcode-org/flumine/tree/master/examples)

*Tags: General Technical*

---

**WilliamR** - *16:47:16*

thank you that's resolved!

*Tags: General Technical*

---

## 2024-11-01

**Unknown** - *19:03:25*

Hi all, I am receiving the following when trying to install flumine and create a marketrecorder. Any pointers to where I am going wrong would be really appreciated.

*Tags: Getting Started*

---

**Mo** - *19:20:26*

I mean the error message tells you exactly what to do 

*Tags: Errors Debugging*

---

**Gooat** - *19:56:44*

Python version?

*Tags: General Technical*

---

## 2024-11-04

**Lee** - *10:48:18*

Testing upgrades in production, nice

*Tags: Deployment*

---

**liam** - *10:56:03*

We have been complaining since the 28th when it started to get really bad, [@UUE6E1LA1](@UUE6E1LA1) has been complaining for a few years, maybe they will admit they have a problem 

*Tags: General Technical*

---

## 2024-11-05

**anomaly** - *06:22:40*

Hi all, quick question regarding betfairlightweight and getting market clarifications for the historical stream. For the live api when i query the APIClient object i have to specify the market_projection, like as follows



```        trading_client.login()

        market_catalogues= trading_client.betting.list_market_catalogue(

            ...

            market_projection=[

                'MARKET_START_TIME',

                'RUNNER_DESCRIPTION',  

                'MARKET_DESCRIPTION', 

            ],

            ...

            )```

and everything works as expected and i can access the clarifications.



Is it possible to also get the market catalogues for the historical streaming (like in examples/examplestreaminghistorical.py). I am only able to retrieve the marketbook right now and it's not clear how I would go about accessing the market catalogues (specifically, clarifications)



cheers!

*Tags: Deployment, Strategies*

---

**liam** - *06:46:19*

No there isn’t anything written however flumine has some code for storing them alongside recording your own historical data if that is what you are asking?

*Tags: Data Quality*

---

**Ulad** - *20:49:07*

Has anyone seen these errors for the streaming API?

```Connection to shard could not be established for message: {op='authentication'...```

*Tags: Errors Debugging*

---

## 2024-11-07

**Newbie99** - *10:00:48*

anyone else getting an exception for listClearedOrders, it keeps saying TOO MANY REQUESTS and I also notice that no P&amp;L is showing in the Betfair GUI, so possibly a problem (nothing showing yet on the outage page)?

*Tags: Errors Debugging*

---

**Unknown** - *10:04:30*

I've had intermittent issues with listClearedOrders for a week or so now. This is the error I've been getting though.

*Tags: Errors Debugging*

---

**tone** - *14:25:36*

Oh dear. The rollback obviously didn't help!

*Tags: General Technical*

---

**James** - *21:48:13*

ohhh I made a seemingly nothing change to handling cleared markets and I started getting errors and didnt have time to look into it. It was probably this too.

*Tags: Errors Debugging*

---

## 2024-11-08

**Unknown** - *20:53:26*

Good afternoon, everyone. One question:



In `betfairlightweight` we have the `filters.market_filter` options for `inplay_only` where we define whether we want only inplay events or all of them.



I noticed that in the API-NG Visualizer you can choose the `NO` option to only get events that are not yet inplay.



Is it also possible to do this in betfairlightweight?



I've already tried using `market_start_time` but in Tennis several games daily escape this option because the matches change their kick-off hour a lot.

*Tags: General Technical*

---

**liam** - *20:55:52*

What endpoint or you referring to streaming?

*Tags: General Technical*

---

**Brøndby IF** - *21:17:22*

Ah [@U4H19D1D2](@U4H19D1D2), I read on `betfairlightweight` that I could set it to `TRUE` or leave it disabled (`in_play_only: restriction to currently inplay, not supplied returns all.`), I was afraid of setting it to `FALSE` and generating a block or error in the request, so can I use `FALSE`?



Request data:

[{"jsonrpc": "2.0", "method": "SportsAPING/v1.0/listMarketCatalogue", "params": {"filter":{"eventTypeIds":["2"],"inPlayOnly":false},"maxResults":"1"}, "id": 1}]

*Tags: Errors Debugging*

---

**Brøndby IF** - *21:19:27*

I believe it was an error on my part in interpreting the text, there is nothing that prohibits the use of FALSE, it is my complete ignorance.

*Tags: Errors Debugging*

---

**Brøndby IF** - *21:34:40*

[@U4H19D1D2](@U4H19D1D2) Thank you very much for your help, I already set it to False and it perfectly removed a event that managed to get through the kick-off hour filter. Battle completed successfully!

*Tags: General Technical*

---

## 2024-11-09

**D C** - *16:59:47*

Yeah I'm cutting stakes right back until this is resolved as it's close to unusable. On the plus side this will force me to concentrate on other areas.

*Tags: General Technical*

---

## 2024-11-27

**Tom** - *05:10:53*

Hi Guys. I've got a problem here I can't solve but instead of trying to describe it I'll try be more direct.

1. Does market_book.is_market_data_delayed work? (If Betfair have delayed my data will it show up here?)

2. Is it appropriate to compare market_book.publish_time with current utc time and call anything more than 2 minutes delayed? 

3. Do you have any suggestions on how to manage this?

*Tags: General Technical*

---

**Tom** - *08:24:56*

python(?) (Flumine)

Win markets Australian Horseracing.



I think it's linked to some of my order placing behaviour, because there are some cancel/place loops with another algo I've been trying to sort out

*Tags: General Technical*

---

**liam** - *08:31:20*

whats a server/API rule? The logs will tell you if your code is the problem re the latency warnings

*Tags: Performance, Deployment*

---

**Tom** - *08:32:30*

There are no errors or warning anywhere

*Tags: Errors Debugging*

---

**liam** - *08:33:29*

this sounds like your code, and you are 100% not getting any latency warnings?

*Tags: Performance*

---

**liam** - *08:34:27*

i am 100% sure flumine code is good

*Tags: General Technical*

---

**Tom** - *08:34:43*

Exactly that's why I think its the betfair API/Server

*Tags: Deployment*

---

**Tom** - *08:39:00*

Something like this has been going on for a while and I've checked it then. I'll take another look. It's sending BSP orders now which doesn't happen when this problem occurs. It'll literally hold onto a 10+min old book.



What are the chances it's a try except loop retaining some old book and never letting go of it? I've noticed they are horrible with random erros.

*Tags: General Technical*

---

**Tom** - *08:39:24*

Remember we were discussing the cross-market orders a while back? I just started using the cross market prices anyway. But this is the same problem.

*Tags: General Technical*

---

**liam** - *08:48:02*

To confirm you have logging setup, no latency warnings, just all logs stop whilst you receive stale market books?

*Tags: Getting Started, Performance*

---

**Tom** - *08:48:23*

it runs code with no errors no warnings and old books

*Tags: Errors Debugging*

---

**Tom** - *08:49:38*

I'm going to remove all the try except blocks. Do you guys use them? There is definitely a problem with them for me.



Like it's creating copies of things and referring back to the wrong copy later

*Tags: General Technical*

---

**liam** - *08:50:34*

:man-shrugging: your hinting at some dodgy stuff but without seeing code to replicate I have no idea and its impossible for anyone to help

*Tags: General Technical*

---

**Tom** - *08:53:40*

Right. Sorry, not trying to be tricky or anything. I'll remove them all and let you know if I see the problem again. I've had this problem a long time now.



There's nothing really to share in the way of code, it's not clearly from anywhere in particular.



Today I put a try except block around storing my order in a trade object; and after just didn't recognise the event and started spitting out multiple orders of the same trade (didn't recognise it already had one)



Are you supposed to return the object in OOP, or just run the method and assume the change has been made universally?



It could also be the try, except plus also returning something incorrectly (?) I'm obviously speculating heavily here I have no idea

*Tags: General Technical*

---

**Tom** - *09:16:57*

2024-11-27 20:15:14,594 [INFO] __main__: Checking market book for market 1.236496631

2024-11-27 20:15:14,594 [DEBUG] __main__: UTC time now is 2024-11-27 09:15:14.594654+00:00

2024-11-27 20:15:14,594 [DEBUG] __main__: Market book publish time is 2024-11-27 09:13:04.942000

2024-11-27 20:15:14,594 [DEBUG] __main__: Market book publish time converted to UTC: 2024-11-27 09:13:04.942000+00:00

2024-11-27 20:15:14,594 [DEBUG] __main__: Time difference: 0:02:09.652654

2024-11-27 20:15:14,595 [WARNING] __main__: Market is more than 2 minutes out of sync with the current time.



So this is all I see when the book is delayed, this is through a method I put at the top of check_market

*Tags: Errors Debugging*

---

**liam** - *09:17:33*

where are the flumine logs?

*Tags: General Technical*

---

**Tom** - *09:48:52*

2024-11-27 20:43:25,730 [DEBUG] __main__: Found order: Order 369539252565: Execution complete. Status: OrderStatus.EXECUTION_COMPLETE

2024-11-27 20:43:25,731 [DEBUG] __main__: Found order: Order 369539257045: Execution complete. Status: OrderStatus.EXECUTION_COMPLETE

2024-11-27 20:43:25,731 [DEBUG] __main__: Found order: Order 369541038302: Execution complete. Status: OrderStatus.EXECUTION_COMPLETE

2024-11-27 20:43:25,731 [ERROR] __main__: Print Marketbook delayed None

2024-11-27 20:43:25,731 [ERROR] __main__: Cross matching is False

2024-11-27 20:43:25,731 [ERROR] __main__: Version is 6300260619

2024-11-27 20:43:25,731 [ERROR] __main__: Market staleness check returned None.

2024-11-27 20:43:25,731 [WARNING] flumine.baseflumine: High latency between current time and MarketBook publish time

2024-11-27 20:43:25,731 [INFO] flumine.baseflumine: Adding: 1.236494334 to markets

2024-11-27 20:43:25,732 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): [http://api.betfair.com:443|api.betfair.com:443](http://api.betfair.com:443|api.betfair.com:443)

2024-11-27 20:43:25,803 [DEBUG] urllib3.connectionpool: [https://api.betfair.com:443](https://api.betfair.com:443) "POST /exchange/betting/json-rpc/v1 HTTP/11" 200 2392

2024-11-27 20:43:25,806 [INFO] root: OrdersMiddleware: Processing order 369500134776

2024-11-27 20:43:25,807 [INFO] root: OrdersMiddleware: New order trade created

2024-11-27 20:43:25,808 [INFO] flumine.order.order: Order status update: Execution complete

2024-11-27 20:43:25,808 [INFO] flumine.order.trade: Trade status update: Complete

2024-11-27 20:43:25,808 [INFO] root: OrdersMiddleware: Processing order 369502827322

2024-11-27 20:43:25,808 [INFO] root: OrdersMiddleware: New order trade created



Ok I wasn't logging very effectively. This is coming up inbetween running markets for the first time. The problem occurs after running a while as well though.



What kind of logs will be useful to see? Startup logs look normal

*Tags: Getting Started, Errors Debugging, Performance, Strategies*

---

**liam** - *09:53:33*

and i can already see a latency warning, what is `OrdersMiddleware`?

*Tags: Performance*

---

**foxwood** - *10:46:33*

That one latency message comes from _process_market_books() - if there were true latency on the stream I'd expect to see loads of standard bflw messages of the form "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 0.60121750831604". Possible application loops not getting back to process_market_book in time ? Try profiling or putting more traces in.

*Tags: Performance*

---

**Mo** - *15:18:47*

In flumine, what's the canonical way to check if a runner has either a live order or a filled order?

*Tags: Deployment*

---

**liam** - *15:36:09*

`market.blotter.strategy_selection_orders` is probably the cleanest but using the `runner_context` will be slightly quicker



[https://github.com/betcode-org/flumine/blob/a9cd71befc6062b52ce65ca695b50a56a2e81344/flumine/markets/blotter.py#L73](https://github.com/betcode-org/flumine/blob/a9cd71befc6062b52ce65ca695b50a56a2e81344/flumine/markets/blotter.py#L73)

*Tags: Strategies*

---

**Mo** - *15:48:32*

Something like



```if any(

    order.status in LIVE_STATUS or order.size_matched &gt; 0

    for order in market.blotter.strategy_selection_orders(

        self, selection_id, 0

    )

):

    # Do cool shit```

?

*Tags: Deployment, Strategies*

---

**liam** - *15:58:23*

yeah or



```if market.blotter.strategy_selection_orders(self, selection_id, 0, order_status=LIVE_STATUS):

    # cook```

*Tags: Deployment, Strategies*

---

**Tom** - *21:50:34*

That's just rude. OrdersMiddleware is from Flumine/Examples. There's just not a clear sign of what it is. I am going to look at libraries/dependencies.

*Tags: General Technical*

---

## 2024-11-28

**anomaly** - *01:05:10*

Quick question, i've got my marketbook stream working on bflw



```self.streaming_unique_id = self.stream.subscribe_to_markets(

    market_filter=self.market_filter,

    market_data_filter=self.market_data_filter,

    conflate_ms=self.conflate_ms,

    initial_clk=self.listener.initial_clk,  # supplying these two values allows a reconnect

    clk=self.listener.clk,  # supplying these two values allows a reconnect

)```

where



```self.market_data_filter = filters.streaming_market_data_filter(fields=self.price_projection_filters,

                                                               ladder_levels=3

                                                               )```

and



```self.price_projection_filters = ['EX_BEST_OFFERS',

                                 'EX_MARKET_DEF',

                                 'EX_TRADED_VOL',

                                 ]```

however when i check a specific runner (or market) which i can see on the exchange has got traded volume, i always get a value of 0



mb.total_matched = 0

mb.total_available = None

mb.runners[7].ex.traded_volume = [] # e.g. looking at the exchange now it has a value of 42

mb.runners[7].total_matched = 0



all other exchange price/sizes are there so not quite sure what i'm missing

*Tags: General Technical*

---

**liam** - *07:54:35*

Tbh you have to be when debugging something like this, people never give you all the information and they never tell you the truth

*Tags: Errors Debugging*

---

## 2024-11-29

**anomaly** - *01:14:51*

ok well consider this solved. i have no clue what happened but it's just working now:thinking_face:

*Tags: General Technical*

---

## 2024-11-30

**NT** - *19:02:51*

Hi All,



Is there a common reason for "BET_ACTION_ERROR" to be triggered? I've adjusted my code to incorporate a 'greening up' process and reduce the variance of payouts across outcomes in a given market, and find that some of these orders are being rejected with no further error message provided (but some are being processed). These are typically small $0.01 orders, so I am wondering if that is the driver, but thought I'd see if anyone here knew more as it isn't a particularly informative error. The inconsistent nature of this is making finding a common pattern tougher.



Cheers

*Tags: Errors Debugging*

---

**liam** - *19:52:22*

Likely to be the 0.01 / zero liability handling, I thought the error message normally gives more info however you shouldn’t be ‘greening’ we don’t allow that chat here  

*Tags: Errors Debugging*

---

**liam** - *20:14:32*

Check the full error message, it will only be on low prices (sub 1.5?)

*Tags: Errors Debugging*

---

**NT** - *20:26:42*

Thanks, I'll look through and see if this is the pattern (and if there are any error messages that extend beyond the "BET_ACTION_ERROR". Appreciate the help

*Tags: Errors Debugging*

---

## 2024-12-01

**foxwood** - *10:51:40*

Tiny bets at wrong price/stake combo are supposed to trigger

```INVALID_PROFIT_RATIO```

error eg if you want to place £0.01 bet then minimum odds are 1.81 and if you want 1.01 then min stake is £0.80 - all following BF formula. According to docs there is a meaningful error code for BET_ACTION_ERROR ... "There is an error with an action that has caused the entire order to be rejected. Check the instructionReports errorCode for the reason for the rejection of the order."

*Tags: Errors Debugging*

---

## 2024-12-02

**foxwood** - *09:31:00*

Yes that would break - been there lol - also seems to be currency conversion involved since quoted $0.01. But as you "rudely" said in another post the devil is in the secret details and getting the right info like the error code to diagnose :wink:

*Tags: Errors Debugging*

---

**tone** - *09:43:42*

Is anybody seeing a recurrence of the "Unable to find appKey" error when logging on to race_card?

*Tags: Errors Debugging*

---

**liam** - *09:44:57*

[https://github.com/betcode-org/betfair/blob/master/HISTORY.rst#2203-2024-09-03|Upgrade](https://github.com/betcode-org/betfair/blob/master/HISTORY.rst#2203-2024-09-03|Upgrade)

*Tags: General Technical*

---

**tone** - *10:42:24*

Hmmm. Upgraded to flumine-2.6.8 but still getting the error.

*Tags: Errors Debugging*

---

**liam** - *10:42:39*

bflw version?

*Tags: General Technical*

---

**tone** - *10:42:57*

betfairlightweight==2.20.4

*Tags: General Technical*

---

**liam** - *10:44:52*

print the bflw version in the same code you are asking for the key

*Tags: General Technical*

---

**tone** - *10:49:17*

in the code bflw is 2.19.1!

*Tags: General Technical*

---

**liam** - *10:51:38*

as linked, the fix was pushed in 2.20.3

*Tags: Errors Debugging*

---

**tone** - *10:53:43*

I think that's the problem. Accidentally upgraded outside the venv

*Tags: General Technical*

---

**NT** - *18:42:41*

Quick update: strangely, at $0.01, there was no clear pattern on which bets were filled or not (occasionally lower price bets were filled and higher price bets were not). Updating the bet size to $0.03 seems to have eliminated the problem, although it has only been running for 7.5 hours now so the issue could potentially re-emerge over a longer run period.

*Tags: General Technical*

---

## 2024-12-12

**ian mcneill** - *21:03:31*

Hi - apologies noob noob trying to reboot attempts at this. I have a fail when trying to install flumine  as output below shows. I will read line by line and try to resolve myself but if anyone can ident my idiocity easily and point me in the right direction, that's great - I'll keep this window open :wink:



Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)

Building wheels for collected packages: pydantic-core

  Building wheel for pydantic-core (pyproject.toml) ... error

  error: subprocess-exited-with-error



  × Building wheel for pydantic-core (pyproject.toml) did not run successfully.

  │ exit code: 1

  ╰─&gt; [115 lines of output]

      Running `maturin pep517 build-wheel -i /Users/ian/miniconda3/envs/fex/bin/python --compatibility off`

      :package: Including license file "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/LICENSE"

      :tropical_drink: Building a mixed python/rust project

      :link: Found pyo3 bindings

      :snake: Found CPython 3.13 at /Users/ian/miniconda3/envs/fex/bin/python

      :satellite_antenna: Using build options features, bindings from pyproject.toml

      :computer: Using `MACOSX_DEPLOYMENT_TARGET=11.0` for aarch64-apple-darwin by default

         Compiling autocfg v1.1.0

         Compiling proc-macro2 v1.0.76

         Compiling unicode-ident v1.0.10

         Compiling target-lexicon v0.12.9

         Compiling python3-dll-a v0.2.9

         Compiling libc v0.2.147

         Compiling once_cell v1.18.0

         Compiling version_check v0.9.4

         Compiling cfg-if v1.0.0

         Compiling static_assertions v1.1.0

         Compiling heck v0.4.1

         Compiling zerocopy v0.7.32

         Compiling parking_lot_core v0.9.8

         Compiling rustversion v1.0.13

         Compiling scopeguard v1.1.0

         Compiling lexical-util v0.8.5

         Compiling allocator-api2 v0.2.16

         Compiling smallvec v1.11.2

         Compiling tinyvec_macros v0.1.1

         Compiling serde v1.0.195

         Compiling tinyvec v1.6.0

         Compiling memchr v2.6.3

         Compiling equivalent v1.0.1

         Compiling unicode-bidi v0.3.13

         Compiling regex-syntax v0.8.2

         Compiling ahash v0.8.7

         Compiling num-traits v0.2.16

         Compiling num-integer v0.1.45

         Compiling lock_api v0.4.10

         Compiling memoffset v0.9.0

         Compiling num-bigint v0.4.4

         Compiling lexical-write-integer v0.8.5

         Compiling lexical-parse-integer v0.8.6

         Compiling unicode-normalization v0.1.22

         Compiling lexical-write-float v0.8.5

         Compiling lexical-parse-float v0.8.5

         Compiling aho-corasick v1.0.2

         Compiling indoc v2.0.4

         Compiling serde_json v1.0.109

         Compiling percent-encoding v2.3.1

         Compiling unindent v0.2.3

         Compiling form_urlencoded v1.2.1

         Compiling regex-automata v0.4.3

         Compiling lexical-core v0.8.5

         Compiling idna v0.5.0

         Compiling ryu v1.0.14

         Compiling itoa v1.0.8

         Compiling uuid v1.6.1

         Compiling base64 v0.21.7

         Compiling url v2.5.0

         Compiling regex v1.10.2

         Compiling quote v1.0.35

         Compiling syn v2.0.48

         Compiling pyo3-build-config v0.20.2

         Compiling getrandom v0.2.10

         Compiling parking_lot v0.12.1

         Compiling hashbrown v0.14.3

         Compiling pyo3-ffi v0.20.2

         Compiling pyo3 v0.20.2

         Compiling pydantic-core v2.16.3 (/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571)

         Compiling indexmap v2.0.0

      error: failed to run custom build command for `pydantic-core v2.16.3 (/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571)`



      Caused by:

        process didn't exit successfully: `/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/target/release/build/pydantic-core-39a2e9245b501e5a/build-script-build` (exit status: 101)

        --- stdout

        cargo:rustc-cfg=Py_3_6

        cargo:rustc-cfg=Py_3_7

        cargo:rustc-cfg=Py_3_8

        cargo:rustc-cfg=Py_3_9

        cargo:rustc-cfg=Py_3_10

        cargo:rustc-cfg=Py_3_11

        cargo:rustc-cfg=Py_3_12

        cargo:rustc-cfg=Py_3_13

        cargo:rerun-if-changed=python/pydantic_core/core_schema.py

        cargo:rerun-if-changed=generate_self_schema.py



        --- stderr

        Traceback (most recent call last):

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 192, in eval_forward_ref

            return type_._evaluate(core_schema.__dict__, None, set())

                   ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

        TypeError: ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'



        During handling of the above exception, another exception occurred:



        Traceback (most recent call last):

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 240, in &lt;module&gt;

            main()

            ~~~~^^

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 210, in main

            value = get_schema(s, definitions)

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 54, in get_schema

            return type_dict_schema(obj, definitions)

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 152, in type_dict_schema

            field_type = eval_forward_ref(field_type)

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 195, in eval_forward_ref

            return type_._evaluate(core_schema.__dict__, None)

                   ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^

        TypeError: ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'

        thread 'main' panicked at [http://build.rs:29:9|build.rs:29:9](http://build.rs:29:9|build.rs:29:9):

        generate_self_schema.py failed with exit status: 1

        note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

      warning: build failed, waiting for other jobs to finish...

      :boom: maturin failed

        Caused by: Failed to build a native library through cargo

        Caused by: Cargo build finished with "exit status: 101": `env -u CARGO MACOSX_DEPLOYMENT_TARGET="11.0" PYO3_ENVIRONMENT_SIGNATURE="cpython-3.13-64bit" PYO3_PYTHON="/Users/ian/miniconda3/envs/fex/bin/python" PYTHON_SYS_EXECUTABLE="/Users/ian/miniconda3/envs/fex/bin/python" "cargo" "rustc" "--features" "pyo3/extension-module" "--message-format" "json-render-diagnostics" "--manifest-path" "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/Cargo.toml" "--release" "--lib" "--crate-type" "cdylib" "--" "-C" "link-arg=-undefined" "-C" "link-arg=dynamic_lookup" "-C" "link-args=-Wl,-install_name,@rpath/pydantic_core._pydantic_core.cpython-313-darwin.so"`

      Error: command ['maturin', 'pep517', 'build-wheel', '-i', '/Users/ian/miniconda3/envs/fex/bin/python', '--compatibility', 'off'] returned non-zero exit status 1

      [end of output]



  note: This error originates from a subprocess, and is likely not a problem with pip.

  ERROR: Failed building wheel for pydantic-core

Failed to build pydantic-core

ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pydantic-core)

*Tags: Getting Started, Errors Debugging, Feature Engineering, Deployment*

---

**liam** - *21:06:54*

Python 3.13 is not supported, was this not discussed last time?

*Tags: General Technical*

---

## 2024-12-19

**moseley82** - *09:11:56*

Hey guys hoping this will be a super simple one, I'm trying to add total_matched into my streaming output but I'm just getting 0's for everything... is there something I'm missing?

*Tags: General Technical*

---

**liam** - *09:54:35*

you have literally shown everything but the streaming filter

*Tags: General Technical*

---

**Unknown** - *09:55:48*

Streaming filter

*Tags: General Technical*

---

## 2024-12-20

**tone** - *15:13:14*

*** I don't like cricket ***

Hi all, I get a warning: "No markets or events found for strategy cricket" trying to simulate a cricket market in Flumine.

The market is Melbourne Stars vs Brisbane Heat from a few days ago which I recorded using MarketRecorder.

Any help would be greatly appreciated.

class ExampleStrategy(BaseStrategy):

   def check_sports_data(self, market, sports_data) -&gt; None:

       print(market, sports_data)

       return True



   def process_market_book(self, market, market_book):

       print(market_book)



 client = clients.SimulatedClient()

 framework = FlumineSimulation(client=client)



 folder = "D:/test/"

 sports_folder = folder+"sportsdata"

 market = folder+"1.237252156"

 framework.add_market_middleware(

   SimulatedSportsDataMiddleware("cricketSubscription", sports_folder)

 )



 strategy = ExampleStrategy(

   name="cricket",

   market_filter=streaming_market_filter(

       market_ids=[market],

   ),

 )



 framework.add_strategy(strategy)

 framework.run()

*Tags: Strategies*

---

**tone** - *15:19:42*

let me fix it

*Tags: Errors Debugging*

---

**tone** - *15:45:08*

Fixed! I found the example you are referring to and it worked straight away. The filter was screwing it up. Thanks Liam, as always!

*Tags: Errors Debugging*

---

**liam** - *15:52:33*

That strategy even shows a profit on that market :joy: 

*Tags: Strategies*

---

## 2024-12-29

**WilliamR** - *09:42:14*

Hi I've started getting the following error complaining about an invalid session seems intermittent and program still runs and places bets.... should I be worried?:



 File "D:\Users\willi\anaconda3\Lib\site-packages\flumine\worker.py", line 126, in poll_market_catalogue

    market_catalogues = client.betting_client.betting.list_market_catalogue(

                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "D:\Users\willi\anaconda3\Lib\site-packages\betfairlightweight\endpoints\betting.py", line 233, in list_market_catalogue

    (response, response_json, elapsed_time) = self.request(method, params, session)

                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "D:\Users\willi\anaconda3\Lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 54, in request

    self._error_handler(response_json, method, params)

  File "D:\Users\willi\anaconda3\Lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 80, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue

Params: {'filter': {'marketIds': ['1.237584679', '1.237584668', '1.237584666', '1.237584713', '1.237582001', '1.237584706', '1.237584674', '1.237582040', '1.237584707', '1.237584715', '1.237584714', '1.237582041', '1.237584699', '1.237611936', '1.237611941', '1.237611968', '1.237611961', '1.237611945', '1.237611955']}, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'maxResults': 25}

Exception: None

Error: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang06a-prd-11260945-00381f34ac', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang06a-prd-11260945-00381f34ac', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}

2024-12-29 09:41:16,405:INFO:162:Client update account details

2024-12-29 09:41:18,027:INFO:263:Updated marketCatalogue for 1.237613210

*Tags: Errors Debugging, Strategies*

---

## 2024-12-30

**Paul** - *10:37:46*

The error is `INVALID_SESSION_INFORMATION` which suggests the credentials used to get the market catalogue here are stale (which happens after ~24 hours).

*Tags: Errors Debugging*

---

**Paul** - *10:38:32*

flumine handles this automatically, but perhaps in your scenario it isn't for some reason. Doing anything funky?

*Tags: General Technical*

---

## 2025-01-01

**Victor Hugo Oliveira** - *11:13:19*

good morning guys and happy new year!

the url to login into betfair in brazil has changed, now the new one is [https://www.betfair.bet.br](https://www.betfair.bet.br) how can i update it to request on the API betfairlightweight? I saw that some countries as italy and australia have an option to add "locale="

*Tags: General Technical*

---

**Brøndby IF** - *11:24:46*

I'm facing this same scenario (at least with this change we didn't lose the App Key like we did when we changed from Dollar to BRL), I hope they can help us because I'm completely lost and don't know what to do.

*Tags: General Technical*

---

**Unknown** - *12:05:30*

It seems to me that they are doing some tests, some test events appeared in the list of events and before when trying to request a return in the API, it generated an unknown error in [https://apps.betfair.bet.br/visualisers/api-ng-sports-operations/](https://apps.betfair.bet.br/visualisers/api-ng-sports-operations/), now the results are appearing normally without the need to choose an option in "Locale" because there is no option "Brazil" in the list.

*Tags: Errors Debugging*

---

**Brøndby IF** - *12:17:07*

When requesting via API-NG Visualizer, locale="pt_BR" appears in the request Cookies, I tried to use it in the direct request with the API and also via betfairlightweight but without success, it continues to generate the same locale authorization error.

*Tags: Errors Debugging*

---

**Gabriel Mocan** - *14:20:30*

I’m also stuck here.



Getting AUTHORIZED_ONLY_FOR_DOMAIN error when trying to non-interactive login.

*Tags: Errors Debugging*

---

**Victor Hugo Oliveira** - *14:31:11*

I'm getting the same error as you [@U07AK2APF2B](@U07AK2APF2B)

*Tags: Errors Debugging*

---

**Lee** - *15:08:13*

&gt; Hi,

&gt; 

&gt; Today, I received a message from Neil Thomas (API Product Specialist | Betfair) regarding the discontinuation of the Betfair Exchange API for Brazilian customers due to regulatory changes. I am a developer in Brazil and have built my own interface to place bets using the Betfair Exchange API.

&gt; 

&gt; The message states:

&gt; 

&gt; "Olá. Devido a mudanças regulatórias, a partir de 1 de Janeiro de 2025, não forneceremos mais acesso à API pessoal para clientes brasileiros até novo aviso. Isso significa que, a partir de 1 de Janeiro de 2025, suas chaves de aplicação existentes serão desativadas e você não poderá mais acessar a API da Betfair Exchange usando suas chaves de aplicação. Se essa situação mudar, avisaremos você diretamente."

&gt; 

&gt; This raises significant concerns for me as a developer. I would appreciate your advice on the following:

&gt; Will Betfair consider offering a commercial license for developers or professional bettors to continue using their own betting interfaces?

&gt; Is this a definitive decision, or are there ongoing discussions that might provide further updates in the near future?

&gt; 

&gt; Any guidance you can provide would be greatly appreciated as I assess how to adapt my work moving forward.

&gt; 

&gt; Thank you for your time and support.

*Tags: Strategies*

---

**Brøndby IF** - *15:15:22*

[@UUE6E1LA1](@UUE6E1LA1) and [@UUCD6P13J](@UUCD6P13J) I think they changed their mind, because the keys are all active and through the API-NG Visualiser the requests are working perfectly, but using Python they are not working at all (at least not for now).



Add: [@UUCD6P13J](@UUCD6P13J) thanks a lot to share!

*Tags: General Technical*

---

**Lee** - *15:18:57*

If you want to test adding the tlds that can be done [https://github.com/betcode-org/betfair/blob/master/betfairlightweight/baseclient.py|here](https://github.com/betcode-org/betfair/blob/master/betfairlightweight/baseclient.py|here) 

*Tags: General Technical*

---

**Brøndby IF** - *15:35:11*

[@UUCD6P13J](@UUCD6P13J) thanks! In this case, here in Brazil, it was changed from `.com` to `.[http://bet.br|bet.br](http://bet.br|bet.br)` and the `locale` in the Cookie appears as `pt_BR`



I'm going to research to learn how to edit an installed library using pip because I have no idea how to do it. Haha

*Tags: Getting Started*

---

**Brøndby IF** - *15:50:26*

I hope that some of the Brazilian users who see this chat have the necessary knowledge to perform these tests and help us more accurately, my knowledge is considerably limited.

*Tags: General Technical*

---

**Brøndby IF** - *20:42:20*

[@U07AK2APF2B](@U07AK2APF2B) hi! How did you do this on betfairlightweight? Did you copy the entire library manually to your computer or is there another way?

*Tags: General Technical*

---

**Gabriel Mocan** - *20:43:36*

Sadly I don’t use betfairlightweight. But I think it’s an easy task, right? [@U4H19D1D2](@U4H19D1D2)

*Tags: General Technical*

---

**Brøndby IF** - *20:50:39*

[@U07AK2APF2B](@U07AK2APF2B) I have several projects that have been running for a long time, but at the moment I had to deactivate everything, because I created them all on betfairlighiweight and my knowledge is very limited and I have no idea how I would be able to change this on my own.



I'm hoping [@U4H19D1D2](@U4H19D1D2) can help us with this.

*Tags: General Technical*

---

**Brøndby IF** - *21:02:50*

[@U4H19D1D2](@U4H19D1D2) I tried doing like this:



```def login() -> APIClient:

    trading = betfairlightweight.APIClient(

        ..., ..., app_key=..., 

        cert_files=('./betfair_brl_certs/myAppBrl.crt','./betfair_brl_certs/myAppBrl.pem'), 

        session=requests.Session()

    )

    trading.api_uri = "[https://api.betfair.bet.br/exchange/](https://api.betfair.bet.br/exchange/)"

    trading.login()

    return trading```

And returned the error:



`betfairlightweight.exceptions.LoginError: API login: AUTHORIZED_ONLY_FOR_DOMAIN`

*Tags: Errors Debugging, Strategies*

---

**liam** - *21:05:32*

No, just read the code 



[https://github.com/betcode-org/betfair/blob/5bd97eaac20a06188f59e6128249134187717d6b/betfairlightweight/baseclient.py#L87|https://github.com/betcode-org/betfair/blob/5bd97eaac20a06188f59e6128249134187717d6b/betfairlightweight/baseclient.py#L87](https://github.com/betcode-org/betfair/blob/5bd97eaac20a06188f59e6128249134187717d6b/betfairlightweight/baseclient.py#L87|https://github.com/betcode-org/betfair/blob/5bd97eaac20a06188f59e6128249134187717d6b/betfairlightweight/baseclient.py#L87)

*Tags: General Technical*

---

**Brøndby IF** - *21:17:27*

[@U07AK2APF2B](@U07AK2APF2B) and [@U4H19D1D2](@U4H19D1D2)



```    trading.api_uri = "[https://api.betfair.bet.br/exchange/](https://api.betfair.bet.br/exchange/)"

    trading.identity_uri = "[https://identitysso.betfair.bet.br/api/](https://identitysso.betfair.bet.br/api/)"

    trading.identity_cert_uri = "[https://identitysso-cert.betfair.bet.br/api/](https://identitysso-cert.betfair.bet.br/api/)"```

Adding these three lines when logging in, everything seems to have worked perfectly again. I'll do some testing and I will bring the final feedback. Thank you very much for your help!

*Tags: Strategies*

---

**Unknown** - *23:22:29*

a few refreshes per hour, far from rate limit. Maybe it’s just a bug and they’ll fix it.

*Tags: Errors Debugging*

---

**Brøndby IF** - *23:54:51*

[@U07AK2APF2B](@U07AK2APF2B) I used to do the same thing as you, creating a new one whenever another one reached the limit and generated the error, but honestly I get a bit anxious seeing several sessions started in the account history there at Betfair. So I decided to unify the session for all projects and created an exclusive trigger in one of the codes for keep-alive, so several days go by and a single session appears in the history, even helping me to monitor a possible account hack or something like that.

*Tags: Errors Debugging, Deployment*

---

## 2025-01-04

**JL** - *13:58:30*

How would one identify if a greyhound race is handicap or not from flumine?

*Tags: General Technical*

---

## 2025-01-05

**Guilherme Scherner** - *15:28:59*

hi everyone,

I'm encountering an issue with our integration due to recent changes in Brazil. Here's the error I'm receiving:

```{

  "jsonrpc": "2.0",

  "error": {

    "code": -32099,

    "message": "ANGX-0007",

    "data": {

      "APINGException": {

        "requestUUID": "ie1-ang28b-prd-11270953-004164ce61",

        "errorCode": "INVALID_APP_KEY",

        "errorDetails": ""

      },

      "exceptionname": "APINGException"

    }

  },

  "id": 1

}```

This suggests that the app key being used is either invalid or no longer recognized.

Does anyone have insights on why this might be happening or how we can address it?

Let me know if you need additional context or details.

Thanks in advance!

*Tags: Errors Debugging*

---

## 2025-01-06

**Paul** - *09:17:23*

You’re going to have to speak to [mailto:bdp@betfair.com|bdp@betfair.com](mailto:bdp@betfair.com|bdp@betfair.com) - nobody here is going to be able to tell you why your API key gets that error message from Betfair all of a sudden.

*Tags: Errors Debugging*

---

**D C** - *10:26:42*

This has been discussed in the past but does anyone use a market AND order subscription within the same streaming connection? I am basically at my max connection limit (10) and looking for ways to cut down. I know people use things like redis so there is a "common" store of updated order information and thus only using a single connection for all order updates, but this is not a great option for me right now. I do some things that most would consider stupid (like having separate bots to record stream data - the same data that production strategy bots also request) but I prefer this approach and won't be changing that.

Basically it seems to me that the quickest and easiest method will be make my market stream connections also subscribe to order change messages but this has always felt a little bit "dirty".

Does anyone actually do this (seem to remember last time the most common approach was single stream each for market and order data)?

*Tags: Deployment, Strategies*

---

**D C** - *10:36:44*

I've not seen any explicit reference saying not  - but as I've never attempted to implement it, there may well be things that surface that make it impossible. Part of the reason I'm asking the question really

*Tags: General Technical*

---

**D C** - *10:40:27*

Don't apologise - you've potentially saved me wasting time on this as a viable solution to the problem

*Tags: General Technical*

---

**liam** - *10:42:39*

aka blue square, purchased by betfair, 10 years ago? they transferred accounts so lots of us ended up with two betfair accounts, I used before I got an MSA to get around your current problem

*Tags: General Technical*

---

**D C** - *10:57:23*

I've emailed Neil so I'll see how it goes. NO idea why I've posted this question in "issues" channel either :thinking_face:

*Tags: General Technical*

---

**Ralegh** - *14:12:14*

Dumb question but can’t you combine some of the market streams?

*Tags: General Technical*

---

## 2025-01-07

**Guilherme Scherner** - *13:25:44*

[@U07AK2APF2B](@U07AK2APF2B) Yes I changed it, login is successful but when I try to call `betting.list_current_orders()` I get INVALID_APP_KEY

```trading = betfairlightweight.APIClient(

                email,

                password,

                app_key,

                cert_files=("certificate.crt", "certificate.pem"),

            )

            trading.api_uri = "[https://api.betfair.bet.br/exchange/](https://api.betfair.bet.br/exchange/)"

            trading.identity_uri = "[https://identitysso.betfair.bet.br/api/](https://identitysso.betfair.bet.br/api/)"

            trading.identity_cert_uri = "[https://identitysso-cert.betfair.bet.br/api/](https://identitysso-cert.betfair.bet.br/api/)"

            trading.login()```

*Tags: Strategies*

---

**Unknown** - *15:57:06*

[@U07AK2APF2B](@U07AK2APF2B) But I think this problem is with me :pensive:

*Tags: General Technical*

---

## 2025-01-18

**D C** - *10:26:18*

Have you asked customer services? Did you ask why you were asked to submit documents? Sounds more like affordability nonsense or AML checks. Can't see why you'd need to submit any documentation for adding a Paypal account unless your paypal email or addres are different to those of your BF account

*Tags: General Technical*

---

## 2025-01-25

**R** - *14:25:54*

Has anyone ever noticed memory leaks when using flumine to collect data?  We've restarted an old collector system and find its crashing.



Of course, we've double checked it's not something on our side RE post processing and storage.  I'm sure it's something benign that we've missed, but it seems like flumine is holding on to market data even after close.



Anyone found something similar?

*Tags: Performance*

---

