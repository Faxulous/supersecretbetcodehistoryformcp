# Errors Debugging - Community Knowledge

*3352 relevant conversations from across all channels*

---

## 2025-01-24 10:11:51 - general channel

**tone**

No, it has been there for ever. The problem seems to have occurred because hitherto the filter has returned too few results to breach the threshold. I've removed RUNNER_METADATA as it wasn't necessary and it's now returning all the markets without error. Thanks for your help.

---

## 2025-01-24 08:56:07 - general channel

**tone**

Is anyone else getting this error this morning?betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue

Params: {'filter': {'eventTypeIds': ['7'], 'marketCountries': ['GB', 'US', 'AE'], 'marketTypeCodes': ['WIN'], 'marketStartTime': {'to': '2025-01-25T05:53:40Z'}}, 'marketProjection': ['RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'COMPETITION', 'EVENT', 'EVENT_TYPE', 'MARKET_DESCRIPTION', 'MARKET_START_TIME'], 'maxResults': 150}

Exception: None

Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang13a-prd-11260945-00632461b2', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang13a-prd-11260945-00632461b2', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}

---

## 2025-01-22 17:56:13 - random channel

**PeterLe**

[@U05N9773A23](@U05N9773A23) was there a data error on that race then? (I was wondering why i hadn't placed any bets?)

If so at least I know that is working then :grinning:

---

## 2025-01-22 15:34:42 - random channel

**Justice**

My model backed 1,000 in that race due to a data error so I got excited for a minute... But no luck, it was the 3rd :joy:

---

## 2025-01-19 12:59:23 - strategies channel

**Unknown**

It's been a frustrating week trying to get `Strategy2` to the point where I'd be comfortable redeploying it



On Monday I started by increasing the exposure limit on `Strategy1` for in play horses to bring it in line with what I've used for backtesting. I haven't spent much time using backtests to gauge how much I can scale everything up but that's perhaps something to start thinking about



I wasn't planning on doing this but I decided on Monday to also compare `Strategy0`'s live bets to the backtest and discovered some big problems with my execution which meant I'd missed out on - very roughly - about 15,000 bets over the past three months. This was largely down to handling the start of races and using the `marketStartTime`. I've completely overhauled the logic and it appears to have fixed things. I made a separate tweak that should also help reduce the number of missing bets but, checking that now, it's been somewhat less successful



Right, back to `Strategy2`. I've definitely made significant improvements to the model over the past week but none of the changes have translated into a meaningful shift in backtest performance. Intuitively, where the model is strongest it must just be agreeing with the market. However, I did have a small breakthrough last night with the filters I'm applying to try to avoid adverse selection and I think the strategy is just about at the stage where I'm happy to start live testing it again today. I don't think the backtest performance is quite good enough but the thing that convinced me it's worth live testing is that I can run it against many more markets than I have scraped prices for - i.e. all of the `OTHER_PLACE` markets. As in my last update, I can use BSP to quickly assess whether it's actually finding value on those markets. The breakthrough I'm referring to should apply to pretty much any taker strategy so I'm excited to apply it to other strategies



So the plan for the rest of the day is to manually run the strategy against today's UK racing and I also still owe my syndicates another couple of hours work for the week. Looking to next week, I should fit `Strategy2`'s model to Australian racing and backtest it again to see how that's looking. I do have one other big model improvement on my to-do list that I'll action and a couple of suggestions from o1 that I think are worth exploring but I haven't thought about what's next beyond that. I'll review my list of strategy ideas and have another chat with o1



A couple of general findings from this week:



1. It really helps to step away from the computer. All of my big breakthroughs in thinking came from taking a shower or cooking dinner or walking the dog

2. o1 continues to be indispensable. It's at least as good as if I had a junior quant working for me

Update on performance:



1. Got rotated back into syndicate strategies yesterday. We've been undertaking a large reconciliation exercise, the end result of which is that I'm quite a bit behind of my share so I imagine I'll be in rotation for a bit now

2. New strategies had a bad couple of days midweek and have been absolutely crushing it since then

New strategies net profit up to 2.3% of existing strategies net profit!

---

## 2025-01-19 12:32:48 - random channel

**D C**

In my last job I was reading "Fixed Odds Sports Betting" by Buchdahl when I had to get involved with applying and removing margins - it definitely had a section on that stuff somewhere. Probably any basic book on sports betting will do although some of them use more American terms (and odds format which I hate) which can be confusing.

---

## 2025-01-18 17:41:23 - random channel

**Unknown**

Quick question please: What signals an error in the Racestream (ie Transponder incorrectly assigned etc)

is it the "warn" field?  (I guess anything other than a 0 denotes an error?

(I couldnt find it in the dev docs)

Thanks

---

## 2025-01-17 09:16:17 - general channel

**D C**

i find this really interesting - it doesn't seem that long ago (although it probably was) that you were saying that GPS was rubbish and was too error prone to yield any edge! Now you are paying TPD for a direct sub - so you are going to have a latency advantage over any of us getting it from Betfair and a presumably massive latency advantage over Gruss/BA/Betmover integrated GPS users. And yet you are worried about alpha decay ???? I share your view on the need for diversification though.

---

## 2025-01-14 15:32:15 - strategies channel

**Unknown**

Apologies in advance to anyone I've already asked about this...

I've been working on a model for GB dogs. No price data or market signals involved at all - it is all fundamental modelling using data freely available to anyone. I'm usually of the opinion that models from such data are going to be worthless but I decided to give it a go anyway.

I've come up with a model that I believe has squeezed as much as it can from the data available. Model summary as follows:

1. Model built to generate win probabilities for dogs ONLY for A grade races

2. Model built using data from 2018 to 2023 (inclusive) using classical statistical modelling only

I've taken the model parameters and using 2024 data have generated some rough numbers to see how well calibrated it is. I've also run a quick and dirty backtest by approximating profit backing to BSP whenever BSP is greated than my model's 0EV price (I realise this step may well be pointless). For what it is worth, this test shows tiny profit after commission.



Looking at the numbers (attached) it looks like the model is reasonably well calibrated - I do have some concerns that it lacks the power to predict high probabilies for runners as the vast majority of fitted prbabilities are 0.4 or under. This might be OK though as these are graded races where each dog is supposed to be roughly the same current standard.



My questions are as follows:



1. Is the model shite and can/should it be abandoned now based on attached numbers

2. Assuming no to 1. what is a "good" next step to take (e.g. full backtest using highest price traded, full backtest using price X seconds from scheduled start etc.)

3. Again assuming no to 1. is it "good enough" to be worth pursuing with the view to augmenting the dataset with some more obscure/less easily available data

A lot of questions here but pre-off fundamental models are new to me. Inplay, backtesting or running strategies without backtest is easier to grasp - you know your model value has a finite lifetime and you need to pull any unmatched money before it gets too stale. Pre-off, your probability is fixed - but the market changes so how do you evaluate the execution (literature tells you value is not around for a long time with bookies, but betfair pre-off dog and horse markets suggest othewise - do you ride a trend in your favour until it reverses or fill your boots while you can) ??



I was going to keep asking people things via DM, but I figured that this is generic enough of a modelling problem to possibly be worth asking about publicly and resulting discourse might be helpful to others (even if only as an example of something that is ultimately useless and should be abandoned)

---

## 2025-01-13 19:58:22 - general channel

**Peter**

The nice new Expert Fee dashboard has now disappeared in my account. I rather liked what it was telling me, but now I'm wondering whether it was too good to be true and they're away fixing it!

---

## 2025-01-06 09:17:23 - issues channel

**Paul**

You’re going to have to speak to [mailto:bdp@betfair.com|bdp@betfair.com](mailto:bdp@betfair.com|bdp@betfair.com) - nobody here is going to be able to tell you why your API key gets that error message from Betfair all of a sudden.

---

## 2025-01-05 15:28:59 - issues channel

**Guilherme Scherner**

hi everyone,

I'm encountering an issue with our integration due to recent changes in Brazil. Here's the error I'm receiving:

```{

  "jsonrpc": "2.0",

  "error": {

    "code": -32099,

    "message": "ANGX-0007",

    "data": {

      "APINGException": {

        "requestUUID": "ie1-ang28b-prd-11270953-004164ce61",

        "errorCode": "INVALID_APP_KEY",

        "errorDetails": ""

      },

      "exceptionname": "APINGException"

    }

  },

  "id": 1

}```

This suggests that the app key being used is either invalid or no longer recognized.

Does anyone have insights on why this might be happening or how we can address it?

Let me know if you need additional context or details.

Thanks in advance!

---

## 2025-01-02 21:41:58 - strategies channel

**AndyL**

&gt;  As in fixed £1 for all odds?

i've tried both flat and liability

---

## 2025-01-02 21:41:33 - strategies channel

**liam**

As in fixed £1 for all odds?



A 5f race will look very different to a NHF race in the closing stages 

---

## 2025-01-01 23:54:51 - issues channel

**Brøndby IF**

[@U07AK2APF2B](@U07AK2APF2B) I used to do the same thing as you, creating a new one whenever another one reached the limit and generated the error, but honestly I get a bit anxious seeing several sessions started in the account history there at Betfair. So I decided to unify the session for all projects and created an exclusive trigger in one of the codes for keep-alive, so several days go by and a single session appears in the history, even helping me to monitor a possible account hack or something like that.

---

## 2025-01-01 23:22:29 - issues channel

**Unknown**

a few refreshes per hour, far from rate limit. Maybe it’s just a bug and they’ll fix it.

---

## 2025-01-01 21:02:50 - issues channel

**Brøndby IF**

[@U4H19D1D2](@U4H19D1D2) I tried doing like this:



```def login() -> APIClient:

    trading = betfairlightweight.APIClient(

        ..., ..., app_key=..., 

        cert_files=('./betfair_brl_certs/myAppBrl.crt','./betfair_brl_certs/myAppBrl.pem'), 

        session=requests.Session()

    )

    trading.api_uri = "[https://api.betfair.bet.br/exchange/](https://api.betfair.bet.br/exchange/)"

    trading.login()

    return trading```

And returned the error:



`betfairlightweight.exceptions.LoginError: API login: AUTHORIZED_ONLY_FOR_DOMAIN`

---

## 2025-01-01 14:31:11 - issues channel

**Victor Hugo Oliveira**

I'm getting the same error as you [@U07AK2APF2B](@U07AK2APF2B)

---

## 2025-01-01 14:20:30 - issues channel

**Gabriel Mocan**

I’m also stuck here.



Getting AUTHORIZED_ONLY_FOR_DOMAIN error when trying to non-interactive login.

---

## 2025-01-01 12:17:07 - issues channel

**Brøndby IF**

When requesting via API-NG Visualizer, locale="pt_BR" appears in the request Cookies, I tried to use it in the direct request with the API and also via betfairlightweight but without success, it continues to generate the same locale authorization error.

---

## 2025-01-01 12:05:30 - issues channel

**Unknown**

It seems to me that they are doing some tests, some test events appeared in the list of events and before when trying to request a return in the API, it generated an unknown error in [https://apps.betfair.bet.br/visualisers/api-ng-sports-operations/](https://apps.betfair.bet.br/visualisers/api-ng-sports-operations/), now the results are appearing normally without the need to choose an option in "Locale" because there is no option "Brazil" in the list.

---

## 2024-12-30 13:44:02 - random channel

**Paul**

Of course we know this isn't laundering. It's such an exceptionally rare activity though (money normally goes only one way with betting operators), it's always going to be a little hard to convince a regular customer service agent that while it walks like a money laundering duck and talks like a money laundering duck, it's actually legit...

---

## 2024-12-30 10:37:46 - issues channel

**Paul**

The error is `INVALID_SESSION_INFORMATION` which suggests the credentials used to get the market catalogue here are stale (which happens after ~24 hours).

---

## 2024-12-29 09:42:14 - issues channel

**WilliamR**

Hi I've started getting the following error complaining about an invalid session seems intermittent and program still runs and places bets.... should I be worried?:



 File "D:\Users\willi\anaconda3\Lib\site-packages\flumine\worker.py", line 126, in poll_market_catalogue

    market_catalogues = client.betting_client.betting.list_market_catalogue(

                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "D:\Users\willi\anaconda3\Lib\site-packages\betfairlightweight\endpoints\betting.py", line 233, in list_market_catalogue

    (response, response_json, elapsed_time) = self.request(method, params, session)

                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "D:\Users\willi\anaconda3\Lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 54, in request

    self._error_handler(response_json, method, params)

  File "D:\Users\willi\anaconda3\Lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 80, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue

Params: {'filter': {'marketIds': ['1.237584679', '1.237584668', '1.237584666', '1.237584713', '1.237582001', '1.237584706', '1.237584674', '1.237582040', '1.237584707', '1.237584715', '1.237584714', '1.237582041', '1.237584699', '1.237611936', '1.237611941', '1.237611968', '1.237611961', '1.237611945', '1.237611955']}, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'maxResults': 25}

Exception: None

Error: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang06a-prd-11260945-00381f34ac', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang06a-prd-11260945-00381f34ac', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}

2024-12-29 09:41:16,405:INFO:162:Client update account details

2024-12-29 09:41:18,027:INFO:263:Updated marketCatalogue for 1.237613210

---

## 2024-12-20 21:18:38 - random channel

**D C**

I recently got my betdaq reactivated and API usage granted. I was sent some truly shocking documentation - not just the SOAP API but there was also something with JSON which looked like a rudimentary sort of stream (all very amateurish with shocking docs). I implemented some of the SOAP stuff with the view of just throwing some simple strats in those markets to test the water. But people sitting at a ladder on variable refresh rates , possibly using polling updates are surely going to miss some price changes? That said, no excuse for Betdaq to not be able to either find an error or produce the paper trail evidence for why those bets were matched without BPE as it appears.

Either way think I will steer clear until they update that thread with a satisfactory explanation.

---

## 2024-12-20 15:45:08 - issues channel

**tone**

Fixed! I found the example you are referring to and it worked straight away. The filter was screwing it up. Thanks Liam, as always!

---

## 2024-12-20 15:19:42 - issues channel

**tone**

let me fix it

---

## 2024-12-20 09:44:18 - random channel

**Dave**

There was a lot of commotion around his election probabilities, and a lot of noise from the dude such as "I ran 80,000 simulations and Kamala won in 50.1% of them, the odds are really as close as you can get!". He got trolled a lot on twitter over that. Why - well if your model says "it's gonna be a coin flip" then maybe your model is just not good (except he kinda failed to see that).

---

## 2024-12-19 22:44:36 - random channel

**Ralegh**

Not that debugger is a new trick

---

## 2024-12-16 08:29:05 - random channel

**PeterLe**

Yep i thought that what ever point I enter on the bet (eg mid point) I should also use that for the future price too.

I would have thought 2 secs would be about right (in the thick of the action ie volatile), but Ill play around with this..

I think I need to alter the code as the graph i posted is both back and lays and im only calculating ev one way (so it can show -ev for a lay bet when it fact it is postive)...TBC



OK i see what you mean now on the cricket graph :+1:

I think I should be able to roll this out to other sports too...

Interesting though.. thanks for sharing Liam



Edit:

Now corrected the code and it does show a downturn on the negative side of ev (Still profitable overall and a good strat but could be a great one...)

One thing I though was useful was to plot the cumulative profit (back and lays) against ev as we have been doing, but to also plot the two sides too on the same graph.

I could quickly see that one side was having a bad effect on the overall PL...just need to fix that and then this time next year Rodney...:grinning:...

---

## 2024-12-14 17:25:18 - random channel

**thambie1**

A big reason to not accept large drawdowns, is that it makes it hard to differentiate variance from a strategy that for one reason or another is no longer working (bugs, changing market conditions, etc). These days my max drawdown is ~6% of annual profits

---

## 2024-12-12 21:03:31 - issues channel

**ian mcneill**

Hi - apologies noob noob trying to reboot attempts at this. I have a fail when trying to install flumine  as output below shows. I will read line by line and try to resolve myself but if anyone can ident my idiocity easily and point me in the right direction, that's great - I'll keep this window open :wink:



Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)

Building wheels for collected packages: pydantic-core

  Building wheel for pydantic-core (pyproject.toml) ... error

  error: subprocess-exited-with-error



  × Building wheel for pydantic-core (pyproject.toml) did not run successfully.

  │ exit code: 1

  ╰─&gt; [115 lines of output]

      Running `maturin pep517 build-wheel -i /Users/ian/miniconda3/envs/fex/bin/python --compatibility off`

      :package: Including license file "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/LICENSE"

      :tropical_drink: Building a mixed python/rust project

      :link: Found pyo3 bindings

      :snake: Found CPython 3.13 at /Users/ian/miniconda3/envs/fex/bin/python

      :satellite_antenna: Using build options features, bindings from pyproject.toml

      :computer: Using `MACOSX_DEPLOYMENT_TARGET=11.0` for aarch64-apple-darwin by default

         Compiling autocfg v1.1.0

         Compiling proc-macro2 v1.0.76

         Compiling unicode-ident v1.0.10

         Compiling target-lexicon v0.12.9

         Compiling python3-dll-a v0.2.9

         Compiling libc v0.2.147

         Compiling once_cell v1.18.0

         Compiling version_check v0.9.4

         Compiling cfg-if v1.0.0

         Compiling static_assertions v1.1.0

         Compiling heck v0.4.1

         Compiling zerocopy v0.7.32

         Compiling parking_lot_core v0.9.8

         Compiling rustversion v1.0.13

         Compiling scopeguard v1.1.0

         Compiling lexical-util v0.8.5

         Compiling allocator-api2 v0.2.16

         Compiling smallvec v1.11.2

         Compiling tinyvec_macros v0.1.1

         Compiling serde v1.0.195

         Compiling tinyvec v1.6.0

         Compiling memchr v2.6.3

         Compiling equivalent v1.0.1

         Compiling unicode-bidi v0.3.13

         Compiling regex-syntax v0.8.2

         Compiling ahash v0.8.7

         Compiling num-traits v0.2.16

         Compiling num-integer v0.1.45

         Compiling lock_api v0.4.10

         Compiling memoffset v0.9.0

         Compiling num-bigint v0.4.4

         Compiling lexical-write-integer v0.8.5

         Compiling lexical-parse-integer v0.8.6

         Compiling unicode-normalization v0.1.22

         Compiling lexical-write-float v0.8.5

         Compiling lexical-parse-float v0.8.5

         Compiling aho-corasick v1.0.2

         Compiling indoc v2.0.4

         Compiling serde_json v1.0.109

         Compiling percent-encoding v2.3.1

         Compiling unindent v0.2.3

         Compiling form_urlencoded v1.2.1

         Compiling regex-automata v0.4.3

         Compiling lexical-core v0.8.5

         Compiling idna v0.5.0

         Compiling ryu v1.0.14

         Compiling itoa v1.0.8

         Compiling uuid v1.6.1

         Compiling base64 v0.21.7

         Compiling url v2.5.0

         Compiling regex v1.10.2

         Compiling quote v1.0.35

         Compiling syn v2.0.48

         Compiling pyo3-build-config v0.20.2

         Compiling getrandom v0.2.10

         Compiling parking_lot v0.12.1

         Compiling hashbrown v0.14.3

         Compiling pyo3-ffi v0.20.2

         Compiling pyo3 v0.20.2

         Compiling pydantic-core v2.16.3 (/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571)

         Compiling indexmap v2.0.0

      error: failed to run custom build command for `pydantic-core v2.16.3 (/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571)`



      Caused by:

        process didn't exit successfully: `/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/target/release/build/pydantic-core-39a2e9245b501e5a/build-script-build` (exit status: 101)

        --- stdout

        cargo:rustc-cfg=Py_3_6

        cargo:rustc-cfg=Py_3_7

        cargo:rustc-cfg=Py_3_8

        cargo:rustc-cfg=Py_3_9

        cargo:rustc-cfg=Py_3_10

        cargo:rustc-cfg=Py_3_11

        cargo:rustc-cfg=Py_3_12

        cargo:rustc-cfg=Py_3_13

        cargo:rerun-if-changed=python/pydantic_core/core_schema.py

        cargo:rerun-if-changed=generate_self_schema.py



        --- stderr

        Traceback (most recent call last):

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 192, in eval_forward_ref

            return type_._evaluate(core_schema.__dict__, None, set())

                   ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

        TypeError: ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'



        During handling of the above exception, another exception occurred:



        Traceback (most recent call last):

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 240, in &lt;module&gt;

            main()

            ~~~~^^

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 210, in main

            value = get_schema(s, definitions)

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 54, in get_schema

            return type_dict_schema(obj, definitions)

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 152, in type_dict_schema

            field_type = eval_forward_ref(field_type)

          File "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/generate_self_schema.py", line 195, in eval_forward_ref

            return type_._evaluate(core_schema.__dict__, None)

                   ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^

        TypeError: ForwardRef._evaluate() missing 1 required keyword-only argument: 'recursive_guard'

        thread 'main' panicked at [http://build.rs:29:9|build.rs:29:9](http://build.rs:29:9|build.rs:29:9):

        generate_self_schema.py failed with exit status: 1

        note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

      warning: build failed, waiting for other jobs to finish...

      :boom: maturin failed

        Caused by: Failed to build a native library through cargo

        Caused by: Cargo build finished with "exit status: 101": `env -u CARGO MACOSX_DEPLOYMENT_TARGET="11.0" PYO3_ENVIRONMENT_SIGNATURE="cpython-3.13-64bit" PYO3_PYTHON="/Users/ian/miniconda3/envs/fex/bin/python" PYTHON_SYS_EXECUTABLE="/Users/ian/miniconda3/envs/fex/bin/python" "cargo" "rustc" "--features" "pyo3/extension-module" "--message-format" "json-render-diagnostics" "--manifest-path" "/private/var/folders/b6/6bn7gvx54lv2p4kjxcdz2s0h0000gn/T/pip-install-9p34jo51/pydantic-core_97eb83b395414c3f9cf1c80056b9a571/Cargo.toml" "--release" "--lib" "--crate-type" "cdylib" "--" "-C" "link-arg=-undefined" "-C" "link-arg=dynamic_lookup" "-C" "link-args=-Wl,-install_name,@rpath/pydantic_core._pydantic_core.cpython-313-darwin.so"`

      Error: command ['maturin', 'pep517', 'build-wheel', '-i', '/Users/ian/miniconda3/envs/fex/bin/python', '--compatibility', 'off'] returned non-zero exit status 1

      [end of output]



  note: This error originates from a subprocess, and is likely not a problem with pip.

  ERROR: Failed building wheel for pydantic-core

Failed to build pydantic-core

ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pydantic-core)

---

## 2024-12-04 17:18:23 - general channel

**Mo**

Should be fixed now

---

## 2024-12-02 10:51:38 - issues channel

**liam**

as linked, the fix was pushed in 2.20.3

---

## 2024-12-02 10:42:24 - issues channel

**tone**

Hmmm. Upgraded to flumine-2.6.8 but still getting the error.

---

## 2024-12-02 09:43:42 - issues channel

**tone**

Is anybody seeing a recurrence of the "Unable to find appKey" error when logging on to race_card?

---

## 2024-12-02 09:31:00 - issues channel

**foxwood**

Yes that would break - been there lol - also seems to be currency conversion involved since quoted $0.01. But as you "rudely" said in another post the devil is in the secret details and getting the right info like the error code to diagnose :wink:

---

## 2024-12-01 10:51:40 - issues channel

**foxwood**

Tiny bets at wrong price/stake combo are supposed to trigger

```INVALID_PROFIT_RATIO```

error eg if you want to place £0.01 bet then minimum odds are 1.81 and if you want 1.01 then min stake is £0.80 - all following BF formula. According to docs there is a meaningful error code for BET_ACTION_ERROR ... "There is an error with an action that has caused the entire order to be rejected. Check the instructionReports errorCode for the reason for the rejection of the order."

---

## 2024-11-30 20:26:42 - issues channel

**NT**

Thanks, I'll look through and see if this is the pattern (and if there are any error messages that extend beyond the "BET_ACTION_ERROR". Appreciate the help

---

## 2024-11-30 20:14:32 - issues channel

**liam**

Check the full error message, it will only be on low prices (sub 1.5?)

---

## 2024-11-30 19:52:22 - issues channel

**liam**

Likely to be the 0.01 / zero liability handling, I thought the error message normally gives more info however you shouldn’t be ‘greening’ we don’t allow that chat here  

---

## 2024-11-30 19:02:51 - issues channel

**NT**

Hi All,



Is there a common reason for "BET_ACTION_ERROR" to be triggered? I've adjusted my code to incorporate a 'greening up' process and reduce the variance of payouts across outcomes in a given market, and find that some of these orders are being rejected with no further error message provided (but some are being processed). These are typically small $0.01 orders, so I am wondering if that is the driver, but thought I'd see if anyone here knew more as it isn't a particularly informative error. The inconsistent nature of this is making finding a common pattern tougher.



Cheers

---

## 2024-11-30 08:45:40 - random channel

**Unknown**

Any chance this match is fixed? My guess it will be 3-3. Implied prob of > 50% for 3-3 most of the match??

---

## 2024-11-28 07:54:35 - issues channel

**liam**

Tbh you have to be when debugging something like this, people never give you all the information and they never tell you the truth

---

## 2024-11-27 16:45:15 - strategies channel

**Peter**

No - I've solved it - I was making an embarrassing error but as always you have to ask the question before you see it

---

## 2024-11-27 09:48:52 - issues channel

**Tom**

2024-11-27 20:43:25,730 [DEBUG] __main__: Found order: Order 369539252565: Execution complete. Status: OrderStatus.EXECUTION_COMPLETE

2024-11-27 20:43:25,731 [DEBUG] __main__: Found order: Order 369539257045: Execution complete. Status: OrderStatus.EXECUTION_COMPLETE

2024-11-27 20:43:25,731 [DEBUG] __main__: Found order: Order 369541038302: Execution complete. Status: OrderStatus.EXECUTION_COMPLETE

2024-11-27 20:43:25,731 [ERROR] __main__: Print Marketbook delayed None

2024-11-27 20:43:25,731 [ERROR] __main__: Cross matching is False

2024-11-27 20:43:25,731 [ERROR] __main__: Version is 6300260619

2024-11-27 20:43:25,731 [ERROR] __main__: Market staleness check returned None.

2024-11-27 20:43:25,731 [WARNING] flumine.baseflumine: High latency between current time and MarketBook publish time

2024-11-27 20:43:25,731 [INFO] flumine.baseflumine: Adding: 1.236494334 to markets

2024-11-27 20:43:25,732 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): [http://api.betfair.com:443|api.betfair.com:443](http://api.betfair.com:443|api.betfair.com:443)

2024-11-27 20:43:25,803 [DEBUG] urllib3.connectionpool: [https://api.betfair.com:443](https://api.betfair.com:443) "POST /exchange/betting/json-rpc/v1 HTTP/11" 200 2392

2024-11-27 20:43:25,806 [INFO] root: OrdersMiddleware: Processing order 369500134776

2024-11-27 20:43:25,807 [INFO] root: OrdersMiddleware: New order trade created

2024-11-27 20:43:25,808 [INFO] flumine.order.order: Order status update: Execution complete

2024-11-27 20:43:25,808 [INFO] flumine.order.trade: Trade status update: Complete

2024-11-27 20:43:25,808 [INFO] root: OrdersMiddleware: Processing order 369502827322

2024-11-27 20:43:25,808 [INFO] root: OrdersMiddleware: New order trade created



Ok I wasn't logging very effectively. This is coming up inbetween running markets for the first time. The problem occurs after running a while as well though.



What kind of logs will be useful to see? Startup logs look normal

---

## 2024-11-27 09:16:57 - issues channel

**Tom**

2024-11-27 20:15:14,594 [INFO] __main__: Checking market book for market 1.236496631

2024-11-27 20:15:14,594 [DEBUG] __main__: UTC time now is 2024-11-27 09:15:14.594654+00:00

2024-11-27 20:15:14,594 [DEBUG] __main__: Market book publish time is 2024-11-27 09:13:04.942000

2024-11-27 20:15:14,594 [DEBUG] __main__: Market book publish time converted to UTC: 2024-11-27 09:13:04.942000+00:00

2024-11-27 20:15:14,594 [DEBUG] __main__: Time difference: 0:02:09.652654

2024-11-27 20:15:14,595 [WARNING] __main__: Market is more than 2 minutes out of sync with the current time.



So this is all I see when the book is delayed, this is through a method I put at the top of check_market

---

## 2024-11-27 08:48:23 - issues channel

**Tom**

it runs code with no errors no warnings and old books

---

## 2024-11-27 08:32:30 - issues channel

**Tom**

There are no errors or warning anywhere

---

## 2024-11-24 17:46:20 - general channel

**Mo**

Fine, so what error do you get when you put the URL encoded password into Postman?

---

## 2024-11-24 17:40:02 - general channel

**Mo**

What error do you get when you use your plain username and password?

---

## 2024-11-24 17:36:15 - general channel

**Elie Couttet**

I don't know much about that stuff tbh, I've been doing a lot of try and error.

---

## 2024-11-24 14:27:06 - general channel

**Elie Couttet**

It does recognize my encoded username though, as if I change it, it gives another error (CERT_AUTH_REQUIRED)

---

## 2024-11-23 19:42:31 - strategies channel

**Ralegh**

Thumbs up for parquet and the fixed number of levels with padding

---

## 2024-11-23 14:31:33 - general channel

**Phydeaux**

[@U08233FRWCA](@U08233FRWCA) the text of the error rather than the blunt status code will point you/us in the right direction… hard to help further without it.

---

## 2024-11-23 14:28:11 - general channel

**Phydeaux**

[@U08233FRWCA](@U08233FRWCA) do you have the non-truncated error message?

---

## 2024-11-23 14:24:31 - general channel

**Elie Couttet**

Exception: Request failed for [https://api.betfair.com](https://api.betfair.com) returned code 403. Truncated server response: [!DOCTYPE html](!DOCTYPE html)

&lt;!--[if lt IE 7]&gt; &lt;html class="no-js ie6 oldie" lang="en-US"&gt; &lt;![endif]--&gt;

&lt;!--[if IE 7]&gt;    &lt;html class="no-js ie7 oldie" lang="en... (use muteHttpExceptions option to examine full response)

jsonRestExample@

---

## 2024-11-23 14:23:52 - general channel

**Phydeaux**

What is the full error you’re receiving?

---

## 2024-11-23 12:42:38 - general channel

**Elie Couttet**

Hi, I'm new here! :wave:

A few months ago, I was playing around with the Betfair API (the free delayed one for now) and was managing to send some POST requests and getting a response from javascript code in a Gsheet.

I've been fighting with the same code since yesterday and keep getting the same 403 response... I have tried to dumb it down as much as I could with still no success. Can one of you put me in the right direction?



Here is the simplified version of my code. I have checked that the appKey and sessionId work on the Betting Api Demo Tool. I'd be grateful for any support!



const url = "[https://api.betfair.com/exchange/betting/json-rpc/v1](https://api.betfair.com/exchange/betting/json-rpc/v1)";



  var header = { 'X-Application' : appkey, 'X-Authentication' : ssid ,'content-type' : 'application/json'}

  var jsonrpc_req={"jsonrpc": "2.0", "method": "SportsAPING/v1.0/listEventTypes", "params": {"filter":{ }}, "id": 1}



  const options = {

    method: 'POST',

    muteHttpExceptions: false,

    headers: header,

    data: jsonrpc_req

  };





    // Send POST request to the API

    var response = UrlFetchApp.fetch(url, options);

---

## 2024-11-18 08:58:42 - general channel

**Paul**

I was debugging something on the train this morning (via mosh + tmux + nvim and some test scripts on my iPhone, AMA... :zany_face:), and was hitting some weird errors and 400s for a while. Seems the errors I was worried about were not mine: API and mobile app access now back, but definitely feels like that was an ~outage~ unannounced maintenance window...

---

## 2024-11-18 08:51:24 - general channel

**Unknown**

Error 500

---

## 2024-11-16 23:55:25 - random channel

**James**

Yeah I write my code locally on mac, and run my logic testing debugging locally. For my sims I use docker compose and run it in a container that mirrors my deployed.

---

## 2024-11-16 20:55:53 - general channel

**Johnny Boston**

[https://www.britishhorseracing.com/racing/results/fixture-results/result/#!/2024/1763/37019/0/|https://www.britishhorseracing.com/racing/results/fixture-results/result/#!/2024/1763/37019/0/](https://www.britishhorseracing.com/racing/results/fixture-results/result/#!/2024/1763/37019/0/|https://www.britishhorseracing.com/racing/results/fixture-results/result/#!/2024/1763/37019/0/)

---

## 2024-11-08 21:19:27 - issues channel

**Brøndby IF**

I believe it was an error on my part in interpreting the text, there is nothing that prohibits the use of FALSE, it is my complete ignorance.

---

## 2024-11-08 21:17:22 - issues channel

**Brøndby IF**

Ah [@U4H19D1D2](@U4H19D1D2), I read on `betfairlightweight` that I could set it to `TRUE` or leave it disabled (`in_play_only: restriction to currently inplay, not supplied returns all.`), I was afraid of setting it to `FALSE` and generating a block or error in the request, so can I use `FALSE`?



Request data:

[{"jsonrpc": "2.0", "method": "SportsAPING/v1.0/listMarketCatalogue", "params": {"filter":{"eventTypeIds":["2"],"inPlayOnly":false},"maxResults":"1"}, "id": 1}]

---

## 2024-11-07 21:48:13 - issues channel

**James**

ohhh I made a seemingly nothing change to handling cleared markets and I started getting errors and didnt have time to look into it. It was probably this too.

---

## 2024-11-07 11:14:32 - random channel

**George**

I am personally active in politics and political campaigns in the UK. The "shy Tory" - or in this case "shy Trump" effect is very well known in these circles. It has played out in most (perhaps not all, but definitely most) UK election polls in the last 40 years.



I don't know why polling companies haven't learnt their lesson, but they haven't. People lie, and they lie in a fairly systematic way (the effect size varies over time but the direction generally does not).



I have no doubt that there were +EV bets to be made on this election, but they could only have been made by someone who has very carefully studied the "shy" effect with data, and I suspect very few of us here have. Theo did, and his data gave him confidence that his bets were +EV, so he placed them - probably he got the Kelly staking wrong but the EV was there.



The idea that Harris was +EV at 2.x based on "the available information" is highly likely to be wrong (though I admit I cannot be 100% of this, having not studied the data in detail) because the available information included a long and predictable history of exactly this sort of polling error.

---

## 2024-11-07 10:04:30 - issues channel

**Unknown**

I've had intermittent issues with listClearedOrders for a week or so now. This is the error I've been getting though.

---

## 2024-11-07 10:00:48 - issues channel

**Newbie99**

anyone else getting an exception for listClearedOrders, it keeps saying TOO MANY REQUESTS and I also notice that no P&amp;L is showing in the Betfair GUI, so possibly a problem (nothing showing yet on the outage page)?

---

## 2024-11-07 09:58:48 - random channel

**Paul**

I wasn't looking at Nate's work. I was looking at a bunch of analysis, but mostly 538 which he founded _but has no involvement in any more_. It's owned by ABC News, and uses methods that he started work on back in 2006-2008, but has been iterated on an improved every year since. I've been saying consistently that the result falls within the published error bars, just at the edge of those bars. The polling was skewed off to the left for reasons unknown (it now seems to be a mixture of "shy" Trump voters and sampling errors - again - which means like a good Bayesian next cycle I'll accept that information to update my prior), meaning those who skewed the market hard to the right were on this occasion correct, but given the public information known at the time, creating EV opportunities for those of us willing to be counter-parties.

---

## 2024-11-06 13:55:22 - random channel

**Paul**

[@U80AMMRKP](@U80AMMRKP) 1.9ish - polling put him slightly ahead. We did not have data to support shy Trump voter, sampling error, whatever else is uncovered as influencing in weeks and months to come. You can only make the call with the info you have. It’s the problem with this sort of betting, you deal with incomplete information, you are managing variance in an unknown distribution, this isn’t dice, roulette or even poker where you can do the maths with absolute or high degrees of confidence. It’s judgement you can add to with more information. I’d ask where is the additional info that made sense to price in that polymarket did price in? I’m not sure it exists. I’m not certain, but in my judgement, with the information available last week, Harris backers had EV, Trump backers didn’t… 

---

## 2024-11-06 13:46:59 - random channel

**Paul**

So fine, I came out flat, I felt I had EV, I went to bed last night thinking it was much closer than it turned out to be, but it’s within the errors of margin of polling and my bet was EV. :shrug: 

---

## 2024-11-06 13:45:41 - random channel

**Paul**

I had no reason to think polling, 538’s analysis or any other data source would be this wrong. Even the partisan republican polls seem off. If it didn’t sound hysterical and unhelpful I’d raise the question of fraud in Trump’s favour: it’s on the edge of the error bars, but not quite outside them.

---

## 2024-11-06 13:43:59 - random channel

**Paul**

If it turns out the polls were systematically wrong through sampling error I’ll hold my hands up and say we shouldn’t have used them to establish an EV reckoning. It’s not obvious that’s the case, only that they weren’t correct. The cause of that is still an unknown. Think we’ll have the answer by early next year.

---

## 2024-11-06 10:15:08 - random channel

**Michael**

I mean if you added "Maybe" to the start of that sentence then you'd have a good case, but you didn't, so you're just repeating the error.

---

## 2024-11-06 08:52:06 - random channel

**Paul**

There was EV backing Harris at 2.5. The margin of victory is within error bars for polling, if you factored that in, the smart bet was to back Harris or lay Trump. Just because somebody was right in picking a winning bet, it doesn’t mean they got value. Keep doing that over and over again and eventually you’ll get ruined.

---

## 2024-11-05 20:49:07 - issues channel

**Ulad**

Has anyone seen these errors for the streaming API?

```Connection to shard could not be established for message: {op='authentication'...```

---

## 2024-11-01 21:38:49 - general channel

**liam**

No



&gt; We'll have an update on Monday regarding the timing of the UDP fix that the team has previously been working on.

---

## 2024-11-01 21:36:56 - general channel

**Unknown**

OK thanks. I just assumed these were acronyms of some server side tech I'd never heard of. So you heard they'd released a UDP fix Monday? Doesn't look like it's helped much. My logs are shocking from yesterday (should add that these times include a dropout that contains the inplay suspension event).

---

## 2024-11-01 21:33:03 - general channel

**liam**

No idea, I imagine internal services that handle the feed. Latest update is some comms on Monday regarding releasing the UDP fix however if you ask me I think they need to work out the cause of the current deterioration

---

## 2024-11-01 19:25:42 - random channel

**Jonjonjon**

Under correct operating procedures, and assuming no errors on Betfair's behalf, is it possible for a greyhound to be removed after BSP has been reconciled?

---

## 2024-11-01 19:20:26 - issues channel

**Mo**

I mean the error message tells you exactly what to do 

---

## 2024-10-31 15:54:00 - general channel

**Jhonny**

Hi everyone, I keep getting NOT_AUTHORIZED error when trying to use the esa api. I haven't used it in about 2 months; my live key just got accepted and it's my first time trying it out:



```:event {:op connection, :connectionId 206-311024154911-133459}

:event {:op status, :statusCode FAILURE, :errorCode NOT_AUTHORIZED, :errorMessage Connection is not authenticated: MarketSubscriptionMessage{marketFilter=MarketFilter{marketIds=[1.235241223], bspMarket=null, bettingTypes=null, eventTypeIds=null, eventIds=null, turnInPlayEnabled=null, marketTypes=null, venues=null, countryCodes=null, raceTypes=null}, marketDataFilter=com.betfair.platform.exchange.stream.api.domain.market.MarketDataFilter@70734c3a, initialClk='null', clk='null', conflateMs=null, heartbeatMs=null}, :connectionClosed true, :connectionId 206-311024154911-133459}

:stream-closed```

Last I tested with the delayed key, it worked. However, both live and delay keys are currently not working. Would appreciate anyone's help, thanks

---

## 2024-10-31 12:08:06 - issues channel

**frank**

Hi, I'm trying to login to betfair api. but this code, gives me an ssl error. :  `# Import libraries`

`import betfairlightweight`

`from betfairlightweight import filters`

`import pandas as pd`

`import numpy as np`

`import os`

`import datetime`

`import json`



`# Change this certs path to wherever you're storing your certificates`

`certs_path = r'C:\certs'`



`with open('credentials.json') as f:`

    `cred = json.load(f)`

    `my_username = cred['username']`

    `my_password = cred['password']`

    `my_locale= cred['locale']`

    `my_app_key = cred['app_key']`



`trading = betfairlightweight.APIClient(username=my_username,`

                                       `password=my_password,`

                                       `locale=my_locale,`

                                       `app_key=my_app_key,`

                                       `certs=certs_path)`



`trading.login()`   errorse is the following: `Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(524297, '[SSL] PEM lib (_ssl.c:3905)')))`  any help would be very appreciated. Thanks

---

## 2024-10-31 09:07:51 - general channel

**liam**

FYI flumine users / [@UUCD6P13J](@UUCD6P13J) there is a bug with this patch when used on long running instances. The issue is the way flumine uses `stream_id` to differentiate between different streams, this starts at 1000 and +=1000 for every new stream, this becomes an issue when you have a stream which has stopped/started more than 1000 times as it starts to conflict with the next stream.



Adding a digit in flumine would be an easy fix but doesn't really solve the issue, `stream_id` is used throughout the framework for subscribing to strategies/closing markets etc so it can't easily be changed to a uuid :thinking_face:

---

## 2024-10-30 19:49:16 - random channel

**Paul**

If it’s a coin toss (which I accept might be a big “if”), Kelly says 9% of bank is max bet (because Kamala is priced with a 9% edge over evens true odds). It seems unlikely the polls are so wide of reality that Fredi is Kelly optimal at that position size unless his bank runs to 9-10 figures. Occam’s razor to my mind says either: it’s nowhere near a coin flip and polls are a mess; the market won’t settle based on actual result (see comments from [@U05L8PZD2FM](@U05L8PZD2FM)), and Fredi is pricing in a coup of some sort here; or, there is a whale in a hot -EV mess skewing prices. I’m not sure which is true but I think public polling is likely closer to reality than being 10% out towards Harris - the error bars can’t be that wide.

---

## 2024-10-30 09:39:06 - strategies channel

**Terry**

ill set to DEBUG

---

## 2024-10-30 09:37:05 - strategies channel

**Unknown**

```if runner_context.invested or runner_context.live_trades:

   [http://logger.info|logger.info](http://logger.info|logger.info)(f"{runner_name} has Live Trades!")

   continue ```

this code avoids logging an error. 12:02:18,536:INFO:Gloze has Live Trades!

---

## 2024-10-29 21:05:51 - random channel

**Alex A**

Yeah, I guess for popular votes you can kind of cancel opposite side polling errors errors out across states in a way you can’t for the actual election.

---

## 2024-10-22 12:59:57 - general channel

**D C**

If it can be reassigned, then presumably that would have to be present until it is resolved (within every RPC). How is this coded? Is it a bitmask because presumably these are not mutually exclusive errors

---

## 2024-10-22 12:57:59 - general channel

**liam**

Yeah it's assignment error that I am interested in however I don't see how often it would be triggered as I believe the operators can actually reassign during loading

---

## 2024-10-22 00:07:59 - issues channel

**NAS**

tried launching the two instances on another computer & it worked



this was thrown during startup



```2024-10-22 01:05:17,751 - flumine.streams.streams - INFO - Starting streams..

2024-10-22 01:05:17,751 - flumine.streams.orderstream - INFO - Starting OrderStream 1000

2024-10-22 01:05:17,752 - flumine.streams.orderstream - INFO - Starting output_thread (OrderStream 1000)

2024-10-22 01:05:17,752 - betfairlightweight.streaming.listener - INFO - [Register: 1001]: orderSubscription

2024-10-22 01:05:17,752 - betfairlightweight.streaming.stream - INFO - [OrderStream: 1001]: "OrderStream" created

2024-10-22 01:05:17,910 - flumine.streams.orderstream - ERROR - OrderStream 1000 run error



ConnectionResetError: [Errno 54] Connection reset by peer



betfairlightweight.exceptions.SocketError: [Connect: 1001]: Socket [Errno 54] Connection reset by peer

2024-10-22 01:05:19,925 - flumine.streams.orderstream - INFO - Starting OrderStream 1000

2024-10-22 01:05:19,926 - betfairlightweight.streaming.listener - INFO - [Register: 1001]: orderSubscription

2024-10-22 01:05:19,926 - betfairlightweight.streaming.listener - WARNING - [Listener: 1001]: stream already registered, replacing data

2024-10-22 01:05:19,926 - betfairlightweight.streaming.stream - INFO - [OrderStream: 1001]: "OrderStream" created```

---

## 2024-10-21 21:19:41 - issues channel

**NAS**

```betfairlightweight.exceptions.SocketError: [Connect: 1002]: Connection closed by server```

```2024-10-21 13:05:15,865 - flumine.streams.marketstream - INFO - Starting MarketStream 2001

2024-10-21 13:05:15,866 - betfairlightweight.streaming.listener - INFO - [Register: 2002]: Unique id updated on listener and stream

2024-10-21 13:05:15,985 - flumine.streams.marketstream - ERROR - MarketStream 2001 run error```

```2024-10-21 13:05:17,057 - flumine.streams.orderstream - INFO - Starting OrderStream 1001

2024-10-21 13:05:17,057 - betfairlightweight.streaming.listener - INFO - [Register: 1002]: orderSubscription

2024-10-21 13:05:17,057 - betfairlightweight.streaming.listener - WARNING - [Listener: 1002]: stream already registered, replacing data

2024-10-21 13:05:17,057 - betfairlightweight.streaming.stream - INFO - [OrderStream: 1002]: "OrderStream" created

2024-10-21 13:05:17,166 - flumine.streams.orderstream - ERROR - OrderStream 1001 run error```

idk if i've seen them before, but got a lot of them today? someone else? connections available.

---

## 2024-10-19 15:22:05 - general channel

**Mo**

1. Look at the [https://github.com/betcode-org/betfair/tree/master/|source code](https://github.com/betcode-org/betfair/tree/master/|source code), especially [https://github.com/betcode-org/betfair/tree/master/examples|the examples](https://github.com/betcode-org/betfair/tree/master/examples|the examples) and [https://github.com/betcode-org/betfair/blob/master/betfairlightweight/resources/bettingresources.py|the resources](https://github.com/betcode-org/betfair/blob/master/betfairlightweight/resources/bettingresources.py|the resources) 

2. Familiarise yourself with the [https://betfair-developer-docs.atlassian.net/wiki/spaces/1smk3cen4v3lu3yomq5qye0ni/pages/2687473/Reference+Guide|Betfair API documentation](https://betfair-developer-docs.atlassian.net/wiki/spaces/1smk3cen4v3lu3yomq5qye0ni/pages/2687473/Reference+Guide|Betfair API documentation)

3. Install and use a decent IDE like [https://www.jetbrains.com/pycharm/|PyCharm](https://www.jetbrains.com/pycharm/|PyCharm) that will allow you to debug which will let you step through code line by line and examine the Python objects involved

---

## 2024-10-19 14:47:24 - general channel

**John**

This the error. Not sure how to fix: AttributeError: 'list' object has no attribute 'text'

---

## 2024-10-19 14:40:55 - general channel

**John**

many thanks. and handling the response in python. I have:  data = json.loads(response.text), but it throws an error

---

## 2024-10-18 15:14:41 - general channel

**Jonas JN**

Hi guys, I'm using betfairlightweight to stream historical data, do you know if it's possible to get the event score for each odd movement?



I would really like to obtain this information along with the movement of the odds, I am trying to link the data with another API to obtain statistics and other information. Could you also tell me if there is a fixed id for teams, besides the selectionId?



Thanks!

---

## 2024-10-16 19:11:23 - random channel

**Jonjonjon**

Yes there's a specific error code for that. I think the rule is that the bet will be rejected if you'd get over 20% extra edge from it.

---

## 2024-10-16 18:30:59 - random channel

**Paul**

[@UPMUFSGCR](@UPMUFSGCR) it was a conversation about how some stake amounts can’t be used because of rounding errors that should only really apply because of you adjusting at very short odds. I have definitely hit rounding errors causing bet rejections in some scenarios.

---

## 2024-10-16 11:13:48 - random channel

**Unknown**

Topics for this meetup included:

• the philosophical nature of Justified True Beliefs and Gettier in the context of open discussion of "alpha"

• almost _passionate_ disagreement on the quality of Nate Silver's knowledge, beliefs, and ability as a writer

• [@U05REBJ21EC](@U05REBJ21EC) honourably deciding to test the legality of trading on crypto prediction markets in the US from the UK for the rest of us - we'll send you a file in a cake if you end up in a Supermax Lorenzo, go for it, haters gonna hate!

• is the real alpha just starting your own exchange?

• dumb ideas that seem to make money, even though they're so obvious they _have_ to be just dimes in front of a steamroller, no?

• how much to invest in smart ideas that don't seem to make money because it _must_ just be the parameter search hasn't hit yet (aka, the source of all imposter syndrome in this domain)

• whether going to Rules for dinner is worth it (probably, yes - speak to [@UBS7QANF3](@UBS7QANF3) if you wish to join)

• would horse racing be the second largest spectator sport in the UK if it weren't for Cheltenham festival?

• undocumented forbidden stake amounts at certain price points created by rounding errors

• and, inevitably, "taxes are bad mmm'kay?", as a means to get a rise out of your local Northern Labour-voting cryptosocialist (:wave:)

Next one will be in a few weeks. Probably. I dunno. You figure it out.

---

## 2024-10-16 08:02:45 - general channel

**Unknown**

Hi Team

For Races, why isnt the Lay bets getting placed via Betfair API and even API tool, getting PERMISSION_DENIED error code. (Attaching screenshot)



The documentation explains the error: `Business rules do not allow order to be placed. You are either attempting to place the order using a Delayed Application Key or from a restricted jurisdiction (i.e. USA)`  and from [https://support.developer.betfair.com/hc/en-us/articles/360015530311-Why-am-I-receiving-the-error-PERMISSION-DENIED-ACCESS-DENIED-when-attempting-to-place-a-bet|https://support.developer.betfair.com/hc/en-us/articles/360015530311-Why-am-I-receiving-the[…]ON-DENIED-ACCESS-DENIED-when-attempting-to-place-a-bet](https://support.developer.betfair.com/hc/en-us/articles/360015530311-Why-am-I-receiving-the-error-PERMISSION-DENIED-ACCESS-DENIED-when-attempting-to-place-a-bet|https://support.developer.betfair.com/hc/en-us/articles/360015530311-Why-am-I-receiving-the[…]ON-DENIED-ACCESS-DENIED-when-attempting-to-place-a-bet) restricted Jurisdiction. But neither is the case. I am connected from London.



What Am I missing here?

---

## 2024-10-14 10:33:11 - strategies channel

**liam**

Weird as it lets me search it but then the link doesn't work



&gt; 

&gt; 

&gt; *liam*  [3:24 PM]

&gt; Does anyone know how much Decimal charge for the Cricket feed?

&gt; 49 replies

&gt; 

&gt; 

&gt; 

&gt; 

&gt; 

&gt; *Robert*  [3:55 PM]

&gt; I'm on the hunt for a decent feed too!

&gt; 

&gt; 

&gt; 

&gt; *D C*  [4:02 PM]

&gt; Is it just a score feed? Is Betfair's not up to scratch?

&gt; 

&gt; 

&gt; 

&gt; *liam*  [4:05 PM]

&gt; No comment

&gt; 

&gt; 

&gt; 

&gt; *D C*  [4:06 PM]

&gt; Understood

&gt; 

&gt; 

&gt; 

&gt; *liam*  [9:10 AM]

&gt; I have sent an email, will share the price if they do however I fear it might be out of my budget

&gt; 

&gt; 

&gt; 

&gt; *Mo*  [9:56 AM]

&gt; I can give you a personal introduction if you don’t get anywhere

&gt; 

&gt; 

&gt; 

&gt; *Robert*  [11:22 AM]

&gt; I think the main issue, not just for cricket, is Betfair's inability to use the widely accepted team or players names.

&gt; 

&gt; 

&gt; 

&gt; *Robert*  [3:15 PM]

&gt; And the inability to match names strikes again :expressionless:

&gt; 

&gt; 

&gt; 

&gt; *liam*  [3:36 PM]

&gt; It's a complete fucking joke tbh, almost 3 years this has been in 'production'

&gt; 

&gt; 

&gt; 

&gt; *Robert*  [3:48 PM]

&gt; you would have thought, it being the same team causing the issue as yesterday, they might have pre-empted it .....

&gt; 

&gt; 

&gt; 

&gt; *Lee*  [3:49 PM]

&gt; what issues are you seeing [@U4H19D1D2](@U4H19D1D2)?

&gt; 

&gt; 

&gt; 

&gt; *liam*  [3:51 PM]

&gt; The usual ongoing mapping issues and there is some sort of bug with the Lancashire game which is pushing out about a million updates per second on certain connections, seems like they just don't care

&gt; 

&gt; 

&gt; 

&gt; *Mo*  [6:11 PM]

&gt; Wow, looks like this is bringing down my entire scraping infrastructure

&gt; 

&gt; 

&gt; 

&gt; *liam*  [6:19 PM]

&gt; Try restarting, doesn’t seem to be on every connection

&gt; 

&gt; 

&gt; 

&gt; *Mo*  [6:21 PM]

&gt; Better but the damage has already been done

&gt; 

&gt; 

&gt; 

&gt; *Lee*  [6:22 PM]

&gt; nice to know the cricket feed could take down all my recording

&gt; 

&gt; 

&gt; 

&gt; *Mo*  [6:23 PM]

&gt; Well your mileage may vary depending on how much disk space your box has and whether you have appropriate alerts set up

&gt; 

&gt; 

&gt; 

&gt; *D C*  [6:24 PM]

&gt; Is this a recent problem or  long term? Just wondering if it's related to my recent server reboot as I am recording the cricket score feed on said server.

&gt; 

&gt; 

&gt; 

&gt; *liam*  [7:53 PM]

&gt; Recent, started today at 11:45ish, apparently now fixed

&gt; 

&gt; 

&gt; 

&gt; *liam*  [8:21 AM]

&gt; Looks like either it was never fixed or it started happening again today at about 1am

&gt; 

&gt; [8:22 AM]

&gt; 

&gt; This file is hidden because it was uploaded more than 90 days ago. [https://betcode-org.slack.com/plans?feature=unlimited_messages|Upgrade to a paid subscription](https://betcode-org.slack.com/plans?feature=unlimited_messages|Upgrade to a paid subscription) to view.

&gt; 

&gt; 

&gt; 

&gt; 

&gt; *Robert*  [12:10 PM]

&gt; My machine must have been smoking, I wonder what's going on... (edited)

&gt; 

&gt; 

&gt; 

&gt; *liam*  [12:29 PM]

&gt; eventide issues apparently

&gt; 

&gt; [http://docs.eventide-project.org/](http://docs.eventide-project.org/)

&gt; 

&gt; 

&gt; *[http://docs.eventide-project.org|docs.eventide-project.org](http://docs.eventide-project.org|docs.eventide-project.org)*

&gt; *[http://docs.eventide-project.org/|Eventide](http://docs.eventide-project.org/|Eventide)*

&gt; Pub/Sub, Event Sourcing, Evented Microservices

&gt; 

&gt; 

&gt; 

&gt; *Gooat*  [6:48 PM]

&gt; Any ball park price numbers come back?

&gt; 

&gt; 

&gt; 

&gt; *liam*  [7:03 PM]

&gt; Nope

&gt; 

&gt; 

&gt; 

&gt; *liam*  [11:29 AM]

&gt; For those interested

&gt; 

&gt;&gt; You are more than welcome to come direct but we do have a minimum fee for direct customers that may be prohibitive to you of £2k per month and £150 per game.

&gt; 

&gt; 

&gt; 

&gt; *D C*  [11:46 AM]

&gt; 2K a month AND £150 a game. No idea if that's cheap or expensive to be fair

&gt; 

&gt; 

&gt; 

&gt; *Mo*  [11:48 AM]

&gt; Expensive compared to other sports but there’s easily enough liquidity in a match to extract that much EV

&gt; 

&gt; 

&gt; 

&gt; *liam*  [12:18 PM]

&gt; I read that as £150 a game, minimum 2k a month.

&gt; 

&gt; Update on the betfair feed is that I have continued hounding Neil to the point they have made some changes to the 'team' lots of politics/stupid code freezes but things have improved

&gt; 

&gt; 

&gt; 

&gt; *Lee*  [12:20 PM]

&gt; I noticed last month there was a big jump in quantity of matches with the feed. Up around 100 matches.

&gt; 

&gt; [12:20 PM]

&gt; Is that seasonal or from the improvements?

&gt; 

&gt; 

&gt; 

&gt; *liam*  [12:21 PM]

&gt; Both but we are now down to missing about 15% of the matches due to mapping, there where times last year where it was around 50%

&gt; 

&gt; 

&gt; 

&gt; *Lee*  [12:22 PM]

&gt; Big improvement

&gt; 

&gt; 

&gt; 

&gt; *Lee*  [2:03 PM]

&gt; How do you work out which markets are missing the feed?

&gt; 

&gt; 

&gt; 

&gt; *liam*  [2:09 PM]

&gt; nightly script to reconcile between market/feed data

&gt; 

&gt; 

&gt; 

&gt; *Lee*  [2:12 PM]

&gt; are we expecting every cricket match to have the feed?

&gt; 

&gt; 

&gt; 

&gt; *liam*  [2:13 PM]

&gt; pretty much, expect sub ~3% to not have a feed depending on what betfair put up

&gt; 

&gt; 

&gt; 

&gt; *Gooat*  [5:38 PM]

&gt; Has anyone levelled up to big stakes from the feed?

&gt; 

&gt; 

&gt; 

&gt; *liam*  [5:58 PM]

&gt; I am up to a few k exposure per market

&gt; 

&gt; 

&gt; 

&gt; *Gooat*  [6:02 PM]

&gt; Nice. Model or mix of price and flow? I struggled to avoid averse selection when testing it.

&gt; 

&gt; 

&gt; 

&gt; *liam*  [6:08 PM]

&gt; model

&gt; 

&gt; 

&gt; 

&gt; *Gooat*  [9:28 PM]

&gt; How did that game go?

&gt; 

&gt; 

&gt; 

&gt; *Sen*  [2:32 PM]

&gt; On this note - [@U4H19D1D2](@U4H19D1D2) how do you know Decimal is the best data provider in the cricket space? Something you've been able to test? (edited)

&gt; 

&gt; 

&gt; 

&gt; *liam*  [2:36 PM]

&gt; I don't, its just the one betfair provide

&gt; 

&gt; 

&gt; 

&gt; *Mo*  [2:37 PM]

&gt; I can say that the people behind it have been involved in cricket data for at least a decade

&gt; 

&gt; 

&gt; 

&gt; *Sen*  [3:15 PM]

&gt; Another option is sportmonks - they look pretty decent too

&gt; 

&gt; 

&gt; 

&gt; *liam*  [3:15 PM]

&gt; Yeah, considerably cheaper

&gt; 

&gt; 

&gt; 

&gt; *D C*  [4:31 PM]

&gt; Has the Betfair cricket feed not improved ?

&gt; 

&gt; 

&gt; 

&gt; *liam*  [7:23 PM]

&gt; Yes it has but it’s been hard work (for myself and Neil)



---

## 2024-10-13 15:29:11 - random channel

**Paul**

My take on it is not too far from the premise covered in [https://www.amazon.co.uk/Interception-Secrets-Modern-Sports-Betting-ebook/dp/B0CKS8GGX4/ref=sr_1_1?crid=3V8X13PPVX0S0&amp;dib=eyJ2IjoiMSJ9.rWpJIs_Gy1zJr2pM-4nqkGmV5GNE5Npr2krst8t4oyYAHRh-tyx88S1-pQeHsebQtU0ipaAqHftXXYPA8gbze8N1x9be32dRjgkSOyE4GomvmUktHTDq53aoo8a50-KQEYInDot_fdZPqjURXCxncspw4LDgXl9aHzOlHO7CBoIenKv5oc7A6_ZY81a8evFw3sb_VK80J-_5FauBF1NOuu6qcNPl45H_owT5TQGBBUY.uCKWCrPwifipksVyutW8QYay2w83z4Y7G-ltzZYKHxY&amp;dib_tag=se&amp;keywords=interception&amp;nsdOptOutParam=true&amp;qid=1728829608&amp;sprefix=interception%2Caps%2C102&amp;sr=8-1|Interception](https://www.amazon.co.uk/Interception-Secrets-Modern-Sports-Betting-ebook/dp/B0CKS8GGX4/ref=sr_1_1?crid=3V8X13PPVX0S0&amp;dib=eyJ2IjoiMSJ9.rWpJIs_Gy1zJr2pM-4nqkGmV5GNE5Npr2krst8t4oyYAHRh-tyx88S1-pQeHsebQtU0ipaAqHftXXYPA8gbze8N1x9be32dRjgkSOyE4GomvmUktHTDq53aoo8a50-KQEYInDot_fdZPqjURXCxncspw4LDgXl9aHzOlHO7CBoIenKv5oc7A6_ZY81a8evFw3sb_VK80J-_5FauBF1NOuu6qcNPl45H_owT5TQGBBUY.uCKWCrPwifipksVyutW8QYay2w83z4Y7G-ltzZYKHxY&amp;dib_tag=se&amp;keywords=interception&amp;nsdOptOutParam=true&amp;qid=1728829608&amp;sprefix=interception%2Caps%2C102&amp;sr=8-1|Interception) - most of these companies are going thin and broad because that's what their customer want/need. That means that it is likely possible to build better models than most of these firms can attempt.

---

## 2024-10-10 14:44:09 - general channel

**liam**

I think we have some issues to fix for 3.12 first :sweat_smile:

---

## 2024-10-08 20:55:22 - general channel

**Brøndby IF**

Hey guys, unfortunately the method I was using, even though I was passing the correct headers for my API access, has now started to generate a Cloudflare block that returns a direct error or an HTML page with the message "Please wait"



So it's possible that the Graph API doesn't allow collecting a request every 1 second when we want to request from multiple markets.



I don't think I will continue creating this code. I don't want any risk of having my account blocked.

---

## 2024-10-07 16:01:35 - general channel

**liam**

&gt; Hi Liam,

&gt; I have been informed that a fix was released this morning.

&gt; Kind Regards,

&gt; Karl

---

## 2024-10-07 14:41:26 - general channel

**liam**

ok but based on what you have told me it would be theoretically impossible for the stream not to raise an error if the latest patch was used

---

## 2024-10-07 14:34:12 - general channel

**liam**

hmm without seeing some debug logs its very tricky to debug

---

## 2024-10-07 14:32:23 - general channel

**Michael**

I have no idea then. All I can say is that I've had everything running this way since that last bunch of problems around June 2023 and I don't think it's failed even once until now.

---

## 2024-10-07 14:29:28 - general channel

**Michael**

I don't do anything to handle the socket timing out, does that raise an exception?

---

## 2024-10-07 14:20:04 - general channel

**liam**

How do you have this setup? ie. are you using tenacity or another way to restart on error?

---

## 2024-10-07 10:49:39 - general channel

**liam**

Neil is on holiday till the 10th, I have messaged bdp so will keep this thread updated if they reply, my money is that they have released something for the protocol fix.



However the bflw patch seems to be working for me

---

## 2024-10-05 08:16:47 - general channel

**liam**

I am going to modify the patch to just restart the stream after 5 minutes on a heartbeat, ie no data coming through the stream, it used to check the cache (`len(self._caches) == 0`) but obviously something else is going on, I haven't heard from [@UNW8Q88EL](@UNW8Q88EL)



```def _on_heartbeat(self, data: dict) -&gt; None:

    self._update_clk(data)



    # reset stream if no data and started over 5 minutes ago

    seconds_since_start = (

        datetime.datetime.utcnow() - self.time_created

    ).total_seconds()

    if seconds_since_start &gt; 300:

        markets = len(self._caches)

        logger.warning(

            "RaceStream no data, restarting",

            extra={"markets": markets, "seconds_since_start": seconds_since_start},

        )

        raise exceptions.ListenerError("", "")```

---

## 2024-10-04 19:46:42 - general channel

**D C**

Yeah I just checked my own. I do similar, it's just for a "dead" connection after startup until a few mins before first race (at least that's the fix that I put in my stuff probably not optimal but was sufficient).

---

## 2024-10-03 21:03:06 - general channel

**D C**

I've not looked at it in depth. Went 4 races with no bets placed. Logs said bet placement blocked because of "GPS errors" but this covers a variety of sins. I'll have to dig deeper for specifics. Restarted once - no solution. Restarted again - all good.

---

## 2024-10-03 18:56:22 - issues channel

**Matthew Lawrence**

Hi, I'm trying to login to betfair api. i have previously been using the interactive login. when I created a docker and access all files and parameters from amazon AWS, this login stops working and gives me ssl error. I'm a bit confused by this as i believed interactive login didnt require certs and ssl. i have since tried using the non interactive login but no matter what i get this error: Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3900)'))). Any help or advice would be greatly appreciated.

---

## 2024-10-03 15:17:05 - general channel

**Newbie99**

(I commented it out after seeing your message thinking that would work, but the error persisted)

---

## 2024-10-03 15:14:00 - general channel

**Newbie99**

Sorry [@U4H19D1D2](@U4H19D1D2), I'm not really understanding the error, the affected line is:



```framework.run()```

What should the syntax be, maybe I'm misunderstanding the error, but I thought this section relates to the Flumine package rather than my code, so I'm a bit confused:



```  File "/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flumine/strategy/strategy.py", line 279, in start

    s.start(flumine)

TypeError: start() takes 1 positional argument but 2 were given ```

---

## 2024-10-03 13:33:01 - general channel

**Newbie99**

I get this post upgrade:



```  File "/home/ec2-user/trading/env/projects/startup.py", line 208, in startup

    framework.run()

  File "/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flumine/flumine.py", line 27, in run

    with self:

  File "/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flumine/baseflumine.py", line 450, in __enter__

    self.strategies.start(self)

  File "/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flumine/strategy/strategy.py", line 279, in start

    s.start(flumine)

TypeError: start() takes 1 positional argument but 2 were given```



---

## 2024-10-03 08:39:08 - general channel

**liam**

bflw and flumine now fixed

---

## 2024-10-02 15:24:54 - general channel

**casper**

[@U4H19D1D2](@U4H19D1D2) are the cricket feed issues/errors purely because of issues on Betfair side or issues from Decimal also?

---

## 2024-09-26 16:20:51 - random channel

**Newbie99**

[@UQL0QDEKA](@UQL0QDEKA) I would agree on the comprehensive aspect. The way it answers is clearer (eg outlining logic and potential alternatives).



But I find it still makes really basic errors in some cases and still goes on loops where it just repeats the same erroneous response multiple times.



So far I’m not particularly impressed with it (vs 4o) tbh.

---

## 2024-09-26 16:09:52 - random channel

**ShaunW**

Haven't used o1 yet but I'm finding the new 'memory' feature to be a blessing and a curse. Once it's on the wrong track it's always been stubbornly wedded to it and those errors in understanding now compound across conversations.     I'm closing some convos with 'don't commit this to memory' because of it. The memory feature also raises new privacy issues imo.

---

## 2024-09-26 15:26:14 - random channel

**foxwood**

Ooh - didn't know that was there. Will have to try that and revisit some of the threads that "failed". Interesting that 4o can now look across all threads which should help but not seen evidence of that yet. Even so, have found 4o much better lately but it is making me lazy - I switch languages a lot so asking chat for silly stuff where I can't be bothered to check the docs for correct syntax lol

---

## 2024-09-26 13:02:38 - random channel

**PeterLe**

Just wondered if anyone has been using o1-preview...

Worth a look if you haven't used it before

Im finding it is generating 400+ lines of code for me (Zero errors) and enabling me to do this I could only dream about 6 months ago

(Revisiting my ML journey, when time permits)



Also finding the answers are much more comprehensive, providing alternates and things to consider etc

---

## 2024-09-25 20:54:57 - general channel

**AndyL**

Hi, I am trying to setup a new AWS Ubuntu 24.04 VM, and have all the python bits and pieces setup, and my certs folder, but am getting the following SSL error. I'm sure i've had this before, but can't remember how I resolved it, any ideas anyone? I'm thinking maybe an OpenSSL problem?

```HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(524297, '[SSL] PEM lib (_ssl.c:3895)'```

---

## 2024-09-19 19:23:04 - random channel

**Joe**

Problems like R4 the wrong horse and unsuspending would usually be fixed by voiding bets that occurred in the false future then undoing and redoing R4. But the general principle of rolling back a market to a previous state then voiding out the false future should always be applied.

---

## 2024-09-18 12:18:11 - random channel

**Unknown**

> To provide the definitive detail regarding TPD transponder / data errors. Below is the flow of the messages, from the data provider, Gmax,to the Bet Angel platform.

> 

> With regard to what Bet Angel displays :-

> When an "Assignment" warning occurs, the Pars Chart and the Real-time Map show a Red banner saying "Transponder Assignment Error"

> 

> When any other warning occurs, an Orange banner is displayed on those screens saying "TPD Warning: " + the warning string itself. I.e. currently 'Clock' or 'Field'.

> 

> For the Automation Conditions, Bet Angel does not distinguish between Clock & Field, they are both treated as 'Data Accuracy Warnings'. The Transponder Assignment Error can be tested individually in an Automation Condition.

---

## 2024-09-18 12:11:52 - random channel

**PeterLe**

By the way, I noticed in the BA forum that the TPD data via BA is now transmitted indicating whether a transponder has been mis assigned (ie to the wrong horse) and also some other errors

We dont get this via Betfair direct

---

## 2024-09-17 07:51:29 - general channel

**liam**

Any warning logs or errors? 

---

## 2024-09-17 07:00:17 - issues channel

**Thomas Conti**

When I do this without restricting market IDs, I get the error. What should I use to restrict the number of markets without picking market_ids?

Appreciate your help.



2024-09-17 15:14:34,927:ERROR:[MarketStream: 2006]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 206 markets whereas max allowed number was: 200



```strategy = LayStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["4339", '7'],  # Greyhound and Horse Racing

        country_codes=["AU", "NZ"],  # Australia and New Zealand

        market_types=["WIN"],  # Win markets

    )

)```



---

## 2024-09-16 10:35:13 - random channel

**liam**

Agreed, I have found the more you try and do with the data the worse it gets, keep it as raw as possible, there are going to be errors but considering you are against users who are betting almost blind it doesn't really matter

---

## 2024-09-16 08:38:51 - random channel

**D C**

I have to admit that when I watch "replays" of the race GPS feed I often witness unexplained lateral (as in perpendicular to current velocity vector) movement that is not apparent in a video replay of the race. But measurement error has always occurred and in all honesty I do think it has improved.

---

## 2024-09-16 08:38:38 - random channel

**Justice**

I don't have access to those files otherwise I would. [@UGV299K6H](@UGV299K6H) Perhaps it's a coincidence then, I just get frustrated with how often my model is making poor decisions due to errors in the data. Though I suppose if it was that good they wouldn't have made it available :joy:

---

## 2024-09-16 02:41:42 - issues channel

**Herugrim**

Question: If a Keep Alive is used and connections are not closed correctly, will they remain active until the Keep Alive duration expires? (And therefore increase the risk of MAX_CONNECTION_LIMIT_EXCEEDED errors? And if so, is there a function to end all active sessions?

---

## 2024-09-15 15:57:55 - random channel

**ShaunW**

In that example [@UPMUFSGCR](@UPMUFSGCR) the risk was always £90 for that very reason. Tech is famously falable and it's naive to assume the worse case scenario won't occur, especially if you're betting 247.



But I'd hope not thinking about that risk adequately would be a one time error, and as such it might not be a reason to stop. Unless you do it twice.

---

## 2024-09-13 20:22:21 - general channel

**foxwood**

[@U012XF5CNPN](@U012XF5CNPN) clever approach to tweaking params with a fairly fixed framework :slightly_smiling_face:

---

## 2024-09-13 20:19:25 - general channel

**foxwood**

[@U05N9773A23](@U05N9773A23) PyCharm runs the scripts for test/live itself in a tool window with interactive debug etc. They do a free community edition that does all of that stuff - can't remember why I upgraded to Pro - think it was just for the sql/db stuff which is not as good imho as ssms/redgate I discovered. Worth a look unless you're a dedicated 'xer - I gave all that up together with the wonders of vi a long long time ago.

---

## 2024-09-12 18:48:45 - strategies channel

**Justice**

[@U4H19D1D2](@U4H19D1D2) Yeh I just have level stake fixed liability at the moment. I used to use flumine. I have my own trading framework written in C# for production code. And I do backtesting using a custom Rust plugin for polars dataframes

---

## 2024-09-11 19:38:40 - issues channel

**foxwood**

Trying to place a lot of bets all together using a transaction. Involves iterating through own runner data stored in market context and calling various functions which also refer to the market context. All that results in a run time error

```    with market.transaction as t: TypeError: 'method' object does not support the context manager protocol```

Is there any easy way of working around this without removing all context usage from the loop (tried removing context for top level of loop and worked ok but fails due to context use in deeper function calls which would be complex to refactor) - presume strategy context would have the same issues ?

---

## 2024-09-06 21:41:22 - random channel

**Sam G**

Sorry guys, i realise i missed this one a few days back. Would love to attend the next one - is it fixed on October 15th now ? Thanks again [@U012XF5CNPN](@U012XF5CNPN) [@US2RWCWKY](@US2RWCWKY)

---

## 2024-09-06 18:38:57 - strategies channel

**Ralegh**

(Higher is likely to be an error/leaky data)

---

## 2024-09-05 12:59:55 - general channel

**ShaunW**

Try it as a sidehussle and if you match your salary for a year or two then maybe think about full time. You'll need to consider other factors such as this not being recognised as income and the affect on your credit status, esp if you want to remortgage your properties.



It's not easy though, knowing how to code won't make you a quant gambler anymore than buying a pencil will make you an architect. The people who make good money have usually been doing it for a decade or more. There's exceptions but they're exceptional people.

---

## 2024-09-04 21:11:25 - general channel

**Sam G**

Great question. I'm tired of running operations.. It drains me out. Depending on electricians and housekeepers to clean and fix properties ( else I lose money) , ensuring that inventory clerk comes in time. Running an operational business that depends on lots of other human beings is stressful



You might say: why don't you go do algo trading in financial markets. ... It's just not possible for an individual. You need big money at least £10million . Colocation near exchange etc



Hence sports trading. Hope that makes sense. Combines my love for trading and programming

---

## 2024-09-03 09:36:04 - strategies channel

**liam**

I think we are on different pages, if you can share some code that replicates the problem I can fix but it will be your code causing issues

---

## 2024-09-03 09:13:59 - strategies channel

**liam**

Fix your code so that it doesn't dupe?

---

## 2024-09-02 14:52:28 - general channel

**tone**

OK, I'm back. Bloodied but unbowed! So, after using the correct example, I feel I might finally be getting somewhere.

However I'm now struggling with this error:

    framework.run()

  File "d:\sports_trading\source_code\projects\trading\lib\site-packages\flumine\simulation\simulation.py", line 97, in run

    self._process_market_books(

  File "d:\sports_trading\source_code\projects\trading\lib\site-packages\flumine\simulation\simulation.py", line 124, in _process_market_books

    market = self._add_market(market_id, market_book)

  File "d:\sports_trading\source_code\projects\trading\lib\site-packages\flumine\baseflumine.py", line 216, in _add_market

    middleware.add_market(market)

  File "d:\sports_trading\source_code\projects\trading\lib\site-packages\flumine\markets\middleware.py", line 338, in add_market

    self._next = next(self._gen)

  File "d:\sports_trading\source_code\projects\trading\lib\site-packages\flumine\streams\historicalstream.py", line 239, in _read_loop

    if listener_on_data(update):

  File "d:\sports_trading\source_code\projects\trading\lib\site-packages\flumine\streams\historicalstream.py", line 225, in on_data

    return self.stream._process(data[self.stream._lookup], publish_time)

KeyError: 'rc'



The raw_data parameter in HistoricListener.on_data(..) is set to: '{"op":"mcm","clk":"-8312644392346355926","pt":1725022823949,"mc":[{"id":"[tel:335344121330|33534412.1330](tel:335344121330|33534412.1330)","mid":"1.232378340","rpc":{"ft":1725022823900,"g":"","st":0,"rt":0,"spd":0,"prg":1609.3,"ord":[],"J":[]}}]}\n'

This seems, to me at least, like plausible TPD data except of course that there is no "rc" key!

Do I need to do some sort of transformation of key values?

---

## 2024-09-02 11:34:02 - general channel

**tone**

Here's the DEBUG level logs: {"asctime": "2024-09-02 10:31:36,488", "levelname": "DEBUG", "message": "Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443%22}|identitysso-cert.betfair.com:443"}](http://identitysso-cert.betfair.com:443%22}|identitysso-cert.betfair.com:443"})

{"asctime": "2024-09-02 10:31:36,707", "levelname": "DEBUG", "message": "[https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) \"POST /api/certlogin HTTP/11\" 200 87"}

{"asctime": "2024-09-02 10:31:36,710", "levelname": "INFO", "message": "Client added", "username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": null, "transaction_count_total": null, "trading_controls": [], "order_stream": true, "best_price_execution": true, "paper_trade": false}

{"asctime": "2024-09-02 10:31:36,710", "levelname": "INFO", "message": "Adding market middleware &lt;flumine.markets.middleware.SimulatedMiddleware object at 0x00000191605B7460&gt;"}

{"asctime": "2024-09-02 10:31:36,711", "levelname": "INFO", "message": "Adding client control MAX_TRANSACTION_COUNT"}

{"asctime": "2024-09-02 10:31:36,711", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2024-09-02 10:31:36,711", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2024-09-02 10:31:36,711", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}

{"asctime": "2024-09-02 10:31:36,712", "levelname": "INFO", "message": "Adding strategy ExampleStrategy"}

{"asctime": "2024-09-02 10:31:36,712", "levelname": "DEBUG", "message": "{'uri': 'D:/test/1.232378340', 'mode': 'r', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd':

True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}"}

{"asctime": "2024-09-02 10:31:36,717", "levelname": "INFO", "message": "Creating new HistoricalStream (1000) for strategy ExampleStrategy", "strategy": "ExampleStrategy", "stream_id": 1000, "market_filter": "D:/test/1.232378340", "event_id": "33534412", "event_processing": false}

{"asctime": "2024-09-02 10:31:36,717", "levelname": "INFO", "message": "Starting flumine", "clients": {"Betfair": {}, "Simulated": {"15986142": {"username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x00000191605B7490&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 0, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 1200)&gt;"]}

{"asctime": "2024-09-02 10:31:36,718", "levelname": "INFO", "message": "Client login", "username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x00000191605B7490&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}

{"asctime": "2024-09-02 10:31:36,719", "levelname": "INFO", "message": "Client update account details", "username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x00000191605B7490&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}

{"asctime": "2024-09-02 10:31:36,719", "levelname": "INFO", "message": "Starting historical market 'D:/test/1.232378340'", "market": "D:/test/1.232378340"}

{"asctime": "2024-09-02 10:31:36,719", "levelname": "INFO", "message": "[Register: 1000]: marketSubscription"}

{"asctime": "2024-09-02 10:31:36,720", "levelname": "INFO", "message": "[MarketStream: 1000]: \"MarketStream\" created"}

{"asctime": "2024-09-02 10:31:36,720", "levelname": "DEBUG", "message": "{'uri': 'D:/test/1.232378340', 'mode': 'r', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd':

True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}"}

{"asctime": "2024-09-02 10:31:36,730", "levelname": "INFO", "message": "[MarketStream: 1000]: 1.232378340 added, 1 markets in cache"}

{"asctime": "2024-09-02 10:31:36,732", "levelname": "INFO", "message": "Adding: 1.232378340 to markets"}

{"asctime": "2024-09-02 10:31:39,061", "levelname": "INFO", "message": "Market 1.232378340 closed", "market_id": "1.232378340", "event_id": "33534412", "event_type_id": "7", "event_name": null, "market_type": "WIN", "market_start_datetime": "2024-08-30 13:30:00", "country_code": "GB", "venue": "Ffos Las", "race_type": "Flat", "orders_cleared": [], "market_cleared": [], "closed": true}

{"asctime": "2024-09-02 10:31:39,062", "levelname": "INFO", "message": "Market cleared", "market_id": "1.232378340", "order_count": 0, "clients": {"Betfair": {}, "Simulated": {"15986142": {"username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x00000191605B7490&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 1, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 1200)&gt;"]}

{"asctime": "2024-09-02 10:31:39,063", "levelname": "INFO", "message": "Market level cleared", "market_id": "1.232378340", "profit": 0, "bet_count": 0}

{"asctime": "2024-09-02 10:31:39,063", "levelname": "INFO", "message": "Market closed", "market_id": "1.232378340", "clients": {"Betfair": {}, "Simulated": {"15986142": {"username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x00000191605B7490&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 1, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 1200)&gt;"]}

{"asctime": "2024-09-02 10:31:39,064", "levelname": "INFO", "message": "Removing market 1.232378340", "clients": {"Betfair": {}, "Simulated": {"15986142": {"username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x00000191605B7490&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 1, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 1200)&gt;"]}

{"asctime": "2024-09-02 10:31:39,065", "levelname": "INFO", "message": "Completed historical market 'D:/test/1.232378340'"}

{"asctime": "2024-09-02 10:31:39,065", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

{"asctime": "2024-09-02 10:31:39,065", "levelname": "INFO", "message": "Shutting down Execution (BetfairExecution)"}

{"asctime": "2024-09-02 10:31:39,066", "levelname": "INFO", "message": "Client logout", "username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total":

0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x00000191605B7490&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}

{"asctime": "2024-09-02 10:31:39,066", "levelname": "INFO", "message": "Exiting flumine", "clients": {"Betfair": {}, "Simulated": {"15986142": {"username": "15986142", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x00000191605B7490&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 1, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 1200)&gt;"]}

{"asctime": "2024-09-02 10:31:39,067", "levelname": "INFO", "message": "Simulation complete"}

---

## 2024-08-30 19:21:51 - issues channel

**Rob**

Probably something dumb that I've done, but moved working flumine strategy simulation code from my linux laptop to a windows desktop and I'm now getting the following error:



```  File "C:\Users\xxx\anaconda3\envs\bfai\lib\site-packages\flumine\simulation\simulation.py", line 34, in run

    with self:

  File "C:\Users\xxx\anaconda3\envs\bfai\lib\site-packages\flumine\baseflumine.py", line 450, in __enter__

    self.strategies.start(self)

  File "C:\Users\xxx\anaconda3\envs\bfai\lib\site-packages\flumine\strategy\strategy.py", line 279, in start

    s.start(flumine)

TypeError: EarlyBackLay.start() takes 1 positional argument but 2 were given```

where `EarlyBackLay` is strategy I've created. The exact same code (e.g. reverted back to the github branch on both) is still working fine on linux, all I've done is update the path for the stored market data  to be the location  on the windows machine.



Anyone got any ideas?

---

## 2024-08-30 15:36:53 - general channel

**ShaunW**

.... Amending lays to adjust for liability/stake at the revised sp estimate, whether you amend back stakes depends on if you're using a fixed stake or fixed return.  But now I'm teaching granny to suck eggs I guess :wink:

---

## 2024-08-30 12:18:37 - betconnect channel

**Mo**

Nevermind, looks like someone fixed it at 10 am yesterday

---

## 2024-08-30 12:15:11 - betconnect channel

**Jimmy**

Your account should be open, getting an error?

---

## 2024-08-29 15:47:10 - issues channel

**river_shah**

Some have drunk the koolaid and love it but it stung sufficient times to be removed with great joy:

[https://news.ycombinator.com/item?id=34005203](https://news.ycombinator.com/item?id=34005203)

```Somehow I became the "poetry guy" at work, and I spend a meaningful amount of time debugging shit for people because the environment somehow got corrupted or something. If there's no issues I guess it's fine (dependency resolution time notwithstanding), but when you experience a persistent bug or environment issue, it takes nothing short of expertise to figure out how to sort it out without losing half a day.```



---

## 2024-08-28 14:04:20 - strategies channel

**liam**

np mate, let me know if this fixes it as I am fairly sure it will

---

## 2024-08-28 14:01:05 - strategies channel

**Aryan Kapoor**

i think that may be the issue and regardless thats an important thing to fix

---

## 2024-08-28 13:58:59 - strategies channel

**Aryan Kapoor**

cause i think that could be an issue i need to fix anyways

---

## 2024-08-28 13:36:34 - strategies channel

**liam**

In your strategy you are writing the headers for the 'theos.csv' file in `start`  so this is being wiped every time a new process starts, is this expected or the bug?

---

## 2024-08-27 21:04:40 - issues channel

**Brøndby IF**

Good afternoon everyone, the same code that I have been using for a long time that works with `betfairlightweight`, today started generating this error (`'Retry' object has no attribute 'backoff_max'`) and I am unable to understand exactly what it means, could you help me with this?



```betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook 

Params: {'marketIds': ['1.232273246', '1.232273382', '1.232273176', '1.232273175', '1.232273174', '1.232354831', '1.232324555', '1.232273308', '1.232324557', '1.232326330'], 'priceProjection': {'priceData': ['EX_BEST_OFFERS', 'EX_TRADED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}} 

Exception: 'Retry' object has no attribute 'backoff_max'```

---

## 2024-08-23 16:37:43 - strategies channel

**Paul**

Keep in mind published race distances aren't accurate. Every day the BHA publish rails changes for a [https://www.britishhorseracing.com/racing/fixtures/upcoming/racecard/#!/2024/1887|racecard](https://www.britishhorseracing.com/racing/fixtures/upcoming/racecard/#!/2024/1887|racecard) like [https://api09.horseracing.software/bha/v1/racecourses/distancechanges/csv/62/dc_62|this](https://api09.horseracing.software/bha/v1/racecourses/distancechanges/csv/62/dc_62|this). Often the changes are quite small but sometimes in the Winter you'll see distance changes over 110 yds (which is half a furlong), as they peg out to avoid false ground.

---

## 2024-08-20 15:51:30 - strategies channel

**Johnny Boston**

``` "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.231956835", "instructionReports": [{"status": "FAILURE", "errorCode": "INVALID_MIN_FILL_SIZE", "instruction": {"selectionId": 71661945, "handicap": 0.0, "limitOrder": {"size": 0.55, "price": 8.4, "minFillSize": 1.35, "timeInForce": "FILL_OR_KILL"}, "customerOrderRef": "43da61bd07abd-139434572457729620", "orderType": "LIMIT", "side": "LAY"}}]}, "order_package": {"id": "37bb203a-0748-4c5d-9931-442a5c2880fd", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f64af923b90&gt;", "market_id": "1.231956835", "orders": ["139434572457729620"], "order_count": 1, "package_type": "Place", "customer_strategy_ref": "[http://ip-10-2-8-71.eu|ip-10-2-8-71.eu](http://ip-10-2-8-71.eu|ip-10-2-8-71.eu)", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": true}}```

---

## 2024-08-20 15:50:47 - strategies channel

**Johnny Boston**

Anyone know why I would get an error like `"error_code": "INVALID_MIN_FILL_SIZE"` with this order?



:thread:

---

## 2024-08-19 14:56:35 - issues channel

**NAS**

fyi had equivalent/similar issues before setting force=True everywhere, was basically a quick-fix attempt

---

## 2024-08-19 13:12:02 - issues channel

**NAS**

yess, but this replace was executed (i think successfully) long before this call. i get a similar error message over and over again for each update in the order stream from bf, with no other logic than the repeated retry of "cancel order" being applied to the particular order

---

## 2024-08-19 12:31:52 - issues channel

**NAS**

having issues with cancelling certain orders despite setting force = True



the order status seems to be a flumine-thing and i thought setting force = True would avoid all checks against current logged status within the flumine instance, but this doesnt seem to be the case



any ideas?

`... - strategies - ERROR - OrderUpdateError - Issue while trying to cancel order ..., order status log: [&lt;OrderStatus.PENDING: 'Pending'&gt;, &lt;OrderStatus.EXECUTABLE: 'Executable'&gt;, &lt;OrderStatus.REPLACING: 'Replacing'&gt;], more info: Traceback (most recent call last):`

  `File "...", line 655, in process_orders`

    `market.cancel_order(order, force=True)`

  `File ".../site-packages/flumine/markets/market.py", line 97, in cancel_order`

    `return t.cancel_order(order, size_reduction, force)`

           `^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^`

  `File ".../site-packages/flumine/execution/transaction.py", line 101, in cancel_order`

    `order.cancel(size_reduction)`

  `File ".../site-packages/flumine/order/order.py", line 345, in cancel`

    `raise OrderUpdateError("Current status: %s" % self.status)`

`flumine.exceptions.OrderUpdateError: Current status: OrderStatus.REPLACING`

---

## 2024-08-18 12:44:45 - strategies channel

**Peter**

[@U016TGY3676](@U016TGY3676) If you're using the same paginator object, then they should be the same. But if you're creating a new paginator object because the session is interrupted, then there's no guarantee.



However, there may be a better way of handling this anyway. I use the S3 inventory feature to get a daily list of objects (or subsets with a key prefix) dumped into a bucket in parquet format (csv format also available). It gives you the same data but without the the need for iterating over a bonkers number of pages.



There are some limitations:

• The list is available no more frequently than daily (weekly or month are also available), but at a time determined by AWS, you have no control over this.

• Even when it arrives the data is typically 12 or more hours out-of-date, I suspect because they run the report against cached data.

But unless you need bang up-to-date data (which would be difficult anyway with buckets containing 1mn plus objects and the most recent at the end of the pagination), these probably aren't big issues. They haven't been for me.

---

## 2024-08-10 18:23:37 - general channel

**Dave**

Backtests are good - if your backtest for May + June look similar and look good, while your real performance for May matches backtest but June doesn't then likely you've broken something (i.e. you got a bug). If your backtest for June shows similar degradation then it suggests your alpha has degraded (either because some participants have scaled down, someone competitive has entereed etc). It might be a matter of recalibrating some params, or it might be a matter of resting the strategy and backtesting again in a few weeks to see if the breakage was transient or not.

---

## 2024-08-10 14:53:24 - general channel

**ShaunW**

.... Wish mine was user error, the source, config and server setup haven't been changed since July 2022.:thinking_face:

---

## 2024-08-10 14:51:28 - general channel

**D C**

Yeah I've enough years as a dev to know that the most likely source of error is the bloke working the keyboard.

---

## 2024-08-06 10:55:47 - general channel

**D C**

As if the behaviour of offering prices in that particular manner is somehow underhand and against the spirit of Betdaq. I mean it is designed to catch someone's error but fuck it - it's a cruel world and the burned hand is the best lesson against playing with matches. I'm all for a Darwinian approach but seems Betdaq want to protect "regular" users.

---

## 2024-08-06 10:52:55 - strategies channel

**D C**

[@U01PJ5YMFBJ](@U01PJ5YMFBJ) IF you stick to pre-race you've got the added bonus in that you can use BSP as a measure to assess your success. Inplay that is not so easy to do. Inplay, you've got delays  - bet placement and internet latency (the latter being variable to some extent) so this makes back testing and simulating stuff more error prone. Then you've got things like offering prices versus taking (the former again harder to simulate and back test - impossible to PRECISELY assess the impact of your offers on the market). Your time is your own to spend of course but how much time have you invested in pre-off horses? Are you looking to move because you think increased volatility inplay is more attractive or because you feel you've hit a brick wall on the pre-race side? Or have you just become downbeat and demotivated because you haven't "cracket it" yet?

You've got to consider that you might never get there - I'm not trying to demotivate you at all but its an event with a non-zero probability. And if you flit around too much from sport to sport or mixing market phases you might do more harm than good.

I don't know your background but have you got the maths/stats chops to considered using some fundamental data instead/in addition your market based variables?

---

## 2024-08-06 10:52:24 - general channel

**foxwood**

Too early in the morning for me - can't see what's wrong ? a) didn't think there was anything like a "palpable error" on an exchange b) Edna's (sic) comment is an ambiguous Irish typo that could mean "paid", "pallpd" or "pulled". I'd take it as meaning the original £10 back bet at 88 will get pulled by the bettor. What am I missing ?

---

## 2024-08-06 06:59:07 - strategies channel

**liam**

Agree with above however racing has the advantage of a lot of opportunities, you can spend an afternoon testing / debugging on live markets. This is invaluable when starting out, sports like cricket really slow your progression down due to the smaller number of markets. 

---

## 2024-08-01 13:07:57 - general channel

**ShaunW**

Similar humble start [@UUE6E1LA1](@UUE6E1LA1), my old man always used to say he wanted to be the guy who paid the most tax. Took me a while to understand that. 



PC seems bad but compared to almost anything else that's legal we have mercifully low fixed overheads. No buildings, no wages, no accountant, no insurance, no stock etc etc. Throw in complete freedom about when and how hard to work..... Most would kill for the deal we get. If people don't like it, they should try a proper job and see how that goes.

---

## 2024-08-01 09:49:14 - issues channel

**Jorge**

Hi, I'm getting these errors in a Flumine Simulation: Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failed: reset_elapsed_seconds (-0.99) &lt; reset_seconds (0.0).

What does [https://github.com/betcode-org/flumine/blob/master/flumine/strategy/runnercontext.py#L60|reset_elapsed_seconds](https://github.com/betcode-org/flumine/blob/master/flumine/strategy/runnercontext.py#L60|reset_elapsed_seconds) mean?

---

## 2024-07-27 22:02:54 - general channel

**Michael**

I'm curious as to why you stopped betting completely rather than just scaling back your stakes? That would have left you with much better data and probably some cash. Of all the problems you can have over scaling is the easiest to fix.

---

## 2024-07-27 17:35:38 - issues channel

**Lee**

you’ll probably need to put a debugger on it and see what’s happening

---

## 2024-07-26 16:56:25 - strategies channel

**thambie1**

You need stake sizing to manage two problems. Adverse selection, and risk. The approach me and Mo take is exceptionally good at the latter, and only somewhat at the former. If you don't have a risk problem (i.e. massive variance in your profit graph), likely not worth the effort

---

## 2024-07-25 18:05:26 - strategies channel

**liam**

I ignore exposure and bet based on a state change, so for TPD it’s an update (with a delay as I don’t want to be every update) and cricket it’s a new ball. 



Basic premise is to reduce risk and try not to have a large exposure on a single ‘state’ that might contain errors / latency that is out of my control 

---

## 2024-07-23 10:52:39 - issues channel

**Jared King**

rgr that. fixed your code:

```runner_context = self.get_runner_context(market_id, selection_id, handicap)

if runner_context.live_trade_count == 0:

    lose money```

---

## 2024-07-17 22:12:27 - general channel

**Michael**

Yeah you did - but in case anyone missed it here's the summary:



1: You've got to have value.



2: Don't "green up", it breaches 1.



3: If your bot does good with small stakes but crashes when you increase your stakes you can fix it by reducing your stakes again.



That's basically it.

---

## 2024-07-15 07:56:59 - issues channel

**Derek C**

If I see messages in Flumine that it's "likely that the thread pool is currently exhausted", what should I look for to fix this, i.e.

1. increase the parameter in flumine config to allow more threads

2. buy a bigger machine

3. look for a bug in my code?

I tried doubling the parameter in Flumine "flumine.max_execution_workers" but it didn't cure the problem.

---

## 2024-07-11 00:04:27 - strategies channel

**thambie1**

@James I have done cost experiments for zipped vs unzipped. I found unzipped to be cheaper in my use case. You should have cpu profiling working and be able to do such experiments yourself if you want to make optimizations of this kind. That being said, the financial choice is clear to just buy a better dev machine if that can fix your problem, unless your really not valuing your time to go the cloud route. It really is a time sink, trust me.

---

## 2024-07-06 09:30:25 - issues channel

**Unknown**

i got it fixed, after synching ntp the server time still wasn't adjusted until i rebooted the VPS. Strange that it doesn't fix itself until reboot. Even docker gave wrong times after reboot too, so that threw me off. Anyway, thanks for everyone's help. It's a long pain in the arse but it's finally fixed

---

## 2024-07-05 16:27:10 - issues channel

**birchy**

Lesson 1: if it ain't broke, don't fix it.

Lesson 2: make sure you have NTP running on your server

---

## 2024-07-05 10:06:59 - issues channel

**Unknown**

i updated the clock. rounding errors went away but still sub 1ms

---

## 2024-07-05 08:47:47 - issues channel

**Adrian**

Yes. WHen you calculate latency by dividing market epoch by 1e3 you get 1000s of a second errors. Because the numbers are exactly the same up to the decimal point

---

## 2024-07-05 08:42:40 - issues channel

**Adrian**

If you notice its all rounding errors

---

## 2024-07-04 13:54:53 - general channel

**D C**

But surely simulation/backtest errors/assumptions effects of your own money on the market etc. would dwarf tiny fluctations in currency? No backtest can be flawless. I might understand if you were trading using some crypto shitcoin that can change 50% in an hour, but surely no fiat currency fluctuates in any significant sense over such small timeframes? I mean obviously your time is your own to do with what you will, but I'd have thought there are better ways to spend time?

---

## 2024-07-03 08:21:28 - general channel

**liam**

Looks like either it was never fixed or it started happening again today at about 1am

---

## 2024-07-02 19:53:46 - general channel

**liam**

Recent, started today at 11:45ish, apparently now fixed 

---

## 2024-07-02 16:19:40 - general channel

**liam**

Yeah, I imagine there will be an optimum, trial &amp; error / a/b testing / randomness can get you there

---

## 2024-07-01 10:09:50 - issues channel

**Lee**

what happens in the “…” section? Any errors? any logs showing an attempt to change the status?

---

## 2024-06-28 12:13:13 - issues channel

**Peter**

I'm trying to use betfairviz to visualise market books from self recorded files. I'm using the create_dashboard function but getting a recursion depth error. Not quite sure where I'm going wrong, please could someone point me in the right direction?

---

## 2024-06-26 15:21:56 - general channel

**foxwood**

@DC as in Peter's script ask for the info within the startup of your program. The entry will still appear on the screen if scrolled back so input should be without echo or take steps to erase after entry. You just don't want to leave it lying around imho. If, as you say, you pass it as a startup argument then it will be in the ps list / python console history. If you PM me the compiled binary you mentioned earlier then I'll run it under debug which will make it easier for me to see all the literal strings in the program or if encrypted single step through until it appears in plain text. Secrets such as pwd etc and keys should never be stored in the same place.

---

## 2024-06-26 11:19:49 - general channel

**PeterLe**

Yes you would use that as well DC ie :

```print("Loading environment variables...")

load_dotenv('details.env')



myacc = os.getenv('USER_SUB1')

if not myacc:

    raise ValueError("Account name not set in environment variables")



mypass = os.getenv('PASS_SUB1')

if not mypass:

    raise ValueError("Password not set in environment variables")



app_key = os.getenv('APP_KEY_SUB1')

if not app_key:

    raise ValueError("App key not set in environment variables")



print("Prompting for 2FA...")

two_fa = input("Please enter your 6-digit Google Authenticator code for Sub1: ")



mypass += two_fa

certs_path = r"C:\certs"



print("Creating API client...")

trading = betfairlightweight.APIClient(myacc, mypass, app_key, certs=certs_path)



print("API Client created, proceeding ...")```



---

## 2024-06-25 10:47:50 - issues channel

**foxwood**

The reason for my fix was to stop wasting time running my code but let the underlying bet matching simulation take place as each packet came through so I got to closed market asap. That reason came to me in the night lol. So, yes there are two cases, stop calling user code and also an abandon (with / without calling closed_market ? - variations grow !)

---

## 2024-06-22 11:44:52 - strategies channel

**Adrian**

`'Error: strategy.validate_order failed: live_trade_count (1) >= max_live_trade_count (1)'`

Is this limit explicitly defined somewhere?

I haven't changed it. Is it just a default safety measure in flumine or something?

---

## 2024-06-19 18:13:47 - issues channel

**Cian Ryan**

EDIT: the PEM pass just turned out to be my password for the database after I tried it in the cmd.



I am getting a new error, however:

betfairlightweight.exceptions.LoginError: API login: CERT_AUTH_REQUIRED



My login details are correct as they work in the websites (both exchange and API). What else causes this issue? login_interactive() works but .login() does not so it should be an issue with my credentials.

---

## 2024-06-18 23:51:12 - issues channel

**Cian Ryan**

Hi all, I am following the betfairlightweight tutorial using Colab notebook. When I call the API however i get a HTTP 403 error. Could this be due to the server potentially being in the US? Same code works fine on local drive, although i have to use the less secure login_interactive() in both cases as I couldn't get it to authenticate my certs.



is there any way around this?

---

## 2024-06-18 15:10:25 - random channel

**D C**

Shit. I managed £4.54 after commission. Lots of "Bet placement blocked due to GPS errors messages" still. Lots.

---

## 2024-06-17 10:42:45 - general channel

**foxwood**

Given that python assignment defaults to "by reference" is there any reason that I shouldn't keep my own list of orders by runner eg `my_runnerX.orders.append(o)` Some quick tests with debug shows that it seems to work ok for simple limit bets ie the blotter orders are == my "copies" at `process_closed_market` Wondering if flumine might recreate the order at any time eg for cancel, modify price/size etc - if so that would break this approach

---

## 2024-06-16 15:42:58 - strategies channel

**Rob**

In terms of the process I coded up, it's effectively:



1. Get all matched orders on the market (and check there are no unmatched orders left)

2. If the back/lay amount for each selection are not even, record the size of the discrepancy (at this point, match price isn't important)

    a. for example, if you've backed runner A for £100 and layed for £90, record a £10 lay bet against this runner

3.  Get your current P&amp;L per runner via `list_market_profit_and_loss` , simulate the effect of adding the bets above to the result at the current prices, and, and get the current prices for the market

4. For runners where you're in profit, record that you want to lay with size `current_profit / current_lp` 

5. For runners where you're losing, record that you want to back with size `( current_loss) / current_bp` 

6. Add the greening bets from steps 4 and 5 to the bets from step 2, and place them at the current back/lay prices and you should have a greened book

The only other complexities are around bet sizes - if you're betting relatively small amounts and include longer odds runners you will be below the minimum bet size. You can place a £1 bet far away from the current prices and then reduce the size, then the price.



At some point you can't do this as you run in to errors from betfair around what's allowed, but at that stage, the amounts of money are small enough not worry about greening

---

## 2024-06-13 18:03:03 - issues channel

**Rodolfo**

hey, I am not a pro coder but I managed to create a script that places bets. Works fine. But I am helping a friend that lives in Sweden, he gets a AUTHORIZED_ONLY_FOR_DOMAIN_SE error. How can I ask betfairlightweight to try the SWEDEN exchange?



trading = betfairlightweight.APIClient(EMAIL, PASSWORD, app_key=API_KEY_DELAYED)

trading.login_interactive()



Thank you.

---

## 2024-06-04 11:02:47 - betconnect channel

**Ben**

anyone know why putting accept each way to 0 gives me invalid payload error but 1 is fine?

---

## 2024-06-01 20:09:28 - random channel

**ShaunW**

Implied comm rate is fixed, across all markets, even if you choose a higher UK base rate via the 'rewards plan' levels. FYI You can't change your base comm rate on Antipodean markets and MBR discounts earned on those markets don't affect the implied 3%.

---

## 2024-06-01 12:45:57 - random channel

**D C**

Is it possible to increase your implied commission on losses by increasing your own personal commission rate, or is it fixed at 3% regardless?

---

## 2024-05-30 13:34:58 - betconnect channel

**trev**

Hi, I have tried but unfortunately I still get the same 401 error

---

## 2024-05-30 12:34:29 - betconnect channel

**trev**

import betconnect

import requests

from requests.auth import HTTPBasicAuth

from time import sleep



# Define your username, password, URL, and additional data

username = 'developer-not shown here'

password = 'not shown here*'

login_url = '[https://developer.betconnect.com/api/v2/login](https://developer.betconnect.com/api/v2/login)'

balance_url = '[https://developer.betconnect.com/api/v2/get_balance](https://developer.betconnect.com/api/v2/get_balance)'

data = {

    'api_code': '2468163c-5efb-47f1-8952-789ae3d60652'

}



try:

    # Send the POST request to the login endpoint

    login_response = [http://requests.post|requests.post](http://requests.post|requests.post)(login_url,      auth=HTTPBasicAuth(username, password), json=data)

    login_response.raise_for_status()  # Raise an error for bad status codes



    # Parse the JSON response to get the access token

    login_data = login_response.json()

    if login_response.status_code == 200:

        token = login_data['data']['token']

        print('Login Status Code:', login_response.status_code)

        print('Login Response Text:', login_response.text)

    elif login_response.status_code == 400:

        print('Login Error:', login_data['message'])

    elif login_response.status_code == 401:

        print('Login Error: Could not verify Username and Password.')

    elif login_response.status_code == 403:

        print('Login Error:', login_data['message'])

    else:

        print('Login Error: Unexpected status code:', login_response.status_code)



except requests.exceptions.RequestException as e:

    print('An error occurred during login:', e)

    token = None



if token:

    # Introduce a delay

    sleep(1)



    # Send the GET request to the balance endpoint with the token

    headers = {

        'accept': 'application/json',

        'Authorization': f'Bearer {token}'

    }



    try:

        # Send the GET request to the balance endpoint

        balance_response = requests.get(balance_url, headers=headers)

        balance_response.raise_for_status()  # Raise an error for bad status codes

        print('Balance Status Code:', balance_response.status_code)

        print('Balance Response Text:', balance_response.text)

    except requests.exceptions.RequestException as e:

        print('An error occurred while fetching the balance:', e)

else:

    print('Login failed; skipping balance request.')

---

## 2024-05-30 11:40:46 - betconnect channel

**trev**

I have api key and url but get error 401 all the time, although winsocket works ok for bookmaker price changes.

---

## 2024-05-29 12:48:49 - general channel

**liam**

I don't think so, if you look at that error message it doesn't align with the code in 0.2.1

---

## 2024-05-29 12:46:00 - general channel

**liam**

actually won't matter, you can upgrade the betconnect repo and it should fix it

---

## 2024-05-29 12:18:13 - general channel

**George**

When setting up CI on GitLab I am encountering a lot of warnings about Pydantic via Betconnect. They look like this:



```../../usr/local/lib/python3.9/site-packages/betconnect/resources/betting.py:92

  /usr/local/lib/python3.9/site-packages/betconnect/resources/betting.py:92: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at [https://errors.pydantic.dev/2.6/migration/](https://errors.pydantic.dev/2.6/migration/)```

Does anyone know why this is happening? Am I using the wrong version of something?

---

## 2024-05-24 14:28:47 - general channel

**Mo**

If you're looking at the _original_ code before I fixed it today then yes I believe there was the bug you describe

---

## 2024-05-24 09:23:45 - general channel

**Mo**

[@UCQB6S222](@UCQB6S222) should be fixed in the next release branch if you'd like to test it

---

## 2024-05-23 11:26:16 - general channel

**Mo**

Create an issue on GitHub and I’ll fix it 

---

## 2024-05-23 11:23:38 - general channel

**George**

I'm having a small issue with `remove_bet_from_runner_book` in betfairutil.

In simulation, the runner-book is a `RunnerBook` object, but the "price-size" objects contained within it are all `dict` objects. The function expects each price-size to be a `PriceSize` object and so it throws an `AttributeError`.



Am I doing something wrong here?

---

## 2024-05-19 21:27:08 - strategies channel

**foxwood**

I've combined them into 1 strat for now but would be nice to get this working. Code follows docs I think but don't remember anything special on multi markets ? These are the main bits of code

`dataDir = "path to directory"`

`strats = [launchTest1, launchTest2]`

`markets = [globbed list of fully pathed file names]`

`client = clients.SimulatedClient()`

`framework = FlumineSimulation(client=client)`



`with mock_patch("builtins.open", smart_open.open):`

    `for launch in strats :`

        `launch(framework, markets, client)`

    `middleware.marketcatalogue.MARKET_CATALOGUE_PATH = dataDir`

    `framework.add_market_middleware(MarketCatalogueMiddleware())`

    `try:`

        `framework.run()`

    `except Exception as e:`

        `print( traceback.format_exc() )`



`In separate file for each strategy:`



`def launchTestN(framework, markets, client):`

    `launchtest(framework, markets, client)`



`def launchtest(framework, markets, client):`

    `framework.add_strategy(`

        `stratN(`

            `name=stratN.__name__,`

            `market_filter={"markets": markets,`

                           `"listener_kwargs": {}`

                           `},`

            `max_order_exposure=999,`

	         `etc,`

            `context={"client": client, },`

        `)`

    `)`

---

## 2024-05-16 08:24:00 - issues channel

**Jorge**

Hey guys, I recently started Simulating 2 strategies in the same flumine instance, with the goal of running them live. Until now, I was running both strategies in different scripts. This is my code:



```client = clients.SimulatedClient()

framework = FlumineSimulation(client=client)



control = BacktestLoggingControl(logs_dir=logs_dir)

framework.add_logging_control(control)



with patch("builtins.open", smart_open.open):

    framework.add_strategy(strategy_1)

    framework.add_strategy(strategy_2)

    framework.add_market_middleware(MarketCatalogueMiddleware(strategy_2.market_filter["markets"]))

    framework.run()```

My issue is with the [https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py](https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py) , I noticed that in my orders.txt, the orders from strategy_1 are duplicated. The same happens with the markets.txt (cleared_markets), I get double the amount of cleared_markets and the last half is the correct one which includes both strategies. How could I fix this so the [https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py](https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|backtestloggingcontrol.py) works when running multiple strategies in the same instance?

---

## 2024-05-15 11:12:49 - random channel

**Johnny**

I've found it is useful in fixing errors or figuring out how to do something very specific, as long as you know exactly what it is you want to achieve.  Big-picture stuff, not much use

---

## 2024-05-13 19:27:11 - issues channel

**Unknown**

I noticed a couple of errors earlier (Status Code error 520 and 404)

(Out of interest, If i had this setting :



```logging.getLogger().setLevel(logging.CRITICAL)```

Would I see the errors you see Lee?

---

## 2024-05-13 10:32:06 - issues channel

**Johnny**

```"/home/xxx/anaconda3/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 47, in request\n    check_status_code(response)\n  File \"/home/xxx/anaconda3/lib/python3.11/site-packages/betfairlightweight/utils.py\", line 37, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 404", "client": "APIClient", "trading_function": "account.get_account_funds", "response": "Status code error: 404"}```

---

## 2024-05-13 10:13:29 - issues channel

**liam**

Anyone else getting 404 errors on the account endpoint?

---

## 2024-05-09 21:29:31 - issues channel

**Ammar**

:+1:  lmk if that fixes if for you locally; can then create a PR and see what the repo owner group have to say

---

## 2024-05-09 21:26:08 - issues channel

**Ammar**

&gt;  replacing the ‘or’ with an ‘and’ fixes it?

it’s what’s highlighted in the code block inside the message linked above.  if keep alive returns a `None` then force a login; that’s it

---

## 2024-05-09 21:24:24 - issues channel

**Ammar**

yeh.  I ran in the fix which is in the thread, and it seemed to resolve that specific issue.  I’m petitioning to get it into flumine, happy to open a PR, but some discussion around the criteria for doing so in the original thread

---

## 2024-05-09 21:21:51 - issues channel

**NAS**

my understanding of the logic:

(1) if theres an issue with the current session, try to refresh it/keep it alive

(2) if this for some reason fails, run a new login instead



as you mentioned it looks like there are unexpected responses coming through that throws exceptions and never lets (2) come into play

---

## 2024-05-09 21:17:39 - issues channel

**NAS**

did you fix it/get any help?

---

## 2024-05-09 15:33:14 - issues channel

**NAS**

my bots went down earlier today due to the maintenance and when this happens flumine fails to reconnect, seems there's an issue with the keep_alive worker? checking code seems to suggest it should always attempt a new login if theres an issue with the sessions?



`2024-05-09 13:23:24,033 - flumine.clients.betfairclient - ERROR - BetfairClient `keep_alive` error`

`Traceback (most recent call last):`

  `File ".../flumine/clients/betfairclient.py", line 44, in keep_alive`

    `return self.betting_client.keep_alive()`

           `^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^`

  `File ".../betfairlightweight/endpoints/keepalive.py", line 30, in __call__`

    `(response, response_json, elapsed_time) = self.request(session=session)`

                                              `^^^^^^^^^^^^^^^^^^^^^^^^^^^^^`

  `File ".../betfairlightweight/endpoints/keepalive.py", line 60, in request`

    `self._error_handler(response_json)`

  `File ".../betfairlightweight/endpoints/keepalive.py", line 67, in _error_handler`

    `raise self._error(response)`

`betfairlightweight.exceptions.KeepAliveError: API keepAlive FAIL: NO_SESSION`

`2024-05-09 13:23:24,038 - flumine.worker - ERROR - Error in BackgroundWorker keep_alive: 'NoneType' object has no attribute 'status'`

`Traceback (most recent call last):`

  `File ".../flumine/worker.py", line 66, in run`

    `self.function(`

  `File "..../flumine/worker.py", line 106, in keep_alive`

    `if resp is True or resp.status == "SUCCESS":`

                       `^^^^^^^^^^^`

`AttributeError: 'NoneType' object has no attribute 'status'`

---

## 2024-05-09 06:44:02 - general channel

**rmwesley**

I think I'm explaining myself badly, apologies :joy: I'm not interested in porting my current system to flumine. I'd like to start from scratch and build something completely new. I was hoping to short circuit a few years of trial-and-error by starting to back-test systems using a general approach which was battle proven in flumine, e.g. either what I call a statistical approach (e.g. purely using historic race data to optimise a target variable like ROI), or a classic technical analysis approach (e.g. finding head-and-shoulders patterns), or a price action approach (betting / laying into support/resistance levels etc.), or something else?



Thanks if you have had the strength to read this far.

---

## 2024-05-07 09:41:14 - issues channel

**Ammar**

here’s where I’ve got to for anyone who was interested in this:



• running the suggested hotfix locally did suppress the initial error I was getting (to handle the `None` return case)

• but i then got other errors coming from betfair (invalid session on polling the account details endpoint; and one other)

• that’s when i tried another background worker to do some more session management - but the issue persisted

• I was seeing this on a totally “vanilla” run (no vpn, no other sessions, small number of events on the filter) after about 4-5 hours of the stream being up

• I’ve got a ticket open with BDP now to get more insight

---

## 2024-05-07 09:32:59 - issues channel

**Adrian**

Ok yep, got it to the next step. It runs the first cell but encounters KeyError: 'name' in the second cell :

`df = pd.merge(df, df_strategies, left_on="trade__strategy", right_on="name", how="left")`

There's no 'name' column in any of the dataframes

---

## 2024-05-06 13:36:55 - general channel

**Adrian**

Single market:

&gt;        1044 function calls (1041 primitive calls) in 0.001 seconds

&gt; 

&gt;    Ordered by: standard name

&gt; 

&gt;    ncalls  tottime  percall  cumtime  percall filename:lineno(function)

&gt;         8    0.000    0.000    0.000    0.000 &lt;frozen genericpath&gt;:121(_splitext)

&gt;         8    0.000    0.000    0.000    0.000 &lt;frozen posixpath&gt;:117(splitext)

&gt;         8    0.000    0.000    0.000    0.000 &lt;frozen posixpath&gt;:140(basename)

&gt;         8    0.000    0.000    0.000    0.000 &lt;frozen posixpath&gt;:41(_get_sep)

&gt;        24    0.000    0.000    0.000    0.000 &lt;frozen posixpath&gt;:52(normcase)

&gt;         1    0.000    0.000    0.001    0.001 &lt;string&gt;:1(&lt;module&gt;)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1087(flush)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1098(emit)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:123(getLevelName)

&gt;         2    0.000    0.000    0.000    0.000 __init__.py:1319(disable)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1479(info)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1561(findCaller)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1595(makeRecord)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1610(_log)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1636(handle)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:164(&lt;lambda&gt;)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1690(callHandlers)

&gt;         2    0.000    0.000    0.000    0.000 __init__.py:1720(getEffectiveLevel)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:1734(isEnabledFor)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:183(dumps)

&gt;        24    0.000    0.000    0.000    0.000 __init__.py:194(_is_internal_frame)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:2223(handle)

&gt;         2    0.000    0.000    0.000    0.000 __init__.py:228(_acquireLock)

&gt;         2    0.000    0.000    0.000    0.000 __init__.py:237(_releaseLock)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:292(__init__)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:368(getMessage)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:606(formatTime)

&gt;        16    0.000    0.000    0.000    0.000 __init__.py:815(filter)

&gt;        16    0.000    0.000    0.000    0.000 __init__.py:922(acquire)

&gt;        16    0.000    0.000    0.000    0.000 __init__.py:929(release)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:942(format)

&gt;         8    0.000    0.000    0.000    0.000 __init__.py:965(handle)

&gt;         1    0.000    0.000    0.000    0.000 accountresources.py:17(__init__)

&gt;         5    0.000    0.000    0.000    0.000 baseclient.py:101(transaction_count_total)

&gt;         5    0.000    0.000    0.000    0.000 baseclient.py:120(info)

&gt;         5    0.000    0.000    0.000    0.000 baseclient.py:87(username)

&gt;         5    0.000    0.000    0.000    0.000 baseclient.py:94(current_transaction_count_total)

&gt;         2    0.000    0.000    0.000    0.000 baseexecution.py:156(shutdown)

&gt;         2    0.000    0.000    0.000    0.000 baseflumine.py:124(log_control)

&gt;         1    0.000    0.000    0.000    0.000 baseflumine.py:128(_add_default_workers)

&gt;         1    0.000    0.000    0.000    0.000 baseflumine.py:401(_process_end_flumine)

&gt;         2    0.000    0.000    0.000    0.000 baseflumine.py:404(info)

&gt;         2    0.000    0.000    0.000    0.000 baseflumine.py:412(&lt;listcomp&gt;)

&gt;         1    0.000    0.000    0.000    0.000 baseflumine.py:417(__enter__)

&gt;         1    0.000    0.000    0.000    0.000 baseflumine.py:445(__exit__)

&gt;         1    0.000    0.000    0.000    0.000 baseresource.py:11(__init__)

&gt;         5    0.000    0.000    0.000    0.000 clientcontrols.py:108(current_transaction_count_total)

&gt;         5    0.000    0.000    0.000    0.000 clientcontrols.py:112(transaction_count_total)

&gt;         1    0.000    0.000    0.000    0.000 clients.py:56(login)

&gt;         1    0.000    0.000    0.000    0.000 clients.py:66(logout)

&gt;         1    0.000    0.000    0.000    0.000 clients.py:71(update_account_details)

&gt;         1    0.000    0.000    0.000    0.000 clients.py:76(simulated)

&gt;         2    0.000    0.000    0.000    0.000 clients.py:84(info)

&gt;         2    0.000    0.000    0.000    0.000 clients.py:86(&lt;dictcomp&gt;)

&gt;         6    0.000    0.000    0.000    0.000 clients.py:87(&lt;dictcomp&gt;)

&gt;         1    0.000    0.000    0.000    0.000 clients.py:94(__len__)

&gt;         8    0.000    0.000    0.000    0.000 encoder.py:105(__init__)

&gt;         7    0.000    0.000    0.000    0.000 encoder.py:161(default)

&gt;         8    0.000    0.000    0.000    0.000 encoder.py:183(encode)

&gt;         8    0.000    0.000    0.000    0.000 encoder.py:205(iterencode)

&gt;        11    0.000    0.000    0.000    0.000 enum.py:1255(value)

&gt;        11    0.000    0.000    0.000    0.000 enum.py:193(__get__)

&gt;         2    0.000    0.000    0.000    0.000 events.py:39(__init__)

&gt;         7    0.000    0.000    0.000    0.000 inspect.py:456(istraceback)

&gt;         8    0.000    0.000    0.000    0.000 jsonlogger.py:176(add_fields)

&gt;         8    0.000    0.000    0.000    0.000 jsonlogger.py:193(_perform_rename_log_fields)

&gt;         8    0.000    0.000    0.000    0.000 jsonlogger.py:198(process_log_record)

&gt;         8    0.000    0.000    0.000    0.000 jsonlogger.py:205(jsonify_log_record)

&gt;         8    0.000    0.000    0.000    0.000 jsonlogger.py:213(serialize_log_record)

&gt;         8    0.000    0.000    0.000    0.000 jsonlogger.py:217(format)

&gt;         8    0.000    0.000    0.000    0.000 jsonlogger.py:28(merge_record_extra)

&gt;         7    0.000    0.000    0.000    0.000 jsonlogger.py:59(default)

&gt;         4    0.000    0.000    0.000    0.000 markets.py:54(markets)

&gt;         2    0.000    0.000    0.000    0.000 markets.py:58(open_market_ids)

&gt;         2    0.000    0.000    0.000    0.000 markets.py:60(&lt;listcomp&gt;)

&gt;         2    0.000    0.000    0.000    0.000 markets.py:69(__iter__)

&gt;         2    0.000    0.000    0.000    0.000 markets.py:72(__len__)

&gt;         8    0.000    0.000    0.000    0.000 process.py:189(name)

&gt;         8    0.000    0.000    0.000    0.000 process.py:37(current_process)

&gt;         1    0.000    0.000    0.000    0.000 simulatedclient.py:18(login)

&gt;         1    0.000    0.000    0.000    0.000 simulatedclient.py:24(logout)

&gt;         1    0.000    0.000    0.000    0.000 simulatedclient.py:27(update_account_details)

&gt;         1    0.000    0.000    0.001    0.001 simulation.py:29(run)

&gt;         1    0.000    0.000    0.000    0.000 strategy.py:142(finish)

&gt;         1    0.000    0.000    0.000    0.000 strategy.py:286(start)

&gt;         1    0.000    0.000    0.000    0.000 strategy.py:298(finish)

&gt;         2    0.000    0.000    0.000    0.000 strategy.py:306(__iter__)

&gt;         1    0.000    0.000    0.000    0.000 strategy.py:96(start)

&gt;         1    0.000    0.000    0.000    0.000 streams.py:254(start)

&gt;         1    0.000    0.000    0.000    0.000 streams.py:263(stop)

&gt;         4    0.000    0.000    0.000    0.000 streams.py:271(__iter__)

&gt;         2    0.000    0.000    0.000    0.000 thread.py:216(shutdown)

&gt;         2    0.000    0.000    0.000    0.000 threading.py:1125(_wait_for_tstate_lock)

&gt;         8    0.000    0.000    0.000    0.000 threading.py:1152(name)

&gt;         2    0.000    0.000    0.000    0.000 threading.py:1192(is_alive)

&gt;         8    0.000    0.000    0.000    0.000 threading.py:1453(current_thread)

&gt;         2    0.000    0.000    0.000    0.000 threading.py:1501(enumerate)

&gt;         4    0.000    0.000    0.000    0.000 threading.py:575(is_set)

&gt;         2    0.000    0.000    0.000    0.000 threading.py:931(__repr__)

&gt;         1    0.000    0.000    0.000    0.000 utils.py:31(__enter__)

&gt;         1    0.000    0.000    0.000    0.000 utils.py:37(__exit__)

&gt;        16    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}

&gt;         1    0.000    0.000    0.001    0.001 {built-in method builtins.exec}

&gt;        53    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}

&gt;        61    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}

&gt;         8    0.000    0.000    0.000    0.000 {built-in method builtins.iter}

&gt;       8/5    0.000    0.000    0.000    0.000 {built-in method builtins.len}

&gt;        40    0.000    0.000    0.000    0.000 {built-in method posix.fspath}

&gt;         8    0.000    0.000    0.000    0.000 {built-in method posix.getpid}

&gt;         8    0.000    0.000    0.000    0.000 {built-in method sys._getframe}

&gt;         8    0.000    0.000    0.000    0.000 {built-in method time.gmtime}

&gt;         8    0.000    0.000    0.000    0.000 {built-in method time.strftime}

&gt;         8    0.000    0.000    0.000    0.000 {built-in method time.time}

&gt;         4    0.000    0.000    0.000    0.000 {built-in method utcnow}

&gt;         2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}

&gt;         2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}

&gt;        18    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}

&gt;         2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}

&gt;         1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}

&gt;         8    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}

&gt;        94    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}

&gt;        25    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}

&gt;         8    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}

&gt;         1    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}

&gt;         2    0.000    0.000    0.000    0.000 {method 'put' of '_queue.SimpleQueue' objects}

&gt;        18    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}

&gt;        24    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}

&gt;        37    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}

&gt;        16    0.000    0.000    0.000    0.000 {method 'update' of 'collections.OrderedDict' objects}

&gt;         6    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}

&gt;         8    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}

---

## 2024-05-06 13:14:17 - general channel

**Adrian**

Sure, thanks for checking it out

&gt; {"asctime": "2024-05-06 12:11:19,275", "levelname": "INFO", "message": "Removing market 1.227403968", "clients": {"Betfair": {}, "Simulated": {"34jhdr5": {"username": “34jhdr5”, "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 1, "transaction_count_total": 1, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x15fcf0950&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 6, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;", "&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;", "&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;", "&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;", "&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;", "&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;", "&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;", "&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 7997365952)&gt;"]}

&gt; {"asctime": "2024-05-06 12:11:19,275", "levelname": "INFO", "message": "Completed historical market '/Users/adrian/Projects/betfair/data/historic/PRO/2024/Apr/11/33180336/1.227403968.decompressed'"}

&gt; {"asctime": "2024-05-06 12:11:19,275", "levelname": "INFO", "message": "Starting historical market '/Users/adrian/Projects/betfair/data/historic/PRO/2024/Apr/11/33180336/1.227403983.decompressed'", "market": "/Users/adrian/Projects/betfair/data/historic/PRO/2024/Apr/11/33180336/1.227403983.decompressed"}

&gt; {"asctime": "2024-05-06 12:11:19,275", "levelname": "INFO", "message": "[Register: 7000]: marketSubscription"}

&gt; {"asctime": "2024-05-06 12:11:19,275", "levelname": "INFO", "message": "[MarketStream: 7000]: \"MarketStream\" created"}

&gt; {"asctime": "2024-05-06 12:11:19,279", "levelname": "INFO", "message": "[MarketStream: 7000]: 1.227403983 added, 1 markets in cache"}

&gt; {"asctime": "2024-05-06 12:11:19,280", "levelname": "INFO", "message": "[MarketStream: 7000]: 1.227403983 added, 1 markets in cache"}

&gt; {"asctime": "2024-05-06 12:11:19,280", "levelname": "INFO", "message": "[MarketStream: 7000]: 1.227403983 added, 1 markets in cache"}

&gt; {"asctime": "2024-05-06 12:11:19,280", "levelname": "INFO", "message": "[MarketStream: 7000]: 1.227403983 added, 1 markets in cache"}

&gt; {"asctime": "2024-05-06 12:11:19,289", "levelname": "INFO", "message": "Adding: 1.227403983 to markets"}

&gt; {"asctime": "2024-05-06 12:11:19,290", "levelname": "INFO", "message": "Execution new hour", "current_transaction_count_total": 1, "current_transaction_count": 1, "current_failed_transaction_count": 0, "total_transaction_count": 1, "total_failed_transaction_count": 0, "client": {"username": "41f95cae", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 1, "transaction_count_total": 1, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x15fcf0950&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}

---

## 2024-05-05 09:46:09 - strategies channel

**foxwood**

I'm sure lots of people will keep trying that path without regard to the fact of how many subtle errors happen in chatGPT's day job. At the other extreme I get 98% accuracy from my models when I leave the target in the dataset :upside_down_face:

---

## 2024-05-02 10:57:26 - random channel

**liam**

In my experience its far more valuable (and profitable) to improve your EV calculation and work off a variation of kelly with a fixed balance

---

## 2024-05-01 15:14:16 - random channel

**PeterLe**

Cheers :+1:

By the way; I loved reading this :[https://www.amazon.co.uk/American-Kingpin-Criminal-Mastermind-Behind/dp/B071JPMB18/ref=sr_1_1?crid=EVJ5LBULM89K&amp;dib=eyJ2IjoiMSJ9.Aoli_NlheBcrIZOdQYbxxepAU38Hx2Sqn-K0OiWf_NZV8ThtXCTVgrGO4is1nHBZ-Xh9lAOlNWChE--ax4dCDs_JHSlF7FDdJZNoHNB1w7YRf09yo6TPDX2LUuMGlQsmGhykMoYCOx2PPSoe2NWlLFAhWMQSi95P_AhjEmVw-2L1UiuQtQ0Erta7NgbEKxGg24BTlVTwPSRXgcaOf_XYlx16uvXRCrWPhM8n5g8GOy0.HIJH3QbZc6V46ZT9W1FB2n0QRI5ZaS_Fotho6_sVb5w&amp;dib_tag=se&amp;keywords=american+kingpin&amp;qid=1714572777&amp;s=audible&amp;sprefix=american+kingpin%2Caudible%2C61&amp;sr=1-1|https://www.amazon.co.uk/American-Kingpin-Criminal-Mastermind-Behind/dp/B071JPMB18/re[…]777&amp;s=audible&amp;sprefix=american+kingpin%2Caudible%2C61&amp;sr=1-1](https://www.amazon.co.uk/American-Kingpin-Criminal-Mastermind-Behind/dp/B071JPMB18/ref=sr_1_1?crid=EVJ5LBULM89K&amp;dib=eyJ2IjoiMSJ9.Aoli_NlheBcrIZOdQYbxxepAU38Hx2Sqn-K0OiWf_NZV8ThtXCTVgrGO4is1nHBZ-Xh9lAOlNWChE--ax4dCDs_JHSlF7FDdJZNoHNB1w7YRf09yo6TPDX2LUuMGlQsmGhykMoYCOx2PPSoe2NWlLFAhWMQSi95P_AhjEmVw-2L1UiuQtQ0Erta7NgbEKxGg24BTlVTwPSRXgcaOf_XYlx16uvXRCrWPhM8n5g8GOy0.HIJH3QbZc6V46ZT9W1FB2n0QRI5ZaS_Fotho6_sVb5w&amp;dib_tag=se&amp;keywords=american+kingpin&amp;qid=1714572777&amp;s=audible&amp;sprefix=american+kingpin%2Caudible%2C61&amp;sr=1-1|https://www.amazon.co.uk/American-Kingpin-Criminal-Mastermind-Behind/dp/B071JPMB18/re[…]777&amp;s=audible&amp;sprefix=american+kingpin%2Caudible%2C61&amp;sr=1-1)

Fab book (Film was crap though :grinning:)

---

## 2024-05-01 15:09:24 - random channel

**PeterLe**

Let me know what you think Mo when you have read it

I have Michael Lewis - Liars Poker which ive been meaning to read for a while (and permanent record - Ed Snowden..find it a bit slow TBH)

You might enjoy this too if you havent read it : [https://www.amazon.co.uk/Bitcoin-Billionaires-Genius-Betrayal-Redemption/dp/B07P75J5MW/ref=sr_1_1?crid=1DCLMGCYTZAG4&amp;dib=eyJ2IjoiMSJ9.RgdEWhLg_WhCKNfP4LIho-17nuVuZO-HTFZ_-Joey7rQUNOdo2bTIQSmuXj3fK6wgJE2wCZehwIDU8_cnnBLkokPR1TF6BUDBlhM-hQeawYTO9BZLrDt2d_y05RF9dkCJ314nKnyaEqOdmivBlW23yKx1a7FIjNokBibne2-uh4RHmzti6e7h69ZVSRYKSaZGPrIEh6uw4FPICZlS4Lag_-zw_TyfL6fwrXDypRbbcY.6EsP9U-reR_p1qmixo-_0Xi-uf7Y6_gU6R7R6f8WNCk&amp;dib_tag=se&amp;keywords=bitcoin+billionaires&amp;qid=1714572380&amp;s=books&amp;sprefix=bitcopin+billionaires%2Cstripbooks%2C71&amp;sr=1-1|https://www.amazon.co.uk/Bitcoin-Billionaires-Genius-Betrayal-Redemption/dp/B07P75J5M[…]books&amp;sprefix=bitcopin+billionaires%2Cstripbooks%2C71&amp;sr=1-1](https://www.amazon.co.uk/Bitcoin-Billionaires-Genius-Betrayal-Redemption/dp/B07P75J5MW/ref=sr_1_1?crid=1DCLMGCYTZAG4&amp;dib=eyJ2IjoiMSJ9.RgdEWhLg_WhCKNfP4LIho-17nuVuZO-HTFZ_-Joey7rQUNOdo2bTIQSmuXj3fK6wgJE2wCZehwIDU8_cnnBLkokPR1TF6BUDBlhM-hQeawYTO9BZLrDt2d_y05RF9dkCJ314nKnyaEqOdmivBlW23yKx1a7FIjNokBibne2-uh4RHmzti6e7h69ZVSRYKSaZGPrIEh6uw4FPICZlS4Lag_-zw_TyfL6fwrXDypRbbcY.6EsP9U-reR_p1qmixo-_0Xi-uf7Y6_gU6R7R6f8WNCk&amp;dib_tag=se&amp;keywords=bitcoin+billionaires&amp;qid=1714572380&amp;s=books&amp;sprefix=bitcopin+billionaires%2Cstripbooks%2C71&amp;sr=1-1|https://www.amazon.co.uk/Bitcoin-Billionaires-Genius-Betrayal-Redemption/dp/B07P75J5M[…]books&amp;sprefix=bitcopin+billionaires%2Cstripbooks%2C71&amp;sr=1-1)

---

## 2024-04-29 15:12:54 - issues channel

**Shashi Khaya**

the background worker callback overwrites the score :

def callback(flumine, event):

    # update market context

    score = event.event

    for market in flumine.markets:

        if market.event_id == str(score.event_id):

            logger.debug(

                "Updated market %s with event %s scores data",

                market.market_id,

                market.event_id,

            )

            market.context["score"] = score

---

## 2024-04-29 07:58:57 - general channel

**Tarang Ambaliya**

And that is not working for me, it gives 403 errors.

---

## 2024-04-26 11:19:03 - issues channel

**foxwood**

It implies you may get a different IP for each outgoing request you make so that could invalidate your session. Just a thought though. Good luck with your debugging.

---

## 2024-04-26 09:15:16 - issues channel

**Ammar**

Well I’m seeking guidance on that. 



It does look like there is an unexpected None being returned in a situation which I’ve hit (rightly or wrongly), and that shows in the logs with errors. 



It’s not stopping streaming data, but it may impact other operations (which I’m not doing via flumine as yet)



But I do seem to be in a small minority here, so I will do more digging and share info on the root cause when I have time in the coming days 

---

## 2024-04-25 21:18:05 - issues channel

**Ammar**

It looks to me like there’s an unexpected response type (as `None`) which is coming thru from the call stack — which looks entirely plausible as I read thru the code all the way back to `betfairlightweight`



to be clear, this isn’t impacting the data stream; but it does look like very unhappy noise in the logs, which is never nice :)



steps to replicate:

• leave the market recorder going on one machine — this is _all_ I’m using flumine for, it’s a single process which I kick off each day.  (currently on a laptop, behind expressVPN, which may be a noteworthy point) 

• use betfair to manually execute and check markets via the mobile app, and other computers

• over the course of 8-10 hours the error will start to present



the fix could be very light in the keepalive (similar to how it’s handling a failure already)





```def keep_alive(context: dict, flumine) -&gt; None:

    """Attempt keep alive if required or

    login if keep alive failed

    """

    for client in flumine.clients:

        if client.EXCHANGE == ExchangeType.BETFAIR:

            if client.betting_client.session_token:

                resp = client.keep_alive()



                # start change

                if resp is None:  # this is the unexpected response type I'm seeing

                    client.login()

                # end chage



                if resp is True or resp.status == "SUCCESS":

                    continue

        elif client.EXCHANGE == ExchangeType.BETCONNECT:

            resp = client.keep_alive()

            if resp:

                continue

        # keep-alive failed lets try a login

        client.login()```

---

## 2024-04-25 21:00:31 - issues channel

**foxwood**

Not sure there is a bug there - runs for weeks on end 24/7 for me and others using flumine. Suggest you look at your usage of flumine and other things you are doing that may interfere. Once you come up with proof of how to cause the supposed error or the repeatable actions that make it happen then that's the time to consider a PR.

---

## 2024-04-25 10:54:44 - issues channel

**Ammar**

```

{"asctime": "2024-04-24 21:20:22,236", "levelname": "ERROR", "message": "BetfairClient `keep_alive` error", "exc_info": "Traceback (most recent call last):

File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/clients/betfairclient.py\", line 44, in keep_alive

return self.betting_client.keep_alive()

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/keepalive.py\", line 30, in __call__

(response, response_json, elapsed_time) = self.request(session=session)

                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

                           File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/keepalive.py\", line 60, in request

                               self._error_handler(response_json)

                                 File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/keepalive.py\", line 67, in _error_handler

                                     raise self._error(response)

                                     betfairlightweight.exceptions.KeepAliveError: API keepAlive FAIL: NO_SESSION", "client": "APIClient", "trading_function": "keep_alive", "response": "API keepAlive FAIL: NO_SESSION"}





{"asctime": "2024-04-24 21:20:22,240", "levelname": "ERROR", "message": "Error in BackgroundWorker keep_alive: 'NoneType' object has no attribute 'status'", "exc_info": "Traceback (most recent call last):

File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/worker.py\", line 66, in run

self.function(

File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/worker.py\", line 106, in keep_alive

if resp is True or resp.status == \"SUCCESS\":

^^^^^^^^^^^

AttributeError: 'NoneType' object has no attribute 'status'", "worker_name": "keep_alive", "function": "[function keep_alive at 0x1041e99e0](function keep_alive at 0x1041e99e0)", "context": {}}```



---

raw json format from the logger

```{"asctime": "2024-04-24 21:02:11,658", "levelname": "ERROR", "message": "BetfairClient `account.get_account_details` error", "exc_info": "Traceback (most recent call last):\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/clients/betfairclient.py\", line 84, in _get_account_details\n    return self.betting_client.account.get_account_details()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/account.py\", line 54, in get_account_details\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: None \nError: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}", "client": "APIClient", "trading_function": "account.get_account_details", "response": "AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: None \nError: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}"}

{"asctime": "2024-04-24 21:02:11,762", "levelname": "ERROR", "message": "BetfairClient `account.get_account_funds` error", "exc_info": "Traceback (most recent call last):\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/flumine/clients/betfairclient.py\", line 98, in _get_account_funds\n    return self.betting_client.account.get_account_funds()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/account.py\", line 35, in get_account_funds\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"/Users/user/.virtualenvs/b2023/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: AccountAPING/v1.0/getAccountFunds \nParams: {} \nException: None \nError: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}", "client": "APIClient", "trading_function": "account.get_account_funds", "response": "AccountAPING/v1.0/getAccountFunds \nParams: {} \nException: None \nError: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}"}```

---

## 2024-04-25 10:54:32 - issues channel

**Ammar**

I think there’s a bug in the keep alive worker where it’s not logging in properly



Traceback in thread



I’ve been getting this for a couple of days wheen leaving the stream running for a long while (to build up local data as discussed  elsewhere) but also logging into betfair from other devices to look at things or manually execute.



The fix should be relatively straightforward, happy to open a PR into the flumine repo if that’s the done thing?

---

## 2024-04-23 15:48:47 - issues channel

**Dario Scardina**

Hello everyone,

for a couple of days I've been encountering issues during API login.

betfairlightweight.exceptions.APIError: None

Params: None

Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.it|identitysso-cert.betfair.it](http://identitysso-cert.betfair.it|identitysso-cert.betfair.it)', port=443): Max retries exceeded with url: /api/certlogin (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x71de1340&gt;, 'Connection to [http://identitysso-cert.betfair.it|identitysso-cert.betfair.it](http://identitysso-cert.betfair.it|identitysso-cert.betfair.it) timed out. (connect timeout=3.05)'))

This has never happened to me before, but these days I'm getting this message almost 80% of the time. What can I check to resolve it?

---

## 2024-04-23 10:54:22 - general channel

**Ammar**

If you partition by a market filter when opening flumine, you will get one connection per filter, so number of markets will be lower per stream / connection. 



I have not seen any posts about anyone hit a stream performance issue tho, so it may not be necessary. But my experience w the framework is still quite limited so I may be missing something



Also I believe betfair limits each api key to 10 streaming connections. 



You could try it and see … it may be a case of trial and error to get the right hardware and stream filter setup for your use case 

---

## 2024-04-21 22:38:34 - general channel

**Unknown**

On a similar note, I currently have a limit of 200 markets for a stream. I assume this is fixed regardless if I fire up another stream?



It seems lots of people got the limit extended to 1K - is there any criteria I'd need to meet to get this?

---

## 2024-04-19 11:18:14 - general channel

**Tarang Ambaliya**

Hello, Need a help.



I have been facing this issue were my account keeps getting blocked and shows up this error `LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE`. I am using the account on one instance. I got it reset more than 4 times now. But still it is getting blocked on second successful login attempt. Double checked the password is correct and username is also correct along with the app key. Earlier it was working fine with multiple login at multiple places but once i faced this error it is not going away now.



Thanks.

---

## 2024-04-18 20:21:37 - general channel

**liam**

Open up your debugger and start looking 

---

## 2024-04-18 19:43:34 - general channel

**Ralegh**

You’d need to read up on linear programming- the gist is you’ve got some variables (how much you bet on each selection) and you want to pick the best combination of values for those variables based on some criteria. In this case you want to minimize your exposure (make your worst case profit/loss as high as it can be). You could write a function to brute force this - calculate your new exposure after hedging by betting £0,£0,£0,£0,£1, then £0,£0,£0,£1,£0, etc (for each of 5 selections). But there are known algorithms you can use if you can formulate the problem in a specific way. Once you do that you can use e.g scipy.optimize and it will come up with a solution a lot faster than brute forcing, for complex problems it may not be possible to come up with a closed form formula so linear programming is sort of smart trial and error.

---

## 2024-04-17 09:22:50 - issues channel

**Ammar**

maybe a silly q (and hopefully I’ve not missed something in docs); but can you add strategies after flumine has started running, or does it have to be done before the `run()` call?



this works as usual:

```# main thread only

for s in strategies:

    framework.add_strategy(s)



framework.run()```



doesn’t seem to work - debug logging isn’t showing files being written to (but it’s just been a quick spike this morning)

```# run() on background thread

framework_thread = threading.Thread(

    name="Flumine Main",

    target=framework.run,

)

framework_thread.start()



# add strategy via main thread

for s in strategies:

    framework.add_strategy(s)```

(the strategies are just MarketRecorder from the examples with custom market filters based on relevant events, countrycodes and market_types to avoid hitting the 200 makret subscription limit which betfair seem to have)



I’ve not tried adding strategies from a background thread yet, but will do that later today.



reason for this is that I want to have one flumine instance running on my ec2, with a trickling in of football events as they are 2hours from start.



so I’ll have the events stored in RDS (which are periodically refreshed) and then have a loop which grabs relevant event_id’s to construct the market_filter going into flumine



is there a better pattern to use for something like this?

---

## 2024-04-14 10:23:28 - strategies channel

**foxwood**

There is only one market data stream per connection which is for all markets that match the filter you supply when adding the strategy to the framework. The subscription limit you mention is only applied each time a new subscription filter is made. Once set up on the connection the market subscription will run "forever" feeding data on current and all new markets as they arise that match your filter. Once the market is closed you would normally receive no more data from BF for it. Sometimes the market is closed in error and is re-opened or has to be opened/closed again to correct WP/winner errors. So, once a market is closed (excl BF issues) that is the end and it never appears on the stream again - all flumine has to do is handle its own objects. Not sure if somewhere in that your question is answered but it's the flow I understand and lets the stream run smoothly 24/7, automatically handling opeing/closing markets.

---

## 2024-04-13 14:40:20 - strategies channel

**ShaunW**

Fixed staking skews the results on the bigger prices. Condiser liability staking, or scale depending on the size of the market.  Yes Andy, alpha is a metric but used here as meaning knowledge.



So what IS the bottom line on minimum staking? Pay enough commision and they'll remove it?

---

## 2024-04-13 09:13:13 - strategies channel

**Chris**

How do you get around the order validation error of minimum bet size of 1

---

## 2024-04-12 14:03:35 - strategies channel

**liam**

Yeah, just used a fixed bankroll/edge so that your size is realistic to the price, £15 is a very large stake, in greyhounds its about 100x too big

---

## 2024-04-12 13:55:48 - strategies channel

**river_shah**

Fixed staking is totally wrong and needs to be adjusted for bet price, value etc

---

## 2024-04-11 22:50:53 - issues channel

**Matthew Lawrence**

Hi, trying to use flumine for the first time. I'm starting off by testing an adjusted version of betfair data scientists: how to automate 2. I can see from the logging that the bets are never being matched, although they are being requested at the correct price and size. Any help would be appreciated.

```trading = betfairlightweight.APIClient('...','...!',app_key='...')

client = clients.BetfairClient(trading, interactive_login=True)



# Login

client = clients.SimulatedClient()

framework = FlumineSimulation(client=client)



# Logging

logger = logging.getLogger()

custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # Set to logging.CRITICAL to speed up simulation



class BackFavStrategy(BaseStrategy):



    # Defines what happens when we start our strategy i.e. this method will run once when we first start running our strategy

    def start(self) -&gt; None:

        print("starting strategy 'BackFavStrategy'")



    def check_market_book(self, market: Market, market_book: MarketBook) -&gt; bool:

        # process_market_book only executed if this returns True

        if market_book.status != "CLOSED":

            return True



    def process_market_book(self, market: Market, market_book: MarketBook) -&gt; None:



        # Collect data on last price traded and the number of bets we have placed

        snapshot_last_price_traded = []

        snapshot_runner_context = []

        for runner in market_book.runners:

                snapshot_last_price_traded.append([runner.selection_id,runner.last_price_traded])

                # Get runner context for each runner

                runner_context = self.get_runner_context(

                    market.market_id, runner.selection_id, runner.handicap

                )

                snapshot_runner_context.append([runner_context.selection_id, runner_context.executable_orders, runner_context.live_trade_count, runner_context.trade_count])



        # Convert last price traded data to dataframe

        snapshot_last_price_traded = pd.DataFrame(snapshot_last_price_traded, columns=['selection_id','last_traded_price'])

        # Find the selection_id of the favourite

        snapshot_last_price_traded = snapshot_last_price_traded.sort_values(by = ['last_traded_price'])

        fav_selection_id = snapshot_last_price_traded['selection_id'].iloc[0]

        [http://logging.info|logging.info](http://logging.info|logging.info)(snapshot_last_price_traded) # logging



        # Convert data on number of bets we have placed to a dataframe

        snapshot_runner_context = pd.DataFrame(snapshot_runner_context, columns=['selection_id','executable_orders','live_trade_count','trade_count'])

        [http://logging.info|logging.info](http://logging.info|logging.info)(snapshot_runner_context) # logging



        for runner in market_book.runners:

            if runner.status == "ACTIVE" and market.seconds_to_start &lt; 60 and market_book.inplay == False and runner.selection_id == fav_selection_id and snapshot_runner_context.iloc[:,1:].sum().sum() == 0:

                trade = Trade(

                    market_id=market_book.market_id,

                    selection_id=runner.selection_id,

                    handicap=runner.handicap,

                    strategy=self,

                )

                order = trade.create_order(

                    side="BACK", order_type=LimitOrder(price=runner.last_price_traded, size=5)

                )

                market.place_order(order)



# Fields we want to log in our simulations

FIELDNAMES = [

    "bet_id",

    "strategy_name",

    "market_id",

    "selection_id",

    "trade_id",

    "date_time_placed",

    "price",

    "price_matched",

    "size",

    "size_matched",

    "profit",

    "side",

    "elapsed_seconds_executable",

    "order_status",

    "market_note",

    "trade_notes",

    "order_notes",

]



# Log results from simulation into csv file named sim_hta_2.csv

# If the csv file doesn't exist then it is created, otherwise we append results to the csv file

class BacktestLoggingControl(LoggingControl):

    NAME = "BACKTEST_LOGGING_CONTROL"



    def __init__(self, *args, **kwargs):

        super(BacktestLoggingControl, self).__init__(*args, **kwargs)

        self._setup()



    def _setup(self):

        if os.path.exists("sim_hta_2.csv"):

            [http://logging.info|logging.info](http://logging.info|logging.info)("Results file exists")

        else:

            with open("sim_hta_2.csv", "w") as m:

                csv_writer = csv.DictWriter(m, delimiter=",", fieldnames=FIELDNAMES)

                csv_writer.writeheader()



    def _process_cleared_orders_meta(self, event):

        orders = event.event

        with open("sim_hta_2.csv", "a") as m:

            for order in orders:

                if order.order_type.ORDER_TYPE == OrderTypes.LIMIT:

                    size = order.order_type.size

                else:

                    size = order.order_type.liability

                if order.order_type.ORDER_TYPE == OrderTypes.MARKET_ON_CLOSE:

                    price = None

                else:

                    price = order.order_type.price

                try:

                    order_data = {

                        "bet_id": order.bet_id,

                        "strategy_name": order.trade.strategy,

                        "market_id": order.market_id,

                        "selection_id": order.selection_id,

                        "trade_id": order.trade.id,

                        "date_time_placed": order.responses.date_time_placed,

                        "price": price,

                        "price_matched": order.average_price_matched,

                        "size": size,

                        "size_matched": order.size_matched,

                        "profit": order.simulated.profit,

                        "side": order.side,

                        "elapsed_seconds_executable": order.elapsed_seconds_executable,

                        "order_status": order.status.value,

                        "market_note": order.trade.market_notes,

                        "trade_notes": order.trade.notes_str,

                        "order_notes": order.notes_str,

                    }

                    csv_writer = csv.DictWriter(m, delimiter=",", fieldnames=FIELDNAMES)

                    csv_writer.writerow(order_data)

                except Exception as e:

                    logger.error(

                        "_process_cleared_orders_meta: %s" % e,

                        extra={"order": order, "error": e},

                    )



        [http://logger.info|logger.info](http://logger.info|logger.info)("Orders updated", extra={"order_count": len(orders)})



    def _process_cleared_markets(self, event):

        cleared_markets = event.event

        for cleared_market in cleared_markets.orders:

            [http://logger.info|logger.info](http://logger.info|logger.info)(

                "Cleared market",

                extra={

                    "market_id": cleared_market.market_id,

                    "bet_count": cleared_market.bet_count,

                    "profit": cleared_market.profit,

                    "commission": cleared_market.commission,

                },

            )



# Searches for all betfair data files within the folder sample_monthly_data_output

data_folder = r"C:\Users\matth\OneDrive\Documents\output_2022_02"

data_files = os.listdir(data_folder,)

data_files = [f'{data_folder}/{path}' for path in data_files]



# Set Flumine to simulation mode

client = clients.SimulatedClient()

framework = FlumineSimulation(client=client)



# Set parameters for our strategy

strategy = BackFavStrategy(

    # market_filter selects what portion of the historic data we simulate our strategy on

    # markets selects the list of betfair historic data files

    # market_types specifies the type of markets

    # listener_kwargs specifies the time period we simulate for each market

    market_filter={

        "markets": data_files,

        'market_types':['MATCH_ODDS', 'BOTH_TEAMS_TO_SCORE'],

        "listener_kwargs": {"inplay": False, "seconds_to_start": 80},

        },

    max_order_exposure=1000,

    max_selection_exposure=1000,

)

# Run our strategy on the simulated market

framework.add_strategy(strategy)

framework.add_logging_control(

    BacktestLoggingControl()

)

framework.run()```



---

## 2024-04-09 18:29:12 - random channel

**liam**

I spent a good chunk of time Nov-Feb applying what I do to racing and made progress however I spent 90% of my time getting very angry with the feed/betfair which they have now finally fixed. Turning over a decent amount per game but just waiting on more data before pushing things further 

---

## 2024-04-09 09:46:17 - general channel

**Trex44**

So, I think the problem was caused by a Jupyter notebook. I had one of the cells take a snap shot of market data when it was executed. I did have trading.logout() in the same cell but all I can think is this didn't execute properly. When I rebooted my IDE (that the notebook was running in) it seems to have fixed the issue. Will see if crops up again or not.

---

## 2024-04-08 10:03:33 - general channel

**Trex44**

Hey guys can anyone help me resolve the following error.  I run three flumine instances, one for data collection, one for horse racing and one for football. I don't understand how I have hit a connection limit this morning seeing as all I did was reboot the horse racing and football instances and add some new strategies to the football instance before the reboot. I thought each instance of FLumine was one connection? So I don't know how I am close to the Max connection limit of 10.

```

{"asctime": "2024-04-08 08:57:25,093", "levelname": "ERROR", "message": "MarketStream 5008 run error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/flumine/streams/marketstream.py\", line 44, in run\n    self._stream.start()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 67, in start\n    self._read_loop()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 233, in _read_loop\n    self._data(received_data)\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 274, in _data\n    raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 107-080424085725-430913, data: {\"op\":\"status\",\"id\":5009,\"statusCode\":\"FAILURE\",\"errorCode\":\"MAX_CONNECTION_LIMIT_EXCEEDED\",\"errorMessage\":\"You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s).\",\"connectionClosed\":true,\"connectionId\":\"107-080424085725-430913\"}"}```

---

## 2024-04-08 09:08:00 - issues channel

**Johnnb**

This is the code that sets up the logging :

```logger = logging.getLogger()

custom_format = "%(asctime) %(levelname) %(message)"

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_file_name = 'multi_recorder.log'

log_handler_file = logging.FileHandler(log_file_name)

log_handler_file.setFormatter(formatter)

log_handler_file.setLevel(logging.WARNING)

logger.addHandler(log_handler_file)```

and this is the whole contents of the log file :

```{"asctime": "2024-04-07 12:06:30,768", "levelname": "WARNING", "message": "[FlumineStream: 4001]: Latency high: 0.5309743881225586"}

{"asctime": "2024-04-07 12:22:38,592", "levelname": "WARNING", "message": "[FlumineStream: 3001]: Latency high: 0.5384097099304199"}

{"asctime": "2024-04-07 12:38:51,513", "levelname": "WARNING", "message": "[FlumineStream: 3001]: Latency high: 0.618567705154419"}

{"asctime": "2024-04-07 13:22:52,309", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.7499873638153076"}

{"asctime": "2024-04-07 13:22:52,309", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.7483816146850586"}

{"asctime": "2024-04-07 13:22:52,309", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.6966326236724854"}

{"asctime": "2024-04-07 13:22:52,309", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5819070339202881"}

{"asctime": "2024-04-07 13:22:52,310", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5760924816131592"}

{"asctime": "2024-04-07 13:32:00,671", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.6668083667755127"}

{"asctime": "2024-04-07 14:21:34,134", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5454201698303223"}

{"asctime": "2024-04-07 14:21:34,135", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5427672863006592"}

{"asctime": "2024-04-07 14:29:44,438", "levelname": "WARNING", "message": "[FlumineStream: 3001]: Latency high: 0.5154736042022705"}

{"asctime": "2024-04-07 15:04:02,227", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.7697350978851318"}

{"asctime": "2024-04-07 15:04:02,229", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.669356107711792"}

{"asctime": "2024-04-07 15:04:02,229", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.5565588474273682"}

{"asctime": "2024-04-07 15:04:02,229", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.5507323741912842"}

{"asctime": "2024-04-07 15:04:02,229", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.452915906906128"}

{"asctime": "2024-04-07 15:04:02,230", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.3592793941497803"}

{"asctime": "2024-04-07 15:04:02,230", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.3554434776306152"}

{"asctime": "2024-04-07 15:04:02,230", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.2436447143554688"}

{"asctime": "2024-04-07 15:04:02,230", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.1467902660369873"}

{"asctime": "2024-04-07 15:04:02,231", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.142089605331421"}

{"asctime": "2024-04-07 15:04:02,231", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 1.0893239974975586"}

{"asctime": "2024-04-07 15:04:02,231", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.9845194816589355"}

{"asctime": "2024-04-07 15:04:02,231", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.8789470195770264"}

{"asctime": "2024-04-07 15:04:02,232", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.8751261234283447"}

{"asctime": "2024-04-07 15:04:02,232", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.7643704414367676"}

{"asctime": "2024-04-07 15:04:02,241", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.7685585021972656"}

{"asctime": "2024-04-07 15:04:02,242", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.6691379547119141"}

{"asctime": "2024-04-07 15:04:02,242", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.574512243270874"}

{"asctime": "2024-04-07 15:06:28,467", "levelname": "ERROR", "message": "DataStream 2001 run error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/flumine/streams/datastream.py\", line 172, in run\n    self._stream.start()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 60, in start\n    self._read_loop()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 228, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 258, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 2002]: Connection closed by server"}

{"asctime": "2024-04-07 15:15:02,315", "levelname": "WARNING", "message": "[FlumineStream: 3001]: Latency high: 0.6098229885101318"}```

---

## 2024-04-08 08:25:55 - issues channel

**Johnnb**

Hi everyone, I'm new here so might be missing something obvious. I'm running an s3marketrecorder in a lightsail instance. I started it yesterday morning and it still seems to be recording ok, but yesterday afternoon it stopped removing the txt and gz files after the markets closed. I got this error at about the time it stopped :

```{"asctime": "2024-04-07 15:06:28,467", "levelname": "ERROR", "message": "DataStream 2001 run error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/flumine/streams/datastream.py\", line 172, in run\n    self._stream.start()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 60, in start\n    self._read_loop()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 228, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py\", line 258, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 2002]: Connection closed by server"}```

The gz files are still being sent to the bucket and there's nothing else in the log apart from a few latency warnings

---

## 2024-04-06 21:12:19 - general channel

**Unknown**

I get quite regular dropouts - for many seconds sometimes. I've queried it before with Neil and posted about it here before. GPS stream basically just disappears. I've verified it across multiple instances and the gaps are the same. I assume it is a TPD side issue. Even if it were a bottleneck or error on my side, I should still get the queued messages on the socket buffer - but I just don't get them. Example below:

---

## 2024-04-04 09:20:07 - issues channel

**Ammar**

thanks both



yeh - confirmed as a betfair issue, they have fixed it now.



certs path was fine, but I have moved it to an absolute just to avoid that being an issue in future :+1:

---

## 2024-04-03 21:37:42 - issues channel

**liam**

Code looks fine, assuming the logs have no errors regarding login it looks to be a betfair issue 

---

## 2024-04-03 18:19:15 - issues channel

**Ammar**

Hi - me again — I’ve had confirmation my live key is streaming enabled, but I am getting this error back on the API when trying to run a simple strategy to just test the connection



`{"op":"status","id":2002,"statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"Unknown error authenticating","connectionClosed":true,"connectionId":"204-030424170351-166509"}`



I’ve raised a ticket to BDP, but wondering if anyone has any insight?

---

## 2024-04-02 13:54:01 - general channel

**ShaunW**

Using the wrong password would (should!) freeze the account rather than just giving a temporary error, and commercial software should use a client interactive logon with 2FA anyway.  Storing people's passwords and linking accounts definately sounds like one for Neil to look at.

---

## 2024-04-02 08:35:46 - general channel

**Aiyaj Khalani**

i also tried to reproduce same from making curl for login in my system and exactly after 16-17 successful attempts, i got this temporary ban error. so i am sure that we're not exceeding 100 login requests

---

## 2024-04-02 08:29:52 - general channel

**Aiyaj Khalani**

would this error be raised only due to Login attempts or is there any other possibility for this error?

---

## 2024-04-01 13:57:59 - general channel

**Aiyaj Khalani**

Hi All,



i am frequently getting TEMPORARY_BAN_TOO_MANY_REQUEST error when trying to login using betfair API, however login from betfair UI works fine. doc says that whenever you gets 100 requests per min for login, you're getting banned for 20 mins. but i dont see that much login requests i am making, what could be the issue in this case?

---

## 2024-04-01 10:59:06 - general channel

**liam**

If you plan on using flumine is there any reason you don’t want to use the dot syntax? 



But to answer your question just use your debugger to have a look or just print the dict 

---

## 2024-03-29 18:04:07 - general channel

**Peter**

The answer is, as you suspect, yes. You'll need them if you're need to track down a problem.



How big they are depends on why you're logging. Normally they'd be logging at level ERROR or CRITICAL, but if you're trying to track down an issue, you might need to set them to INFO or even DEBUG, in which case they'd be much larger.



How long to keep them for? It depends on your reason for logging. Normally I clear them out frequently, but I have some that I keep forever as they log data that helps me to develop new signals.

---

## 2024-03-29 16:19:03 - random channel

**AndyL**

anyway i've fixed the bathroom sink this afternoon while it's been churning.... so not all bad :smile:

---

## 2024-03-29 13:12:52 - issues channel

**Lee**

add logging like in the [https://github.com/betcode-org/flumine/blob/master/examples/example.py#L14|examples](https://github.com/betcode-org/flumine/blob/master/examples/example.py#L14|examples), it will reveal the error

---

## 2024-03-29 09:08:11 - issues channel

**Paul**

I'm trying to do something very basic with betfairlightweight's streaming (long story, I don't want flumine for this). Here is some of my code based on [https://github.com/betcode-org/betfair/blob/f730238df65a9e0f86f3fe9690bf5a7ecff77715/examples/examplestreaming.py|the streaming example](https://github.com/betcode-org/betfair/blob/f730238df65a9e0f86f3fe9690bf5a7ecff77715/examples/examplestreaming.py|the streaming example) in the repo:

```trading = betfairlightweight.APIClient([...])

trading.login()

output_queue = queue.Queue()

listener = betfairlightweight.StreamListener(output_queue = output_queue)

stream = trading.streaming.create_stream(listener = listener)

market_filter = filters.streaming_market_filter(

    event_type_ids          = ["7"],

    market_types            = ["WIN"],

)

market_data_filter = filters.streaming_market_data_filter(

    fields=["EX_BEST_OFFERS, EX_MARKET_DEF"], ladder_levels=1

)



streaming_unique_id = stream.subscribe_to_markets(market_filter = market_filter, market_data_filter=market_data_filter, conflate_ms = 200)

t = threading.Thread(target=stream.start, daemon = True)

t.start()```

This ^^ is obviously not very exotic. I'm asking for single ladder level and the market definition for all WIN horse racing market, with conflation at 200ms. Straight out of the box...

```2024-03-29 08:52:35: [Register: 1]: marketSubscription

2024-03-29 08:52:35: [MarketStream: 1]: "MarketStream" created

2024-03-29 08:52:35: [MarketStream: 1]: connection_id: XXX-XXXXXXXXXXXXX-XXXXXXX

2024-03-29 08:52:35: [MarketStream: 2]: SUCCESS (7 connections available)

2024-03-29 08:52:35: [MarketStream: None]: INVALID_INPUT: Failed to un-marshall: '{"op": "marketSubscription", "id": 1, "marketFilter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"]}, "marketDataFilter": {"fields": ["EX_BEST_OFFERS, EX_MARKET_DEF"], "ladderLevels": 1}, "initialClk": null, "clk": null, "conflateMs": 200, "heartbeatMs": null, "segmentationEnabled": true}'```

My understanding is the `INVALID_INPUT` is from the API as per [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-ErrorCode|the docs](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-ErrorCode|the docs), but there isn't much else to go on. :thinking_face: Only thing obvious is that there are extra attrs in there that I didn't create that could be confusing it, but I expect that this is normal bflw behaviour.



While I go and get some caffeine to see if that helps, any Idiot Adjustments you can offer to my obviously feeble brain would be welcome. :slightly_smiling_face:

---

## 2024-03-28 08:49:04 - issues channel

**Adrian**

[https://stackoverflow.com/questions/38518023/unicodedecodeerror-utf8-codec-cant-decode-byte-0x80-in-position-3131-invali](https://stackoverflow.com/questions/38518023/unicodedecodeerror-utf8-codec-cant-decode-byte-0x80-in-position-3131-invali)

---

## 2024-03-28 08:44:29 - issues channel

**Adrian**

Same error different file

---

## 2024-03-28 08:44:19 - issues channel

**Adrian**

``` File "&lt;frozen codecs&gt;", line 322, in decode

UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte```

---

## 2024-03-28 08:35:23 - issues channel

**Adrian**

Does anyone know what this means?

```Traceback (most recent call last):

  File "/Users/adrian/Projects/betfair/valbet/simulation.py", line 137, in &lt;module&gt;

    framework.add_strategy(strategy)

  File "/Users/adrian/miniconda3/envs/flumine/lib/python3.11/site-packages/flumine/baseflumine.py", line 98, in add_strategy

    self.streams(strategy)  # create required streams

    ^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/adrian/miniconda3/envs/flumine/lib/python3.11/site-packages/flumine/streams/streams.py", line 44, in __call__

    market_definition = get_file_md(market)

                        ^^^^^^^^^^^^^^^^^^^

  File "/Users/adrian/miniconda3/envs/flumine/lib/python3.11/site-packages/flumine/utils.py", line 76, in get_file_md

    first_line = f.readline()

                 ^^^^^^^^^^^^

  File "&lt;frozen codecs&gt;", line 322, in decode

UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte```

---

## 2024-03-27 15:10:16 - random channel

**D C**

Anyone experiencing problems today? I've had a total of 4 different bots running on distinct servers ALL crap out at around 13:30 today. NO_SESSION and HTTP 400 errors amongst other things?

---

## 2024-03-26 23:50:19 - general channel

**JP**

Hi all, this is probably a n00b question but I couldnt find the answer in the slack. When I try to run two strategies at once I get an error:

```{"op":"status","id":3002,"statusCode":"FAILURE","errorCode":"MAX_CONNECTION_LIMIT_EXCEEDED","errorMessage":"You have exceeded your max connection limit which is: 2 connection(s).You currently have: 3 active connection(s).","connectionClosed":true,"connectionId":"204-260324233850-3056148"}```

This seems like a crazy low number of concurrent connections. Could this be because it’s a delayed key?

---

## 2024-03-26 22:20:24 - random channel

**AndyL**

yeah, rookie error, did'nt dropna

---

## 2024-03-26 21:59:25 - random channel

**AndyL**

suspect there's something wrong with my df, if I do a noddy test it's fine, but tying to read df from a csv, gets above error, even though df shape and dtypes look good...

---

## 2024-03-26 21:50:28 - random channel

**AndyL**

pandas errors can be so cryptic, just trying to "bin" a DataFrame, what am I not understanding?

```   selection_id         BSP  winner  

0      41569073    2.129299   False  

1      61343324    2.640000   False  

2      26741931   14.107778   False  

3      61939657   55.000000    True  

4      62819706  120.000000   False  

---&gt; 29 df['bsp_bin'] = pd.cut(df['BSP'], bins=4)

TypeError: putmask: first argument must be an array```



---

## 2024-03-21 23:09:29 - general channel

**Brøndby IF**

Guys, I saw a conversation here a few days ago suggesting limiting the number of ticks below the current odds when using `place_orders()` (strategy where must enter the market immediately and not set a standard odds for everything, but instead define how many ticks would be an acceptable limit). If anyone's interested, I've created (to keep it handy for perhaps a future need) a function that accepts both tick increments and decrements. In case it's useful for anyone, here it is (if by any chance someone has a smarter method than this or if any errors are discovered, please let me know):



```from betfairlightweight import utils



def tick_ladder(current_odds:float, ticks:int) -> float:

    """

    Limit odds based on the reference odds and the number of ticks away.



    Args:

        current_odds (float): The reference odds to be used.

        ticks (int): The number of ticks to be added or subtracted from the reference odds.

                     Positive values move up the ladder, while negative values move down the ladder.



    Returns:

        float: The new odds after applying the ticks adjustment.



    Raises:

        ValueError: If the adjusted index exceeds the limits of the ladder.

    """

    full_ladder = [1.01]

    ticks_list = list(utils.TICK_SIZES.keys())



    for i, pattern in enumerate(ticks_list[:-1]):

        while full_ladder[-1] < ticks_list[i+1]:

            new_value = round(full_ladder[-1] + TICK_SIZES[pattern], 2)

            full_ladder.append(new_value)



    index_current_odds = full_ladder.index(current_odds)

    if index_current_odds + ticks < len(full_ladder):

        return full_ladder[index_current_odds + ticks]

    else:

        raise ValueError("Exceeded ladder limits")```

---

## 2024-03-20 08:34:49 - general channel

**liam**

For live you need a worker, here is mine



```import logging

from flumine.utils import chunks

from betfairlightweight import BetfairError

from flumine.events.events import CustomEvent



logger = logging.getLogger(__name__)





def poll_race_card(context: dict, flumine) -&gt; None:

    client = flumine.clients.get_betfair_default()

    trading = client.betting_client

    if trading.race_card.app_key is None:

        trading.race_card.login()

    markets = _get_markets(flumine.markets)

    for market_ids in chunks(markets, 10):

        try:

            race_cards = trading.race_card.get_race_card(market_ids=market_ids)

        except BetfairError as e:

            logger.error(

                "poll_race_card error",

                exc_info=True,

                extra={"trading_function": "get_race_card", "response": e},

            )

            continue

        if race_cards:

            flumine.handler_queue.put(CustomEvent(race_cards, callback))





def _get_markets(markets: list, event_type_id: str = "7") -&gt; list:

    """Restrict to open and eventTypeId"""

    _markets = []

    for market in markets:

        if not market.closed and market.event_type_id == event_type_id:

            _markets.append(market.market_id)

    return _markets





def callback(flumine, event):

    # update market context

    race_cards = event.event

    for race_card in race_cards:

        for market in flumine.markets:

            for race_card_market in race_card.race.markets:

                if market.market_id == race_card_market.market_id:

                    market.context["race_card"] = race_card```



---

## 2024-03-19 10:55:28 - general channel

**James**

Actually looking closer it seems its the market_name I need which doesn’t appear to be in your mappings. Thanks though.



I’ll just record some and try again tomorrow with a days worth of data to debug the strat.

---

## 2024-03-18 21:21:43 - general channel

**Testes Squads**

Not to mention [@UGV299K6H](@UGV299K6H) that through Betfair or Geeks Toy I would need to do more steps, change the game page, etc., and there are more chances of human error, so my only mistake would be to write NO instead of YES and vice versa .

---

## 2024-03-12 00:39:05 - general channel

**Herugrim**

I seem to have fixed this error, just by removing a trading.logout() line

---

## 2024-03-11 16:35:27 - issues channel

**foxwood**

I think [@U012XF5CNPN](@U012XF5CNPN) explains it well and encapsulates the reasons I have turned the "feature" off. There are a mass of issues that can cause Python to throw concrete excpetions and they are not just related to Python, flumine or flumine strategy code. They include exceptions from the operating system and bugs in any of the host of python packages used - all of which would be ignored by flumine. Imho the probability of an exception arising is real and I favour the dead bot theory rather than the faulty live one.

---

## 2024-03-11 14:15:37 - issues channel

**liam**

I agree there are some nuances but the controls are there to prevent issues, the simulation / paper trading is also there as a way to test (integration) but obviously there is a limit when it comes to betfair exceptions / edge cases etc.

---

## 2024-03-11 14:13:48 - issues channel

**Paul**

I think this default behaviour might be surprising behaviour to most. I think order controls in flumine in general can be a little surprising (selection exposure is not related to P&amp;L, only net exposure of trades on that selection, correct?), and in live trading these surprises could get expensive. I think defaults could defer to risk minimisation and that might make more sense: a dead bot that crashed out due to an exception can’t win big, but it also critically can’t lose big either. You can’t say that about a faulty live one…

---

## 2024-03-11 12:24:51 - general channel

**liam**

Just check the latency yourself



```market_book.publish_time or market_book.publish_time_epoch```

But yeah fix your code :joy:

---

## 2024-03-11 12:24:41 - general channel

**river_shah**

Fix your code

---

## 2024-03-11 11:39:33 - general channel

**liam**

Fix your code, use conflation as a last resort 

---

## 2024-03-11 05:36:14 - general channel

**Herugrim**

Hi,

I'm using the example code here: [https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py](https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py)

I'm getting the below error:



```betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listCurrentOrders

Params: {'orderProjection': 'EXECUTION_COMPLETE', 'customerStrategyRefs': ['MELWKS-4535'], 'dateRange': {'from': None, 'to': None}}

Exception: None

Error: {'code': -32099, 'message': 'ANGX-0005', 'data': {'APINGException': {'requestUUID': 'ie2-ang14b-prd-01291035-005af2205e', 'errorCode': 'NO_SESSION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0005', 'data': {'APINGException': {'requestUUID': 'ie2-ang14b-prd-01291035-005af2205e', 'errorCode': 'NO_SESSION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}```

I'm able to use Flumine without the middleware and am only getting the error when calling listCurrentOrders

---

## 2024-03-10 15:38:34 - issues channel

**Newbie99**

Okay (had to go for 3.9 as 3.11 wouldn't work for some reason), now oddly I get this (which I think some people mentioned before, but I am UK based):



```{"asctime": "2024-03-10 15:36:14,413", "levelname": "ERROR", "message": "OrderStream 1000 run error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/flumine/streams/orderstream.py\", line 40, in run\n    self.stream_id = self._stream.subscribe_to_orders(\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 180, in subscribe_to_orders\n    self._send(message)\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 284, in _send\n    self.authenticate()\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 92, in authenticate\n    self._data(received_data)\n  File \"/home/ec2-user/.pyenv/versions/3.9.0/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 273, in _data\n    raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 107-100324153614-1292830, data: {\"op\":\"status\",\"id\":1002,\"statusCode\":\"FAILURE\",\"errorCode\":\"INVALID_SESSION_INFORMATION\",\"errorMessage\":\"DSC-0036\",\"connectionClosed\":true,\"connectionId\":\"107-100324153614-1292830\"}\r\n"}```

---

## 2024-03-09 12:20:41 - issues channel

**foxwood**

Yup it is a subjective decision since you can get caught both ways and could also win hugely in both ways. Just my take on what I expected. Prob best left as is to avoid upgrade issues with existing user base - maybe make the point in intro docs that system / python  exceptions are eaten by default but can be turned on if wanted.

---

## 2024-03-09 09:42:58 - issues channel

**liam**

I am willing to change it but it could work the other way where by erroring on an exception would result in the instance stopping completely and potentially leave unwanted exposure.



Understand your frustration but you removed all of the other controls which to me is the problem

---

## 2024-03-07 23:41:28 - issues channel

**foxwood**

Certainly it is - as with any bug - not worried about that. Just found it unusual that a package would consume standard language exceptions so suggesting that a different safety default might be better and more in line with new user expectations.

---

## 2024-03-07 18:07:30 - issues channel

**liam**

This sounds like user error regarding lack of controls 

---

## 2024-03-07 18:05:12 - issues channel

**foxwood**

You are right on exposure - the selection limit was too high. It would have stopped the bets eventually but I was testing and caught it manually before too much damage was done.

Even so, would have preferred that the program aborted rather than "ignore" a standard language exception.

I understand there are situations where the "ignore" approach is valid but that is not the default behaviour one would expect. I have it covered now but more a thought for the benefit/safety of new users.

---

## 2024-03-07 14:46:54 - issues channel

**foxwood**

Had an issue last week with a test strategy running live. It was going through the runners placing bets and then hit an outlier not allowed for that resulted in a divide by zero. Flumine neatly ate the exception and fed the next `mc` to the strategy which placed bets, hit the outlier again and crashed again - rinse and repeat.



The impact of this was to start draining the bank rather quickly - fortunately I was monitoring it but it still took a big bite. After investigating, I discovered that flumine ate non-flumine exceptions due to `config.raise_errors = False` Taken 2+ years to fall down that hole. I know all the guff about testing and defensive code etc but the reality is that most of us are in permanent beta and things slip through.



I think this should default to `True` which would stop any runaways like mine and, more importantly, would be the expected behaviour for people new to flumine. In the meantime all my flumine wrappers set it to `True` right at the start.

---

## 2024-02-29 13:29:57 - random channel

**D C**

Ahhh thanks for this. I can see several entries market "Fix" and "Error". I guess it is that.

---

## 2024-02-26 19:05:48 - random channel

**D C**

No bets placed. That is rare unless the feed is down or had severe errors.

---

## 2024-02-26 10:18:16 - issues channel

**foxwood**

ok - had 9 versions yesterday trying to work around it so clean start today running under debug with debug logging - more later

---

## 2024-02-26 09:51:36 - issues channel

**foxwood**

no sign of BF error in the logs run at DEBUG level

---

## 2024-02-26 09:51:04 - issues channel

**liam**

flumine, it will retry on a betfair error

---

## 2024-02-25 19:47:52 - issues channel

**foxwood**

Probably doing something stupid but I'm getting an exception `Execution unknown error` thrown live (ok on backtest) using `market.replace_order()` called from within override of `stratBase.process_orders()` From the log the exception is thrown because the dictionary item `new_price` is missing from `update_data` although generated solely by `order.replace()` as part of the normal flow.

The scenario is playing with sub £1 bets by laying at very low odds, changing the size (works ok every time) and then replacing the order with a new price - which fails on about 2% of bets - I have a workaround that ensures the size/price combo doesn't hit `INVALID_PROFIT_RATIO` error.

All seems to happen on different thread - sample stack trace below. Can't reproduce at will. Feels like could possibly be python assign/copy issue around the "lost" dictionary item. Any clues / ideas welcome



`{"asctime": "2024-02-25 18:26:59,554", "levelname": "CRITICAL", "message": "Execution unknown error", "exc_info": "Traceback (most recent call last):`

  `File \"\\flumine\\execution\\betfairexecution.py\", line 251, in _execution_helper  response = trading_function(order_package, http_session)`

  `File \"\\flumine\\execution\\betfairexecution.py\", line 222, in replace  instructions=order_package.replace_instructions,`

  `File \"\\flumine\\order\\orderpackage.py\", line 164, in replace_instructions  return [`

  `File \"\\flumine\\order\\orderpackage.py\", line 165, in &lt;listcomp&gt;  order.create_replace_instruction()`

  `File \"\\flumine\\order\\order.py\", line 425, in create_replace_instruction  return {\"betId\": self.bet_id, \"newPrice\": self.update_data[\"new_price\"]}`

  `KeyError: 'new_price'", "trading_function": "replace", "exception": "'new_price'", "order_package": {"id": "4baba968-543d-49d4-84b4-a75355ab6a94", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x000001FE966E3EB0&gt;", "market_id": "1.225213820", "orders": ["139281784190412005"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "stratXX", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}`

---

## 2024-02-24 19:31:18 - general channel

**Peter**

Even much used strategies can have subtle edge cases triggered by exceptional real-world circumstances. But tracking them down generally requires forensic examination of the code alongside the logs, neither of which you're providing here.

---

## 2024-02-22 13:04:10 - issues channel

**liam**

Open up your debugger and you would see this

---

## 2024-02-21 15:17:14 - issues channel

**Unknown**

repeated code, received error. why?

---

## 2024-02-19 23:16:50 - general channel

**Jonjonjon**

The `ERROR_CODE` was `MARKET_SUSPENDED`.

Looking at my historical data file, the market did not get suspended at time of placement.

---

## 2024-02-19 23:07:41 - general channel

**Jonjonjon**

I noticed this in my logs:



`"instructionReports": [{"status": "FAILURE", "errorCode": "ERROR_IN_ORDER", "instruction":`



The market was shortly unsuspended.



What's the recommended way to handle this in my code? I would like to attempt to place the order after the market resumes.



For context, this was pre-race.

---

## 2024-02-19 10:07:28 - general channel

**liam**

Betfair won't actually close your stream on session expiry however you should use the error handling [https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py|example](https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py|example) or just use flumine and it does it all for you

---

## 2024-02-17 19:25:23 - general channel

**liam**

How have you calculated these returns? Fixed odds or lowest traded?

---

## 2024-02-17 14:17:19 - strategies channel

**D C**

TPD has been available through Gruss, BA and BM for quite some time now. It is also not free for users getting it through OTS software. The amount of utter horseshit assumptions about TPD I see on twitter from people who have NOT used it is incredible. TPD is great - but it has flaws. If it were that simple, TPD would likely never have made it available for use by paying customers and just milked the markets themselves. There are plenty of clever people on here who have said they've tried and failed to make TPD pay (or at least its not augmented their already profitable mehods). How many have paid X hundred quid for a month or two access only to find that they don't know what to do with it and then given up??? For sure the more people who access it will result in more people finding a way to use it profitably but they will be in the minority. Meanwhile those who try and fail because they think its a "pay to win" solution have given their money to other players and given up when they discover the truth.

---

## 2024-02-16 19:34:53 - issues channel

**Jeff Waters**

I just tried to subscribe to all UK greyhound markets, and got told:



*{"asctime": "2024-02-16 19:32:46,796", "levelname": "ERROR", "message": "[MarketStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 230 markets whereas max allowed number was: 200"}*

*{"asctime": "2024-02-16 19:32:46,796", "levelname": "INFO", "message": "[MarketStream: 2001]: FAILURE (9 connections available)"}*



Is there any way around this, apart from asking Betfair to increase my subscription limit?



Thanks



Jeff

---

## 2024-02-15 14:05:00 - issues channel

**Al**

Please tell me what condition should be prescribed in the strategy so that when the max_trade_count = 1 parameter is set, the strategy stops and does not continue to try to create new orders and does not issue "message": "Order status update: Violation", "violation_msg": "strategy.validate_order failed: trade_count (1) &gt;= max_trade_count (1)". Thanks

---

## 2024-02-14 08:46:15 - issues channel

**liam**

Oversight by myself on an optimisation to reduce func calls, fix [https://github.com/betcode-org/flumine/pull/737|here](https://github.com/betcode-org/flumine/pull/737|here)

---

## 2024-02-12 19:14:20 - general channel

**Ralegh**

I look at data as proof, you want enough of it to reach some confidence level. The level isn’t some fixed thing, it depends on the complexity model/chance of overfitting and the number of avenues you’ve tried with the data. The more ideas you try the more likely you are to get ‘lucky’ and find something which only made money by accident. Ultimately it’s down to your intuition. 

---

## 2024-02-12 18:25:51 - general channel

**ShaunW**

GPT is a permanent fixture on my right-hand screen.  Productivity should be going through the roof but it comes up with so many avenues to consider it's almost overwhelming.   Best to keep topics to single threads as it takes a while to understand your context.  "tidy my scruff code and put some comments in" is handy too:smirk:.

---

## 2024-02-12 18:17:11 - general channel

**ShaunW**

Hi [@U034TBZ5H6F](@U034TBZ5H6F) It depends on the odds of the situation you're looking for but a rule of thumb on sample size is.......:

1. *Calculate Implied Probability*: First, convert the odds into an implied probability. For decimal odds, the formula is Implied Probability=1OddsImplied Probability=Odds1​.

2. *Estimate Variance*: The variance in outcomes is inversely related to the implied probability. For a binary outcome (win/lose), the variance can be approximated by Variance=p×(1−p)Variance=p×(1−p), where pp is the implied probability.

3. *Determine Sample Size*: There's no one-size-fits-all formula for this, but a general rule of thumb is that higher variance requires a larger sample size. A common approach in statistics for estimating sample size for a proportion (which a win probability is) is using the formula: n=Z2×p×(1−p)E2n=E2Z2×p×(1−p)​ where nn is the sample size, ZZ is the Z-score for your desired confidence level (e.g., 1.96 for 95% confidence), pp is the implied probability, and EE is the margin of error you're willing to accept.

4. If in doubt ask chatGPT:smirk:



---

## 2024-02-09 15:25:32 - random channel

**D C**

I used to find strategy reference string a really useful thing but it ultimately ended up hampering my performance and in conjunction with other things, cost me a lot of money.

I don't use it at all now and just use distinct suffix per strategy on customer order reference strings to distinguish between strats. You live and learn...

---

## 2024-02-05 22:43:06 - strategies channel

**James**

Any idea which ones specifically/a prefix [@UUCD6P13J](@UUCD6P13J)?  Lots of spam in my logs rn for debugging reasons.



[@U01PJ5YMFBJ](@U01PJ5YMFBJ) yeah, my LAY is placed pre play if I get the price I want, and I hedge when its fully matched or when market turns in play I hedge the partial match.

These the logs are all for the same bet though, The lay was placed, and appears to be fully matched but it never moved to execution_complete. Even if it wasn’t matched, it should lapse and move to execution complete when the market moved in play. which it didn’t seem to. I may be misunderstanding how the order statuses work though.

---

## 2024-02-05 19:36:48 - strategies channel

**AndyL**

run with [http://logger.INFO|logger.INFO](http://logger.INFO|logger.INFO), you maybe getting a placement error...?

---

## 2024-02-04 20:32:45 - issues channel

**Jeff Waters**

Fair point, Peter, and working out how to do logging that is more useful than the basic  logging.DEBUG("message") stuff is on my to do list.



My situation at the moment is that I have a system that I've back tested, which I'd like to try applying on automated betting on. However, before I can do that, I need to properly investigate how this stuff works, and then build a bet placement app that also keeps track of how my bets fare. At the moment, I'm just at the research/exploration phase (which I'm finding really interesting, by the way! :slightly_smiling_face: ).



Thanks.

---

## 2024-02-04 19:42:20 - issues channel

**Jeff Waters**

Hi Peter



Thanks for taking a look.



I'm not using logging. This is the stack trace, though:



*Exception in thread Thread-1:*

*Traceback (most recent call last):*

  *File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\threading.py", line 973, in _bootstrap_inner*

    *self.run()*

  *File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\threading.py", line 910, in run*

    *self._target(*self._args, **self._kwargs)*

  *File "C:\Users\User\Documents\golive\venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 60, in start*

    *self._read_loop()*

  *File "C:\Users\User\Documents\golive\venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 232, in _read_loop*

    *self._data(received_data)*

  *File "C:\Users\User\Documents\golive\venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 273, in _data*

    *raise ListenerError(self.listener.connection_id, received_data)*



This is my full code:



```import betfairlightweight

import queue

import threading

import json



from betfairlightweight.filters import streaming_market_filter, streaming_market_data_filter

from log_in import log_in_and_get_API_client_object



# [https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py](https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py)



trading = log_in_and_get_API_client_object()

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

    event_type_ids=["4339"], country_codes=["GB"], market_types=["WIN"]

)

market_data_filter = streaming_market_data_filter(

    fields=["EX_BEST_OFFERS", "EX_MARKET_DEF"], ladder_levels=3

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)

t.start()



"""

Data can also be accessed by using the snap function in the listener, e.g:



    market_books = listener.snap(

        market_ids=[1.12345323]

    )



Errors need to be caught at stream.start, resubscribe can then be used to

prevent full image being sent, e.g:



    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=1000,  # send update every 1000ms

        initial_clk=listener.initial_clk,

        clk=listener.clk,

    )



The streaming unique id is returned in the market book which allows multiple

streams to be differentiated if multiple streams feed into the same queue.

"""



# check for updates in output queue

while True:

    market_books = output_queue.get()

    print(market_books)



    for market_book in market_books:

        print(

            json.dumps(market_book.streaming_update),  # json update received

        )```

If I change the event type id back from "4339" to "7", the app works fine.

---

## 2024-02-04 18:58:17 - issues channel

**Jeff Waters**

I've been experimenting with the Betfair Lightweight sample code at [https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py](https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py).



I've tried changing the event type id field from "9" to "4339" like so ("4339" being the event type id for greyhounds - [https://betfair-datascientists.github.io/api/apiPythontutorial/](https://betfair-datascientists.github.io/api/apiPythontutorial/)):



```market_filter = streaming_market_filter(

    event_type_ids=["4339"], country_codes=["GB"], market_types=["WIN"]

)```

However, the app pauses for about 30 seconds, and I then get this error message:



betfairlightweight.exceptions.ListenerError: connection_id: [deleted], data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"deleted"}



Where am I going wrong, please?

---

## 2024-02-04 14:07:48 - general channel

**D C**

Seen this asked in the past and IIRC there are no fixed thresholds. But when you apply for stream access there used to be a short set of questions you had to answer where you state your expected turnover and things like that and then you'd get a yes or no to access. Not sure if that is still the case now though (it was when I requested it about 4 years ago).

---

## 2024-02-02 13:37:10 - issues channel

**PeterLe**

Anyone seeing any issues this afternoon like this ;

AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)", "client": "APIClient", "trading_function": "account.get_account_details", "response": "AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)"}



Thanks



edit : Seems fine again now :+1:

---

## 2024-02-02 12:07:55 - general channel

**Simon Chan**

What do you mean nuke your cache?  I tried clearing the browser cache and even a different browser to test placing bets, it is still not working. It is weird because I already switched to VPN and can login and navigate the website without any issues. The geo-restriction error only happens when I place a bet.

---

## 2024-02-01 15:43:56 - general channel

**Simon Chan**

Thank for the info. I try the same VPN provider on my smartphone and placing bets seems to work

. I use Surfshark with their dedicated IP setup. It looks like my laptop might be part of the problem. I will debug it further tomorrow

---

## 2024-02-01 13:21:23 - general channel

**Unknown**

Don't know if this is a good place to ask. Does anyone here successfully used VPN to place a bet on the website (the Australia version)? I keep getting geo-blocked errors. I even try to route my internet through one of my VPS, but the errors keep happening.

---

## 2024-01-30 17:29:56 - general channel

**Trex44**

Hmm that might be the issue but I did specifically enforce data types on the columns of the pandas dataframe before converting to a parquet so I don't know why the column type would then differ from one parquet file to another.



I think I have found a workaround for now, I saved about 100 of the files as csvs then loaded them up into a data flow in SageMaker and had sagemaker convert them to parquet files. I could then crawl and load these files in a notebook just fine. I am trying it with the whole data set now.  Strangely when I tried this trick with parquet files I got garbage, the data viewer function in the data flow just showed random symbols instead of headers and the data. Yet downloading the same parquet files and converting them to csv worked just fine and showed the data was in tact and readable.  Its all quite odd. The fix will be fine for now but it means I cant just save the days races as parquets and run a crawler on them which is what I really want to do.

---

## 2024-01-30 16:43:12 - general channel

**Derek C**

In the case above it looks like the type of a column has changed. The crawler, I think, doesn't scan every single file but just a sample so it assumes all files are like its samples. I've found this error sometimes disappears if you are not querying the column that is confusing Athena - is the query above selecting all columns or just a subset? does selecting a single column work? If you have a column that in some parquet files is a string and in others numeric then that might explain your error. that could happen where a null field was defined as string but is being treated as floating point somewhere, i.e. nan, in your code.

---

## 2024-01-30 14:25:07 - general channel

**Trex44**

```QueryFailed: TYPE_MISMATCH: Unable to read parquet data. This is most likely caused by a mismatch between the parquet and metastore schema. You may need to manually clean the data at location '[s3://aws-athena-query-results-630653152022-eu-west-2/tables/3cfa2ebf-9d15-438d-8615-822f68e2af17](s3://aws-athena-query-results-630653152022-eu-west-2/tables/3cfa2ebf-9d15-438d-8615-822f68e2af17)' before retrying. Athena will not delete data in your account.```

Yea they typically look like the above. I don't understand why the metastore schema is different. I generate the schema off of the parquet files using a crawler. If I save the files as csv's I get no problems at all. I crawl the csv's, get the table and then there is no issue.

---

## 2024-01-30 08:09:31 - general channel

**Ralegh**

Hmm, alright I need to debug a bit then bc that’s not happening right now

---

## 2024-01-30 08:07:04 - general channel

**Ralegh**

Yeah I could do that, and mostly just for debugging to see what orders I have open, I’ve ended up with a duck taped monstrosity but it appears to work

---

## 2024-01-29 14:03:49 - strategies channel

**ShaunW**

Struggling to see how people aren't retrying anyway if their trigger persists and they don't have a corresponding order. Admittedly that might only occur on the next mktchage rather than iro the same update as price change frequency is typically faster than the failed order notification. But if it's a relatively inactive market it could help. But tbh I don't think I have many that fail or at least fail fast enough to process another during the same update.

---

## 2024-01-28 21:17:15 - strategies channel

**Ralegh**

Makes sense, and yeah shouldn’t matter either way if not latency sensitive.



I think generally I try to keep trading code stateless so the logic by default would just be to ignore failed orders and only retry if conditions are still true. Target position = (calculation)… trade while position &lt; target position. Or target position at price level = (calculation) and the same

---

## 2024-01-28 20:40:19 - strategies channel

**Ralegh**

Does it? I’d assume if you’ve already done the round trip to hear a place order failed then super latency sensitive stuff would have gone already, otherwise unless you’re taking a lot of time to process it should be similar latency wise to just resubmitting a failed order, but you wouldn’t resubmit if the condition had changed. If you’re doing heavy calculations with latency sensitivity I’d assume you’d need to offload to another thread and cache the results anyway, and just do a quick check of e.g price &gt; X, so don’t see how it’d be different. Not sure what context you’re talking about though

---

## 2024-01-27 15:36:27 - random channel

**ShaunW**

I'm trying to fix my broken Countal Slide loop.

---

## 2024-01-27 11:37:17 - strategies channel

**birchy**

It makes sense to use a language you're familiar with rather than learning a new one. The only caveat is that you have to find and fix your own bugs vs using open sourced code where multiple users are contributing.

---

## 2024-01-27 11:29:10 - issues channel

**birchy**

If you open a python console and enter `from ssl import wrap_socket` do you get the same error? Sounds like your ssl library is somehow different. Maybe you've inadvertently overridden it with a silly mistake like `ssl = 1234`

---

## 2024-01-27 11:20:26 - strategies channel

**birchy**

I feel your pain [@UUE6E1LA1](@UUE6E1LA1), mainly because I've built a heavy reliance on simulation and now know that I've binned quite a few potentially good strategies because they under/over performed in simulation. For passive bets, Flumine simulation is pretty accurate, although I have found it tends to under match vs live, but that's ok as long as you account for it. So in conclusion, simulation is probably best used for development, bug fixing and general analysis but going live is the only true way to find out how our bets affect XM, market impact, match rates, etc.

---

## 2024-01-27 04:27:48 - issues channel

**Adrian**

I am getting a strange error that is preventing me from logging in. It's "Attribute error: module 'ssl' has no attribute 'wrap_socket'"

Any ideas what's causing this? I'm using python 3.12

There is also "INVALID_SESSION_INFORMATION" error that comes before it but I don't know which one is causing which

---

## 2024-01-26 13:58:45 - strategies channel

**D C**

Cheers [@U016TGY3676](@U016TGY3676) . With this question you've just made me realise I've a massive bug in my own simulator code.

---

## 2024-01-25 20:28:58 - issues channel

**Lee**

Yep upgrade, that’s fixed in 2.5.4

---

## 2024-01-25 20:28:04 - issues channel

**Ralegh**

2.5.0, I’ll upgrade and see if that fixes tomorrow

---

## 2024-01-24 20:42:20 - issues channel

**Creepto**

Hello, 



I am trying to stream historical data using the python client betfairlightweight, with create_historical_generator_stream(), as in the examples. But I got the error: 'charmap' codec can't decide byte 0x88 in position xy: character maps to &lt;undefined&gt;.

However, when I just open the file with bz2 lib I can read the file. What am I missing?

---

## 2024-01-24 11:02:32 - general channel

**Ralegh**

If you’re not logged in on the website it will randomize also, otherwise sounds like an error on your end, maybe wrong market

---

## 2024-01-23 21:20:01 - random channel

**D C**

Yeah I agree. I suppose it is probably easier if you are focused on one out of the stalls, but picking one out of the pack at a quick glance seems like it has a lot of potential to get wrong.  I don't know much about how these inplay manual lads go about their business anyway though.

Makes you wonder what proportion of bets matched are the result of a manual error.

---

## 2024-01-22 19:54:50 - general channel

**AndyL**

was fixed in Flumine 2.5.4

---

## 2024-01-22 19:54:13 - general channel

**AndyL**

[@U03FS7KM2NL](@U03FS7KM2NL) sounds like the issue I saw : [https://github.com/betcode-org/flumine/issues/721](https://github.com/betcode-org/flumine/issues/721)

but is now fixed with the latest Flumine version

---

## 2024-01-21 10:41:06 - random channel

**Ralegh**

I assume they’re mostly looking at LOB and trade data, and you should be able to calibrate that to crypto, there’s probably some idiosyncratic differences like order types on exchanges but that might be fixable with small changes or through the calibration. 

---

## 2024-01-19 13:07:16 - random channel

**D C**

I don't "know" C# really [@UQL0QDEKA](@UQL0QDEKA) - I just work with compiled languages rather than interpreted languages (hence the earlier question). While updating can be a good thing, if you've been running an app profitably for YEARS, why risk changing it? Maybe base a new app off the old code, update all internals then run it with a different strat (with roughly same bet placement density) and compare bet placement latencies and see if there is a significant difference? Then if you notice a change (for the better) consider upgrading the old app?  Using 3rd party closed source components is always tricky - quality of documentation can vary! I was burned heavily in 2022 using a 3rd party async HTTPS component that I had failed to read the small print for.

---

## 2024-01-18 14:35:35 - random channel

**PeterLe**

Yes you have to drag and drop the zipped folder Shaun ;

I asked ;

You

if i were to upload it can you understand a full C# solution





ChatGPT

Yes, I can understand and analyze a full C# solution. If you upload the files, I can review the code, answer questions about it, suggest improvements, or help with debugging. Please ensure that the files are in a format that I can access, such as a ZIP file containing the solution and its associated project files.

---

## 2024-01-18 13:01:49 - random channel

**PeterLe**

Thanks [@UBS7QANF3](@UBS7QANF3) I hadnt thought of looking in your utils package. When I comapred your version with the ChatGpt version it stated that there were some pros ie :

(Where it states 'Your' it means betfairutils)

• Complexity: Your version adds a bit more complexity due to additional type checks and handling different scenarios (like the `Side.BACK` check). While this might be necessary for your specific use case, it can introduce slight overhead compared to the more streamlined version.

• Flexibility: Your version is more flexible in handling different data structures (like `PriceSize` objects and dictionaries), which can be advantageous if your data comes in various formats.

• Error Handling: Neither version uses explicit exception handling within the loop, which is good for performance. However, the reliance on external functions like `get_best_price_size` and `iterate_active_runners` means that error handling should be considered within these functions to avoid unexpected crashes.

• Readability and Maintainability: The use of type hints and clear separation of logic in your version can make the code more readable and maintainable, albeit at a slight cost to performance.

and conclusion ;

Conclusion:

• Performance: The streamlined version I provided is likely to be slightly faster due to its simplicity and direct approach. However, the difference might be marginal depending on the implementation details of the helper functions you use.

• Applicability: If your codebase frequently deals with different data structures for market data or requires additional checks like the `Side.BACK` logic, your version could be more suitable despite the potential slight performance trade-off.

So it may suit the more accomplished/better programmer than me (mine is just very basic stuff)? Ill need to just try and understand it better really and see if it would benefit me?

Hi [@UUCD6P13J](@UUCD6P13J) no ive never used cprofile before. Is it worth learning as a relative beginner or is it more intended for the advanced programmer?

---

## 2024-01-18 12:37:19 - random channel

**PeterLe**

I just fed some of my code into Chatgpt for comments on how to optimse.

it suggested that this code ;



```def calculate_book_percentage(runners):

    back_book = 0

    lay_book = 0

    ltp_book = 0



    for runner in runners:

        if runner.status == "ACTIVE":

            try:

                back = get_price(runner.ex.available_to_back, 0)

                if back:

                    back_book += 1 / back

            except AttributeError:

                return None



            try:

                lay = get_price(runner.ex.available_to_lay, 0)

                if lay:

                    lay_book += 1 / lay

            except AttributeError:

                return None



            if runner.last_price_traded:

                ltp_book += 1 / runner.last_price_traded



    return round(back_book, 4), round(lay_book, 4), round(ltp_book, 4)```

be replaced by this code

```def calculate_book_percentage(runners):

    back_book, lay_book, ltp_book = 0, 0, 0



    for runner in runners:

        if runner.status != "ACTIVE":

            continue



        back = get_price(runner.ex.available_to_back, 0)

        lay = get_price(runner.ex.available_to_lay, 0)

        ltp = runner.last_price_traded



        if back:

            back_book += 1 / back

        if lay:

            lay_book += 1 / lay

        if ltp:

            ltp_book += 1 / ltp



    return round(back_book, 4), round(lay_book, 4), round(ltp_book, 4)```

The rationale presented as ;

Key Changes:

1. Removed `try-except` Blocks:

    ◦ The original version used `try-except` blocks to catch `AttributeError` if the `available_to_back` or `available_to_lay` prices were not available. This can be inefficient in a loop.

2. Direct Checks for Price Availability:

    ◦ The optimized version directly checks if the `back` and `lay` prices are available using simple `if` statements, which is more efficient than handling exceptions.

3. Simplified Logic:

    ◦ Streamlined the logic to be more concise and straightforward, improving readability and performance.

By making these changes, the function becomes more efficient, especially in a real-time data processing context where

every millisecond counts



I've tested in back tests (all ok) and ran it live yesterday, all OK.

As I only know a very basic amount about Python, would any more experienced coders comment as to whether it is a positive change for the better? Thanks

---

## 2024-01-16 15:22:45 - general channel

**PeterLe**

Well Ive had these on and off intermittently Liam since I started using Flumine (either when running locally or on AWS).

Some days its fine, last 3 or 4 days have been fine for instance..

I usually have the terminal window visible so i can keep my eye on it when doing the day job alongside...ie of any error messages etc..

When the latency message comes through it just streams down the page and I can see other messages

I know its there for a reason but its working and making profits etc

---

## 2024-01-15 21:52:50 - general channel

**Jonjonjon**

A large budget and exceptional communication skills would be required for buying skills.

---

## 2024-01-15 10:36:00 - issues channel

**liam**

Yes but do it like this, use `get_price` as it might be None/empty list and your code will error and you can loop `runners` which makes things 10x easier to read



```        with market.transaction() as t:

            for runner in market_book.runners:

                if runner.status != "ACTIVE":

                    continue

                lay_price = get_price(runner.ex.available_to_lay, 0)

                trade = Trade(

                    market_book.market_id, 

                    runner.selection_id, 

                    0, 

                    self

                )

                order = trade.create_order(

                    side="LAY",

                    order_type=LimitOrder(price=1.10, size=1.00),

                    notes=OrderedDict(

                        required_size=0.10,

                        required_price=lay_price,

                    ),

                )

                t.place_order(order)```

---

## 2024-01-15 08:45:29 - issues channel

**liam**

Fixed in 2.5.7

---

## 2024-01-14 15:01:05 - issues channel

**Derek C**

Does anybody else experience this error with Flumine 2.5.6?



>  line 182, in _process_sports_data

>     event_id = sports_data.event_id

> AttributeError: 'Race' object has no attribute 'event_id'

It seems a genuine error when I inspect in the debugger - there is no 'event_id' in the Race object. If I switch to Flumine 2.5.4 then the error doesn't occur because the code references market_id instead of event_id in 2.5.4.



My sample code to reproduce the error:



```

class ExampleStrategy(BaseStrategy):

    def process_sports_data(self, market, sports_data) -> None:

        # called on each update from sports-data-stream

        print('***',market, sports_data)



client = clients.BetfairClient(trading)



framework = Flumine(client)



strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["7"], market_types=["WIN"],

            country_codes=['GB' ],

    ),

    sports_data_filter=['raceSubscription'],  

)

framework.add_strategy(strategy)



framework.run()```

---

## 2024-01-11 17:49:09 - issues channel

**liam**

User error?

---

## 2024-01-10 15:08:37 - general channel

**Derek C**

most of my Athena data is stored as parquet. Can you share the error?

---

## 2024-01-10 14:00:47 - general channel

**Trex44**

[@U04NWADNCFR](@U04NWADNCFR) Hey mate, do you know why Athena seems to hate nearly all parquet files? If I use Athena on CSVs its fine but if I use it on the same data saved as parquets it can usually find a way to error and there isn't enough information in the error for me to figure out the issue. For speed and costs I was hoping to save my data as parquets but at the moment can't.

---

## 2024-01-09 08:16:52 - random channel

**lorenzo**

Hi [@UPMUFSGCR](@UPMUFSGCR), quick noob Q. How do you account for the `MAX_CONNECTION_LIMIT_EXCEEDED` errors? Do you "bundle" strats together under one/couple market filters?

---

## 2024-01-08 20:10:55 - random channel

**liam**

[http://www.stat.columbia.edu/~gelman/research/published/standarderror.pdf|http://www.stat.columbia.edu/~gelman/research/published/standarderror.pdf](http://www.stat.columbia.edu/~gelman/research/published/standarderror.pdf|http://www.stat.columbia.edu/~gelman/research/published/standarderror.pdf)

---

## 2024-01-08 10:01:01 - issues channel

**George**

Seems like they might have fixed it

---

## 2024-01-08 09:50:52 - issues channel

**George**

I'm getting 'TIMEOUT_ERROR' this morning - is it me or is there a BF issue?

---

## 2024-01-07 23:35:23 - random channel

**Unknown**

Here you go [@UUE6E1LA1](@UUE6E1LA1) Even allowing for time zones I haven't ever recorded a -£2,185 in any 24hr period, I'd have noticed.  Maybe it's fixed now but the screenshot is from when I first noticed the feature was there.  The 9th was correct so I'm not interpretting it incorrectly, and the 11th is wrong too as I lost about 450 vs the -350 it shows.

---

## 2024-01-04 18:30:16 - random channel

**Peter**

You can validate the statement that they are accurate on average visually by inverting them to get the implied probability, grouping them into bins, and plotting the win rate for each bin. Apart from the tails they'll fall nicely into a straight upwardly trending line.



You could quantify the variance using a measure such as mean squared error, and see if this varied over time.



But I would challenge the idea that the accuracy of BSP could tell us much about whether it is smart or dumb money exiting the market. If one accepts wisdom of the crowds as a major contributor to prices converging to true odds,  then it's not necessary for the guesses (bets) to be good, just (relatively) independent.

---

## 2024-01-04 15:20:55 - issues channel

**NAS**

when i launch my flumine instance, it runs correctly for a while (30-60 mins) but then starts throwing invalid session errors when performing account operations



flumine.clients.betfairclient - ERROR - BetfairClient `account.get_account_funds` error

flumine.clients.betfairclient - ERROR - BetfairClient `account.get_account_details` error



Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}



guess there's a problem in the keep-alive updating?

---

## 2024-01-04 09:34:28 - general channel

**liam**

The token will expire as per the docs however your stream won't be closed, the streaming error handling example will handle this or flumine

---

## 2024-01-03 08:06:11 - general channel

**river_shah**

Happy new year everyone! '23 saw some good growth within sports betting. My goals for '24 are to keep focusing on more scalable and robust research methods and automating ever more. Also one of the key goals is to find exceptional people to work with. If you are an experienced researcher / trader constrained on technology, capital or market access and could benefit from collaborating, please DM me for an exploratory chat. Focus is sports betting &amp; crypto.

---

## 2023-12-29 10:14:03 - random channel

**D C**

I'd been at it for years off and on. Started botting on the SOAP API but only data gathering. In truth everything I was doing was pretty half arsed - the only things I had working models for there was zero money available on Betfair (MLB basically). I turned it around getting on for 4 years ago now. Started off at minus £50K after years of recreational betting and failed "systems" (although on the plus side that heavy usage means I still don't pay PC)

---

## 2023-12-28 22:45:43 - random channel

**Adrian**

So I'm nearly at the finish line after 9 months of building a start-to-finish ML app in python including learning how to code properly along the way. I spent 6 months doing something similar that failed a couple of years ago. I've spent nearly 4 years total trying to make money with Betfair. And I'm wavering at the finish line. I took a break for the holidays and it's made me reflect on how hard I've been working on this project and how many hours I've put in (virtually every waking hour outside of work) for no result yet because it's not finished and I haven't put it to use. I'm writing this to get some inspiration to finish it. How many of you have been in this situation and pushed through to find the rewards? Is it worth it? Do you actually make a good living doing this? The opportunity cost of doing something else is now weighing heavily as the project drags on I fear wasting time on something that doesn't pay off in the end.

---

## 2023-12-27 13:45:13 - issues channel

**Mo**

What error are you getting?

---

## 2023-12-27 12:27:24 - issues channel

**Alejandro Pablos Sánchez**

Hi, is anybody facing API Error issues today? The place_order method is not working for me today :smiling_face_with_tear:

---

## 2023-12-25 17:39:20 - general channel

**Matthieu Labour**

Hi all,



I am looking for guidance to implement properly in Flumine what I have done below in a hacky way. I would be grateful for any help on how to leverage flumine constructs as opposed to the hacks I have in place. Thank you in advance!



The purpose is to run a simulation in tennis with scores and marketdata.



The historical file that is being streamed has both mb and score



Example:

```[...]



"op": "mb", "clk": "APTx4AcAw63/BgDA8+cH", "pt": 1698962123328, "mc": [{"id": "1.220368399", "rc": [{"atb": [[1.55, 133.58]], "id": 51718172}]}]}



{"op": "score", "clk": "", "pt": 1698962127237, "mc": [{"eventTypeId": 2, "eventId": 32753994, "score": {"home": {"name": "Hunter/Mertens", "score": "15", "halfTimeScore": "", "fullTimeScore": "", "penaltiesScore": "", "penaltiesSequence": [], "games": "0", "sets": "0", "gameSequence": [], "isServing": true, "highlight": true, "serviceBreaks": 0}, "away": {"name": "Krawczyk/Schuurs", "score": "15", "halfTimeScore": "", "fullTimeScore": "", "penaltiesScore": "", "penaltiesSequence": [], "games": "1", "sets": "0", "gameSequence": [], "isServing": false, "highlight": false, "serviceBreaks": 0}}, "currentSet": 1, "currentGame": 2, "fullTimeElapsed": {"hour": 0, "min": 0, "sec": 0}}]}



{"op": "mb", "clk": "AJv04AcA+a//BgC29ucH", "pt": 1698962128901, "mc": [{"id": "1.220368399", "rc": [{"trd": [[2.82, 66.15]], "ltp": 2.82, "tv": 916.22, "id": 43352014}, {"atb": [[1.55, 13.23]], "trd": [[1.55, 120.35]], "ltp": 1.55, "tv": 1413.85, "id": 51718172}], "tv": 2330.07}]}



[...]```

And the strategy is the example of the tennis strategy in flumine



```class ExampleStrategy(BaseStrategy):

  def process_market_book(self, market, market_book):

        # process marketBook object

        if "score" in market.context:

            score = market.context["score"]

            print(

                score.match_status,

                score.current_game,

                score.current_set,

                score.current_point,

                score.score.home.score,

                score.score.away.score,

            )```



I have the following hacks in place



In `historicalstream.py`, I combine the lines mb and score lines so I get the score in the mb message

```[...]

    def on_data(self, raw_data: bytes) -> Optional[bool]:

        try:

            data = json.loads(raw_data)

        except ValueError:

            logger.error("value error: %s" % raw_data)

            return



        # remove error handler / operation check



        # skip on_change / on_update as we know it is always an update

        publish_time = data["pt"]

        if data["op"] == "score":

            self.last_score = data

        if data["op"] == "mb" and self.last_score:

            data["mc"][0]["score"] = self.last_score["mc"][0]

            self.last_score = None

        return self.stream._process(data[self.stream._lookup], publish_time)



[...]```



In `simulation.py`, I attach the score to the context of the market



```def _process_market_books(self, event: events.MarketBookEvent) -> None:

[...]

            # process market

            market(market_book)



            if "score" in market_book["streaming_update"]:

                market.context["score"] = Scores(

                    eventId=market_book["streaming_update"]["score"]["eventId"],

                    eventTypeId=market_book["streaming_update"]["score"]["eventTypeId"],

                    currentGame=market_book["streaming_update"]["score"]["currentGame"],

                    currentSet=market_book["streaming_update"]["score"]["currentSet"],

                    fullTimeElapsed={"hour": 0, "min": 0, "sec": 0},

                    score=market_book["streaming_update"]["score"]["score"],

                )

[..]```

---

## 2023-12-20 08:53:04 - general channel

**liam**

User error 

---

## 2023-12-14 15:22:23 - general channel

**Johnny Boston**

Well upgrading meant I'm seeing this now...





```{"asctime": "2023-12-14 15:19:58,081", "filename": "worker.py", "name": "flumine.worker", "levelname": "ERROR", "message": "Error in BackgroundWorker poll_market_closure: '1.222524898'", "exc_info": "Traceback (most recent call last):\n File \"/usr/local/lib/python3.10/site-packages/flumine/worker.py\", line 66, in run\n self.function(\n File \"/usr/local/lib/python3.10/site-packages/flumine/worker.py\", line 180, in poll_market_closure\n if _get_cleared_orders(\n File \"/usr/local/lib/python3.10/site-packages/flumine/worker.py\", line 226, in _get_cleared_orders\n market = flumine.markets.markets[market_id]\nKeyError: '1.222524898'", "worker_name": "poll_market_closure", "function": "&lt;function poll_market_closure at 0x7fc4c8e49480&gt;", "context": {}}```

---

## 2023-12-14 11:20:38 - random channel

**D C**

I can at least console myself with the fact that its a very easy bug to fix.

---

## 2023-12-14 11:15:34 - random channel

**D C**

OK I've spotted a few errors in my code already from this. I had not implemented any place in queue stuff yet and knew I had to do so but when going through the code in `simulatedorder.py` I came across this:



    `def _calculate_process_traded(self, publish_time: int, traded_size: float) -&gt; float:`

        `_traded_size = traded_size / 2`



Does this mean that regardless of odds, the traded volume as supplied by the API is simply a doubling of the BACK stakes matched?

---

## 2023-12-12 15:27:20 - random channel

**Justice**

[@UUE6E1LA1](@UUE6E1LA1) I accept a margin of error, and the odd glitch but, at least back then, it was far too frequent to warrant the significant effort to train a model or code some automation strategy. It must have improved since

---

## 2023-12-12 15:17:11 - random channel

**Justice**

[@UUE6E1LA1](@UUE6E1LA1) We are talking over 4 years ago. I contacted them directly and we agreed a select number of meetings on trial, mostly jumps. I can't remember the exact cost but it was far cheaper than £40 per meeting, perhaps as low as £10, but again it was just a trial. The direct UDP feed was the only way to consume the data back then. Perhaps it has improved, but for me, the positional errors were frequent, and sometimes very significant

---

## 2023-12-12 15:07:07 - random channel

**D C**

Interesting. I can't help but feel that you might have missed a trick. I mean, I agree with you about the occasional positional errors but to go to such lengths to pay for the data and write a stream listener app AND a viewer and then give up is an odd one. I wish I'd had access around when you did as there were far fewer GPSers around then. Out of interest what were you paying back then when you had it. I think I was quoted about £40 a meeting but you are the only person I've ever spoken to who has paid for the UDP feed direct from TPD as opposed to getting it via Betfair or OTS trading applications.

---

## 2023-12-12 14:56:36 - random channel

**Justice**

[@UUE6E1LA1](@UUE6E1LA1) That was many years ago, long before it was available with BetAngel etc. It was offered as a raw UDP stream sent direct via a fixed IP address. I only trailed it for probably 2 dozen meetings and didn't proceed any further as I was unimpressed with the accuracy of the data. But I have heard it has improved recently

---

## 2023-12-05 10:10:25 - issues channel

**Neil T (Betfair)**

Hi [@UFTBRB3F1](@UFTBRB3F1) - I can confirm that listClearedOrders returned to normal service yesterday morning. We haven't found any underlying issues with the service itself but believe the errors were caused by a network issue.

---

## 2023-12-04 10:33:21 - random channel

**Unknown**

It might be unrelated actually as that error seems to come up fairly often and it just looks like the server isn't responding.  Just went back a bit further and see a cryptic "Killed" line in the logs, and then the container restarts on the next line... I'll do a smaller market filter and report back.



CPU is 32 cores of a Xeon from 2017, 32gb allocated.

---

## 2023-12-04 10:22:05 - random channel

**Johnny**

I'm just using the example marketrecorder.py.  It seems to die (docker container restarts) on match days which means I have a load of incomplete market files - been checking the logs and get a load of "latency high" lines followed by a timeout error.  Maybe subscribing to too many markets is the issue, will try narrowing it down next



```{"asctime": "2023-12-03 13:12:51,407", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/site-packages/flumine/worker.py\", line 235, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.221745228'], 'customerStrategyRefs': ['d69966378a3d'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00af825869', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00af825869', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.221745228'], 'customerStrategyRefs': ['d69966378a3d'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00af825869', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00af825869', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

---

## 2023-12-03 18:57:18 - issues channel

**AndyL**

[@UUCD6P13J](@UUCD6P13J) you mean these ?

```{"asctime": "2023-12-02 22:49:10,557", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flumine/worker.py\", line 229, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.222016636'], 'customerStrategyRefs': ['AAAA'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00ae6c3413', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00ae6c3413', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.222016636'], 'customerStrategyRefs': ['AAAA'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00ae6c3413', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00ae6c3413', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

---

## 2023-12-03 16:15:09 - issues channel

**Unknown**

Has anyone been getting an increase of errors on list_cleared_orders endpoint over the last 3 days?

---

## 2023-12-03 03:12:22 - general channel

**Adam**

Hey all, hoping someone can help me understand the ‘available to back’ price and sizing for runners (horses) in a WIN market.

From a conceptual perspective, I want to understand how the available to back prices equate to traditional book makers odds in order to get a better understanding what I’m looking at in betfair markets. This isn’t for building a strategy, just to help aid my knowledge when analysing betfair market book data.



In a traditional market (e.g. on [http://bet365.com|bet365.com](http://bet365.com|bet365.com) or [http://www.tab.com.au|www.tab.com.au](http://www.tab.com.au|www.tab.com.au) etc) the fixed-odds available in a race is set by the platform and are traditionally BACK odds. In this example on bet365, at a point in time *Horse A is given a 9.7 odds to win*. The same Horse A on Tab sports has 9.8 odds to win.

In Betfair we receive the following EX for Horse A:

```Horse A - EX Details:

 - Available to Back: [{'price': 9.6, 'size': 7.03}, {'price': 9.4, 'size': 18.77}, {'price': 9.2, 'size': 12.29}]

 - Available to Lay: [{'price': 10.5, 'size': 11.79}, {'price': 11, 'size': 18.89}, {'price': 11.5, 'size': 3.6}]

 - Traded Volume: []```

Since betfair operates as a betting exchange, where bettors can bet against each other in a market exchange, we are provided with the market book for that runner. My understanding is that therefore the best available price to back on betfair for Horse A is *9.6* and this is the true reflection of the price provided by the other markets. But this maybe naive because it doesn’t consider the size or volume traded at this price. E.g. since the size is 7.03 is less than half of the size available at price 9.4, maybe is 9.4 a truer representation of the best backed odds for this horse? Do we need to take some average or consider volume or size to find this equivalence?

---

## 2023-12-02 10:36:54 - random channel

**Unknown**

Same output but laying to fixed liability

---

## 2023-12-02 09:20:47 - random channel

**Peter**

These aren't executed with high frequency: every 60s for `poll_market_closure` and every 120s for `poll_account_balance`  so shouldn't make a huge difference to your requests count.



If that is enough to cause "too many requests"-type errors, then time may be better spent looking at how to combine your strategies under a smaller number of Flumine instances.

---

## 2023-12-01 21:23:37 - random channel

**Jonjonjon**

Are the default workers `poll_account_balance` and `poll_market_closure` important? Would there be any unwanted side effects if I turned them off?



I'm asking as I'm running a lot of Flumine bots under a single account, and keep TIMEOUT_ERROR's due to too many requests.

---

## 2023-12-01 20:48:23 - random channel

**D C**

OK I will rerun it laying to lose fixed amount.

---

## 2023-12-01 20:47:36 - random channel

**liam**

Just lay to a fixed liability if you want to keep it simple, be interesting to see how the graph changes along with roi 

---

## 2023-12-01 15:04:15 - random channel

**D C**

Its basically testing value prices from a new model - lay bets only offered at a fixed scaling of the model value price (max 50-1 offered). Inplay horses.

---

## 2023-12-01 13:08:12 - general channel

**birchy**

Yeah, I've seen `client.account_funds`, but that's populated with the full account balance. I was actually thinking of using a fixed 'bank' due to the fact that it doesn't take long to hit stake market capacity and trying to get £200 matched in one hit is a bad idea. :wink:

---

## 2023-12-01 11:42:43 - random channel

**Jimmy**

Thanks Liam — don’t think I’ll hit that error path. Appreciate your help

---

## 2023-12-01 11:29:58 - issues channel

**Mo**

Nevermind, user error

---

## 2023-12-01 10:39:38 - issues channel

**CL**

betfairlightweight.exceptions.InvalidResponse: Invalid response received

---

## 2023-12-01 10:25:53 - issues channel

**liam**

Suddenly got lots of errors coming through, maybe it was me..

---

## 2023-12-01 10:02:15 - random channel

**liam**

Regarding its use, you will just pay the transaction change if applicable and you will be blocked if trying to do it at low odds where you have &lt;0.01 liability but you will get a cryptic error for that

---

## 2023-12-01 09:26:22 - strategies channel

**JFP**

Thanks, no log errors, must be something in the conditions. Will keep digging, thanks for your response.

---

## 2023-12-01 08:10:11 - general channel

**liam**

You have `self.clients` however my experience is that many use a fixed bank when using kelly on sports (ie ignore it)

---

## 2023-11-29 09:29:50 - strategies channel

**liam**

It seems that what you put in to train it wants when you predict (which makes sense), as far as I could work out when training it wanted something like this:



```dtrain = xgb.DMatrix(X_train.values, label=y_train.values)

dtest  = xgb.DMatrix(X_test.values, label=y_test.values)



# xgboost

param = {

    'objective': 'reg:squarederror'

}

n_estimators = 100

reg = xgb.train(param, dtrain, n_estimators, evals=[(dtest, 'eval'), (dtrain, 'train')], verbose_eval=False)



y_pred = reg.predict(dtest)```

---

## 2023-11-27 08:18:30 - general channel

**Adrian**

Hi Rob

Make sure you've "purchased" all the data you're trying to download. Even for the free data on the basic plan. If there's any missing you'll get an error message.

---

## 2023-11-25 12:10:29 - general channel

**Roy**

[@U066M1HC42V](@U066M1HC42V) That's right. I was trying it for horse racing and I have used almost all headers but I was getting same 403 error. However, I tried to open URL with PowerBI and it was able to extract the data.

---

## 2023-11-25 07:35:19 - general channel

**db888**

[@U067MDW0YPK](@U067MDW0YPK) Same issue I was having, despite only attempting to scrape it every few minutes throughout a live event. I've found that the rate limiting is non-deterministic - for some events I can hammer it and get what I want without issues, but in other cases it just fails with a 403 error. Hence why I feel the `Public Streaming API` may be a better option than the `loadRunnerChart` private API. Worth also noting that the priv API endpoint will purge data shortly after a match has ended - so if you wanted to scrape something after the fact, you won't get data via this method.

---

## 2023-11-25 07:27:33 - general channel

**Roy**

[@U4H19D1D2](@U4H19D1D2) I get 403 forbidden error while I try to scrape price data vs time from Load runner chart. Any other ways to scrape it? Thanks

---

## 2023-11-23 10:00:38 - strategies channel

**Ralegh**

If you create a formula with only a few parameters you could just do a grid search of sims for max pnl/max risk adjusted pnl and fix them

---

## 2023-11-22 18:58:37 - random channel

**AndyL**

Did I meet you in the Darts "red" team last week [@U066B8Z0L3F](@U066B8Z0L3F)? seem to remember you mentioning RacingPost to me and fundamentals...

Your database looks quite neat. I tried fundamentals on the greyhounds and failed misserably...!

---

## 2023-11-20 20:18:14 - random channel

**Adrian**

Mongo could be worse, I don't have any experience with it so... I'll try a few things, as long as they have a python interface. Pandas own write to SQL library failed to complete at all with my final dataset without it being split up into parts, even then it was problematic (creating ghost entries).

Although the flat files thing is working, it's getting messy- i've got raw, unprocessed data, then cleaned, workable data, then formatted data, then finally transformed data. Trying to keep it all linked with folders and file names seems cursed.

---

## 2023-11-19 14:31:40 - general channel

**db888**

So it seems like the `Private API`  rate limits or chokes (perhaps user error). Therefore I feel like recording data from the `Public Streaming API` throughout the course of an event is probably easiest..

---

## 2023-11-19 10:24:33 - issues channel

**AndyL**

[@U05KECSV68N](@U05KECSV68N) yes, 2.5.3 will have the issue.... Liam fixed it in 2.5.4

---

## 2023-11-19 09:59:04 - issues channel

**Rishab**

[@U4H19D1D2](@U4H19D1D2), I'll share it. just digging if there's some pattern in it. [@U01PJ5YMFBJ](@U01PJ5YMFBJ) I'm on '2.5.3', I think it's the same issue u are talking about. I'll quickly check and confirm. How did it fix for you?

---

## 2023-11-19 09:25:00 - issues channel

**AndyL**

[@U05KECSV68N](@U05KECSV68N) if the bet "status log" shows "Pending, ExecutionComplete", that sounds like the error I was getting which has now been fixed. Whereby the place_trade actually failed... Check what version of Flumine you are using...?

---

## 2023-11-17 20:31:11 - issues channel

**Derek C**

I'm having a problem using middleware in Flumine. Based on the  example: _examples/middleware/marketcatalogue.py,_ I want to populate market catalogues in a simulation. The trouble is that I store the market catalogue files on AWS S3 and the calls to AWS get rejected because the API call is using the monkey-patched version  of datetime.utcnow() in the request, causing AWS to reject the request.



The AWS error message is:

>  _"botocore.exceptions.ClientError: An error occurred (RequestTimeTooSkewed) when calling the GetObject operation: The difference between the request time and the current time is too large."_

So my question is - how can I use a middleware class without the monkey-patch?



I've tried using the SimulatedDateTime class but I'm stumped.

---

## 2023-11-17 19:28:36 - issues channel

**liam**

Yeah fixing your code is the easy fix, the warning logs normally hint at this but as you have found out things tend to escalate rather quickly 

---

## 2023-11-17 19:22:59 - issues channel

**AndyL**

[@U4H19D1D2](@U4H19D1D2) thanks Liam, yes, I think i've worked it out, it's not a memory leak per-se. Basically since I added PLACE to the listener, I am now subscribing GB,IE and WIN,PLACE for this one strategy, and it actively trades from 3hours out from startTime. What I see is a gradual increase in CPU towards mid-day when the main afternoon races fall within that 3hour window. I roughly calculated the market processing thread will be going around 50 markets, and my strategy code is probably not as efficient as it could be... My VM CPU then hits 50% in a 2vCPU box, which then starts to limit it, the affect it had was to cause the market update processing to lag the live updates, causing a steady progression of increase in latency, eventually towards a latency of 30mins!!! My trading  logic once the latency hit around 5mins was starting to put orders in for markets that were now closed! Thus getting lots of BF errors, and what made things worse for my hedge bets I was rather stupidly immediately re-placing the failed hedge causing yet more of a race......and eventually bang!

What i've learned:

1. I need to profile my strategy code more to try and make it more efficient. I've already done a good set of fixes...

2. I'm perhaps pushing my luck adding PLACE and doubling the number of active markets in that 3hour trade window, running on a single Flumine instance....

3. Importantly I need to monitor "latency" to prevent this sort of CPU race condition

I've done a set of fixes for 1 & 3 and I'm testing them now.....

---

## 2023-11-17 13:51:21 - issues channel

**liam**

np, if i remember I will put some error handling on this, FYI don't use version 2.5.2 as it has a bug when placing orders

---

## 2023-11-17 13:46:09 - issues channel

**liam**

looks like you are passing that in as per a market file which then gives the error

---

## 2023-11-17 13:38:29 - issues channel

**liam**

Can you share a file that errors?

---

## 2023-11-17 13:37:37 - issues channel

**Jimmy**

Just come back to Flumine and have been recording some data — trying to set up a simulation using the data. Based it off the WOM example [@U4H19D1D2](@U4H19D1D2) shared: [https://github.com/liampauling/flumine-strategy-development/blob/master/main.py](https://github.com/liampauling/flumine-strategy-development/blob/master/main.py)



Hits this error when I chuck a few files at it:



```  File "path removed", line 68, in &lt;module&gt;

    framework.run()

  File "/flumine/venv/lib/python3.11/site-packages/flumine/simulation/simulation.py", line 96, in run

    for event in stream_gen():

  File "/flumine/venv/lib/python3.11/site-packages/flumine/streams/historicalstream.py", line 224, in _read_loop

    if listener_on_data(update):

       ^^^^^^^^^^^^^^^^^^^^^^^^

  File "/flumine/venv/lib/python3.11/site-packages/flumine/streams/historicalstream.py", line 209, in on_data

    publish_time = data["pt"]



KeyError: 'pt'```

---

## 2023-11-16 17:50:31 - issues channel

**AndyL**

Hmm yeah, ok thanks, i'll do some debug

---

## 2023-11-14 09:21:11 - issues channel

**Clive**

Will do. I’ll ideally fix it if I have time too. 

---

## 2023-11-12 22:52:15 - random channel

**Adrian**

This is a newbie question as I'm moving over from Jupyterlab and Sublime to Pycharm. So learning how packages and projects work is a learning curve of its own. What is the best practice for working with the flumine package. Should I create my strategies within the flumine directories and then import my custom functions there? Or should I create a new project/venv separately with all my modules and import flumine into there instead? I would like to still be able to explore the flumine package and its variables through the debugger. Thanks

---

## 2023-11-12 16:26:26 - issues channel

**JazzMan**

Thanks for your reply [@UBS7QANF3](@UBS7QANF3), the main point is it's been working for years then today the betfair api gives me an error, tried on different machines.

---

## 2023-11-12 16:23:05 - issues channel

**Mo**

Is this a Betfair API error message? An HTTP error message? An OS error message?

---

## 2023-11-12 15:29:21 - issues channel

**JazzMan**

Does anyone know why I’m getting this error message when sending a REQUEST_AUTHENTICATION “Unable to write data to the transport connection: An established connection was aborted by the software in your host machine”, just happened today, been running for years, c# program 

---

## 2023-11-11 17:19:33 - issues channel

**Derek C**

I'm quite superstitious about rounding errors so I would try a payout of £11, in case the intended bet of ~18.5 pence is causing a payout of 9.99 and being rejected as less than 10.00

---

## 2023-11-11 16:18:05 - issues channel

**AndyL**

you've probably got better error handling than me...! i'm working on improving my handling of errors

---

## 2023-11-11 15:34:53 - issues channel

**Unknown**

[@U4H19D1D2](@U4H19D1D2) so found error from logging as to why my place_order is occaisionally failing:

```{"asctime": "2023-11-11 15:25:56,077", "levelname": "INFO", "message": "Order Place: FAILURE", "bet_id": null, "order_id": "1072113949238803678", "status": "FAILURE", "error_code": "INVALID_CUSTOMER_ORDER_REF"}```

:

```{"asctime": "2023-11-11 15:25:56,076", "levelname": "INFO", "message": "execute_place", "trading_function": "place", "elapsed_time": 0.04937458038330078, "response": {"customerRef": "a897131b2ef44081b9581b8d9d7d72bc", "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.221016025", "instructionReports": [{"status": "FAILURE", "errorCode": "INVALID_CUSTOMER_ORDER_REF", "instruction": {"selectionId": 49020468, "handicap": 0.0, "limitOrder": {"size": 47.18, "price": 1000.0, "persistenceType": "MARKET_ON_CLOSE"}, "customerOrderRef": "653232d17db55-1072113949238803678", "orderType": "LIMIT", "side": "BACK"}}]}, "order_package": {"id": "a897131b-2ef4-4081-b958-1b8d9d7d72bc", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0xffffb6d03c40&gt;", "market_id": "1.221016025", "orders": ["1072113949238803678"], "order_count": 1, "package_type": "Place", "customer_strategy_ref": "AAAAAA", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}```

This is happening about 25% of my hedge bets, and I am sure this was not happening a week ago...

---

## 2023-11-11 15:07:42 - issues channel

**Paul**

I'm using bflw to place some LIMIT orders as per below, but getting back INVALID_BET_SIZE errors on some bets - others formatted in the same way, with the same stake get executed fine. Ideas?

```{'orderType': 'LIMIT', 'selectionId': 22386662, 'side': 'BACK', 'handicap': '0', 'limitOrder': {'price': '55', 'persistenceType': 'PERSIST', 'betTargetType': 'PAYOUT', 'betTargetSize': '10'}}```



---

## 2023-11-11 10:22:31 - random channel

**Ralegh**

Fwiw most experienced people I know (inc river) do use flat files especially if you’re using it for research - you’re not gonna get any pnl gain from using sql. I personally used a db because it’s convenient to record market prices and my orders at the same time and check them with queries in real time but that’s more for debugging and not necessary 

---

## 2023-11-10 19:12:38 - issues channel

**AndyL**

yeah now worries, i'm going to catch the cancel no OrderId exception within the inner bit of code, so at least my hedging can recover...

---

## 2023-11-10 19:11:12 - issues channel

**liam**

Without some code to replicate it’s impossible for me to debug 

---

## 2023-11-10 19:05:05 - issues channel

**liam**

Do you know when you are getting the exception? Placing and cancelling is async so there will be a delay before you get a response / betId which I assume is causing the issue here 

---

## 2023-11-10 18:27:14 - issues channel

**AndyL**

I think old_order is getting the exception...

---

## 2023-11-10 18:06:51 - issues channel

**AndyL**

thanks [@UQL0QDEKA](@UQL0QDEKA) So i've moved to a AWS t4g, and no latency issues anymore,which is progress.

However, bot still having issues which looks like a coding bug of mine, it's interesting it's taking a while to develop given this version of the instance has been running a month, but this week my "hedging" is failing, and i'm getting loads of these exceptions:

```Order does not currently have a betId```

Which is odd, unfortunately it's in my hedging logic, I need to handle it better I think.

But [@U4H19D1D2](@U4H19D1D2) how does an Order not have a betId ?

---

## 2023-11-09 20:50:16 - issues channel

**AndyL**

yeah i've been looking through the code and logs... the one other thing i've noticed periodically is:

```Exception processing order for 1.220920786 : 54907 : Order does not currently have a betId"```

---

## 2023-11-09 20:49:29 - issues channel

**liam**

It will be some dodgy code or the instance, the latter is a quick fix 

---

## 2023-11-06 14:55:09 - random channel

**D C**

Does anyone who obtains TPD via betfair ever come across the stream feed time parameter is sometimes later than the betfair publish time parameter? It's not all the time and I've not noticed if off by more than 200 millisecs. Just be curious to know if its an actual thing or a bug with my gps collector program. I've never thought to check it in actual production code just always assumed chronological ordering would be a given.

---

## 2023-11-03 13:54:20 - issues channel

**foxwood**

In `simulatedorder.py:_process_sp()` there can be occasions when `actual_sp` is in `'None','NaN','Infinity'` (last 2 are as per BF docs - think I've found `None` before since have something in my code testing that). Currently my backtest logs show an exception thrown `File "C:\\...\\flumine\\simulation\\simulatedorder.py", line 391, in _process_sp\n    size = round(remaining_risk / (actual_sp - 1.0), 2)\nTypeError: unsupported operand type(s) for -: 'str' and 'float'"` Have a sample recorded file with 'Nan' if would help ?



EDIT: raised a git issue for this

---

## 2023-11-01 21:10:47 - general channel

**Trex44**

[@UUCD6P13J](@UUCD6P13J) No the instances were on different EC2 environments. I didn't notice that behaviour again so shut down the test instance and am just continuing with the main one. I am willing to bet the firing of the strat on one instance an not the other is related to the seconds_to_start_parameter in the strategy as its possible for this to be different across two different instances for the same market update due to the EC2's local clock being used in the calculation.  I am very happy with the fix and am pushing ahead, I was just reporting back to you guys to let you know.



Curious, as I haven't used GitHub much before, will the commit that fixed this now become part of the main codebase?

---

## 2023-10-29 13:15:37 - issues channel

**foxwood**

As I understand it the function definition `def selection_exposure(self, strategy, lookup: tuple) -&gt; float:` requires a tuple which I am presuming should contain one or more selection ids



That means (to me) that `market.blotter.selection_exposure(self,(mything.selection_id,))` should work ok. No matter what construct I use for the tuple it fails with an error of one sort or another.



Eventually I found that `market.blotter.selection_exposure(self,(0,mything.selection_id))` seems to work correctly.



If my understanding is right, cause of problem may be in `blotter.get_exposures() ... for order in self.strategy_selection_orders(strategy, *lookup[1:]):` which looks to me that it expects to start from subscript 1 and not 0.



Is something else expected in subscript position 0 ?

---

## 2023-10-27 14:01:35 - issues channel

**George**

it's almost like the version of `flumine.markets` which is passed to the thread is faulty, and then when I go in with the debugger it's picked up the correct version again

---

## 2023-10-27 13:43:08 - issues channel

**George**

In a worker, I am executing the following code:

```for m in flumine.markets:

    do_stuff(m)```

My problem is that `do_stuff` is never called; python is never entering the `for` loop. I put a print statement in the code, to print the value of `len(flumine.markets)` , and I get 0, which explains why `do_stuff` is not getting called.



Then I go in with the debugger and print the value of `len(flumine.markets)` and it is 126.



Does anyone know what is happening? This is super weird to me.

---

## 2023-10-22 19:01:55 - general channel

**Trex44**

Hey Guys. So the TLDR is the fix worked. Thanks very much.



A few more details. I set up another instance and ran the patch on that one. I ran the same strategies at the same stakes on the patched instance as the for the unpatched instance. I couldn't get the install to work using the CLI even though everything seemed to download/install ok so I manually overwrote the workers file using the updated workers file Lee created. It might not have worked via the CLI because I am inexperienced using GitHub so did something wrong.



All the printed results in the the patched instance had the 'profit' column in the csv filled in correctly. The unpatched instance displayed the same error as before with zeros in sometimes present in the profit column.



• I have noticed that sometimes the same line or set of lines will be written twice. This occurs on both instances but not necessarily for the same results on each instance. My guess is its a different bug to the one that has just been fixed. It doesn't bother me as I only upload each unique bet id once to my results database. See below for an example from the patched instance. The same strategy executes on two markets but the results from the first market print again after the second.

`325529200273,strat_x,1.219940406,6846739,e75cea8e-7019-11ee-b135-17589b09afd9,2023-10-21 13:58:25.603658,3.65,3.7,1,1,-1.0,BACK,0.034584,Execution complete,"3.65,3.7,3.7",,"{'runner_id': 6846739}"`



`325538377913,strat_x,1.219940554,15914199,ca20765c-701e-11ee-b135-17589b09afd9,2023-10-21 14:33:24.004443,3.4,3.4,1,1,-1.0,BACK,0.021638,Execution complete,"3.4,3.45,3.45",,"{'runner_id': 15914199}"`



`325529200273,strat_x,1.219940406,6846739,e75cea8e-7019-11ee-b135-17589b09afd9,2023-10-21 13:58:25.603658,3.65,3.7,1,1,-1.0,BACK,0.034584,Execution complete,"3.65,3.7,3.7",,"{'runner_id': 6846739}"`





• A strategy that was active on both instances and fired on both instances over the two day test period fired on one extra market on the patched instance than on the un patched instance. Uncertain why this happened, possible could be strategy related so will need to look into the code to see. 

I will leave the two instances running the next few days to see what is generated. The unpatches instance is one I use at low stakes for my test strategies. I will be upgrading my main instance to the new patch of the back of these results.

---

## 2023-10-19 15:00:05 - general channel

**liam**

[@U03N4QBJ0TV](@U03N4QBJ0TV) can you try using Lee's [https://github.com/betcode-org/flumine/pull/712|fix](https://github.com/betcode-org/flumine/pull/712|fix) and report back?



```pip install git+[https://github.com/lunswor/flumine.git@handle-clearing-orders-only-once-settled](https://github.com/lunswor/flumine.git@handle-clearing-orders-only-once-settled)```

---

## 2023-10-19 10:55:42 - general channel

**liam**

:+1: if you just copy the LowestLayer strategy and debug through / print stuff you can see how it works/simulates things

---

## 2023-10-19 10:24:12 - general channel

**Unknown**

Hi folks,



I think I may be getting somewhere, but very slowly!

The attached code is attempting to use a MarketRecorder strategy to record a simulated market but I'm running into the attached error in marketrecorder.py.

It seems there is no "id" property in the data object. I've tried hard-coding market_id to be the actual market id but this then creates a some new problems, which I'm happy to go into if anyone thinks necessary.

---

## 2023-10-18 13:36:26 - issues channel

**Neil T (Betfair)**

Hi [@U4H19D1D2](@U4H19D1D2),  keep alive should work as expected for Italian users when requested within the session expiry time.  Regardless of this, clients should still handle INVALID_SESSION_INFORMATION errors by creating a new API login request

---

## 2023-10-18 09:54:14 - issues channel

**D C**

You don't need to explicitly set to null [@U9JHLMZB4](@U9JHLMZB4) - just the absence of "sizeReduction" is sufficient. I don't have this field in my bets when I cancel them. What I did wonder is what would happen if you sent orders that are in a different market to the one specified in the request. Never tried it myself but I would suspect that you'd just get an error, but perhaps that could be an issue too. Not much to go on here though to be honest - could be a multitude of other things going on that we are not aware of.

---

## 2023-10-17 19:09:16 - strategies channel

**Jonjonjon**

Thanks for sharing Liam. I've tried predicting the error too, but with mixed results.

---

## 2023-10-17 17:22:50 - issues channel

**D C**

If this is the actual JSON you are sending then I can't see what is wrong with it. Maybe someone else can find an error in it.

---

## 2023-10-16 10:33:40 - strategies channel

**Unknown**

*ML Day 70*



Haven't given up, after exploring a few algos I found that using XGBoost seemed to be the most applicable / get the best results in terms of accuracy on the problem I was trying to solve. Using my current prediction I used the algo to predict the error (delta), from my understanding this is a common technique (does it have a name?) and proved to be far more accurate than starting 'fresh'.



Had a few issues with latency when simulating using the sklearn integration as its considerably slower compared to using the low level [https://xgboost.readthedocs.io/en/stable/python/python_api.html|library](https://xgboost.readthedocs.io/en/stable/python/python_api.html|library).



However the improvements just didn't equate to more profit, I have since worked on trying to get the algo to reveal what it was doing. I started reverse engineering / brute force by plugging in values that I believe had the highest importance and graphing the results. Without revealing too much this gave me a regression model for the variables as opposed to an 'if statement' on the min/max, not sure this is how I am supposed to be using machine learning but its working for me right now :joy:

---

## 2023-10-15 15:43:37 - issues channel

**PeterLe**

Im running four instances Liam on the same AWS instance, three were giving that error (if Ive checked it correctly and didnt miss it on the one I thought was OK..)

The one that looked ok -  I restarted that one yesterday after I changed some parameters? Not sure if that had something t do with it?

Anyway, all good now, been a good day so far :grinning:

---

## 2023-10-12 20:54:42 - issues channel

**AndyL**

nope can't start my recorder... always fails:

```{"asctime": "2023-10-12 19:51:46,255", "levelname": "ERROR", "message": "[FlumineStream: 3002]: MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s)."}```

---

## 2023-10-12 20:30:36 - issues channel

**AndyL**

[@U4H19D1D2](@U4H19D1D2) I think it's just me, i've got 4 Flumine processes, that consume 2 connections each, and a Recorder process consuming 2, so that should be the "10"

But for some reason, if I restart my Recorder it bombs loads of 10 connections exceeded error....

Not sure what i've done other than extend the some of the subscriptions to cover "PLACES" markets

---

## 2023-10-12 17:45:08 - issues channel

**AndyL**

all my bots had "connection closed by server" errors at about 06:20 this morning, followed by numerous MAX_CONNECTIONS_EXCEEDED you have 11 max 10 ! Which meant several failed to instantiate the order stream I think, caused all sorts of mess !! Closed them all off now, will restart them later.

Anyone else have issues today?

---

## 2023-10-12 16:25:01 - general channel

**Lee**

Yep, looks like the same problem. This can probably be fixed with a cleaner version of the patch i’m running. I’ll raise a PR to fix it but will probably be next week.

---

## 2023-10-12 13:50:10 - issues channel

**Riccardo Fresi**

my script was a loop with wait, basically a keep_alive every cycle; inddeed i used to make a try call for every api and a reconnect call in case of error

---

## 2023-10-12 11:51:11 - issues channel

**liam**

any error logs

```"BetfairClient `keep_alive` error"```



---

## 2023-10-12 11:20:25 - issues channel

**Riccardo Fresi**

new error, random during the recorder

```{"asctime": "2023-10-12 10:19:03,147", "levelname": "WARNING", "message": "_get_cleared_orders error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\riccardo.fresi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\flumine\\worker.py\", line 195, in _get_cleared_orders\n    cleared_orders = betting_client.betting.list_cleared_orders(\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\riccardo.fresi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\betfairlightweight\\endpoints\\betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\riccardo.fresi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"C:\\Users\\riccardo.fresi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.219555230'], 'customerStrategyRefs': ['C11-8C3Y06BQHRN'], 'settledDateRange': {'from': None, 'to': None}, 'fromRecord': 0} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang13b-prd-09131022-003f2bc994', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}```

any ideas?

---

## 2023-10-10 18:02:32 - random channel

**D C**

Hi [@U02GSMUSG56](@U02GSMUSG56) . Thanks for the info. To be fair, I get no errors - just don't get any GPS data for anything from Keeneland for some reason.

---

## 2023-10-10 17:48:35 - betfair-news channel

**Neil T (Betfair)**

[@U02K1MG7YCA](@U02K1MG7YCA) this issue is now fixed 

---

## 2023-10-10 17:08:35 - random channel

**Carl**

Keeneland does appear to be correctly mapped as code #75. I can also see there's been 5-figures of volume from TPD users at Keeneland so it seems to be working ok, please do DM me any errors you're seeing and we can dig a little deeper.



I'm told Belmont at the big A is the name of a meeting they do which is actually raced at the Aqueduct 28 day fall meeting because they are doing work to Belmont park.

---

## 2023-10-09 19:02:30 - issues channel

**liam**

Yeah was a regression I fixed this morning 

---

## 2023-10-09 18:07:23 - issues channel

**Lee**

looks like it was fixed in [https://github.com/betcode-org/flumine/commit/06451c28252b87a94132dc1f29777cc696937f98#diff-28dd751aae21cc91cc5ad919ae03d17ecd9e6e3564b84b3c580798dc3a6b9a20L263|2.5.2](https://github.com/betcode-org/flumine/commit/06451c28252b87a94132dc1f29777cc696937f98#diff-28dd751aae21cc91cc5ad919ae03d17ecd9e6e3564b84b3c580798dc3a6b9a20L263|2.5.2)

---

## 2023-10-09 16:19:13 - issues channel

**Riccardo Fresi**

Hi,



new error today, i had to downgrade python from 3.12 to 3.11, now on market recorded i got this, any idea?

Traceback (most recent call last):

  File "c:\Users\riccardo.fresi\OneDrive - Accenture\Downloads\Odds\streaming_soccer.py", line 61, in [module](module)

    framework.run()

  File "C:\Users\riccardo.fresi\AppData\Local\Programs\Python\Python311\Lib\site-packages\flumine\flumine.py", line 48, in run

    self._process_market_catalogues(event)

  File "C:\Users\riccardo.fresi\AppData\Local\Programs\Python\Python311\Lib\site-packages\flumine\baseflumine.py", line 263, in _process_market_catalogues

    market.market_book.streaming_unique_id in strategy.stream_ids

    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

AttributeError: 'NoneType' object has no attribute 'streaming_unique_id'

---

## 2023-10-09 15:28:12 - general channel

**foxwood**

Run it under debug with some breakpoints and explore the structure and field contents of `market` and `market_book` - it makes a lot more sense when populated with real data than trying to unravel the sources. Step it through and see what happens with different packets as well.

---

## 2023-10-09 14:44:42 - issues channel

**liam**

Just to update this, fix was released in 2.18.0 (we are now on 2.19.0) and I haven't seen any 'idle connection' errors since upgrading

---

## 2023-10-07 18:51:12 - issues channel

**Rishab**

Hi [@U4H19D1D2](@U4H19D1D2). Continuing on the last query I posted on the channel. I'm now using blotter in process_market_book for checking if my orders get traded and it seems to be working well in most of the cases. However, in one of the trades I got execution_complete status immediately, but it took a lot of time for size_remaining & matched_size to update(1 second). Could this exception happen sometimes? Just to note I also submitted a cancellation request for the same order as market moved through my quote in the tick & I didn't see any trade happen on that quote(because size_matched didn't update, so I pushed a cancellation request) & got an Execution_Complete status in the next tick(not sure if this was because of the trade happening in the last tick or my cancellation). So could it be that the cancellation request on a matched order is causing this delay or some sort of error at the exchange?

---

## 2023-10-06 17:51:20 - general channel

**joe taylor**

Hi all!

Is their a fixed protocol that is followed before the match goes inplay- I’ve noticed for horse racing that market is closed for a few seconds before going inplay. I want to stop my signal before it goes inplay and put some bets on bsp at the very last moment. Is there a way to find the “last moment” using seconds_to_start or something?

---

## 2023-10-06 16:15:59 - general channel

**Peter**

I don't believe that there is a convention for Betfair football names. I see inconsistencies, duplications, the occasional error and even no longer accurate historical names. You'll need to create and maintain a mapping between Betfair's and the alert service's names.

---

## 2023-10-06 13:18:25 - betconnect channel

**Sam**

Thanks [@U035RKUN199](@U035RKUN199), just on a call but will check these in about 45mins.

I spent quite some time some digging into this over the past few days but haven't gotten to the root cause of the issue.

We have a planned release around session management/authentication for next week which I think could potentially fix this but it's speculative without knowing the exact cause.



I'll keep you updated

---

## 2023-10-06 13:06:54 - betconnect channel

**Sam - DH**

Getting them right now [@U043G3YDB1Q](@U043G3YDB1Q)  if helpful. Last one 13:04. Generic 401 error code whilst trying to lay.

EDIT: Another now 13:07

---

## 2023-10-06 10:42:45 - general channel

**Trex44**

```import csv

import logging

from flumine.controls.loggingcontrols import LoggingControl

from flumine.order.ordertype import OrderTypes

import datetime



logger = logging.getLogger(__name__)

today_date = datetime.datetime.now().strftime("%d-%m-%Y--%H:%M")



FIELDNAMES = [

    "bet_id",

    "strategy_name",

    "market_id",

    "selection_id",

    "trade_id",

    "date_time_placed",

    "price",

    "price_matched",

    "size",

    "size_matched",

    "profit",

    "side",

    "elapsed_seconds_executable",

    "order_status",

    "market_note",

    "trade_notes",

    "order_notes",

]





class StandardLoggingControl(LoggingControl):

    NAME = "Standard_Logging_Control"



    def __init__(self, *args, **kwargs):

        super(StandardLoggingControl, self).__init__(*args, **kwargs)

        self._setup()



    def _setup(self):

        with open(f"orders_{today_date}.txt", "w") as m:

            csv_writer = csv.DictWriter(m, delimiter=",", fieldnames=FIELDNAMES)

            csv_writer.writeheader()



    def _process_cleared_orders_meta(self, event):

        orders = event.event

        with open(f"orders_{today_date}.txt", "a") as m:

            for order in orders:

                if order.order_type.ORDER_TYPE == OrderTypes.LIMIT:

                    size = order.order_type.size

                else:

                    size = order.order_type.liability

                if order.order_type.ORDER_TYPE == OrderTypes.MARKET_ON_CLOSE:

                    price = None

                else:

                    price = order.order_type.price

                try:

                    order_data = {

                        "bet_id": order.bet_id,

                        "strategy_name": order.trade.strategy,

                        "market_id": order.market_id,

                        "selection_id": order.selection_id,

                        "trade_id": order.trade.id,

                        "date_time_placed": order.responses.date_time_placed,

                        "price": price,

                        "price_matched": order.average_price_matched,

                        "size": size,

                        "size_matched": order.size_matched,

                        "profit": order.profit,

                        "side": order.side,

                        "elapsed_seconds_executable": order.elapsed_seconds_executable,

                        "order_status": order.status.value,

                        "market_note": order.trade.market_notes,

                        "trade_notes": order.trade.notes_str,

                        "order_notes": order.notes_str,

                    }

                    csv_writer = csv.DictWriter(m, delimiter=",", fieldnames=FIELDNAMES)

                    csv_writer.writerow(order_data)

                except Exception as e:

                    logger.error(

                        "_process_cleared_orders_meta: %s" % e,

                        extra={"order": order, "error": e},

                    )



        [http://logger.info|logger.info](http://logger.info|logger.info)("Orders updated", extra={"order_count": len(orders)})



    def _process_cleared_markets(self, event):

        cleared_markets = event.event

        for cleared_market in cleared_markets.orders:

            [http://logger.info|logger.info](http://logger.info|logger.info)(

                "Cleared market",

                extra={

                    "market_id": cleared_market.market_id,

                    "bet_count": cleared_market.bet_count,

                    "profit": cleared_market.profit,

                    "commission": cleared_market.commission,

                },

            )```

---

## 2023-10-05 12:17:01 - general channel

**Andy B**

That timing indicates there must be an issue, as it actually takes around a minute for 50 markets.  I can't get cProfile to run without errors when executing against my flumine script, but it works with other none flumine scripts, and I think it might be the multi-processing causing the issue.



concurrent.futures.process._RemoteTraceback:

"""

Traceback (most recent call last):

  File "C:\Python\lib\multiprocessing\queues.py", line 245, in _feed

    obj = _ForkingPickler.dumps(obj)

  File "C:\Python\lib\multiprocessing\reduction.py", line 51, in dumps

    cls(buf, protocol).dump(obj)

_pickle.PicklingError: Can't pickle &lt;function run_process at 0x00000251473E35E0&gt;: attribute lookup run_process on __main__ failed

"""



The above exception was the direct cause of the following exception:



Traceback (most recent call last):

  File "C:\Python\lib\runpy.py", line 197, in _run_module_as_main

    return _run_code(code, main_globals, None,

  File "C:\Python\lib\runpy.py", line 87, in _run_code

    exec(code, run_globals)

  File "C:\Python\lib\cProfile.py", line 180, in &lt;module&gt;

    main()

  File "C:\Python\lib\cProfile.py", line 173, in main

    runctx(code, globs, None, options.outfile, options.sort)

  File "C:\Python\lib\cProfile.py", line 19, in runctx

    return _pyprofile._Utils(Profile).runctx(statement, globals, locals,

  File "C:\Python\lib\profile.py", line 62, in runctx

    prof.runctx(statement, globals, locals)

  File "C:\Python\lib\cProfile.py", line 100, in runctx

    exec(cmd, globals, locals)

  File "C:\Users\elmob\OneDrive\Punting\Scripts\Betfair\BoxPercSimsAll.py", line 945, in &lt;module&gt;

    job.result()  # wait for result

  File "C:\Python\lib\concurrent\futures\_base.py", line 433, in result

    return self.__get_result()

  File "C:\Python\lib\concurrent\futures\_base.py", line 389, in __get_result

    raise self._exception

  File "C:\Python\lib\multiprocessing\queues.py", line 245, in _feed

    obj = _ForkingPickler.dumps(obj)

  File "C:\Python\lib\multiprocessing\reduction.py", line 51, in dumps

    cls(buf, protocol).dump(obj)

_pickle.PicklingError: Can't pickle &lt;function run_process at 0x00000251473E35E0&gt;: attribute lookup run_process on __main__ failed

---

## 2023-10-05 10:23:14 - general channel

**rob smith**

Hi, I've been trying to download data from Betfair using this script: [https://github.com/betcode-org/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/betcode-org/betfair/blob/master/examples/examplehistoricdata.py). I've added my login details but not made any other changes. I keep getting the following error: `Traceback (most recent call last):`

 `File "C:\Users\Rob\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\endpoints\historic.py", line 206, in request`

   `response_json = json.loads(response.content.decode("utf-8"))`

`orjson.JSONDecodeError: unexpected character: line 4 column 1 (char 6)`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

 `File "E:/Documents/PycharmProjects/bfData/bfDataDownloadv1.py", line 53, in [module](module)`

   `file_type_collection=["M"],`

 `File "C:\Users\Rob\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\endpoints\historic.py", line 148, in get_file_list`

   `(response, response_json, elapsed_time) = self.request(method, params, session)`

 `File "C:\Users\Rob\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\endpoints\historic.py", line 208, in request`

   `raise InvalidResponse(response.text)`

`betfairlightweight.exceptions.InvalidResponse: Invalid response received:`





`[!DOCTYPE html](!DOCTYPE html)`

`[html](html)`

`[head](head)`

`[meta name="viewport" content="width=device-width" /](meta name="viewport" content="width=device-width" /)`

`[title](title)ngErrorRedirect[/title](/title)`

`[/head](/head)`

`[body](body)`

`[div](div)`

`Error`

`[/div](/div)`

`[script defer src="<https://static.cloudflareinsights.com/beacon.min.js/v8b253dfea2ab4077af8c6f58422dfbfd1689876627854](script defer src="<https://static.cloudflareinsights.com/beacon.min.js/v8b253dfea2ab4077af8c6f58422dfbfd1689876627854)" integrity="sha512-bjgnUKX4azu3dLTVtie9u6TKqgx29RBwfj3QXYt5EKfWM/9hPSAI/4qcV5NACjwAo8UtTeWefx6Zq5PHcMm7Tg==" data-cf-beacon='{"rayId":"811491476cdf0742","version":"2023.8.0","b":1,"token":"d048f65d27954a24aa6b1d7d2ddcb256","si":100}' crossorigin="anonymous">[/script](/script)`

`[/body](/body)`

`[/html](/html)`

---

## 2023-10-05 09:47:18 - general channel

**liam**

[https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#250-2023-10-05|flumine 2.5.0 ](https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#250-2023-10-05|flumine 2.5.0 )released, lots of improvements (smart open now integrated) and bug fixes but let me know if anything breaks

---

## 2023-10-04 11:48:37 - issues channel

**Rishab**

Hey guys! I'm using Flumine to execute my orders &amp; noticing that for a few orders that are traded, in that tick itself the order.size_matched doesn't change. Don't see any bug in my code so far so wanted to confirm if the order details take some time to update or something?

---

## 2023-10-04 11:31:39 - general channel

**Andy B**

Actually, it's not a bug, it's because I set this in another strategy:

if 'processed' not in market.context:

                market.context['processed'] = True

---

## 2023-10-04 11:25:16 - issues channel

**Riccardo Fresi**

sorry liam, probably i explain myself very bad:

1. the problem with my laptop is fixed

2. there is something else that is not working properly, i don't think is it related to my laptop, i found that use context should be a best practice ([https://docs.python.org/3/library/ssl.html](https://docs.python.org/3/library/ssl.html)), so i said to myself that could be useful for everyone, so i ask to the community that have people more expert than me. if it's not useful, no problem

---

## 2023-10-04 11:17:18 - issues channel

**liam**

You want to push code to everyone that fixes a problem that just impacts your work laptop?

---

## 2023-10-03 21:25:48 - issues channel

**foxwood**

Log full of 503 errors on the streams from 6ish until it came back at about 08:05 then automatically sorted itself out and carried on as normal. Any fancy middleware ? My setup is just basic flumine and inheriting from BaseStrategy.

---

## 2023-10-03 10:47:59 - issues channel

**Lee**

actually i think the issue i had in previous outages was fixed in [https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#223-2022-08-01|2.2.3](https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#223-2022-08-01|2.2.3) - the cancel race condition

---

## 2023-10-02 15:28:52 - betconnect channel

**Sam - DH**

Hey guys, I've been receiving a lot of 'Unauthorised' API response messages recently (earliest occurred on 16/08).



Couple observations:

• Seems to only occur when attempting to match a bet request, doesn't occur when retrieving bet request info etc.

• Happens maybe once or twice a week, and usually only lasts for around 45mins or so, but it is sporadic and bet-dependant it seems

• Restarts/re-authenticating don't appear to resolve the 'issue'

I've enabled some more verbose logging to determine which node it's happening to etc. If there's no obvious reason as to why this is happening from your end, I can provide more info over DMs.



Todays timestamps of errors are 14:16-14:26



Just curious to see if there's anything I'm doing wrong, and cautious to not be operating out of line with expected use. Having said this, I haven't changed anything in the X amount months we've been working with the API so, a bit stumped.



Any assistance greatly appreciated, cheers in advance

---

## 2023-10-01 09:06:07 - general channel

**Andy B**

Thanks (again) Liam.  I'm still not getting the response I was expecting though.  My strategy looks like:



strategy = BoxPercSim(

        market_filter={

            "markets": markets,

            'market_types':['WIN','PLACE'],

            "listener_kwargs": {"inplay": False, "seconds_to_start": 80},

            "event_processing": True

            },

    max_order_exposure= 50, # Max bet sizes of $50

    max_trade_count=1, # Max of trade/bet attempt per selection

    max_live_trade_count=1, # Max of 1 unmatched Bet per selection

    )



And then the rest of my code is:



place_market = market.event["PLACE"]

                            print(place_market)

                            for a in place_market:

                                print('event:', a.event, 'market_type:', a.market_type, 'place_market_type:', type(place_market))

                            place_market_book = place_market[0].market_book



I put that bit of debug in there to try and see what is being returned and I can see that place_market is indeed a flumine object as per my code in the live stream - &lt;flumine.markets.market.Market object at 0x000001B593B74AF0&gt;.



In the second part of the debug, I can see the output as:

event: defaultdict(&lt;class 'list'&gt;, {'WIN': [&lt;flumine.markets.market.Market object at 0x000001B592FECDF0&gt;], 'PLACE': [&lt;flumine.markets.market.Market object at 0x000001B593B74AF0&gt;]}) market_type: PLACE place_market_type: &lt;class 'list'&gt;



Using the vscode debugger, I can see that market.event = 'WIN" and the value of place_market is an empty list i.e. [].  Presumably I need to be getting the value for place_market from somewhere else, but looking through the debuger output in vscode isn't giving me the answers I expect.  I did wonder if the market I was accessing was only a WIN market, but it does this for every market when I let the back test run, so that can't be the answer.  It has to be the way I am trying to access it.

---

## 2023-09-30 20:34:18 - general channel

**Peter**

I use vscode too and would be lost without the debugger. Highly recommended.

---

## 2023-09-30 18:40:16 - random channel

**river_shah**

[https://github.com/AntonOsika/gpt-engineer/blob/main/ROADMAP.md](https://github.com/AntonOsika/gpt-engineer/blob/main/ROADMAP.md) The plan is to let llms write the tests and debug failing tests too

---

## 2023-09-30 18:06:50 - random channel

**AndyL**

When a "user" reports a "bug" in a GPT-AI written piece of software who debugs the problem?

"Hey GPT what ye doin putting bugs in this crap? fix it now!!"

---

## 2023-09-30 08:14:00 - general channel

**Andy B**

I have this code working well in the live stream using flumine, but I can't get it going in a back test.  In my live code I use:

place_market = market.event["PLACE"]

place_market_book = place_market[0].market_book



So I initially tried using the same in a back test, but no dice.  I then tried it as:

place_market = market.market_book.market_definition.market_type["PLACE"]

place_market_book = place_market.market_book



But again it didn't work and it throws the error TypeError: string indices must be integers.



I tried looking at it in the debugger and both market.event and market.market_book.market_definition.market_type show the value as 'WIN', which is correct, and leads me to think that maybe the context of the place market either doesn't exist in the recorded data, or there is yet another way to access it.  Any thoughts?

---

## 2023-09-29 08:30:08 - general channel

**liam**

Nice debugger can be a game changer when learning 

---

## 2023-09-29 08:18:30 - general channel

**Unknown**

What about when you use the debugger?

---

## 2023-09-29 08:17:20 - general channel

**Andy B**

I tried debugging it by printing market.market_book.market_definition and I get:

&lt;betfairlightweight.resources.streamingresources.MarketDefinition object at 0x000001D6DA25CB80&gt;



So I can see that it is an object and VSCode tells me it is a variable.  If I wanted to get the market_id, I know that I can do print(market.market_book.market_id), but I have no clue how to process the market_definition values.

---

## 2023-09-25 13:44:06 - general channel

**Jorge**

Hi, looks like the [https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py#L10|OrdersMiddleware](https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py#L10|OrdersMiddleware) has a bug because it is not filtering by market.market_id (in [https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py#L23|list_current_orders](https://github.com/betcode-org/flumine/blob/master/examples/middleware/orders.py#L23|list_current_orders) ) when processing orders. Is anyone else using it?



This is the code I use to add the Middleware:

```....



framework.add_strategy(strategy)

framework.add_market_middleware(RestoreOrdersMiddleware(framework))

framework.run()```

---

## 2023-09-25 07:44:49 - general channel

**D C**

When I started I wrote a GUI app with a price grid trading tool with the view to using it as a visual aid to manually trading. In retrospect this was rather stupid for a variety of reasons, but I am actually quite glad I started off like this because watching the rendered GPS in real time made it very clear what kind of "surprises" the data can throw at you. Especially when watching a race replay after and comparing with the GPS visuals. I don't want to criticize though  - there is still plenty of information there despite the errors.

---

## 2023-09-24 00:05:08 - general channel

**Rishab**

Hey! In the flumine backtest I'm getting MAX_TRANSACTION_COUNT Error, was trying to figure out how is 1 hour considered in backtest for total no. of transactions?(Lets say 50 races are backtested within an hour , would all the trades in this time period be considered as trades in 1 hour?)

---

## 2023-09-22 10:04:47 - general channel

**D C**

I had between 10 and 20 on certain API operations yesterday and quite a few "Connection reset by peer" errors. That said I am testing out a new codebase and the latter could be down to me. Previous code bases don't clock the HTTP result codes so I don't know how common the 502s are in general to compare it with.

---

## 2023-09-22 09:10:18 - general channel

**casper**

Getting quite a few Status Code Error 502 lately and some “Connection aborted” messages when using trading.betting endpoints. Anyone experiencing similar things? Yesterday had particularly a lot of those.

---

## 2023-09-20 20:40:47 - general channel

**Mona**

I wanted to record this "structured data" in a file that is easy for me to debug. I am not using market recorder, can it be used to record processed data&gt;?

---

## 2023-09-17 10:11:45 - general channel

**PeterLe**

Morning,

I noticed i had some STRATEGY_EXPOSURE errors  yesterday (This is a new strategy; I was expecting a lot more bets to be placed than it did)

I have a number of strategies all running on a single system...

Each one of which is run from the command line...

The code at the bottom of each strat is like so:



`strategy = Sub6(`

    `name="WIN",`

    `market_filter=betfairlightweight.filters.streaming_market_filter(`

        `event_type_ids=["7"],`

        `country_codes=["GB", "IE"],`

        `market_types=["WIN"],`

    `),`

    `max_order_exposure=50,`

    `max_selection_exposure=100,`

    `max_trade_count=5000,`

    `max_live_trade_count=8`

`)`

`framework.add_strategy(strategy)`



`framework.run()`



I can also see that we also have these settings in strategy.py too :



 `def __init__(`

        `self,`

        `market_filter: Union[dict, list],`

        `market_data_filter: dict = None,`

        `sports_data_filter: List[`

            `str`

        `] = None,  # 'raceSubscription', 'cricketSubscription'`

        `streaming_timeout: float = None,`

        `conflate_ms: int = None,`

        `stream_class: Type[BaseStream] = MarketStream,`

        `name: str = None,`

        `context: dict = None,`

        `max_selection_exposure: float = 15, # 15`

        `max_order_exposure: float = 2,`

        `max_trade_count: int = 1000,`

        `max_live_trade_count: int = 15,`

        `multi_order_trades: bool = False,`

    `):`



So my question is: Am I correct in setting the exposures in the individual strategy files and if so, do these setting take precedence/over ride over any other areas of code?

Thanks in advance

---

## 2023-09-17 06:04:42 - general channel

**AI Trader**

Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x7fd25870c290&gt;, 'Connection to [http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com) timed out. (connect timeout=30)'))

Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x7fd25870c290&gt;, 'Connection to [http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com) timed out. (connect timeout=30)'))

---

## 2023-09-17 06:04:26 - general channel

**AI Trader**

Guys, has anyone had issues creating stream connections using betfairlightweight in EC2 instances? I guess it's more an AWS question (sorry), but when I run my docker in AWS ECS Fargate, it works fine. Whenever I try to run the same container on ECS using an EC2 instance, I get a Timeout error (max retries exceeded). Error in the comments. I have tried to ssh into the instance and ping betfair server to make sure it wasn't some firewall or connectivity issue, but the ping works.

---

## 2023-09-16 11:17:46 - issues channel

**Riccardo Fresi**

Today is not a good day! Internal error 500 both local machine and aws……you too?

---

## 2023-09-15 16:06:58 - issues channel

**H**

Haha yeah, at least they have a fix out though

---

## 2023-09-15 15:11:30 - issues channel

**H**

In case anyone is having issues where some of their Python scripts randomly die with 100% CPU usage, I think I've tracked this down to a bug in orjson which is fixed in the latest version (3.9.7) but present in a few previous versions (3.9.3-3.9.6).

[@U4H19D1D2](@U4H19D1D2) it might be worth merging this PR since it looks like all tests pass with `orjson==3.9.7`: [https://github.com/betcode-org/betfair/pull/538](https://github.com/betcode-org/betfair/pull/538)

Details of the problem in this GitHub issue: [https://github.com/ijl/orjson/issues/415](https://github.com/ijl/orjson/issues/415)

When the bug occurs it stops logging, and doesn't even respond to KeyboardInterrupts, so it was a real pain to track down :sweat_smile:

---

## 2023-09-15 03:00:40 - issues channel

**Pramod S**

Hi I am trying to use flumine for getting data stream to get horse racing complete data for GB

While using sample code i am getting error



starting strategy 'ExampleStrategy'

Traceback (most recent call last):

  File "&lt;pyshell#0&gt;", line 1, in &lt;module&gt;

    framework.run()

  File "C:\Python37\lib\site-packages\flumine\flumine.py", line 33, in run

    self._process_market_books(event)

  File "C:\Python37\lib\site-packages\flumine\baseflumine.py", line 151, in _process_market_books

    market = self._add_market(market_id, market_book)

  File "C:\Python37\lib\site-packages\flumine\baseflumine.py", line 204, in _add_market

    self.markets.add_market(market_id, market)

  File "C:\Python37\lib\site-packages\flumine\markets\markets.py", line 21, in add_market

    if market.event_id:

  File "C:\Python37\lib\site-packages\flumine\markets\market.py", line 133, in event_id

    return self.market_book.market_definition.event_id

AttributeError: 'NoneType' object has no attribute 'event_id'

---

## 2023-09-14 18:55:04 - issues channel

**Riccardo Fresi**

no other laptop...i try to connect on hotspot from phone, same error, i think we can conclude that it's about the computer configuration, maybe

---

## 2023-09-14 11:06:36 - issues channel

**Riccardo Fresi**

```&lt;ssl.SSLSocket fd=4780, family=2, type=1, proto=0, laddr=('127.0.0.1', 51863), raddr=('84.20.210.135', 443)&gt;



     10 s.connect((host, __port))

     12 print(s)

---&gt; 14 print(s.recv(1024))



File C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\ssl.py:1296, in SSLSocket.recv(self, buflen, flags)

   1292     if flags != 0:

   1293         raise ValueError(

   1294             "non-zero flags not allowed in calls to recv() on %s" %

   1295             self.__class__)

-&gt; 1296     return self.read(buflen)

   1297 else:

   1298     return super().recv(buflen, flags)



File C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\ssl.py:1169, in SSLSocket.read(self, len, buffer)

   1167         return self._sslobj.read(len, buffer)

   1168     else:

-&gt; 1169         return self._sslobj.read(len)

   1170 except SSLError as x:

   1171     if x.args[0] == SSL_ERROR_EOF and self.suppress_ragged_eofs:



TimeoutError: The read operation timed out```

---

## 2023-09-14 10:58:13 - issues channel

**Riccardo Fresi**

something strange happens now. this on stream creation



```DEBUG:urllib3.connectionpool:[https://identitysso.betfair.it:443](https://identitysso.betfair.it:443) "POST /api/login HTTP/1.1" 200 None```

this on connect

```TimeoutError                              Traceback (most recent call last)

File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py:243, in BetfairStream._receive_all(self)

    242 try:

--&gt; 243     part = self._socket.recv(self.buffer_size)

    244 except (socket.timeout, socket.error) as e:



File C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\ssl.py:1296, in SSLSocket.recv(self, buflen, flags)

   1293         raise ValueError(

   1294             "non-zero flags not allowed in calls to recv() on %s" %

   1295             self.__class__)

-&gt; 1296     return self.read(buflen)

   1297 else:



File C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\ssl.py:1169, in SSLSocket.read(self, len, buffer)

   1168     else:

-&gt; 1169         return self._sslobj.read(len)

   1170 except SSLError as x:



TimeoutError: The read operation timed out



During handling of the above exception, another exception occurred:



SocketError                               Traceback (most recent call last)

c:\Users\riccardo.fresi\OneDrive - Accenture\Documents\Odds\betfair_sample_Stream.ipynb Cella 11 line 1

...

--&gt; 247     raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

    248 else:

    249     return  # 133, prevents error if stop is called mid recv



SocketError: [Connect: 0]: Socket The read operation timed out```

i also notice that this is endless

```# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)```

---

## 2023-09-14 10:40:34 - issues channel

**Riccardo Fresi**

DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso.betfair.it:443|identitysso.betfair.it:443](http://identitysso.betfair.it:443|identitysso.betfair.it:443)

DEBUG:urllib3.connectionpool:[https://identitysso.betfair.it:443](https://identitysso.betfair.it:443) "POST /api/login HTTP/1.1" 200 None

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 1] Sending: b'{"op":"authentication","id":1,"appKey":"xxx","session":"xxx="}\r\n'

---

## 2023-09-14 10:39:02 - issues channel

**liam**

Can you share the logs from this:



```# setup logging

logging.basicConfig(level=logging.DEBUG)  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

trading = betfairlightweight.APIClient("/")



# login

trading.login_interactive()



# create stream

stream = trading.streaming.create_stream()



stream._connect()

stream.authenticate()```



---

## 2023-09-14 10:34:21 - issues channel

**liam**

Here is mine



```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso.betfair.com:443|identitysso.betfair.com:443](http://identitysso.betfair.com:443|identitysso.betfair.com:443)

DEBUG:urllib3.connectionpool:[https://identitysso.betfair.com:443](https://identitysso.betfair.com:443) "POST /api/login HTTP/1.1" 200 None

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[MarketStream: 1]: connection_id: 206-213456-64155124

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"authentication","id":2,"appKey":"/","session":"/"}\r\n'

INFO:betfairlightweight.streaming.listener:[MarketStream: 2]: SUCCESS (5 connections available)```

---

## 2023-09-14 10:33:31 - issues channel

**liam**

That is very tricky to read, but I want to see the response from this



```DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"authentication","id":2,"appKey":"XXXXX","session":"XXXXXX="}\r\n'```

It seems like it just carries on?? which it shouldn't in v2.18

---

## 2023-09-14 10:29:26 - issues channel

**Riccardo Fresi**

different

```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.it:443|identitysso-cert.betfair.it:443](http://identitysso-cert.betfair.it:443|identitysso-cert.betfair.it:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.it:443](https://identitysso-cert.betfair.it:443) "POST /api/certlogin HTTP/1.1" 200 125

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"authentication","id":2,"appKey":"XXXXX","session":"XXXXXX="}\r\n'

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"marketSubscription","id":1,"marketFilter":{"eventTypeIds":["7"],"marketTypes":["WIN"],"countryCodes":["GB"]},"marketDataFilter":{"fields":["EX_BEST_OFFERS","EX_MARKET_DEF"],"ladderLevels":3},"initialClk":null,"clk":null,"conflateMs":1000,"heartbeatMs":null,"segmentationEnabled":true}\r\n'

Exception in thread Thread-14 (start):

Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1038, in _bootstrap_inner```

```'\nData can also be accessed by using the snap function in the listener, e.g:\n\n    market_books = listener.snap(\n        market_ids=[1.12345323]\n    )\n\nErrors need to be caught at stream.start, resubscribe can then be used to\nprevent full image being sent, e.g:\n\n    streaming_unique_id = stream.subscribe_to_markets(\n        market_filter=market_filter,\n        market_data_filter=market_data_filter,\n        conflate_ms=1000,  # send update every 1000ms\n        initial_clk=listener.initial_clk,\n        clk=listener.clk,\n    )\n\nThe streaming unique id is returned in the market book which allows multiple\nstreams to be differentiated if multiple streams feed into the same queue.\n'```

```    self.run()

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 975, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    return

^^^^^^^^^^^

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 226, in _read_loop

    if self._running:

                      

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 256, in _receive_all

    "[Connect: %s]: Connection closed by server"

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

betfairlightweight.exceptions.SocketError: [Connect: 2]: Connection closed by server```



---

## 2023-09-14 10:11:02 - issues channel

**liam**

Can you try 2.18.0, don't expect it to work but it should error at the issue

---

## 2023-09-13 14:52:32 - general channel

**liam**

Add this to the top of your script and you will get lots



```import logging

from http.client import HTTPConnection



HTTPConnection.debuglevel = 1

logging.basicConfig()

logging.getLogger().setLevel(logging.DEBUG)

requests_log = logging.getLogger("requests.packages.urllib3")

requests_log.setLevel(logging.DEBUG)```



---

## 2023-09-13 14:46:07 - general channel

**rob smith**

This is a basic question but I'm a self-taught beginner and can't work it out. I moved my scripts to a vps and they worked as normal for the first few days before returning a "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host" error at login. Betfair's support have asked me for the json request and the response. This is where I'm stuck. I'm using trading.login_interactive() to login. How do I get the json request/response? Thanks

---

## 2023-09-13 07:31:25 - issues channel

**Mo**

Looks like a random network error

---

## 2023-09-13 06:25:39 - issues channel

**Paras Stefanopoulos**

Anyone know what could be happening here? been getting this for months randomly from betfair stream:



```2023-09-11 08:09:43,688 ERROR [Connect: 37]: Socket [Errno 104] Connection reset by peer

Traceback (most recent call last):

  File "/home/ec2-user/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py", line 244, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "/usr/lib64/python3.9/ssl.py", line 1227, in recv

    return self.read(buflen)

  File "/usr/lib64/python3.9/ssl.py", line 1102, in read

    return self._sslobj.read(len)

ConnectionResetError: [Errno 104] Connection reset by peer



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "…", line 32, in wrapper

    result = await async_func(*args, **kwargs)

  File "…", line 108, in main

    raise betfair_streamer.error

  File "/usr/lib64/python3.9/threading.py", line 980, in _bootstrap_inner

    self.run()

  File "/usr/lib64/python3.9/threading.py", line 917, in run

    self._target(*self._args, **self._kwargs)

  File "…", line 50, in _start_stream

    raise e

  File "...", line 47, in _start_stream

    self.stream.start()

  File "/home/ec2-user/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py", line 67, in start

    self._read_loop()

  File "/home/ec2-user/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

  File "/home/ec2-user/.local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py", line 248, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 107]: Socket [Errno 104] Connection reset by peer```

---

## 2023-09-12 15:43:37 - issues channel

**Unknown**

No...

got ssoid from inspect element on logged in betfair tab.

My account was suspended (due to auth) for a bit but fixed, not sure if that's relavant.

---

## 2023-09-12 14:08:11 - issues channel

**Unknown**

Hi - a newbie question: I get an INVALID_APP_KEY error APINGException when trying to run trading.betting.list_event_types(). Any ideas here?

I think login is okay (can see session_token and expired=false)

Using python 3.10.6

---

## 2023-09-11 09:30:22 - general channel

**D C**

Yeah charging for the API was something I couldn't believe when I first heard about it. Feels like pure greed - same with charging for historical data. I can't understand creating obstacles to automation like that - I remember when I first started dabbling with automation years ago I would lose hundreds of quid on a new strategy while ironing out the bugs. Probably says more about my slapdash approach to things back then but I can't be the only one who has lost more than £299 learning the hard way along the way.

---

## 2023-09-09 21:58:59 - random channel

**thambie1**

[https://www.washingtonpost.com/world/interactive/2023/tennis-match-fixing-gambling-investigation-belgium/](https://www.washingtonpost.com/world/interactive/2023/tennis-match-fixing-gambling-investigation-belgium/)

---

## 2023-09-08 09:49:38 - issues channel

**Riccardo Fresi**

```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.it:443|identitysso-cert.betfair.it:443](http://identitysso-cert.betfair.it:443|identitysso-cert.betfair.it:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.it:443](https://identitysso-cert.betfair.it:443) "POST /api/certlogin HTTP/1.1" 200 125

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"authentication","id":2,"appKey":"XXXX","session":"XXXXX/XX="}\r\n'

DEBUG:betfairlightweight.streaming.betfairstream:[Subscription: 2] Sending: b'{"op":"marketSubscription","id":1,"marketFilter":{"eventTypeIds":["7"],"marketTypes":["WIN"],"countryCodes":["GB"]},"marketDataFilter":{"fields":["EX_BEST_OFFERS","EX_MARKET_DEF"],"ladderLevels":3},"initialClk":null,"clk":null,"conflateMs":1000,"heartbeatMs":null,"segmentationEnabled":true}\r\n'

INFO:root:log point before t.start()```

---

## 2023-09-08 09:38:02 - issues channel

**liam**

Can you set logging to debug and share (hide keys etc)

---

## 2023-09-08 09:30:11 - issues channel

**Riccardo Fresi**

copy from example, but the while at the end

```# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

trading = betfairlightweight.APIClient(BETFAIR_USER, 

                                       BETFAIR_PASSWORD, 

                                       app_key=BETFAIR_APPKEY, 

                                       certs=CERT_PATH, 

                                       locale='italy')



# login

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

    event_type_ids=["7"], country_codes=["GB"], market_types=["WIN"]

)

market_data_filter = streaming_market_data_filter(

    fields=["EX_BEST_OFFERS", "EX_MARKET_DEF"], ladder_levels=3

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)

t.start()```

same error



```INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

Exception in thread Thread-5 (start):

Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1038, in _bootstrap_inner

    self.run()

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 975, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

                        ^^^^^^^^^^^^^^^^^^^

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 256, in _receive_all

    raise SocketError(

betfairlightweight.exceptions.SocketError: [Connect: 2]: Connection closed by server```



---

## 2023-09-08 09:08:55 - issues channel

**Riccardo Fresi**

this is the full error

Exception in thread Thread-12 (start):

Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1038, in _bootstrap_inner

    self.run()

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.1520.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 975, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

                        ^^^^^^^^^^^^^^^^^^^

  File "C:\Users\riccardo.fresi\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\betfairlightweight\streaming\betfairstream.py", line 256, in _receive_all

    raise SocketError(

betfairlightweight.exceptions.SocketError: [Connect: 2]: Connection closed by server

---

## 2023-09-08 09:08:15 - issues channel

**liam**

What does the error tell you?

---

## 2023-09-08 09:05:22 - issues channel

**liam**

I think you are not sharing the real error here, which at a guess is a subscription limit as you are trying to subscribe to all eventTypeIds 1?

---

## 2023-09-08 09:04:11 - issues channel

**Riccardo Fresi**

from here everything ok

```logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# login

trading.login()

# create queue

output_queue = queue.Queue()

output_queue

# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)

listener

# create stream

stream = trading.streaming.create_stream(listener=listener)

stream

# create filters (GB WIN racing)

market_filter = streaming_market_filter(

    event_type_ids=["1"]#, country_codes=["GB"], market_types=["WIN"]

)

market_data_filter = streaming_market_data_filter(

    fields=["MATCH_ODDS"], ladder_levels=3

)

# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)

# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)```

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created



from here i got the warning message

```t.start()```

after that the line "market_books = output_queue.get()" is endless

```streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=1000,  # send update every 1000ms

        initial_clk=listener.initial_clk,

        clk=listener.clk,

    )

# check for updates in output queue

while True:

    market_books = output_queue.get()

    print(market_books)



    for market_book in market_books:

        print(

            market_book,

            market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

            market_book.streaming_update,  # json update received

            market_book.market_definition,  # streaming definition, similar to catalogue request

            market_book.publish_time,  # betfair publish time of update

        )```



---

## 2023-09-08 08:57:19 - issues channel

**Unknown**

hi guys,

i don't understand the reason of this error on streaming, any ideas?

---

## 2023-09-07 04:07:22 - issues channel

**Unknown**

When I go back to my Betfair login function which is similar to this [https://forum.developer.betfair.com/forum/sports-exchange-api/net/26471-recent-vb-login-code](https://forum.developer.betfair.com/forum/sports-exchange-api/net/26471-recent-vb-login-code), I still get the



thePage.ResponseUri.Query = ?redirectMethod=POST&amp;errorCode=INPUT_VALIDATION_ERROR



I also note that the INFO Variable contains 2 sort of sessions IDs and that it expires tomorrow?  However if looks different to the ssoid I had a few minutes ago which started  ssoid = PXVhiddenxxxxxxJI

---

## 2023-09-06 23:32:54 - issues channel

**Troy Edwards**

Public Function LoginSessionBetfair(username As String, password As String) As String

        Dim ssoid As String = [String].Empty

        Dim info As String()

        Dim sessToken As String = ""

        LoginSessionBetfair = ""



        Try

            ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12    'V0.40 12 March 2019 added as requested by Betfair



         Dim uri As String = String.Format("[https://identitysso.betfair.com/api/login?username={0}&amp;password=](https://identitysso.betfair.com/api/login?username={0}&amp;password=)                          {1}&amp;login=true&amp;redirectMethod=POST&amp;product=[http://home.betfair.int|home.betfair.int](http://home.betfair.int|home.betfair.int)&amp;url=[https://www.betfair.com/](https://www.betfair.com/)", username, password)

            Dim myRequest As HttpWebRequest = DirectCast(WebRequest.Create(uri), HttpWebRequest)



            myRequest.Method = "POST"

            myRequest.Timeout = 5000



            Dim thePage As WebResponse = myRequest.GetResponse()

            info = thePage.Headers.GetValues("Set-Cookie")

            Debug.Print(thePage.ResponseUri.Query) 'PRINT OUT WHY I MIGHT HAVE AN ERROR?





            Dim i As Integer = 0

            While ssoid = [String].Empty AndAlso i &lt; info.Length

                If info(i).Contains("ssoid=") Then

                    ssoid = info(i)

                End If

                i += 1

            End While



            sessToken = ssoid.Replace("ssoid=", "") 'Dump front string

            sessToken = sessToken.Replace("; Domain=.[http://betfair.com|betfair.com](http://betfair.com|betfair.com); Path=/; Secure", "")         'dump rear string



        Catch ex As System.Exception



        End Try



        Return sessToken '~~&gt; Should work ok if Login a success

    End Function 'Session Token and Login

---

## 2023-09-06 23:32:51 - issues channel

**Troy Edwards**

Thanks for the replies.  DC this login function was coded in 2014 but I did update it to include TLS 1.2 in 2019.



I get this response atm and I have printed to the console window using debug.print

Debug.Print(thePage.ResponseUri.Query) = ?redirectMethod=POST&amp;errorCode=INPUT_VALIDATION_ERROR



I am also wondering whether this code is non-interactive OR is it interactive in that I am just passing in my login details and password however I am passing it through a HTTPWebRequest.  I guess once I received my session ID I have never had to look at this code again.





My code is below and thanks btw:

---

## 2023-09-06 12:48:52 - issues channel

**Mo**

What is the error you get when logging in

---

## 2023-09-06 12:39:23 - issues channel

**Troy Edwards**

Hi guys does the betfair Non-Interactive login required a self signed certificate as per [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login)????



I coded my login code back in 2014 which worked well and returned my Session ID (SSOID), however as I have continued to call the function Keep Betfair Alive [https://identitysso.betfair.com/api/keepAlive](https://identitysso.betfair.com/api/keepAlive) I believe this function has been keeping my SSOID current and maybe I have missed Betfair have increased their login security ??   I changed my password the other day and then when the betbot try to login I get Errors.









Also slightly unrelated but does anyone here use the Betfair Developer Forum [https://forum.developer.betfair.com/](https://forum.developer.betfair.com/) and can you login ?   I assume the login is your current betfair login but it just will not allow me to login to the forum yet I used to have access :disappointed:

---

## 2023-09-05 12:58:13 - betconnect channel

**Jimmy**

Hi [@UBS7QANF3](@UBS7QANF3), we've identified the issue here. I can confirm that the settlement of these bets are correct, but it looks like there is slight display issue with the decimal odds on some of the bets.



We believe it is due to a mapping error for a particular bookmakers odds. We are looking into this now and will get it fixed ASAP. Apologies for the confusion here.

---

## 2023-09-04 11:07:46 - general channel

**Jorge**

This is what I have tried, but got an error: `raise RuntimeError('cannot schedule new futures after shutdown')`



```    framework.add_strategy(strategy)



    try:

        framework.run()



    finally:

        log_error('Exiting. Canceling all open orders and saving state of the bot...')

        for market in framework.markets:

            for order in market.blotter:

                if order.status == OrderStatus.EXECUTABLE:

                    log_error('Canceling order {}', order)

                    market.cancel_order(order) ```

---

## 2023-09-04 10:37:20 - general channel

**Jorge**

Hi, I'd like my Strategy to cancel all open orders when stopping the script (i.e. Ctrl+C but also in case of a bug). Would you put this inside process_market_book() or is there a better place for it?



Also, I save the exposures per runner/market_id when the Strategy stops, so I could continue from there if I need to restart it.

---

## 2023-09-03 12:03:12 - betconnect channel

**Mo**

1. No they haven't been fixed

2. No haven't spoken to support, would rather speak to someone on here who knows what they're talking about

3. No, just football Double Chance and 1X2 markets

---

## 2023-09-03 11:27:02 - betconnect channel

**Ralegh**

Hmm ok, were they fixed later? Checked with support? Any market specific rules in play (eg horses)? Seems high

---

## 2023-09-02 17:09:43 - random channel

**AndyL**

I must admit i'm rather old school (matching my age!), and like to run python strategies and stuff directly from the command line. But i'm trying to get to grips with Juypter, and struggling!, firstly to get it to work on Mac M1, due to this bug : [https://github.com/jupyter/notebook/issues/6974](https://github.com/jupyter/notebook/issues/6974)

Eventually got past that with their workaround... downgrading...

Then i'm trying to do a noddy plotly example:

```import plotly.express as px

fig = px.bar(x=["a", "b", "c"], y=[1, 3, 2])

fig.show()```

Now it displayed once!

But now doesn't any more....

Looking at the Jupyter console, I see:

```[W 17:03:38.386 NotebookApp] 404 GET /static/plotly.js (::1) 0.830000ms referer=[http://localhost:8888/notebooks/workspace/Test1.ipynb](http://localhost:8888/notebooks/workspace/Test1.ipynb)```

As though it's cached it, but now can't find it...?

I'm all for these IDEs to help you, but as ever you have to use them has they expected...?

---

## 2023-09-02 09:45:03 - general channel

**foxwood**

All my files recorded with flumine have a value for that field eg "clk":"AJjuvAEAhcOpAQCIxccB" - maybe a recorder issue ? Sort of thing I'd write a mm for once the recorder was fixed and run through all the files setting the field to a fixed string. Pain but future proofs it.

---

## 2023-09-02 03:27:51 - issues channel

**mon mon**

Hi all - how can I monitor exceptions raised by the streams in Flumine?

I am getting them in my logs ok, but for selected exceptions I want to be able to monitor within my program and take actions when they are raised

(e.g.  [MarketStream: 3073]: SUBSCRIPTION_LIMIT_EXCEEDED, I would adjust the market filter on to limit the markets/dates etc).

---

## 2023-09-01 22:48:59 - general channel

**Mo**

I think because of this line: [https://github.com/tarb/betfair_data/blob/5babe169ef625c193bec405580eaf04daaeb6e5e/src/ids.rs#L7](https://github.com/tarb/betfair_data/blob/5babe169ef625c193bec405580eaf04daaeb6e5e/src/ids.rs#L7) if you want to try to fix it

---

## 2023-09-01 21:02:24 - general channel

**Peter**

Trying to use the rust-based betfair_data package. Sadly it barfs on the first line of each of the marketrecorder files that I feed it with the following (example) parse error:

`file: 1.217507712 err: (JSON Parse Error) invalid type: null, expected a borrowed string at line 1 column 25`



Example first line:

```{"op": "mcm", "clk": null, "pt": 1692873297553, "mc": [{"id": "1.217507712", "marketDefinition": {"bspMarket": true, "turnInPlayEnabled": true, "persistenceEnabled": true, "marketBaseRate": 5, "eventId": "32583319", "eventTypeId": "7", "numberOfWinners": 1, "bettingType": "ODDS", "marketType": "WIN", "marketTime": "2023-08-26T12:50:00.000Z", "suspendTime": "2023-08-26T12:50:00.000Z", "bspReconciled": false, "complete": true, "inPlay": false, "crossMatching": false, "runnersVoidable": false, "numberOfActiveRunners": 6, "betDelay": 0, "status": "OPEN", "runners": [{"adjustmentFactor": 46.361, "status": "ACTIVE", "sortPriority": 1, "id": 46821369}, {"adjustmentFactor": 19.97, "status": "ACTIVE", "sortPriority": 2, "id": 36503217}, {"adjustmentFactor": 15.785, "status": "ACTIVE", "sortPriority": 3, "id": 41122645}, {"adjustmentFactor": 8.596, "status": "ACTIVE", "sortPriority": 4, "id": 2507254}, {"adjustmentFactor": 6.617, "status": "ACTIVE", "sortPriority": 5, "id": 122409}, {"adjustmentFactor": 2.673, "status": "ACTIVE", "sortPriority": 6, "id": 26486375}], "regulators": ["MR_INT"], "venue": "York", "countryCode": "GB", "discountAllowed": false, "timezone": "Europe/London", "openDate": "2023-08-26T12:50:00.000Z", "version": 5406653488, "raceType": "Flat", "priceLadderDefinition": {"type": "CLASSIC"}}, "img": true}]}```

Anybody know how to work around this?

---

## 2023-08-31 11:07:57 - issues channel

**river_shah**

The network architecture of BF is not entirely well understood but if you queue too many packets due to your high bandwidth / low latency connection, reasonable chance packet drops occur and strange connection errors will pop up. I could be totally wrong on this, so please verify if indeed your connection matches said description.

---

## 2023-08-31 11:03:11 - issues channel

**river_shah**

George, I am just guessing but likely you are on an extremely high bandwidth, low latency connection into BF. Your last two errors seem to suggest this. I think packets are getting dropped before BF handshakes properly.

---

## 2023-08-30 16:14:51 - issues channel

**foxwood**

thought I'd try chatgpt on this - it didn't seem to know at first so I had to tell it that it was a known term ! However it's answer may help ...



I apologize for the confusion. It seems that "SSLEOFError" is indeed a known term related to SSL errors, though it might not be as commonly referenced as other SSL error types.



SSLEOFError stands for "SSL EOF Error," where "EOF" stands for "End of File." This error occurs when an SSL/TLS connection is unexpectedly terminated before completing the necessary handshake or data exchange. In simpler terms, it indicates that the connection was closed prematurely by one of the parties involved.



Common causes of SSLEOFError include:



1. **Network Issues:** Sudden network interruptions, packet loss, or connectivity problems between the client and the server can lead to an SSL EOF Error.



2. **Server Termination:** The server might have terminated the connection due to its own issues or misconfigurations.



3. **Client Termination:** The client might have intentionally or unintentionally closed the connection before the SSL handshake could complete.



4. **Firewall or Proxy Interference:** Intermediary devices like firewalls or proxies might interfere with the connection and cause premature termination.



5. **Resource Limitations:** The server or client might have encountered resource limitations, leading to a forced connection closure.



6. **Misconfigured SSL/TLS Settings:** Incorrect configurations of SSL/TLS settings on either the client or server side can also lead to this type of error.



7. **Protocol Version Issues:** Mismatched or incompatible SSL/TLS protocol versions can cause connection termination.



To troubleshoot and address an SSLEOFError, you should review server logs, client logs, and network logs to identify the underlying cause. It's also important to ensure that both the client and server are correctly configured to support the same SSL/TLS version and cipher suite. If the issue persists, examining network conditions and potential interference can help diagnose the problem.

---

## 2023-08-30 15:00:13 - issues channel

**George**

Yesterday I had a few "Execution errors" that I have not seen before. I get "SSLEOFError: EOF occurred in violation of protocol". Anyone know what that means?

---

## 2023-08-30 10:06:10 - general channel

**Riccardo Fresi**

my personal issue is interpret the error. it's not really clear (to me of course)

---

## 2023-08-29 19:11:37 - general channel

**AI Trader**

Error:

Hi guys,

Over the past few days I have noticed I have been receivng the error &lt;head&gt;&lt;title&gt;502 Bad Gateway&lt;/title&gt;&lt;/head&gt; when trying to place orders. Did this happen to any of you? Any tips on how to solve?

---

## 2023-08-29 17:29:19 - general channel

**Riccardo Fresi**

Guys,

what's wrong on this function?

```def place_order(size, price, selection_id, trading, market_id, lay="LAY"):

    # placing an order

    limit_order = filters.limit_order(size=size, price=price, persistence_type="LAPSE")

    instruction = filters.place_instruction(

        order_type="LIMIT",

        selection_id=selection_id,

        side=lay,

        limit_order=limit_order,

    )

    place_orders = trading.betting.place_orders(

        market_id=market_id, instructions=[instruction]  # list

    )

    return place_order```

```U.place_order(1, 1.1, 1.217703269, trading, 4940266, lay="BACK")```

```APIError: SportsAPING/v1.0/placeOrders 

Params: {'marketId': '4940266', 'instructions': [{'orderType': 'LIMIT', 'selectionId': '1.217703269', 'side': 'BACK', 'limitOrder': {'price': 1.1, 'persistenceType': 'LAPSE', 'size': 1}}]} 

Exception: None 

Error: {'code': -32602, 'message': 'DSC-0018'} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}```



---

## 2023-08-25 10:53:41 - general channel

**Unknown**

hi guys, need some help



i implemented a kelly method function

```def kelly_method(odds):

    b = odds - 1

    p = 0.94 #0.9851668726823238  # precision value for prediction model or historical win rate

    f = ((odds * p) - 1) / b

    return odds, b, p, f```

i have some doubt: p should be the % winning probability of the bet, i'm not sure to use the precision of model or the ex-post % based on actual historical results



in the first case i have a very bad performance

in the second case, not so bad;



by the way also the function give me negative results if the odds has more implicit probability respect the p variable (it makes sense to you?) so i use a 0.5 fixed for negative value (it also make sense to you?)



Other thing: the one i've loss, i suspect that i collect very bad the live odds for this single event, may i ask you if you can send me the historical data for that since seems in italy we cannot retrieve historical data? of course if is not a problem

---

## 2023-08-23 17:32:16 - random channel

**PeterLe**

Yep he plus version Foxwood

Ive just recoded to include the comments by Leo, results are:

Random Forest Accuracy: 0.9062742305480078

Total Profit/Loss using Simple strategy: £26007.66999999987

Total Profit/Loss using ML strategy for X 1.19: £22294.659999999945

             Feature  Importance

0  last_price_traded    0.116026

1               back    0.093928

2                lay    0.107229

3          back_book    0.206596

4           lay_book    0.203972

5           ltp_book    0.193442

6             Spread    0.075818

7     cross_matching    0.002990

(note: I found an error in my simple strategy :grinning: that why it was such a massive negative in previous text)

What is interesting now is that the ML seems to give a worse result :thinking_face:

---

## 2023-08-17 09:01:16 - random channel

**Mo**

The intention is the results will be equal up to floating point error

---

## 2023-08-17 06:21:12 - issues channel

**Guy Incognito**

Coding error smh

---

## 2023-08-15 16:57:23 - issues channel

**George**

does that mean we might be able to fix this in flumine soon? if so that would be great!

---

## 2023-08-15 14:30:49 - strategies channel

**Unknown**

No you're right, I don't need everything, just in play. I need to fix that going forward...

Its really interesting looking at this data

I was checking something else as per the attached graph...The blue vertical line is the suggested optimal value of a certain variable...the red line is the value I've been using for years..(through trial and error)

Its only a slight change but I'm sure this will increase profits

---

## 2023-08-15 12:11:30 - issues channel

**Neil T (Betfair)**

_for all the connections above in ESA logs we can see only connection being requested, but no authentication and subscription after that. Because of this, connection not having subscription, ESA runs an Idle check , sends error message on the socket and then closes connection.

Can you confirm  that after connection is created an authentication and marketSubscription/orderSubscription/operation are sent?_

---

## 2023-08-15 04:34:11 - issues channel

**Unknown**

It’s more BFLW than flumine (I think?) but I had a bet failure with no more context as to why. Is there any way I can find out what caused the failure?

There are successful orders going on around it. Any ideas where to look? Naturally it was the winning bet that failed. :disappointed:

---

## 2023-08-14 16:45:21 - general channel

**mzaja**

The reason why I even dived into this matter is because I noticed that Flumine was rejecting order placement with

```"strategy.validate_order failed: live_trade_count (1) &gt;= max_live_trade_count (1)"```

when I tried to reuse the Trade to place a closing order. This never happened in the simulation so I investigated further and found out that a percentage of opening bets does not change status to "Execution complete" when the bet is fully matched (and even if it isn't, it should be cancelled). Therefore, it cannot be down to a delay in the logging controls because Flumine's behaviour on a live market confirms it.

---

## 2023-08-14 03:20:49 - general channel

**Unknown**

Hi guys! While debugging the cache mechanism, I found this `'con': True` attribute in the `market_change` on an UPDATE message. In the `update_cache()` function, there is no `'con'` equivalent. What is this `'con'` attribute? and why is Betfair sending it?

---

## 2023-08-13 16:52:19 - random channel

**D C**

There is no error. Just latency buildup. Writing further requests to this component just results in it queuing them until it can send

---

## 2023-08-13 16:51:06 - random channel

**Lee**

if you try more than 6 parallel requests, what error do you get?

---

## 2023-08-13 16:42:36 - random channel

**Lee**

What errors do you get?

---

## 2023-08-13 16:29:44 - random channel

**Lee**

Seems a bit drastic migrating your whole project for a bug. Maybe ask here or bdp for help with that?

Have you tested to see if placing bets 1ms to 10ms apart really has the impact you think it does?

With regards to flumine, strategies are run sequentially for each update so depending on what your strategies are doing it’s unlikely you can loop through all them and execute in under 1ms.



In regards to your questions,

1. Maintains a session

2. They are created when needed and recreated of older than 200 seconds

3. Yes

Most of that logic is [https://github.com/betcode-org/flumine/blob/master/flumine/execution/baseexecution.py|here](https://github.com/betcode-org/flumine/blob/master/flumine/execution/baseexecution.py|here) 

---

## 2023-08-12 22:21:06 - issues channel

**George**

Similar to the above - I've received an error with the message "MarketStream 2001 run error" - and further down it says "SocketError Connect 2002: Connection closed by server".



Does that mean I have to kill the flumine process and start again? Or is it all good?

---

## 2023-08-12 01:58:52 - issues channel

**Andy**

[@UCQB6S222](@UCQB6S222) I used to get this error sporadically when I had a max market limit on the stream of 200 (default). Once they increased it to 1000 for me the issue went away. Another thing to try

---

## 2023-08-11 21:33:22 - issues channel

**George**

sometimes when I start a Flumine process, I get an error message saying "[MarketStream: None] TIMEOUT: Connection is not subscribed and is idle: 1500ms".

sometimes it's OrderStream instead of MarketStream.

i don't get it every time.



is this a problem at my end? how can i prevent this from happening?

---

## 2023-08-10 21:20:50 - general channel

**AndyL**

the market was also Suspended at 20:05:11 and triggered an error for me:

```Order has violated: MARKET_VALIDATION Error: Market is not open```

---

## 2023-08-08 14:03:29 - strategies channel

**Joe**

[@UUE6E1LA1](@UUE6E1LA1) I don't have any papers I'd recommend.

If you are doing NN classification with back propagation then you are just using the chain rule of derivatives to calculate the changes to the network weights to minimise total network error, the derivatives being those of the activation functions in your nodes and the learning rate basically how far down the slope you want to step. Typically you would choose the activation functions only.

If you are doing decision trees (boosted and/or ensemble / RF) then you splitting based on the most effective split point in the most effective dimension, usually assuming a linear gradient wrt that dimension.

If you are doing metaheuristic search then these are usually based on a pseudo biological explanation, like genetic crossing and mutation in populations, or the swarming nature of insects around some energy source, but all really boil down to guided brute force, these algos don't bear any resemblance to anything mathematical in the underlying system being optimised.



I think the problem you are having getting started is that every single non-paper based method of optimising anything has fallen under the umbrella term of ML, mainly because it enables the fading coding/developer tech industry to pivot to a post-coding 'data science' industry, this makes is really difficult to discuss in general terms.



If I was getting started today I would start with simple NN classifier, read up on it and code a network solver.

If you wanted to look at something more unsupervised then someone has decided to name a fairly general method 'Q-Learning', look this up.

---

## 2023-08-08 03:16:01 - issues channel

**Grant Allison-Young**

Hi there, last night I created my certificates and created a not-interactive function to login to Betfair.  All good :  {"sessionToken":"ZZZZZZZ=","loginStatus":"SUCCESS"}.  Today when I woke up and ran it again,without any changes I got  “The remote server returned an error: (500) Internal Server Error.”



I have no Idea what to check.  I ran the same process through Postman and it worked fine.  What end point should I be targeting?  When I did it last night i used  ("[https://identitysso-api.betfair.com/api/certlogin](https://identitysso-api.betfair.com/api/certlogin)") but the Postman version used  [https://identitysso-cert.betfair.com/api/certlogin](https://identitysso-cert.betfair.com/api/certlogin) - I get the same response with both....

---

## 2023-08-07 09:58:47 - strategies channel

**Joe**

Without knowing how long it takes you to run a back test with a set of parameters it is difficult to advise. But say you can already do this reasonably quickly then simply wrapping your existing back tester in a simple parameter walk (fix N-1 params vary 1 until optimal, then vary the next one) using newtons method might help.

---

## 2023-08-04 13:42:14 - general channel

**D C**

Thanks for this explanation chaps this has confused me for ages. Ages ago I wrote a half-arsed price grid market replay display application that allowed manual step through each delta and a toggle for virtual/actual odds. Many times saw worse virtual prices but always assumed it was a coding error on my part.

---

## 2023-08-04 09:27:21 - issues channel

**Mo**

Did you fix it or you used verify=False?

---

## 2023-08-04 01:50:57 - issues channel

**Guy Incognito**

Hi guys, looking at my log file I see this:



```2023-08-04 09:18:40:ERROR:53:OrderStream 1001 run error

Traceback (most recent call last):

  File "/usr/local/lib/python3.10/site-packages/flumine/streams/orderstream.py", line 51, in run

    self._stream.start()

  File "/usr/local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py", line 67, in start

    self._read_loop()

  File "/usr/local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

  File "/usr/local/lib/python3.10/site-packages/betfairlightweight/streaming/betfairstream.py", line 256, in _receive_all

    raise SocketError(

betfairlightweight.exceptions.SocketError: [Connect: 1002]: Connection closed by server

2023-08-04 09:18:42:INFO:21:Starting OrderStream 1001

2023-08-04 09:18:42:INFO:23:[Register: 1002]: orderSubscription

2023-08-04 09:18:42:WARNING:25:[Listener: 1002]: stream already registered, replacing data

2023-08-04 09:18:42:INFO:115:[OrderStream: 1002]: "OrderStream" created 

```

Does anyone know what this means? My guess is that my connection gets closed but the flumine opens a new one afterwards?

---

## 2023-08-03 15:55:49 - general channel

**D C**

FWIW if I run anything new I manually monitor it by running it locally on my machine for as low stakes as I can get away with verbose console logging enabled and fingers on CRTL and C at the ready. I don't use flumine but have similar exposure limits which I know will prevent me getting a total burnout but things still can go to s*it. I'd never run something totally "new" without being there at the first run.



Maybe I am paranoid but tearning through a bankroll just once in life due to one's own coding errors changes a man.

---

## 2023-08-03 15:38:57 - general channel

**liam**

So why is speed an issue? Just use a worker to disable the strategy when balance &lt; x however just fix the issue 

---

## 2023-08-03 09:42:36 - issues channel

**liam**

Fixed in 2.4.2

---

## 2023-08-03 03:06:54 - general channel

**Unknown**

Hi [@U4H19D1D2](@U4H19D1D2), Thanks for the advice! I made the git clone. But the problem persisted. After a while, I realized that the betfairlightweight library had been installed and imported from there.

This behavior didn't let me debug the things happening inside the library, just limited to the file where I was running the example.

To solve this, I put the libraries as in the image, added the _`__init__`_ necessary files, changed the route for importing, and voila! It worked! and now I can debug throughout both libraries! :raised_hands::tada:

---

## 2023-08-02 23:56:10 - general channel

**Rishab**

Im using the MarketRecorder file available online to record data. The cell with framework.run() keeps on running until I kill the process. I believe its because it keeps on saving a timeseries data(I desire the same). If i kill the cell instatly after running, I'm able to load the JSON that was saved from the process (But it just has the data for one timestamp, cuz I didn't see data for any runner twice). However, if I keep on running the cell for a long time &amp; then kill it manually I see an error when loading the json - JSONDecodeError: Extra data: line 2 column 1 (char 16137)

---

## 2023-08-02 13:44:54 - issues channel

**Mo**

It sounds pretty obvious from the error message that the problem is there's a self signed certificate in the certificate chain. The question is what certificate is it? I wonder if he's accidentally added his personal certificate to the store

---

## 2023-08-02 13:43:33 - issues channel

**Mo**

```results = trading.betting.list_event_types()

print(results)



    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listEventTypes

Params: {'filter': {}}

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/betting/json-rpc/v1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1002)')))```

Well there appears to be some certificate somewhere in his certificate store that _is_ getting used on these requests

---

## 2023-08-02 13:13:48 - issues channel

**foxwood**

Running it live today and will let you know if it works . Another issue that I've not looked at with this is that bets are voided - wondering what happens to orders in blotter for both simulation and live ? Market info for dogs : _If a non-runner or reserve runner is declared all bets with the exception of Betfair SP bets on unaffected traps, placed on the race prior to the update of the market on Betfair will be void._ I've been ignoring all this in the past and just accepting the swings and roundabouts this causes but having to look at it now matching to external data.

---

## 2023-08-02 10:28:21 - betconnect channel

**Riccardo Fresi**

Hi,

i nees assistance on connet, since here everything is ok

```session = requests.session()

trading = betfairlightweight.APIClient(

  'xxxxxxx', 

  'xxxxx', 

  app_key='xxxxxxs', 

  certs='C:/xxxxxxx/certs',

  locale='italy',

  session=session)```

then

```login = trading.login()

print(login.login_status)



&gt;&gt;&gt;SUCCESS```

later

```results = trading.betting.list_event_types()

print(results)



    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listEventTypes

Params: {'filter': {}}

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/betting/json-rpc/v1 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1002)')))```

what's wrong? should use endpoint '.it' but i see '.com'

or the problem is something else?

---

## 2023-08-01 22:12:33 - issues channel

**foxwood**

done - suggested dirty fix

---

## 2023-08-01 19:40:24 - issues channel

**liam**

Ah good spot, can you create a github issue and I can see if we can fix 

---

## 2023-08-01 19:35:18 - issues channel

**foxwood**

Market objects have a `__call()` method which flags a catalogue update needed when the `market_book.version` changes. That changes a few times when the reserve substitution takes place. Debugging the market recorder the `market_book` field for every event is set to `None` - is this the gotcha - no book when recording ?

---

## 2023-08-01 17:48:13 - issues channel

**foxwood**

Just did a quick mod of `BFLWexampleone.py` to dump current live GH catalogues - lots of runner in latest catalogues today with `"(res)"` suffix where reserve taking place of original dog. Therefore issue when recording doesn't appear to be a BF issue.

---

## 2023-08-01 10:01:48 - issues channel

**foxwood**

I'm guessing it's something like that having slept on it - pretty sure the latest should work - BF manage to get the name plus "Res" suffix into their price data. Just used the flumine market recorder out of the box I think but will have a look and see if I managed to break it ! Assume this is not normal otherwise others would have fallen over it before ?

---

## 2023-07-31 20:27:14 - issues channel

**AP**

Has anyone ever come across this error?

```Unknown error 'LimitOnCloseOrder' object has no attribute 'price_ladder_definition' in process_market_book```

---

## 2023-07-30 14:08:35 - general channel

**Unknown**

Just noticed a few errors on my stuff...

---

## 2023-07-27 07:58:56 - issues channel

**Nacho Uve**

My Betfair account is in Spain. I was running Flumine on a server that I would like to cancel. I was completing the migration to an EC2 instance (region Paris), but when trying to connect from the server, it throws an error:

&gt; betfairlightweight.exceptions.LoginError: API login: BETTING_RESTRICTED_LOCATION

In Europe, EC2 offers regions: London, Dublin, Stockholm, Paris, or Frankfurt, none of which are in Spain.



Do you think any of these will work, or is there a way to operate from AWS with a Spanish account?

---

## 2023-07-26 10:21:25 - issues channel

**Harry Corrigan**

flumine shows no errors beforehand

---

## 2023-07-26 10:17:29 - issues channel

**Harry Corrigan**

Hi, i'm having an issue placing basic trades from within a strategy using flumine

on proccess_market_book being called i attempt to place an order but when i run market.place_order i get a runtime error raised by `self._thread_pool.submit(func, order_package, http_session)`  the error says cannot schedule new futures after interpreter shutdown, i have a custom stream to pipe data into the strategy which may be causing it? wondering if anyone has seen this error before and if so how did you fix it

---

## 2023-07-25 02:06:01 - general channel

**Felix Vasquez**

Hi [@U4H19D1D2](@U4H19D1D2)!, Thanks for your response!

The reason for this change is that I'm in a discovery process, studying all files and what is doing every function, imported library, decorators, and so on. I'm new in programming, python, betting, trading, and all this world. Basically, I am learning Python through betfairligthweigth library and further in my path with Flumine, to finally built some strategies there.

I was running it from the debug window in VSCode, I modified the `examplestreaming.py` file by adding calls to different endpoints, playing around with the response, and analyzing the data provided by de API. And all this worked fine, but I was surprised when saw the mentioned behavior.

What you say has total sense to me, and maybe the problem is that `examplestreaming.py` is importing the library and isn't using the code I download to my PC. I will change it to a relative import and see if this solves the problem.

Finally, you ask me why am I running from terminal?, is there any other way to run it?

Any advice to facilitate the learning process will be appreciated.

Cheers

---

## 2023-07-24 11:43:05 - general channel

**Peter**

I recommend using an IDE with a debugger. [@UBS7QANF3](@UBS7QANF3) recommends PyCharm. I use Visual Studio Code. Both allow you to set a breakpoint (e.g. at the start of `process_market` or `process_orders` ) and then examine all the data that's available to you at that point. It can be a real eye opener.

---

## 2023-07-24 10:00:20 - issues channel

**foxwood**

Amazing lol. And to know of such a system field when the explanation of its use is for when an unhandled exception occurs :joy: `sys.last_type sys.last_value sys.last_traceback These three variables are not always defined; they are set when an exception is not handled and the interpreter prints an error message and a stack traceback.`

Edit: Never heard of it either and had to look it up

---

## 2023-07-24 09:10:58 - issues channel

**Mo**

They're just clueless - sounds like they don't know about exception handling so rather than using try/except they are looking at sys.last_value which I have never heard of before?!

---

## 2023-07-24 09:01:31 - issues channel

**liam**

Probably, just find it amazing that someone can go to the effort of writing all of that but not fix there shitty code

---

## 2023-07-24 08:50:03 - issues channel

**Mo**

I think a simple response along the lines of:



&gt; If you are unable or unwilling to implement robust error handling in your code I suggest you look at flumine which is a fully featured trading framework sitting atop betfairlightweight

would go a long way

---

## 2023-07-21 13:02:49 - issues channel

**foxwood**

I had wrapped it in a try call cos broke on back odds at some point. The exception was handled by just calling shin for the lay odds and no exception from that was allowed for lol. Will change my code to cope with the error.

---

## 2023-07-21 12:55:48 - issues channel

**Mo**

The package could definitely do with some better error handling

---

## 2023-07-21 12:54:52 - issues channel

**foxwood**

I think it was a BF issue at the time - the actual race had 6 dogs  and none were reserves. Only 3 were marked as ACTIVE in market_book.runners and 3 as REMOVED. Just a weird combo that crashes with exception though.

---

## 2023-07-21 12:44:23 - issues channel

**foxwood**

Sorry, seem to have managed to break the shin() implementation [@UBS7QANF3](@UBS7QANF3) This was a backtest on a race with only 3 active runners. Occurred on only a couple of races in many thousands. Digging around, came up with the code below that crashes in console. Running latest v0.0.2 under Python 3.9. Think the maths is above my pay grade lol.



```import shin

odds = [2.08, 2.12, 3]	# back odds - works ok

shinDict = shin.calculate_implied_probabilities(odds)

print(shinDict)

odds = [5, 10, 20]	# lay odds - OverflowError (34, 'Result too large')

shinDict = shin.calculate_implied_probabilities(odds)

print(shinDict)```

---

## 2023-07-21 10:07:10 - general channel

**Mo**

Also suggest you run the code in a debugger using and IDE such as PyCharm. That will make it easy to inspect objects

---

## 2023-07-20 13:08:24 - issues channel

**liam**

Race stream ‘unexpected error’ issues today or is it just me? 

---

## 2023-07-18 07:31:05 - issues channel

**Nacho Uve**

Here It is a simple dummy strategy to visualize the problem.

It use an example market  where this happens:

```import sys

import logging



from flumine import BaseStrategy



from flumine.order.trade import Trade

from flumine.order.order import OrderStatus

from flumine.order.ordertype import LimitOrder







MARKET_ID = "1.214780186"

SELECTION_ID = 676464



class Back_Dummy_Strategy(BaseStrategy):



    def check_market_book(self, market, market_book):

        if market.market_id != MARKET_ID:

            return False

        return market_book.inplay





    def process_market_book(self, market, market_book):



        if market_book.status == "SUSPENDED":

            import time

            print("SUSPENDED")

            try:

                import ipdb

                ipdb.set_trace()

            except Exception as e:

                print(e)



        if len(market.blotter):

            for oo in market.blotter:

                if oo.status == OrderStatus.EXECUTABLE:

                    print("Already one order... ")

                    self.available_to_back(market_book)

        else:

            trade = Trade(

                market_id=market.market_id,

                selection_id=SELECTION_ID,

                handicap=0,

                strategy=self

            )

            order = trade.create_order(

                side="BACK",

                order_type=LimitOrder(price=1.11, size=2),

                notes={1:f"My first dummy order"}

            )

            market.place_order(order)





    def available_to_back(self, market_book):

        print("== market_book available to back ==")

        print(f"Time: {market_book.publish_time}")

        for rr in market_book.runners:

            atb = rr.ex.available_to_back

            print(rr.selection_id, atb)

        print("==================================")



    def process_orders(self, market, orders):



        super().process_orders(market, orders)



        for i, oo in enumerate(orders):

            try:

                print("********** Orders *************")

                print(f"****  {i+1}/{len(orders)}")

                print(oo.status)

                print(f"@{oo.order_type.price} {oo.order_type.size}$")

                print(f"Matched: {oo.size_matched}$")

                print("*******************************")



            except Exception as e:

                print(e)```

Could I share the recorded stream file of example? or is there any restriction?

---

## 2023-07-18 07:12:42 - issues channel

**Nacho Uve**

Hi,



I'm stuck with a problem that I've encountered before when simulating football strategies.

Here are the steps:

1. I place an order at a price slightly higher than the current market price.

2. The order is marked as "EXECUTABLE," but

3. When the market reaches that price or a higher price, the bet remains unmatched (even though there is enough size available).

I've tried to check the simulation code in flumine to see what might be happening, but I can't find the source of the error. I suspect that for some reason, the order is no longer being evaluated during market_books stream updates. Am I understanding this correctly, or am I doing something wrong?



I have a recorded stream file and a simple strategy example that I can share if it would be helpful to review.



Thanks in advance!

---

## 2023-07-14 12:39:38 - issues channel

**Andy**

They are asking though if you have any idea why I didn't get *SUBSCRIPTION_LIMIT_EXCEEDED* message. Looking at their messages, is it just they have logging on for this? In their test, they get *SUBSCRIPTION_LIMIT_EXCEEDED* then they get Encountered an error (connection_id: 106-080723010256-1216805, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"101-080723010255-1157348"}) when starting or running the stream afterwards, same as me

---

## 2023-07-14 11:49:21 - issues channel

**Andy**

Now this :



Do they mean by this comment that flumine can only handle 1k markets or they don’t want to increase above 1k…?



Hi Andy,

 

We’re not experts with using Flumine, but I managed to recreate the error message using the same filters.

 

It triggered the SUBSCRIPTION_LIMIT_EXCEEDED, then the TIMEOUT error that you received.

 

We can’t increase the market limit again as appears you’ll need to adjust your strategy to filter the number of markets to below 1000 and see if that works.

 

You could see if Liam (betcode) has any suggestions on why you’re not seeing the SUBSCRIPTION_LIMIT_EXCEEDED?

 

 

Filters

 

strategy = ExampleStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["7","4339"],

        #country_codes=["GB"],

        market_types=["WIN","PLACE"],

    ),

 

 

Error Log

 

2023-07-14 16:32:54,606:ERROR:[MarketStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 1258 markets whereas max allowed number was: 1000

2023-07-14 16:32:54,607:INFO:[MarketStream: 2001]: FAILURE (4 connections available)

2023-07-14 16:33:03,126:INFO:Client update account details

2023-07-14 16:33:10,123:ERROR:[MarketStream: None]: TIMEOUT: Connection is not subscribed and is idle: 15000 ms

2023-07-14 16:33:10,124:ERROR:MarketStream 2001 run error

Traceback (most recent call last):

  File "c:\Users\DouglasB\GitHub\How-to-Automate-Public-Version\.venv\lib\site-packages\flumine\streams\marketstream.py", line 44, in run

    self._stream.start()

  File "c:\Users\DouglasB\GitHub\How-to-Automate-Public-Version\.venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "c:\Users\DouglasB\GitHub\How-to-Automate-Public-Version\.venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 233, in _read_loop

    self._data(received_data)

  File "c:\Users\DouglasB\GitHub\How-to-Automate-Public-Version\.venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 274, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 209-140723063254-1955531, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"209-140723063254-1955531"}

---

## 2023-07-14 00:46:48 - issues channel

**Andy**

[@U4H19D1D2](@U4H19D1D2)  the problem came back overnight…



I was previously getting this error 100% of the time within a minute when I tried to get all horses and dogs win and place for AU racing.



• After my live key was pumped up to 1k markets, the problem seemingly went away instantly and stayed away for ~14 hours. 

• Last night it came back. There were a lot of horse racing markets on site at the time (more than I’d probably ever received before). All of Fridays thoroughbred and trots meetings (15 meetings) and 5 of Saturdays thoroughbred already. But no greyhound racing at all as they hadn’t been loaded yet for the next day. This is the part that perplexes me. 

• I think it’s clear that whatever was done to pimp my API key the previous day had some desirable effect but in saying that, I wasn’t near 1k markets when the crash happened….



Now betfair have come back with the following:





Hi Andy,



I checked with the UK API team and got the response below overnight. Sounds like the issue is related to the socket handling outlined in this GitHub issue thread - [https://github.com/betcode-org/betfair/issues/11|https://github.com/betcode-org/betfair/issues/11](https://github.com/betcode-org/betfair/issues/11|https://github.com/betcode-org/betfair/issues/11)



If you could check those settings and see if it resolves the issue.



UK Response



A TIMEOUT error on a subscription request has a clear root cause – this is indicated by the error description and in our docs (":"Connection isnot subscribed and is idle: 15000 ms)  (see [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-TCP/SSLConnection|https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-TCP/SSLConnection](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-TCP/SSLConnection|https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-TCP/SSLConnection))



Avoiding TIMEOUT on connection

Once you have established a connection you should send a message within 15 seconds to avoid receiving a TIMEOUT error



Strange that he would receive this error in any other circumstances though, so yes, it could be related to socket handling as mentioned in that github issue thread.

---

## 2023-07-13 12:02:47 - general channel

**liam**

No, fix your subscription 

---

## 2023-07-12 20:47:01 - issues channel

**Andrey Luiz Malheiros**

After much effort and debugging, I discovered that a function of mine that I applied in the `processed_closed_market` was in an infinite loop, and that was causing significant delays.

---

## 2023-07-12 16:52:55 - issues channel

**Andrey Luiz Malheiros**

I seem to be having some latency issues. It was working fine until yesterday, but today it started consistently showing the following errors. Even if I terminate the execution of Flumine and start it again, the errors persist. I'll send the logs I'm receiving. These errors persist, and no orders are being placed, and the strategies are not being executed. Does anyone know how to resolve this or at least attempt to remedy it?

```[2023-07-12 14:20:07,894: INFO/ForkPoolWorker-2] Client update account details

[2023-07-12 14:21:07,795: INFO/ForkPoolWorker-2] Updated marketCatalogue for 1.215993597

[2023-07-12 14:21:18,819: INFO/ForkPoolWorker-2] Market 1.215993597 closed

[2023-07-12 14:21:42,401: WARNING/ForkPoolWorker-2] [MarketStream: 2001]: Latency high: 0.5233955383300781

[2023-07-12 14:53:35,502: WARNING/ForkPoolWorker-2] [MarketStream: 2001]: Latency high: 1505.3750047683716

[2023-07-12 15:30:03,086: WARNING/ForkPoolWorker-2] [MarketStream: 2001]: Latency high: 4085.18798494339```

---

## 2023-07-12 08:21:28 - issues channel

**liam**

Thats weird as you should get a subscription limit error rather than timeout

---

## 2023-07-12 03:19:06 - issues channel

**Unknown**

:wave: Hello, team!   I am trying to get a API key but i get an error.  Any idea what I can do to fix this?

---

## 2023-07-12 02:34:30 - issues channel

**Andy**

Betfair response:



Hi Andy,



Thanks for sending through the details of the error messages you’re getting. It looks like you’re hitting the market limit on your live key.



We’ll forward this to our API team in the UK and get them to increase the market limit. That should happen overnight tonight and we’ll confirm tomorrow.

---

## 2023-07-11 20:22:10 - issues channel

**R**

Is there a way I can format order prices that I get from the SP near price (during simulation) so that I don't get the error:



`Order price is not valid for CLASSIC ladder`



I've dug around quickly in the codebase but nothing popped out to me that there was some handler to "squash" prices into the correct bracket of the ladder

---

## 2023-07-11 18:10:39 - general channel

**George**

the error occurs because `strategy.process_market_book` requires access to the runner names which should be in `market.market_catalogue`

but `market.market_catalogue` is `None` even though the `poll_market_catalogue` worker is active

---

## 2023-07-11 18:08:45 - general channel

**George**

```22 def run():

23   start_time_seconds = 43000

 24   stop_time_seconds = 1800

 25   setup_logger(logging.DEBUG)

 26   trading = login_with_bflw()

 27   client = clients.BetfairClient(trading)

 28   framework = Flumine(client=client)

 29   strategy = get_strategy(start_time_seconds, stop_time_seconds)

 30   pred_worker = get_prediction_worker(framework, start_time_seconds)

 31   logging_control = MarketOrderControl()

 32   framework.add_strategy(strategy)

 33   framework.add_worker(pred_worker)

 34   framework.add_logging_control(logging_control)

 35   with patch.object(config, 'raise_errors', True):

 36     framework.run()

 37   return framework```

---

## 2023-07-11 18:03:12 - general channel

**George**

I get loads of these but it's not an error:

{"asctime": "2023-07-11 16:32:58,689", "levelname": "DEBUG", "message": "BackgroundWork er poll_market_catalogue executing", "worker_name": "poll_market_catalogue", "function" : "&lt;function poll_market_catalogue at 0x103c73820&gt;", "context": {}}

---

## 2023-07-11 18:02:19 - general channel

**George**

the error in the logs  is an error coming from me trying to access the market_catalogue when it's None

---

## 2023-07-11 18:01:29 - general channel

**liam**

So no logs? Error logs? Or you haven’t set up logging as per examples? 

---

## 2023-07-11 17:45:53 - general channel

**George**

apologies [@U4H19D1D2](@U4H19D1D2) but after several hours of debugging I still cannot understand why `market.market_catalogue` is None. the `poll_market_catalogue` worker is active and I can see that it is doing its job.

but, flumine's `_process_market_catalogues` never seems to get called. do you know why could this be happening?

---

## 2023-07-11 03:23:44 - issues channel

**Andy**

• Wanting to get WIN and PLC markets for horse and greyhounds but currently it's impossible.

Ideally would have one filters.streaming_market_filter with event_type_ids=["7","4339"] and market_types=["WIN","PLACE"]



• Scenario 1) Using 1 streaming_market_filter with both of the above settings shows the following error multiple times and returns nothing:

Encountered an error (connection_id: 208-110723015800-1550840, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is

not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"208-110723015800-1550840"}) when starting or running the stream.



• Scenario 2) Using 1 streaming_market_filter with both of the above settings works for market_types=[WIN] only.

• *Scenario 3) Using 1 filter - event_type_ids=["7"] and market_types=["WIN", "PLACE"] works?? (only scenario with multiple parameters set where any place markets are received)*

• Scenario 4) Using 1 filter - event_type_ids=["4339"] and market_types=["WIN", "PLACE"] *does not work*. Same error as trying event_type_ids=["7","4339"] and market_types=["WIN","PLACE"]

Encountered an error (connection_id: 210-110723020837-1593171, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"210-110723020837-1593171"}) when starting or running the stream.



• Scenario 5) trying two streaming_market_filters (one with event_type_ids=["7"] and another one with event_type_ids=["4339"]) and market_types=["WIN","PLACE"] for both does not work, throws error:

Encountered an error (connection_id: 203-110723021056-1561190, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"203-110723021056-1561190"}) when starting or running the stream.



• *Scenario 6) trying two streaming_market_filters (one with event_type_ids=["7"] and another one with event_type_ids=["4339"]) and market_types=["WIN"] also works..*

• Scenario 7) Subscribing with 4 different streaming filters shows this error twice:

Encountered an error (connection_id: 210-110723013905-1590774, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is

not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"210-110723013905-1590774"}) when starting or running the stream.

Very ocassionally get this issue:

Encountered an error ([Connect: 5]: Socket [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:2546)) when starting or running the stream



Using Live API key which I'm told has 10 max connections by default

---

## 2023-07-08 16:09:09 - general channel

**Alex**

I'm looking at a historic data file where total matched declines from one step to another. Is this just a data error or do I fundamentally misunderstand the concept of total matched. I assumed it was just CUMSUM(volume) in the market (double counted), i.e. dividing it by 2 and diffing it gives you an idea of volume traded

---

## 2023-07-08 14:03:00 - issues channel

**Andy**

# Create filters to get the events

    horse_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["PLACE", "WIN"]

    )

    greyhound_market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["4339"],

        country_codes=["AU"],

        market_types=[“WIN"]

    )





Encountered an error (connection_id: 106-080723010256-1216805, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"101-080723010255-1157348"}) when starting or running the stream.





Getting this error when have tried to add both Win and Place to the market types filter. It works for Win and Place individually but won’t work with both for some reason? I have seen other peoples code having multiple market filters though?

---

## 2023-07-07 06:08:02 - general channel

**Mo**

I believe the error is related to how frequently you are connecting to the database so if you have reduced that frequency then that is a workaround



Another workaround I was going to suggest would be to use the IP address of the database server, assuming it is fixed, to avoid having to resolve the name



In my case, although I recall I had to mess around with the default name resolver setup in Ubuntu, that doesn't seem to be reflected in my current configuration so I assume it was fixed at some point. I am running 22.04. Upgrading should be a permanent solution

---

## 2023-07-06 23:53:21 - general channel

**Michael**

I think this was genuinely a error in the code, it never wrote in some tests either. I still connect to the database, but call during process_closed_markets now which works with no issue. I may well run into it in future if it is a issue you’ve had so if you could share how you solved it that’d be great, you said you’d take a look at how you solved it but never came back. My linux version is Ubuntu 20.04

---

## 2023-07-06 10:05:19 - issues channel

**John Foley**

the historical data has a 5 day delay, so never been a big deal if I miss a day or two because of connection errors 

---

## 2023-07-06 10:01:38 - issues channel

**John Foley**

yeah i am doing this (systematically collecting the data every day) and there’s no avoiding the random errors, just have to handle the retries in your code. For me, the program runs daily and if it keeps failing, after x number of failures just give up and try again tomorrow. 

---

## 2023-07-06 07:15:29 - general channel

**Mo**

If it was a system wide connection issue then you would have had problems with your connection to Betfair as well



I had exactly this problem in the past - ie a temporary failure in name resolution when connecting to a database - where the fact it was a connection issue stretched credibility. It was in fact a problem with the name resolver itself



It sounds like you’ve “fixed” it by no longer connecting to the database which doesn’t sound like a fix at all?



What version of Ubuntu are you running?

---

## 2023-07-05 22:02:59 - general channel

**Michael**

I was writing metadata to a mysql database, it was getting stuck connecting. Once I reverted changes and fixed it then I get this no more

---

## 2023-07-04 09:40:07 - issues channel

**Johnny**

Potentially a very basic question here.  I'm trying out the example marketrecorder.py and have changed only my login details and local_dir - it starts up and finds all the markets, and creates an empty folder with a UUID, but then all the workers stop.  The strategy continues to run though with no data being supplied.  Does anyone have what else I need to do to get the standard recorder working?



```{"asctime": "2023-07-04 08:31:24,036", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215758531 added, 53 markets in cache"}

{"asctime": "2023-07-04 08:31:24,036", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215758545 added, 54 markets in cache"}

{"asctime": "2023-07-04 08:31:24,037", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215758486 added, 55 markets in cache"}

{"asctime": "2023-07-04 08:31:24,037", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215758498 added, 56 markets in cache"}

{"asctime": "2023-07-04 08:31:24,038", "levelname": "INFO", "message": "[MarketStream: 2001] 1.215727888 added, 57 markets in cache"}

{"asctime": "2023-07-04 08:31:24,039", "levelname": "INFO", "message": "[FlumineStream: 2001]: 57 mc added"}

{"asctime": "2023-07-04 08:31:24,039", "levelname": "INFO", "message": "Adding: 1.215727854 to markets", "client": {"id": "61ef3ddb", "exchange": "Betfair", "betting_client": "APIClient", "chargeable_transaction_count": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxOrderCount object at 0x7f014c174310&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}, "markets": {"market_count": 0, "open_market_count": 0, "live_orders": false, "markets": []}, "streams": ["&lt;OrderStream(OrderStream, started daemon 139643035035200)&gt;", "&lt;DataStream(DataStream, started daemon 139643026642496)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 139643610474304)&gt;", "&lt;Thread(Thread-2, started daemon 139643479651904)&gt;", "&lt;Heartbeat(Thread-3, started daemon 139643471259200)&gt;", "&lt;HistorySavingThread(IPythonHistorySavingThread, started 139643446081088)&gt;", "&lt;ParentPollerUnix(Thread-1, started daemon 139643437688384)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 139643076998720)&gt;", "&lt;BackgroundWorker(poll_account_balance, started daemon 139643068606016)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 139643060213312)&gt;", "&lt;BackgroundWorker(poll_cleared_orders, started daemon 139643051820608)&gt;", "&lt;Thread(TEST_load_processor, started daemon 139643043427904)&gt;", "&lt;OrderStream(OrderStream, started daemon 139643035035200)&gt;", "&lt;DataStream(DataStream, started daemon 139643026642496)&gt;", "&lt;Thread(OrderStream_output_thread, started daemon 139642540127808)&gt;"]}

{"asctime": "2023-07-04 08:31:24,042", "levelname": "INFO", "message": "Stopped DataStream 2001"}

{"asctime": "2023-07-04 08:31:24,042", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

{"asctime": "2023-07-04 08:31:24,042", "levelname": "INFO", "message": "Stopped OrderStream 1001"}

{"asctime": "2023-07-04 08:31:24,044", "levelname": "INFO", "message": "Shutting down Execution (BetfairExecution)"}

{"asctime": "2023-07-04 08:31:24,045", "levelname": "INFO", "message": "BackgroundWorker keep_alive shutting down", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x7f0144ce3670&gt;"}

{"asctime": "2023-07-04 08:31:24,235", "levelname": "INFO", "message": "Stopped output_thread (OrderStream 1001)"}

{"asctime": "2023-07-04 08:31:28,046", "levelname": "INFO", "message": "BackgroundWorker poll_account_balance shutting down", "worker_name": "poll_account_balance", "function": "&lt;function poll_account_balance at 0x7f0144ce3940&gt;"}

{"asctime": "2023-07-04 08:31:32,047", "levelname": "INFO", "message": "BackgroundWorker poll_market_catalogue shutting down", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x7f0144ce38b0&gt;"}

{"asctime": "2023-07-04 08:31:36,049", "levelname": "INFO", "message": "BackgroundWorker poll_cleared_orders shutting down", "worker_name": "poll_cleared_orders", "function": "&lt;function poll_cleared_orders at 0x7f0144ce39d0&gt;"}

{"asctime": "2023-07-04 08:31:40,172", "levelname": "INFO", "message": "Exiting flumine", "client": {"id": "61ef3ddb", "exchange": "Betfair", "betting_client": "APIClient", "chargeable_transaction_count": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxOrderCount object at 0x7f014c174310&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}, "markets": {"market_count": 1, "open_market_count": 1, "live_orders": false, "markets": ["1.215727854"]}, "streams": ["&lt;OrderStream(OrderStream, stopped daemon 139643035035200)&gt;", "&lt;DataStream(DataStream, stopped daemon 139643026642496)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 139643610474304)&gt;", "&lt;Thread(Thread-2, started daemon 139643479651904)&gt;", "&lt;Heartbeat(Thread-3, started daemon 139643471259200)&gt;", "&lt;HistorySavingThread(IPythonHistorySavingThread, started 139643446081088)&gt;", "&lt;ParentPollerUnix(Thread-1, started daemon 139643437688384)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 139643076998720)&gt;", "&lt;BackgroundWorker(poll_account_balance, started daemon 139643068606016)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 139643060213312)&gt;", "&lt;BackgroundWorker(poll_cleared_orders, started daemon 139643051820608)&gt;", "&lt;Thread(TEST_load_processor, started daemon 139643043427904)&gt;"]}

---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-2-ce727f3ddda0&gt; in &lt;module&gt;

     20 framework.add_strategy(strategy)

     21 

---&gt; 22 framework.run()



~/anaconda3/lib/python3.8/site-packages/flumine/flumine.py in run(self)

     27 

     28                 elif event.EVENT_TYPE == EventType.RAW_DATA:

---&gt; 29                     self._process_raw_data(event)

     30 

     31                 elif event.EVENT_TYPE == EventType.CURRENT_ORDERS:



~/anaconda3/lib/python3.8/site-packages/flumine/baseflumine.py in _process_raw_data(self, event)

    211             for strategy in self.strategies:

    212                 if stream_id in strategy.stream_ids:

--&gt; 213                     strategy.process_raw_data(publish_time, datum)

    214 

    215     def _process_market_catalogues(self, event: events.MarketCatalogueEvent) -&gt; None:



TypeError: process_raw_data() missing 1 required positional argument: 'data'```



---

## 2023-07-03 16:23:21 - issues channel

**Andrey Luiz Malheiros**

The worst part is that I've been retrying for a while. It seems like it keeps indefinitely responding with an error, so I think the solution is to wait and hope for it to come back

---

## 2023-07-03 16:10:38 - issues channel

**Andrey Luiz Malheiros**

I'm having issues with the Betfair Historical API. Sometimes I receive the ngErrorRedirect error, and other times I get the correct response for the exact same API request. Does anyone know how to resolve this?

---

## 2023-07-01 19:00:37 - general channel

**Michael**

It was a couple of weeks ago, I reverted the changes so let me re-run and cause the error again. Its definitenly to do with writing to the database however as removing it fixed it

---

## 2023-07-01 17:44:12 - general channel

**liam**

Any context to this error / got the full stack trace?

---

## 2023-07-01 17:39:49 - general channel

**Michael**

This is an extremely basic question but I’m having a lot of trouble implementing it. For those using market recorder, I’m trying to write the metadata to a SQL database. I’m calling a function in the process_closed_market function which takes the market definiton, connects to the sql database and then writes it, but nothing is being written (or showing up on logs). When I implement this, I get the following error:

```2023-06-17 22:27:22,654 - ERROR - _get_cleared_market error

Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn

    conn = connection.create_connection(

  File "/home/ubuntu/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 72, in create_connection

    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):

  File "/usr/lib/python3.8/socket.py", line 918, in getaddrinfo

    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):

socket.gaierror: [Errno -3] Temporary failure in name resolution



During handling of the above exception, another exception occurred:```

It feels like the market is never closing and then I am stuck with a full /tmp file and hence the above error occurs. How does everyone else implement this?

---

## 2023-07-01 10:37:07 - issues channel

**Lee**

Surprised it’s taking so long to fix

---

## 2023-07-01 03:25:52 - general channel

**James**

I have run into issues in the past when getting an error placing a bet (eg my account balance is too low to place the. bet) and then the bot kept retrying in a loop. But that surfaced as API charges on my account rather than a suspension.

---

## 2023-06-30 05:08:52 - issues channel

**Andrey Luiz Malheiros**

Hey guys, I'm using Flumine and couldn't find the answers to these two questions:



1. I tried starting Flumine, and there were 300 markets available for subscription. However, I received an error notification stating that the maximum allowed number was 200 markets. Therefore, I would like to know if it is possible to increase the maximum number of subscriptions.

2. Additionally, I am curious to know if Flumine only performs subscriptions to markets upon initialization or if it continually searches for new markets to subscribe to.

Does anyone have any information on this?

---

## 2023-06-26 23:16:42 - issues channel

**Carl Nielsen**

Thanks Mo, yes the Delphi TCP Client uses the INDY components and the host is set to the right URL and Port number.  There are also several SSL settings all of which I've double checked.



Everything is as it should be so why I get the Host Not Found error is a mystery.



Thanks for your help.

---

## 2023-06-26 10:09:32 - general channel

**liam**

Yeah if you get that then you are in deep trouble, fix the cause don’t try and debug this outcome. What are you doing to cause it? Have you profiled? 

---

## 2023-06-26 08:32:05 - issues channel

**Carl Nielsen**

Thanks Mo, of the dozens of people and sites I've asked you're the first person (including from Betfair) to confirm the the endpoints are correct.   Surprisingly,  that is a start, when you get Host Not Found errors you tend to focus on the url, now I know that's correct so as you say the problem lies with the SSL settings or the Indy TCP client or settings I'm using..



Sorry if i was a bit sort before, I've been at this for over a week and haven't got of first base yet..

---

## 2023-06-26 08:20:19 - issues channel

**Mo**

Stated another way: we've done the obvious which is to confirm that you're using the right endpoints. So why would you get a "Host Not Found" error? It's not like you're doing something wrong with the message protocol. It can't even resolve the host name. So this has to be something Delphi specific. You're the one who has to solve that

---

## 2023-06-26 08:02:41 - issues channel

**Mo**

Hate to be dogmatic but I have no idea why you'd be getting that error and I doubt you will find anyone who has the first clue about Delphi on here



I suggest you try `betfairlightweight` ([https://github.com/betcode-org/betfair](https://github.com/betcode-org/betfair)) instead. Streaming example in the documentation here: [https://betcode-org.github.io/betfair/streaming/#market](https://betcode-org.github.io/betfair/streaming/#market)

---

## 2023-06-25 20:57:46 - issues channel

**Brøndby IF**

I'm trying to use the API and I get this error alert, but I've been using it for months. Could you help me, please?



If this has already been addressed, I apologize, but I couldn't find the solution.

---

## 2023-06-24 08:20:28 - strategies channel

**thambie1**

Thanks for all the suggestions. The approach that that I'm experimenting with now is to use a fixed margin, then use kelly (ignoring existing positions) to determine the size given the margin, and finally use kelly (considering existing positions) to determine what price to offer given the size computed in the previous step. Theoretically I'm pretty comfortable with it :crossed_fingers:

---

## 2023-06-24 03:00:33 - general channel

**Andy**

Anyone running their code in VSC getting these oom errors and VSC crashing periodically? The program doesn’t seem to be using large amounts of memory if I check task manager and the json files I’m reading and writing to aren’t more than a few mb in size. Have tried the google suggestions but hasn’t improved things - [https://stackoverflow.com/questions/71614897/vscode-crashed-reason-oom-code-536870904#:~:text=If%20you%20are%20using%20VSCode,Optimizations%22%20and%20mark%20the%20checkbox.&amp;text=It's%20easy%20than%20you%20think,will%20see%20that%20it%20works|https://stackoverflow.com/questions/71614897/vscode-crashed-reason-oom-code-536870904#:~:text=If%20you%20are%20using%20VSCode,Optimizations%22%20and%20mark%20the%20checkbox.&amp;text=It's%20easy%20than%20you%20think,will%20see%20that%20it%20works](https://stackoverflow.com/questions/71614897/vscode-crashed-reason-oom-code-536870904#:~:text=If%20you%20are%20using%20VSCode,Optimizations%22%20and%20mark%20the%20checkbox.&amp;text=It's%20easy%20than%20you%20think,will%20see%20that%20it%20works|https://stackoverflow.com/questions/71614897/vscode-crashed-reason-oom-code-536870904#:~:text=If%20you%20are%20using%20VSCode,Optimizations%22%20and%20mark%20the%20checkbox.&amp;text=It's%20easy%20than%20you%20think,will%20see%20that%20it%20works).

---

## 2023-06-21 16:29:49 - general channel

**Alejandro Pablos Sánchez**

This is the exact error message I get, is the same for whatever API function I wanna use

---

## 2023-06-21 16:29:14 - general channel

**Alejandro Pablos Sánchez**

`*APIError*: AccountAPING/v1.0/getAccountFunds` 

Params: {}

Exception: None

Error: {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}

---

## 2023-06-21 16:29:06 - general channel

**Alejandro Pablos Sánchez**

Coming back to this, I'm still not able to fix it with the keep_alive method

---

## 2023-06-21 09:56:19 - strategies channel

**Mo**

How about Kelly with fixed margin?

---

## 2023-06-20 23:36:14 - general channel

**Alex**

Any reason why line 191 in markets.blotter reads `for order in self.strategy_selection_orders(strategy, *lookup[1:])` ? Why is disregarding the first element in lookup? I suspect this is a bug because strategy_selection_orders would normally take strategy, selection_id, and handicap as parameters. In the above it would just get strategy and selection_id=handicap and handicap defaulting to 0. [https://github.com/betcode-org/flumine/blob/master/flumine/markets/blotter.py#L191](https://github.com/betcode-org/flumine/blob/master/flumine/markets/blotter.py#L191)

---

## 2023-06-20 21:27:36 - general channel

**Alejandro Pablos Sánchez**

Hello mates !! Since yesterday night, I'm getting the AccountAPING exception error when using the API client. Is anyone experiencing the same issue? Apparently it says "INVALID_SESSION_INFORMATION" but I didn't change the credentials neither the key, so I can't figure out why this is happening. Any help? 



Thanks :wink:

---

## 2023-06-20 21:20:21 - issues channel

**Jeff Waters**

Hi



I've been back testing a system that involves placing a lot of bets. I kept getting an 'ERROR - Transaction limit reached' message, which I presume is meant to prevent users from going over the 5000 (?) bets you can place per hour before you start paying a charge. However, it looks like it continues to apply when processing market activity that took place over an hour after the 5000 limit would have been hit.



Is there anything I can do to get around this, please, as the constant console output slows things down?

---

## 2023-06-20 18:29:34 - strategies channel

**thambie1**

Visually by looking at a graph of returns. Profiling against alternatives. Definition doesn't really matter, as I'm not being nuanced about risk. I found fixed liability given a margin was worse against any risk profile metric you could reasonably come up with

---

## 2023-06-19 20:13:03 - random channel

**Laybot McBackbot**

[@U0128E7BEHW](@U0128E7BEHW): It was indeed through Twitter. I was pissed because she treated me like I was a retard but decided to look at her profile on LinkedIn before going full Karen as she might be new (and I am not that heartless!). Saw that she had only been working in the gambling industry for six months so I thought she was just new and not to get her into trouble so I moved on. Her colleague fixed that thing anyway.

---

## 2023-06-19 16:28:04 - random channel

**Aaron Smith**

wasnt meant to be an excuse, rather my guess on what is more likely going on. Its obviously still pretty bad. Not sure how they could go about fixing that rather than having a better trained CS though. Personally i m sure i d go insane working at betfair CS, so i cant really blame them :smile:

---

## 2023-06-19 16:15:01 - random channel

**Laybot McBackbot**

They eventually fixed it but not before I told them I am not a noob.

---

## 2023-06-19 10:54:53 - issues channel

**Aaron Smith**

Just to double check:

I am getting a lot of these bois:

`"WARNING", "message": "Order has violated: MARKET_VALIDATION Error: Market is not open"`

I never really cared much about them, as i assume what happens is that the market is getting closed after my order has been sent out, but before its processed on betfairs end -  so there isnt much to do about it. In that case, i assume everyone is getting a bunch of these over the day?

---

## 2023-06-18 21:21:37 - issues channel

**Michael**

Also, nothing was written to S3 during this error period so I’ve basically got a full /tmp. Flumine doesn’t seem to have cleaned this up, can I force this somehow

---

## 2023-06-18 20:55:03 - issues channel

**Michael**

Has anyone run into the following? I think its stemmed from a code change I implemented to write to a database but not sure why it is coming out as this error



```2023-06-17 22:27:22,654 - ERROR - _get_cleared_market error

Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn

    conn = connection.create_connection(

  File "/home/ubuntu/.local/lib/python3.8/site-packages/urllib3/util/connection.py", line 72, in create_connection

    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):

  File "/usr/lib/python3.8/socket.py", line 918, in getaddrinfo

    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):

socket.gaierror: [Errno -3] Temporary failure in name resolution



During handling of the above exception, another exception occurred:```

---

## 2023-06-18 18:07:09 - random channel

**Peter**

That wide a variation in the time to fix, suggests that they are very willing to make corrections when they become aware of them, but that there's no systemic process in place to check post-settlement. Not a criticism - I wouldn't design one in either - all the focus should be on catching errors prior to settlement, with no we can always correct it later loophole.

---

## 2023-06-18 16:36:45 - random channel

**Peter**

How can we know? If a mis-settlement occurs and they fix it (I've see and reported them too), it could have been because they caught it, or their service provider notified them of an error in their feed, or a customer reported it so they double checked it - but we can't see which it was.



Given the volume of markets they manage, I personally doubt that they spend time re-visiting them after settlement in case they got it wrong, but for a definitive answer, you'd need to ask Betfair whether they have an internal process to do so.



I can though confirm that when I've reported them, they've been fixed very quickly.

---

## 2023-06-18 15:01:03 - random channel

**Laybot McBackbot**

Happened to dogs in the past but quickly fixed.

---

## 2023-06-18 15:00:14 - random channel

**Laybot McBackbot**

Hmm.... Does anyone know if Betfair settled a football match from a small league incorrectly and nobody complained, it will automatically fix it later? This is the second time recently I found them settling bet wrongly and I had to contact them.

---

## 2023-06-17 10:54:50 - general channel

**AI Trader**

Hi guys,

I am looking for a solution to test strategies with small amounts of money. I know I. can limit that through software and using the concept of strategies in the orders and etc, but I was wondering if there is any way to have anything similar to a sub-account (as in crypto exchanges), so regardless of software bugs, I can guarantee I will be using a limited amount of money for a strategy. Any ideas on this? [https://support.betfair.com/app/answers/detail/a_id/94|Betfair seems not to allow multiple accounts per client](https://support.betfair.com/app/answers/detail/a_id/94|Betfair seems not to allow multiple accounts per client)

---

## 2023-06-17 03:00:02 - issues channel

**Aaron Smith**

I see. How about:

```def cancel_all(strat: BaseStrategy, framework: Flumine) -&gt; None:

    """cancels all executable orders of strat and waits for confirmation"""

    num_cancel_attempts = 5

    for _ in range(num_cancel_attempts):

        for market in framework.markets:

            orders = market.blotter.strategy_orders(strategy=strat, order_status=[OrderStatus.EXECUTABLE])

            cancel_orders(market=market, orders=orders)

        [http://logging.info|logging.info](http://logging.info|logging.info)('Sleeping for 3s')

        time.sleep(3)  # waiting for orders to be cancelled in another thread



        e_orders = []

        for market in framework.markets:

            orders = market.blotter.strategy_orders(strategy=strat, order_status=[OrderStatus.EXECUTABLE])

            e_orders += orders

            [http://logger.info|logger.info](http://logger.info|logger.info)(f"{len(orders)} orders executable in market {market.market_id}")

        if not e_orders:

            break

    else:

        logger.warning(f"failed to cancel {len(e_orders)} orders")```

this function would be called in BaseStrategy.finish()

downsides:

• If order takes longer than 3s to cancel, we d send out multiple cancelations for the same order (but maximum 5 and with 3s delay between attempts, so i guess that should be fine?)

upsides:

• if an order slips through, we try to cancel again

• giving up instead of infinte while loop (maybe not perfect either, but the lesser evil?)

---

## 2023-06-16 16:53:32 - issues channel

**Michael**

I keep getting _getclearedmarket error in Market recorder because of read time outs. Is Flumine handling these or is this an error on my part somewhere?

---

## 2023-06-16 14:20:06 - issues channel

**Aaron Smith**

2 seconds for you maybe :smile:

so you want me to write the terminate function like this?:

```

def terminate(context: dict, framework: Flumine) -&gt; None:

# stop market streams

for market in framework.markets:

    for order in market.blotter:

        if order.status == OrderStatus.EXECUTABLE:

            market.cancel_order(order)

# wait for confirmation

    framework.handler_queue.put(TerminationEvent)```

if so, regarding "stop market streams", i cant see a clean way of doing this. Flumine seems to have one attribute "streams" which includes all streams. I could iterate over, check if isinstance(stream, FlumineMarketStream) and stop those, i guess.



Regarding "wait for confirmation" my lack of experience with threading may be the problem. I guess i d need to collect all bet_id's of the orders i just canceled, then open a listener_thread where i check for coming updates and wait until all bets that i have canceled have been confirmed to be cancelled? + some error handling when a bet failed to cancel.

---

## 2023-06-16 12:14:23 - issues channel

**liam**

I mean fix your worker and test it, 2 second test will tell you if things are working, dw about the exit change, I can improve that

---

## 2023-06-16 09:35:45 - issues channel

**liam**

Good point, that is possible, [https://github.com/betcode-org/flumine/blob/master/flumine/baseflumine.py#L429|this](https://github.com/betcode-org/flumine/blob/master/flumine/baseflumine.py#L429|this) is the exit code, easy fix is to stop the streams first and then call the workers

---

## 2023-06-16 09:29:22 - issues channel

**Aaron Smith**

that will be the reason then. I thought once sent out, it will just complete even if i dont wait for the confirmation. Thank you, i ll check how to fix that

---

## 2023-06-13 21:18:37 - strategies channel

**Peter**

My approach is to use the terminate middleware to close my strategies down at the end of each day and cron to re-start them the next day, so they're always close to a fresh start, and then rely on Flumine to bridge any intraday outages.



Like others I don't worry about the odd exceptional event, anticipating that the positives and negatives will even out over the long-term, and the net effect will therefore be too small to justify the added complexity of trying to mitigate or handle them.

---

## 2023-06-13 19:34:37 - issues channel

**foxwood**

Is cancel and change price function for an order supposed to work in simulation ? My code to play with this is basically

```for order in market.blotter:

	if order.size_remaining != 0.0 :

		price = ...

		order.replace(price)```

and that sets the order status to "Replacing" but as shown in log below it doesn't switch to "Execution complete" until 44 seconds later when the market closes and no matching done on the order. Originally placed lay bet at 7.4 none of which was matched then replaced asking for  8.8 which should have taken lower current lay price of which there were many trades less than that. Haven't found anywhere in the simulation code yet that seems to be aware of the replacing operation ?

Am I just using it wrong or it doesn't work as I think it should ?

EDIT: I am using a build from last April but still can't see any signs it would work looking at latest github ?

```......

{"asctime": "2023-06-13 18:23:50,367", "levelname": "DEBUG", "message": "Simulated order 139059698302594198 traded: 7.6 - 1.2"}

{"asctime": "2023-06-13 18:23:50,368", "levelname": "DEBUG", "message": "getSecondsToStart: 29.829"}

{"asctime": "2023-06-13 18:23:50,368", "levelname": "INFO", "message": "Order status update: Replacing" ...

	"status": "Replacing", "status_log": "Pending, Executable, Replacing", ...

{"asctime": "2023-06-13 18:23:50,368", "levelname": "DEBUG", "message": "Replacing odds for 53923661 from odds 7.4 to 8.8"}

{"asctime": "2023-06-13 18:23:50,368", "levelname": "DEBUG", "message": "getSecondsToStart: 29.62"}

{"asctime": "2023-06-13 18:23:50,369", "levelname": "DEBUG", "message": "getSecondsToStart: 29.517"}

{"asctime": "2023-06-13 18:23:50,369", "levelname": "DEBUG", "message": "Simulated order 139059698302594198 traded: 7.6 - 0.08"}

{"asctime": "2023-06-13 18:23:50,370", "levelname": "DEBUG", "message": "getSecondsToStart: 29.304"}

......

"asctime": "2023-06-13 18:23:50,509", "levelname": "DEBUG", "message": "Simulated order 139059698302594198 traded: 8 - 11.52"}

{"asctime": "2023-06-13 18:23:50,510", "levelname": "DEBUG", "message": "getSecondsToStart: -13.085"}

{"asctime": "2023-06-13 18:23:50,510", "levelname": "DEBUG", "message": "getSecondsToStart: -13.189"}

{"asctime": "2023-06-13 18:23:50,510", "levelname": "DEBUG", "message": "getSecondsToStart: -13.293"}

{"asctime": "2023-06-13 18:23:50,511", "levelname": "DEBUG", "message": "getSecondsToStart: -13.352"}

{"asctime": "2023-06-13 18:23:50,511", "levelname": "DEBUG", "message": "getSecondsToStart: -13.457"}

{"asctime": "2023-06-13 18:23:50,512", "levelname": "DEBUG", "message": "getSecondsToStart: -14.183"}

{"asctime": "2023-06-13 18:23:50,513", "levelname": "INFO", "message": "Order status update: Execution complete" ......

{"asctime": "2023-06-13 18:23:50,513", "levelname": "INFO", "message": "Trade status update: Complete"......

{"asctime": "2023-06-13 18:23:50,515", "levelname": "INFO", "message": "Market 1.215094455 closed" ......

......```

---

## 2023-06-13 18:20:33 - strategies channel

**liam**

flumine deals with it as gracefully as it can, have a look at the [https://github.com/betcode-org/flumine/blob/master/flumine/streams/marketstream.py|marketstream](https://github.com/betcode-org/flumine/blob/master/flumine/streams/marketstream.py|marketstream) code to see how it retries to connect with exponential backoff. I think there has only been one occasion in the past year where I have had to restart but I think we have fixed this particular issue (memory leak)

---

## 2023-06-11 11:32:09 - random channel

**D C**

[https://www.amazon.co.uk/Betfair-Trading-Made-Simple-Ultimate/dp/1980887039/ref=sr_1_1?crid=3PIPU3F84WQ9X&amp;keywords=caan+berry+betfair&amp;qid=1686479509&amp;sprefix=caan+berry%2Caps%2C90&amp;sr=8-1|https://www.amazon.co.uk/Betfair-Trading-Made-Simple-Ultimate/dp/1980887039/ref=sr_1_[…]+betfair&amp;qid=1686479509&amp;sprefix=caan+berry%2Caps%2C90&amp;sr=8-1](https://www.amazon.co.uk/Betfair-Trading-Made-Simple-Ultimate/dp/1980887039/ref=sr_1_1?crid=3PIPU3F84WQ9X&amp;keywords=caan+berry+betfair&amp;qid=1686479509&amp;sprefix=caan+berry%2Caps%2C90&amp;sr=8-1|https://www.amazon.co.uk/Betfair-Trading-Made-Simple-Ultimate/dp/1980887039/ref=sr_1_[…]+betfair&amp;qid=1686479509&amp;sprefix=caan+berry%2Caps%2C90&amp;sr=8-1)

---

## 2023-06-07 12:20:51 - strategies channel

**Mo**

I'm not (yet) convinced by your argument. You seem to be saying that provided there is no systematic bias in your probabilities compared to the market then you can use whatever probability you want for the EV calculation. It seems contrived to think there is no systematic bias in your probabilities compared to the market and, in fact, in all likelihood there must be some for you to identify a mispricing



Example situation where the EV could be misleading:



1. Your strategy backs long price horses

2. You calculate EV using market implied probabilities calculated from BSP using the standard overround removal method

3. Your overround removal method has failed to account for favourite longshot bias, the market implied probabilities are too high and your EV is an overestimate

---

## 2023-06-07 11:32:42 - issues channel

**Tom**

I'm having a nightmare of a time trying to use RaceCards; I want to call them to get results, bsp, market data e.t.c. - Wouldnt mind seeing the full functionality; there is something there that even has form related data (I presume it's not available for Australian horse racing?).



I've spun myself around enough times to not really know what to try next.



```def get_race_results(race_card: RaceCard, market_ids: List[str]):

    logging.debug(f"Getting race card for market_ids: {market_ids}")

    try:

        racecards = race_card.get_race_card(market_ids, data_entries="RACE")

        race_results = race_card.get_race_result(market_ids)

        print(f"race results are {race_results}")

        logging.debug(f"Received race card data: {racecards}")

    except Exception as e:

        logging.error(f"Failed to get race card data: {e}")

        return []



    result = []

    for race in racecards:

        logging.debug(f"Processing race: {race['raceName']}")

        for runner in race['runners']:

            runner_data = {

                "Market ID": race['marketId'],

                "Race Name": race['raceName'],

                "Race Time": race['raceTime'],

                "Runners": race['numberOfRunners'],

                "Distance": race['distance'],

                "Runner Name": runner['runnerName'],

                "Runner ID": runner['selectionId'],

                "Starting Price": runner['sp'],

                "Final Position": runner['finishingPosition'],

                "In-Play High Price": runner['inPlayHighPrice'],

                "BSP": runner['bsp'],

            }

            result.append(runner_data)

            logging.debug(f"Processing runner_data: {runner_data}")



    return result



def get_results(trading):

    date_str = datetime.date.today().strftime("%d-%m-%Y")

    file_path = f'data/market_trade_data/market_trade_data_{date_str}.pkl'

    market_trade_data = pd.read_pickle(file_path)

    logging.debug(f"Market trade data: {market_trade_data}")

    market_ids = refresh_market_ids(market_trade_data)



    race_card = trading.RaceCard.login()

    try:

        trading.race_card.login()

        print("Logged in successfully.")

    except Exception as e:

        print(f"Failed to log in: {e}")



    all_results = []

    for market_id in market_ids:

        logging.debug(f"Getting race results for market_id: {market_id}")

        all_results.extend(get_race_results(race_card, [market_id]))



    df_results = pd.DataFrame(all_results)

    df_results.to_csv(f"data/race_results/race_results_{date_str}.csv", index=False)

    logging.debug(f"Saved race results to 'data/race_results/race_results_{date_str}.csv'")```

---

## 2023-06-06 14:21:37 - strategies channel

**D C**

Surely you're never going to be able to identify inaccurate prices on individual case basis. You can only really assess performance of probability estimates on a large scale (regardless of whether BSP / odds at off etc). We can get away with it on theoretical idealisation of things like fair coins/dice etc, but you can surely never know that an even money closing price favourite should really have gone off at 10/11 ??? And then you've got stuff like race/match fixing and inside info to contend with. Surely its all a lost cause trying to work out when a particilar off price is "bad" ?

---

## 2023-06-06 09:44:08 - issues channel

**liam**

Haven't seen this one before?



```.. "statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"No available feeds to subscribe to","connectionClosed":true..```

---

## 2023-06-04 22:45:52 - issues channel

**Alexander O'Reilly**

runner.sp.near_price gives me an AttributeError: NoneType object has no attribute ‘near_price’



I can access other attributes such as runner.ex.available_to_back etc. but sp attribute gives me none response.



This is for win markets, horse racing AU, flat

---

## 2023-06-04 11:16:56 - general channel

**D C**

I used to do something similar but that was with stuff off a serial port at low baud rate where you could get one byte at a time - and this was with fixed format message protocol where you had specific end of message identifier charactetr. Higher level stuff probably won't give you that kind of granularity. I'd imagine JSON parsing would be a lot trickier but my inner nerd is intrigued how you would go about doing it with a  more open ended message structure. Would you be just looking to parse interior structures as they arrive and assemble once you identify end of message?

---

## 2023-06-03 03:18:06 - general channel

**thambie1**

Anyone know if it's possible to login using the API using a trading master account? Currently getting error "TRADING_MASTER" when I try.

---

## 2023-06-02 22:49:26 - issues channel

**AI Trader**

I have managed to fix the issue with a simple hack (adding verify = False to every single request to betfair, which is not a good solution as defeats the purpose)

---

## 2023-06-02 09:39:46 - issues channel

**Andy**

Mainloop Timer 3: 2023-06-02T08:29:03.045302

Exception in thread Thread-1 (start):

Traceback (most recent call last):

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\threading.py", line 1038, in _bootstrap_inner

    self.run()

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\threading.py", line 975, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 233, in _read_loop

    self._data(received_data)

  File "C:\Users\AppData\Local\Programs\Python\Python311\Lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 274, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 105-020623082852-707950, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"103-020623082851-731897"}

---

## 2023-06-02 09:39:41 - issues channel

**Andy**

Get this annoying error anytime I start my stream. It doesn't seem to cause any issues but just want to get to the bottom of it. All error handling attempts have failed

---

## 2023-06-01 22:34:54 - issues channel

**AI Trader**

I am placing my orders through threads concurrently.  I can see that when the strategy starts, the first orders are placed successfully.

Are you aware of any limitations imposed by Betfair? I've found [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions|here](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions|here) that:



[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders|placeOrders](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders|placeOrders), [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/cancelOrders|cancelOrders.](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/cancelOrders|cancelOrders.) [https://docs.developer.betfair.com/pages/viewpage.action?pageId=2621600|updateOrders](https://docs.developer.betfair.com/pages/viewpage.action?pageId=2621600|updateOrders), [https://docs.developer.betfair.com/pages/viewpage.action?pageId=2621599|replaceOrders](https://docs.developer.betfair.com/pages/viewpage.action?pageId=2621599|replaceOrders) if the number of transactions (instructions) submitted exceeds 1000 in a single second causes an error. This is by far not my case (I am sending less than 100 requests per second surely).

---

## 2023-06-01 21:51:52 - issues channel

**AI Trader**

I get this error every time I run the strategy. After a couple of minutes running the strategy, I get dozens of these messages in a couple of seconds (It's an HFT strategy), and from there no orders are placed anymore, only errors. Do you have any guesses on what could be happening?

---

## 2023-06-01 21:48:41 - issues channel

**AI Trader**

[@UBS7QANF3](@UBS7QANF3) I have. It's weird because I manage to login thorugh the betfairlightweight api and place orders successfuly. But whenever I run my strategy, some time after I get the error below



```2023-06-01 20:46:58,742 - ERROR - executor.replace - ERROR REPLACE: SportsAPING/v1.0/replaceOrders 

Params: {'marketId': '1.214777671', 'instructions': [{'betId': '309396638021', 'newPrice': 4.3}]} 

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/betting/json-rpc/v1 (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:997)')))```

---

## 2023-06-01 18:07:01 - issues channel

**Mo**

[@U055BSWEY7M](@U055BSWEY7M) fixed _his_ problem in one of the threads I linked to: [https://betcode-org.slack.com/archives/C4H05ML2E/p1682713756666659?thread_ts=1682643720.988399&amp;cid=C4H05ML2E](https://betcode-org.slack.com/archives/C4H05ML2E/p1682713756666659?thread_ts=1682643720.988399&amp;cid=C4H05ML2E). Perhaps it's the same as yours (although perhaps not)

---

## 2023-06-01 18:04:04 - betconnect channel

**Lee**

what’s the error? same as before?

---

## 2023-06-01 17:50:21 - issues channel

**AI Trader**

Same. Did you amnage to fix [@U05AR7HNHUZ](@U05AR7HNHUZ)?

---

## 2023-05-31 23:22:03 - issues channel

**AI Trader**

[@U053U2PUK2M](@U053U2PUK2M) did you find out the reason? Im experiencing the same issue, ie, it works locally, but when deploying in the cloud (with the same requirements.txt and python version, i SOMETIMES get this error

---

## 2023-05-31 20:24:11 - issues channel

**Stephen Shirley**

Hi I'm getting ssl.SSLError: [SSL] PEM lib (_ssl.c:3874) when I try to login using betfairlightweight. It's the same error I would get using the regular betfair api if my key was wrong but I have tried it using the regular api with the same key and it works. If anyone could help it would be much appreciated.

---

## 2023-05-30 21:51:46 - betconnect channel

**Alejandro Pablos Sánchez**

[Running] python -u "c:\Users\aleja\OneDrive\Escritorio\Tipster_Auto\src\login2.py"

Traceback (most recent call last):

  File "c:\Users\aleja\OneDrive\Escritorio\Tipster_Auto\src\login2.py", line 7, in &lt;module&gt;

    trading.login_interactive()

  File "C:\Users\aleja\AppData\Roaming\Python\Python38\site-packages\betfairlightweight\endpoints\logininteractive.py", line 30, in __call__

    (response, response_json, elapsed_time) = self.request(

  File "C:\Users\aleja\AppData\Roaming\Python\Python38\site-packages\betfairlightweight\endpoints\logininteractive.py", line 63, in request

    self._error_handler(response_json)

  File "C:\Users\aleja\AppData\Roaming\Python\Python38\site-packages\betfairlightweight\endpoints\logininteractive.py", line 70, in _error_handler

    raise self._error(response)

betfairlightweight.exceptions.LoginError: API login: AUTHORIZED_ONLY_FOR_DOMAIN_ES

---

## 2023-05-30 21:51:44 - betconnect channel

**Alejandro Pablos Sánchez**

Hello again, this is the code I'm using changing now the locale attribute but still getting the same error. I cannot figure out why that's happening... Anyone that has been able to login like this can help me? It would be great definitely, getting this to work is being a headache really. Btw, the error I'm getting is the following:

---

## 2023-05-27 23:37:54 - betconnect channel

**Alejandro Pablos Sánchez**

Hi everyone, I got a question. When trying to connect to the API, I am getting the following exception error: betfairlightweight.exceptions.LoginError: API login: AUTHORIZED_ONLY_FOR_DOMAIN_ES

---

## 2023-05-27 12:10:55 - issues channel

**Jeff Waters**

Hi



I'm doing back testing, and using market.cancel_order(order) to cancel orders, like so:



```def cancel_order(self, market: Market, order: BaseOrder):

    with market.transaction() as t:

        t.cancel_order(order)```

However, the logger shows that an exception was thrown:



  *File "C:\Users\User\Documents\New back test\venv\lib\site-packages\flumine\execution\transaction.py", line 101, in cancel_order*

    *order.cancel(size_reduction)*

  *File "C:\Users\User\Documents\New back test\venv\lib\site-packages\flumine\order\order.py", line 339, in cancel*

    *raise OrderUpdateError("Order does not currently have a betId")*

*flumine.exceptions.OrderUpdateError: Order does not currently have a betId*

*ERROR - FlumineException Order does not currently have a betId in process_market_book (1.145085632)*



I'm using the following code to create orders:



```order = OrderFactory().non_bsp_order(self, back_or_lay, target_price, stake, runner, market_book)

with market.transaction() as t:

    t.place_order(order)```

and this is what the OrderFactory method looks like:



```def non_bsp_order(self, strategy_object: BaseStrategy, back_or_lay: str, bet_price: float, stake_size: float,

                  runner: RunnerBook, market_book: MarketBook) -&gt; BetfairOrder:

    trade = Trade(

        market_book.market_id,

        runner.selection_id,

        runner.handicap,

        strategy_object,

    )

    return trade.create_order(

        side=back_or_lay, order_type=LimitOrder(price=bet_price, size=stake_size)

    )```

Where am I going wrong, please?

---

## 2023-05-26 07:53:25 - random channel

**Jonjonjon**

Still, I'd prefer to have more in my bank account than Betfair. I don't have the expertise to know if Betfair did it in a way that is safe.



E.g. I could back £1m @1,000. That would let me lay £1m@990.

There could be some sort of exchange error leading to the cancellation of the back.

I would owe more than my deposit

---

## 2023-05-25 09:48:49 - general channel

**Andy B**

Yes, but I got the same error.  I am assuming I have done it correctly, but my assumptions are not always great.

---

## 2023-05-25 07:57:37 - general channel

**Andy B**

I think that I am accessing the keras model to make predictions too fast when back testing against the market stream:

2023-05-25 16:21:56,369:CRITICAL:Unknown error bad allocation in process_market_book (1.212040559)

Traceback (most recent call last):

  File "C:\Python\lib\site-packages\flumine\utils.py", line 239, in call_strategy_error_handling

    return func(market, market_book)

  File "C:\Python\Scripts\flumine\FlumineSims.py", line 228, in process_market_book

    ModelName = tf.keras.models.load_model(ModelName)

  File "C:\Python\lib\site-packages\keras\utils\traceback_utils.py", line 70, in error_handler

    raise e.with_traceback(filtered_tb) from None

  File "C:\Python\lib\site-packages\h5py\_hl\files.py", line 533, in __init__

    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)

  File "C:\Python\lib\site-packages\h5py\_hl\files.py", line 226, in make_fid

    fid = h5f.open(name, flags, fapl=fapl)

  File "h5py\_objects.pyx", line 54, in h5py._objects.with_phil.wrapper

  File "h5py\_objects.pyx", line 55, in h5py._objects.with_phil.wrapper

  File "h5py\h5f.pyx", line 106, in h5py.h5f.open

  File "h5py\h5fd.pyx", line 155, in h5py.h5fd.H5FD_fileobj_get_eof

  File "h5py\h5fd.pyx", line 155, in h5py.h5fd.H5FD_fileobj_get_eof

MemoryError: bad allocation



That makes sense if it is multi-processing and trying to open it n number of times I guess, but I am not sure if there is a way to do this without slowing down the stream.  Is there a better way to do this?

---

## 2023-05-24 09:01:13 - issues channel

**Jeff Waters**

Hi



I've amended the error handling method to print the details of the errors:



```def call_strategy_error_handling(

    func: Callable, market, market_book: MarketBook

) -&gt; Optional[bool]:

    try:

        return func(market, market_book)

    except FlumineException as e:

        logger.error(

            "FlumineException %s in %s (%s)" % (e, func.__name__, market.market_id),

            exc_info=True,

        )

        print(e)

    except Exception as e:

        logger.critical(

            "Unknown error %s in %s (%s)" % (e, func.__name__, market.market_id),

            exc_info=True,

        )

        print(e)

        if config.raise_errors:

            raise

    return False```

How do I get it to print a full stack trace, please? Currently, the output is just telling me 'list index out of range', but it would be helpful to know which bit of my code was responsible for that error.



GPT suggested adding:



traceback_str = traceback.format_exc()  # Get the formatted traceback as a string

print(traceback_str)  # Print the stack trace



However, that had no effect.



Thanks

---

## 2023-05-23 15:37:09 - issues channel

**Newbie99**

Last week I got this error:



```betfairlightweight.exceptions.LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE```

When trying to make REST API calls from my local machine, didn't think too much of it as its fairly self explanatory, so I changed my password and moved on.



However I've just received the same error again (less than a week after changing my password), which seems a bit odd as I can login via the GUI, I'm logged in via the streaming API (not seeing any errors in the logs currently), so is there any other reason why this might be happening?

---

## 2023-05-23 09:45:09 - issues channel

**Jorge**

I think it's just a typo, because keep_alive() returns None for both the case where no keep_alive is required and when it is required but an Exception is raised (my case)

---

## 2023-05-23 09:40:37 - issues channel

**liam**

Whats the error?

---

## 2023-05-23 09:39:57 - issues channel

**Jorge**

They told me the session token has expired. I think this could be improved in flumine: [https://github.com/betcode-org/flumine/blob/master/flumine/clients/betfairclient.py#L46|keep_alive()](https://github.com/betcode-org/flumine/blob/master/flumine/clients/betfairclient.py#L46|keep_alive()) is logging an Exception but returns None, so in [https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#L100|worker.py](https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#L100|worker.py) it does not [https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#LL108C1-L108C23|client.login()](https://github.com/betcode-org/flumine/blob/master/flumine/worker.py#LL108C1-L108C23|client.login())

---

## 2023-05-22 13:34:21 - strategies channel

**Andrew**

A simple method could be to split bank across strategies in a fixed but not necessarily equal proportion. Borrowing from security selection and position sizing in finance you could modify stake size by confidence of selection. I don’t apply anything like this, rather thinking from my day job in investment management.

---

## 2023-05-22 12:25:15 - strategies channel

**James**

Is there a “best” way of mitigating risk when using highly correlated strategies, ie those whose selections overlap? Eg  80% of selections in strategy B are also selections in strategy A (albeit placed by auto instead of manually and at a difference time). Likewise 60% of selections in strategy C are also picked in strategy A. Capping the max exposure per selection to a fixed amount is one option but I wondered whether there is a better way. Thanks

---

## 2023-05-22 09:07:47 - issues channel

**Jorge**

Hi, I keep getting this error after my flumine trader is running for ~ 1 day. I never get the error in the flumine market recorder script but I do in the trader. The error is gone after restarting the script.

INVALID_SESSION_INFORMATION: UnrecognisedCredentials. This is the full log:



```{"asctime": "2023-05-22 08:01:42,808", "levelname": "ERROR", "message": "[MarketStream: 6393]: INVALID_SESSION_INFORMATION: UnrecognisedCredentials"}

{"asctime": "2023-05-22 08:01:42,808", "levelname": "ERROR", "message": "MarketStream 6392 run error", "exc_info": "Traceback (most recent call last):\n  File \"/root/environments/flumine/lib/python3.8/site-packages/flumine/streams/marketstream.py\", line 44, in run\n    self._stream.start()\n  File \"/root/environments/flumine/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py\", line 67, in start\n    self._read_loop()\n  File \"/root/environments/flumine/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py\", line 233, in _read_loop\n    self._data(received_data)\n  File \"/root/environments/flumine/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py\", line 274, in _data\n    raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 101-220523080142-760501, data: {\"op\":\"status\",\"id\":6393,\"statusCode\":\"FAILURE\",\"errorCode\":\"INVALID_SESSION_INFORMATION\",\"errorMessage\":\"UnrecognisedCredentials\",\"connectionClosed\":true,\"connectionId\":\"101-220523080142-760501\"}"}```

---

## 2023-05-21 22:13:14 - issues channel

**George**

I believe this fixed it by the way. Thanks very much!

---

## 2023-05-17 02:27:32 - strategies channel

**Alex**

It also depends on the number of bets placed, i.e. are you closing out bets half way through the race, then placing new bets? With 1000 datapoints your estimated strategy performance will have larger error than with 10000. Overfitting might be an issued based on how many parameters your model has (you'll likely be fine if you just have a few). You can try to bootstrap standard errors of your strategy to get an idea of how significant your results are.

---

## 2023-05-16 21:01:22 - issues channel

**Jonjonjon**

My logs are full of TOO_MANY_REQUESTS errors when calling listClearedOrders. How do people avoid that?

---

## 2023-05-16 16:32:42 - issues channel

**Mo**

This thread: [https://discourse.jupyter.org/t/jupyter-notebook-zmq-message-arrived-on-closed-channel-error/17869/17](https://discourse.jupyter.org/t/jupyter-notebook-zmq-message-arrived-on-closed-channel-error/17869/17) suggests you should try downgrading to 6.1

---

## 2023-05-16 16:09:35 - issues channel

**Mo**

And when the error occurs does the dashboard break or is it still usable?

---

## 2023-05-16 16:09:07 - issues channel

**George**

it definitely looks like a jupyter error but i'm wondering if anyone can suggest maybe a different version of a package that i should upgrade to for example?

---

## 2023-05-16 16:07:07 - issues channel

**Mo**

It looks to me like it’s some jupyter error unrelated to betfairviz but I could be wrong

---

## 2023-05-16 16:04:56 - issues channel

**George**

```Exception in callback functools.partial(&lt;function ZMQStream._update_handler.&lt;locals&gt;.&lt;lambda&gt; at 0x107b25160&gt;)

  Traceback (most recent call last):

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/ioloop.py", line 738, in _run_callback

    ret = callback()

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 718, in &lt;lambda&gt;

    self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 634, in _handle_events

    self._handle_recv()

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 663, in _handle_recv

    self._run_callback(callback, msg)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 584, in _run_callback

    f = callback(*args, **kwargs)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/zmq/eventloop/zmqstream.py", line 308, in stream_callback

    return callback(self, msg)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/notebook/services/kernels/handlers.py", line 572, in _on_zmq_reply

    super()._on_zmq_reply(stream, msg)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/notebook/base/zmqhandlers.py", line 256, in _on_zmq_reply

    self.write_message(msg, binary=isinstance(msg, bytes))

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/websocket.py", line 334, in write_message

    return self.ws_connection.write_message(message, binary=binary)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/websocket.py", line 1081, in write_message

    fut = self._write_frame(True, opcode, message, flags=flags)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/websocket.py", line 1056, in _write_frame

    return self.stream.write(frame)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/iostream.py", line 539, in write

    self._handle_write()

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/iostream.py", line 965, in _handle_write

    self._write_buffer.advance(num_bytes)

   File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/iostream.py", line 182, in advance

    assert 0 &lt; size &lt;= self._size

  AssertionError```

---

## 2023-05-16 16:02:56 - issues channel

**George**

I just started using betfairviz today. I am very frequently getting an exception and I wondered if anyone knows how I can avoid it. It looks like this:

```File "/Users/george/Library/Python/3.9/lib/python/site-packages/tornado/iostream.py", line 182, in advance

    assert 0 &lt; size &lt;= self._size

  AssertionError```

---

## 2023-05-15 21:36:45 - issues channel

**D C**

OK thanks. Must be my end. Max connection limit errors even when my stream authentication message tells me I have connections available. Weird.

---

## 2023-05-15 21:01:12 - issues channel

**D C**

Has anyone else had lots of errors on the order stream this evening?

---

## 2023-05-13 09:52:48 - general channel

**Dennis**

did something change in the list_cleared_orders endpoint? I have some code that was working fine for ages but then fell over a few months back, now it just times out with an error

```cleared_orders = trading.betting.list_cleared_orders(

                bet_status="SETTLED",

                record_count=10,

                from_record=0,

                settled_date_range=range_dates

            )```

and I get an 'UNEXPECTED_ERROR' after a long time

---

## 2023-05-13 09:45:54 - issues channel

**moseley82**

Anyone getting timeout errors this morning?

---

## 2023-05-11 22:13:40 - issues channel

**Michael**

When I’m trying to call list_market_catalogues, I get the following error: `betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue` 

`Params: {'filter': {'eventTypeIds': ['7'], 'marketCountries': ['GB', 'IRE'], 'marketTypeCodes': ['WIN', 'PLACE', 'E/W', 'OTHER_PLACE']}, 'marketProjection': ['RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'COMPETITION', 'EVENT', 'EVENT_TYPE', 'MARKET_DESCRIPTION', 'MARKET_START_TIME'], 'maxResults': 200}` 

`Exception: None` 

`Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie1-ang16b-prd-03210933-006fb19e72', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie1-ang16b-prd-03210933-006fb19e72', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`



The betfair API docs list that maxResults must be less than 1000 but when I change it to 100 it seems to work. Any ideas?

---

## 2023-05-09 19:41:14 - random channel

**Newbie99**

```  ncalls  tottime  percall  cumtime  percall filename:lineno(function)

   288135    1.555    0.000  662.991    0.002 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/simulation/simulation.py:109(_process_market_books)

        4    0.000    0.000  467.806  116.951 /python_files/backtesting_functions.py:44(startup)

        4    0.232    0.058  467.637  116.909 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/simulation/simulation.py:29(run)

  1134046    8.263    0.000  459.433    0.000 /python_files/market_making.py:36(place_passive_order)

  9757016   17.160    0.000  396.170    0.000 /python_files/place_order_functions.py:327(place_or_cancel)

   1992/1    0.020    0.000  282.462  282.462 {built-in method builtins.exec}

        1    0.000    0.000  282.462  282.462 backtesting.py:1(&lt;module&gt;)

        1    0.000    0.000  280.392  280.392 backtesting.py:325(start_backtest_b)

  1151150    0.395    0.000  267.220    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/utils.py:235(call_strategy_error_handling)

   287798    0.840    0.000  243.036    0.001 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/simulation/simulation.py:154(_process_simulated_orders)

   574944    0.413    0.000  242.620    0.000 /python_files/betting_strategy.py:53(process_market_book)

   559802    0.202    0.000  241.037    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/utils.py:272(call_process_orders_error_handling)

   559802    0.632    0.000  240.835    0.000 /python_files/betting_strategy.py:68(process_orders)

  4342013   47.805    0.000  154.966    0.000 /python_files/place_order_functions.py:577(validate_new_order)

  1152415    0.544    0.000  150.247    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/utils.py:255(call_middleware_error_handling)

  4784556    3.025    0.000  102.676    0.000 /python_files/place_order_functions.py:310(cancel_orders_by_price)

   288103    1.304    0.000   78.054    0.000 /python_files/risk_worker.py:9(__call__)

121605882   50.622    0.000   73.601    0.000 /python_files/validation_functions.py:769(true_or_false)

 20833220   20.227    0.000   72.348    0.000 /python_files/place_order_functions.py:924(get_limit)

   576206   14.875    0.000   71.167    0.000 /python_files/risk_functions.py:31(calc_exposure_metrics)

   288104    0.207    0.000   62.674    0.000 /python_files/competition.py:121(__call__)

 14541572   31.843    0.000   61.683    0.000 /python_files/risk_functions.py:127(get_runner_exposure)

   287472    0.419    0.000   61.392    0.000 /python_files/competition.py:146(update_market)

   287472    0.980    0.000   60.909    0.000 /python_files/competition.py:187(update_modelled_price_list)

  4784556   11.933    0.000   60.852    0.000 /python_files/cancel_and_replace.py:12(cancel_orders)

 55674710   31.552    0.000   48.538    0.000 /python_files/validation_functions.py:725(check_race_type_by_country)

  1136008    3.174    0.000   45.434    0.000 /python_files/validation_functions.py:47(validate_market_book)

   287472    0.664    0.000   42.708    0.000 /python_files/competition.py:221(&lt;listcomp&gt;)

  2486230    2.362    0.000   42.045    0.000 /python_files/competition.py:234(update_runner_price)

  2486230    1.287    0.000   39.121    0.000 /python_files/competition.py:171(get_runner_name)

  2486230    4.873    0.000   37.716    0.000 /python_files/competition.py:172(&lt;listcomp&gt;)

  9757016   10.321    0.000   36.596    0.000 /python_files/market_making.py:6(create_runner_dict)

  1440123    3.603    0.000   35.733    0.000 /python_files/place_order_functions.py:228(construct_price)

 28978669   10.676    0.000   32.843    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/betfairlightweight/resources/bettingresources.py:8(__getitem__)

   576206    6.713    0.000   29.727    0.000 /python_files/risk_functions.py:46(&lt;listcomp&gt;)

  1134046    2.796    0.000   26.220    0.000 /python_files/validation_functions.py:163(validate_order_windows)

  5095443   10.677    0.000   25.777    0.000 /python_files/place_order_functions.py:138(get_benchmark_percentage_and_tolerance)

   576206    0.372    0.000   24.206    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/strategy/strategy.py:101(check_market)

   576206    0.590    0.000   23.735    0.000 /python_files/betting_strategy.py:37(check_market_book)

  9757016    4.906    0.000   22.284    0.000 /python_files/misc_functions.py:72(get_runner_info)

 43650454   10.245    0.000   21.749    0.000 /python_files/risk_functions.py:135(validate_order_has_risk)

   288166    0.864    0.000   21.579    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/streams/historicalstream.py:204(_read_loop)

 28978669    7.751    0.000   20.991    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/betfairlightweight/utils.py:69(to_snake_case)

 10891063   11.955    0.000   19.219    0.000 /python_files/validation_functions.py:254(check_market)

 14541572   18.712    0.000   18.712    0.000 /python_files/risk_functions.py:130(&lt;listcomp&gt;)

380141490   17.861    0.000   17.863    0.000 {built-in method builtins.isinstance}

  9757016   16.306    0.000   16.887    0.000 /python_files/misc_functions.py:73(&lt;listcomp&gt;)

   287472    2.668    0.000   16.183    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/shin/__init__.py:5(calculate_implied_probabilities)

  4342013    3.838    0.000   15.908    0.000 /python_files/place_order_functions.py:565(get_benchmark_value)

  1134046    1.803    0.000   15.850    0.000 /python_files/validation_functions.py:76(get_price_at_post_time)

   589543    0.445    0.000   15.093    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/streams/historicalstream.py:187(on_data)

 51813748    8.634    0.000   13.955    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/order/order.py:436(size_matched)

   589543    1.351    0.000   13.903    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/streams/historicalstream.py:30(_process)

 14497067    3.100    0.000   12.459    0.000 {built-in method builtins.sum}

   589543    1.884    0.000   12.020    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/betfairlightweight/streaming/cache.py:234(update_cache)

 28980260   11.731    0.000   11.731    0.000 {method 'sub' of 're.Pattern' objects}

  4342013   11.682    0.000   11.682    0.000 /python_files/place_order_functions.py:571(&lt;listcomp&gt;)

  1134046    1.977    0.000   11.560    0.000 /python_files/validation_functions.py:88(&lt;listcomp&gt;)

144563009   11.485    0.000   11.485    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/strategy/strategy.py:249(name)

  4342013   11.182    0.000   11.182    0.000 /python_files/misc_functions.py:148(create_ordered_dict)```

---

## 2023-05-09 13:19:49 - random channel

**Newbie99**

I've recently switched to a new MacBook pro, from an old windows machine and as I knew performance was rubbish on that, I didn't worry too much, just left things processing overnight etc. However with an M2 Max I was expecting super fast backtesting, but compared to the results people post on here I seem to be way behind (e.g. 16k pre-race horse racing markets, 1 hour before the off takes circa 3 hours).



My code is as follows:

```def start_backtest_a(chunked_markets, max_workers, profit_sum, in_play, seconds_to_start, event_processing,

                    strategy_names, match_all, middleware):



    _process_jobs = []

    with futures.ProcessPoolExecutor(max_workers=max_workers) as p:

        for m in chunked_markets:

            _process_jobs.append(

                p.submit(startup,

                         profit_sum=profit_sum,

                         in_play=in_play,

                         seconds_to_start=seconds_to_start,

                         event_processing=event_processing,

                         markets=m,

                         strategy_names=strategy_names,

                         match_all=match_all,

                         middleware=middleware

                )

            )

        for i, job in enumerate(futures.as_completed(_process_jobs)):

            try:

                mini_output_list = job.result()  # wait for result

                output_list.extend(mini_output_list)

                progress = len(m) * i+1

                time_taken_seconds = (datetime.datetime.utcnow() - sim_start_time).total_seconds()

                time_taken_minutes = time_taken_seconds / 60

                percentage = progress / total_markets

                time_taken = time_taken_minutes if time_taken_minutes &gt; 2 else time_taken_seconds

                time_remaining = (time_taken / percentage) - time_taken

                time_measure = 'minutes' if time_taken_minutes &gt; 2 else 'seconds'

                print(f'Currently on market {progress} / {percentage*100:.2f}% of {total_markets}, '

                      f'time taken so far is {time_taken:.2f} {time_measure}, estimated time remaining is {time_remaining:.2f} {time_measure}, ')

            except Exception as e:

                print(f'Exception {e}.')

        return output_list```

With startup being as follows:



```def startup(markets, profit_sum, in_play, seconds_to_start, event_processing, strategy_names, match_all, middleware=False):

    logger = logging.getLogger()



    custom_format = "%(asctime) %(levelname) %(message)"

    log_handler = logging.StreamHandler()

    formatter = jsonlogger.JsonFormatter(custom_format)

    formatter.converter = time.gmtime

    log_handler.setFormatter(formatter)

    logger.addHandler(log_handler)

    logger.setLevel(logging.CRITICAL)  # Set to logging.CRITICAL to speed up simulation



    start_time = get_utc_time()



    # Gets a list of strategy settings

    settings = [setting for setting in rc if setting['on'] is True and setting['strategy_name'] in strategy_names]



    client = clients.SimulatedClient(simulated_full_match=match_all)



    framework = FlumineSimulation(client=client)



    # with mock_patch("builtins.open", smart_open.open): # Commented out as files will be unzipped prior to running

    for s in settings:

        max_selection_exposure = s['max_selection_exposure'] if true_or_false(s['max_selection_exposure']) != False else None

        include_virtual_prices = "EX_BEST_OFFERS_DISP" if true_or_false(

            s['include_virtual_prices']) is not False else "EX_ALL_OFFERS"

        if s['strategy_type'] == 'simple':



            strategy = betting_strategy(start_time=start_time, settings=s, paper=client.paper_trade,

                                        market_filter=create_market_filter(markets, in_play, seconds_to_start, event_processing),

            market_data_filter=streaming_market_data_filter(

            fields=[

                include_virtual_prices,

                "EX_TRADED",

                "EX_TRADED_VOL",

                "EX_LTP",

                "EX_MARKET_DEF",

                "SP_TRADED",

                "SP_PROJECTED",

            ]

            ),

            streaming_timeout=2,

            max_selection_exposure=max_selection_exposure,

            max_order_exposure=s['max_order_exposure'],

            conflate_ms=s['conflate'],

            name=s['strategy_name'],



            )



            framework.add_strategy(strategy)



    ''' Add in Middleware to get Market Catalogue '''

    framework.add_market_middleware(MarketCatalogueMiddleware())



    if middleware is not False:

        framework.add_market_middleware(middleware)



    framework.add_market_middleware(RiskMiddleware(framework))



    framework.run()```

I presume that calling the middleware could be an issue and also potentially my structure is wrong (i.e. in terms of trying to multiprocess at the wrong point).



I did try to get chatGPT to re-write things and it tried to use:



_with mp.get_context('spawn').Pool(max_workers) as pool:_ 



However I couldn't get it working (i.e. it never actually ran the framework, so I couldn't work out how to proceed).



Appreciate this is a bit of a '_how long is a piece of string_' situation, but is there a fairly generic approach to using multi processing with middleware that perhaps I could use as a template?

---

## 2023-05-07 23:15:39 - general channel

**Jeff Waters**

I've put some code in process_market_book to log the WOM when my orders are at least partially matched:



```for order in market.blotter.live_orders:

    runner = Repository().get_runner_from_order(order)

    if order.size_matched &gt; 0 and not hasattr(order, "wom"):

        order.wom = Wom().get_wom_for_runner(runner)```

When I print my results to a spreadsheet, I use:



```wom = order.wom if hasattr(order, "wom") else 0```

When I print the results, for orders that were matched, some of my entries are zero and some are the wom. I don't understand why it's sometimes the case that the order object is given a 'wom' attribute when money has been matched, and sometimes it isn't?



I wondered whether it might be due to race conditions, as I'm using multi-processing. I'm aware that, with multi-processing, each process has its own memory space, but Chat GPT assures me that race conditions can nevertheless happen (and yes, I'm aware that GPT isn't an authoritative source! :smile:). Anyway, I applied a lock to everything in process_market_book, but that didn't fix the issue.



Any suggestions would be appreciated.



Thanks



Jeff

---

## 2023-04-28 14:00:34 - issues channel

**JazzMan**

Anybody seen this Betfair error before “BET_LAPSED_PRICE_IMPROVEMENT_TOO_LARGE”

---

## 2023-04-28 11:45:33 - general channel

**Mo**

What do you mean by "fix this"? The time is in UTC as it always has been

---

## 2023-04-28 11:35:05 - general channel

**James**

Ever since the clocks changed market catalogue race times are showing -1 hour (13.30 shows as 12.30, etc). Does anyone know how to fix this? Thanks 

---

## 2023-04-28 02:02:00 - issues channel

**Philip Joss**

Hi. I've followed the guide here to create the necessary certificate using the XCA tool: [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA). I've then uploaded it successfully to the Betfair site. When I try to login using the bflw client I get the following error `Exception: Certificates not found in directory: '&lt;path to certificates folder&gt;' (make sure .crt and .key pair or a single .pem is present)`. This is self explanatory but the guide above doesn't mention creating a `.key` file or a `.pem` file! Playing around with the XCA app I have found that I can create a `.pem` file  from either exporting the key or the certificate request. I've tried both of these but on both I get the following error: `Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3874)')))`. I've had a search through [#C4H05ML2E|issues](#C4H05ML2E|issues) and there's a similar post but that's for a `4044` error. Any ideas on where I could go from here?

---

## 2023-04-23 13:23:12 - general channel

**Lee**

Can you share the full logs? It’s easier to debug when we can see the orders placed/cancelled/status’s changing

---

## 2023-04-23 13:21:41 - general channel

**Unknown**

Hi, here is the log:



2023-04-22 08:26:33 |  Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failed: live_trade_count (1) &gt;= max_live_trade_count (1)



I manually/visually checked the market (on betfair website). There were no orders from this strategy (as they all had been cancelled by the code).

---

## 2023-04-20 06:57:01 - issues channel

**Mo**

Sorry, keep meaning to reply to this:



1. The GitHub repo for CPython is here: [https://github.com/python/cpython](https://github.com/python/cpython)

2. The tag for version 3.9.16 is here: [https://github.com/python/cpython/tree/v3.9.16](https://github.com/python/cpython/tree/v3.9.16)

3. The _ssl.c file referenced in your exception is here: [https://github.com/python/cpython/blob/v3.9.16/Modules/_ssl.c](https://github.com/python/cpython/blob/v3.9.16/Modules/_ssl.c)

4. The line referenced in your exception is here: [https://github.com/python/cpython/blob/595f9ccb0c059f2fb5bf13643bfc0cdd5b55a422/Modules/_ssl.c#L4044](https://github.com/python/cpython/blob/595f9ccb0c059f2fb5bf13643bfc0cdd5b55a422/Modules/_ssl.c#L4044)

5. All I can personally infer at this stage is that a) the problem is with your certificate b) the problem is NOT related to the certificate file's password c) the problem is NOT some OS error such as being unable to find the certificate file

---

## 2023-04-18 09:24:58 - general channel

**Jorge**

I found out the issue I posted above is related to Orders going to [https://github.com/betcode-org/flumine/blob/master/flumine/order/order.py#L39|OrderStatus.VIOLATION](https://github.com/betcode-org/flumine/blob/master/flumine/order/order.py#L39|OrderStatus.VIOLATION) .

1. I place an order and it gets accepted, so the Status is EXECUTABLE.

2. The Market gets suspended.

3. I cancel the order and get the following log: "Order status update: Violation", "Order has violated: MARKET_VALIDATION Error: Market is not open". But, the order's info is `"info": {"side": "BACK", "size_matched": 0.0, *"size_remaining": 20,* "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}` .

I thought [https://github.com/betcode-org/flumine/blob/master/flumine/order/order.py#L39|OrderStatus.VIOLATION](https://github.com/betcode-org/flumine/blob/master/flumine/order/order.py#L39|OrderStatus.VIOLATION) is part of [https://github.com/betcode-org/flumine/blob/master/flumine/order/order.py#L49|COMPLETE_STATUS](https://github.com/betcode-org/flumine/blob/master/flumine/order/order.py#L49|COMPLETE_STATUS) so the order.size_remaining would be 0. How are you guys handling orders that go to VIOLATION status?

---

## 2023-04-17 18:49:46 - issues channel

**eugene brown**

This is with python 3.9.16 and betfairlightweight==2.17.1



The login is successful within a docker container locally however I am deploying this container within a custom training job on google cloud platform and that is where I'm experiencing this error.

---

## 2023-04-16 18:12:14 - issues channel

**eugene brown**

There is a question on the developer forum here [https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/35113-connection-error-for-betfairlightweight](https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/35113-connection-error-for-betfairlightweight) about an issue that I am also experiencing and the author was directed here.



When logging in I am getting this error. Could anyone help resolve this?



```requests.exceptions.SSLError: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4044)')))```

---

## 2023-04-16 17:05:27 - issues channel

**foxwood**

App key error as it says on the box. [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions)



Do you have a valid App key ? [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Application+Keys](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Application+Keys)

---

## 2023-04-16 10:42:19 - issues channel

**alan fisher**

Hi there. I'm a newbie trying to use Betfairlightweight python examples for the first time. I've  succeeded  in getting passed the trading.login which generates a session token but then anything I then try with the Trading object results in this error



Error: {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie2-ang08a-prd-03211101-003751a790', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie2-ang08a-prd-03211101-003751a790', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}



Can anyone give me any pointers?

---

## 2023-04-10 11:04:00 - issues channel

**Unknown**

This issue occurred again over the weekend. Everything had been running fine for over a week and then on Saturday strategy_selection_orders() stopped returning any orders again. I stopped and restarted the flumine instance and it started working again. [@U4H19D1D2](@U4H19D1D2) any idea what could be going on here? I'm on holiday at the moment so can't really debug it or look at the logs, but will take a look again when I get back.

---

## 2023-04-09 20:47:25 - general channel

**Michael**

I’m still getting the following error: 2023-04-09 20:43:47,803 - *ERROR* - *Error* accessing S3 bucket: An error occurred (AccessDenied) when calling the ListBuckets operation: Access Denied when trying to use Boto3 even though I created a user with S3FullAccess

---

## 2023-04-08 04:31:25 - issues channel

**Tom**

I'm having the same problem - I'm not sure how to fix it with client.min_bet_validation. Can we override or adjust that? How and where does it go into the code.



Part of this is learning OOP for me, I've almost got something functioning but it's still arcane

---

## 2023-04-07 08:08:14 - general channel

**Tom**

2023-04-07 17:07:41,638 - ERROR - [MarketStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 242 markets whereas max allowed number was: 200



I'm getting this bad boy, which seems like the most obvious problem

---

## 2023-04-07 07:34:17 - general channel

**Tom**

The old data isn't a huge deal for what I want to do to get it going - the goal is just to get the machinery functioning at this point - I think it's to do with the market filter but I'm not sure how to modify it, just looking through betfairlighweight docs now (but not completely sure if it will fix it)

---

## 2023-04-07 03:59:56 - general channel

**Tom**

Just looking for a bit of help with this error.



I was using the broad market filter

#     market_filter = streaming_market_filter(

#         event_type_ids=['7'],

#         country_codes=['AU'],

#         market_types=['WIN']

# ),



Then thought I would try to limit it to the number of markets I am interacting with in testing (a single event, all markets). I'm loading them in _init_ and attempting to loop through that list in the market filter with a lambda function (is that the problem?)



This is the error. It could also be because I am not logging out properly?- I have 2 files I am running, one is collecting data and the other is running strategy in flumine; I haven't figured out how to run both at the same time yet, but the idea is that the first one would manage data (inc. which markets to stream/process for bets).



betfairlightweight.exceptions.ListenerError: connection_id: 206-070423024222-349976, data: {"op":"status","id":3002,"statusCode":"FAILURE","errorCode":"MAX_CONNECTION_LIMIT_EXCEEDED","errorMessage":"You have exceeded your max connection limit which is: 2 connection(s).You currently have: 3 active connection(s).","connectionClosed":true,"connectionId":"206-070423024222-349976"}

---

## 2023-04-04 00:51:03 - issues channel

**Andy B**

Thanks Lee, I have done a bit of logging to trap the error, and it does appear at times that the marketID is non-existent even though I the market is live, but that really doesn't make sense.  I see the issue in both live scripts and back-testing of markets through flumine, so I guess I'll just have to find a market that doesn't work and step through it again.  I can check to see if the market consistently errors or if it is random, but it feels like a strange issue.

---

## 2023-04-03 23:29:26 - issues channel

**Lee**

This is something you’d need to handle, it looks like on line 231 you’re trying to access a market id in the data frame but it doesn’t exists. As it happens rarely it’s probably an edge case. You can use a try/catch with some logging to help you understand why this happens to fix the underlying issue.

---

## 2023-04-03 21:34:47 - issues channel

**Andy B**

I have had my first flumine strategy up and running for about a week and it seems to work well apart from one issue that happens inconsistently.  I'm not sure if it is relevant or not, but the strategy fires when the there is less than 5 seconds to start time and the event has not gone inplay.  I keep getting batches of the following somewhat generic error filling my log file, and I am wondering if this is a common issue that I should be handling in the code with try\catch.  I'd like to know why it happens though, rather than just ignoring it:

2023-04-03 22:02:21,329:CRITICAL:Unknown error '1.212248357' in process_market_book (1.212248357)

Traceback (most recent call last):

  File "C:\Python\lib\site-packages\pandas\core\indexes\base.py", line 3803, in get_loc

    return self._engine.get_loc(casted_key)

  File "pandas\_libs\index.pyx", line 138, in pandas._libs.index.IndexEngine.get_loc

  File "pandas\_libs\index.pyx", line 165, in pandas._libs.index.IndexEngine.get_loc

  File "pandas\_libs\hashtable_class_helper.pxi", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item

  File "pandas\_libs\hashtable_class_helper.pxi", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item

KeyError: '1.212248357'



The above exception was the direct cause of the following exception:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\flumine\utils.py", line 239, in call_strategy_error_handling

    return func(market, market_book)

  File "c:\Users\elmob\OneDrive\Punting\Scripts\Betfair\FluStrat.py", line 231, in process_market_book

    ratio_price = iggy_df.loc[market_book.market_id].loc[runner.selection_id].item() / runner.ex.available_to_back[0]['price']

  File "C:\Python\lib\site-packages\pandas\core\indexing.py", line 1073, in __getitem__

    return self._getitem_axis(maybe_callable, axis=axis)

  File "C:\Python\lib\site-packages\pandas\core\indexing.py", line 1312, in _getitem_axis

    return self._get_label(key, axis=axis)

  File "C:\Python\lib\site-packages\pandas\core\indexing.py", line 1260, in _get_label

    return self.obj.xs(label, axis=axis)

  File "C:\Python\lib\site-packages\pandas\core\generic.py", line 4049, in xs

    loc, new_index = index._get_loc_level(key, level=0)

  File "C:\Python\lib\site-packages\pandas\core\indexes\multi.py", line 3160, in _get_loc_level

    indexer = self._get_level_indexer(key, level=level)

  File "C:\Python\lib\site-packages\pandas\core\indexes\multi.py", line 3263, in _get_level_indexer

    idx = self._get_loc_single_level_index(level_index, key)

  File "C:\Python\lib\site-packages\pandas\core\indexes\multi.py", line 2849, in _get_loc_single_level_index

    return level_index.get_loc(key)

  File "C:\Python\lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc

    raise KeyError(key) from err

KeyError: '1.212248357'

---

## 2023-04-02 11:05:01 - issues channel

**Will**

Hello. Any reason when placing a trade with flumine that the order would return None. 

The market id, selection id, price and stake are valid, the trade object is created but the order object is None and I get the error “Execution unknown error. 

---

## 2023-03-30 21:05:03 - general channel

**Jesus Perdomo**

Have given it a go now - seems like the SSL cert for non-interactive login doesn't play nice with a proxy. I keep getting SSL errors when trying to login unfortunately :disappointed:



Was worth a try

---

## 2023-03-27 23:35:56 - issues channel

**Andy B**

One more error I noted in my ogs: Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (5) or payout (30) for currency.  Is this configurable in Flumine as my minimum bet sizes have been lowered by Betfair?

---

## 2023-03-26 19:17:50 - strategies channel

**birchy**

Going back to my opening post, the model I was using:



`from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error`



`# Convert the target variable to binary (0 for lose, 1 for win)

df['winner'] = df['profit'].apply(lambda x: 1 if x &gt; 0 else 0)`



`# Split data into training and test sets

features = ['sig1', 'sig2', 'sig3']`

`X_train, X_test, y_train, y_test = train_test_split(df[features], df['winner'], test_size=0.2)`



`# Instantiate a logistic regression model

model = LogisticRegression()`



`# Fit the model to the training data

model.fit(X_train, y_train)`



`# Use the model to make predictions on the test data

y_pred = model.predict(X_test)`



`# Evaluate the model's performance using appropriate metrics

accuracy = accuracy_score(y_test, y_pred)

precision = precision_score(y_test, y_pred)

recall = recall_score(y_test, y_pred)

f1 = f1_score(y_test, y_pred)

mse = mean_squared_error(y_test, y_pred)

print(f"Accuracy: {accuracy}")

print(f"Precision: {precision}")

print(f"Recall: {recall}")

print(f"F1-score: {f1}")

print(f"MSE: {mse}")`



Bearing in mind that the dataset is a bet history (BACK bets only) where all unmatched bets have been removed and 'profit' is a real-world number, would this not achieve the same result as calculating EV for training? My gut feeling is that the model is shyte, or at least the data I'm using is too optimised due to being pre-filtered by the strategy that generated it. Thoughts?

---

## 2023-03-26 05:16:12 - issues channel

**Andy B**

Ah rookie error, I'm passing an invalid price.

---

## 2023-03-26 05:13:42 - issues channel

**Andy B**

I have my first flumine strategy running and I was going to test with small stakes, but I am getting the error "Order has violated: ORDER_VALIDATION Error: Order price is not valid for CLASSIC ladder".  I am only guessing that it has something to do with the stake size, which works quite fine in bflw, but I'm not 100% sure, so just wondering if this rings a bell with anyone else?

---

## 2023-03-25 11:01:41 - issues channel

**Lee**

the default connection limit for a live key is 10 and the delayed key has a limit of 2 which is the error you are getting so might be worth double checking

---

## 2023-03-25 10:53:04 - issues channel

**Andy B**

Hi All,

I have just created my first flumine strategy after a couple of years of hacking together bflw and my own custom code.  I copied the code from [https://betfair-datascientists.github.io/api/How_to_Automate_3/?h=iggy#scrape-todays-model-ratings](https://betfair-datascientists.github.io/api/How_to_Automate_3/?h=iggy#scrape-todays-model-ratings) and then modified it with my own strategy, which I think has worked successfully, but I have just noticed a lot of errors containing the following:



betfairlightweight.exceptions.ListenerError: connection_id: 102-250323104256-6797689, data: {"op":"status","id":2007,"statusCode":"FAILURE","errorCode":"MAX_CONNECTION_LIMIT_EXCEEDED","errorMessage":"You have exceeded your max connection limit which is: 2 connection(s).You currently have: 3 active connection(s).","connectionClosed":true,"connectionId":"102-250323104256-6797689"}



This is followed by a number of:



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\flumine\streams\orderstream.py", line 51, in run

    self._stream.start()

  File "C:\Python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 67, in start

    self._read_loop()

  File "C:\Python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 226, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\Python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 248, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 1007]: Socket [WinError 10054] An existing connection was forcibly closed by the remote host

2023-03-25 21:13:30,779:INFO:Starting MarketStream 2006

2023-03-25 21:13:30,779:INFO:[Register: 2007]: Unique id updated on listener and stream

2023-03-25 21:13:31,771:INFO:[MarketStream: 2007]: connection_id: 108-250323104330-6863571

2023-03-25 21:13:32,096:ERROR:MarketStream 2007 run error

Traceback (most recent call last):

  File "C:\Python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 244, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "C:\Python\lib\ssl.py", line 1226, in recv

    return self.read(buflen)

  File "C:\Python\lib\ssl.py", line 1101, in read

    return self._sslobj.read(len)

ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host



I only have one instance running, so I am not sure what is generating these errors.  Just wondering if anyone else has experienced this or has some thoughts on what may cause it?

---

## 2023-03-24 11:50:23 - general channel

**Jesus Perdomo**

I'll be placing bets as usual (not using the API but manually) - I'm just using the API for some alerts and a prompt on my phone to place a bet. Do I need to place a bet through the API to avoid a ban? Also, thanks for advising on the session. I guess the best way would be to try and send the API request, and if failed with exception INVALID SESSION or NOT LOGGED IN then attempt to login first

---

## 2023-03-24 07:50:25 - general channel

**Herugrim**

Information from the Best Practice page:



• Logins sessions last up to 12 hours by default and you can use [https://docs.developer.betfair.com/pages/viewpage.action?pageId=3834909|Keep Alive](https://docs.developer.betfair.com/pages/viewpage.action?pageId=3834909|Keep Alive) to extend the session beyond the stated session expiry time. 

• A single session can be used across multiple API calls/threads simultaneously.  *Please note:*  *you don't need to make a new login request for every API call*.

• You should ensure that you handle the *INVALID_SESSION_TOKEN* error within your code by creating a new session token via the [https://docs.developer.betfair.com/pages/viewpage.action?pageId=3834909|API login](https://docs.developer.betfair.com/pages/viewpage.action?pageId=3834909|API login) method.

• If[https://docs.developer.betfair.com/pages/viewpage.action?pageId=3834909#Login&amp;SessionManagement-LoginRequestLimits| login limits ](https://docs.developer.betfair.com/pages/viewpage.action?pageId=3834909#Login&amp;SessionManagement-LoginRequestLimits| login limits )are exceeded, you'll be automatically prevented from making further login requests for a period of 20 minutes. During this time all existing sessions will remain valid.



---

## 2023-03-24 00:18:53 - issues channel

**Greg**

Added this but same error :

```strategy = BookmakerStrategy()

market_filter=streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["WIN"],

    )

framework.add_strategy(strategy)```



---

## 2023-03-24 00:00:34 - issues channel

**Greg**

Hi All.been away for a while.Hope you are all well. I have ben using a certain Ai engine to help teach me some python and seem to get the odd thing running. I am getting a subscription exceed error :"ERROR", "message": "[MarketStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 19639 markets whereas max allowed number was: 1000"} though, which I have noted has occurred once on this forum in the past I can find and that was referred to BF bdp. They have increases my allowed threshold to 1000 markets but have suggested I limit the market monitoring and/or increase connection threads. Here is the code snippet that looks relevant

```class BookmakerStrategy(BaseStrategy):

    market_filter = streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["GBR", "IRE", "AUS"],

        market_types=["WIN"],

    )



    def check_market_book(self, market, market_book):

        if self.seconds_to_start &gt; 600:  # 10 minutes

            return False

        if market_book.status not in ["CLOSED", "SUSPENDED"]:

            return False



    def __init__(self, market_filter=None):

        super().__init__(market_filter)

        self.race_time = 0

        self.race_started = False```

Any advice appreciated.Cheers

---

## 2023-03-23 22:11:46 - general channel

**Jesus Perdomo**

Hey guys, so glad I found this library, very cool!



Just trying to figure out what would be best practice for my use (I read the official betfair stuff but doesn't really answer the question).

My understanding is that there is a limit to how many login requests the API can receive before soft-banning. The 'best practices' page states that a single login session can carry out multiple API calls as long as it's alive. I'm trying to make an app that gets some information from the API, hopefully in the future extend it to allow betting through the app as well. The app will make some requests to find out if a particular markets exists (by searching for a team name), and what the odds are at the time of request. The app will be using non-interactive logon as it is hands-off



Would best practice be as follows? Logon --&gt; Get Data --&gt; Logout?

Or should I just keep the connection open for the next API call? - I'd say the time in-between calls can be variable, sometimes in quick succession (seconds to minutes), but most of the time it would be in the minutes to hours range.



If the best thing to do is to keep the connection open, does the API send an exception code or some other response if a session is already open?

I'm just trying to figure out how to code the logic: If already logged-in, send call, otherwise, attempt login and get a session id

---

## 2023-03-21 10:26:26 - general channel

**D C**

When I wanted to use stream API I had to make an application for it - even though I had been using the SOAP and NG API for years. They may have changed things and made streaming accessible by default but based on your error message it is probably not the case so if you have been in touch with Betfair about it you probably just need to wait for approval.

---

## 2023-03-21 10:14:12 - general channel

**Tom**

I can also get markets e.t.c. from the API, but run into this trying to execute stream.start()



betfairlightweight.exceptions.ListenerError: connection_id: 107-210323101234-6265894, data: {"op":"status","id":2,"statusCode":"FAILURE","errorCode":"NOT_AUTHORIZED","errorMessage":"AppKey is not configured for service","connectionClosed":true,"connectionId":"107-210323101234-6265894"}



I've contacted betfair about it and just waiting but thought there could be some wisdom here on it

---

## 2023-03-19 17:27:46 - random channel

**Michael**

Generally, it gets code right but the issue is more the model being natural language and therefore ambiguity, so it is right but might not do 100% what you meant it to. I saw someone suggest you could let it access your shell and then use it to iterate your code as it runs and runs into errors, very interesting use case but it would probably get itself stuck in circles at some point

---

## 2023-03-18 13:09:53 - random channel

**PeterLe**

In response to the question : summarise the key points from the book - efficiency of racetrack betting markets by william T Ziemba and which is the most optimal strategy:



"Efficiency of Racetrack Betting Markets" is a book by William T. Ziemba and Donald B. Hausch that provides a comprehensive analysis of the betting markets in horse racing. The book examines the efficiency of these markets and explores various strategies for betting on horse races. Here are the key points from the book:

1. Market efficiency: The authors argue that racetrack betting markets are relatively efficient, meaning that odds generally reflect the true probability of outcomes. However, they also point out that there are inefficiencies that can be exploited by astute bettors.

2. The favorite-longshot bias: The book discusses the well-known favorite-longshot bias, which is the tendency for bettors to overbet longshots and underbet favorites. This bias can lead to consistent losses for bettors who consistently back longshots.

3. The importance of data: The authors emphasize the importance of using data to make informed betting decisions. This includes historical data on horse performances, track conditions, and other relevant factors.

4. Handicapping: Ziemba and Hausch provide a detailed overview of various handicapping methods, such as speed ratings, pace analysis, and form analysis. They argue that successful handicapping is essential for consistently identifying value bets.

5. Optimal betting strategies: The book examines several betting strategies and their potential profitability, such as the Kelly Criterion, proportional betting, and fixed fractional betting.

6. Market efficiency and arbitrage opportunities: The authors explore the existence of arbitrage opportunities in racetrack betting markets, where bettors can lock in a profit regardless of race outcomes.

7. Risk management: The book emphasizes the importance of managing risk in betting, highlighting that the optimal betting strategy should take into account the bettor's risk tolerance and bankroll size.

The most optimal strategy, according to the authors, is using the Kelly Criterion. This betting strategy involves adjusting bet sizes based on the perceived edge and the bettor's bankroll. The Kelly Criterion is known for maximizing long-term growth while also managing risk. However, it's important to note that the success of this strategy depends on the bettor's ability to accurately estimate the true probabilities of race outcomes and identify value bets.

---

## 2023-03-18 11:48:29 - random channel

**river_shah**

Sometimes I like to bet the farm. Is that a good strategy?





Betting the farm, or wagering your entire bankroll on a single bet, is generally considered a high-risk strategy and is not advisable for most bettors. Here are several reasons why betting the farm is not a good strategy:

1. Risk of ruin: Betting your entire bankroll on a single bet exposes you to a significant risk of losing everything if the bet does not go in your favor. This can be emotionally and financially devastating, especially if you've spent a considerable amount of time building your bankroll.

2. No room for recovery: When you bet the farm, you leave no room for recovery if the bet goes against you. A more prudent approach would involve placing smaller, calculated bets that allow you to recover from losses and maintain a more consistent betting strategy.

3. Inefficient capital allocation: Betting the farm usually implies that you are overconfident about a particular outcome. However, even in situations where you have a strong edge, it is more efficient to allocate your capital across multiple bets to maximize the long-term growth of your bankroll.

4. Encourages emotional decision-making: Betting the farm can lead to emotional decision-making, as you are likely to be more concerned about the immediate outcome rather than focusing on the long-term growth of your bankroll. Emotional decisions often lead to poor results, as they are not based on a sound analysis of probabilities and odds.

A more sensible approach to betting involves using a disciplined bankroll management strategy, such as the Kelly Criterion, fixed percentage betting, or fixed-unit betting. These strategies aim to balance risk and reward, maximizing the long-term growth of your bankroll while minimizing the risk of ruin. By following a disciplined approach, you can enjoy betting while protecting yourself from significant financial losses.

---

## 2023-03-18 11:45:55 - random channel

**river_shah**

If I know favourites are over bet in signifiant horse races, what should I do?





If you believe that favorites are overbet in significant horse races, it means that the public is putting too much money on the favorite horses, causing their odds to be lower than their true probabilities of winning. In this case, you can consider the following strategies to potentially take advantage of this market inefficiency:

1. Bet on non-favorites: Focus on betting on non-favorite horses that may have higher odds than their true probabilities of winning. These horses may be undervalued due to the overbetting on the favorites, which can create potential value bets.

2. Look for value in exotic bets: Exotic bets, such as exactas, trifectas, or superfectas, involve predicting the order of finish for multiple horses in a race. Since most bettors tend to focus on favorites, there may be value in including non-favorite horses in your exotic bets.

3. Bet on races with less public attention: Large races tend to attract more casual bettors who tend to overbet favorites. By focusing on races with less public attention, you may find more accurately priced odds, allowing you to identify value bets more easily.

4. Utilize a data-driven approach: Collect and analyze historical data on horses, jockeys, trainers, and race conditions to build a predictive model. This can help you identify undervalued horses and make more informed betting decisions.

5. Implement a disciplined bankroll management strategy: To minimize your risk, use a disciplined bankroll management strategy, such as betting a fixed percentage of your bankroll on each race. This can help protect your bankroll from significant losses due to unexpected race outcomes.

6. Monitor the odds movement: Keep an eye on the odds as they change leading up to the race. You may find value bets if you can identify and capitalize on any discrepancies between the odds and your assessment of each horse's true probability of winning.

Remember, betting on horse races always involves a level of risk. While you may be able to identify value bets by exploiting the overbetting on favorites, it's essential to have a disciplined approach to bankroll management and be prepared for potential losses.

---

## 2023-03-18 10:52:49 - random channel

**PeterLe**

Do you think Chat GPT4 can make a successful trader (gambler :grinning:) even better? (Ive used GPT-3 to help me with simple code errors, but Im thinking beyond that)

---

## 2023-03-17 14:08:47 - issues channel

**Kosta Pana**

Thank you very much... I got the heartbeats showing with the above template via setting logging to debug. But I wanted to be able to use the heartbeat in my code to handle if the stream disconnects/breaks, not sure how to use it via logging (other than watching it with my eyes lol)

---

## 2023-03-17 11:06:50 - issues channel

**Andrew**

Connected to pydev debugger (build 191.7479.30)

{"asctime": "2023-03-17 10:56:16,147", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2023-03-17 10:56:16,147", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2023-03-17 10:56:16,148", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}

{"asctime": "2023-03-17 10:56:16,148", "levelname": "INFO", "message": "Adding strategy back_strat_42"}

{"asctime": "2023-03-17 10:56:16,148", "levelname": "INFO", "message": "Creating new &lt;class 'flumine.streams.marketstream.MarketStream'&gt; (2000) for strategy back_strat_42"}

{"asctime": "2023-03-17 10:56:16,148", "levelname": "INFO", "message": "Starting flumine", "clients": {"username": "", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": null, "transaction_count_total": null, "trading_controls": [], "order_stream": true, "best_price_execution": true, "paper_trade": false}, "markets": {"market_count": 0, "open_market_count": 0}, "streams": ["&lt;OrderStream(OrderStream, initial daemon)&gt;", "&lt;MarketStream(MarketStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 18028)&gt;", "&lt;WriterThread(pydevd.Writer, started daemon 11888)&gt;", "&lt;ReaderThread(pydevd.Reader, started daemon 14476)&gt;", "&lt;PyDBCommandThread(pydevd.CommandThread, started daemon 8612)&gt;"]}

{"asctime": "2023-03-17 10:56:16,293", "levelname": "ERROR", "message": "BetfairClient `login` error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\clients\\betfairclient.py\", line 29, in login\n    return self.betting_client.login()\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\betfairlightweight\\endpoints\\login.py\", line 31, in __call__\n    self.url, session=session\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\betfairlightweight\\endpoints\\login.py\", line 57, in request\n    check_status_code(response)\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\betfairlightweight\\utils.py\", line 34, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 500", "client": "APIClient", "trading_function": "login", "response": "Status code error: 500"}

{"asctime": "2023-03-17 10:56:16,509", "levelname": "INFO", "message": "Adding worker keep_alive"}

{"asctime": "2023-03-17 10:56:16,509", "levelname": "INFO", "message": "Adding worker poll_market_catalogue"}

{"asctime": "2023-03-17 10:56:16,510", "levelname": "INFO", "message": "Adding worker poll_account_balance"}

{"asctime": "2023-03-17 10:56:16,510", "levelname": "INFO", "message": "Adding worker poll_market_closure"}

{"asctime": "2023-03-17 10:56:16,512", "levelname": "INFO", "message": "BackgroundWorker keep_alive starting", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x000001823546B268&gt;", "context": {}, "start_delay": 0, "interval": 1200, "func_args": [], "func_kwargs": {}}

{"asctime": "2023-03-17 10:56:16,513", "levelname": "ERROR", "message": "Error in BackgroundWorker keep_alive: 'Flumine' object has no attribute 'clients'", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 65, in run\n    self.context, self.flumine, *self.func_args, **self.func_kwargs\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 97, in keep_alive\n    for client in flumine.clients:\nAttributeError: 'Flumine' object has no attribute 'clients'", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x000001823546B268&gt;", "context": {}}

{"asctime": "2023-03-17 10:56:16,514", "levelname": "INFO", "message": "BackgroundWorker poll_market_catalogue starting", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x000001823546B378&gt;", "context": {}, "start_delay": 10, "interval": 60, "func_args": [], "func_kwargs": {}}

{"asctime": "2023-03-17 10:56:16,516", "levelname": "INFO", "message": "BackgroundWorker poll_account_balance starting", "worker_name": "poll_account_balance", "function": "&lt;function poll_account_balance at 0x000001823546B400&gt;", "context": {}, "start_delay": 10, "interval": 120, "func_args": [], "func_kwargs": {}}

{"asctime": "2023-03-17 10:56:16,518", "levelname": "INFO", "message": "BackgroundWorker poll_market_closure starting", "worker_name": "poll_market_closure", "function": "&lt;function poll_market_closure at 0x000001823546B488&gt;", "context": {}, "start_delay": 10, "interval": 60, "func_args": [], "func_kwargs": {}}

{"asctime": "2023-03-17 10:56:16,520", "levelname": "INFO", "message": "Starting streams.."}

{"asctime": "2023-03-17 10:56:16,521", "levelname": "INFO", "message": "Starting OrderStream 1000", "stream_id": 1000, "customer_strategy_refs": "LAPTOP-SDCL040E", "conflate_ms": null, "streaming_timeout": 0.25, "client_username": ""}

{"asctime": "2023-03-17 10:56:16,522", "levelname": "INFO", "message": "Starting output_thread (OrderStream 1000)"}

{"asctime": "2023-03-17 10:56:16,523", "levelname": "INFO", "message": "[Register: 1001]: orderSubscription"}

{"asctime": "2023-03-17 10:56:16,524", "levelname": "INFO", "message": "[OrderStream: 1001]: \"OrderStream\" created"}

{"asctime": "2023-03-17 10:56:16,590", "levelname": "INFO", "message": "[OrderStream: 1001]: connection_id: 209-170323105616-5848216"}

{"asctime": "2023-03-17 10:56:16,622", "levelname": "INFO", "message": "[OrderStream: 1002]: SUCCESS (1 connections available)"}

{"asctime": "2023-03-17 10:56:16,626", "levelname": "INFO", "message": "[OrderStream: 1001]: SUCCESS (1 connections available)"}

{"asctime": "2023-03-17 10:56:16,658", "levelname": "INFO", "message": "[OrderStream: 1001]: 0 oc added"}

{"asctime": "2023-03-17 10:56:16,780", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:16,781", "levelname": "INFO", "message": "Starting output_thread (MarketStream 2000)"}

{"asctime": "2023-03-17 10:56:18,785", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:20,794", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:24,811", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:26,530", "levelname": "ERROR", "message": "Error in BackgroundWorker poll_market_catalogue: 'Flumine' object has no attribute 'clients'", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 65, in run\n    self.context, self.flumine, *self.func_args, **self.func_kwargs\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 113, in poll_market_catalogue\n    client = flumine.clients.get_betfair_default()\nAttributeError: 'Flumine' object has no attribute 'clients'", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x000001823546B378&gt;", "context": {}}

{"asctime": "2023-03-17 10:56:26,531", "levelname": "ERROR", "message": "Error in BackgroundWorker poll_account_balance: 'Flumine' object has no attribute 'clients'", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 65, in run\n    self.context, self.flumine, *self.func_args, **self.func_kwargs\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 155, in poll_account_balance\n    for client in flumine.clients:\nAttributeError: 'Flumine' object has no attribute 'clients'", "worker_name": "poll_account_balance", "function": "&lt;function poll_account_balance at 0x000001823546B400&gt;", "context": {}}

{"asctime": "2023-03-17 10:56:26,532", "levelname": "ERROR", "message": "Error in BackgroundWorker poll_market_closure: 'Flumine' object has no attribute 'clients'", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 65, in run\n    self.context, self.flumine, *self.func_args, **self.func_kwargs\n  File \"C:\\Users\\andre\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\flumine\\worker.py\", line 166, in poll_market_closure\n    for client in flumine.clients:\nAttributeError: 'Flumine' object has no attribute 'clients'", "worker_name": "poll_market_closure", "function": "&lt;function poll_market_closure at 0x000001823546B488&gt;", "context": {}}

{"asctime": "2023-03-17 10:56:32,822", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

{"asctime": "2023-03-17 10:56:48,827", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["GB", "IE"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_LTP", "EX_MARKET_DEF"], "ladderLevels": 1}, "conflate_ms": 1000, "streaming_timeout": null}

---

## 2023-03-17 10:52:27 - issues channel

**Kosta Pana**

Thanks very much Liam - I will have a try with setting logging to debug.



Do you know if setting logging to debug has any performance cost? Otherwise what is the best way to detect if a stream breaks down?

---

## 2023-03-17 10:45:39 - issues channel

**Andrew**

2023-03-16 20:59:02,419:INFO:Starting streams..

2023-03-16 20:59:02,419:INFO:Starting SimulatedOrderStream 1000

2023-03-16 20:59:02,419:INFO:Starting MarketStream 2000

2023-03-16 20:59:02,419:INFO:Starting output_thread (MarketStream 2000)

2023-03-16 20:59:02,419:INFO:[Register: 2001]: marketSubscription

2023-03-16 20:59:02,419:INFO:[MarketStream: 2001]: "MarketStream" created

2023-03-16 20:59:02,497:INFO:[MarketStream: 2001]: connection_id: 105-160323205902-5809353

2023-03-16 20:59:02,513:ERROR:MarketStream 2001 run error

---

## 2023-03-17 10:39:31 - issues channel

**liam**

Heartbeats aren't sent through the queue but if you set your logging to debug you should see them

---

## 2023-03-16 09:53:24 - general channel

**rob smith**

Seems there's more than one issue as I still get the failure message. Changing limit_order to limit_on_close_order gives me a 32602/DSC-0018 error

---

## 2023-03-13 16:02:56 - random channel

**Neil T (Betfair)**

_*"It seems that Gmax's racelist systems didn't track the post time correctly causing an hour mismatch of races, strangely it only affected the racelist feed and most internal Gmax systems weren't affected. It's been fixed now and we don't expect a repeat for tonight's fixtures but we will monitor it closely as soon as the races are added to the racelist API,*_



_*Apologies for the inconvenience caused"*_

---

## 2023-03-12 12:01:34 - issues channel

**foxwood**

Tracing back some oddball issues from the other day I discovered missing data for some markets. The logs showed connection issues with number of markets when BF published the next days GH races. I had 188 markets in the cache (rest of day + the next day). It looks like BF closed the connection for some reason (?) so Flumine automatically opened another stream but the number of markets ticked over the 200 limit. This kept repeating until 5 more markets had been closed and the count got down to 200. Any workaround for this ?



```{"asctime": "2023-03-09 19:30:47,754", "levelname": "INFO", "message": "[MarketStream: 1002] 1.211067730 removed, 188 markets in cache"}



{"asctime": "2023-03-09 19:32:40,581", "levelname": "INFO", "message": "Created marketCatalogue for 1.211115814", "market_id": ...}

{"asctime": "2023-03-09 19:32:40,581", "levelname": "INFO", "message": "Created marketCatalogue for 1.211115887", "market_id": ...}



{"asctime": "2023-03-09 19:37:27,776", "levelname": "ERROR", "message": "DataStream 1002 run error", "exc_info": "Traceback (most recent call last):\n  raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 1003]: Connection closed by server"}

{"asctime": "2023-03-09 19:37:29,784", "levelname": "INFO", "message": "Starting DataStream 1002", "stream_id": 1002, "market_filter": {"eventTypeIds": ["4339"], "marketTypes": ["WIN"], "countryCodes": ["GB"]}, "market_data_filter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "conflate_ms": null}

{"asctime": "2023-03-09 19:37:29,784", "levelname": "INFO", "message": "[Register: 1003]: Unique id updated on listener and stream"}

{"asctime": "2023-03-09 19:37:29,831", "levelname": "INFO", "message": "[FlumineStream: 1003]: connection_id: 208-090323193730-4882826"}

{"asctime": "2023-03-09 19:37:29,862", "levelname": "INFO", "message": "[FlumineStream: 1004]: SUCCESS (5 connections available)"}

{"asctime": "2023-03-09 19:37:29,894", "levelname": "ERROR", "message": "[FlumineStream: 1003]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 205 markets whereas max allowed number was: 200"}

{"asctime": "2023-03-09 19:37:29,894", "levelname": "INFO", "message": "[FlumineStream: 1003]: FAILURE (5 connections available)"}

{"asctime": "2023-03-09 19:37:45,417", "levelname": "ERROR", "message": "[FlumineStream: None]: TIMEOUT: Connection is not subscribed and is idle: 15000 ms"}

{"asctime": "2023-03-09 19:37:45,417", "levelname": "ERROR", "message": "DataStream 1003 run error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\PycharmProjects\\betfair1\\venv\\lib\\site-packages\\flumine\\streams\\datastream.py\", line 166, in run\n        raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 208-090323193730-4882826, data: {\"op\":\"status\",\"statusCode\":\"FAILURE\",\"errorCode\":\"TIMEOUT\",\"errorMessage\":\"Connection is not subscribed and is idle: 15000 ms\",\"connectionClosed\":true,\"connectionId\":\"208-090323193730-4882826\"}"}```

---

## 2023-03-11 13:55:27 - general channel

**Unknown**

Hi, I am a step closer in that this file is now going into the file and exporting the data which is excellent! The only problem now is it is only returning one market. I don't seem to get any error messages, but it just says there is one market in the cache. Apologies for taking up more of your time, but would you be able to cast an eye over this one and see if it is something painfully obvious? I have also uploaded the csv file produced which just has one match shown (and also spacing but this bit I am not as worried about!)

---

## 2023-03-10 16:16:58 - general channel

**liam**

and the error?

---

## 2023-03-10 15:11:13 - general channel

**Unknown**

Sorry to take up so much of your time, I am a bit further along but still getting some error messages when running the following script:

---

## 2023-03-10 14:26:29 - general channel

**liam**

You can just copy the original code



```with mock_patch("builtins.open", smart_open.open):

    for path in glob.iglob(file_path + "**/**/*.bz2", recursive=True):

        # create generator

        stream = trading.streaming.create_historical_generator_stream(

            file_path=path,

            listener=listener,

        )

        ...```

One thing to note is that this will write the data once complete so if there is an error it won't have recorded anything, you might want to refactor to write to file after each market

---

## 2023-03-10 10:06:35 - general channel

**liam**

Here is a hopefully an easier to understand script and considerably faster, few caveats:



• Half time isn't possible without some assumptions and/or other data

• All odds movements would be a massive list, is that what you actually want?

```import logging

import csv

import smart_open

from unittest.mock import patch as mock_patch

import betfairlightweight



COLUMNS = [

    "market_id",

    "event_date",

    "event_name",

    "country",

    "market_name",

    "selection_id",

    "selection_name",

    "result",

    "actual_sp",

    "pp_min",

    "pp_max",

    "pp_wap",

    "pp_ltp",

    "pp_volume",

    "ip_min",

    "ip_max",

    "ip_wap",

    "ip_ltp",

    "ip_volume"

]



file_path = "/Users/liampauling/Documents/tmp/marketdata/1.177242007.gz"



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



# create trading instance (don't need username/password)

trading = betfairlightweight.APIClient("username", "password", "appKey")



# create listener

listener = betfairlightweight.StreamListener(

    max_latency=None,  # ignore latency errors

    output_queue=None,  # use generator rather than a queue (faster)

    lightweight=True,  # lightweight mode is faster

    update_clk=False,  # do not update clk on updates (not required when backtesting)

    cumulative_runner_tv=True,

    calculate_market_tv=True,

)



with mock_patch("builtins.open", smart_open.open):

    # create generator

    stream = trading.streaming.create_historical_generator_stream(

        file_path=file_path,

        listener=listener,

    )

    market_data = {}  # store all data



    # loop all markets

    for i in stream.get_generator()():

        for market_book in i:

            market_id = market_book["marketId"]

            if market_id not in market_data:

                market_data[market_id] = {

                    "market_definition": market_book["marketDefinition"],

                    "selections": {

                        i["id"]: {

                            "id": i["id"],

                            "name": i.get("name"),

                            "pp_min": None,

                            "pp_max": None,

                            "pp_ltp": None,

                            "pp_volume": None,

                            "ip_min": None,

                            "ip_max": None,

                            "ip_ltp": None,

                            "ip_volume": None,

                        } for i in market_book["marketDefinition"]["runners"]

                    },

                    "inplay": False,

                    "final_market_book": None,

                }

            market = market_data[market_id]



            # update selection values when prePlay

            if market_book["status"] == "OPEN" and not market_book["inplay"]:

                for selection in market_book["runners"]:

                    selection_data = market["selections"][selection["selectionId"]]

                    if selection_data["pp_min"] is None:

                        selection_data["pp_min"] = selection["lastPriceTraded"]

                        selection_data["pp_max"] = selection["lastPriceTraded"]

                        selection_data["pp_ltp"] = selection["lastPriceTraded"]

                        selection_data["pp_volume"] = selection["totalMatched"]

                    else:

                        selection_data["pp_min"] = min(selection_data["pp_min"], selection["lastPriceTraded"])

                        selection_data["pp_max"] = max(selection_data["pp_max"], selection["lastPriceTraded"])

                        selection_data["pp_ltp"] = selection["lastPriceTraded"]

                        selection_data["pp_volume"] = selection["totalMatched"]



            # update selection values when inPlay

            if market_book["status"] == "OPEN" and market_book["inplay"]:

                for selection in market_book["runners"]:

                    selection_data = market["selections"][selection["selectionId"]]

                    if selection_data["ip_min"] is None:

                        selection_data["ip_min"] = selection["lastPriceTraded"]

                        selection_data["ip_max"] = selection["lastPriceTraded"]

                        selection_data["ip_ltp"] = selection["lastPriceTraded"]

                        selection_data["ip_volume"] = selection["totalMatched"]

                    else:

                        selection_data["ip_min"] = min(selection_data["ip_min"], selection["lastPriceTraded"])

                        selection_data["ip_max"] = max(selection_data["ip_max"], selection["lastPriceTraded"])

                        selection_data["ip_ltp"] = selection["lastPriceTraded"]

                        selection_data["ip_volume"] = selection["totalMatched"]

                        selection_data["actual_sp"] = selection["sp"]["actualSP"]



            # final book

            market["final_market_book"] = market_book



# write data to csv

with open("output_bflw_new.csv", "w") as f:

    writer = csv.DictWriter(f, fieldnames=COLUMNS)

    writer.writeheader()

    for market_id, market in market_data.items():

        market_definition = market["market_definition"]

        selection_lookup = {i["selectionId"]: i for i in market["final_market_book"]["runners"]}

        for selection in market["selections"].values():

            writer.writerow(

                {

                    # market level data

                    'market_id': market_id,

                    'event_date': market_definition["marketTime"],

                    'event_name': market_definition.get("eventName"),

                    'country': market_definition["countryCode"],

                    'market_name': market_definition.get("name"),

                    # selection level data

                    'selection_id': selection["id"],

                    'selection_name': selection["name"],

                    'result': selection_lookup[selection["id"]]["status"],

                    'actual_sp': selection["actual_sp"],

                    "pp_min": selection["pp_min"],

                    "pp_max": selection["pp_max"],

                    # "pp_wap",

                    "pp_ltp": selection["pp_ltp"],

                    "pp_volume": selection["pp_volume"],

                    "ip_min": selection["ip_min"],

                    "ip_max": selection["ip_max"],

                    # "ip_wap",

                    "ip_ltp": selection["ip_ltp"],

                    "ip_volume": selection["ip_volume"],

                }

            )```

---

## 2023-03-08 09:40:49 - betfair-news channel

**Unknown**

Morning all. Not meaning to take attention away from Neil's message above on a far more important matter but for the BSP fans....After another solid month of BSP Football, we've decided to add all Grade 2 competitions, which will more than double the number of BSP Football markets to around 4,000 per annum. This means we'll be capturing match odds markets that account for over 60% of volume but less than 10% of football fixtures, so we have headroom to explore further if there's demand. I've attached a list of all Grade 1 and 2 competitions with their current status.



We'll review again next month to see whether we should add new football markets (over/under goals, correct score) or a new sport such as golf or look at Grade 3 football. I'd be keen to hear from anyone who had a particular view on this.

---

## 2023-03-06 06:37:41 - issues channel

**jp**

A few times every week I have gotten the following exception when calling Betfair API lately:



The SSL connection could not be established, see inner exception.

 ---&gt; System.Security.Authentication.AuthenticationException: Authentication failed because the remote party sent a TLS alert: 'DecryptError'.

 ---&gt; System.ComponentModel.Win32Exception (0x80090326): The message received was unexpected or badly formatted.



I am not using Flumine/Betcode, but my own C# code. This happens when calling placeOrders or cancelOrders (and maybe others). I could send thousands of working requests before and after this, and ignoring it seems to work out ok. But it would be nice to understand what it is about. Anyone else seen it?

---

## 2023-03-03 14:23:54 - random channel

**D C**

It always misbehaves a little.... But I've seen no glaring errors today. Been 2 Steward's in the first 2 races though - 2nd race between the first 3 runners

---

## 2023-02-24 10:13:15 - issues channel

**Newbie99**

This error just randomly seems to happen from time to time, normally if you try again later it’s fine.

---

## 2023-02-24 09:17:55 - issues channel

**EJono**

I have a function set up to pull through cleared orders from record that started to fail on the 15th. Nothing has changed about the function which executes 3 times a day, depsite it working for weeks prior. This code executes in a loop with "iteration" being incremented from 0, 1, 2, 3, ... while the returned moreAvailable firled is True.



bet_status = 'SETTLED'

group_by = 'BET'

from_record = iteration *100

record_count = (iteration+1) *100



orders = trading.betting.list_cleared_orders(

            group_by=group_by,

            bet_status=bet_status,

            from_record=from_record,

            record_count=record_count,

            lightweight=True,



        )



The full exception is quite long but the final traceback handled states the following:



Traceback (most recent call last):

  File "/mnt/syndicate_middleware/adjustFunctions/betfairLadderOperations.py", line 1290, in getFilteredClearedOrders

    orders = trading.betting.list_cleared_orders(

             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/betting.py", line 434, in list_cleared_orders

    (response, response_json, elapsed_time) = self.request(method, params, session)

                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 45, in request

    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders

Params: {'betStatus': 'SETTLED', 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'BET', 'fromRecord': '0', 'recordCount': '100'}

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=16)



Ive tried messing with the parameters  ie reducing volume records requested in each call but nothing seems to be solving this issue. From docemunetation you should be able to retrieve up to 1000 records at a time. Current order requests still work fine. Anything obvious im missing for succesfully retrieving the cleared orders from record?

---

## 2023-02-23 13:36:34 - betfair-news channel

**Carl**

We've released a fix today which will take effect tomorrow to address the column headers concern i.e. they will revert back to upper case. If you can provide some more info re: the MENU_HINT issue, we will explore this too.

---

## 2023-02-21 17:34:33 - random channel

**Newbie99**

Thanks [@U016TGY3676](@U016TGY3676) it seems on some older Macs the issue may well have been to do with SMB protocol, but it seems a lot of people are suffering the same fate with the latest OS and recent M series chipsets too, so it seems like a bug at this stage (but I'll work my way through those settings and see if any help).



A bit annoying, but via SSH its fine, so that will have to do as a stopgap for now (tbh via python it doesn't matter too much anyway, SSH is fine, just a bit annoying when you want to simply drag and drop a single folder or similar)!

---

## 2023-02-21 09:05:48 - general channel

**liam**

fix your initial filter

---

## 2023-02-20 18:58:48 - general channel

**AI Trader**

Diving deeper in on Flumine, it seems to me that the inconsistency with respect to my own backtester is cause by this function:





```def _calculate_process_traded(self, publish_time: int, traded_size: float) -&gt; float:

    _traded_size = traded_size / 2

    if self._piq - _traded_size &lt; 0:

        size = _traded_size - self._piq

        size = round(min(self.size_remaining, size), 2)

        if size:

            self._update_matched(

                [

                    publish_time,

                    self.order.order_type.price,

                    size,

                ]

            )

        _matched = (self._piq + size) * 2

        self._piq = 0

        return _matched

    else:

        self._piq -= _traded_size

        if logger.isEnabledFor(logging.DEBUG):

            logger.debug(

                "Simulated order {0} PIQ: {1}".format(self.order.id, self._piq)

            )

        return traded_size```

If I understand correctly, we only assume execution if the traded amount is greater than 2 times my piq, and every time there is a trade, my piq only gets reduced by half the traded amount. If this is correct, could someone explain why you decided to make these hypotheses? [@U4H19D1D2](@U4H19D1D2), I understand that might have been done to be conservative on the execution, at the same time, this leads to further inconsistencies such as having a piq that is higher than the volume on the top of the orderbook (which is impossible).

---

## 2023-02-20 14:49:48 - random channel

**foxwood**

From my logs I had a few 503 errors on the order stream at about 13:32. Only about a dozen log entries but nothing after that. Didn't seem to affect any of my stuff but not bothered to look in detail - some on BA seemed to get hammered because greening bets were placed but not being shown as matched (presumably order stream issues) - so they closed position again and again. BF did refund one of them about £700 apparently.

---

## 2023-02-16 02:53:16 - general channel

**AI Trader**

I think I might have narrowed down the error.



To be more precise, when debugging, the code stops at line 34 (in FlumineSimulation.run() on `with self:`) [https://github.com/betcode-org/flumine/blob/aaf2e1a027a19e1bb2209a77015e16eb8c689040/flumine/simulation/simulation.py#L34](https://github.com/betcode-org/flumine/blob/aaf2e1a027a19e1bb2209a77015e16eb8c689040/flumine/simulation/simulation.py#L34), with no errors, but never ends.



I think the reason for the error is that I have created a Child class of Flumine BaseStrategy, and thus I am not reaching BaseFlumine.__exit__.



Will try to produce a minimal example tomorrow

---

## 2023-02-15 04:08:46 - general channel

**AI Trader**

Hi guys,

I am running the Flumine backtester, and for some reason the backtester never exits.

It gets stuck at self._process_end_flumine() in FlumineSimulation with no error messages or logs. Anyone had a similar issue?

I suspect there could be an error not being shown, as for some reason no erros are being logged when running in Simulation mode (using Pycharm).

---

## 2023-02-12 12:58:54 - strategies channel

**PeterLe**

OK Just found this...As I say it may well be out of date as I only tend to use 7: (It looks like  Horseracing Todays Card use to be 13?



public enum EventTypeIdEnum

    {

        [Description("Soccer")]

        Soccer = 1,

        [Description("Tennis")]

        Tennis = 2,

        [Description("Golf")]

        Golf = 3,

        [Description("Cricket")]

        Cricket = 4,

        [Description("Rugby Union")]

        RugbyUnion = 5,

        [Description("Boxing")]

        Boxing = 6,

        [Description("Horse Racing")]

        HorseRacing = 7,

        [Description("Motor Sport")]

        MotorSport = 8,

        [Description("Special Bets")]

        SpecialBets = 10,

        [Description("Cycling")]

        Cycling = 11,

        [Description("Rowing")]

        Rowing = 12,

        [Description("HorseRacing Todays Card")]

        HorseRacingTodaysCard = 13,

        [Description("Soccer Fixtures")]

        SoccerFixtures = 14,

        [Description("Greyhound Todays Card")]

        GreyhoundTodaysCard = 15,

        [Description("Rugby League")]

        RugbyLeague = 1477,

        [Description("Darts")]

        Darts = 3503,

        [Description("Athletics")]

        Athletics = 3988,

        [Description("Greyhound Racing")]

        GreyhoundRacing = 4339,

        [Description("Financial Bets")]

        FinancialBets = 6231,

        [Description("Snooker")]

        Snooker = 6422,

        [Description("American Football")]

        AmericanFootball = 6423,

        [Description("Baseball")]

        Baseball = 7511,

        [Description("Basketball")]

        Basketball = 7522,

        [Description("Hockey")]

        Hockey = 7523,

        [Description("Ice Hockey")]

        IceHockey = 7524,

        [Description("Sumo Wrestling")]

        SumoWrestling = 7525,

        [Description("Australian Rules")]

        AustralianRules = 61420,

        [Description("Gaelic Football")]

        GaelicFootball = 66598,

        [Description("Hurling")]

        Hurling = 66599,

        [Description("Pool")]

        Pool = 72382,

        [Description("Chess")]

        Chess = 136332,

        [Description("Trotting")]

        Trotting = 256284,

        [Description("Commonwealth Games")]

        CommonwealthGames = 300000,

        [Description("Poker")]

        Poker = 315220,

        [Description("Winter Sports")]

        WinterSports = 451485,

        [Description("Handball")]

        Handball = 468328,

        [Description("Badminton")]

        Badminton = 627555,

        [Description("International Rules")]

        InternationalRules = 678378,

        [Description("Bridge")]

        Bridge = 982477,

        [Description("Volleyball")]

        Volleyball = 998917,

        [Description("Bowls")]

        Bowls = 998919,

        [Description("Floorball")]

        Floorball = 998920,

        [Description("Netball")]

        Netball = 606611,

        [Description("Yachting")]

        Yachting = 998916,

        [Description("Swimming")]

        Swimming = 620576,

        [Description("Exchange Poker")]

        ExchangePoker = 1444073,

        [Description("Backgammon")]

        Backgammon = 1938544,

        [Description("GAA Sports")]

        GAASports = 2030972,

        [Description("Gaelic Games")]

        GaelicGames = 2152880,

        [Description("International Markets")]

        InternationalMarkets = 2264869,

        [Description("Politics")]

        Politics = 2378961

---

## 2023-02-12 06:48:55 - issues channel

**Andy B**

Thanks Liam, I knew that I needed to get across to Flumine at some point and this might be the clincher.  I have always prioritised worki g on building profitable models, but I do need to take a step back and take a more holistic view of my environment.

I do catch errors for most of my code, but I hadn't wrapped anything around this.  I think i'll do that as the first step while I look at how I migrate my code across to flumine and whatever changes that requires within my code.

---

## 2023-02-12 06:34:31 - issues channel

**liam**

Sounds like you are not catching errors, you will get errors.



Why aren’t you streaming? Why aren’t you using flumine?

---

## 2023-02-12 00:47:07 - issues channel

**Andy B**

Hi All,



I am trying to get to the bottom of Betfair connection issues which have cropped up in the last week.  I have a feeling it is because of the way I have implemented by strategies, because I am running 6 separate scripts which all do repeated logins to Betfair.  The error that has been randomly appearing this week is:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request

    self._validate_conn(conn)

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn

    conn.connect()

  File "C:\Python\lib\site-packages\urllib3\connection.py", line 414, in connect

    self.sock = ssl_wrap_socket(

  File "C:\Python\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket

    ssl_sock = _ssl_wrap_socket_impl(

  File "C:\Python\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl

    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)

  File "C:\Python\lib\ssl.py", line 500, in wrap_socket

    return self.sslsocket_class._create(

  File "C:\Python\lib\ssl.py", line 1040, in _create

    self.do_handshake()

  File "C:\Python\lib\ssl.py", line 1309, in do_handshake

    self._sslobj.do_handshake()

socket.timeout: _ssl.c:1105: The handshake operation timed out



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\requests\adapters.py", line 489, in send

    resp = conn.urlopen(

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen

    retries = retries.increment(

  File "C:\Python\lib\site-packages\urllib3\util\retry.py", line 550, in increment

    raise six.reraise(type(error), error, _stacktrace)

  File "C:\Python\lib\site-packages\urllib3\packages\six.py", line 770, in reraise

    raise value

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen

    httplib_response = self._make_request(

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 389, in _make_request

    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)

  File "C:\Python\lib\site-packages\urllib3\connectionpool.py", line 340, in _raise_timeout

    raise ReadTimeoutError(

urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 36, in request

    response = [http://session.post|session.post](http://session.post|session.post)(

  File "C:\Python\lib\site-packages\requests\api.py", line 115, in post

    return request("post", url, data=data, json=json, **kwargs)

  File "C:\Python\lib\site-packages\requests\api.py", line 59, in request

    return session.request(method=method, url=url, **kwargs)

  File "C:\Python\lib\site-packages\requests\sessions.py", line 587, in request

    resp = self.send(prep, **send_kwargs)

  File "C:\Python\lib\site-packages\requests\sessions.py", line 701, in send

    r = adapter.send(request, **kwargs)

  File "C:\Python\lib\site-packages\requests\adapters.py", line 578, in send

    raise ReadTimeout(e, request=request)

requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Users\elmob\OneDrive\Punting\Scripts\Betfair\Model6.py", line 649, in &lt;module&gt;

    GetBFRunners()

  File "C:\Users\elmob\OneDrive\Punting\Scripts\Betfair\Model6.py", line 164, in GetBFRunners

    greyhounds_events = trading.betting.list_events(

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\betting.py", line 123, in list_events

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 45, in request

    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listEvents

Params: {'filter': {'eventTypeIds': [4339], 'marketCountries': ['AU', 'NZ'], 'marketStartTime': {'to': '2023-02-14T00:24:32Z'}}}

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)



To clarify how my scripts run, they all begin by creating the betfair login using:

trading = betfairlightweight.APIClient(username=my_username,

                                    password=my_password,

                                    app_key=my_app_key,

                                    certs=certs_path)



trading.login()



I then get my list of races and runners from Betfair using a custom function, and I suspect this is where it is falling over every time.  I've got a hunch that when I call the BFLW functions within betting.py, the fact that I am calling the same methods multiple times across the 6 scripts is causing it to timeout because it is too many attempts or too much data requested from Betfair.



Does this sound logical or is there something else in the error code that points to the issue?  If it is the problem, what is the best method of implementing my code to manage multiple different strategies with their own independent methods in my code?



Cheers

---

## 2023-02-11 19:44:41 - issues channel

**liam**

I think it got blocked, hence the cryptic error message you are now getting 

---

## 2023-02-11 16:50:25 - issues channel

**Mikkel**

Hi all,



No matter what I do to try to connect to the API using Betfairlightweight I keep getting :



```LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE```

I have tried to change my password multiple times, but I get the same error?

---

## 2023-02-10 11:48:22 - random channel

**Unknown**

Hey Mo, here is an example of a Market that exibits the marketTime type error. Please also see my consult output on this market:

---

## 2023-02-10 11:07:48 - random channel

**Nicholas vizard**

Hey Mo thanks for your pseudo code. I have transitioned to Betfair lightweight and it has indeed resolved my issue involving the bz2 files that are missing the market_type entry. I am now able to parse the details of the markets who are missing market_type entires with market_type as NaN in my CSV, rather than skipping over them entirely. However, using betfair lightweight, I have discovered an analogous problem for bz2 files that are missing the market_time entry. Betfair lightweight is unable to handle bz2 files that are missing the market_time entry: specifically I recieve the tpye error: __init__() missing 1 required positional argument: 'marketTime'. The obvious solution is to skip these markets entirely though a try and except, however I would like to retain these markets with an NaN. Do you know if this is possible/how one would go about modifying the code so that this is the case?



Thanks again for your help

---

## 2023-02-09 21:01:26 - general channel

**Trex44**

I know lol, thought that too. Hubris, I had it in my head I had already modified it to fix on the first runner it placed a bet on.

---

## 2023-02-09 20:46:51 - general channel

**Trex44**

:weary: So obvious too. Fixed it, thanks very much.

---

## 2023-02-09 12:28:52 - random channel

**liam**

So you are using the `betfair_data` library but in 'betfairlightweight' format, therefore a bug in the Rust library, I would create an issue on the [https://github.com/tarb/betfair_data/issues|repo](https://github.com/tarb/betfair_data/issues|repo) however I am not sure how active Rob is

---

## 2023-02-09 12:21:01 - random channel

**Nicholas vizard**

Hey guys,

Hope everyone is keeping well.



I am attempting to parse Betfair historical stream data (bz2 files) to CSV using the modules Betfair_Data and Betfair Lightweight in Python.

However, when parsing the bz2 files using Betfair_Data, I am receiving the print statement _“ (JSON Parse Error) missing required field &lt;marketType&gt; at line X column Y“_, and consequently, data on the markets that exhibit this error are not included in my final csv.



*I was wondering if somebody may be able to point me to the module (or help me modify the module), such that the bz2 files that are missing the MarketType entry are still parsed with market_type = NaN, rather than excluded from consideration.* 



As a side note, I have confirmed that this issue is indeed arising because in several of the raw bz2 files provided by Betfair, the marketType entry is missing.

Any help that could be provided would be much appreciated!



Cheers!

---

## 2023-02-08 08:07:43 - general channel

**liam**

Can you share some code and the market? Not sure its possible to debug without

---

## 2023-02-07 21:39:43 - general channel

**Trex44**

```{"asctime": "2023-02-07 21:17:57,216", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.138465931", "selection_id": 10200239, "handicap": 0, "id": "138950974772156791", "customer_order_ref": "4d8a4a5a825e8-138950974772156791", "bet_id": null, "date_time_created": "2018-01-01 13:05:50.071000", "publish_time": "2018-01-01 13:05:50.071000", "market_version": null, "async": false, "trade": {"id": "e47d1976-a72c-11ed-93b3-3fe541d536d4", "strategy": "LowestLayer", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138950974772156791"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 3.7, "size": 5.0, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null, "price_ladder_definition": "CLASSIC"}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 5.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Pending", "status_log": "Pending", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "0.9912", "market_notes": null, "client": "72f36d32"}

{"asctime": "2023-02-07 21:17:57,216", "levelname": "INFO", "message": "1 order packages executed in transaction", "market_id": "1.138465931", "order_packages": [{"id": "e47d1978-a72c-11ed-93b3-3fe541d536d4", "client": "&lt;flumine.clients.simulatedclient.SimulatedClient object at 0x7f61a3560250&gt;", "market_id": "1.138465931", "orders": ["138950974772156791"], "order_count": 1, "package_type": "Place", "customer_strategy_ref": "ip-172-31-38-7", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}], "transaction_id": 1, "client_username": "72f36d32"}

Entry Bet

{"asctime": "2023-02-07 21:17:57,217", "levelname": "INFO", "message": "Trade status update: Pending", "id": "e47d1976-a72c-11ed-93b3-3fe541d536d4", "strategy": "LowestLayer", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138950974772156791"], "offset_orders": [], "notes": "", "market_notes": "3.7,3.8,3.7", "status": "Pending", "status_log": "Pending"}

{"asctime": "2023-02-07 21:17:57,218", "levelname": "INFO", "message": "Order Place: SUCCESS", "bet_id": null, "order_id": "138950974772156791", "status": "SUCCESS", "error_code": null}

{"asctime": "2023-02-07 21:17:57,218", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.138465931", "selection_id": 10200239, "handicap": 0, "id": "138950974772156791", "customer_order_ref": "4d8a4a5a825e8-138950974772156791", "bet_id": "100000000001", "date_time_created": "2018-01-01 13:05:50.071000", "publish_time": "2018-01-01 13:05:50.071000", "market_version": null, "async": false, "trade": {"id": "e47d1976-a72c-11ed-93b3-3fe541d536d4", "strategy": "LowestLayer", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138950974772156791"], "offset_orders": [], "notes": "", "market_notes": "3.7,3.8,3.7", "status": "Pending", "status_log": "Pending"}, "order_type": {"order_type": "Limit", "price": 3.7, "size": 5.0, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null, "price_ladder_definition": "CLASSIC"}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 5.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2018-01-01 13:05:50.294000", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Executable", "status_log": "Pending, Executable", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 25.65, "matched": []}, "notes": "0.9912", "market_notes": "3.7,3.8,3.7", "client": "72f36d32"}

{"asctime": "2023-02-07 21:17:57,218", "levelname": "INFO", "message": "Trade status update: Live", "id": "e47d1976-a72c-11ed-93b3-3fe541d536d4", "strategy": "LowestLayer", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138950974772156791"], "offset_orders": [], "notes": "", "market_notes": "3.7,3.8,3.7", "status": "Live", "status_log": "Pending, Live"}

{"asctime": "2023-02-07 21:17:57,220", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.138465931", "selection_id": 10200239, "handicap": 0, "id": "138950974772156791", "customer_order_ref": "4d8a4a5a825e8-138950974772156791", "bet_id": "100000000001", "date_time_created": "2018-01-01 13:05:50.071000", "publish_time": "2018-01-01 13:05:50.071000", "market_version": null, "async": false, "trade": {"id": "e47d1976-a72c-11ed-93b3-3fe541d536d4", "strategy": "LowestLayer", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138950974772156791"], "offset_orders": [], "notes": "", "market_notes": "3.7,3.8,3.7", "status": "Live", "status_log": "Pending, Live"}, "order_type": {"order_type": "Limit", "price": 3.7, "size": 5.0, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null, "price_ladder_definition": "CLASSIC"}, "info": {"side": "LAY", "size_matched": 5.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 3.7}, "responses": {"date_time_placed": "2018-01-01 13:05:50.294000", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Execution complete", "status_log": "Pending, Executable, Execution complete", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0, "matched": [[1514811950696, 3.7, 5.0]]}, "notes": "0.9912", "market_notes": "3.7,3.8,3.7", "client": "72f36d32"}

{"asctime": "2023-02-07 21:17:57,220", "levelname": "INFO", "message": "Trade status update: Complete", "id": "e47d1976-a72c-11ed-93b3-3fe541d536d4", "strategy": "LowestLayer", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138950974772156791"], "offset_orders": [], "notes": "", "market_notes": "3.7,3.8,3.7", "status": "Complete", "status_log": "Pending, Live, Complete"}

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;

SECONDS TO START = 104.043

strategy_selection_orders[Order 100000000001: Execution complete]

market.blotter.orders = [Order 100000000001: Execution complete]

market status = OPEN

runner status = ACTIVE

selection exposure = 13.5

stats = {'matched_profit_if_win': -13.5, 'matched_profit_if_lose': 5.0, 'worst_potential_unmatched_profit_if_win': 0.0, 'worst_potential_unmatched_profit_if_lose': 0.0, 'worst_possible_profit_on_win': -13.5, 'worst_possible_profit_on_lose': 5.0}

number of active runners = 8

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;

SECONDS TO START = 103.929

strategy_selection_orders[]

market.blotter.orders = [Order 100000000001: Execution complete]

market status = OPEN

runner status = ACTIVE

selection exposure = -0.0

stats = {'matched_profit_if_win': 0.0, 'matched_profit_if_lose': 0.0, 'worst_potential_unmatched_profit_if_win': 0.0, 'worst_potential_unmatched_profit_if_lose': 0.0, 'worst_possible_profit_on_win': 0.0, 'worst_possible_profit_on_lose': 0.0}

number of active runners = 8

{"asctime": "2023-02-07 21:17:58,369", "levelname": "INFO", "message": "Market 1.138465931 closed", "market_id": "1.138465931", "event_id": "28531405", "event_type_id": "7", "event_name": "Sthl 1st Jan", "market_type": "WIN", "market_start_datetime": "2018-01-01 13:10:00", "country_code": "GB", "venue": "Southwell", "race_type": null, "orders_cleared": [], "market_cleared": [], "closed": true}

{"asctime": "2023-02-07 21:17:58,370", "levelname": "INFO", "message": "Market cleared", "market_id": "1.138465931", "order_count": 1, "clients": {"Betfair": {}, "Simulated": {"72f36d32": {"username": "72f36d32", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 1, "transaction_count_total": 1, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7f61a0256950&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 1, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140057390804992)&gt;"]}

{"asctime": "2023-02-07 21:17:58,370", "levelname": "INFO", "message": "Market level cleared", "market_id": "1.138465931", "profit": 5.0, "bet_count": 1}

{"asctime": "2023-02-07 21:17:58,371", "levelname": "INFO", "message": "Market closed", "market_id": "1.138465931", "clients": {"Betfair": {}, "Simulated": {"72f36d32": {"username": "72f36d32", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 1, "transaction_count_total": 1, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7f61a0256950&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 1, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140057390804992)&gt;"]}

{"asctime": "2023-02-07 21:17:58,371", "levelname": "INFO", "message": "Removing market 1.138465931", "clients": {"Betfair": {}, "Simulated": {"72f36d32": {"username": "72f36d32", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 1, "transaction_count_total": 1, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7f61a0256950&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 1, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140057390804992)&gt;"]}

{"asctime": "2023-02-07 21:17:58,371", "levelname": "INFO", "message": "Completed historical market '/home/ubuntu/Python_projects/tmp/races/1.138465931'"}

{"asctime": "2023-02-07 21:17:58,371", "levelname": "INFO", "message": "Simulation complete"}

{"asctime": "2023-02-07 21:17:58,371", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

{"asctime": "2023-02-07 21:17:58,372", "levelname": "INFO", "message": "Shutting down Execution (BetfairExecution)"}

{"asctime": "2023-02-07 21:17:58,372", "levelname": "INFO", "message": "Client logout", "username": "72f36d32", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 1, "transaction_count_total": 1, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7f61a0256950&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}

{"asctime": "2023-02-07 21:17:58,372", "levelname": "INFO", "message": "Exiting flumine", "clients": {"Betfair": {}, "Simulated": {"72f36d32": {"username": "72f36d32", "exchange": "Simulated", "betting_client": null, "current_transaction_count_total": 1, "transaction_count_total": 1, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7f61a0256950&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}}, "BetConnect": {}}, "markets": {"market_count": 1, "open_market_count": 0}, "streams": ["&lt;HistoricalStream(HistoricalStream, initial daemon)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140057390804992)&gt;"]}

&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;

Profit: 5.00

10200239 2018-01-01 13:05:50.294000 OrderStatus.EXECUTION_COMPLETE 3.7 3.7 5.0 5.0```

---

## 2023-02-07 16:54:40 - issues channel

**Mikkel**

Doing this still gives me the same error..



payload = 'username=' + my_username + '&amp;password=' + my_password

headers = {'X-Application': my_app_key, 'Content-Type': 'application/x-www-form-urlencoded'}

resp = [http://requests.post|requests.post](http://requests.post|requests.post)('[https://identitysso-cert.betfair.com/api/certlogin',data=payload,cert=('BetfairApp1.crt','BetfairApp1.pem'),headers=headers](https://identitysso-cert.betfair.com/api/certlogin',data=payload,cert=('BetfairApp1.crt','BetfairApp1.pem'),headers=headers))

json_resp=resp.json()

SSOID = "******"



but I can login using this?

---

## 2023-02-07 09:51:08 - issues channel

**Paras Stefanopoulos**

Nope, errors if they’re not strings

---

## 2023-02-06 11:15:19 - general channel

**mzaja**

Thanks, I'll do that. Is there a quick way to check how many market subscriptions I am consuming at a given time? Or do I need to try going over the limit and catching the error?

---

## 2023-02-05 12:05:48 - general channel

**Trex44**

Thanks very much for this Peter that works. Going to try and adapt it to my strat today and see if it still works, been using a workaround involving scheduling the last week.



It looks the same as what I had built with one exception. The instance of the BetfaireClient object that is created and stored in the client var is instantiated with its orderstream parameter/attribute set to False (default value is True in the Baseflumine class). I just left it as its default value before, do you think this would have caused the error? What does this parameter/attribute actually do? Can't figure it out scouring through the code.

---

## 2023-02-02 11:14:54 - betfair-news channel

**Yosef Mentzer**

Hi, is the Historical Data API down? I am getting error 500 when I make requests and the web API does not show plans, "My Data", etc.

---

## 2023-02-01 02:21:38 - general channel

**AI Trader**

Hi guys,

What is the best way to use Flumine as a "batch process"? I.e. react to market on a fixed frequency (1h for instance) rather than at every book update? I know it wasn't designed for that, but what would be a good "hack" ? I would like this solution to also work with the backtester, so using something as checking if the time is a multiple of 1h might not work since in the backtester the time would be the local time?

---

## 2023-01-31 18:05:19 - general channel

**Newbie99**

Just to add to [@U01HQ97J5HA](@U01HQ97J5HA), there are far better people on here than I to advise, but you could modify this script:



[https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py](https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py)



Changing this section:



```event_type_ids=["7"],

        country_codes=["GB", "IE"],

        market_types=["WIN"],```

to:



```event_type_ids=["1"],

market_types=["OVER_UNDER_25"],```

Some things to consider:



1. You need to have the live key enabled for streaming (the delayed key is useless for this unfortunately)

2. You need to be placing real money bets at the same time (even if only in small size), you can't just record, otherwise you will get your account blocked

3. There are A LOT of football markets, so you may find it necessary to use multiple connections (i.e. a different connection for each OVER_UNDER_XX if you are looking at more than one)...you may find you are initially limited to 200 markets per connections and 10 connections, this can be tricky for football as if there are over 200 markets (quite likely) you will get an error! If that happens you can either try to look at market_types that have fewer live markets or speak to Betfair to get your limit increased (but referring back to point 1, you may need to be placing live orders for this to happen).

4. You can loop through the market book to get the price data and need to match the market_id &amp; selection_id (and handicap, but this will always be 0 for football) to the market_catalogue, there is an example here: [https://github.com/betcode-org/flumine/blob/master/examples/strategies/lowestlayer.py](https://github.com/betcode-org/flumine/blob/master/examples/strategies/lowestlayer.py)

That hopefully helps you get started, but of course, please feel free to ask away if you get stuck!

---

## 2023-01-30 20:47:39 - issues channel

**Mikkel**

Does anyone know how I can use betfairlightweight as a Dane? I get this error: LoginError: API login: DANISH_AUTHORIZATION_REQUIRED



But can login in through Betfair API using SSOID

---

## 2023-01-27 04:19:35 - issues channel

**Jose Maquia**

Hi guys, I'm having a problem with a project I'm working on. I'm using Flumine to get information from greyhound and horse racing data. I was able to get the data available on the Stream API but when I try to stream both (horses and greyhounds) at once I get an error saying I have too many connections (MAX_CONNECTION_LIMIT_EXCEEDED). What's the right way to achieve this?

---

## 2023-01-26 19:09:51 - general channel

**Unknown**

Ah, I see. But that still doesn't explain why you're getting what look to be authentication errors. Attached is an example 3, that first gets a list market IDs from the betting attribute, passes it to the race_cards endpoint and generates a new (filtered) list based on a condition found only there, and finally passes that into the Flumine strategy's market filter. The code works with no authentication issues, so you must be doing something subtly different.

---

## 2023-01-22 22:47:18 - general channel

**Peter**

The error message you're getting from Betfair is for an invalid session, so nothing to do with your filter or strategy. This feels more like an issue with how you're initiating your script.

---

## 2023-01-22 22:05:39 - general channel

**Trex44**

```  File "/home/ubuntu/Python_projects/initiate_strat.py", line 95, in &lt;module&gt;

    target_arr = get_filter_list()

  File "/home/ubuntu/Python_projects/initiate_strat.py", line 27, in get_filter_list

    results = trading.betting.list_market_catalogue(

  File "/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/endpoints/betting.py", line 233, in list_market_catalogue

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File "/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 55, in request

    self._error_handler(response_json, method, params)

  File "/home/ubuntu/.local/lib/python3.10/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue 

Params: {'filter': {'eventTypeIds': [7], 'marketCountries': ['GB'], 'marketTypeCodes': ['WIN']}, 'marketProjection': ['RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'COMPETITION', 'EVENT', 'EVENT_TYPE', 'MARKET_DESCRIPTION', 'MARKET_START_TIME'], 'maxResults': 100} 

Exception: None 

Error: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang05b-prd-01191051-000775c81b', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang05b-prd-01191051-000775c81b', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}```

---

## 2023-01-22 22:05:31 - general channel

**Trex44**

Wonder if anyone can help. I was trying to pass a list of market_ids as part of the market filter to a strategy. The id's are generated by filtering the markets based on information in the race_card. At the moment I am logging in using the market filter, getting all the market_ids for races then passing the market_ids to get_race_card. Then using ifnformation from the race_card I filter the market_ids and return a list of filtered market ids  to the strategy. But I get the following error . (see attached). Both the filter and strategy work fine when executed separate to one another.

---

## 2023-01-22 19:26:47 - issues channel

**foxwood**

Is the simulation supposed to delete completed bets when a non-runner / reserve is declared on uk dogs prior to the off ? Investigated a divide by zero bug of mine in a strategy which arose with a REMOVED runner that had an EXECUTION_COMPLETE order in market.blotter that predated the runner removal time - there were other runners bets also in the blotter from before the removal time. Confused about what should happen but current T&amp;Cs say "If a non-runner or reserve runner is declared, then all bets prior to the update of the market on Betfair will be void". Never checked what happens live !

---

## 2023-01-20 17:27:49 - betfair-news channel

**Carl**

Hi all,

Carl from Betfair here. _Betfair Starting Price (BSP) for new sports_ has been a discussion point in two of the last ABA's [@UNW8Q88EL](@UNW8Q88EL) has hosted on here. Following the demand from yourselves and other BSP customers, we're pleased to announce that we'll be launching the BSP on Football (Match Odds) *next week*. There will be some final testing Wednesday morning however the intention is to launch it on Wednesday 25th Jan for the Nottingham Forest v Man Utd Carabao Cup game. I'll update you here if we do have to delay launch due to unforeseen circumstances. We'll also offer it on the following fixtures as part of the first phase;



• Friday 27 Jan – Man City v Arsenal– FA Cup

• Saturday 28 Jan – All five 14:30 (UK time) Bundesliga games

• Sunday 29 Jan – All four La Liga games

A review will then take place to make sure prices are holding up but all being well, we plan to start offering BSP on all fixtures for the following competitions from Saturday 4th Feb;



• English Premier League

• Spanish La Liga

• Italian Serie A

• German Bundesliga

• UEFA Champion’s League

At the end of February, we'll undergo another review and listen to any suggestions for other competitions such as French Ligue 1 or International Football. In theory we could offer on every competition but we're keen to avoid massively skewed SP's. If all of the above is a success, we could then look at other markets and sports.



I'm disappearing for the weekend now but happy to answer any questions you have next week!

---

## 2023-01-19 13:53:00 - general channel

**liam**

When I meet people this seems to be question number 1, from profitable through to newbies. I always give the same answer which is that there is no way I would be where I am now without having worked with and spoken to those that I have met through open sourcing bflw/betcode.



You make the assumption that anyone who uses betcode libraries will make money, they are just tools. Open sourcing flumine was always a risk as its far more powerful than it lets on however it has pushed me (and others) to improve it, add features, fix bugs and is now 100x quicker than its predecessor.



The biggest change I have seen in the 'landscape' since this slack is the acceptance that you need to get value to make money. Its a secret world and think this slack is the closest you can see it in public other than the meetups :wink:

---

## 2023-01-19 12:19:14 - issues channel

**Unknown**

Hello.



I created a logic for place bet below to min size. It is work fine for market enter and for exit market in lay when the size reduction is below 4.2 (Brazilian currency). But when size reduction is above i receive the imagem error.



Is there any limit for price reduction in cancel_order method?



Many thanks for helping in this case.

---

## 2023-01-18 10:55:20 - issues channel

**D**

From what I can see, that is why you are getting the error, it is expecting to find a folder called strategies containing the marketrecorder file

---

## 2023-01-18 10:24:53 - issues channel

**James**

Making my first venture into flumine using the marketrecorder ([https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py|https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py](https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py|https://github.com/betcode-org/flumine/blob/master/examples/marketrecorder.py)). I get a “no module named strategies” error even though I’ve installed all the dependencies. What am I doing wrong?

---

## 2023-01-16 12:05:04 - random channel

**D C**

Well a market book is an ideal structure to store in a binary format surely ? It's fixed type (double/float) and fixed size. Essentially its a mulidimensional matrix at heart

---

## 2023-01-14 14:29:55 - general channel

**Jeff Waters**

Manchester United are now just one point behind City in the Premier League table: [https://www.bbc.co.uk/sport/football/premier-league/table](https://www.bbc.co.uk/sport/football/premier-league/table)



However, they are miles behind them in the Premier League winner market odds: [https://www.betfair.com/exchange/plus/football/market/1.199506934](https://www.betfair.com/exchange/plus/football/market/1.199506934)



It may well be that United have tricker fixtures still to come in the season, but even so, intuitively the gap seems way too high to me. 15.0 vs 2.1



Anyone agree/disagree?

---

## 2023-01-14 07:13:37 - issues channel

**Guy Incognito**

Yep, that fixed it. Thanks

---

## 2023-01-14 06:40:30 - issues channel

**liam**

I think [@UUCD6P13J](@UUCD6P13J) fixed this in latest version 

---

## 2023-01-14 02:00:28 - issues channel

**Guy Incognito**

Has anyone ever encountered the issue

`AttributeError: 'LimitOnCloseOrder' object has no attribute 'price_ladder_definition'`



When running simulations in flumine

---

## 2023-01-13 10:23:39 - random channel

**Unknown**

Hi All, the above issue occurs when there's a problem with our virtual stream producer, which causes invalid virtual prices to be displayed via all channels (including the Stream API).  I can confirm that there is an item on our development roadmap to fix this within Q2 this year.

---

## 2023-01-12 13:45:55 - strategies channel

**D C**

Yeah but I think that is also dependent on exactly how you are using it. Sometimes these errors can be "removed" but we will all be biased from our own perspectives and how we are dealing with it.

---

## 2023-01-12 10:56:15 - strategies channel

**D C**

I suppose if you are a large player from a volume perspective thats a great tool at your disposal. It feels like a mystery to me as I will probably replay at least half of the GPS markets visually in sync with the price feed and the GPS still has a LOT of measurement error - particularly with motion perpendicular to the racing line. I've reached a point now where I spend my time looking at non-GPS IP strats and PE stuff now. Feels like the ROI (from a time / productivity perspective) on GPS stuff has dropped off a cliff for me.

---

## 2023-01-10 10:05:26 - issues channel

**Andy**

I just used the 1.0-DELAY one, and ran the code again. No error this time. But nothing happened again

---

## 2023-01-10 10:02:47 - issues channel

**Andy**

and ran, and get this error



Traceback (most recent call last):

  File "c:\Users\Documents\Python - Problem Solving and Programming\Betfairlightweight.py", line 17, in &lt;module&gt;

    event_types = trading.betting.list_event_types()

                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\Python\Python311\Lib\site-packages\betfairlightweight\endpoints\betting.py", line 37, in list_event_types

    (response, response_json, elapsed_time) = self.request(method, params, session)

                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\Python\Python311\Lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 55, in request

    self._error_handler(response_json, method, params)

  File "C:\Users\Python\Python311\Lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listEventTypes

Params: {'filter': {}}

Exception: None

Error: {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie2-ang22a-prd-01051046-0009aa71d1', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie2-ang22a-prd-01051046-0009aa71d1', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}

---

## 2023-01-10 09:59:59 - issues channel

**Andy**

when I run the code, nothing happens, no error etc

---

## 2023-01-10 09:58:04 - issues channel

**liam**

What is the error? Do you actually have an appKey?

---

## 2023-01-10 07:06:13 - issues channel

**Andrew**

I’m embarrassed to own up to my foolishness to open my report in Excel and it truncated trailing zeroes on order ids. But I do still note the code above where customer_order_ref has hash of strategy name prefixed to order I’d.



I’ve got my cancel and place working. Thinking of using async on that. Any experiences?

---

## 2023-01-09 17:43:13 - general channel

**D**

How did you do it and what was the error message?

---

## 2023-01-09 15:12:46 - general channel

**PeterLe**

Thanks Alessio, this is just a standard drive (ie not SSD)...so if I slowing increase the setting, at some point it will be too slow and errors would occur?

---

## 2023-01-09 10:47:22 - issues channel

**Andrew**

Doesn’t customer_order_ref have a hash of the strategy name as a prefix, so they aren’t equivalent?

---

## 2023-01-08 01:07:34 - general channel

**Unknown**

Thanks [@UBS7QANF3](@UBS7QANF3), I have tried that and it still errored out?

---

## 2023-01-07 13:02:00 - general channel

**Meow**

Hey anyone know how to cancel a particular betid? I have tried this



`cancel_order_filter = betfairlightweight.filters.cancel_instruction( bet_id = '292096868384')`

`cancel_order = trading.betting.cancel_orders(instructions = cancel_order_filter)`



This snippet of code errors out.

---

## 2023-01-03 05:36:58 - random channel

**ShaunW**

It's experience that adds the zeros to your wages.  The world isn't short of bedroom programmers but finding someone who can be productive in your sphere from day 1 is hard.  Quality is an issue too, zero errors isn't a goal it determine whether you get a binbag on your desk... It's all just like any trades (work) really, given a week most people could plaster a room reasonably well but a pro will be in and out in a morning, and do it better.

---

## 2023-01-02 15:44:16 - issues channel

**D**

Flumine question - creating a LAY order using trade.create_order()  with price=40.0, bet_target_type='PAYOUT', bet_target_size=40,



I get the following order violation message and the order isn't placed:



`"WARNING", "message": "Order has violated: STRATEGY_EXPOSURE Error: Order exposure (1560.0) is greater than strategy.max_order_exposure (400)"` 



Whereas I was expecting the exposure from this order to be counted as 40 and not 1,560 - is this correct?

---

## 2022-12-30 12:41:13 - random channel

**Mo**

Administrative error by the company

---

## 2022-12-30 08:56:10 - random channel

**Paul**

In the “Against”: those licensing issues might be insurmountable, and most programming work is actually about debugging and refactoring. Every line of code in a large code base gets touched multiple times in its lifetime, and I’m not seeing any progress on AI in refactoring use cases, so it’ll be interesting to see how that progresses.

---

## 2022-12-28 15:29:33 - issues channel

**liam**

yeah just don't do this, fix it

---

## 2022-12-22 09:20:38 - issues channel

**D C**

Didn't notice at the time but after looking at logs today I can see a load of ERROR_IN_MATCHER bet placement failures around the time you sent that message.

---

## 2022-12-21 14:30:31 - issues channel

**Matthieu Labour**

Will send some code, although seems the error is coming from within flumine/betfairlightweight.

```2022-12-21 14:26:46 DEBUG    [Subscription: 3002] Sending: b'{"op": "marketSubscription", "id": 3001, "marketFilter": {"eventTypeIds": "2", "marketTypes": ["MATCH_ODDS"]}, "marketDataFilter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "initialClk": null, "clk": null, "conflateMs": 0, "heartbeatMs": null, "segmentationEnabled": true}\r\n'

2022-12-21 14:26:46 INFO     [MarketStream: 3001]: connection_id: 105-211222142646-1695898

2022-12-21 14:26:46 INFO     [MarketStream: 3002]: SUCCESS (4 connections available)

2022-12-21 14:26:46 ERROR    [MarketStream: None]: INVALID_INPUT: Failed to un-marshall: '{"op": "marketSubscription", "id": 3001, "marketFilter": {"eventTypeIds": "2", "marketTypes": ["MATCH_ODDS"]}, "marketDataFilter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "initialClk": null, "clk": null, "conflateMs": 0, "heartbeatMs": null, "segmentationEnabled": true}'

2022-12-21 14:26:46 ERROR    MarketStream 3001 run error```



---

## 2022-12-21 08:57:46 - issues channel

**R**

without code I can hazard a guess that your request to/from betfair is not formatted correctly (un-marshalling error)



But yeah, code plz

---

## 2022-12-20 23:31:08 - issues channel

**Matthieu Labour**

Hi, I am running into the following error. I am looking for guidance. I run berfairlightweight = 2.17.0 and Flumine 2.3.1. Thank you for your help.

```2022-12-20 23:27:23 ERROR    [MarketStream: None]: INVALID_INPUT: Failed to un-marshall: '{"op": "marketSubscription", "id": 3003, "marketFilter": {"eventTypeIds": "2", "marketTypes": ["MATCH_ODDS"]}, "marketDataFilter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "initialClk": null, "clk": null, "conflateMs": 0, "heartbeatMs": null, "segmentationEnabled": true}'

2022-12-20 23:27:23 ERROR    MarketStream 3003 run error

Traceback (most recent call last):

  File "/home/xxx/.cache/pypoetry/virtualenvs/s7v-trader-QDeCTrzc-py3.8/lib/python3.8/site-packages/flumine/streams/marketstream.py", line 44, in run

    self._stream.start()

  File "/home/xxx/.cache/pypoetry/virtualenvs/s7v-trader-QDeCTrzc-py3.8/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 67, in start

    self._read_loop()

  File "/home/xxx/.cache/pypoetry/virtualenvs/s7v-trader-QDeCTrzc-py3.8/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 233, in _read_loop

    self._data(received_data)

  File "/home/xxx/.cache/pypoetry/virtualenvs/s7v-trader-QDeCTrzc-py3.8/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 274, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 209-201222232723-1629057, data: {"op":"status","statusCode":"FAILURE","errorCode":"INVALID_INPUT","errorMessage":"Failed to un-marshall: '{\"op\": \"marketSubscription\", \"id\": 3003, \"marketFilter\": {\"eventTypeIds\": \"2\", \"marketTypes\": [\"MATCH_ODDS\"]}, \"marketDataFilter\": {\"fields\": [\"EX_ALL_OFFERS\", \"EX_TRADED\", \"EX_TRADED_VOL\", \"EX_LTP\", \"EX_MARKET_DEF\", \"SP_TRADED\", \"SP_PROJECTED\"]}, \"initialClk\": null, \"clk\": null, \"conflateMs\": 0, \"heartbeatMs\": null, \"segmentationEnabled\": true}'","connectionClosed":true,"connectionId":"209-201222232723-1629057"}

2022-12-20 23:27:23 DEBUG    [OrderStream: 1001]: HEARTBEAT: {'op': 'ocm', 'id': 1001, 'clk': 'ADUAJwBSAGkAaw==', 'pt': 1671578843234, 'ct': 'HEARTBEAT'}```

---

## 2022-12-16 08:58:13 - random channel

**liam**

I have a SimpleStrategy which places a single order at 1.01 on a market/selection and then cancels, invaluable for validating changes/errors etc

---

## 2022-12-13 17:52:36 - issues channel

**Liam Querido**

Well that's interesting, but I still get the same error. It doesn't seem that market_definition_fields is an input -&gt; the help page doesn't show market_definition_fields



TypeError: prices_file_to_data_frame() got an unexpected keyword argument 'market_definition_fields'

---

## 2022-12-13 13:41:07 - issues channel

**Liam Querido**

AttributeError: 'str' object has no attribute 'runners'

---

## 2022-12-13 13:41:06 - issues channel

**Liam Querido**

This is the error:

---

## 2022-12-13 13:40:56 - issues channel

**Liam Querido**

I tried the following and it gives me an attribute error.



prices_file_to_data_frame(OutputFileMarketID,OutputFileCSV,market_catalogues={"marketName":"market_name"})

---

## 2022-12-13 04:06:12 - issues channel

**Liam Querido**

Hmmm, got the following error:



TypeError: prices_file_to_data_frame() got an unexpected keyword argument 'market_definition_fields'

---

## 2022-12-11 22:18:02 - random channel

**Alessio**

It's insane it took them so long to get even a minimal fix

---

## 2022-12-11 22:08:38 - general channel

**AI Trader**

*CANCEL ORDERS BEFORE STOPPING TRADING THE MARKET*

Hi guys,

I want to cancel all my orders before I start trading the market. Currently, the way I "stop" trading it is by placing conditions on `check_market_book`

I am not sure this is the right way though, as it seem that whenever `check_market_book` returns *False*, there is no call to any function like `process_closed_market`, `finish` (see code below from `baseflumine.BaseFlumine._process_market_books`.



Could someone advise:

1 - Where should I add my condition to check if I want to stop trading the market

2 - What is the right function to override in order to close all my orders before exiting the market?



Any help is hugely appreciated. Tks



```for strategy in self.strategies:

    if utils.call_strategy_error_handling(

        strategy.check_market, market, market_book

    ):

        utils.call_strategy_error_handling(

            strategy.process_market_book, market, market_book

        )```



---

## 2022-12-11 10:53:32 - issues channel

**WaftyCrancker**

Does anyone know what might be causing the below error? It's when I try to back test using horse data. I have no issues when using greyhounds. Both are unzipped in the same way, I can't see anything obviously wrong with the files, I've tried re-unzipping them but still the same issues. Any help would be appreciated!

```File "C:\Users\Dave\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 337, in decode

    obj, end = self.raw_decode(s, idx=_w(s, 0).end())

               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\Dave\AppData\Local\Programs\Python\Python311\Lib\json\decoder.py", line 355, in raw_decode

    raise JSONDecodeError("Expecting value", s, err.value) from None

json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)```

---

## 2022-12-10 21:18:10 - general channel

**Peter**

Haven't seen it differ for horses, but I have seen differences (errors) for golf so it is possible.

---

## 2022-12-09 19:47:51 - issues channel

**AP**

Has anyone got this error when running flumine simulation on py 3.11



`UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 115: character maps to &lt;undefined&gt;`

---

## 2022-12-09 16:04:55 - general channel

**EJono**

its specifically nothing out to azure (excluding my own [http://logger.info|logger.info](http://logger.info|logger.info)("...") messages). Following the example in the docs would this be the correct way to implement both handlers such that the "proper flumine logs" are outputted  via the AzureLogHandler?



```logger = logging.getLogger()

logger.addHandler(AzureLogHandler)



custom_format = "Internal Flumine Log: %(asctime) %(levelname) %(message)"

stream_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

stream_handler.setFormatter(formatter)

logger.addHandler(stream_handler)



logger.setLevel(logging.DEBUG)```

I would like the behaviour of both handlers.

---

## 2022-12-09 08:22:26 - general channel

**liam**

What do you mean no outputs? Nothing to stdout or nothing to azure? If you want logs to stdout then you need to add `StreamHandler` as per the examples



```logger = logging.getLogger()



log_handler = logging.StreamHandler()

logger.addHandler(log_handler)

logger.addHandler(AzureLogHandler)

logger.setLevel(logging.DEBUG)```

If you want the proper flumine logs then you also want to add the `jsonlogger` formatter as per the examples

---

## 2022-12-08 15:48:10 - general channel

**EJono**

Im trying to publish the standard output logs from flumine to azure for storage but cant seem to get any outputs. Is there any reason why the below wouldnt output anything.



```from .strategies import test_strategy

from .handlers import AzureLogHandler



logger = logging.getLogger()

logger.addHandler(AzureLogHandler)

logger.setLevel(logging.DEBUG)



framework.add_strategy(test_strategy)



framework.run()```

I can see log messages i set up from inside the "process_market_book" function of "test_strategy" so im sure the handler is working correctly but nothing other than these manual messages are appearing. Do i need to refer to a specifc logger name in the "getLogger(...)" method? Does this have to execute at the root level to work correctly, iniside "__main__"? or something else?

Feel like am im missing something fundamental about logging or otherwise simple.

Cheers!

---

## 2022-12-08 11:30:29 - strategies channel

**Newbie99**

Just going back to your earlier point about less size being matched, could it be anything more complex than a drop in discretionary spending due to increased fixed living costs (hence betfair volumes are down amongst recreational punters and a higher proportion of those remaining are more likely to only take/offer value prices)?

---

## 2022-12-04 06:46:37 - general channel

**Tony**

Hi, I am very impressed with this forum and I am interested in learning more about backtesting and strategy development. I am a university student and I am unable to afford the pro data, which is quite expensive. Is there an alternative to using pro data for beginners who are just starting out? It seems that some people have run into errors when using only the free data, and while there are a few months of free, full data available, I am not sure if this would be sufficient for testing the significance of a strategy. Thanks all for your help

---

## 2022-12-03 16:47:59 - issues channel

**D C**

I'm not a BFLW user so not sure what the member variables would be called. You get a list of PlaceExecutionReports - iterate over that list and get the instruction report error code - that should contain details like INVALID_ODDS etc.

---

## 2022-12-03 16:28:23 - issues channel

**Michael**

How do I find the reason for ERROR_IN_ORDER? Not sure what "The action failed because the parent order failed" means

---

## 2022-12-03 14:09:31 - general channel

**D C**

But surely if the market conditions are right then why not. Unless you can be certain of the lag on the feed on which you watched it, you can't 100% match visual event with market response can you? If the race looked innocuous then probably just an error that soaked up everything available? At those high prices the volumes are usually pretty thin from what I see in general. XM can only do so much especially at the higher price end.

---

## 2022-11-28 18:34:03 - random channel

**Newbie99**

Nope, logs all read as normal, no errors at all. I can however see that it wasn't sending cancel requests for a chunk of the day, so the problem definitely occuered at my end.

---

## 2022-11-28 16:34:44 - random channel

**Newbie99**

I finally got round to re-running the data from Saturday and it all worked fine, no errors, orders were cancelled as expected looking at the backtest results. So what happened in reality is a complete mystery :man-shrugging:

---

## 2022-11-27 15:29:56 - general channel

**AI Trader**

Thanks ! Is there a way to add a callback and only add market based on information on the market_catalogue? Such as time to start and volume traded? Of course, I could do that check_market_book, but I think I wouldn't even be able to get there in the code as I would get the subscribing to &gt; 200 markets error before.



Is this the right way to go? Or am I missing smth? I guess that approach would work whenever bdp will increase my limit

---

## 2022-11-27 12:20:46 - random channel

**liam**

I don’t have any serious errors from yesterday 

---

## 2022-11-26 19:09:40 - random channel

**Newbie99**

I suspect the answer is no, but did anyone notice any strange data from Betfair (football or horses) today (sorry thats a bit vague as I'm not sure what I'm looking for precisely)?



In short, for no apparent reason (that I can see), all strategies I'm running across football and horse racing didn't cancel any orders after 11:00 this morning (so I've only been getting filled @ -EV prices all day), I have made no code changes and there are no errors in the logs (the logs show no cancel request appears to have been sent).



Therefore all I can assume is that some data is being mishandled at my end (probably something stupid like a None value instead of whatever it should be), but I'm struggling to find what it could be (I've restarted the EC2 instance and its working fine now).



Appreciate its almost certainly just something weird that I have done, but just thought I'd check on the off chance anyone spotted any weird streaming data (I have it recorded so if there is anything should be able to find it and hopefully replicate, just wanted to save time in case anyone else had come across anything).

---

## 2022-11-26 18:08:34 - general channel

**AI Trader**

[@U4H19D1D2](@U4H19D1D2)

I tried to add a `betfairlightweight.filters.market_filter` filter so that I could also filter by market_start_time, but I am getting almost 10_000 markets, whereas I should be getting less than 300. Any ideas why?

I used the below filter as a *market_filter* for the BaseStrategy, which returns the below error:

```filter = betfairlightweight.filters.market_filter(event_type_ids=["1"], market_start_time={'from': '2022-11-26T23:31:33Z', 'to': '2022-11-28T17:31:33Z'})```

`{"asctime": "2022-11-26 17:52:58,912", "levelname": "ERROR", "message": "[FlumineStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 9866 markets whereas max allowed number was: 200"}`



It says there are 9866 markets passing this filter, but if I manually check it through:

```all_event_ids = [event.event.id for event in self.trading.betting.list_events(filter=filter)]```

I get only 232 event ids (and there should be a single market_id per event ids as I am only fetching MATCH_ODDS., which is way smaller than the number of market_ids the BaseStrategy complains about (9866)



Below is the code Ive used for the BaseStrategy:

```framework = Flumine(client=client)

strategy = S3MarketRecorder(

    name="WIN",

    market_filter=filter,

    stream_class=DataStream,

    context={

        "local_dir": "./bet_data_temp",

        "force_update": False,

        "remove_file": True,

        "remove_gz_file": True,

        "bucket" : bucket,

    },

)```



---

## 2022-11-26 17:12:35 - general channel

**AI Trader**

Hi gents,

Questions related to *BaseStrategy:*

Q1 : It receives  `market_filter` and `market_data_filter` as arguments. Does it automatically update the markets based on these filters? Eg.: If on day 24 Nov the Market M doesn't pass through the filters, but on day 25 Nov it does, will the strategy automatically include this market on Nov 25 without me restarting the code? If not, is there an alternative to restarting the code every X hours? As it would stop the strategy during the restart time, which is risky for trading and would make me loose data for data recording.



Q2: I am trying to find a way to filter markets for which I want to store data using the *MarketRecorder* strategy in the examples.

I want to fetch football matches, but if I filter by:

```market_filter=betfairlightweight.filters.streaming_market_filter(

    event_type_ids=["1"],

    market_types=["MATCH_ODDS"],

    betting_types=["ODDS"],

),```

 I get:

`{"asctime": "2022-11-26 16:40:19,795", "levelname": "ERROR", "message": "[FlumineStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 505 markets whereas max allowed number was: 200"}`



I could obviously get a reduced number of  market_ids myself by doing:

```filter = betfairlightweight.filters.market_filter(event_type_ids=[1], market_start_time={'from': datetime_from, 'to': datetime_to})

self.trading.betting.list_events(filter=filter)```

But then I would have static ids and certainly would have to restart the program to fetch the new markets, which is a problem as described above.



What would be the recommended way to reduce the subset of markets while avoiding having static market_ids ?

---

## 2022-11-25 15:01:52 - random channel

**river_shah**

I tried, so many errors. qemu crashes and bugs

---

## 2022-11-22 14:04:30 - strategies channel

**R**

you might be right, the word "eigenvector" is involved so that tends to make people run screaming in terror :joy:

---

## 2022-11-22 14:03:04 - strategies channel

**river_shah**

Sorry if I am being very dense but why is it called Brier score? isn't it `mean_squared_error` applied to random variables bounded [0, 1]. Unrelated to the actual post, which I will go through. Thanks for posting

---

## 2022-11-21 02:35:46 - general channel

**AI Trader**

Hi guys,

I'm running my flumine instance in the cloud with the Middleware available in the examples for retrieving EXECUTION_COMPLETE orders whenever the program restarts. When running the same code locally, the middleware fails to retrieve the orders that were placed by the program in the cloud due to the strategy_name_hash `(current_order.customer_order_ref[:STRATEGY_NAME_HASH_LENGTH])` being different (even though the strategy name is the same both locally and in the cloud). I need help figuring out why this is happening, as  `customer_order_ref` should only depend on the strategy name? Any hints would be hugely appreciated as I have spent a lot of time trying to debug this with no success. The fact that orders only store the hash of the strategy name makes it more difficult to figure out if for some undesired reason my code is changing the strategy name.

---

## 2022-11-20 15:28:36 - general channel

**AI Trader**

[@U4H19D1D2](@U4H19D1D2) Sorry, let me make it more clear:



When using the `_create_order_from_current()` (see in the middleware example [https://github.com/betcode-org/flumine/blob/47af44b2173cf9d6b32fd9daef22dae510adea3f/examples/middleware/orders.py#L45](https://github.com/betcode-org/flumine/blob/47af44b2173cf9d6b32fd9daef22dae510adea3f/examples/middleware/orders.py#L45)), I get None in `strategy = self.flumine.strategies.hashes.get(strategy_name_hash)`

This entails that none of my previous orders gets created when the program restarts, as I get the error :

{"asctime": "2022-11-20 15:23:35,051", "levelname": "WARNING", "message": "OrdersMiddleware: Strategy not available to create order 138876445504398400", "bet_id": "287696652099", "market_id": "1.197093506", "customer_strategy_ref": "menoci", "customer_order_ref": "5458cb00631fc-138876445504398400", "strategy_name": "None", "client_username": "[mailto:xxxxx@gmail.com|xxxxx@gmail.com](mailto:xxxxx@gmail.com|xxxxx@gmail.com)"}

---

## 2022-11-19 15:20:48 - issues channel

**Charlie Daragon**

```HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x43c5d28&gt;: Failed to establish a new connection: [Errno 50] Protocol not available'))```



---

## 2022-11-19 15:20:44 - issues channel

**Charlie Daragon**

Hi I am getting a connection error when trying to use Betfair API - anyone know how to help?

---

## 2022-11-17 11:51:25 - general channel

**Mo**

You definitely need to be robust to random HTTP errors

---

## 2022-11-17 09:19:50 - general channel

**Aaron Smith**

i think that would raise some error, it needs to be executable. Dont worry about the milliseconds the bet is up. I m doing the same as you are right now and all is good on my end.

---

## 2022-11-16 11:01:43 - issues channel

**Lee**

What version of flumine are you running? I believe this was fixed in 2.2.3

---

## 2022-11-16 10:59:35 - issues channel

**Peter C**

I have an issue that sometimes appears after a `connection closed by server` error. When the flumine strategy reconnects, it can sometimes get stuck in a cancelling loop. My cancel logic checks whether an order has Executable status, and then cancels based on time executable. Sometimes after a reconnect the strategy attempts to cancel an order, and this transaction fails as `bet_taken_or_lapsed`. The strategy will continually try to cancel these orders, so I'm wondering what the best way to avoid this is.

---

## 2022-11-15 21:39:44 - random channel

**V**

The arguments need to be hashable, since under the hood that decorator pretty much just uses a dictionary keyed by the args. Don’t think a RunnerBook is hashable so I’d expect a call to that func to just raise an exception.

---

## 2022-11-14 15:22:17 - general channel

**Jorge**

Hi, I am debugging an inplay market where I run flumine. The live log indicates an order was placed but I cannot see this order anywhere in the betfair website or quering `trading.betting.list_cleared_orders`



```2022-11-13 14:53:25,981 | INFO | a | a | Order status update: Pending

2022-11-13 14:53:25,982 | INFO | a | a | Deleting requests.Session

2022-11-13 14:53:25,982 | INFO | a | a | New requests.Session created

2022-11-13 14:53:25,987 | INFO | a | a | Thread pool submit

2022-11-13 14:53:25,987 | INFO | a | a | 1 order packages executed in transaction

2022-11-13 14:53:31,266 | INFO | a | a | execute_place

2022-11-13 14:53:31,267 | INFO | a | a | Trade status update: Pending

2022-11-13 14:53:31,267 | INFO | a | a | Order Place: SUCCESS

2022-11-13 14:53:31,267 | INFO | a | a | Order status update: Executable

2022-11-13 14:53:31,267 | INFO | a | a | Trade status update: Live

2022-11-13 14:53:31,505 | INFO | a | a | Order status update: Execution complete

2022-11-13 14:53:31,505 | INFO | a | a | Trade status update: Complete```

Any idea what could have happened?

---

## 2022-11-13 06:11:07 - general channel

**liam**

The best case scenario you describe is the only acceptable scenario, if it isn't you fix it

---

## 2022-11-12 17:43:09 - general channel

**liam**

You would want to monitor this but it will be number of orders that tends to cause problems (&gt;1k per market) Simple fix is to split up markets and run a flumine instance per split but you are probably over complicating things 

---

## 2022-11-12 16:43:45 - general channel

**liam**

Assumption are:



• you would never want to miss an update

• make sure your strategies can process quicker than a new book update 

• If you find this is a limitation then flumine isn’t for you (although I would fix the slow strategies)

• Workers are for polling type situations (

ie. external data update)

• Middleware gets called on every marketBook update (similar to django request/response cycle / middleware)

---

## 2022-11-12 16:02:36 - general channel

**Carlos M**

Fixed

---

## 2022-11-09 13:27:19 - general channel

**FT**

Problem solved: I had a small but catastrophic typo in the `process_orders` function. An exception lead to the orders beeing stuck in PENDING until the end.

---

## 2022-11-09 13:11:50 - general channel

**liam**

without some code to replicate very hard to debug this

---

## 2022-11-07 22:03:11 - issues channel

**Mikkel**

```ConnectionError: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x7ff2a218bee0&gt;: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))```

Can someone help with this error when trying to connect through the API?

---

## 2022-11-07 20:08:28 - betconnect channel

**Unknown**

But I get a validation error

---

## 2022-11-06 14:31:27 - general channel

**liam**

Tbh I don’t understand, what are you using to develop, just open up the debugger 

---

## 2022-11-06 09:13:45 - general channel

**Jeff Waters**

That seems to have fixed the issue. Thank you, Mo.

---

## 2022-11-05 20:10:37 - issues channel

**liam**

Looks like you are giving it a compressed file, smart_open is the easy fix 

---

## 2022-11-05 20:08:49 - issues channel

**Unknown**

I've written a back testing app: [https://github.com/JeffW12345/Basic-Betfair-Backtesting-App](https://github.com/JeffW12345/Basic-Betfair-Backtesting-App)



I get the attached error message. When I googled this message, I get this SO article: [https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character](https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character)



Following the article's advice, I tried changing line 66 of utils.py to:



```with open(file_dir, "r", encoding="utf8") as f:```

However, I then got a different error message: UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcd in position 10: invalid continuation byte



I'm using JSON files supplied by Betfair.



Any suggestions would be much appreciated.



Thanks

---

## 2022-11-04 13:31:16 - random channel

**liam**

just email TPD, they are quick to respond and monitor the error on each race

---

## 2022-11-03 22:40:51 - random channel

**Aaron Smith**

you should not compare floats with ==, due to floating-point errors, where it would return false even though the values should be equal. Try math.isclose() instead.

---

## 2022-11-03 16:44:06 - general channel

**liam**

without seeing some code this is very tricky to debug...

---

## 2022-11-02 18:56:43 - issues channel

**Mikkel**

Does anyone know if the API works from Denmark? I keep getting this..



```LoginError: API login: DANISH_AUTHORIZATION_REQUIRED```



---

## 2022-11-02 11:14:26 - issues channel

**liam**

```config.raise_errors = True```

---

## 2022-11-02 11:13:53 - issues channel

**river_shah**

[@U4H19D1D2](@U4H19D1D2) this was asked a while ago but sorry I can't find answer in search. How do I force process termination if I hit something like this please?

```CRITICAL[flumine.utils:call_strategy_error_handling:246] Unknown error xxx```

---

## 2022-11-01 11:47:12 - issues channel

**Guy Incognito**

Anyone ever has this issue before? Using the simulation client in flumine using purchased data. Tested it out with a few data files and all had this issue. I've even checked if runner.status is active before placing any bets



2022-11-01 22:42:25,440:CRITICAL:198:Trade error in 416eae93-59da-11ed-8a6c-6c2b59d9baa8

 Traceback (most recent call last):

   File "C:\Users\VL\Documents\virtual_environments\backtest\lib\site-packages\flumine\execution\simulatedexecution.py", line 42, in execute_place

     simulated_response = order.simulated.place(

   File "C:\Users\VL\Documents\virtual_environments\backtest\lib\site-packages\flumine\simulation\simulatedorder.py", line 87, in place

     if runner.status == "REMOVED":

 AttributeError: 'NoneType' object has no attribute 'status'

---

## 2022-11-01 06:28:49 - issues channel

**Muhammad Adeel Zahid**

Ok, when I try to run the following code

```trading = betfairlightweight.APIClient(username = my_username, password = my_password, app_key = my_app_key, certs=certs_path)

trading.login()

market_id = "1.199777126"

selection_id = 31484513

resources = trading.race_card.get_race_card(market_ids=[market_id])

print(resources)```

I get the exception

`Traceback (most recent call last):`

  `File "E:\Git\betfair\dailyracevenuedatagrabber.py", line 37, in &lt;module&gt;`

    `resources = trading.race_card.get_race_card(market_ids=[market_id])`

  `File "E:\Git\betfair\venv\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 59, in get_race_card`

    `raise RaceCardError(`

`betfairlightweight.exceptions.RaceCardError: You need to login before requesting a race_card`

`APIClient.race_card.login()`

when I change `trading.login()` to `trading.race_card.login()`

I get the following exception

`Traceback (most recent call last):`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen`

    `httplib_response = self._make_request(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request`

    `self._validate_conn(conn)`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connectionpool.py", line 1040, in _validate_conn`

    `conn.connect()`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connection.py", line 414, in connect`

    `self.sock = ssl_wrap_socket(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\util\ssl_.py", line 449, in ssl_wrap_socket`

    `ssl_sock = _ssl_wrap_socket_impl(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\util\ssl_.py", line 493, in _ssl_wrap_socket_impl`

    `return ssl_context.wrap_socket(sock, server_hostname=server_hostname)`

  `File "C:\Users\adeel\AppData\Local\Programs\Python\Python310\lib\ssl.py", line 512, in wrap_socket`

    `return self.sslsocket_class._create(`

  `File "C:\Users\adeel\AppData\Local\Programs\Python\Python310\lib\ssl.py", line 1070, in _create`

    `self.do_handshake()`

  `File "C:\Users\adeel\AppData\Local\Programs\Python\Python310\lib\ssl.py", line 1341, in do_handshake`

    `self._sslobj.do_handshake()`

`ssl.SSLError: [SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\adapters.py", line 440, in send`

    `resp = conn.urlopen(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen`

    `retries = retries.increment(`

  `File "E:\Git\betfair\venv\lib\site-packages\urllib3\util\retry.py", line 592, in increment`

    `raise MaxRetryError(_pool, url, error or ResponseError(cause))`

`urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='[http://www.betfair.com|www.betfair.com](http://www.betfair.com|www.betfair.com)', port=443): Max retries exceeded with url: /exchange/plus/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)')))`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "E:\Git\betfair\venv\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 28, in login`

    `response = session.get(self.login_url)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\api.py", line 75, in get`

    `return request('get', url, params=params, **kwargs)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\api.py", line 61, in request`

    `return session.request(method=method, url=url, **kwargs)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\sessions.py", line 529, in request`

    `resp = self.send(prep, **send_kwargs)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\sessions.py", line 645, in send`

    `r = adapter.send(request, **kwargs)`

  `File "E:\Git\betfair\venv\lib\site-packages\requests\adapters.py", line 517, in send`

    `raise SSLError(e, request=request)`

`requests.exceptions.SSLError: HTTPSConnectionPool(host='[http://www.betfair.com|www.betfair.com](http://www.betfair.com|www.betfair.com)', port=443): Max retries exceeded with url: /exchange/plus/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)')))`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "E:\Git\betfair\dailyracevenuedatagrabber.py", line 34, in &lt;module&gt;`

    `trading.race_card.login()`

  `File "E:\Git\betfair\venv\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 30, in login`

    `raise APIError(None, self.login_url, None, e)`

`betfairlightweight.exceptions.APIError: [https://www.betfair.com/exchange/plus/](https://www.betfair.com/exchange/plus/)` 

`Params: None` 

`Exception: HTTPSConnectionPool(host='[http://www.betfair.com|www.betfair.com](http://www.betfair.com|www.betfair.com)', port=443): Max retries exceeded with url: /exchange/plus/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:997)')))`

Please note that my certificate setup and credentials are correct as I am able to use other API methods like `trading.betting.list_market_catalogue` . What could be the reason of this exception for this particular endpoint?

---

## 2022-10-31 20:21:06 - issues channel

**Mikkel**

Hi, can someone help with this error in the python API?



```Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4067)')))```



---

## 2022-10-31 10:21:01 - betconnect channel

**Beeblebrox**

Ha ha - classic error! Thanks

---

## 2022-10-27 11:01:01 - issues channel

**liam**

Should now be fixed

---

## 2022-10-25 17:48:52 - strategies channel

**Alessio**

Very interesting question. I don't have a good answer for you but the way I do it is that I do two scorings. The first one is by chopping the time of the event in 5-10 mins intervals, and looking at only the ones at the beginning of the window. This is to kind of evaluate the 'baseline' model. The second one, is that i look for changes in the odds OR the model (derivatives) and evaluate a random subset of fixed size per event. For each of these changes, I look X seconds before.

---

## 2022-10-24 19:59:59 - issues channel

**Beeblebrox**

I'm paper trading a strat on a TOTAL_POINTS_LINE market, but I'm getting an ORDER_VALIDATION error:



```{"asctime": "2022-10-24 18:48:19,823", "name": "flumine.controls", "levelname": "WARNING", "message": "Order has violated: ORDER_VALIDATION Error: Order price is not valid", "control": "ORDER_VALIDATION", "error": "Order price is not valid", "order": {"market_id": "1.205496414", "selection_id": 105545, "handicap": 0, "id": "138859300988413659", "customer_order_ref": "354b9995c9ce8-138859300988413659", "bet_id": null, "date_time_created": "2022-10-24 18:48:18.842366", "publish_time": null, "market_version": null, "async": null, "trade": {"id": "6be453dd-53cc-11ed-a6ba-001b213a8a25", "strategy": "NBABackOvers", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138859300988413659"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 233.0, "size": 10, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 10.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: ORDER_VALIDATION Error: Order price is not valid", "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}}```

In these markets the back prices are the unders value and the lay prices are the overs value. The actual price is always 2.0.  So for the example above, I tried to place a bet on the overs at 233.0, but this trips up the order validation stuff here: [https://github.com/betcode-org/flumine/blob/b59a077e5e3d09e5042de5438677782e4be330f8/flumine/controls/tradingcontrols.py#L53](https://github.com/betcode-org/flumine/blob/b59a077e5e3d09e5042de5438677782e4be330f8/flumine/controls/tradingcontrols.py#L53)

---

## 2022-10-23 15:58:18 - general channel

**Mo**

They had some problems with that endpoint a couple of days ago. Should be fixed now

---

## 2022-10-21 11:22:41 - issues channel

**EJono**

ah right ok i will bear that in mind when handling the error. I'm not as proficient with flumine and utilising the streaming api as I would like to be, at this stage. In the process of learning but not there yet

---

## 2022-10-21 11:17:40 - issues channel

**EJono**

I am encountering an error every hour or so which I cant seem to repeat, stemming from a list_market_book request. The strategy runs every 2 minutes or so across ~100 markets. The traceback of the error appears to be timeout related but im not sure how to tackle whatever is causing it.



`market_books = trading.betting.list_market_book(`

  `File "/usr/local/lib/python3.10/site-packages/betfairlightweight/endpoints/betting.py", line 283, in list_market_book`

    `(response, response_json, elapsed_time) = self.request(method, params, session)`

  `File "/usr/local/lib/python3.10/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 45, in request`

    `raise APIError(None, method, params, e)`

`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': ['1.205155225'], 'priceProjection': {'priceData': ['EX_ALL_OFFERS'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}` 

`Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)`



 `SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': ['1.205155225'], 'priceProjection': {'priceData': ['EX_ALL_OFFERS'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}` 

`Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)`



On follow up runs  on the same market 2 mins later the issue no longer occurs. Anyone familiar with this problem or have encountered it before and know how to addres it? Cheers

---

## 2022-10-19 12:31:04 - issues channel

**Mick**

I just got a TOO_MUCH_DATA error when calling list_market_book() with a list of 40 races. So I can read less at once - but is there any way to know in advance whether or not I will get this error again? Using try/except feels kinda yucky.

---

## 2022-10-18 12:52:57 - issues channel

**Artiom Giz**

Hello!

I have an issue with *Java* code ([https://github.com/betfair/stream-api-sample-code](https://github.com/betfair/stream-api-sample-code))

• Cloned the code :white_check_mark:

Running `mvn install` :

• *Build worked* (after adding javax.annotation to pom.xml) :white_check_mark:

• *Tests fail* (mostly "StartStop", sometimes single test, sometimes two or three) :eyes:

Q1: Somebody might be met this issue? Or say something about it (fix/remove tests/...)?

Q2: Is this code widely used and supported?

Q3: Trying to understand the best way to combine my existing Java env with BF.  I see a lot of information about Python libs: *betfairlightweight* or *flumine*. Worth using them or it's the same (from support/problems POV)?



Thanks in advance, really appreciate!

---

## 2022-10-18 07:44:04 - issues channel

**liam**

There is a log that I assume you have stripped out that looks like this which might explain things



`DEBUG | [Subscription: 2] Sending: b'{"op": "authentication", "id": 2, "appKey": "test", "session": "test"}`

---

## 2022-10-18 04:21:37 - issues channel

**Liam Querido**

Hi Liam, thanks for your help. Below are the logs and the traceback.



DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

INFO:betfairlightweight.streaming.listener:[Register: 1]: marketSubscription

INFO:betfairlightweight.streaming.stream:[MarketStream: 1]: "MarketStream" created

Traceback (most recent call last):



  File "&lt;ipython-input-1-5f9601b88fb7&gt;", line 46, in &lt;module&gt;

    streaming_unique_id = stream.subscribe_to_markets(



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 145, in subscribe_to_markets

    self._send(message)



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 285, in _send

    self.authenticate()



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 96, in authenticate

    self._send(message)



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 287, in _send

    message_dumped = json.dumps(message)



  File "C:\Users\liamq\anaconda3\lib\json\__init__.py", line 231, in dumps

    return _default_encoder.encode(obj)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 199, in encode

    chunks = self.iterencode(o, _one_shot=True)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 257, in iterencode

    return _iterencode(o, 0)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 179, in default

    raise TypeError(f'Object of type {o.__class__.__name__} '



TypeError: Object of type bytes is not JSON serializable

---

## 2022-10-16 23:48:35 - issues channel

**Liam Querido**

Unfortunately yes, I also tried running in Jupyter Notebook, but I am getting the exact same error. Do I perhaps need to update some packages?

---

## 2022-10-15 09:58:06 - issues channel

**liam**

Do you get the same error running it from python via console 

---

## 2022-10-15 02:52:06 - issues channel

**Liam Querido**

Hi Liam. I tried running the example code you shared with me, but I'm getting the same error = "TypeError: Object of type bytes is not JSON serializable."



Do you have any idea what could be causing it? Even with DEBUG I am still unsure. Thanks in advance for your help.

---

## 2022-10-14 12:42:47 - issues channel

**Aaron Smith**

sadly not, this results in an import error

---

## 2022-10-13 15:52:25 - issues channel

**Aaron Smith**

trying to profile my code turns out to be harder than expected. I already call my code with

`python -m bla.bla.bla` , and seemingly you cant give another `-m`  argument (which would be needed for `-m cprofilev` ). I tried to fix this some time ago to not have to use the `-m` , but it seems i m to dumb for imports in python :smile: I cant seem to find a solid solution that doesnt feel hacky

---

## 2022-10-13 15:07:04 - general channel

**liam**

its just an API client/wrapper, if it can't access the API then you are just going to get errors :man-shrugging:

---

## 2022-10-13 13:07:31 - issues channel

**liam**

you might be surprised, common error to pass in an incorrect var, anyway run [https://betcode-org.github.io/flumine/performance/#cprofile|this](https://betcode-org.github.io/flumine/performance/#cprofile|this) and share the output (dm if you want) and you will know the answer straight away

---

## 2022-10-13 13:05:55 - issues channel

**Aaron Smith**

understandable, now that you point it out, i ll fix that aswell. Pretty doubtful that will solve my issue though :smile:

---

## 2022-10-13 09:59:57 - issues channel

**liam**

Not sure where you got that example from but in the [https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py|examples](https://github.com/betcode-org/betfair/blob/master/examples/examplestreaming.py|examples) we have some logging setup, if you set to DEBUG it might show the issue

---

## 2022-10-13 07:28:44 - issues channel

**Liam Querido**

Hi Liam, thanks for your prompt response. Below is the traceback.



Traceback (most recent call last):



  File "&lt;ipython-input-3-131767784cbe&gt;", line 1, in &lt;module&gt;

    betfair_socket.subscribe_to_markets(



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 145, in subscribe_to_markets

    self._send(message)



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 285, in _send

    self.authenticate()



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 96, in authenticate

    self._send(message)



  File "C:\Users\liamq\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 287, in _send

    message_dumped = json.dumps(message)



  File "C:\Users\liamq\anaconda3\lib\json\__init__.py", line 231, in dumps

    return _default_encoder.encode(obj)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 199, in encode

    chunks = self.iterencode(o, _one_shot=True)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 257, in iterencode

    return _iterencode(o, 0)



  File "C:\Users\liamq\anaconda3\lib\json\encoder.py", line 179, in default

    raise TypeError(f'Object of type {o.__class__.__name__} '



TypeError: Object of type bytes is not JSON serializable

---

## 2022-10-13 01:12:35 - issues channel

**Liam Querido**

Hi there. I am trying to stream market data using the code below; however, I am getting an error when I run the subscribe_to_markets function. The error reads as follows: "TypeError: Object of type bytes is not JSON serializable."



I don't quite understand this error, as the market_filter and market_data_filters variables are dictionaries (not byte objects), so this error doesn't make sense to me intuitively.



Any help with resolving this issue would be much appreciated. Thanks in advance!



```from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



betfair_socket = trading.streaming.create_stream()



market_filter = streaming_market_filter(

    event_type_ids=['7'],

    country_codes=['IE'],

    market_types=['WIN'],

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_ALL_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3

)



betfair_socket.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

)



betfair_socket.start()  # blocking```

---

## 2022-10-11 12:47:21 - general channel

**Tom**

Roger that thanks Ivan. It won't come up for me to use and says "ModuleNotFoundError: No module named 'fasttrack'" So I thought I needed to install a package. I'll check those out.

---

## 2022-10-06 22:17:32 - betconnect channel

**Unknown**

Still getting the key error with the new code:(

---

## 2022-10-06 16:12:56 - betconnect channel

**Jeffrey Been**

Ah, thats explains the error :slightly_smiling_face: well im gonna look into this branch then. If I have any questions I will post. Thanx a lot for now! Saves a lot of time and frustration.



One final question though: would it be worth the 70 quid to switch to advanced?

---

## 2022-10-06 15:49:02 - betconnect channel

**Unknown**

Sorry I have to bother again: I am getting an error message when calling the the prices_file_to_csv_file method like this:

`betfairutil.prices_file_to_csv_file("1.119760905.bz2", "betfair_test2.csv")`



Following the signature of the method, I believe I only have to specify input file and output file? I am getting a key_error(see image)? Why am I getting this error and how should I fix this? Again any help is appreciated :smile:

---

## 2022-10-05 11:22:47 - issues channel

**Michael McGarry**

Hi, I'm trying to parse historical data with betfairlightweight and I'm encountering an issue with get_file_list that I can't seem to solve. I get an error every time stating:



```InvalidResponse: Invalid response received: 

[!DOCTYPE html](!DOCTYPE html)

&lt;html&gt;

&lt;head&gt;

&lt;meta name="viewport" content="width=device-width" /&gt;

&lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

&lt;div&gt;

Error

&lt;/div&gt;

&lt;script defer src="[https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194](https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194)" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"75556616acc7dc25","token":"d048f65d27954a24aa6b1d7d2ddcb256","version":"2022.8.1","si":100}' crossorigin="anonymous"&gt;&lt;/script&gt;

&lt;/body&gt;```

This happens even when trying to search for just a couple of days of data, so it isn't an issue of querying too much data. The files definitely exist as the get_collection_options and get_data_size are returning what I'd expect for the same parameters.

---

## 2022-10-05 10:43:14 - issues channel

**Michael McGarry**

[@U02USNASPRD](@U02USNASPRD) did you ever find a solution to this? I'm copying the exact code from the example docs and getting the same error when searching for a file list. The files are definitely there since get_collection_options and get_data_size are both returning what I'd expect them to!

---

## 2022-10-04 21:05:07 - issues channel

**mp2003**

Hi all, I'm a beginner to betfairlightweight, although know a bit of Python. I've got an app key and SSL cert sorted, and managed to log in OK. When running the example code for 'Streaming' in Jupiter Notebook, I can run all the code OK except the last part, which just hangs on the egg timer and does not complete - no errors, resources on my machine are fine etc.



This is when running both the 'Streaming' example code in [https://betcode-org.github.io/betfair/streaming/](https://betcode-org.github.io/betfair/streaming/) (the '# check for updates in output queue' section) and also the streaming area in [https://github.com/betcode-org/betfair](https://github.com/betcode-org/betfair) (at the line 'betfair_socket.start()')



Have restarted python/web browser - at a bit of a loss! Any help would be really appreciated, thank you.

---

## 2022-10-04 16:33:29 - issues channel

**Michael McGarry**

[@U01BTD8FR3P](@U01BTD8FR3P) did you ever find a solution? I'm experiencing the exact same issue. login_interactive also isn't working for me as I get an error: API login: STRONG_AUTH_CODE_REQUIRED

---

## 2022-09-29 08:42:53 - issues channel

**liam**

easy fix will be to change it to a warning

---

## 2022-09-28 22:56:09 - random channel

**foxwood**

I think [@UBS7QANF3](@UBS7QANF3) is the resident wizard on this stuff - he posted a link recently to a free pdf of a textbook well worth reading - worth searching for. Think whether all the features are useful - if they are not really relevant to the prediction then leave them out since it can mislead the training. Categories can help things along if they represent very different things eg NH racing versus flat. Beware of including any data that would be unknown to your program at the time of running it live eg don't include BSP if it is a pre-race model. Maybe try a binary classification model if you just want yes/no. Worst thing I ever did was leave the result in the data set - training was superb at over 95% :rolling_on_the_floor_laughing:. Correlation matrix might throw some light on meaningful relationships in the data. No easy fixes that I know of unfortunately - just have to  keep at it refining and thinking - rinse and repeat.

---

## 2022-09-27 14:35:13 - issues channel

**liam**

[https://superfastpython.com/thread-exception-handling/](https://superfastpython.com/thread-exception-handling/)

---

## 2022-09-26 15:18:50 - issues channel

**Newbie99**

Ah sorry I see, yes quite possibly...it seems very likely I'm trying to ask too much of it with that many markets, I will let it run a bit as I want to try and capture the exception in the logs if possible, so dont want to restart just yet, but once I get that I can cut the market filter and hopefully it will be able to cope better

---

## 2022-09-26 13:09:04 - issues channel

**Newbie99**

for the smaller file I moved it to here:



```   def _load_processor(self):

        # process compression/load in thread

        while True:

            try:

                market, file_dir, market_definition = self._queue.get(block=True)

                # check file still exists (potential race condition)

                if not os.path.isfile(file_dir):

                    logger.warning(

                        "File: %s does not exist in %s" % (market.market_id, file_dir)

                    )

                    continue

                # compress file

                compress_file_dir = self._compress_file(file_dir)

                # core load code

                self._load(market, compress_file_dir, market_definition)

                # clean up

                self._clean_up()

            except Exception as e:

                logging.critical(f'{e}')```

---

## 2022-09-26 13:08:49 - issues channel

**Newbie99**

If I'm understanding correctly, then for the larger file I had the try, except here:



```    def start(self) -&gt; None:

        # start load processor thread

        try:

            threading.Thread(

                name="{0}_load_processor".format(self.name),

                target=self._load_processor,

                daemon=True,

            ).start()

        except Exception as e:

            logging.critical(f'{e}')```

---

## 2022-09-26 12:59:53 - issues channel

**liam**

So the `football_load_processor` is getting killed at some point around 2022-09-25 09:43:15,786, can you share the code you changed to catch the error?

---

## 2022-09-26 12:04:54 - issues channel

**Newbie99**

Just to check, when you said put a try, except around load processing, you did mean here (from the marketrecorder.py file):

```    def _load_processor(self):

        # process compression/load in thread

        while True:

            try:

                market, file_dir, market_definition = self._queue.get(block=True)

                # check file still exists (potential race condition)

                if not os.path.isfile(file_dir):

                    logger.warning(

                        "File: %s does not exist in %s" % (market.market_id, file_dir)

                    )

                    continue

                # compress file

                compress_file_dir = self._compress_file(file_dir)

                # core load code

                self._load(market, compress_file_dir, market_definition)

                # clean up

                self._clean_up()

            except Exception as e:

                logging.critical(f'{e}')```

Interestingly (and confusingly) horse racing files are correctly being zipped, without any problems.



Football files are still not zipping...as a test I tried to GZIP a couple and it worked fine.



So whilst I'm not seeing anything unusual in the logs, the only difference is that I'm recording a significantly larger number of football markets on a single connection, than with horse racing. Is it worth cutting the number of market_types for a bit and seeing if that changes anything?

---

## 2022-09-24 20:43:27 - issues channel

**Peter**

You'll have more of a problem if you try to take the newlines out, as then Flumine won't be able to stream the files.



Also, the gzipping process doesn't care about them as it simply streams the file as a binary string, so they're a red herring for debugging your problem.

---

## 2022-09-24 16:56:41 - issues channel

**foxwood**

Most exceptions seem to raise a critical error in the logs under flumine - worth checking ?

---

## 2022-09-24 16:46:29 - issues channel

**Mo**

Uncaught exception in the thread responsible for gzipping 

---

## 2022-09-22 23:18:17 - betconnect channel

**Mark Wells**

```ValidationError: 1 validation error for AccountPreferences

kyc_result

  none is not an allowed value```

---

## 2022-09-22 23:18:00 - betconnect channel

**Mark Wells**

Hi guys. I'm trying to log in to the api for the first time with a staging account. I'm getting an error in

```client.account.login() ```

---

## 2022-09-20 08:41:13 - issues channel

**Mo**

[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Exceptions)



&gt; -32602	

&gt; 

&gt; Problem parsing the parameters, or a mandatory parameter was not found

---

## 2022-09-20 08:40:02 - issues channel

**Michael**

Is there a dictionary for error codes? I'm getting -32602 and I'm not sure what it means

---

## 2022-09-20 07:17:13 - general channel

**Tom**

Cheers. Roger that, I have a BET_ACTION_ERROR and INVALID_RUNNER which I'll chase down - did flumine get built on top of betfairlightweight and you use it instead, or do they work together?



Ultimately I am trying to create a bot, although I also want to get good at coding, python and understand all this stuff so in no hurry.



I'm just going through the tutorials and getting them to work on my end, make a few simple changes and just do the work to learn it at depth.



But I will get onto flumine and sounds like I will be up and running quicker than I think!

---

## 2022-09-20 06:57:42 - general channel

**liam**

SUCCESS, error code should tell you the problem (sometimes)



2023? Start using flumine and you can be running by the end of the day 

---

## 2022-09-19 20:57:38 - general channel

**Mo**

1. We've had a lively debate about this before but in my very humble opinion it is not correct to store the market ID as a string. The "1." prefix is a throwback to when there was a separate Australian exchange where the markets had a "2." prefix. As this is no longer the case, it is significantly better to encode market IDs as the integer after dropping the prefix

2. Yes will update it when I have a chance. Poke me if I forget

---

## 2022-09-19 11:02:03 - general channel

**Peter**

However, the code could be dangerous depending on the context in which it's executed.



If it's being used as part of a Flumine strategy you should be OK as IIRK Flumine will ensure that you have an available_to_back attribute on your runner_book.ex object.



But as your code refers to "runner_books", rather than just "runners", this suggests to me that you might be using Betfairlightweight, which doesn't offer the same safety, so your runner_book.ex object could be None. In which case your code would fall over with a missing attribute error.



So for safety, you might want to make that condition:

 `if runner_book.ex and runner_book.ex.available_to_back`

---

## 2022-09-19 07:48:05 - general channel

**Tom**

Hi guys, I am new to coding- I've done about 120 hours of training in Python in a Udemy course, which was ok but decided to get into a project to maintaining the trajectory of interest and have a background in financial markets and thought I would test an idea I've had in Horse Racing pricing, so am building a Betfair bot.



Although I don't know enough to really understand it at depth, Liams work is pretty impressive and appreciate the sharing (and no doubt others in here contributed, it's pretty cool/impressive what some people can do with this stuff)



```Anyway, the question I had is the code below - for the part that says if runner_book.ex.available_to_back - is that returning a boolean that will progress to runner_book.ex.available_to_back[0].price (to avoid an error) and will instead give us the extreme result automatically (1.01, or 1000 for the lay options)?```

```best_back_prices = [runner_book.ex.available_to_back[0].price

    if runner_book.ex.available_to_back

    else 1.01

    for runner_book

    in runner_books]```

---

## 2022-09-17 20:52:03 - random channel

**Newbie99**

Sorry to dwell on this, but looking at: [https://betcode-org.github.io/flumine/markets/#middleware](https://betcode-org.github.io/flumine/markets/#middleware)



I tried the following:



```from flumine.markets.middleware import Middleware



class FootballMiddleware(Middleware):

    def __call__(self, market) -&gt; None:

        if market.event_type_id in ['1', 1] and market.market_catalogue is not None \

            and market.market_book is not None and market.seconds_to_start &lt;= 7200 \

            and market.market_book.status not in ['CLOSED', 'SUSPENDED'] \

            and market.market_type not in ['HALF_TIME_SCORE']:

            update_market(market)```

Adding to the framework as follows:



```framework.add_logging_control(FootballMiddleware())```

But I get the following:



```concurrent.futures.process._RemoteTraceback: 

"""

Traceback (most recent call last):

  File "D:\Python38\lib\concurrent\futures\process.py", line 239, in _process_worker

    r = call_item.fn(*call_item.args, **call_item.kwargs)

  File "D:\Python37\webpages\backtesting.py", line 170, in startup

    framework.add_logging_control(FootballMiddleware())

  File "D:\Python38\lib\site-packages\flumine\baseflumine.py", line 124, in add_logging_control

    [http://logger.info|logger.info](http://logger.info|logger.info)("Adding logging control {0}".format(logging_control.NAME))

AttributeError: 'FootballMiddleware' object has no attribute 'NAME'

"""



The above exception was the direct cause of the following exception:



Traceback (most recent call last):

  File "D:/Python37/webpages/backtesting.py", line 445, in &lt;module&gt;

    output_list = start_backtest_a(chunked_markets, CPUs, snapshot, strategy_names, event_list)

  File "D:/Python37/webpages/backtesting.py", line 365, in start_backtest_a

    mini_output_list = job.result()  # wait for result

  File "D:\Python38\lib\concurrent\futures\_base.py", line 432, in result

    return self.__get_result()

  File "D:\Python38\lib\concurrent\futures\_base.py", line 388, in __get_result

    raise self._exception

AttributeError: 'FootballMiddleware' object has no attribute 'NAME'```

I assumed it would be a simple change:



```class FootballMiddleware(Middleware):

    def __call__(self, market) -&gt; None:

        self.NAME = 'Football_Logging_Control'

        if market.event_type_id in ['1', 1] and market.market_catalogue is not None \

            and market.market_book is not None and market.seconds_to_start &lt;= 7200 \

            and market.market_book.status not in ['CLOSED', 'SUSPENDED'] \

            and market.market_type not in ['HALF_TIME_SCORE']:

            update_market(market)```



But the error still persists, so I'm clearly mis-understanding this. Do you have any suggestions by chance?

---

## 2022-09-17 13:40:23 - random channel

**Newbie99**

Just to come back to this again, I'm having trouble passing parameters, my data is as follows (should it be a list of tuples instead or does it not matter), which are all grouped by event_id):



```[['Y:/betcode/unzipped_files\\1.201875723', 'Y:/betcode/unzipped_files\\1.202058901', 'Y:/betcode/unzipped_files\\1.202058903', 'Y:/betcode/unzipped_files\\1.202058896', 'Y:/betcode/unzipped_files\\1.202058942', 'Y:/betcode/unzipped_files\\1.202020603', 'Y:/betcode/unzipped_files\\1.202020594', 'Y:/betcode/unzipped_files\\1.202020596', 'Y:/betcode/unzipped_files\\1.202020589'], ['Y:/betcode/unzipped_files\\1.202347516', 'Y:/betcode/unzipped_files\\1.202108260', 'Y:/betcode/unzipped_files\\1.202108265', 'Y:/betcode/unzipped_files\\1.202108267', 'Y:/betcode/unzipped_files\\1.202108306', 'Y:/betcode/unzipped_files\\1.202228381', 'Y:/betcode/unzipped_files\\1.202228342', 'Y:/betcode/unzipped_files\\1.202228335'], ['Y:/betcode/unzipped_files\\1.202261399', 'Y:/betcode/unzipped_files\\1.202261353', 'Y:/betcode/unzipped_files\\1.202261358', 'Y:/betcode/unzipped_files\\1.202261360', 'Y:/betcode/unzipped_files\\1.202277070', 'Y:/betcode/unzipped_files\\1.202277031', 'Y:/betcode/unzipped_files\\1.202277029', 'Y:/betcode/unzipped_files\\1.202277024'], ['Y:/betcode/unzipped_files\\1.202093071', 'Y:/betcode/unzipped_files\\1.202084753', 'Y:/betcode/unzipped_files\\1.202084748', 'Y:/betcode/unzipped_files\\1.202084755', 'Y:/betcode/unzipped_files\\1.202084762', 'Y:/betcode/unzipped_files\\1.202346073', 'Y:/betcode/unzipped_files\\1.202346071']]```

My function is as follows:



```def start_backtest_a(chunked_markets, max_workers, snapshot, strategy_names, event_list):



    with ProcessPoolExecutor(max_workers=max_workers) as executor:

        futures = executor.map(startup, chunked_markets, snapshot, strategy_names, event_list)```

Where startup is essentially this (from Liam's example in the docs):



```def run_process(markets):

    client = clients.SimulatedClient()

    framework = FlumineSimulation(client=client)

    strategy = LowestLayer(

        market_filter={"markets": markets},

        context={"stake": 2},

    )

    with mock_patch("builtins.open", smart_open.open):

        framework.add_strategy(strategy)

        framework.run()```

But it needs some parameters, which are causing the issue.



snapshot is a static dict (e.g. {'a': 1})

strategy_names is a list of strategy names (e.g. ['strat_a', 'strat_b'])

event_list is either a list of historic data (e.g. scores data to map against a betfair event) or a bool, so in this instance False as I'm not passing any historic data.



However it appears to be expecting an iterable for each parameter.



```Traceback (most recent call last):

  File "D:/Python37/webpages/backtesting.py", line 484, in &lt;module&gt;

    output_list = start_backtest_a(chunked_markets, CPUs, snapshot, strategy_names, event_list)

  File "D:/Python37/webpages/backtesting.py", line 346, in start_backtest_a

    futures = executor.map(startup, chunked_markets, snapshot, strategy_names, event_list)

  File "D:\Python38\lib\concurrent\futures\process.py", line 674, in map

    results = super().map(partial(_process_chunk, fn),

  File "D:\Python38\lib\concurrent\futures\_base.py", line 600, in map

    fs = [self.submit(fn, *args) for args in zip(*iterables)]

  File "D:\Python38\lib\concurrent\futures\_base.py", line 600, in &lt;listcomp&gt;

    fs = [self.submit(fn, *args) for args in zip(*iterables)]

  File "D:\Python38\lib\concurrent\futures\process.py", line 182, in _get_chunks

    it = zip(*iterables)

TypeError: 'bool' object is not iterable```

---

## 2022-09-16 15:23:37 - random channel

**Aaron Smith**

indeed :smile: though its been working for pretty long, and the new code (using transaction class) looks like it could never produce such error. Well, i ll see once i use flumines internal method :slightly_smiling_face:

---

## 2022-09-16 15:19:14 - random channel

**Aaron Smith**

I used to create event files myself (pretty much the same way flumine does, not sure if it didnt exist back then or if i overlooked it), but now as i m getting some weird results (vaidation failed due to some negative numbers as [@U4H19D1D2](@U4H19D1D2) probs remembers [https://betcode-org.slack.com/archives/C4H05ML2E/p1663231320648429](https://betcode-org.slack.com/archives/C4H05ML2E/p1663231320648429) ), i wanted to switch to using the method implemented in flumine. Is there anything more it does than creating those event_files that maybe my current code didnt do?

---

## 2022-09-15 19:49:11 - general channel

**Peter**

Putting those snippets together works, i.e. this works:

```start_time = "17 September 2022 11:00"

game_time = datetime.strptime(start_time, "%d %B %Y %H:%M")

game_filter = betfairlightweight.filters.market_filter(

    event_type_ids=[1],

    market_start_time={

        'from': (game_time - timedelta(hours=2)).strftime("%Y-%m-%dT%TZ"),

        'to': (game_time + timedelta(hours=2)).strftime("%Y-%m-%dT%TZ")

    },

)

games = trading.betting.list_events(

    filter=game_filter

)```

returning (currently) a list of 57 EventResult objects.



Looking at the specific error you're getting though, it's telling you that your request is missing a mandatory parameter. Since listEvents only has one mandatory parameter, the filter. This means that you're either not actually attaching it, or that the market filter method is returning None, so it's still feeling like we're not quite seeing the actual code that you're using.

---

## 2022-09-15 17:31:47 - general channel

**Peter**

Is that the actual code you're running? Asking because it shouldn't get as far as the API call. Instead it should throw an error when you try to perform arithmetic on the game_time string and the timedelta object.

---

## 2022-09-15 15:59:12 - general channel

**Andy Bason**

Hi guys, I want to search for events using market_start_time. I thought the below would work but It throws this error: `Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}`

```        

game_time = '2022-09-15 14:49:41.209270'

game_filter = betfairlightweight.filters.market_filter(

            event_type_ids=[1],

            market_start_time={

                'from': (game_time - timedelta(hours=2)).strftime("%Y-%m-%dT%TZ"),

                'to': (game_time + timedelta(hours=2)).strftime("%Y-%m-%dT%TZ")

            },

        )```

Can anyone see what the problem is? Thanks

---

## 2022-09-15 09:57:08 - issues channel

**liam**

understood but it's something you aren't showing which is causing the issue, I can't fix what I can't see

---

## 2022-09-15 09:45:23 - issues channel

**liam**

the code you added/changed to suddenly get the errors

---

## 2022-09-15 09:42:00 - issues channel

**Aaron Smith**

Hey ppl,

I am currently implementing the transaction class for placing orders (instead of market.place_order).

After the change, during simulation i get a lot of these errors:

`"Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failed: reset_elapsed_seconds (-0.188) &lt; reset_seconds (0.0)"`

Anyone have a clue on how that negative number comes to be?

---

## 2022-09-12 16:32:15 - general channel

**Aaron Smith**

not sure if i understand. The way i imagine it is

total_latency = signal_from_betfair_to_me + code_runetime + signal_from_me_to_betfair.

In a backtest, the time a signal between me and betfair takes can only be assumed, so you set some fixed value. But runtime of your code would be the same. Basically, if i added a time.sleep(1) in my process_market_book, this would not effect the result of the simulation ?

---

## 2022-09-12 13:04:50 - random channel

**Fab**

In the last week or so I experienced several GitHub "unicorn" errors around this time of day

---

## 2022-09-12 09:51:17 - betfair-news channel

**Newbie99**

So in effect matching internal team name A, internal team name B, fixture time &amp; league to the Betfair event name (I do something to that effect currently)?



However I then do an additional check on selection ID, so in the above case I would simply bypass this market.

---

## 2022-09-12 08:36:16 - betfair-news channel

**Newbie99**

[@UBS7QANF3](@UBS7QANF3) but in this instance wouldn't the result be the same?



If you have your internally mapped team here, Guadalajara which your own ID ABC this would be mapped to betfair 230909, but the problem here is that betfair have applied the wrong id from their end, so surely your mapping would still 'work' in the sense it would map 230909 to ABC and flag up the wrong team due to Betfair's error?

---

## 2022-09-09 10:23:15 - issues channel

**Jimmy**

Hi all — seeing the odd “Connection closed by server” error in my logs. Can’t find much around why it might occur online — anyone any tips/suggestions? :slightly_smiling_face:

---

## 2022-09-08 16:43:34 - issues channel

**Aaron Smith**

checking through my latency warnings i see that 98% of them are this version:

```"WARNING", "message": "High latency between current time and OrderPackage creation time, it is likely that the thread pool is currently exhausted", "trading_function": "cancel", "session": "&lt;requests.sessions.Session object at 0x7f02236a0b20&gt;", "latency": 0.102, "order_package": {"id": "3f6818d6-2f8b-11ed-969e-257a4444e788", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f028fd7ba30&gt;", "market_id": "1.203111349", "orders": ["138819438430078669"], "order_count": 1, "package_type": "Cancel", "customer_strategy_ref": "prod_GH", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}, "thread_pool": {"num_threads": 25, "work_queue_size": 2}```

I get these on cancel and place. `work_queue_size` can be higher (last one it was at 19, this time 2 was highest for this chunk of latency errors (they generally come in chunks). What i m surprised by is `"num_threads": 25` , i can not really see why i would have 25 threads running?

---

## 2022-09-08 09:56:05 - issues channel

**Alessio**

I mean, it's simple: BF put the wrong time, this may happen for a multitude of reasons (match delayed, human error, etc..)

---

## 2022-09-08 09:08:21 - issues channel

**Mo**

If you have something logging timestamps, you could look for a jump around the time the latency errors started. For example, if you log something that is typically around 100 milliseconds between messages and then you see a much larger gap and then a return to 100 milliseconds this might be evidence for this

---

## 2022-09-08 09:01:11 - issues channel

**liam**

Should now be fixed in v2.2.6

---

## 2022-09-07 13:39:22 - issues channel

**liam**

without seeing your code its very tricky to debug

---

## 2022-09-07 10:22:24 - issues channel

**liam**

yeah it needs to be fixed, just need to work out how it should be handled correctly, can you copy all of this into an issue?

---

## 2022-09-07 10:00:23 - issues channel

**AP**

Thanks Liam, is it something that you think it's worth the effort in fixing or it's not a big deal?

---

## 2022-09-06 16:38:33 - issues channel

**Unknown**

here is one of the files showing this error

---

## 2022-09-04 12:58:08 - random channel

**Graham**

[@UFTBRB3F1](@UFTBRB3F1) I was reading a few of those recently too. But not hacked, just mismanaged - mainly from unknowing startups. 



The billing thresholds don’t actually do anything aside from alerting. But, AWS and GCP have a good track record of forgiving such accounts.



It’s one of my biggest bug bears of them, the pricing is quite difficult to figure out.

---

## 2022-09-04 07:54:03 - issues channel

**sartux**

Good morning guys,

to make the account report I have always used the "get_account_statement" method and it has always worked.



```

dateStart = datetime.datetime(2022, 8,30,0,0)

acct_statement_date_filter = betfairlightweight.filters.time_range(from_=dateStart)



account_statement = trading.account.get_account_statement(item_date_range=acct_statement_date_filter)```

Since this morning instead I get this error



```TypeError: __init__() missing 1 required positional argument: 'fullMarketName'



   raise InvalidResponse(response=result)

betfairlightweight.exceptions.InvalidResponse: Invalid response received: {'accountStatement': [{'refId': '51365225816', 'itemD... ```

the script was working for 7 days without any problem

---

## 2022-09-03 09:22:38 - random channel

**Newbie99**

The default output as you say is 127.0.0.1:4000 (or localhost:4000). However I have an elastic IP setup on AWS, which normally I send data to via Flask as follows:



```socketio.run(app, debug=False, host='0.0.0.0', port=PORT_NO)```

I can then view the output as expected from my app.



However (obviously not running my flask app at this point) when I put in the output as 0.0.0.0 and any port from cprofilev the page doesn't exist.



So I'm assuming I'm missing something simple.

---

## 2022-09-01 14:36:45 - issues channel

**AP**

on my side I was testing to substitute lines 194-197 in flumine.simulation.simulatedorder.py with

```return SimulatedCancelResponse(

                status="FAILURE",

                size_cancelled=0,

                error_code="ERROR_IN_ORDER",

            )```

and also changing line 389 (for example inverting the 2 arguments of the "or" operation worked, because (0 or None) != (None or 0))

---

## 2022-09-01 14:20:13 - issues channel

**AP**

the points 1,2,3 are correct, from what I explored, but the extra filter doesn't fix the problem

---

## 2022-09-01 14:18:58 - issues channel

**AP**

I updated the code above, but I still get the same error

---

## 2022-09-01 11:34:28 - issues channel

**AP**

Hi! I created an example strategy just to test some features of flumine but I'm struggling with a problem

```class ExampleStrategy(BaseStrategy):

    def start(self) -&gt; None:

        print("starting strategy 'ExampleStrategy'")



    def check_market_book(self, market: Market, market_book: MarketBook) -&gt; bool:

        return (market_book.status == "OPEN") and (not market_book.inplay)



    def process_market_book(self, market: Market, market_book: MarketBook) -&gt; None:

        for i in range(len(market_book.runners)):

            runner = market_book.runners[i]



            LPT = runner.last_price_traded



            if runner.status == "ACTIVE" and (LPT is not None):

                if LPT &lt; 2:

                    trade = Trade(

                        market_id=market_book.market_id,

                        selection_id=runner.selection_id,

                        handicap=runner.handicap,

                        strategy=self

                    )

                    order = trade.create_order(

                        side="BACK",

                        order_type=LimitOrder(price=LPT, size=2.00)

                    )



                    res = market.place_order(order)



                    if res:

                        print("Order placed: ", market_book.market_id, runner.selection_id, LPT)



    def process_orders(self, market: Market, orders: list) -&gt; None:

        if not((market.market_book.status == "OPEN") and (not market.market_book.inplay)):

            return



        for order in orders:

            if order.status == OrderStatus.EXECUTABLE:

                if order.size_remaining == 2.00:

                    market.cancel_order(order, 0.02)  # reduce size to 1.98



                if order.order_type.persistence_type == "LAPSE":

                    market.update_order(order, "PERSIST")



                if order.size_remaining &gt; 0:

                    market.replace_order(order, new_price=1.02)```

I had run this strategy on a specific market, but then the following error was raised:

```Traceback (most recent call last):

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulation.py", line 97, in run

    self._process_market_books(

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulation.py", line 117, in _process_market_books

    self._check_pending_packages(market_id)

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulation.py", line 189, in _check_pending_packages

    order_package.client.execution.handler(order_package)

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/execution/simulatedexecution.py", line 31, in handler

    func(order_package, http_session=None)

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/execution/simulatedexecution.py", line 142, in execute_replace

    place_instruction_report = replacement_order.simulated.place(

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulatedorder.py", line 70, in place

    return self._create_place_response(

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulatedorder.py", line 181, in _create_place_response

    if self.size_remaining == 0:

  File "/home/alessandro/venv/lib/python3.8/site-packages/flumine/simulation/simulatedorder.py", line 395, in size_remaining

    size

TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'```

It seems that the execution is broken while the framework is trying to replace an order: first it tries to cancel the order, but then it discovers that the market.status is not OPEN and raise the error with

```return SimulatedCancelResponse(

                status="FAILURE",

                error_code="ERROR_IN_ORDER",

            )```

in flumine/simulation/simulatedorder.py, line 194. I don't understand why it is happening, because the check_market_book functions should already have checked that the market is OPEN. Also, in this specific case, the market is SUSPENDED before the race, Idk if it is an useful information. Can somebody help me with it?

---

## 2022-08-31 09:45:10 - general channel

**Jon K**

Hi all, I'm trying to place an SP bet but am getting Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1} which is a mandatory param isn't being supplied yet I'm scratchign my head with what it could be.

This is what is being sent through

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/placeOrders

Params: {'marketId': 11166579, 'instructions': [{'orderType': 'MARKET_ON_CLOSE', 'selectionId': '1.202730586', 'side': 'BACK', 'handicap': 0, 'marketOnCloseOrder': {'liability': 1.5}}]}

---

## 2022-08-29 09:54:07 - random channel

**D C**

Generic question not specific to flumine/BFLW - if you place a bet asynchronously that would fail if placed synchronously, do you get anything at all on the order stream? I am trying to get my head around edge cases like the following example:

1. You place a bet inply with async flag

2. Response comes back with PENDING state.

3. Market suspends before the inplay delay elapses which would be a failed bet under sync bet placement conditions.

What happens here? Zero order stream update for this bet or some kind of response with the customer order ref and a null bet ID or similar that allows you to determine the failure?

Essentially I am asking if we can rely on order strem 100% or if best practice for using async is to have some call or listCurrentOrders in addition for any bets that slip through the net (if that is possible).

---

## 2022-08-27 10:13:57 - general channel

**birchy**

Numpy is now working in PyCharm, but not really sure what the fix was. So I'd installed python 3.10 apple silicone version and was using that for PyCharm and running my code in the terminal as it became the default for `python3`. I then removed 3.10 which left me with the default 3.8 version and now PyCharm &amp; numpy work as expected. Haven't looked into the details but I suspect the default mac version may be Intel compatible.

---

## 2022-08-26 14:07:22 - general channel

**liam**

I remember having similar issues, no idea how I fixed it tbh

---

## 2022-08-26 10:52:19 - general channel

**liam**

Any flumine users want to see what simulation is like with 100% matching on placement this code patches the place code:



```def _create_place_response(

    self,

    bet_id: Optional[int],

    status: str = "SUCCESS",

    order_status: str = None,

    error_code: str = None,

) -&gt; SimulatedPlaceResponse:

    if status == "SUCCESS" and self.size_remaining:

        self.matched.append([123, self.order.order_type.price, self.size_remaining])

        self.size_matched, self.average_price_matched = wap(self.matched)

    if order_status is None:

        if self.size_remaining == 0:

            order_status = "EXECUTION_COMPLETE"

        else:

            order_status = "EXECUTABLE"

    return SimulatedPlaceResponse(

        status=status,

        order_status=order_status,

        bet_id=str(bet_id),

        average_price_matched=self.average_price_matched,

        size_matched=self.size_matched,

        placed_date=datetime.datetime.utcnow(),

        error_code=error_code,

    )



SimulatedOrder._create_place_response = _create_place_response```

---

## 2022-08-26 09:14:50 - general channel

**liam**

Its a bit complicated, a strategy is subscribed to streams, you can see the ids with `Strategy.stream_ids` or the streams themselves with `Strategy.streams`



We add the `stream_id` to the `MarketBook` which you can see with `MarketBook.streaming_unique_id` however there isn't anything in the Market object telling you this as it can be shared with multiple streams. This relates to a current bug where two streams could be updating a single Market due to a crossover in the filters

---

## 2022-08-24 20:40:34 - strategies channel

**liam**

Yeah pretty much, I have values for exposure/trade_count but they are very high and more to catch really bad errors/downtime’s etc.



Tbh I really don’t like the idea of stopping based on exposure, it’s almost like stopping when you reach x profit 

---

## 2022-08-23 14:49:46 - random channel

**liam**

Do your -ev bets point to errors?

---

## 2022-08-23 14:42:48 - random channel

**liam**

Yes and that as a whole over time it will be correct, of course the market can be miss-priced but if I think a team/runner is about to win but the odds are 100/1 for an extended period of time it doesn't make sense to go all in and start backing with the same stake I would be if it was 1.10.



Basically using the wisdom of the crowds to reduce the risk, harder when things are tighter / errors less extreme

---

## 2022-08-23 14:22:16 - random channel

**Alessio**

Hey folks, inplay q: what is your favorite way of dealing with inconsistent data between betfair and whatever-other-data-source-for-in-play you use? Say, your source is usually good and fast, but is missing some shots.. do you try to build consensus or do you just stick to one source and eat the errors (assuming our source is on average more truthful than the betfair one :wink:

---

## 2022-08-22 09:16:25 - issues channel

**liam**

haha...



```"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result

    raise self._exception

TypeError: don't know how to handle uri "PUT_YOUR_MARKET_IDS_HERE"```

---

## 2022-08-22 09:11:39 - issues channel

**liam**

cryptic error as its not obvious that `...` is referred to an Ellipsis, that example is just left as `...` to make it simple

---

## 2022-08-22 08:57:55 - issues channel

**mandelbot**

I'm trying to run multiprocessing on backtests for the first time (I know right?) and i keep getting the following error:



```TypeError: don't know how to handle uri Ellipsis```



```concurrent.futures.process._RemoteTraceback: 

"""

Traceback (most recent call last):

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py", line 246, in _process_worker

    r = call_item.fn(*call_item.args, **call_item.kwargs)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/strategy/testmulti.py", line 41, in run_process

    framework.add_strategy(strategy)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/baseflumine.py", line 101, in add_strategy

    self.streams(strategy)  # create required streams

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/streams/streams.py", line 46, in __call__

    market_type = get_file_md(market, "marketType")

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/utils.py", line 66, in get_file_md

    with open(file_dir, "r") as f:

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/smart_open/smart_open_lib.py", line 224, in open

    binary = _open_binary_stream(uri, binary_mode, transport_params)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/smart_open/smart_open_lib.py", line 396, in _open_binary_stream

    raise TypeError("don't know how to handle uri %s" % repr(uri))

TypeError: don't know how to handle uri Ellipsis

"""



The above exception was the direct cause of the following exception:



Traceback (most recent call last):

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/flumine/strategy/testmulti.py", line 63, in &lt;module&gt;

    job.result()  # wait for result

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 439, in result

    return self.__get_result()

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py", line 391, in __get_result

    raise self._exception

TypeError: don't know how to handle uri Ellipsis```

Can't figure it out, anyone have any ideas?

---

## 2022-08-21 10:20:41 - strategies channel

**Alessio**

Indeed, maybe if you fix the laying it backs even better :slightly_smiling_face:

---

## 2022-08-21 08:55:23 - strategies channel

**Alessio**

:smile: at some point we will all want to know what fixed it.

---

## 2022-08-19 16:43:52 - issues channel

**Newbie99**

Just one thought, but looking quickly it seems that there are over 1000 MATCH_ODDS markets, so unless you have unlimited markets per connection it would generate an error.



The only way to get around this (apart from asking nicely if you can get your limit increased, which may or may not happen) is to split things up by country so not all MATCH_ODDS markets are on one connection.

---

## 2022-08-19 08:58:25 - random channel

**mandelbot**

well if anyone's interested I ended up going for a [https://www.amazon.co.uk/WD_BLACK-Battlefield-Bundle-speeds-3600MB/dp/B0989X548R/ref=sr_1_3?crid=HJVDEJZY2P23&amp;keywords=wd+black+sn750&amp;qid=1660895871&amp;sprefix=wd+black+sn750%2Caps%2C76&amp;sr=8-3|WD_BLACK SN750](https://www.amazon.co.uk/WD_BLACK-Battlefield-Bundle-speeds-3600MB/dp/B0989X548R/ref=sr_1_3?crid=HJVDEJZY2P23&amp;keywords=wd+black+sn750&amp;qid=1660895871&amp;sprefix=wd+black+sn750%2Caps%2C76&amp;sr=8-3|WD_BLACK SN750) + ACASIS enclosure

---

## 2022-08-17 15:20:57 - general channel

**thambie1**

Yeah... that's definitely not normal. I'm getting the same error page. I'm guessing you'll have more luck reporting it to Betfair Developer Support

---

## 2022-08-17 15:17:57 - general channel

**Peter**

Can't access it at all. The webpage is a Cloudflare 522 error page saying that it although it can connect to the [http://historicdata.betfair.com|historicdata.betfair.com](http://historicdata.betfair.com|historicdata.betfair.com) server, requests aren't being completed i.e. they're timing out.

---

## 2022-08-15 17:08:59 - betfair-news channel

**Unknown**

A few days ago I posted on "issues" about a question I have in relation to the values ​​provided by `tradedVolume`, because I want to follow the matches, seeing the movement of the market with each request I make, easily indicating how much in *Back* was transacted between the requests in how much in *Lay* it took to match.



[@U9JHLMZB4](@U9JHLMZB4) helped me to better understand the calculations but I decided to put a complete example so that if there is still an error in what I'm doing, it's easier to see the problem.



So an example without real values ​​(from odds 1.20) from this week's Liverpool game:



```[{"jsonrpc": "2.0", "method": "SportsAPING/v1.0/listRunnerBook", "params": {"marketId":"1.200236669","selectionId":"56323","priceProjection":{ "priceData":["EX_TRADED"]}}, "id": 1}]```

*Request 1:*

`"tradedVolume":[{"price":1.2,"size":100}]`

Back liability: 100

Lay liability: 20

Total Matched: 100

Total Money Transacted on the Betfair System: 120



*Request 2:*

`"tradedVolume":[{"price":1.2,"size":300}]`

Back liability: 300

Lay liability: 60

Total Matched: 300

Total Money Transacted on the Betfair System: 360



*Request 3:*

`"tradedVolume":[{"price":1.2,"size":800}]`

Back liability: 800

Lay liability: 160

Total Matched: 800

Total Money Transacted on the Betfair System: 960

`------------------------------------------------------------`

So, let's say I want to register on the chart how much liability we had between:



_*Request 1 and 2:*_

Back liability: 200

Lay liability: 40

Total Money Transacted on the Betfair System: 240



_*Request 2 and 3:*_

Back liability: 500

Lay liability: 100

Total Money Transacted on the Betfair System: 600



Now is the view I want to have of the separate values ​​correct?



I understand that it is a simplistic view because there are more details that must be taken into account (such as, for example, there is no way to know if it was a single transaction that corresponded to the entire amount or if there were multiple ones) but I want to create a follow-up just to help me to visualize in more detail the financial movement of the market in each odds.



Otherwise, I want to create a real-time chart to see how much money traders will lose if their investment result is 100% negative.

---

## 2022-08-12 09:33:42 - issues channel

**liam**

Nothing, bug in how we created replacement orders, fix [https://github.com/betcode-org/flumine/pull/605|here](https://github.com/betcode-org/flumine/pull/605|here)

---

## 2022-08-11 19:03:48 - strategies channel

**birchy**

For those of you with profitable strategies, how often do you all have to carry out maintenance or "tweak" settings/signals/etc? Personally I have one particular strategy that was my first live one with Flumine that's been untouched for ~2 years now. It's nothing adventurous but has been slowly ticking along and in recent months has performed exceptionally well. No doubt there will be an equal downturn at some point....

---

## 2022-08-11 17:30:52 - general channel

**Dario Scardina**

Hello, how can I get the runner name of a selection in flumine? Let's say I want to place orders only to Under selections

```strategy = ExampleStrategy(

    name="BackUnderSH",

    market_filter=streaming_market_filter(

        event_type_ids=["1"],

        event_ids=["31653002"],

        market_types=["OVER_UNDER_05", "OVER_UNDER_15", "OVER_UNDER_25", "OVER_UNDER_35", "OVER_UNDER_45",

                           "OVER_UNDER_55", "OVER_UNDER_65"]

    )

)```

I was trying then to skip Over selections in

```def process_market_book(self, market: Market, market_book: MarketBook) -&gt; None:

    # process marketBook object

    for runner in market_book.runners:

        skip_runner = False

        for runner_info in market.market_catalogue.runners:

            logger.debug("process_cleared_markets: %s" % runner_info.runner_name)

            if runner.selection_id == runner_info.selection_id:

                if "Ov" in runner_info.runner_name:

                    skip_runner = True

...```

But I've found out that market.market_catalogue is None.



Did somebody faced this problem?

---

## 2022-08-10 14:06:34 - betfair-news channel

**Brøndby IF**

Good morning everyone (good afternoon to the people of Europe)!



A few days ago I asked about keeping my code running on a server in Ireland and I live in Brazil, if that had a problem ([@U80AMMRKP](@U80AMMRKP) even commented to me that there were no problems). This morning I woke up with several access errors on the server and when I went to access the account manually, it asked me to change my password.



I contacted Betfair chat and they told me that there was an unauthorized IP access in Ireland. I argued that this IP and this access I knew, that it was from the server that I kept my code executing the access to the Betfair API.



At that moment the attendant started asking if I worked with Betfair, asked how I didn't know about the other emails or access to Betfair, told me he couldn't help, gave me a contact email and ended the service without even finishing answering my questions.



Has anyone ever experienced this? The attendant talked to me like I was a hacker or something, doubting everything I said.



Is it normal to have the password changed from time to time if we have a server in a different country to which we reside?

---

## 2022-08-08 16:37:39 - strategies channel

**Mo**

Yeah so essentially you have (at least) 2 competing methods for making a prediction: the near price and the mid point. Take your 10 am snapshot and calculate the 2 values and also record where the BSP ended up. Score the two methods according to some reasonable criterion such as mean squared error. Repeat for all the races and runners in your data set then add up the scores and see which method has the best overall score

---

## 2022-08-08 10:10:16 - issues channel

**George**

Of course I've been looking at Flumine for a month but only wasted one day debugging this issue thankfully

---

## 2022-08-08 10:02:31 - issues channel

**George**

To fix event processing couldn't we just check whether the event details of the market book update matches the event details of the event that we are trying to simulate?

---

## 2022-08-08 10:01:11 - issues channel

**liam**

regarding the error, not sure how we can get the stream filter talking to the middleware to raise the error

---

## 2022-08-08 09:53:56 - issues channel

**George**

i can see how this might not be the top item on your to-do list, but if event_processing breaks the TPD simulation then could we at least have a FlumineError to tell us not to use event_processing with inplay simulation :slightly_smiling_face:

---

## 2022-08-08 08:58:59 - betconnect channel

**rob smith**

I'm using the dailyhorseracing example without amendment

`Traceback (most recent call last):`

  `File "C:/Users/James/PycharmProjects/betConnect/betConnectv1.py", line 27, in &lt;module&gt;`

    `login = client.account.login()`

  `File "C:\Users\James\AppData\Local\Programs\Python\Python37\lib\site-packages\betconnect\endpoints\account.py", line 70, in login`

    `method_uri=f"{self.api_version}/login"`

  `File "C:\Users\James\AppData\Local\Programs\Python\Python37\lib\site-packages\betconnect\endpoints\account.py", line 188, in _post`

    `status_code=response.status_code, url=response.url`

`betconnect.exceptions.UnexpectedResponseStatusCode: Unexpected status code (500) returned for request: [https://xxxxxxxapi.betconnect.com/api/v2/login](https://xxxxxxxapi.betconnect.com/api/v2/login)`

---

## 2022-08-08 08:40:20 - betconnect channel

**rob smith**

Thanks. Now I get this:

`betconnect.exceptions.UnexpectedResponseStatusCode: Unexpected status code (500) returned for request`

Seems like an issue their side?

---

## 2022-08-08 08:34:50 - betconnect channel

**rob smith**

Thanks Liam. That throws a different error:

`Traceback (most recent call last):`

  `File "C:/Users/James/PycharmProjects/betConnect/betConnectv1.py", line 20, in &lt;module&gt;`

    `personalised_production_url="[https://xxxxxxxxapi.betconnect.com](https://xxxxxxxxapi.betconnect.com)",`

  `File "C:\Users\James\AppData\Local\Programs\Python\Python37\lib\site-packages\betconnect\apiclient.py", line 35, in __init__`

    `personalised_production_url=personalised_production_url,`

  `File "C:\Users\James\AppData\Local\Programs\Python\Python37\lib\site-packages\betconnect\baseclient.py", line 37, in __init__`

    `self._set_endpoint_uris(environment)`

  `File "C:\Users\James\AppData\Local\Programs\Python\Python37\lib\site-packages\betconnect\baseclient.py", line 142, in _set_endpoint_uris`

    `assert self._personalised_production_url[-16:] == ".[http://betconnect.com/|betconnect.com/](http://betconnect.com/|betconnect.com/)"`

`AssertionError`

---

## 2022-08-08 08:29:23 - betconnect channel

**rob smith**

`I'm having a first crack with Bet Connect but have run into this error:`

`Traceback (most recent call last):`

  `File "C:/Users/James/PycharmProjects/betConnect/betConnectv1.py", line 20, in &lt;module&gt;`

    `personalised_production_url="[https://xxxxxxxapi.betconnect.com/api/v2](https://xxxxxxxapi.betconnect.com/api/v2)",`

  `File "C:\Users\James\AppData\Local\Programs\Python\Python37\lib\site-packages\betconnect\apiclient.py", line 35, in __init__`

    `personalised_production_url=personalised_production_url,`

  `File "C:\Users\James\AppData\Local\Programs\Python\Python37\lib\site-packages\betconnect\baseclient.py", line 37, in __init__`

    `self._set_endpoint_uris(environment)`

  `File "C:\Users\James\AppData\Local\Programs\Python\Python37\lib\site-packages\betconnect\baseclient.py", line 142, in _set_endpoint_uris`

    `assert self._personalised_production_url[-16:] == ".[http://betconnect.com/|betconnect.com/](http://betconnect.com/|betconnect.com/)"`

`AssertionError`

---

## 2022-08-06 17:09:24 - issues channel

**liam**

Agreed, I will fix regardless 

---

## 2022-08-06 17:06:47 - issues channel

**George**

OK, I'll try turning it off and see what happens. However, even if that fixes everything, I'd still be interested to see if there is an underlying issue as it seems odd that turning on event processing should completely break the simulation

---

## 2022-08-06 15:45:03 - issues channel

**George**

Clearer formatted code:

```import smart_open

from mock import patch

from flumine import FlumineSimulation, clients, config

from flumine.markets.middleware import SimulatedSportsDataMiddleware

from flumine.strategy.strategy import BaseStrategy



if __name__ == '__main__':

	client = clients.SimulatedClient()

 	framework = FlumineSimulation(client=client)

	markets = ['/path/to/file/1.201463615.gz', '/path/to/file/1.201463621.gz']

	strategy = BaseStrategy(market_filter= {'markets': markets, 'listener_kwargs': {'seconds_to_start': 60, '    calculate_market_tv':False, 'cumulative_runner_tv':False}, 'event_processing': True})

	with patch('builtins.open', smart_open.open):

 		framework.add_market_middleware(SimulatedSportsDataMiddleware('raceSubscription', '/sports/data/path'))

 		framework.add_strategy(strategy)

 		with patch.object(config, 'raise_errors', True):

 			framework.run()```

---

## 2022-08-06 15:27:39 - issues channel

**George**

Hi [@U4H19D1D2](@U4H19D1D2) here is the code I'm using:

```import smart_open

from mock import patch

from flumine import FlumineSimulation, clients, config

from flumine.markets.middleware import SimulatedSportsDataMiddleware

from flumine.strategy.strategy import BaseStrategy



if __name__ == '__main__':

    client = clients.SimulatedClient()

    framework = FlumineSimulation(client=client)

    sports_data_path = '/sports/data/path/'

    markets = ['/path/to/file/1.201463615.gz', '/path/to/file/1.201463621.gz']

    strategy = BaseStrategy(market_filter= {'markets': markets, 'listener_kwargs': {'seconds_to_start': 60, '    calculate_market_tv':False, 'cumulative_runner_tv':False}, 'event_processing': True})

    with patch('builtins.open', smart_open.open):

        framework.add_market_middleware(SimulatedSportsDataMiddleware('raceSubscription', sports_data_path))

        framework.add_strategy(strategy)

        with patch.object(config, 'raise_errors', True):

            framework.run()```

---

## 2022-08-06 07:31:18 - issues channel

**Mo**

This is a bit obscure but when backtesting using concurrent.futures i.e. multiprocessing I sometimes get a BrokenProcessPool because one of the worker processes has a segmentation fault. Using [https://docs.python.org/3/library/faulthandler.html|faulthandler](https://docs.python.org/3/library/faulthandler.html|faulthandler), the stack trace shows me the segmentation fault occurs when using betfairlightweight to read the prices file on [https://github.com/betcode-org/betfair/blob/master/betfairlightweight/streaming/cache.py#L83|this line in cache.py](https://github.com/betcode-org/betfair/blob/master/betfairlightweight/streaming/cache.py#L83|this line in cache.py):



```class Available:

...

    def serialise(self) -&gt; None:

-&gt;      self.serialised = [book[-1] for book in self.order_book.values()]```

Usually I can just restart the backtest and then everything works fine. In fact, it usually happens once or twice after booting and after that I can run as many backtests as I like without error. Anyone experienced anything similar?

---

## 2022-08-06 01:52:27 - issues channel

**George**

Under some conditions, it doesn't seem to be possible to run a Flumine racing simulation with `SimulatedSportsDataMiddleware` across multiple markets.

The logic in the software appears to be as follows:

• `add_market` is called for race 1

• simulation begins to work normally taking in race 1 TPD data

• `add_market` is called for race 2

• simulation for race 1 continues abnormally, attempting to use race 2 TPD data

• race 1 finishes

• `remove_market` is called for race 1, but the TPD data was race 2 data, which is what is removed (the race 1 data was overwritten anyway)

• simulation for race 2 is attempted, but there is now no TPD data at all, so the code crashes

Now the question is - why would `add_market` be called for race 2, before race 1 has finished? I think this is occurring because I have `EX_MARKET_DEF` in my MarketRecorder script and, because the race status is SUSPENDED when these updates come around, they are not skipped. I'm not sure about this though, and in fact any update where the market is SUSPENDED would presumably cause this issue.



Tagging [@U4H19D1D2](@U4H19D1D2) as this appears to be a Flumine bug but I would rather be wrong and hoping it's just user error... please let me know either way!Thanks

---

## 2022-08-04 09:45:34 - general channel

**Alessio**

i think it's a bit of short term vs long term: if i am working on something my mind is fresh, so directory names are cheap and easy enough and very fast to glance over. I don't expect it to be fully descriptive though, that's why the params file. however, i know myself and in 2 months i won't remember which other parameters i. changed or i kept fixed, that's why i save the full command line in the file

---

## 2022-08-04 09:34:56 - general channel

**Alessio**

since i also do local backtesting, i went like this:

• add a json file with the git commit and the exact command line i used, plus the parameters in abstract form.

• add a line in a psql database which contains exactly the json file contents +  directory

• group backtests by "idea"", which are named by the directory

• still name the directory of each iteration of the tuning grid with a reasonablel fantasy name (edit: prefix), this is to avoid duplication and still have a way to remember which thing is which at a glance (so something like, big-horses-roi4)

psql or sqlite up to you, but psql was easy because i already had it and i can add json querying. the json file is because i may want to process things with the json file on another machine without having to port the psql over.

---

## 2022-08-04 07:30:36 - general channel

**Mo**

Does anyone have any tips for organising backtest results? The output of my backtests is one file per event so each backtest occupies a single directory. I'm currently distinguishing between the different parameters used in each backtest in the directory name but this is quickly becoming unwieldy as I add more parameters and it's hardly the best way to encode this information. For example:



```.../backtests/results-new-min-roi-0.0-max-roi-120.0-max-price-1000-bankroll-10000-bet-latency-100ms-cooldown-20000ms-entire-race-with-tags```

I'm thinking of having some kind of "meta file" in each backtest directory that could contain these parameters and other useful information for example:



```{

    "git_commit": "00e8402a7395de0b91d24a2fa15953a9f3271dca",

    "number_of_events": 19214,

    "event_status_breakdown": {

        "SUCCESS": 12007,

        "ERROR": 43,

        "MISSING_DATA": 7167

    },

    "parameters": {

        "min_roi": 0.0,

        "max_roi": 120.0,

        ...

    },

    "profit": -143762.12,

    ...

}```

and/or possibly have a top-level index of the backtests, either in a flat file or SQLite database and then the directories can have uninformative names like "00000043" or "cc097b8048064a3acd969de313e52f9b3fd896c7"

---

## 2022-08-03 17:35:11 - random channel

**birchy**

Fixed it! It was clearly an inheritance issue and then I realised that I wasn't explicitly importing my library, i.e. I was doing:

`from mylibrary` `import...`

But didn't have:

`import mylibrary`

---

## 2022-08-03 05:01:24 - strategies channel

**Tiago Augusto Ferreira**

Hello. I am try filter my strategy using the competition_ids. But i receive a error SUBSCRIPTION_LIMIT_EXCEEDED. What is the correct form to filter by this field?

`strategy_over = MyStrategy(`

    market_filter=market_filter(competition_ids=[141]),

    name='OVER05HT_MODELO',

    max_trade_count=3,

    max_live_trade_count=3,

    max_order_exposure=12,

    conflate_ms=1000,



)



The error:



2022-08-03 00:57:07 *ERROR*    [MarketStream: 2001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 14995 markets whereas max allowed number was: 200

2022-08-03 00:57:07 INFO     [MarketStream: 2001]: *FAILURE* (9 connections available)

---

## 2022-07-31 23:44:21 - strategies channel

**Troy Edwards**

Hi all long time since chatting.  I have been trying some strategies with Aussie and NZ greyhound racing and still don't have an edge yet.  So back to learning and I have come across SVM - Support Vector Machine regression tool which I want to apply to greyhound data.  Some of the X inputs will be form, speed, rating, starting odds etc and some of my own inputs.  However for the Y inputs which are the results, should I enter say 1 (True) for the winner and then -1 (False) for the other 7 runners?  OR should I enter the actual finishing positions 1 thru 8?    I am wondering if training the model with positions 1-8 may introduce errors OR be too difficult?  I was also thinking I could just set positions 1-3 True and everything else False as most of my strategies are for Lay bets?   I  have started any coding yet for the model but am going to use Accord.MachineLearning.VectorMachines.Learning in the .NET library.

---

## 2022-07-31 19:14:13 - issues channel

**thambie1**

But still occasionally seeing API errors

---

## 2022-07-31 19:11:53 - issues channel

**Dave**

Anyone else seeing API errors?

---

## 2022-07-29 14:23:45 - issues channel

**liam**

Out of memory, hard to debug without knowing what is running on the box or if it's the python process itself that has a leak, login at 10:20 and monitor will tell you straight away 

---

## 2022-07-28 20:03:47 - issues channel

**Michael**

Anyone got any advice on Certs? Mine from last year has expired, I've followed the XCA example to the letter on betfair but keep getting cert errors

---

## 2022-07-28 17:05:56 - random channel

**Mick**

I have the following code...



```	price_filter = betfairlightweight.filters.price_projection(price_data=['EX_ALL_OFFERS', 'SP_PROJECTED'])

	print(f"mk_id={mk_id}")

	print(f"price_filter={price_filter}")

	market_books = trading.betting.list_market_book(market_ids=[mk_id],price_projection=price_filter)```

Which produces the following output



```mk_id=1.201434570

price_filter={'priceData': ['EX_ALL_OFFERS', 'SP_PROJECTED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}

Traceback (most recent call last):

  File "c:\Users\mick\Predictor\bfapi\bfex.py", line 2556, in &lt;module&gt;

    display_odds_for_this_race( course,stime,None,race_fp,            True,        "WIN")

  File "c:\Users\mick\Predictor\bfapi\bfex.py", line 1065, in display_odds_for_this_race

    market_books = trading.betting.list_market_book(market_ids=[mk_id],price_projection=price_filter)

  File "c:\users\mick\appdata\local\programs\python\python310\lib\site-packages\betfairlightweight\endpoints\betting.py", line 283, in list_market_book

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File "c:\users\mick\appdata\local\programs\python\python310\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 55, in request

    self._error_handler(response_json, method, params)

  File "c:\users\mick\appdata\local\programs\python\python310\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook

Params: {'marketIds': ['1.201434570'], 'priceProjection': {'priceData': ['EX_ALL_OFFERS', 'SP_PROJECTED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}```

BTW, if instead I just had this at the start:

```	price_filter = betfairlightweight.filters.price_projection(price_data=['EX_ALL_OFFERS']) ```

then there is no error.

---

## 2022-07-27 11:51:10 - issues channel

**JFP**

Thanks [@U0174A50YKS](@U0174A50YKS), this should fix that issue.

---

## 2022-07-27 09:34:16 - issues channel

**Alessio**

and when it starts looping you start seeing the same error of execute_cancel over and over, right?

---

## 2022-07-26 22:12:04 - issues channel

**Newbie99**

This BET_TAKEN_OR_LAPSED issue has returned again (the full log won't help, its just a perpetual loop of Cancelling &amp; Executable):



```{"asctime": "2022-07-26 18:49:36,460", "levelname": "INFO", "message": "execute_cancel", "trading_function": "cancel", "elapsed_time": 0.0769505500793457, "response": {"customerRef": "b236ce8e0d1311ed95da02054918c7c6", "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.201257099", "instructionReports": [{"status": "FAILURE", "errorCode": "BET_TAKEN_OR_LAPSED", "instruction": {"betId": "275113850428"}}]}, "order_package": {"id": "b236ce8e-0d13-11ed-95da-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7fd0c9f06d10&gt;", "market_id": "1.201257099", "orders": ["138781504696928340"], "order_count": 1, "package_type": "Cancel", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}```

What does confuse me though, is that it says retry_count is 0 (and this always shows zero looking through), even though it attempts to cancel the order multiple times.



Appreciate this is a known issue, but I'm really struggling to come up with a stopgap solution as nothing I've tried works, does anyone have any sticking plaster suggestions for now?



Just in case anyone reading this hasn't seen this before, it occurs when Flumine tries to cancel an order that has already been matched, for some reason in some situations it gets stuck in an endless loop, trying to cancel the bet that no longer exists...but I can't figure out why. Even more strangely it seems to occur loads over a period and then stops for weeks or months on end!

---

## 2022-07-24 10:54:00 - general channel

**PeterLe**

I use Lightsail, windows and Ubuntu. I didn't realise till Birchy mentioned it, that Lightsail is actually based on a EC2 (T Class?) but branded as Lightsail.  Lightsail is a fixed monthly cost and is much cheaper than If you choose an ‘EC2’

---

## 2022-07-24 10:32:19 - issues channel

**Gib**

Traceback (most recent call last):

  File "bflw_stream_v4.py", line 21, in &lt;module&gt;

    trading.login_interactive()

  File "/usr/local/lib/python3.8/dist-packages/betfairlightweight/endpoints/logininteractive.py", line 30, in __call__

    (response, response_json, elapsed_time) = self.request(

  File "/usr/local/lib/python3.8/dist-packages/betfairlightweight/endpoints/logininteractive.py", line 56, in request

    check_status_code(response)

  File "/usr/local/lib/python3.8/dist-packages/betfairlightweight/utils.py", line 34, in check_status_code

    raise StatusCodeError(response.status_code)

betfairlightweight.exceptions.StatusCodeError: Status code error: 403

---

## 2022-07-24 10:31:40 - issues channel

**Gib**

hi, ive created a small app to record market data using streaming, however i have now decided to migrate to GCP on a linux box and having a few problems. ive set up my linux box, but i am getting an error logging in to betfair with logininteratice.py. im assuming this is in relation to firewall rules. can someone advise what ports i need to open? or point me to the right documentation so i can check?

---

## 2022-07-21 14:07:05 - strategies channel

**DeeJenn**

100*0=0



Granted, this is more complicated when we’re talking about GBP instead of USD, but crypto exchanges let you convert between USD and USDC for no fees at a fixed rate of 1

---

## 2022-07-21 13:17:26 - strategies channel

**D C**

I am not anti crypto in general but agree with [@U4H19D1D2](@U4H19D1D2) in general - with the exception that it WOULD allow a workaround for people who get on the arse end of affordability checks (if they come to pass). Problem is that it then creates so many more problems and most people who are NOT addicts would just say that gambling is just too much hassle.

---

## 2022-07-21 11:30:31 - general channel

**Rudeger Jamison**

Shout out to the underrated fact that using the Flumine simulation is an unbelievably good way to iron out any possible bugs you have in your code. :white_check_mark:

---

## 2022-07-19 14:52:29 - betconnect channel

**liam**

spent hours on that before, python need to sort that error out

---

## 2022-07-19 14:46:53 - betconnect channel

**Mick**

I've fallen at the first hurdle trying to use betconnect. I have done pip install betconnect, then if I just run this:



`import betconnect`

`from betconnect.apiclient import APIClient`



I get... ModuleNotFoundError: No module named 'betconnect.apiclient'; 'betconnect' is not a package

---

## 2022-07-18 19:01:08 - random channel

**Newbie99**

With the Closed Market Logging control, should the following always produce an output, even if there are no settled orders (e.g. orders were placed, but 100% of orders were cancelled and market profit = 0)?



```def _process_cleared_markets(self, event):

        cleared_markets = event.event

        for cleared_market in cleared_markets.orders:

            [http://logger.info|logger.info](http://logger.info|logger.info)(

                "Cleared market",

                extra={

                    "market_id": cleared_market.market_id,

                    "bet_count": cleared_market.bet_count,

                    "profit": cleared_market.profit,

                    "commission": cleared_market.commission,

                },

            )```

Or does the above only return an output when there are 1 or more settled orders (I assumed it was the former, but I don't seem to get any output if I only have cancelled orders and I'm not sure if that's because I'm doing something weird or if its expected behaviour)?



I'm guessing I'm doing something weird as I output to a JSON and despite no error, I suspect something is going on there, but just wanted to check...

---

## 2022-07-17 17:20:21 - strategies channel

**liam**

Correct not having the sp would cause issues in simulation! Out of interest where you getting an error or just negative pnl

---

## 2022-07-17 17:11:41 - strategies channel

**Tom Cannon**

Hey, thanks all! Assuming that EXECUTION_COMPLETE was matched was clearly a mistake. I have now fixed these issues and have a very steady profit of ~1200 a month  :tada:



I have similar responses from flumine.simulation and my EV - however my data doesn't have any runner.sp.actual_sp (I got this from historic data) which causes issues with the flumine simulation?



I've had to add a hack to simulatedorder._ process_sp_ to read sp_prices from a file I'd compiled from [https://promo.betfair.com/betfairsp/prices](https://promo.betfair.com/betfairsp/prices) I'm assuming (hoping) this data is reliable.



Feel free to direct message me if anyone else doesn't have the runner.sp.actual_sp in their data,  I'll share you the code :slightly_smiling_face:



Again, thanks for the help.

---

## 2022-07-16 10:43:21 - strategies channel

**Tom Cannon**

[@UCQB6S222](@UCQB6S222) this would be ideal. I've just implemented a green strategy and unfortunatly I'm getting similar negative profits in simulation - which doesn't make much sense to me ...



[@U4H19D1D2](@U4H19D1D2)

Am I correct in thinking that OrderStatus.EXECUTION_COMPLETE is only true when an order has been fully matched? So laying immediately at the BSP using MarketOnCloseOrder should give me a margin if BSP &lt; matched_back_price (which it does when I track it) but in simulation It's as if my lay order is never fulfilled. The only similar debugging I can find is here [https://github.com/betcode-org/flumine/issues/354](https://github.com/betcode-org/flumine/issues/354) Of which I think is still present in FlumineSimulation.__process_s_simulation_orders().



I also seem to be getting matched in simulation at strange prices. For ~95% it's sensible (matched at 5 &amp; BSP = 4.677) but some are far too high in my opinion (for instance matched at 170 for BSP 26) I suspect that these aren't actually getting matched - are there other reasons that EXECUTION_COMPLETE would be triggered?

---

## 2022-07-16 06:41:31 - issues channel

**Andrew**

But what's the 1. purpose as the prefix of the market Id?

---

## 2022-07-15 17:22:31 - strategies channel

**Tom Cannon**

My expected returns based on EV and simulation are so wildly off I think both of your points probably means I've either made an error or discovered a very niche area of BSP's that are not representing Pr(Win). If I were a betting man :face_with_rolling_eyes: I'd assume the error :joy:.

---

## 2022-07-15 16:54:31 - strategies channel

**Tom Cannon**

Hey all,



Following from my previous post (5 posts above).  Thank you all for the pointers I'm making far better progress!



I have changed strategy and am now successful matching better than BSP (On FlumineSimulation). In fact ... I match about 100 trades correctly and 20 incorrectly per race. Which is great!



But I have vast differences in expected profit from calculation and expected profit from Flumine. Calculations make me rich :slightly_smiling_face: and simulation makes me poor :grimacing:

I'm simulating on a months worth of Horses Win data - and so expect that this is statistically significant enough to tend them to the same expectation. (If BSP is a good indicator of probability?)



For each back trade matched I calculate expected return as:



E_back = Pr(Win) * return - Pr(Lose) * stake

E_lay = Pr(Lose) * stake - Pr(Win) * return



Where:  Pr(Win) = 1/bsp,       Pr(Lose) = 1 - (1/bsp),       return = (price-1)*(stake)



Profit is calculated directly from Flumines market.blotter order.simulated.profit (which I'm assuming works from race results)



Can anyone see any issues / had any similar realisations with using BSP as an estimate of Pr(win), or have any suggestions of where I might have made an error?



Ofcourse ... I could just engineer a green at BSP method and remove the need for expected returns ... #teamgreen :face_with_rolling_eyes:

---

## 2022-07-14 17:53:26 - issues channel

**Mick**

I get the same error with either of these

---

## 2022-07-14 17:35:50 - issues channel

**Mick**

I'm having a bash at using betfairutil... there doesn't seem to be any documentation for it (did I miss something?). But I think I am supposed to call betfairutil.prices_file_to_csv_file(filename_including_path_of_source,filename_including_path_of_destination_csv). However, I get KeyError: 'selection_id' - this is happening within pandas. The (randomly selected) input file I'm trying to process is "BASIC-1.117880714". Any ideas?

---

## 2022-07-14 09:36:53 - general channel

**liam**

[https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#221-2022-07-14|flumine 2.2.1](https://github.com/betcode-org/flumine/blob/master/HISTORY.rst#221-2022-07-14|flumine 2.2.1) released, few bug fixes but also added `SimulatedSportsDataMiddleware` this allows the ability to process betfair sports data (cricket or race) chronologically through the simulation engine with a single line:



```framework.add_market_middleware(

    SimulatedSportsDataMiddleware("cricketSubscription", "res/sportsdata")

)```

The [https://github.com/betcode-org/flumine/blob/master/flumine/markets/middleware.py#L287|middleware](https://github.com/betcode-org/flumine/blob/master/flumine/markets/middleware.py#L287|middleware) will pick up the file on the marketId and create a generator that is then called based on the publishTime of the market, this could easily be modified to simulate other historic events football/tennis/scores/custom events etc



Full example strategy [https://github.com/betcode-org/flumine/blob/master/examples/simulate-sportsdata.py#L22|here](https://github.com/betcode-org/flumine/blob/master/examples/simulate-sportsdata.py#L22|here) that places a back bet on the bowling team on a wicket :moneybag:

---

## 2022-07-14 09:28:52 - random channel

**Newbie99**

I use the market catalogue middleware example when backtesting and it all works fine:



[https://github.com/betcode-org/flumine/blob/master/examples/middleware/marketcatalogue.py](https://github.com/betcode-org/flumine/blob/master/examples/middleware/marketcatalogue.py)



However, when self recording, the market catalogues are saved as a .json.gz, so if I run the following in a standalone script:



```mc_path = '/1.200396929.json.gz'



with open(mc_path, "rb") as r:

    data = gzip.GzipFile(fileobj=r).read()

    catalogue_json_data = json.loads(data)

    print(catalogue_json_data)```

As expected it returns:



```{'marketId': '1.200396929', 'marketName': 'Over/Under 2.5 Goals', 'marketStartTime': '2022-06-22T16:00:00.000Z', 'description': {'persistenceEnabled': True, 'bspMarket': False, 'marketTime': '2022-06-22T16:00:00.000Z', 'suspendTime': '2022-06-22T16:00:00.000Z', 'bettingType': 'ODDS', 'turnInPlayEnabled': True, 'marketType': 'OVER_UNDER_25', 'regulator': 'GIBRALTAR REGULATOR', 'marketBaseRate': 2.0, 'discountAllowed': False, 'wallet': 'UK wallet', 'rules': '&lt;!--Football - Over/Unders --&gt;&lt;br&gt;How many goals will be scored in this match.&lt;br&gt; All bets apply to Full Time according to the match officials, plus any stoppage time. Extra-time/penalty shoot-outs are not included.&lt;br&gt;&lt;br&gt;&lt;/b&gt;For further information please see &lt;a href=[http://content.betfair.com/aboutus/content.asp?sWhichKey=Rules%20and%20Regulations#undefined.do](http://content.betfair.com/aboutus/content.asp?sWhichKey=Rules%20and%20Regulations#undefined.do) style=color:0163ad; text-decoration: underline; target=_blank&gt;Rules &amp; Regs&lt;br&gt;&lt;br&gt;\n', 'rulesHasDate': True, 'priceLadderDescription': {'type': 'CLASSIC'}}, 'totalMatched': 35.4, 'runners': [{'selectionId': 47972, 'runnerName': 'Under 2.5 Goals', 'handicap': 0.0, 'sortPriority': 1, 'metadata': {'runnerId': '47972'}}, {'selectionId': 47973, 'runnerName': 'Over 2.5 Goals', 'handicap': 0.0, 'sortPriority': 2, 'metadata': {'runnerId': '47973'}}], 'eventType': {'id': '1', 'name': 'Soccer'}, 'competition': {'id': '4051', 'name': 'Norwegian Cup'}, 'event': {'id': '31543907', 'name': 'Strindheim v Kristiansund', 'countryCode': 'NO', 'timezone': 'GMT', 'openDate': '2022-06-22T16:00:00.000Z'}}```

However, if I try to adapt the middleware code as follows:



```class MarketCatalogueMiddleware(Middleware):

    def add_market(self, market) -&gt; None:

        try:

            zipped_catalogue_file_path = str(get_mc_folder(market, zipped_folder_path))

            catalogue_file_path = os.path.join(MARKET_CATALOGUE_PATH, market.market_id + '_market_catalogue.json')

            if zipped_catalogue_file_path is not False:

                if os.path.exists(zipped_catalogue_file_path):

                    with open(zipped_catalogue_file_path, "rb") as r:

                        data = gzip.GzipFile(fileobj=r).read()

                        catalogue_json_data = json.loads(data)

                        print(catalogue_json_data)```

Then I just get the following error:



```Exception 'int' object has no attribute 'startswith' occured on market 1.200522372```

If I use a different approach, as follows:



```class MarketCatalogueMiddleware(Middleware):

    def add_market(self, market) -&gt; None:

        try:

            zipped_catalogue_file_path = str(get_mc_folder(market, zipped_folder_path))

            catalogue_file_path = os.path.join(MARKET_CATALOGUE_PATH, market.market_id + '_market_catalogue.json')

            if zipped_catalogue_file_path is not False:

                if os.path.exists(zipped_catalogue_file_path):

                    with gzip.open(zipped_catalogue_file_path, 'rb') as fin:

                        catalogue_json_data = json.loads(fin.read().decode('utf-8'))

                        market.market_catalogue = MarketCatalogue(**catalogue_json_data)```

Then I get the following error:



```Exception Not a gzipped file (b'{"') occured on market 1.199593125```

Now of course, I can get around this by unzipping the files first, but I feel I must be missing something obvious here, why can I unzip into memory from a static script, but not via middleware, I presume there is a logical reason and whilst it doesn't matter as there is an obvious alternative approach, I would like to understand why this doesn't work if possible?

---

## 2022-07-13 11:49:11 - random channel

**Leo**

Yeah it's a tricky one really. I use fundamental models and my general assessment is that the chances of a horse improving significantly over a new distance or first time in handicaps etc is usually overestimated in the market in comparison to its previous form. But there are definitely exceptions 

---

## 2022-07-13 11:22:00 - issues channel

**liam**

Ah, no the market recorder will use a different stream, I have a fix [https://github.com/betcode-org/flumine/pull/594/commits/9895e827ea15aa51db74bd36ed957358c235c983|here](https://github.com/betcode-org/flumine/pull/594/commits/9895e827ea15aa51db74bd36ed957358c235c983|here) that I will push out today

---

## 2022-07-13 00:21:17 - random channel

**Newbie99**

A question for the football traders on here (well its probably generic in all honesty)....



Presumably I just need to maintain a many to one relationship for whatever randomness Betfair decide to come up with to map to whichever 3rd party data provider, or are situations like the one below likely to be errors, rather than duplicates (i.e. rather than keeping both with a many to one mapping, should I just keep the one that comes up more often and ignore any one offs)?



```'betfair_runner_name': 'Paris St-G', 'betfair_selection_id': 489720

'betfair_runner_name': 'PSG', 'betfair_selection_id': 65323,```



---

## 2022-07-11 20:17:31 - general channel

**liam**

Potentially, run it and find out, you will get errors 

---

## 2022-07-11 15:39:30 - issues channel

**mon mon**

I used to have a worker which updated my time-limited market filters for the streams every few hours (as a way to get around the 200 market limit).

I was worried this might be causing the error so I have since got rid of it, and now use a standard market filter with no time limits.

Can post a new log if that helps.

---

## 2022-07-11 15:33:26 - issues channel

**Gib**

i think that worked, im now getting a certs error, so im guessing it will only work with trading.login() not trading.login_interactive()?

---

## 2022-07-11 15:19:42 - issues channel

**mon mon**

Today I tried running with a single market filter to see if that made any difference ( I usually run 2 or 3) - the instance ran for a bit longer but eventually ended up with the same "list.remove(x): x not in list" error.

---

## 2022-07-11 14:49:18 - issues channel

**Gib**

thanks for quick response liam, yes looks like i got an error when installing logging. will try to get that working...  Great job putting these resource together, really appreciate it.

---

## 2022-07-11 14:22:22 - issues channel

**Gib**

hi, ive been using the streaming example below as basis for my app and it is working brilliantly. However, when i leave running for a long period, it does seem to time out. Ive tried adding the error handing code to overcome this but it seems to hang. Do i need to do anything special to get the errorhandling code to run? [https://betcode-org.github.io/betfair/streaming/](https://betcode-org.github.io/betfair/streaming/) i get the "Starting MarketStreaming" in my console about 7 times in a row then it just seems to stop. Any help appreciated

---

## 2022-07-08 12:39:23 - issues channel

**mon mon**

Here's the time before the error - let me know if you need a bigger time slice:

---

## 2022-07-08 09:30:59 - issues channel

**liam**

any logs before the error you can share?

---

## 2022-07-08 09:30:45 - issues channel

**liam**

damn, thought I had fixed this, will look into it today

---

## 2022-07-07 22:55:22 - issues channel

**mon mon**

I haven't spotted anything nefarious in the logs just before Flumine shuts itself down, but on the console the last message from python is

```Traceback (most recent call last):

  File "live_trade.py", line 717, in &lt;module&gt;

    framework.run()

  File "/usr/local/lib/python3.8/site-packages/flumine/flumine.py", line 57, in run

    self._process_close_market(event)

  File "/usr/local/lib/python3.8/site-packages/flumine/baseflumine.py", line 347, in _process_close_market

    self._remove_market(market)

  File "/usr/local/lib/python3.8/site-packages/flumine/baseflumine.py", line 211, in _remove_market

    self.markets.remove_market(market.market_id)

  File "/usr/local/lib/python3.8/site-packages/flumine/markets/markets.py", line 34, in remove_market

    self.events[event_id].remove(market)

ValueError: list.remove(x): x not in list```

---

## 2022-07-06 23:22:27 - issues channel

**Jonjonjon**

Thinking about it, I'm not sure if always using the market book will fix things. As I don't know if it definitely updates correctly. From looking at the way it currently updates the market catalogue, that should have happened every minute, though it didn't happen for me on atleast 2 occasions last month.:shrug::skin-tone-6:

---

## 2022-07-06 22:42:30 - issues channel

**Jonjonjon**

Yes. Thanks Liam. I've just done a local change that does that, though that won't fix it for other users.

---

## 2022-07-06 22:06:56 - issues channel

**liam**

I can have a look tomorrow, going forward I assume using the MarketBook for the start time in live (rather than cat) would fix things?

---

## 2022-07-06 13:14:41 - betconnect channel

**Sam - DH**

I thought initially the issue was just GetBetRequestFilter() erroneously converting this param to a String value before making the request, as it's currently defined as

```accept_each_way: Optional[str] = Field(default=0)```

Which meant that even passing in the default value of 0 resulted in a

```message: accept_each_way value is invalid.```

error when attempting .bet_request_get().



Although I changed this param param definition to

```accept_each_way: Optional[int] = Field(default=0)```

and it still wouldn't allow 1 as a valid value; passing in 0 was now fine however.



Went on to try this just using the requests library and found similar problems, allows 0, doesn't allow 1, nor any other combination of 'True', 'Included' etc. so, main issue seems outside the scope of the wrapper.



Finally, had a quick look through the JS on your site for closure, and found a section that seems to confirm it should be dictated by a 1 or a 0 so, time to call in the big boys.



Cheers in advance for any help.

Sam

---

## 2022-07-05 15:09:55 - general channel

**Alessio**

exceptions, I'd say :wink:

---

## 2022-07-05 12:01:50 - general channel

**D**

If you can see past all my formatting errors :grinning:

---

## 2022-07-05 11:38:12 - general channel

**Phil Anderson**

Hi all. I'm having problems with market_start_time filter. I've used this same filter with football and it works fine:



```comp_filter = filters.market_filter(

                                    event_type_ids=[7],

                                    venues=[race_edit],

                                    market_countries=['GB', 'IE'],

                                    market_start_time={

                                        "from": current_time2.format(datetime.date.today()),

                                        "to": "{0}T14:45:00Z".format(datetime.date.today())

                                       }```

But for horse racing it's showing races after 14:45. I was actually looking to find the exact time (i.e. market_start_time=["14:45"] but it didnt like that so was just going to put "from2 and "to" as race start time, but realised the cutoff time didn't seem to have any effect.



In essence my questions are:

1. Is there something different with horse racing why my cutoff time doesnt work?

2. How do I find a specific race?

I can cycle through the races and match the time but I'm sure there must be a simpler way to do it.



EDIT:



OK so I've actually got it working. After the original filter i've put:



```results = trading.betting.list_events(

    filter=comp_filter

)



for i in results:

    print(i.event.id, i.event.name)

    market_types_filter = betfairlightweight.filters.market_filter(event_ids=[i.event.id],

                                                                   market_type_codes=["WIN"],                                                                           

                                                                   market_start_time={

                                        "from": "{0}T14:45:00Z".format(datetime.date.today()),

                                        "to": "{0}T14:45:01Z".format(datetime.date.today())

                                       }

                                                                   )```

Now this works fine, but I'd still like a way of putting in the start time if possible. something like:



```market_start_time = "{0}T14:45:00Z".format(datetime.date.today())```

Whatever way I try it I get highlighted as an error. Does the market_start_time ave to have a "from" or a "to". And if so is there another way to do this?



Thanks in advance for any help.

---

## 2022-07-04 12:40:16 - issues channel

**Dave**

Pfft. print() is the OG debugger :laughing:

---

## 2022-07-04 10:32:05 - issues channel

**Unknown**

Similar to [@UBS7QANF3](@UBS7QANF3)'s Pycharm suggestion. I use the debugger in vscode. It gives me a panel like the one below that I can use to drill down to any level in any of the data objects.

---

## 2022-07-03 15:18:53 - issues channel

**Mo**

Debugger in PyCharm is good for this

---

## 2022-07-03 14:57:47 - issues channel

**mon mon**

I've trolled through the DEBUG level logs but can't see anything that hints as to why the program is deciding to shut down.

---

## 2022-07-03 14:56:27 - issues channel

**mon mon**

That was just the console output....

```log_config = {

        'version':1,

        'disable_existing_loggers': False,

        'formatters':{

                'screen_text': {

                        'format': '%(asctime)s | %(levelname)-8s | %(message)s',

                        'datefmt':"%H:%M:%S"

                },

                "json_file": {

                        '()': 'pythonjsonlogger.jsonlogger.JsonFormatter',

                        'format': "%(asctime)s %(levelname)s %(name)s %(message)s",

                },

        },

        'handlers':{

                'consoleHandler':{

                        'formatter': "screen_text",

                        'class': "logging.StreamHandler",

                        'level': 'INFO',

                },

                'fileHandler':{

                        'formatter': 'json_file',

                        'class': 'logging.handlers.TimedRotatingFileHandler',

                        'filename': 'logs/flumine.log',

                        'when': 'midnight',

                        'interval': 1,

                        'backupCount':7,

                        'level': 'DEBUG',

                },

        },

        'root':{

                'level': 'DEBUG',

                'handlers' : ['consoleHandler','fileHandler'],

        },

}





logging.config.dictConfig(log_config)

logger = logging.getLogger()```

---

## 2022-06-30 18:01:51 - general channel

**PeterLe**

Hi Liam, This is hte message (which i can now see is coming from flumine) : "Violation", "violation_msg": "Order has violated: STRATEGY_EXPOSURE Error: Potential selection exposure (32.00) is greater than strategy.max_selection_exposure (30)"

---

## 2022-06-27 14:19:14 - general channel

**James**

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}

---

## 2022-06-26 13:39:18 - issues channel

**Beginner**

Yesterday I discovered that Heroku and several other code clouds don't have a path to tell the code where to find the certificate files: `cert_files=('./certs/bf_certs.pem')`



So I tried another approach, logging into my machine, saving a pickle file and uploading it to Google Drive:



```with open('betfair_login.pickle', 'wb') as handle:

    trading = betfairlightweight.APIClient('email', 'pssw', app_key='app_key', cert_files=('./certs/bf_certs.pem'),session=requests.Session())

    trading.login()

    pickle.dump(trading, handle, protocol=pickle.HIGHEST_PROTOCOL)```

And on Heroku use `urllib.request.urlopen` passing the url of the Drive file:



```from urllib.request import urlopen

    loaded_pickle_object = pickle.load(urlopen("[https://drive.google.com/file/d/xxxxxxxxxxxxxxxx/](https://drive.google.com/file/d/xxxxxxxxxxxxxxxx/)"))

    trading = loaded_pickle_object```

However, when trying to open it generates an error `invalid load key, '&lt;'.`



Could someone help me find an option to use the betfairlightweight when there is no way to pass the path where the certificates are?

Thank you in advance and happy Sunday to all!

---

## 2022-06-21 17:45:52 - random channel

**Jonjonjon**

It's telling me I need to pay £x&gt;0. I'd consider it fixed when I need to pay £0.

---

## 2022-06-21 17:20:35 - random channel

**Mr West**

PC page fixed now

---

## 2022-06-21 07:48:44 - issues channel

**Dave**

Yeah was just about to say the same, error page straight outta the 2000s

---

## 2022-06-21 07:48:09 - random channel

**thambie1**

Betfair's down, I would ignore that error for now

---

## 2022-06-21 07:42:08 - issues channel

**thambie1**

This crash looks pretty bad, never seen "500 Internal Server Error" when going to [http://betfair.com|betfair.com](http://betfair.com|betfair.com)

---

## 2022-06-18 20:50:13 - issues channel

**Brøndby IF**

I didn't find it directly in search bar on documentation ([https://docs.developer.betfair.com/](https://docs.developer.betfair.com/)), so I'll publish this list here because if in the future someone has a question with an error code and tries to search bar here in the slack community, they will find it without having to ask how I did it:



`ANGX-0001 → The operation requested too much data (TOO_MUCH_DATA)`

`ANGX-0002 → Invalid input data (INVALID_INPUT_DATA)`

`ANGX-0003 → The session token passed is invalid (INVALID_SESSION_INFORMATION)`

`ANGX-0004 → An application key is required for this operation (NO_APP_KEY)`

`ANGX-0005 → A session token is required for this operation (NO_SESSION)`

`ANGX-0006 → An unexpected internal error occurred that prevented successful request processing (UNEXPECTED_ERROR)`

`ANGX-0007 → The application key passed is invalid (INVALID_APP_KEY)`

`ANGX-0008 → There are too many pending requests (TOO_MANY_REQUESTS)`

`ANGX-0009 → The service is currently too busy to service this request (SERVICE_BUSY)`

`ANGX-0010 → Internal call to downstream service timed out (TIMEOUT_ERROR)`

`ANGX-0011 → The application key creation has failed (APP_KEY_CREATION_FAILED)`

`ANGX-0012 → The application name specified already exists (DUPLICATE_APP_NAME)`

`ANGX-0013 → The application name specified is too long (APP_CREATION_FAILED)`

`ANGX-0014 → The request has exceeded the maximum allowed size (REQUEST_SIZE_EXCEEDS_LIMIT)`

`ANGX-0015 → The access to this functionality is not allowed (ACCESS_DENIED)`

`ANGX-0016 → Provided market group id does not identify a known market group (INVALID_MARKET_GROUP)`

`ANGX-0017 → Unable to delete/update limit as it doesn't exist (EXPOSURE_LIMIT_NOT_EXIST)`

`ANGX-0018 → Unable to unblock market group after exposure limit breach, market group is not blocked (MARKET_GROUP_NOT_BLOCKED)`

---

## 2022-06-18 17:06:14 - issues channel

**Unknown**

Thanks [@UBS7QANF3](@UBS7QANF3) just today I received 18 such errors, so I'll put a pass to ignore this.

---

## 2022-06-18 17:05:03 - issues channel

**Mo**

Random error, nothing you can do about it. Just make the request again

---

## 2022-06-18 17:03:54 - issues channel

**Brøndby IF**

Good afternoon everyone, I researched about this error but I didn't find anything to understand and work around it, has anyone gone through it?



`index                                      4`

`event_id                            31536297`

`event_name    Baltyk Gdynia v Jarota Jarocin`

`Name: 4, dtype: object`



`Traceback (most recent call last):`

`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': ['1.200293211'], 'priceProjection': {'priceData': ['EX_TRADED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}` 

`Exception: None` 

`Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': '...........', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': '..........', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`

---

## 2022-06-16 18:02:25 - issues channel

**RMG**

and back to the same error. :shrug:

---

## 2022-06-16 17:22:44 - issues channel

**RMG**

btw, I had all this (code and certs) working before (2 years ago), but tried to login this week, and gave me the certs errors, so i've recreated them, but still receiving errors.

---

## 2022-06-16 17:05:52 - issues channel

**Unknown**

Here's the full error:

---

## 2022-06-16 16:58:14 - issues channel

**Mo**

Can you share the full error?

---

## 2022-06-16 16:57:04 - issues channel

**RMG**

Have created keys with XCA, uploaded .crt to BF security, but when i try and use trading.login() I'm getting similar errors to above:  Max tries exceeded with url: /api/certlogin.

---

## 2022-06-16 16:02:37 - random channel

**liam**

Reminds me of the legendary inplay [https://community.betfair.com/horse_racing/go/thread/view/94102/28802591/tony-calvin-it-is-an-obvious-error?liveView=0&amp;pg=5|error](https://community.betfair.com/horse_racing/go/thread/view/94102/28802591/tony-calvin-it-is-an-obvious-error?liveView=0&amp;pg=5|error) 

---

## 2022-06-16 13:48:24 - issues channel

**Newbie99**

Actually I lie...Interactive login does actually appear to work now, odd. So it must be cert related (which makes sense of course from the error), odd it still works on AWS with certs though.

---

## 2022-06-16 13:37:27 - issues channel

**Newbie99**

By chance is anyone else getting errors today (can't see anything showing as down):



```ERROR:flumine.clients.betfairclient:BetfairClient `login` error

Traceback (most recent call last):

  File "D:\Python38\lib\site-packages\urllib3\connection.py", line 169, in _new_conn

    conn = connection.create_connection(

  File "D:\Python38\lib\site-packages\urllib3\util\connection.py", line 96, in create_connection

    raise err

  File "D:\Python38\lib\site-packages\urllib3\util\connection.py", line 86, in create_connection

    sock.connect(sa)

socket.timeout: timed out



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:\Python38\lib\site-packages\urllib3\connectionpool.py", line 699, in urlopen

    httplib_response = self._make_request(

  File "D:\Python38\lib\site-packages\urllib3\connectionpool.py", line 382, in _make_request

    self._validate_conn(conn)

  File "D:\Python38\lib\site-packages\urllib3\connectionpool.py", line 1010, in _validate_conn

    conn.connect()

  File "D:\Python38\lib\site-packages\urllib3\connection.py", line 353, in connect

    conn = self._new_conn()

  File "D:\Python38\lib\site-packages\urllib3\connection.py", line 174, in _new_conn

    raise ConnectTimeoutError(

urllib3.exceptions.ConnectTimeoutError: (&lt;urllib3.connection.HTTPSConnection object at 0x0000022DED12BC40&gt;, 'Connection to [http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com) timed out. (connect timeout=3.05)')



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:\Python38\lib\site-packages\requests\adapters.py", line 439, in send

    resp = conn.urlopen(

  File "D:\Python38\lib\site-packages\urllib3\connectionpool.py", line 755, in urlopen

    retries = retries.increment(

  File "D:\Python38\lib\site-packages\urllib3\util\retry.py", line 574, in increment

    raise MaxRetryError(_pool, url, error or ResponseError(cause))

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPSConnection object at 0x0000022DED12BC40&gt;, 'Connection to [http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com) timed out. (connect timeout=3.05)'))```

Interestingly Interactive login also doesn't work for me....however this is only when trying to connect from my local machines.



AWS appears to be chugging away happily (all the certs are obviously the same and Interactive login doesn't work locally, so I'm a bit perplexed).

---

## 2022-06-15 14:58:30 - strategies channel

**Unknown**

after all adjustments, with $1 fixed stake.

---

## 2022-06-15 13:53:38 - strategies channel

**Unknown**

I made another selection rule, to restrict the model selections using VWAP.



With $1 fixed stake:

---

## 2022-06-15 13:32:18 - strategies channel

**Unknown**

This is the version with *$1* fix stake.

---

## 2022-06-13 11:54:23 - betfair-news channel

**Oliver Archer**

Hi all, potential noob question incoming.. I'm looking to write an automated trading script in Python that uses a scheduler to run every couple of minutes. I could run it on my local machine but ideally don't want to have to have my laptop on 24/7 so looking to move it to the cloud. I've previously written a similar automated script trading crypto through a Binance API using a combination of Kaggle notebooks and PythonAnywhere (followed a guide on Towards Data Science) but when I try to do the same using betfairlightweight I get a 403 error when logging in which I'm assuming is a result of the servers being based in the US. So question is, how would people recommend I move my script to the cloud? Would ideally like to use the Kaggle/PythonAnywhere route if at all possible given I'm paying for that already, but can sign up to something else if I have to! Thanks in advance!!

---

## 2022-06-13 09:10:41 - general channel

**Barclay**

ok a restart fixed the issue, not sure what the exact problem was then

---

## 2022-06-11 09:21:15 - issues channel

**Rudeger Jamison**

```    def _write_logs(self, client, data: List[bytes], write_table: str):

        records = [{"Data": d, "PartitionKey": f"{self.log_prefix}{write_table}"} for d in data]

        for chunk in chunks(records, n=200):

            client.put_records(StreamName="LoggingStream", Records=chunk)```

---

## 2022-06-11 07:07:27 - issues channel

**liam**

Can you share some code that replicates? Very hard to debug without 

---

## 2022-06-08 01:10:14 - random channel

**Rudeger Jamison**

Hey - I am trying to do this within flumine and make the currency request process every 24 hours as a CustomStream.



I am trying to access the bflw object in order to make a request.



tried *`self.clients.get_betfair_default().betting_client.account.list_currency_rates("AU")`*



*but get an error* 

```Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}```

---

## 2022-06-06 09:10:12 - general channel

**liam**

Any ideas? My logs all looked fine, showing the 503 errors etc, I can't see anything obvious that was causing it, instinct is telling me maybe it was one of the workers stuck in a loop

---

## 2022-06-06 09:02:26 - issues channel

**liam**

What do you mean by streaming properly? I haven't had any errors on my side

---

## 2022-06-05 07:51:11 - random channel

**LM**

So using the below will continually give me all markets from the filter continuously? At the moment I'm passing market_ids to the filter which is why it stops at the end of the day. I needed to use the second approach to begin with as I was getting errors associated with connecting to too many streams (may be wrong terminology).

```    market_filter=streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["WIN"],

        race_types=["Flat"],

        turn_in_play_enabled=True

    )```

---

## 2022-05-31 18:57:29 - random channel

**Newbie99**

[@UUX1L88MC](@UUX1L88MC) I was playing around with your Betfair Data library and I just wanted to check whether it can be used in conjunction with Flumine for backtesting?



I ask as I noted you can output BFLW objects, but I can't seem to get it to work for this purpose, so I'm wondering if this isn't a valid use case?



As an example, I would normally do something like this with a standard file (uncompressed from a .gz file):



```markets = ["Y:/betcode/unzipped_recorder_files/1.199726796"]





strategy = example_strategy(market_filter={"markets": markets},

        market_data_filter=streaming_market_data_filter(

            fields=[

                "EX_ALL_OFFERS",

                "EX_TRADED",

                "EX_TRADED_VOL",

                "EX_LTP",

                "EX_MARKET_DEF",

                "SP_TRADED",

                "SP_PROJECTED",

            ]

            ),

            name='dummy_strategy_name',

            )



framework.add_strategy(strategy)```

So I assumed I could do something like this:



```markets = bfd.Files(["Y:/betcode/unzipped_recorder_files/1.199726796.gz"])





strategy = example_strategy(market_filter={"markets": markets},

        market_data_filter=streaming_market_data_filter(

            fields=[

                "EX_ALL_OFFERS",

                "EX_TRADED",

                "EX_TRADED_VOL",

                "EX_LTP",

                "EX_MARKET_DEF",

                "SP_TRADED",

                "SP_PROJECTED",

            ]

            ),

            name='dummy_strategy_name',

            )



framework.add_strategy(strategy)```

But then I get the following:



```  File "D:\Python38\lib\site-packages\flumine\baseflumine.py", line 101, in add_strategy

    self.streams(strategy)  # create required streams

  File "D:\Python38\lib\site-packages\flumine\streams\streams.py", line 44, in __call__

    markets.sort()

AttributeError: 'builtins.Files' object has no attribute 'sort'```

So I essentially wanted to check whether I'm doing something wrong in terms of my approach, or whether this isn't what it is designed to do?

---

## 2022-05-30 23:08:44 - issues channel

**John Foley**

Im guessing probably invalid credentials/app key causing you to get an error message as a response (rather than a valid json response)

---

## 2022-05-30 21:50:14 - issues channel

**Newbie99**

Sounds like an invalid json file from that error?

---

## 2022-05-30 21:23:29 - issues channel

**Michael**

Hi, I'm getting the following error when trying to pull a file list (same code as example) `json.decoder.JSONDecodeError: Expecting value: line 2 column 1 (char 1)`



During handling of the above exception, another exception occurred:

---

## 2022-05-26 12:04:51 - issues channel

**liam**

Hmm [@UG03WDCHH](@UG03WDCHH) had this issue, any fixes?

---

## 2022-05-26 11:58:05 - issues channel

**LM**

Any thoughts on below error. Seems to occur sporadically after flumine has been running for a while

```{"asctime": "2022-05-26 10:56:10,717", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ec2-user/.local/lib/python3.8/site-packages/flumine/worker.py\", line 229, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n  File \"/home/ec2-user/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ec2-user/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ec2-user/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.199541139'], 'customerStrategyRefs': ['ip-172-31-43-15'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03a-prd-05180823-000f838978', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03a-prd-05180823-000f838978', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.199541139'], 'customerStrategyRefs': ['ip-172-31-43-15'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03a-prd-05180823-000f838978', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03a-prd-05180823-000f838978', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

---

## 2022-05-25 09:42:15 - issues channel

**liam**

Sorry on holiday at the moment so can't investigate but I was under the impression I had fixed this in the latest version and had pulled all releases that had this issue 

---

## 2022-05-25 08:47:26 - issues channel

**Oliver Varney**

Ill debug more today but im not sure why this is not being hit currently size remaining is zero and the current_order.status is equal to EXECUTION_COMPLETE

---

## 2022-05-25 08:46:03 - issues channel

**mandelbot**

```{"asctime": "2022-05-25 07:30:16,680", "levelname": "WARNING", "message": "Order has violated: MARKET_VALIDATION Error: Market is not open", "control": "MARKET_VALIDATION", "error": "Market is not open", "order": ```

even though I have `market_book.status not in ["CLOSED", "SUSPENDED"]`  in `check_market_book`

---

## 2022-05-25 08:37:13 - issues channel

**mandelbot**

Seem to have a similar issue where my code is looking to cancel EXECUTABLE orders but getting "BET_TAKEN_OR_LAPSED" errors

---

## 2022-05-24 20:54:24 - issues channel

**Jonjonjon**

Reverting to 1.9 fixed my tests. Thanks for the tips guys.

---

## 2022-05-24 08:04:42 - issues channel

**Jonjonjon**

Yes, I had to rename a few things as things with Backtest in the name have been replace with Simulation. I updated those bits, so that things can run without throwing an error. I just hope I don't have to spend this evening going through the differences line by line.:disappointed:

---

## 2022-05-24 08:01:48 - issues channel

**Jonjonjon**

Ah good point. A mistake on my side. Though I did fix one of the breaks by changing my check_market_book function to check_market.

---

## 2022-05-23 07:32:32 - issues channel

**mandelbot**

So I've recently ported my marketrecorder to a linux ec2 but it keeps getting shut down for some reason. Can someone shed light on this for me please?



```{"asctime": "2022-05-23 05:16:35,115", "levelname": "INFO", "message": "Market removed", "market_id": "1.199445646"}

{"asctime": "2022-05-23 05:16:35,119", "levelname": "INFO", "message": "Market closed", "market_id": "1.199439954", "clients": {"Betfair": {"d": {"username": "d", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7fcb7bddd190&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}}, "Simulated": {}, "BetConnect": {}}, "markets": {"market_count": 728, "open_market_count": 670}, "streams": ["&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140512124557120)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 140511835891456)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 140511825401600)&gt;", "&lt;Thread(WIN_load_processor, started daemon 140511814911744)&gt;", "&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"]}

{"asctime": "2022-05-23 05:16:35,123", "levelname": "INFO", "message": "Removing market 1.199445645", "clients": {"Betfair": {"d": {"username": "de", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7fcb7bddd190&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}}, "Simulated": {}, "BetConnect": {}}, "markets": {"market_count": 728, "open_market_count": 670}, "streams": ["&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140512124557120)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 140511835891456)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 140511825401600)&gt;", "&lt;Thread(WIN_load_processor, started daemon 140511814911744)&gt;", "&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"]}

{"asctime": "2022-05-23 05:16:35,123", "levelname": "INFO", "message": "BackgroundWorker keep_alive shutting down", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x7fcb7967f5f0&gt;"}

{"asctime": "2022-05-23 05:16:35,426", "levelname": "INFO", "message": "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199439954.gz successfully loaded to s3"}

{"asctime": "2022-05-23 05:16:35,452", "levelname": "INFO", "message": "1.199439954 successfully loaded marketCatalogue to s3"}

{"asctime": "2022-05-23 05:16:35,452", "levelname": "INFO", "message": "Removing: /home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199445646.gz, age: 3669.27s"}

{"asctime": "2022-05-23 05:16:35,453", "levelname": "INFO", "message": "Removing: /home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199445646, age: 3669.29s"}

{"asctime": "2022-05-23 05:16:35,453", "levelname": "INFO", "message": "Removing: /home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199445645.gz, age: 3659.23s"}

{"asctime": "2022-05-23 05:16:35,453", "levelname": "INFO", "message": "Removing: /home/ec2-user/.local/lib/python3.7/site-packages/flumine/historical/ALL/1.199445645, age: 3659.26s"}

{"asctime": "2022-05-23 05:16:39,124", "levelname": "INFO", "message": "BackgroundWorker poll_market_catalogue shutting down", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x7fcb78031440&gt;"}

{"asctime": "2022-05-23 05:16:43,124", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

{"asctime": "2022-05-23 05:16:43,124", "levelname": "INFO", "message": "Shutting down Execution (BetfairExecution)"}

{"asctime": "2022-05-23 05:16:43,196", "levelname": "INFO", "message": "Client logout", "username": "d", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7fcb7bddd190&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}

{"asctime": "2022-05-23 05:16:43,197", "levelname": "INFO", "message": "Exiting flumine", "clients": {"Betfair": {"d": {"username": "d", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x7fcb7bddd190&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}}, "Simulated": {}, "BetConnect": {}}, "markets": {"market_count": 727, "open_market_count": 670}, "streams": ["&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140512124557120)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 140511835891456)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 140511825401600)&gt;", "&lt;Thread(WIN_load_processor, started daemon 140511814911744)&gt;", "&lt;DataStream(DataStream, started daemon 140511599916800)&gt;"]}

Traceback (most recent call last):

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/strategies/marketrecorder.py", line 54, in &lt;module&gt;

    framework.run()

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/flumine.py", line 43, in run

    self._process_close_market(event)

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/baseflumine.py", line 350, in _process_close_market

    self._remove_market(market)

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/baseflumine.py", line 211, in _remove_market

    self.markets.remove_market(market.market_id)

  File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/markets/markets.py", line 31, in remove_market

    self.events[market.event_id].remove(market)

ValueError: list.remove(x): x not in list```

---

## 2022-05-21 08:38:54 - issues channel

**George**

At API Login I'm getting the error "DUPLICATE_CARDS". The Betfair docs say that the description of this error is "duplicate cards". Very helpful. Does anyone know what it means?

---

## 2022-05-20 14:43:27 - general channel

**liam**

My only recommendation is to make sure your dev box is the same, wasted way too much time trying to debug os issues 

---

## 2022-05-20 10:36:08 - random channel

**Alex Alex**

I have tried it recently. I have to say it is a bit of a mixed bag. Yes, it saves a ton of time with boilerplate code and some of the stuff it writes is really amazing. But then other times it writes code that looks ok but doesn’t quite do what I intended it to do, so I end up fixing the code which tends to end up slower than just writing it correctly in the first place. It’s still super amazing to see it work and it is 1000x more useful than I first thought it was.

---

## 2022-05-20 09:58:51 - issues channel

**liam**

do you get any other errors? I subscribe to FR without issues, confident on the filter as it looks like it might be timeout related

---

## 2022-05-20 08:51:40 - issues channel

**mandelbot**

Not sure why i get the following error when trying to stream FR horseracing markets

```{"asctime": "2022-05-20 07:50:39,625", "levelname": "ERROR", "message": "MarketStream 8006 run error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flumine\\streams\\marketstream.py\", line 44, in run\n    self._stream.start()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 67, in start\n    self._read_loop()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 226, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 256, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 8007]: Connection closed by server"}```

---

## 2022-05-18 10:15:49 - issues channel

**Neil T (Betfair)**

Morning [@UG03WDCHH](@UG03WDCHH) - please can you confirm what error is thrown by the Keep Alive request?  Is it still NO_SESSION?

---

## 2022-05-16 18:07:52 - random channel

**liam**

Anyone else getting lots errors from AWS? Looks like it might be APIGateway related 

---

## 2022-05-16 10:09:52 - issues channel

**liam**

can you try the latest version of flumine 2.1.1 which will use the latest bflw, this might fix things

---

## 2022-05-16 10:01:30 - issues channel

**liam**

20mins after starting do you get any error or warnings logs from the keep_alive worker?

---

## 2022-05-16 09:58:32 - issues channel

**liam**

this won't fix your problem though, as the code defaults to a minimum of 1200s hence why this hasn't been a problem for others, something else is going on here, are you aus?

---

## 2022-05-16 09:00:27 - general channel

**Nicholas vizard**

Hey guys just a quick one and hope everyone is keeping well!

*Is there a reason why (other than a coding error) a ladder midpoint  between the best back and lay price at an event start may be dramatically different to BSP for the same selection?*

I have been conducting some analyses on Australian Thoroughbred markets, and in this analyses need to compare the ladder midpoint at the off to the BSP for all selections.

On whole, these two numbers reconcile. However, there are some instances were they are dramatically different. e.g. (A ladder mid point of 4.9 and BSP of 1.11).

I probably only have a couple hundred of these instances in a sample of 600,000 so am not overly concerned but would like to identify if it is likely i have made a coding error or this can be expected based on the way in which BSP is constructed.



Many thanks for any help!

Nick

---

## 2022-05-15 23:30:32 - issues channel

**Rudeger Jamison**

any idea how to debug something like this ?

---

## 2022-05-15 23:30:24 - issues channel

**Rudeger Jamison**

Hey mate, same error as before.



All I can see of note is another error before the `NO_SESSION` from `BetfairClient `account.get_account_details` error

---

## 2022-05-15 06:41:11 - issues channel

**Rudeger Jamison**

nothing of note,



The closest error since the first `NO_SESSION` error was just a `STRATEGY_EXPOSURE` Warning, no actual errors.

---

## 2022-05-15 06:35:23 - issues channel

**liam**

Can you find the first error, Ie is there any error that isn’t a no session  

---

## 2022-05-15 06:34:40 - issues channel

**Rudeger Jamison**

I deployed it yesterday to AWS and it appeared to work the whole day and then these errors started today, so after the container had been running for about 24 hrs

---

## 2022-05-15 06:17:16 - issues channel

**Rudeger Jamison**

```

Traceback (most recent call last):

File "/usr/local/lib/python3.9/site-packages/flumine/clients/betfairclient.py", line 44, in keep_alive

return self.betting_client.keep_alive()

File "/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/keepalive.py", line 30, in __call__

(response, response_json, elapsed_time) = self.request(session=session)

File "/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/keepalive.py", line 60, in request

self._error_handler(response_json)

File "/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/keepalive.py", line 67, in _error_handler

raise self._error(response)

betfairlightweight.exceptions.KeepAliveError: API keepAlive FAIL: NO_SESSION```

---

## 2022-05-15 06:14:11 - issues channel

**liam**

Any errors would have keep_alive in them 

---

## 2022-05-15 05:51:12 - issues channel

**Rudeger Jamison**

It appears as though the session has lapsed and Flumine hasnt renewed it, when I run another local instance of Flumine the error does not occur and the bot starts betting again.



Is there a parameter to provide to make sure Flumine handles my session for me?

---

## 2022-05-15 05:49:15 - issues channel

**Rudeger Jamison**

any ideas on how to debug this?

---

## 2022-05-15 05:48:48 - issues channel

**Rudeger Jamison**

```Traceback (most recent call last):\n File \"/usr/local/lib/python3.9/site-packages/flumine/worker.py\", line 229, in _get_cleared_market\n cleared_markets = betting_client.betting.list_cleared_orders(\n File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n (response, response_json, elapsed_time) = self.request(method, params, session)\n File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n self._error_handler(response_json, method, params)\n File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.199151822'], 'customerStrategyRefs': ['ip-10-2-10-44.e'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03b-prd-04211134-00307ff265', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang03b-prd-04211134-00307ff265', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}",```

---

## 2022-05-15 05:48:37 - issues channel

**Rudeger Jamison**

Hey I am getting several *`INVALID_SESSION_INFORMATION` Errors from the `list_cleared_orders` call in Flumine details in* :thread: 

---

## 2022-05-14 15:21:13 - general channel

**EJono**

thank you for the heads up that will save me some debugging :slightly_smiling_face:

---

## 2022-05-12 19:53:05 - general channel

**H**

I managed to download through the GUI, though I keep getting the same error when I try the API. Let me know if the API works for you!

---

## 2022-05-12 16:40:34 - issues channel

**foxwood**

Not worth changing imho even though it is a dirty fix - presumably been there a long time and not been a problem generally it seems. Use functions like I listed above if you need true local/event time - eg I used dateAsVenueTimezone() to get the correct hour after the UK clocks changed to avoid events at certain times. That worked without change on both backtest and live when checking "market.market_start_datetime". I think when I checked my recorded files they contained "naive" utc dates (not sure about official BF files ?). Changing may risk breaking too much proven code that people already working with ? My 2p for what it's worth  - you can always hide behind the Microsoft get-out of "feature - by design" :)

---

## 2022-05-12 16:17:35 - general channel

**H**

They claim it's fixed now but I'm still seeing the same error

---

## 2022-05-12 13:04:27 - general channel

**H**

Yesterday they said they'd let me know once it's fixed

---

## 2022-05-12 09:07:38 - issues channel

**liam**

This is a lot more complicated than I thought it would be to fix it, I have created an [https://github.com/betcode-org/flumine/issues/584|issue](https://github.com/betcode-org/flumine/issues/584|issue) with some thoughts

---

## 2022-05-11 20:01:38 - general channel

**Lukas Trišauskas**

hi there, I have a newbie question. I am trying to get match odds for several events with betfairlightweight python package. I am able to login and get market catalogue for match_odds, but when I try to get market book for a specific market id, I get an error that I do not provide selection id. Maybe someone could explain me, which method returns this data? By the way, I am using delayed API key

---

## 2022-05-11 14:40:36 - random channel

**liam**

I always have logging set to ERROR when simulating so if I have any logs then I know something has gone wrong, maybe we update config to True for simulating? Just don't like flumine overriding things it shouldn't

---

## 2022-05-11 14:35:39 - random channel

**Oliver Varney**

I dont mind the flumine exceptions but if ive written crappy code which is likely :joy: id rather personally have the code terminate rather then cause more destruction, maybe just me

---

## 2022-05-11 14:34:42 - random channel

**liam**

ah I see what you are saying, yes it probably makes sense to put the if/raise in the flumine exception as well

---

## 2022-05-11 14:31:43 - random channel

**liam**

defaulted to False because I imagine the last thing a user wants is the python process to end, its configurable for debugging purposes only really

---

## 2022-05-11 14:28:57 - random channel

**Oliver Varney**

Just out of interest / for my knowledge, the process_market_book and check_market_book calls are wrapped with exception handling, with the config.raise_errors used to control this from what i can see. It looks like Flumine exceptions continue, im guessing these are due to streaming issues / recoverable issues? Is there any reason why config.raise_errors is defaulted to False for all other execeptions?

---

## 2022-05-11 08:35:33 - general channel

**H**

Yeah, even if I restrict to one day I still get that error

---

## 2022-05-11 08:15:25 - general channel

**H**

Hi, anyone else having issues with the Betfair historic data API? I'm trying to download some files I've purchased and I'm getting something that looks like a redirect error from cloudflare:

```JSONDecodeError: Expecting value: line 2 column 1 (char 1)



During handling of the above exception, another exception occurred:



...



InvalidResponse: Invalid response received: 

[!DOCTYPE html](!DOCTYPE html)

&lt;html&gt;

&lt;head&gt;

&lt;meta name="viewport" content="width=device-width" /&gt;

&lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

&lt;div&gt;

Error

&lt;/div&gt;

&lt;script defer src="[https://static.cloudflareinsights.com/beacon.min.js/](https://static.cloudflareinsights.com/beacon.min.js/)...&lt;/script&gt;

&lt;/body&gt;

&lt;/html&gt;```

I tried downloading through the GUI/web page as well and that also didn't work.

---

## 2022-05-11 07:38:33 - issues channel

**Rudeger Jamison**

Is this a typo in `loggingcontrols.py`



```

    def _process_cleared_markets(self, event):

        """

        :param event.event: betfairlightweight resources.ClearedOrders

        """

        logger.debug("process_cleared_markets: %s" % event)```

I think is would return a Market object or something? as `process_cleared_orders` returns the ClearedOrders object? or does it only return the cleared orders for the market that closed?

---

## 2022-05-10 13:24:10 - issues channel

**Unknown**

error I got using trading.login() is displayed below . Any help will be greatly appreciated! Thank you :slightly_smiling_face: :cat2:

---

## 2022-05-10 13:17:37 - issues channel

**liam**

I think a quick fix would be to patch both, not sure why it does this tbh

---

## 2022-05-07 19:52:19 - issues channel

**moseley82**

Hi guys, randomly started getting CERT_AUTH_REQUIRED error this evening, not changed a thing my end. Is this a wider issue does anyone know?

---

## 2022-05-07 18:22:23 - strategies channel

**foxwood**

I have a derived base strategy which does all sorts of parameter driven grunt work and provides helpers for various tasks. Deriving from this makes it easy to create and modify strategies quickly but each strategy ends up with it's own stream as part of the flumine BaseStrategy  construction.



When different strategies have identical market filter requirements is there any way to share a single stream to save on sockets and duplicate processing ? I could use lots of if/elif code but that quickly becomes a maintenance / debug 'mare.



One solution I'm considering is introducing another layer that feeds an array of child strategies in some way - just seems a bit messy compared to having a shared common feeder stream. Any ideas / Python tricks / alternative design patterns welcome :)

---

## 2022-05-07 10:35:57 - issues channel

**Newbie99**

I think at the mo its trying to pull in all Italian football markets which is why you're getting the error

---

## 2022-05-07 10:30:12 - issues channel

**Marco**

But I still get this error `ERROR:betfairlightweight.streaming.listener:[MarketStream: 2006]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 11347 markets whereas max allowed number was: 200`  and then a timeout `betfairlightweight.exceptions.ListenerError: connection_id: 202-070522092912-6500674, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"202-070522092912-6500674"}`  probably related to the market limit

---

## 2022-05-07 10:17:09 - issues channel

**Marco**

Hello, how to reduce the number of subscriptions to the markets via flumine? I'm having this error: `ERROR:betfairlightweight.streaming.listener:[MarketStream: 2002]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 11311 markets whereas max allowed number was: 200` . I checked the filters but I didn't find a way to limit it

---

## 2022-05-06 07:56:53 - issues channel

**Oliver Varney**

yer one sec im debugging the code ill get there

---

## 2022-05-05 13:12:20 - issues channel

**Newbie99**

That could work as a stop gap fix I guess?

---

## 2022-05-05 12:19:43 - issues channel

**liam**

Hmm thought I had fixed this, do you know how to replicate?

---

## 2022-05-05 12:02:19 - issues channel

**Newbie99**

As a quick fix, is there some easy way I can try to disable multiple cancels of the same bet (I can see a retry flag, but I suspect this isn't what I think it is)

---

## 2022-05-05 12:00:20 - issues channel

**Newbie99**

I'm still getting these perpetual cancel loops, which occur when a bet is (presumably) matched after I've sent the cancel request:



```{"asctime": "2022-05-05 10:56:32,246", "levelname": "INFO", "message": "execute_cancel", "trading_function": "cancel", "elapsed_time": 0.19069957733154297, "response": {"customerRef": "05f0b9cbcc6211eca0d32016d8944b85", "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.167249009", "instructionReports": [{"status": "FAILURE", "errorCode": "BET_TAKEN_OR_LAPSED", "instruction": {"betId": "267210054221"}}]}, "order_package": {"id": "05f0b9cb-cc62-11ec-a0d3-2016d8944b85", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x0000010E03500FA0&gt;", "market_id": "1.167249009", "orders": ["138710406780430137"], "order_count": 1, "package_type": "Cancel", "customer_strategy_ref": "BlueOcean", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}```

---

## 2022-05-04 19:59:21 - issues channel

**foxwood**

Loads of latency issues recorded in logs on the market stream today at 2 different locations and different strategies - up to 15 seconds at times and then recovers - anybody else ?



Edit - 50 even ?!

Saw something similar the other day and thought it was just local connection issue

```{"asctime": "2022-05-04 18:04:15,828", "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 13.703663110733032"}

{"asctime": "2022-05-04 18:04:15,875", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.198672766", "latency": 50.026501417160034, "pt": "2022-05-04T17:03:25.849000"}```

Edit 2 - that PC was saving it's log to a NAS over wifi - very slow. Think a race developed between trying to log latency warnings and taking so long to do so it increased the latency more ! Switched to local PC now instead which will hopefully fix things.

---

## 2022-05-04 09:22:12 - betconnect channel

**Mo**

[@U02QTC0RWDC](@U02QTC0RWDC) afraid not, I have the same error as [@U010GM77S4W](@U010GM77S4W)

---

## 2022-05-03 19:14:47 - issues channel

**AndyL**

Had a weird issue on Aus Warwick 07:42 last night which end with bot not hedging .

I had a matched backbet and an unmatched Lay TakeSP bet, then market was suspended for a non runner at 111secs, then unsuspended, bot then matched another bet on same selection at 103secs, then tried to cancel previous takeSP to update with a new Back takeSP bet. At this point the cancel threw an exception, order status Completed!! How can the takeSP at 1.01 have completed 2mins before actual inplay???

My transaction log shows the bet completing at the point of the nonrunner suspension...weird?

Anyone seen this before?

---

## 2022-05-03 16:07:47 - issues channel

**D**

Hi Test, I don't know the answer to your problem but have you tried making it work without multi-processing involved? It doesn't look like it's adding a lot of value to the overall process. Also, in your try....except clauses, it might be useful to print out any exceptions just in case there's something unexpected going on in there.

---

## 2022-05-03 15:45:16 - issues channel

**Unknown**

Hello guys, updating my question, with the current code, the error `TypeError: cannot pickle 'module' object` of not being able to send `trading` as an argument disappeared, but the function `odds_search` that analyzes the odds is not being executed. When I go to look at the two lists, they are empty and `print('odds search run')` does not appear in the terminal, indicating that the function was not even called.

---

## 2022-05-03 00:35:31 - issues channel

**Rudeger Jamison**

```{"asctime": "2022-05-02 23:33:50,466", "levelname": "INFO", "message": "[OrderStream: 1001]: connection_id: 102-020522233350-5969716"}

{"asctime": "2022-05-02 23:33:50,607", "levelname": "INFO", "message": "Starting MarketStream 2000", "stream_id": 2000, "market_filter": {"eventTypeIds": ["7"], "marketTypes": ["WIN"], "countryCodes": ["AU"], "raceTypes": ["Flat"]}, "market_data_filter": {"fields": ["EX_BEST_OFFERS", "EX_MARKET_DEF"], "ladderLevels": 3}, "conflate_ms": null, "streaming_timeout": null}

{"asctime": "2022-05-02 23:33:50,609", "levelname": "INFO", "message": "Starting output_thread (MarketStream 2000)"}

{"asctime": "2022-05-02 23:33:50,610", "levelname": "INFO", "message": "[Register: 2001]: marketSubscription"}

{"asctime": "2022-05-02 23:33:50,611", "levelname": "INFO", "message": "[MarketStream: 2001]: \"MarketStream\" created"}

{"asctime": "2022-05-02 23:33:50,755", "levelname": "ERROR", "message": "[OrderStream: 1002]: INVALID_SESSION_INFORMATION: DSC-0036"}

{"asctime": "2022-05-02 23:33:50,756", "levelname": "ERROR", "message": "OrderStream 1001 run error", "exc_info": "Traceback (most recent call last):\n  File \"/Users/benmuller/code/betfair-trading-bots/.venv/lib/python3.9/site-packages/flumine/streams/orderstream.py\", line 51, in run\n    self._stream.start()\n  File \"/Users/benmuller/code/betfair-trading-bots/.venv/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 67, in start\n    self._read_loop()\n  File \"/Users/benmuller/code/betfair-trading-bots/.venv/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 233, in _read_loop\n    self._data(received_data)\n  File \"/Users/benmuller/code/betfair-trading-bots/.venv/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 274, in _data\n    raise ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 102-020522233350-5969716, data: {\"op\":\"status\",\"id\":1002,\"statusCode\":\"FAILURE\",\"errorCode\":\"INVALID_SESSION_INFORMATION\",\"errorMessage\":\"DSC-0036\",\"connectionClosed\":true,\"connectionId\":\"102-020522233350-5969716\"}"}```

---

## 2022-05-02 18:32:09 - issues channel

**Unknown**

Guys, this code is to analyze if everything is ok in both markets and if it is, it responds with `'Approved to invest'`



This file is called `Betfair.py`, so in my main code I call it like this:



`import Betfair`

`print(Betfair.match_data(31410834))`



This id `31410834` is from an example game that has open markets and everything is ok.



Perfect, you guys who have advanced knowledge in Python and have been using betfairlightweight for a long time... As can see, in this place in the code:



`for _ in range(3):`

        `for _, market in markets.iterrows():`

            `odds_search(trading,market)`



I'm asking to generate a loop for 3 times in the analysis of the filtered markets, calling the `odds_search` function.



It works perfectly, but as you can see, I add the login data to the api (`trading`) when calling the function, but when I try to use basic multiprocessing or pool, I can't send `trading` as an argument, this error appears: `TypeError: cannot pickle 'module' object`.



When someone has some spare time, could help me out and show me how I could edit this code to make it work with multiprocessing so that these 3 loops are done at the same time to increase speed to colect the data?



I can create a question on stackoverflow if want. Any help will be most welcome!

---

## 2022-05-02 05:40:11 - issues channel

**Rudeger Jamison**

Hey, wondering if someone can help me debug, I am following the `QuickStart` in the Flumine docs, but not having much luck...details in :thread:

---

## 2022-04-29 23:12:20 - general channel

**Tom**

```from matchbook.apiclient import APIClient

from matchbook.exceptions import AuthError, PasswordError, ApiError, MBError



import logging

import os

logger = logging.getLogger(__name__)

MATCHBOOK_PW = os.environ.get('MATCHBOOK_PW')

MATCHBOOK_USR = os.environ.get('MATCHBOOK_PW')

api = APIClient(MATCHBOOK_USR, MATCHBOOK_PW)



def get_client():



    try:

        if not api.session_token or api.session_token is None:

            api.login()

            logger.warn(f'this is the {api.session_token}')

    except (AuthError,ApiError,MBError):

            api.login()

    return api



def get_orders():

    api = get_client()

    r = api.betting.get_orders(runner_ids=None, market_ids=None, offer_id=None, offset=0, per_page=500,

                    interval=None, side=Side.Default, status=Status.All, session=None)

    print(r)

    print(api.session_token)```

Hi there, I was wondering if anyone is using this repo for matchbook [https://github.com/rozzac90/](https://github.com/rozzac90/)

I cannot log in again after 6 hours to refresh the token. For some reason I can't run the except block to create a new token when ApiError occurs. Does anyone know how best to handle logging in to refresh the session? My get orders function polls indefinitely so I need to be able to handle the logging in again when the token expires. Thanks

---

## 2022-04-29 17:33:27 - random channel

**liam**

Messaged George and it looks like its fixed

---

## 2022-04-29 10:33:10 - random channel

**Michael**

Yes [@U01335QG2G3](@U01335QG2G3) Q1 last year was quite an anomaly for me too. Really exceptional. Generally Q1 is the worst time though. That's another thing to bear in mind right now.

---

## 2022-04-29 10:00:50 - random channel

**charlie_v**

[@UUE6E1LA1](@UUE6E1LA1) did some C++ last yes, talk about painful, was coding in .net and the debugger is so darn slow,. code was twice as fast as my C# but they really do not make it easy.

---

## 2022-04-28 17:54:39 - issues channel

**Vadym Zh**

Hey! My client runs the bot on Australian VPS and it works well. But then he decided to change the server (location - UK) and started getting an error 'MULTIPLE_USERS_WITH_SAME_CREDENTIAL'. He runs only 1 bot simultaneously, not both servers. Interactive login. Are there any methods to 'reset' the session? Or what would you recommend to fix this error? The goal is to just run it on the UK server.

---

## 2022-04-27 11:51:13 - random channel

**Robert**

[@U0382CCLV08](@U0382CCLV08) It seems to be that this is just moving money around rather than fixing, or someone who knows something. I think the  + result of backing the draw is just coincidental. As Liam said, the chances of being matched  randomly at those sizes on these games is almost zero, hence they are using these games to move money. I am surprised you have seen it happen 81 times and it's not been identified on the exchange as suspicious :thinking_face:

---

## 2022-04-26 17:31:21 - issues channel

**D**

My understanding is that when you use multiple-processing, any objects passed across the boundary are pickled before being sent, that's why the error message is coming up - it can't pickle something you're trying to share across multiple processes.

---

## 2022-04-26 15:29:18 - issues channel

**Beginner**

Guys, hello! I have a very beginner question but maybe you with very advanced knowledge can help me.



Is there a way to send API Client login data to a separate function? For example, I have the `trading.login()` in the `main()` function and I'm trying to send this data to be able to work with a separate function::



`def matches(trading):`

    `trading = trading`

    `id_event = '12345'`



    `filter_catalog_market = betfairlightweight.filters.market_filter(`

        `event_ids=[id_event],`

        `market_type_codes = [`

            `'MATCH_ODDS'`

            `]`

        `)`



    `catalog_market = trading.betting.list_market_catalogue(`

        `filter=filter_catalog_market,`

        `max_results='100',`

        `sort='FIRST_TO_START',`

        `market_projection=['RUNNER_METADATA']`

    `)`



`def main():`

    `trading = betfairlightweight.APIClient(username, pw, app_key=app_key, cert_files=('blablabla.crt','blablabla.key'))`

    `trading.login()`

    `matches(trading)`



The error that appears is:



`TypeError: cannot pickle 'module' object`



Is there any way to send this API Client login data to a separate function?

I'm sorry for the question that I know is simple, but I'm really struggling to understand.

---

## 2022-04-26 15:11:02 - random channel

**Robert**

very odd,  was it a fix, or a bit of washing going on...

---

## 2022-04-26 14:56:52 - random channel

**Dave**

Strange choice of game to move money around tbh. Fix?

---

## 2022-04-26 08:23:35 - random channel

**Newbie99**

A significant improvement...unsurprisingly perhaps it was mostly due to inefficient looping, but I re-wrote a few other bits too.



One thing that is confusing me however, is that occasionally I do get a:



```"status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failed: live_trade_count (1) &gt;= max_live_trade_count (1)"```

But I perform this check before trying to place an order:



```live_trades = market.blotter.strategy_selection_orders(self, runner.selection_id, runner.handicap, order_status=[OrderStatus.EXECUTABLE])



    if len(live_trades) == 0:```

---

## 2022-04-25 12:27:22 - random channel

**liam**

fix line 33 and it will be a good start

---

## 2022-04-25 12:14:36 - random channel

**Newbie99**

```53265807 function calls (53250311 primitive calls) in 151.446 seconds



   Ordered by: cumulative time



   ncalls  tottime  percall  cumtime  percall filename:lineno(function)

     5682    0.076    0.000  124.859    0.022 D:\Python37\webpages\place_order_functions.py:192(place_or_cancel)

      738    0.068    0.000  124.829    0.169 D:\Python37\webpages\market_making.py:19(place_passive_order)

      341    0.007    0.000  116.552    0.342 D:\Python38\lib\site-packages\flumine\baseflumine.py:254(_process_current_orders)

      681    0.001    0.000  115.210    0.169 D:\Python38\lib\site-packages\flumine\utils.py:259(call_process_orders_error_handling)

      681    0.003    0.000  115.209    0.169 D:\Python37\webpages\betting_strategy.py:32(process_orders)

     5697   21.047    0.004   80.373    0.014 D:\Python37\webpages\risk_functions.py:18(get_runner_exposure)

     4997    0.022    0.000   43.979    0.009 D:\Python37\webpages\place_order_functions.py:188(cancel_orders_by_price)

     4997    0.014    0.000   42.767    0.009 D:\Python37\webpages\place_order_functions.py:180(get_orders)

     4997    0.541    0.000   42.754    0.009 D:\Python37\webpages\place_order_functions.py:185(&lt;listcomp&gt;)

    77775    0.790    0.000   42.540    0.001 D:\Python37\webpages\place_order_functions.py:132(construct_price)

    73587    0.095    0.000   39.810    0.001 D:\Python37\webpages\place_order_functions.py:489(adjust_price_for_self_matching)

    73587    0.390    0.000   39.715    0.001 D:\Python37\webpages\validation_functions.py:425(validate_order_self_matching)

   147174    0.484    0.000   39.253    0.000 D:\Python37\webpages\validation_functions.py:465(get_order_list)

   147174   37.736    0.000   37.736    0.000 D:\Python37\webpages\validation_functions.py:474(&lt;listcomp&gt;)

  1056788   23.509    0.000   23.509    0.000 D:\Python37\webpages\risk_functions.py:33(&lt;listcomp&gt;)

      108    0.001    0.000   21.532    0.199 D:\Python38\lib\threading.py:270(wait)

      997   21.530    0.022   21.530    0.022 {method 'acquire' of '_thread.lock' objects}

      464    0.004    0.000   21.454    0.046 D:\Python38\lib\queue.py:153(get)

     5697    0.030    0.000   19.673    0.003 D:\Python37\webpages\risk_functions.py:78(check_combined_strategy)

     5697    3.140    0.001   19.598    0.003 D:\Python37\webpages\risk_functions.py:86(&lt;listcomp&gt;)

       50    0.002    0.000    9.686    0.194 D:\Python38\lib\site-packages\flumine\baseflumine.py:134(_process_market_books)

      625    0.001    0.000    9.638    0.015 D:\Python38\lib\site-packages\flumine\utils.py:222(call_strategy_error_handling)

       57    0.000    0.000    9.624    0.169 D:\Python37\webpages\betting_strategy.py:22(process_market_book)

  2113432    4.618    0.000    9.271    0.000 D:\Python38\lib\site-packages\flumine\utils.py:80(create_cheap_hash)

  8518043    4.560    0.000    8.305    0.000 D:\Python38\lib\site-packages\flumine\order\order.py:426(size_matched)

  2113059    2.288    0.000    7.743    0.000 D:\Python37\webpages\risk_functions.py:11(get_order_matched_exposure)

  4291494    2.451    0.000    7.361    0.000 D:\Python37\webpages\risk_functions.py:4(get_order_matched_stake)

  2113821    3.039    0.000    5.130    0.000 D:\Python38\lib\site-packages\flumine\order\order.py:259(customer_order_ref)

 10643310    4.577    0.000    4.577    0.000 D:\Python38\lib\site-packages\flumine\order\order.py:188(current_order)

     5696    0.775    0.000    4.467    0.001 D:\Python37\webpages\risk_functions.py:39(&lt;listcomp&gt;)

   1391/2    0.018    0.000    3.269    1.635 {built-in method builtins.exec}

        1    0.000    0.000    3.269    3.269 startup.py:1(&lt;module&gt;)

  1045/16    0.014    0.000    3.082    0.193 &lt;frozen importlib._bootstrap&gt;:986(_find_and_load)

  1044/16    0.007    0.000    3.081    0.193 &lt;frozen importlib._bootstrap&gt;:956(_find_and_load_unlocked)

  1002/16    0.007    0.000    3.066    0.192 &lt;frozen importlib._bootstrap&gt;:650(_load_unlocked)

   890/16    0.005    0.000    3.065    0.192 &lt;frozen importlib._bootstrap_external&gt;:777(exec_module)

  1348/16    0.002    0.000    3.053    0.191 &lt;frozen importlib._bootstrap&gt;:211(_call_with_frames_removed)

  2113432    2.341    0.000    2.341    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}

  2113469    1.233    0.000    2.061    0.000 D:\Python38\lib\site-packages\flumine\order\order.py:419(average_price_matched)

      341    0.013    0.000    1.827    0.005 D:\Python38\lib\site-packages\flumine\order\process.py:33(process_current_orders)

  563/115    0.003    0.000    1.797    0.016 {built-in method builtins.__import__}

       46    0.001    0.000    1.721    0.037 D:\Python38\lib\site-packages\flumine\order\process.py:93(create_order_from_current)

        7    0.000    0.000    1.603    0.229 D:\Python38\lib\site-packages\flumine\baseflumine.py:197(_add_market)

        7    0.008    0.001    1.596    0.228 D:\Python37\webpages\middleware_example.py:24(add_market)

2117384/2117380    1.525    0.000    1.525    0.000 {method 'format' of 'str' objects}

 1227/677    0.003    0.000    1.475    0.002 &lt;frozen importlib._bootstrap&gt;:1017(_handle_fromlist)

     1586    0.005    0.000    1.400    0.001 D:\Python38\lib\logging\__init__.py:1553(_log)

        1    0.000    0.000    1.335    1.335 D:\Python37\webpages\orders_worker.py:1(&lt;module&gt;)

        1    0.000    0.000    1.332    1.332 D:\Python37\webpages\racing_functions.py:1(&lt;module&gt;)

  2113432    1.331    0.000    1.331    0.000 {built-in method _hashlib.openssl_sha1}

        1    0.000    0.000    1.325    1.325 D:\Python37\webpages\import_historic_horse_data.py:1(&lt;module&gt;)

     1586    0.002    0.000    1.308    0.001 D:\Python38\lib\logging\__init__.py:1579(handle)

     1586    0.012    0.000    1.305    0.001 D:\Python38\lib\logging\__init__.py:1633(callHandlers)

     4758    0.011    0.000    1.293    0.000 D:\Python38\lib\logging\__init__.py:937(handle)

    77775    0.183    0.000    1.271    0.000 D:\Python37\webpages\place_order_functions.py:222(get_base_price_source)

     4758    0.019    0.000    1.265    0.000 D:\Python38\lib\logging\__init__.py:1069(emit)

     1505    0.007    0.000    1.249    0.001 D:\Python38\lib\logging\__init__.py:1424(info)

        6    0.000    0.000    1.222    0.204 D:\Python38\lib\site-packages\requests\api.py:16(request)

        6    0.000    0.000    1.199    0.200 D:\Python38\lib\site-packages\requests\sessions.py:470(request)

     4997    0.018    0.000    1.189    0.000 D:\Python37\webpages\cancel_and_replace.py:33(cancel_orders)

        6    0.000    0.000    1.111    0.185 D:\Python38\lib\site-packages\requests\sessions.py:626(send)

        6    0.000    0.000    1.105    0.184 D:\Python38\lib\site-packages\requests\adapters.py:394(send)

   153222    1.010    0.000    1.078    0.000 D:\Python38\lib\site-packages\flumine\markets\blotter.py:268(__iter__)

        6    0.000    0.000    1.062    0.177 D:\Python38\lib\site-packages\urllib3\connectionpool.py:518(urlopen)

        6    0.000    0.000    1.058    0.176 D:\Python38\lib\site-packages\urllib3\connectionpool.py:357(_make_request)

        5    0.000    0.000    1.056    0.211 D:\Python38\lib\site-packages\requests\api.py:107(post)

        1    0.000    0.000    1.056    1.056 D:\Python38\lib\site-packages\pandas\__init__.py:3(&lt;module&gt;)```

---

## 2022-04-23 16:03:52 - issues channel

**Ruben**

okay, but if you have already sent the cancellation, you will receive the error "BET_TAKEN_OR_LAPSED" because the order is no longer there; eventually as you say flumine should receive the corresponding update and no longer see it as executable

---

## 2022-04-23 15:58:00 - issues channel

**Unknown**

I keep getting a BET_TAKEN_OR_LAPSED error when cancelling, my cancel logic is as follows:

```orders = [order for order in market.blotter.strategy_orders(self) if

        (order.selection_id, order.handicap) == (runner.selection_id,runner.handicap)]```

```for order in orders:

    runner_exposure = get_runner_exposure(self, market, selected_runner=order)

    if order.status == OrderStatus.EXECUTABLE:

        if order.side == 'BACK':

            if positive_runner_exposure &lt; runner_exposure['if_win']:

                logging.info('Cancelling {0} due to positive exposure breach, runner exposure is: {1} and limit is: {2}.'.format(order.bet_id, runner_exposure, negative_runner_exposure))

                market.cancel_order(order)

            elif validate_current_order(order, time_to_cancel_orders) is True:

                logging.info('Cancelling {0} as order has been live for {1} seconds.'.format(order.bet_id, time_to_cancel_orders))

                market.cancel_order(order)

        else:

            if negative_runner_exposure &gt; runner_exposure['if_win']:

                [http://logging.info|logging.info](http://logging.info|logging.info)('Cancelling {0} due to negative exposure breach, runner exposure is: {1} and limit is: {2}.'.format(order.bet_id, runner_exposure, negative_runner_exposure))

                market.cancel_order(order)

            elif validate_current_order(order, time_to_cancel_orders) is True:

                [http://logging.info|logging.info](http://logging.info|logging.info)('Cancelling {0} as order has been live for {1} seconds.'.format(order.bet_id, time_to_cancel_orders))

                market.cancel_order(order)```

I don't understand how this error could (repeatedly) happen when I check to ensure the order is EXECUTABLE before cancelling (logs for one example attached, I have had multiple instances of this today)?



(I do appreciate it will be an error on my side, I'm just completely stumped as to what it could be), so any clues would be greatly appreciated!

---

## 2022-04-23 07:50:29 - general channel

**Mo**

Version 0.3.0 of [https://github.com/mberk/betfairutil|betfairutil](https://github.com/mberk/betfairutil|betfairutil) released:



```### Added



* Unit tests #14

* Various price related functions:

    * get_spread

    * calculate_price_difference

    * get_inside_best_price

    * get_outside_best_price

    * get_best_price

    * increment_price

    * decrement_price

    * is_price_the_same_or_better

    * is_price_worse

* Various horse racing related functions:

    * get_race_id_from_string

    * get_win_market_id_from_race_card

    * read_race_file



### Changed



* Updated typing of all price related functions to accept Path objects



### Fixed



* Various fixes when using MarketBook objects instead of dictionaries```



---

## 2022-04-21 20:50:33 - issues channel

**Brøndby IF**

Good afternoon everyone, in relation to the error that I showed below, does anyone know the limits for not have the risk of this happening?



I believe that it will be impossible for this happen to me because nothing I use needs to do multiple logins, I only use one for several calls to collect data odds and then I log out.

But anyway, it would be interesting to know this for future knowledge.



`TEMPORARY_BAN_TOO_MANY_REQUESTS → The limit for successful login requests per minute has been exceeded. New login attempts will be banned for 20 minutes`

---

## 2022-04-20 11:01:50 - random channel

**Troy Edwards**

Hmmm when I entered that SQL statement there was no error at myDataReader = myCommand.ExecuteReader()

---

## 2022-04-20 10:33:38 - random channel

**Troy Edwards**

Ta Liam it errors at

        myDataReader = myCommand.ExecuteReader()



and the message is Invalid Object name???

---

## 2022-04-20 10:14:44 - random channel

**liam**

but any error message on this?

---

## 2022-04-20 10:14:15 - random channel

**liam**

quick fix is use a db such as postgres or MySQL

---

## 2022-04-20 10:02:20 - random channel

**Troy Edwards**

Hey guys - I have been storing data in a BINARY file because I had structures within structures.  Today I ran out of memory and I know its time to go to SQL.  So I added a local MDF local database to my Visual Studio, created a table and tested access but I can't get it to work ?



Dim myDataReader As SqlDataReader

Dim myConnection As SqlConnection

Dim myCommand As SqlCommand

Dim strSQL As String



myConnection = New SqlConnection("Data Source=(LocalDB)\MSSQLLocalDB; Initial Catalog=C:\CODE\BETFAIR ARB\PREVIOUS DATA\PreviousRaceData.mdf")

myConnection.Open()



strSQL = "SELECT ID FROM dbo.tblCompletedRaces"

myCommand = New SqlCommand(strSQL, myConnection)



myDataReader = myCommand.ExecuteReader()



If myDataReader.Read() Then

            Debug.Print(myDataReader.Item("Runnername"))

        Else

            MsgBox("Didn't work...")

        End If

Any ideas :disappointed:

---

## 2022-04-19 21:35:00 - issues channel

**liam**

Yeah, can you fix that? Are you actually going over enough that you are paying the charges? I think I have mine set at 20k per account and just pay if required 

---

## 2022-04-19 21:29:16 - issues channel

**liam**

Why not fix the real problem?

---

## 2022-04-17 11:34:14 - random channel

**D C**

If you place a bet using the async flag on the API placeOrders operation, can you get a FAILURE state in the response? Docs are somewhat unclear here. For example, if I have a bug and I am trying to place something with async flag at an INVALID price will I still get a PENDING status or does the server filter out my error immediately?

---

## 2022-04-16 18:15:29 - issues channel

**thambie1**

I'm not using flumine of bflw. The bug was on Betfair's side, but I haven't seen it happen again since I made this comment

---

## 2022-04-13 12:17:24 - issues channel

**foxwood**

I'm running 2 live frameworks on same server for the first time - one for "ok" strategies and another for suspect ones and debugging.



As they both place bets it ends up with cross-talk warnings in the other framework's log log saying "Strategy not available to create order" and "Order %s not present in blotter". Was a bit worrying at first sight lol.



Presume this is in part caused by both frameworks having the socket hostname as the customer order ref since this does not happen when running the two frameworks on separate machines.



Suggestions: if the common hostname is the cause then extend the hostname with python PID (poss problems with multi proc) or an instance specific framework uuid property (logging does a short uuid for example) ?

---

## 2022-04-13 09:14:42 - random channel

**Nacho Uve**

I'm trying to use betfairviz.create_dashboard.



The module is imported correctly and MarketBooks are rendered as expected in jupyter notebook.



But when I call ``betfairviz.create_dashboard(prices)`, being `prices` a dict obtained with `betfairutil.read_prices_file` nothing happens. No error neither visualization of the widget.



Any clue to what I'm doing wrong?

---

## 2022-04-13 08:48:39 - issues channel

**Unknown**

```from betfairlightweight import StreamListener



class Streaming(threading.Thread):

    """

    Streaming example to handle timeouts or connection errors, with reconnect. Code uses 'tenacity' library for retrying.

    Streaming class inherits threading module to simplify start/stop.

    """

    def __init__(

            self,

            client: betfairlightweight.APIClient,

            market_filter: dict,

            market_data_filter: dict,

            conflate_ms: int = None,

            streaming_unique_id: int = 1000,

    ):

        threading.Thread.__init__(self, daemon=True, name=self.__class__.__name__)

        self.client = client

        self.market_filter = market_filter

        self.market_data_filter = market_data_filter

        self.conflate_ms = conflate_ms

        self.streaming_unique_id = streaming_unique_id

        self.stream = None

        self.output_queue = queue.Queue()

        self.listener = StreamListener(output_queue=self.output_queue)



    @retry(wait=wait_exponential(multiplier=1, min=2, max=20))

    def run(self) -&gt; None:

        log_info("Starting MarketStreaming")

        self.client.login()  # this is needed in case of reconnection so the session is started again

        self.stream = self.client.streaming.create_stream(

            unique_id=self.streaming_unique_id, listener=self.listener

        )

        try:

            self.streaming_unique_id = self.stream.subscribe_to_markets(

                market_filter=self.market_filter,

                market_data_filter=self.market_data_filter,

                conflate_ms=self.conflate_ms,

                initial_clk=self.listener.initial_clk,  # supplying these two values allows a reconnect

                clk=self.listener.clk,

            )

            self.stream.start()

        except BetfairError:

            log_exception("MarketStreaming run error")

            raise

        except Exception:

            log_exception("MarketStreaming run error")

            raise

        log_info("Stopped MarketStreaming {0}".format(self.streaming_unique_id))



    def stop(self) -&gt; None:

        if self.stream:

            self.stream.stop()```

---

## 2022-04-13 08:29:26 - issues channel

**Jorge**

I think it does use it. Anyway, I can and will remove that line, it was there for debuggin purposes

---

## 2022-04-13 08:23:15 - issues channel

**Jorge**

Hi, my streaming_market_data process is suddenly using a lot of memory RAM. For the first couple of days it is completely OK but then suddenly it starts accumulating more RAM and in a couple of days it takes all the available RAM in the Server, making the process freeze. Yesterday it took 80MB RAM (normal) and today it went up to 250MB RAM. Has anyone experienced something similar? This is basically my code for the process:



```trading = betfairlightweight.APIClient(... , lightweight=True)

trading.login()



market_filter = streaming_market_filter(event_type_ids=event_type_ids, market_types=market_type_codes, turn_in_play_enabled=True, country_codes=country_codes)

market_data_filter = streaming_market_data_filter(fields=["EX_BEST_OFFERS_DISP", 'EX_TRADED_VOL', "EX_MARKET_DEF"], ladder_levels=1)

streaming = Streaming(trading, market_filter, market_data_filter)

streaming.start()



while True:

    try:

        new_market_books = streaming.output_queue.get()

        publish_to_redis(db_0, new_market_books)

        log_debug('Total markets saved in Redis: {}'.format(len(db_0.keys())))



    except Exception as e:

        log_exception(e)```

I don't see any ERROR logs. Only some WARNINGs here and there about "Latency high", but I had those long time ago and the same process did not accumulate RAM memory...

---

## 2022-04-10 03:21:31 - general channel

**JFP**

Thanks [@U01C12ZEADQ](@U01C12ZEADQ) [@U9JHLMZB4](@U9JHLMZB4) [@UFTBRB3F1](@UFTBRB3F1)



So if I add market.market_catalogue is not None check, it will skip until catalogue becomes available?



I am not using middleware and I'm not calling the market_catalogue anywhere else, I thought it is automatically loaded in the market class? Or do I need to explicitly load it?



This error does arise as soon as market_book starts processing, sounds like adding the catalogue check should do the trick.

---

## 2022-04-09 16:24:23 - general channel

**JFP**

Hi all, I'm trying to filter out Novice races for a live strategy. For back testing the below code works:



```if "Nov" in market_book.market_definition.name:```

However I get NoneType error when running live. I have tried using the catalogue:



```if "Nov" in market.market_catalogue.market_name:```

This does not work either (I am trying to use this in the process market_book function). Would really appreciate it if someone could point me in the right direction. Thanks

---

## 2022-04-06 08:38:09 - issues channel

**Mo**

I ran your code for both Bundesliga and Spanish Segunda Division



Segunda Division ran fine, I got the list of market catalogues back



Bundesliga had an API error because there are too many markets on the exchange



I hope that is clearer

---

## 2022-04-04 15:10:36 - issues channel

**liam**

yep, use your debugger and you can see what you have available or read the code :wink:

---

## 2022-04-03 20:15:21 - random channel

**D C**

Is it ever possible to get a virtual price that is worse than a non-virtual price? It seems a stupid question I am sure, but I just want to check because I am debugging something that is showing me a lower non-virtual LAY price than the virtual price. Seems to happen only for prices in the high 3 digit ranges. Just want a sanity check really before digging deeper

---

## 2022-03-31 13:36:09 - betconnect channel

**Oliver Varney**

In the latest push which I'm waiting on something from BC end, error messages are added to provide more detail when error codes are returned, plus a fix for customer / order refs and maybe a few type  changes if I get some confirmation

---

## 2022-03-31 13:31:51 - betconnect channel

**Peter**

So doesn't appear to be a problem at the BetConnect end, though the error message received when the competitor ID is invalid is very misleading.

---

## 2022-03-31 13:17:38 - betconnect channel

**Graham**

```CreateBetRequestFilter(fixture_id=108400430, market_type_id=10160, competitor='10840043052320480', price=29.0, stake=500, handicap=None, bet_type='Win', customer_strategy_ref=Customer strategy ref: horse_racing, customer_order_ref=Customer order ref: 9168296c-23e7-4abd-b158-6355ddc5615f)```

---

## 2022-03-31 11:43:07 - betconnect channel

**Graham**

```{'source_fixture_id': '108400418', 'source_market_id': '101608400418', 'source_market_type_id': '10160', 'source_selection_id': '10840041852297932', 'trading_status': 'Trading', 'name': 'Patagonia', 'competitor_id': '1052297932', 'max_price': '4.33'}```

---

## 2022-03-30 09:35:25 - issues channel

**Jonjonjon**

I worked it out. It was a typical case on user error. In my check_market_book I was excluding NSW markets for live trading. But not for backtesting. Apologies for wasting everyone's time.:face_palm::skin-tone-6:

---

## 2022-03-30 07:36:14 - issues channel

**liam**

Very tricky for me to debug this, are you simulating with the same data you placing live, something must be different 

---

## 2022-03-29 21:50:49 - issues channel

**Jonjonjon**

I'm still trying to debug the problem of missing bets (I'm getting lots of placed bets in the backtest, but they're not being place when live). After checking my live latency is fine, and then increasing the backtest latency to 1 second (where it still has lots of placed bets) I'm totally flumoxed.:disappointed:

---

## 2022-03-29 18:29:49 - betconnect channel

**Graham**

I'm pretty sure it's an import error

---

## 2022-03-29 18:22:38 - betconnect channel

**Graham**

I'm running the `horseracingexample.py` and am getting the following

```AttributeError: module 'betconnect.resources' has no attribute 'filters'```

---

## 2022-03-29 18:08:00 - betconnect channel

**Oliver Varney**

just working on a fix will be either later on or early tomorrow morning, for now if your testing just populate customer_order_ref and customer_strategy_ref per the horse racing example

---

## 2022-03-29 17:54:06 - betconnect channel

**Oliver Varney**

found it just working on a fix now

---

## 2022-03-29 17:13:56 - betconnect channel

**Oliver Varney**

hmm okay let me debug it properly it just was on the odd chance it was that

---

## 2022-03-29 17:10:08 - betconnect channel

**mandelbot**

tried also wrapping fixture_id as an int

---

## 2022-03-29 17:05:54 - betconnect channel

**Oliver Varney**

try this maybe:

```client.betting.bet_request_create(

    request_filter=resources.filters.CreateBetRequestFilter(

        fixture_id=selection.source_fixture_id,

        market_type_id=int(selection.source_market_type_id),

        competitor=selection.competitor_id,

        price=max_price,

        stake=5,

        bet_type="Win",

        handicap=None

    )

)```



---

## 2022-03-29 16:52:22 - betconnect channel

**mandelbot**

Yeah will have a go with dailyhorseracing.py, i took the bet request from that and added it to Liam's example and thats what's been throwing errors

---

## 2022-03-29 16:49:49 - betconnect channel

**Oliver Varney**

do you have a new exmaple fixture as the old onelooks like it may have finished?

---

## 2022-03-29 16:43:18 - betconnect channel

**mandelbot**

getting the same error

---

## 2022-03-29 14:37:31 - betconnect channel

**Joel Beasley**

`market_type_id` has been fixed in Staging now [@U01EZ613ZCZ](@U01EZ613ZCZ), will update Production in the morning :thumbsup:

---

## 2022-03-29 13:48:02 - betconnect channel

**mandelbot**

```fixture_id=108391794

market_type_id=10160

competitor= 1052139537

price= 34.0 

bet_type='Win'```

---

## 2022-03-29 13:45:47 - betconnect channel

**Graham**

placing a bet request with some manual fields

```            bet_create_response = client.betting.bet_request_create(

                request_filter=resources.filters.CreateBetRequestFilter(

                    fixture_id=fixture.fixture_id,

                    market_type_id= 10160, #win_market_type.market_type_id,

                    competitor=selection.competitor_id,

                    price=2.75,#best_price.price,

                    stake=500,

                    bet_type=win_bet_type,

                    customer_strategy_ref=resources.CustomerStrategyRef.create_customer_strategy_ref(

                        STRATEGY_NAME

                    ),

                    customer_order_ref=resources.CustomerOrderRef.create_customer_order_ref(

                        str(uuid.uuid4())

                    ),

                )

            )```

returns a validation error

```

Traceback (most recent call last):



  File "C:\Users\Graham\AppData\Local\Temp/ipykernel_3964/974456888.py", line 67, in &lt;module&gt;

    bet_request_get = client.betting.bet_request_get(



  File "C:\Users\Graham\anaconda3\lib\site-packages\betconnect\endpoints\betting.py", line 221, in bet_request_get

    return self.process_response(



  File "C:\Users\Graham\anaconda3\lib\site-packages\betconnect\endpoints\baseendpoint.py", line 192, in process_response

    return resource.create_from_dict(data)



  File "C:\Users\Graham\anaconda3\lib\site-packages\betconnect\resources\baseresource.py", line 26, in create_from_dict

    return cls.parse_obj(d)



  File "pydantic\main.py", line 572, in pydantic.main.BaseModel.parse_obj



  File "pydantic\main.py", line 400, in pydantic.main.BaseModel.__init__



ValidationError: 1 validation error for BetRequest

backer_stats

  field required (type=value_error.missing)```

---

## 2022-03-29 13:43:04 - betconnect channel

**Oliver Varney**

[@U010GM77S4W](@U010GM77S4W) can you take a screenshot of the debugger / provide values for that data?

---

## 2022-03-29 13:39:10 - betconnect channel

**Graham**

I'm using this one [@U010GM77S4W](@U010GM77S4W)

```bet_create_response = client.betting.bet_request_create(

                request_filter=resources.filters.CreateBetRequestFilter(

                    fixture_id=fixture.fixture_id,

                    market_type_id=win_market_type.market_type_id,

                    competitor=selection.competitor_id,

                    price=best_price.price,

                    stake=500,

                    bet_type=win_bet_type,

                    customer_order_ref=resources.CustomerOrderRef.create_customer_order_ref(

                        str(uuid.uuid4())

                    ),

                )

            )```

---

## 2022-03-29 13:37:09 - betconnect channel

**mandelbot**

I'm getting

```{"asctime": "2022-03-29 12:35:10,069", "levelname": "ERROR", "message": "Issue with request for: [https://stgapi.betconnect.com/api/v2/bet_request_create](https://stgapi.betconnect.com/api/v2/bet_request_create), message: Input payload validation failed", "exc_info": "NoneType: None"}```

my bet looks like this:

```                            client.betting.bet_request_create(                                request_filter=resources.filters.CreateBetRequestFilter(

                                fixture_id=selection.source_fixture_id,

                                market_type_id=selection.source_market_type_id,

                                competitor=selection.competitor_id,

                                price=max_price,

                                stake=5,

                                bet_type="Win",

                                handicap=None

                                )

                                )```



---

## 2022-03-29 13:29:08 - betconnect channel

**Graham**

```CreateBetRequestFilter(fixture_id=108391776, market_type_id=6, competitor='1052767814', price=2.88, stake=500, handicap=None, bet_type='Win')```



---

## 2022-03-29 13:24:08 - betconnect channel

**Graham**

```bet_create_response

Out[53]: BaseRequestException(message='Market type id is not valid for fixture.', request_url='[https://stgapi.betconnect.com/api/v2/bet_request_create](https://stgapi.betconnect.com/api/v2/bet_request_create)', status_code=400)```

getting this from the staging env when passing `6` as the market type ID

---

## 2022-03-29 12:02:38 - betfair-news channel

**Mo**

Can the historic data API error messages be improved? A lot of the time when someone comes here with a problem it's hard to tell if they're doing something wrong - like passing in invalid arguments - or if the API is just being its usual flakey self

---

## 2022-03-26 16:52:13 - issues channel

**Oliver Varney**

Basically pedantic is very strict so if it'd told to accept a value and none is passed it will throw an error

---

## 2022-03-26 16:44:56 - issues channel

**mandelbot**

Yes I've had a look at my account preferences on the site but am not seeing anything relevant. I did change odds to decimal and the error seems to have changed to



value is not a valid integer (type=type_error.integer)



rather than none is not an allowed value

---

## 2022-03-26 16:18:49 - issues channel

**mandelbot**

So I'm trying to use the example to login to the betconnect staging area but get the following error

```    return cls.parse_obj(d)

  File "pydantic\main.py", line 511, in pydantic.main.BaseModel.parse_obj

  File "pydantic\main.py", line 331, in pydantic.main.BaseModel.__init__

pydantic.error_wrappers.ValidationError: 1 validation error for AccountPreferences

building

  none is not an allowed value (type=type_error.none.not_allowed)```

How do i pass this `AccountPreference`  in?

---

## 2022-03-25 19:15:54 - general channel

**liam**

ah that first example is very confusing, will fix it

---

## 2022-03-25 16:03:13 - general channel

**mandelbot**

Fixed it. Was using `Flumine()` instead of `FlumineSimulation()`

---

## 2022-03-25 15:57:48 - general channel

**mandelbot**

Not sure what im missing here

```Traceback (most recent call last):

  File "C:/FlumineNew/Lib/site-packages/flumine/examples/strategies/BSPtest.py", line 210, in &lt;module&gt;

    framework.run()

  File "C:\FlumineNew\lib\site-packages\flumine\flumine.py", line 15, in run

    with self:

  File "C:\FlumineNew\lib\site-packages\flumine\baseflumine.py", line 415, in __enter__

    self._add_default_workers()

  File "C:\FlumineNew\lib\site-packages\flumine\flumine.py", line 54, in _add_default_workers

    client_timeouts = [

  File "C:\FlumineNew\lib\site-packages\flumine\flumine.py", line 55, in &lt;listcomp&gt;

    client.betting_client.session_timeout for client in self.clients

AttributeError: 'NoneType' object has no attribute 'session_timeout'```

---

## 2022-03-25 14:18:27 - strategies channel

**liam**

do the battering's/big wins coincide with errors/discrepancies in the accuracy or just bad luck? Back in 2018 I found it was common to have every single market as +++ve, in hindsight I don't think I took advantage, much harder now

---

## 2022-03-25 09:59:02 - general channel

**liam**

flumine v2.0.0 now released, this has a few breaking changes 99% around naming (Backtest-&gt;Simulated) hence the major version bump (over 2yrs since v1!) but now allows multi clients/exchanges, see [https://betcode-org.github.io/flumine/clients/|docs](https://betcode-org.github.io/flumine/clients/|docs) on how to use. Also added a rough [https://github.com/betcode-org/flumine/blob/master/examples/example-betconnect.py|example](https://github.com/betcode-org/flumine/blob/master/examples/example-betconnect.py|example) on using the BetConnect client.



I have been testing for a few weeks now and I believe it to be bug free, any issues are likely to be around simulation rather than live due to the changes but let me know if you spot anything.



Future work will involve opening up the framework to be more exchange/API agnostic in terms of execution/market/orders etc.

---

## 2022-03-23 12:16:14 - random channel

**Peter**

Over the years I've found all the sources to provide very similar data, even down to the same errors. The two that I find it easiest to extract data from are the Greyhound Board of Great Britain and Sporting Life.

---

## 2022-03-22 19:07:59 - general channel

**liam**

Have you seen the error handling [https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py|example](https://github.com/betcode-org/betfair/blob/master/examples/examplestreamingerrhandling.py|example)?

---

## 2022-03-22 16:53:02 - general channel

**VT**

Hi guys, I'm having problems with the order_stream connection, after some time I get disconnected by Betfair. Is there a way for me to automatically reconnect when this happens? I use the simplest code.



----------------------------------------------------------------------------

Exception in thread Thread-13:

Traceback (most recent call last):

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 230, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "C:\anaconda3\lib\ssl.py", line 1226, in recv

    return self.read(buflen)

  File "C:\anaconda3\lib\ssl.py", line 1101, in read

    return self._sslobj.read(len)

ConnectionResetError: [WinError 10054] Forced cancellation of an existing connection by the remote host



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\anaconda3\lib\threading.py", line 932, in _bootstrap_inner

    self.run()

  File "C:\anaconda3\lib\threading.py", line 870, in run

    self._target(*self._args, **self._kwargs)

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 60, in start

    self._read_loop()

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 212, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 234, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 2]: Socket [WinError 10054] Forced cancellation of an existing connection by the remote host

----------------------------------------------------------------------------



Code:



output_queue = queue.Queue()

listener = betfairlightweight.StreamListener(output_queue=output_queue, lightweight=True)

stream = trading.streaming.create_stream(listener=listener)

order_filter = streaming_order_filter()

streaming_unique_id = stream.subscribe_to_orders(order_filter=order_filter, conflate_ms=0)

t = threading.Thread(target=stream.start, daemon=True)

t.start()

---

## 2022-03-19 16:38:25 - general channel

**thambie1**

Anyone else getting occasional DUPLICATE_TRANSACTION errors when placing a bet, despite not actually placing duplicate orders? Just started happening in the last week, no code change on my end, and logs aren't showing duplicate customer refs.

---

## 2022-03-16 02:23:18 - general channel

**anomaly**

Hi all,



Newbie to flumine/bflw here! Got a few question about best practice placing single ex / bsp bets with flumine. In the examples, it seems you need to wrap BaseStrategy and internally define the logic in process_market_book() which seems straightforward enough. Peeking inside the Flumine class the .run() executes a while True loop suggesting that the process_market_book() will run forever when triggered.

In my case, I simply want to execute a single bet on demand and that's it. What's the recommended practice for placing single market-selection_id bets like this? Is it fine to continuously initialise new Flumine() instances per market and include a select_id as an additional class attribute (e.g self.selection_id)? In hindsight, I have a feeling flumine might be overkill for what I need and that a simple bflw order placement is enough... but don't know enough to know if I should be taking advantage of what flumine has to offer (order tracking, error handling, etc) - the impression is that it seems more trading-focused which is not what I need right now.



The last question is, what's the best way to uniquely identify a strategy in bflw or flumine so that it's easy to track specific strategies and the bets they place? From what I understand it's ideal to use the listClearedOrders api and also customerOrderRef / customerStrategyRef. How do you specify these with bflw / flumine?

---

## 2022-03-14 20:45:38 - issues channel

**Mo**

Still does not work with the same error code?

---

## 2022-03-13 13:01:19 - random channel

**Dave**

Premium charge should be reduced by a Betfair error factor :)

---

## 2022-03-12 18:24:59 - random channel

**Oliver Varney**

I guess it depends on complexity, and proper gabion of errors.

---

## 2022-03-11 14:49:47 - issues channel

**Dave**

My end goal is to populate a poisson model with betfair odds and fixtures

---

## 2022-03-11 14:38:27 - issues channel

**Dave**

Hi all, I'm hoping for some help from experts. I've been trying to get to grips with the API using Python so that I don't have to outsource it but I'm running in to the following error:



raise APIError(None, exception=e)

betfairlightweight.exceptions.APIError: None

Params: None

Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3932)')))



I'm pretty green so my apologies if this is something obvious - I saw this was asked on the Betfair Developer Forum and the OP was directed here as Liam said it had been answered - it was over a year ago though so I can't find the thread.....

---

## 2022-03-11 14:20:15 - issues channel

**Paul**

Possibly stupid question: is it possible to use the DataStream and `process_raw_data` with data recorded with the market recorder? I tried to throw it in there to debug something around what I'm doing in `process_market_book` and it didn't seem to fire.

---

## 2022-03-10 14:28:16 - issues channel

**liam**

that error normally points to a bad connection to betfair

---

## 2022-03-10 14:20:57 - issues channel

**Brøndby IF**

The error now wasn't in a specific eventid, it didn't even load the call data:



`betfairlightweight.exceptions.APIError: None`

`Params: None`

`Exception: HTTPSConnectionPool(host='[http://identitysso.betfair.com|identitysso.betfair.com](http://identitysso.betfair.com|identitysso.betfair.com)', port=443): Read timed out. (read timeout=3.05)`

---

## 2022-03-10 14:13:58 - issues channel

**Brøndby IF**

I just sent the error to know if it's something that sometimes happens or if it's because of some code failure.

---

## 2022-03-10 14:13:10 - issues channel

**Brøndby IF**

Hi guys, today I'm getting this response when running the code, is it a one-time glitch or should I change something in my code? If necessary, I'll send you the complete code here. The error is this: `betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue`

`Params: {'filter': {'eventIds': ['31291900']}, 'marketProjection': ['RUNNER_METADATA'], 'sort': 'FIRST_TO_START', 'maxResults': '100'}`

`Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)`

---

## 2022-03-09 20:43:24 - issues channel

**Dave**

Use a debugger after making the call, or just print(dir(response)) to see all its attributes

---

## 2022-03-08 10:36:55 - issues channel

**Beeblebrox**

I had the same thing happen to me the other day - no cpu spikes or anything, but only 1/2 checks passed.  Stopping and restarting was the only thing that fixed it for me.

---

## 2022-03-08 09:24:55 - issues channel

**J**

UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 82: character maps to &lt;undefined&gt; &lt;--Does anyone hit this a lot in Flumine when loading stored markets on disk (like historic files)? I'm hitting it often but somewhat randomly. Hitting it in both historic files and also marketrecorded files



Ful trace: Traceback (most recent call last):

  File "c:\Users\heari\Desktop\flumine\bfbulk v2.py", line 537, in &lt;module&gt;

    *framework.add_strategy(strategy2)*

  File "C:\Users\heari\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\baseflumine.py", line 90, in add_strategy

    self.streams(strategy)  # create required streams

  File "C:\Users\heari\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\streams\streams.py", line 45, in __call__

    market_type = get_file_md(market, "marketType")

  File "C:\Users\heari\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\utils.py", line 67, in get_file_md

    first_line = f.readline()

  File "C:\Users\heari\AppData\Local\Programs\Python\Python39\lib\encodings\cp1252.py", line 23, in decode

    return codecs.charmap_decode(input,self.errors,decoding_table)[0]

*UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 82: character maps to &lt;undefined&gt;*

---

## 2022-03-08 08:07:17 - general channel

**Michael**

Seems like you have occasional unusually good days as well [@UPMUFSGCR](@UPMUFSGCR)? Looked at that way your latest blip maybe just looks like one unusually bad day and a couple flat-ish? I don't think I'd take any immediate action based on the plot above.



[@U01DVUAE2G1](@U01DVUAE2G1) Going from thousands of bets to very few over-night seems unusual, but even that I'd give time. Whenever I try something new I start it small and ramp up gently, a "big bang" type switch on seems likely to be a bad idea. Whilst I could be wrong I wouldn't normally expect a sophisticated player to operate that way, which might leave you with someone more naive, if that's the case they won't be around for long. Great big structural errors in your approach kill you really quickly.



As a general rule overnight changes are usually not the concern as they tend to be more random although they often don't feel like it. It's the long term trends that get you, the gradual decline of margin or tailing off of opportunities. That's what you look out for.

---

## 2022-03-07 19:42:04 - issues channel

**Aaron Smith**

s3_recorder is on the newest version, only difference is my add function:

```    def add(self) -&gt; None:

        [http://logger.info|logger.info](http://logger.info|logger.info)("Adding strategy %s with id %s" % (self.name, self.recorder_id))

        # check local dir

        if not os.path.isdir(self.local_dir):

            os.makedirs(self.local_dir)  # added by smiffy

            # raise OSError("File dir %s does not exist" % self.local_dir) &lt;- original by liam

        # create sub dir

        directory = os.path.join(self.local_dir, self.recorder_id)

        if not os.path.exists(directory):

            os.makedirs(directory)```

Trying to fix the problem i restarted the recorder from scratch and got tired of manually making the local file each time :smile:

---

## 2022-03-07 18:09:53 - general channel

**Peter**

I have seen similar. A strategy that was placing several hundred bets a day, suddenly just stopped. I anticipated an error in my code, some sort of untrapped condition that I'd failed to allow for and catch.



However when I dug into it, it turned out to be a large bets coming arriving in a way that trampled all over my signal, to the point when very few of my trades were still were still in range, and those that were still triggered, were failing a 2nd signal. Lasted about three days, then went back to normal.



I suspect that somebody was running a new strategy that didn't work out for them - maybe because they pushed me and others out and didn't like what they were left with. But it did warn me that my strategy was more sensitive than I'd realised.

---

## 2022-03-07 12:49:11 - general channel

**J**

Oh, think I may have screwed something up in trying to get around a codec error and inadvertently filtered out completed files, which would explain it. I'll dig deeper into that and confirm before I waste more of your time. Thanks for the help mate

---

## 2022-03-03 06:29:06 - general channel

**J**

Is anyone else hitting subscription limit exceeded errors since Betfair came back up? I'm hitting it just on the Australian horse racing market by itself (using the same code as before, and the code from this morning even went across multiple countries)

---

## 2022-03-02 13:10:14 - general channel

**Paul**

I don't know why I was using `price_size` - just getting on with it I guess, didn't read the docs properly - but it explains a _lot_ of strange behaviour that I thought was a transient error in my code. I guess it was. PEBKAC on this one though, definitely PEBKAC.

---

## 2022-03-02 07:46:13 - strategies channel

**Jonjonjon**

I had to set my logging level to warning before it told me what a recent problem was. When spamming many orders, I had rounding errors. So it thought a potential exposure of 15 was greater than my limit of 15. I'll probably get around it by adding a penny to my exposure limit

---

## 2022-03-02 05:58:21 - strategies channel

**J**

Whipped up a bot/strategy today in flumine but it's not placing bets. The market.place_order(order) call goes through without error (and on to the next line of code fine so there's no silent exception in the main code) but no order is placed. Is there a place that order errors are logged?

---

## 2022-02-28 23:18:37 - issues channel

**William**

Yes. It was something I added when trying to fix the issue

---

## 2022-02-28 20:07:46 - issues channel

**William**

```   # setup logging

    logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updat



    # create trading instance

    trading = betfairlightweight.APIClient(user, password, app_key=appKey, certs='/certs')



    # login

    trading.login_interactive()

    # create queue

    output_queue = queue.Queue()



    # create stream listener

    listener = betfairlightweight.StreamListener(

        output_queue=output_queue

        # lightweight=True

    )

    # create stream

    stream = trading.streaming.create_stream(

        host="race",

        listener=listener

    )

    # create filters (GB WIN racing)



    market_filter = streaming_market_filter(

        # event_type_ids=['7'],

        # country_codes=['AU'],

        # market_types=['WIN'],

        market_ids=market_id

    )

    market_data_filter = streaming_market_data_filter(

        # fields=['EX_LTP', "EX_ALL_OFFERS", 'EX_MARKET_DEF', 'EX_TRADED_VOL', 'EX_TRADED'],

        # fields=['EX_ALL_OFFERS', 'EX_MARKET_DEF'],

        # ladder_levels=9,

    )

    # subscribe

    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=100,  # send update every 1000ms

    )

    stream.start()

    return trading, output_queue, listener```

---

## 2022-02-28 20:07:24 - issues channel

**William**

What would be causing 'NOT_AUTHORIZED: AppKey is not configured for service' errors?

---

## 2022-02-25 16:37:34 - issues channel

**dont**

Hi folks, I'm trying to run the example from here: [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py) The login works fine and also the fileCount is retrieved ok, but the `get_list_files` fails and the error is not necessarily clear:

[https://gist.github.com/erikseulean/827218ab95ddd13f519505aed839b142](https://gist.github.com/erikseulean/827218ab95ddd13f519505aed839b142)



I did try to do a POST directly and I'm getting the same issue. I think there might be a misconfiguration on my side but I'm not entirely sure what exactly the issue is. Anybody had the same issue by any chance ?

---

## 2022-02-24 18:35:29 - issues channel

**Newbie99**

By chance is anyone having issues with listClearedOrders?



I keep getting this (seems to affect orders from 13:00 today onwards only), but everything seems to be operational:



```Params: {'betStatus': 'SETTLED', 'eventTypeIds': ['4339'], 'settledDateRange': {'from': '2022-02-24T13:00:00', 'to': '2022-02-24T14:00:00'}, 'includeItemDescription': True, 'fromRecord': 0} 

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)```

Or is it just a case of try a bit later, as its just a standard betfair timeout issue?

---

## 2022-02-24 09:11:53 - issues channel

**river_shah**

```Anyone seeing this:



  File "/usr/local/lib/python3.9/site-packages/flumine/flumine.py", line 48, in run

    del event

  File "/usr/local/lib/python3.9/site-packages/flumine/baseflumine.py", line 399, in __exit__

    self._process_end_flumine()

  File "/usr/local/lib/python3.9/site-packages/flumine/baseflumine.py", line 354, in _process_end_flumine

    self.strategies.finish(self)

  File "/usr/local/lib/python3.9/site-packages/flumine/strategy/strategy.py", line 242, in finish

    s.finish(flumine)

TypeError: finish() takes 1 positional argument but 2 were given```



---

## 2022-02-24 07:26:16 - issues channel

**Rob**

looks like that fixed it!, i wasnt handling img properly all the time. thanks [@UBS7QANF3](@UBS7QANF3)

---

## 2022-02-23 12:16:43 - issues channel

**Nacho Uve**

I've made a dummy strategy to get familiarized with the framework and backtesting.

I feed it with just one market file that I recorded, and it is just configured to place a back bet at a specific price when the match starts.



I see the order is placed correctly in the logs.



That price is reached after some minutes and log shows that the order is matched [EXECUTION_COMPLETED].

But when I summarized using the blotter, it looks like it was nothing there. No winning or losses.



&gt; marketId      sel_id  date_time_placed	   Order.status			price  avg_price_matched  size_matched    profit

&gt; 1.193102045   56085   2022-01-26 19:48:55    EXECUTION_COMPLETE 	1.6    0.0                0.0             -0.0



Where is my error?



Strategy Code here: [https://pastebin.com/amQPbdKN](https://pastebin.com/amQPbdKN)

---

## 2022-02-22 21:22:25 - strategies channel

**foxwood**

I've finally worked out a combination of market filters and strategy parameters and as I read it flumine provides one common order stream and a discreet market stream for each strategy ie if the framework is running 2 strategies it uses up 3 connections.



Question: I'm running some instances of the sample marketrecorder and each one has an open order stream. How can I close that order stream and release a connection - or must it stay open ? I've looked in the debugger, docs etc but can't see an obvious way to reach the stream object and call stop() - I thought I had it with client.order_stream but that was a bool flag ! (I know I should wrap the recorders in one instance but that's a job for another day)

---

## 2022-02-21 18:12:10 - issues channel

**AndyL**

Last night bot got numerous error: peer reset connection failures followed by you have exceeded your 10 subscriptions limit error...anyone seen that before?

Seemed to resolve itself after a few mins, but one consequence seemed to be that flumine lost track of an order, or maybe thought it had failed when it hadn't... so bot ended up hedging incorrectly...

---

## 2022-02-19 10:37:41 - general channel

**Mo**

```import logging

import queue

import threading



import betfairlightweight



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for cricket stream)

trading = betfairlightweight.APIClient("username", "password", app_key="appKey")



# login

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener, host="sports_data")



# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)

t.start()



# subscribe

streaming_unique_id = stream.subscribe_to_cricket_matches()



# check for updates in output queue

while True:

    updates = output_queue.get()

    for update in updates:

        print(update.json())```

---

## 2022-02-18 07:13:06 - issues channel

**liam**

Standard error 

---

## 2022-02-17 22:26:13 - issues channel

**Aaron Smith**

Note: i m not confident that the missing data in the s3 bucket is directly connected to this error message, as this error is not thrown for all market ids, but only a few. Thanks to anyone taking the time to have a look :blush:

---

## 2022-02-17 22:24:33 - issues channel

**Aaron Smith**

Lately my market_recorder is throwing some of those bois below over the day. Often times the market_recorder fails to put the market files into the s3 bucket (at any step, all i know for now is they are not in the bucket at the end of the day). For a single day/run cycle of the market recorder, either all or none of markets that have orders in them makes it into the bucket. Anyone having an idea whats going on here?

```{"asctime": "2022-02-16 19:08:14,104", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):

  File \"/path/prod_market_recorder/venv/lib/python3.10/site-packages/flumine/worker.py\", line 230, in _get_cleared_market

    cleared_markets = betting_client.betting.list_cleared_orders(

  File \"/path/prod_market_recorder/venv/lib/python3.10/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File \"/path/prod_market_recorder/venv/lib/python3.10/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request

    self._error_handler(response_json, method, params)

  File \"/path/prod_market_recorder/venv/lib/python3.10/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.194823061'], 'customerStrategyRefs': ['ip-xxx-xx-xx-x'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} 

Exception: None 

Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-02011018-001f0d3c34', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-02011018-001f0d3c34', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders 

Params: {'betStatus': 'SETTLED', 'marketIds': ['1.194823061'], 'customerStrategyRefs': ['ip-xxx-xx-xx-x'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} 

Exception: None 

Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-02011018-001f0d3c34', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-02011018-001f0d3c34', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

---

## 2022-02-17 16:36:45 - general channel

**Andrew**

It seems that Betfair will close your _entire_ cricket score feed connection if you subscribe to a single bad eventId?

e.g.

```[

  ;; outgoing subscription request

  {

    "eventIds": [

      "31238985", ;; Islamabad United v Peshawar Zalmi, in progress right now

      "31238538"  ;; Australia v Sri Lanka in 17 hours from now

    ],

    "heartbeatMs": 10000,

    "id": 2,

    "op": "cricketSubscription"

  },



  ;; incoming subscription response

  {

    "connectionClosed": true, ;; !!!!

    "connectionId": "xxx",

    "errorCode": "INVALID_REQUEST",

    "errorMessage": "Not all provided eventIds are available to subscribe to. EventIds: [31238538]",

    "id": 2,

    "op": "status",

    "statusCode": "FAILURE"

  }

  ;; entire connection was killed!

]```

worse, you have to parse out which eventId failed from the `errorMessage` string. Is anyone else trying to subscribe to individual eventIds? Am I better off just leaving it blank and subscribing to the entire firehose?

---

## 2022-02-17 09:20:54 - issues channel

**Mo**

[@UNW8Q88EL](@UNW8Q88EL) is the appropriate person to tag. But this is a very well known limitation, if it was easy to fix I'm sure they would have

---

## 2022-02-17 05:43:47 - general channel

**Mo**

[@UUX1L88MC](@UUX1L88MC) - rust beginner question, I am trying to build the package from source. I have cloned it and am running `maturin develop` and get this error:



```💥 maturin failed

  Caused by: Cargo metadata failed. Does your crate compile with `cargo build`?

  Caused by: `cargo metadata` exited with an error: error: failed to parse manifest at `xxx`



Caused by:

  feature `edition2021` is required



  consider adding `cargo-features = ["edition2021"]` to the manifest```

---

## 2022-02-16 14:32:24 - random channel

**Jonjonjon**

Suppose I ran a script locally and it had no problems, but running it on AWS caused memory issues. How would you try to debug it? I have checked that I am running the same version of the script.

---

## 2022-02-15 11:04:00 - random channel

**Unknown**

Am I right in thinking debug got recently removed?

---

## 2022-02-14 16:48:55 - issues channel

**liam**

You don't need to kill, you can just wait for it to fix itself and then carry on

---

## 2022-02-14 16:45:48 - issues channel

**D C**

Is there a best practice for what to do with a 503 error? I just have an alert that tells me I need to kill my bots but this seems a bit excessive.

---

## 2022-02-14 16:37:54 - issues channel

**mandelbot**

Same here. 503 errors

---

## 2022-02-14 16:37:42 - issues channel

**Laybot McBackbot**

I am getting a lot of errors!!

---

## 2022-02-14 16:25:10 - issues channel

**Paul**

Card from Betfair in the post: Roses are red, violets are blue, this Valentine's Day `Invalid response received` is my exception for you!

---

## 2022-02-14 16:23:18 - issues channel

**Paul**

I'm going to be dreaming of `betfairlightweight.exceptions.InvalidResponse: Invalid response received: [{'eventType': {'id': '7'}, 'marketCount': 357}]` all night. It's like a special valentine's day treat...

---

## 2022-02-13 20:16:31 - issues channel

**Brøndby IF**

```order_filter = betfairlightweight.filters.ex_best_offers_overrides(

    best_prices_depth=3

)



price_filter = betfairlightweight.filters.price_projection(

    price_data=['EX_BEST_OFFERS'],

    ex_best_offers_overrides=order_filter

)



# Obtendo odds para o mercado

market_books = trading.betting.list_market_book(

    market_ids=jogo_betfair_exchange_mercados['IDMercado'],

    price_projection=price_filter

)



#Lista de runners

runners = market_books[0].runners```

hi guys, please help me understand why this error is occurring and what should I do to solve it?



The error is:



```betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook

Params: {'marketIds': '1.194661463', 'priceProjection': {'priceData': ['EX_BEST_OFFERS'], 'exBestOffersOverrides': {'bestPricesDepth': 3}, 'virtualise': True, 'rolloverStakes': False}}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}```



---

## 2022-02-13 09:01:27 - issues channel

**Mo**

To be clear, you're getting the error when trying to scrape the market catalogues. So your prices files may continue to be scraped OK but you'll be missing the corresponding market catalogues

---

## 2022-02-12 19:15:12 - issues channel

**Nacho Uve**

I find a lot these errors in the log using "marketrecorder.py":



{"asctime": "2022-02-12 18:08:02,572", "levelname": "ERROR", "message": "poll_market_catalogue error", "exc_info": "Traceback (most recent call last):\n  File \"c:\\users\\myuser\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\flumine\\worker.py\", line 128, in poll_market_catalogue\n    market_catalogues = client.betting_client.betting.list_market_catalogue(\n  File \"c:\\users\\myuser\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\betfairlightweight\\endpoints\\betting.py\", line 233, in list_market_catalogue\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"c:\\users\\myuser\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"c:\\users\\myuser\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue \nParams: {'filter': {'marketIds': ['1.194430217', '1.194430009', '1.194553817', '1.194429905', '1.194430113', '1.194441740']}, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'maxResults': 25} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang11a-prd-02010955-99993c3ac9', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang11a-prd-02010955-99993c3ac9', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_market_catalogue", "response": "SportsAPING/v1.0/listMarketCatalogue \nParams: {'filter': {'marketIds': ['1.194430217', '1.194430009', '1.194553817', '1.194429905', '1.194430113', '1.194441740']}, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'maxResults': 25} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang11a-prd-02010955-99993c3ac9', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie1-ang11a-prd-02010955-99993c3ac9', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}



More lines of example here:

[https://pastebin.com/2VutqGi8](https://pastebin.com/2VutqGi8)



So, it returns a errorCode: 'INVALID_SESSION_INFORMATION'.   It is strange because the program continues with the recording, and the files stream files are OK, makes the gzip, etc.

---

## 2022-02-11 23:53:50 - issues channel

**Jonjonjon**

It accidentally popped up in my code after I un-commented some `numba` decorators that I'd commented out for debugging purposes many moons ago.:disappointed:

---

## 2022-02-11 23:40:39 - issues channel

**Jonjonjon**

`x = np.float64(123)`

`import json`

`json.dumps({"A":x})`

`Out[8]: '{"A": 123.0}'`

`import orjson`

`orjson.dumps({"A":x})`

`Traceback (most recent call last):`

  `File "/home/jon/miniconda3/envs/betfair/lib/python3.8/site-packages/IPython/core/interactiveshell.py", line 3418, in run_code`

    `exec(code_obj, self.user_global_ns, self.user_ns)`

  `File "&lt;ipython-input-10-801def5f984d&gt;", line 1, in &lt;module&gt;`

    `orjson.dumps({"A":x})`

`TypeError: Type is not JSON serializable: numpy.float64`

---

## 2022-02-11 15:43:25 - issues channel

**foxwood**

[@U016TGY3676](@U016TGY3676) It's on a Windows server so was easier to replicate my devenv and run it that way for now rather than setting up for command line. Early days with flumine and it has helped with some needed debugging and quick fixes. PyCharm is certainly a memory hog though which with other stuff that runs is pushing the hardware.

---

## 2022-02-10 19:40:23 - random channel

**D C**

I have a "market" class. This used to be initialised from a marketInfo from the listMarketCat. Moving to the stream now, I instead initialise from the initial stream image, then later call listMarketCat. When new markets are added, I pick it up off the stream and call listMarketCat later. Couple of times today though I've had exceptions fire because the initial stream message was NOT an image. I didn't think this was possible. It's happened twice over about 1500 markets now. I can't even think of an explanation and your response suggests that it simply should not happen

---

## 2022-02-10 10:55:13 - general channel

**Nacho Uve**

Cool! It works!



Just a minor comment: it raises the exception:



&gt;  ValueError: No objects to concatenate

if the `market_type_filter` contains a market_type that is not in the file.



I don't know if it is better to catch that with a better message or it is ok like that.



Thank you very much!

---

## 2022-02-09 10:02:08 - issues channel

**liam**

lots of connection errors this morning, anyone else?

---

## 2022-02-08 16:04:47 - general channel

**VT**

Hi guys, I'm trying to send a Fill or Kill order but I can't see the error.



    limit_order_filter = filters.limit_order(

        size=3,

        price=2,

        persistence_type='LAPSE',

        time_in_force='FillOrKill'

        )



    instructions_filter = filters.place_instruction(

        selection_id=id_leader,

        order_type="LIMIT",

        side='BACK',

        limit_order=limit_order_filter,

        )



    order = trading.betting.place_orders(

        lightweight=True,

        async_=True,

        market_id=id_mercado,

        instructions=[instructions_filter],

        session=session

        )



--------------------------------------



Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}



I searched for DSC-0018 error in API



DSC-0018 MandatoryNotDefined Client 400 A parameter marked as mandatory was not provided

---

## 2022-02-08 11:01:05 - issues channel

**river_shah**

Just hit this error:

```2022-02-08 10:48:12.425 CRITICAL[flumine.utils:call_strategy_error_handling:233] Unknown error 'Market' object has no attribute 'blotter' in process_market_book```

Any idea why it may occur? Prod only, let me know what further debug I can provide (although I have very little aside from this `CRITICAL`message)

---

## 2022-02-06 10:23:31 - issues channel

**Peter**

Very basic:



```import os

import logging

import queue

import threading



import betfairlightweight



# setup logging

# logging.basicConfig(level=logging.DEBUG)  # change to DEBUG to see log all updates

logging.basicConfig(

    level=logging.DEBUG,

    filename='tpd/race-subscription.log',

    filemode="a",

    format='%(asctime)s - %(levelname)s - %(message)s',

)



# create trading instance (app key must be activated for streaming)

workspace_prefix = os.getenv("WORKSPACE_PREFIX")

trading = betfairlightweight.APIClient(os.getenv("BETFAIR_USERNAME"), os.getenv("BETFAIR_PASSWORD"), app_key=os.getenv("BETFAIR_LIVE_KEY"), certs=workspace_prefix + "certs")



# login

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener)



# subscribe

streaming_unique_id = stream.subscribe_to_races()



# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)

t.start()



# check for updates in output queue

while True:

    update = output_queue.get()

    print(update)```

---

## 2022-02-06 10:16:40 - issues channel

**liam**

```2022-02-06 10:16:11,801 | DEBUG | Starting new HTTPS connection (1): [http://identitysso.betfair.com:443|identitysso.betfair.com:443](http://identitysso.betfair.com:443|identitysso.betfair.com:443)

2022-02-06 10:16:12,072 | DEBUG | [https://identitysso.betfair.com:443](https://identitysso.betfair.com:443) "POST /api/login HTTP/1.1" 200 None

2022-02-06 10:16:12,073 | INFO | [Register: 1]: raceSubscription

2022-02-06 10:16:12,073 | INFO | [RaceStream: 1]: "RaceStream" created

2022-02-06 10:16:12,206 | DEBUG | [Subscription: 2] Sending: b'{"op": "authentication", "id": 2, "appKey": "poo", "session": "loo"}\r\n'

2022-02-06 10:16:12,206 | DEBUG | [Subscription: 2] Sending: b'{"op": "raceSubscription", "id": 1}\r\n'

2022-02-06 10:16:12,208 | INFO | [RaceStream: 1]: connection_id: 102-060222101612-211789

2022-02-06 10:16:12,328 | INFO | [RaceStream: 2]: SUCCESS (9 connections available)

2022-02-06 10:16:12,328 | INFO | [RaceStream: 1]: SUCCESS (9 connections available)

2022-02-06 10:16:12,328 | DEBUG | [RaceStream: 1]: SUB_IMAGE: {'op': 'rcm', 'id': 1, 'initia```

---

## 2022-02-06 10:15:15 - issues channel

**Peter**

Wondered if anybody else has had this and has any suggestions. To me the message that erroring appears to be exactly what the documentation suggests the service is expecting.

---

## 2022-02-06 10:14:18 - issues channel

**Peter**

Having difficulty subscribing the the race stream:



```2022-02-06 10:09:25,303 - DEBUG - Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

2022-02-06 10:09:25,667 - DEBUG - [https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

2022-02-06 10:09:25,691 - INFO - [Register: 1]: raceSubscription

2022-02-06 10:09:25,694 - INFO - [RaceStream: 1]: "RaceStream" created

2022-02-06 10:09:25,795 - DEBUG - [Subscription: 2] Sending: b'{"op": "authentication", "id": 2, "appKey": "redacted", "session": "redacted"}\r\n'

2022-02-06 10:09:25,798 - DEBUG - [Subscription: 2] Sending: b'{"op": "raceSubscription", "id": 1}\r\n'

2022-02-06 10:09:25,811 - INFO - [RaceStream: 1]: connection_id: 201-060222100925-406302

2022-02-06 10:09:25,844 - INFO - [RaceStream: 2]: SUCCESS (14 connections available)

2022-02-06 10:09:25,847 - ERROR - [RaceStream: None]: INVALID_INPUT: Failed to un-marshall: '{"op": "raceSubscription", "id": 1}'```

---

## 2022-02-04 22:06:35 - general channel

**VT**

Guys I found the reason for the error I posted a few days ago, at least I believe I found it. As I only seek the stream of 1 market at a time, it is necessary to end this connection because Betfair, somehow, even if the market is closed, takes a long time to close this connection. Now, always before opening a new request to stream I finalize the last one. Since I started doing this I haven't had that error anymore.



streaming.stop()

INFO:__main__:Stopped MarketStreaming 1001

---

## 2022-02-04 13:46:07 - random channel

**Oliver Varney**

just was getting that debug issue then double checked

---

## 2022-02-03 21:23:12 - general channel

**Jonjonjon**

Will it encourage more people to attempt rounding error exploits?

---

## 2022-02-02 10:27:02 - random channel

**Mo**

[@U4H19D1D2](@U4H19D1D2) yeah was fixed 2 versions ago in betfairutil so must have been a stale install that was fixed when restarting his IDE

---

## 2022-02-02 10:07:14 - random channel

**liam**

that error is due to debug being removed as a variable for the Listener

---

## 2022-02-02 10:05:52 - random channel

**Lee**

[https://en.wikipedia.org/wiki/Rubber_duck_debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging)

---

## 2022-02-02 09:11:34 - random channel

**Peter C**

Hi [@UBS7QANF3](@UBS7QANF3), I'm having a play with this this morning, but I'm having problems loading my self recorded data. I get the following error, please would you help me debug? I get the same error importing various files with a variety of the betfairutil functions. I installed betfairutil/viz as above



```~\anaconda3\lib\site-packages\betfairutil\__init__.py in read_prices_file(path_to_prices_file, lightweight)

    792     stream = trading.streaming.create_historical_generator_stream(

    793         file_path=path_to_prices_file,

--&gt; 794         listener=StreamListener(

    795             max_latency=None, lightweight=lightweight, debug=False, update_clk=False

    796         ),



TypeError: __init__() got an unexpected keyword argument 'debug'```

---

## 2022-02-02 05:47:16 - general channel

**Mo**

Firstly, you are being paranoid, this has nothing to do with you being blocked



It's a simple network error and the fact you have 200 mb fibre is irrelevant. Your bandwidth has nothing to do with latency and the packets have a very long way to travel to you from Dublin



I don't speak Brazilian Portugese but I believe it's saying the remote host (i.e. Betfair) has closed the connection. Possibly at the TCP level your ACK packets are not getting back to them so they believe the connection has been lost. You might be able to keep the connection from dropping by tweaking some of your network settings but I don't use Windows so can't offer any specific advice there



The simple solution is what you're already doing which is to use a server (much) closer to Betfair

---

## 2022-02-01 23:12:06 - general channel

**VT**

Hi [@U030L8PPSHM](@U030L8PPSHM), VM stands for Virtual Machine? If so, I have no problems with the VPS, I never had an error in the market stream hosted on AWS, the error is on my local machine and has nothing to do with CPU or memory.

---

## 2022-02-01 23:08:43 - general channel

**Alex Alex**

Never encountered this kind of error before but my guess would be that it takes some time to get a response for your request reaching the server. `Latency high` sounds like it. What is the CPU load on your VM when you encounter this error?

---

## 2022-02-01 22:45:22 - general channel

**VT**

Guys, if anyone can help, I'm not able to proceed with my tests, every 5 minutes the error stream.



I ran the example code for examplestreamingerrhandling.py errors and the answer is below.



I even thought it could be due to data consumption, but the account I currently use must have already paid more than 20 thousand pounds just in commissions. I use a VPS on AWS and I leave the stream market running there, I believe it has nothing to do with it, I connect to the server and my computer at the same time.



I'm going to stop testing because I'm afraid my account will be blocked.



+++++++++++++++++++++++++++++++++++++++++++++++++++++++



The latency error appears 100% of the time, but it used to be between 0.6 and 0.9, this value above 1 had never seen. I'm in Brazil and this is the best we can get, 200mb download and upload, fiber optics.



WARNING:betfairlightweight.streaming.stream:[MarketStream: 1003]: Latency high: 1.6549324989318848



+++++++++++++++++++++++++++++++++++++++++++++++++++++++



ERROR:__main__:MarketStreaming run error



Traceback (most recent call last):

  File "C:\Users...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 230, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "C:\Users...\anaconda3\lib\ssl.py", line 1226, in recv

    return self.read(buflen)

  File "C:\Users...\anaconda3\lib\ssl.py", line 1101, in read

    return self._sslobj.read(len)

ConnectionResetError: [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Users...\AppData\Local\Temp/ipykernel_6984/859485830.py", line 61, in run

    self.stream.start()

  File "C:\Users...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 60, in start

    self._read_loop()

  File "C:\Users...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 212, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\Users...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 234, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 1003]: Socket [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto

INFO:__main__:Starting MarketStreaming

---

## 2022-02-01 13:50:42 - general channel

**liam**

Got some errors when trying to install from PyPi, expected?



```  error: could not compile `bzip2-rs` due to 5 previous errors

  warning: build failed, waiting for other jobs to finish...

  error: build failed

  💥 maturin failed

    Caused by: Failed to build a native library through cargo

    Caused by: Cargo build finished with "exit status: 101": `cargo rustc --message-format json --manifest-path Cargo.toml --release --lib -- -C link-arg=-undefined -C link-arg=dynamic_lookup -C link-args=-Wl,-install_name,@rpath/betfair_data.cpython-39-darwin.so`

  🔗 Found pyo3 bindings

  🐍 Found CPython 3.9 at /Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9

  error[E0432]: unresolved import `std::io::ReadBuf`

   --&gt; /Users/liampauling/.cargo/git/checkouts/bzip2-rs-5185c758a5d48e65/748b36f/src/decoder/parallel/reader.rs:2:5

    |

  2 | use std::io::ReadBuf;

    |     ^^^^^^^^^^^^^^^^ no `ReadBuf` in `io`





  error[E0432]: unresolved import `std::io::ReadBuf`

   --&gt; /Users/liampauling/.cargo/git/checkouts/bzip2-rs-5185c758a5d48e65/748b36f/src/decoder/reader.rs:2:5

    |

  2 | use std::io::ReadBuf;

    |     ^^^^^^^^^^^^^^^^ no `ReadBuf` in `io`





  error[E0599]: no method named `read_buf` found for type parameter `R` in the current scope

     --&gt; /Users/liampauling/.cargo/git/checkouts/bzip2-rs-5185c758a5d48e65/748b36f/src/decoder/parallel/reader.rs:110:37

      |

  110 |                         self.reader.read_buf(&amp;mut read_buf)?;

      |                                     ^^^^^^^^ method not found in `R`





  error[E0599]: no method named `read_buf` found for type parameter `R` in the current scope

    --&gt; /Users/liampauling/.cargo/git/checkouts/bzip2-rs-5185c758a5d48e65/748b36f/src/decoder/reader.rs:68:37

     |

  68 |                         self.reader.read_buf(&amp;mut read_buf)?;

     |                                     ^^^^^^^^ method not found in `R`





  error: aborting due to 4 previous errors





  Some errors have detailed explanations: E0432, E0599.



  For more information about an error, try `rustc --explain E0432`.



  Error: command ['maturin', 'pep517', 'build-wheel', '-i', '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9'] returned non-zero exit status 1

  ----------------------------------------

  ERROR: Failed building wheel for betfair-data

Failed to build betfair-data

ERROR: Could not build wheels for betfair-data which use PEP 517 and cannot be installed directly

WARNING: You are using pip version 20.3.1; however, version 22.0.2 is available.

You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.```

---

## 2022-02-01 09:27:47 - random channel

**Paul**

Sounds like it. Most importantly you haven't made the novice error of trying to write your own :ok_hand: 

---

## 2022-01-31 19:14:13 - general channel

**VT**

Hi everyone, I received this error about 10 times today, I had received it before but it was not common, now I can't stay connected to the stream for 5 minutes and the connection is interrupted. I connect to one market only.



Exception in thread Betfair Stream:

Traceback (most recent call last):

  File "C:\Users...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 230, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "C:\Users...\anaconda3\lib\ssl.py", line 1226, in recv

    return self.read(buflen)

  File "C:\Users...\anaconda3\lib\ssl.py", line 1101, in read

    return self._sslobj.read(len)

ConnectionResetError: [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\Users...\anaconda3\lib\threading.py", line 932, in _bootstrap_inner

    self.run()

  File "C:\Users...\anaconda3\lib\threading.py", line 870, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 60, in start

    self._read_loop()

  File "C:\Users...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 212, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\Users...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 234, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 2]: Socket [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto

---

## 2022-01-31 12:23:05 - issues channel

**Aaron Smith**

anyone else getting some stream errors?

---

## 2022-01-30 16:24:07 - issues channel

**birchy**

Has something changed in the Flumine order validation, because, for example, a LAY bet of £1@10.0 is now throwing:

`Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency`

This is a 6+ months running strategy (live) which is still working ok, but fails when backtesting.

If I change the size to £2, validation passes.

FYI: live is running on Flumine 1.20.13 and backtesting is 1.21.2

Ok, so this seems to be related to PR #546:

[https://github.com/liampauling/flumine/blob/770fcf967dab590cba63350dd2ee46839363f8d1/flumine/controls/tradingcontrols.py#L71|https://github.com/liampauling/flumine/blob/770fcf967dab590cba63350dd2ee46839363f8d1/flumine/controls/tradingcontrols.py#L71](https://github.com/liampauling/flumine/blob/770fcf967dab590cba63350dd2ee46839363f8d1/flumine/controls/tradingcontrols.py#L71|https://github.com/liampauling/flumine/blob/770fcf967dab590cba63350dd2ee46839363f8d1/flumine/controls/tradingcontrols.py#L71)

As far as I can tell, £1@10.0, £0.10@100, etc should still be valid?

[https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=3833942#placeOrders-Abilitytoplacelowerminimumstakesatlargerprices|https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=3833942#placeOrders-Abilitytoplacelowerminimumstakesatlargerprices](https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=3833942#placeOrders-Abilitytoplacelowerminimumstakesatlargerprices|https://docs.developer.betfair.com/plugins/servlet/mobile?contentId=3833942#placeOrders-Abilitytoplacelowerminimumstakesatlargerprices)

---

## 2022-01-28 19:42:45 - issues channel

**AndyL**

If I try and start a strategy subscribing to say uk greyhounds and it tries to get over 200 markets i get the subscription limit exceeded error, is there a parameter to say just subscribe to the next 200 ?

---

## 2022-01-28 15:34:45 - random channel

**D C**

I might not have joined at all if it had Py in the name because I don't use Python. Probably not many of us in here that don't actually use the BFLW code base, but I feel that if I had not joined this group by just because of that "Py" prefix I would have missed out on an incredible resource.

---

## 2022-01-28 13:33:01 - issues channel

**Lee**

Has anyone seen an increase in errors on the execution endpoints this last week or so? (Place, cancel etc) Mainly timeouts and connection reset.

---

## 2022-01-26 09:40:36 - issues channel

**foxwood**

Don't know if it's common but had a couple of these overnight on OrderStream which rebuilt connection ok "betfairlightweight\\streaming\\betfairstream.py\", line 242, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 1003]: Connection closed by server" -  anything to worry about ?

---

## 2022-01-25 17:48:36 - strategies channel

**birchy**

Yeah, check that clock is syncing to an NTP server. Should be automatic on Linux but can be flakey on Windows. Also in PyCharm, if you run in debug mode, there's extra overheads.

---

## 2022-01-25 17:31:29 - strategies channel

**foxwood**

ok fixed that safely. strategy prints out immediate info from process_closed_market for markets still on BF but closed so getting there. Actually made some bets but I'd changed stake to £1 so not taken but no error message in log - maybe it doesn't - no probs. However, nothing in log except high latency messages for {MarketStream: 2201] with typical time of 0.84 - no flumine setup messages / bet errors / markets or anything like that - not sure what to expect lol. What section of processing / transmission is the latency referring to ?

---

## 2022-01-25 16:43:24 - strategies channel

**liam**

that error is because you need to wait for the catalogue to be populated by the worker



```if market.market_catalogue:

    crap```

---

## 2022-01-24 21:55:24 - issues channel

**birchy**

While on the subject of RAM, how do you guys handle "big" backtests/signal processing with Flumine? I've found that if I run a strategy that produces 200k+ bets, the Framework eventually falls over because my 4GB AWS machine falls over with OOM errors. I know that increasing the amount of RAM is a solution (as is running on my local 8GB machine), but am wondering if there's a way to break up the framework into smaller chunks so that it can run on lower spec hardware?

---

## 2022-01-24 21:22:02 - strategies channel

**foxwood**

Was worth doing as [@U4H19D1D2](@U4H19D1D2) said lol. Many confusing issues. My connection to BF from server stopped late afternoon. At that same time I had logged in to test and live at least 7 times in 20 mins after fixing issues from a local PC and also started a BA instance. Think I blew the connection limits since no graceful termination - just killed flumine. Local ran for the rest of the day but server didn't get any live data it seems and stuck cycling non-stop with Latency high: 3317.0....."". Not sure if they simply killed that IP. See what tomorrow brings.

---

## 2022-01-22 17:22:33 - issues channel

**mandelbot**

Send mail to bdp@betfair with the connection ID and error

---

## 2022-01-22 16:32:42 - issues channel

**Aaron Smith**

Hi ppl, i m getting this bad boy today:

```"ERROR", "message": "[MarketStream: 2002]: MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s)."}```

I am not using that many connections (should be 4 i think?) So i assume some connections just dont get closed? Any idea how to approach this?

---

## 2022-01-20 18:34:58 - random channel

**Lee**

Very verbose, large diffs, if using a non typed language like Python for the api then it can be tricky to get the right structure in the swagger def, takes a bit of trial and error.

All that aside, personally I'd say the benefits outweighs the negatives. Especially when working in a team or have a fair amount or endpoints.

---

## 2022-01-20 11:32:49 - issues channel

**Newbie99**

I've reported numerous issues to them about nonsensical P&amp;L on that page, I think they just ignore it and hope it fixes itself :slightly_smiling_face:



I think 'under the hood' the numbers are correct, its just the Betfair GUI p&amp;l that comes up with randomness at times!

---

## 2022-01-20 09:32:40 - issues channel

**Ruben**

quite sure, in fact I noticed because I got an error because I was trying to round the profit. `{"asctime": "2022-01-19 22:56:20,772", "threadName": "MARKET_LOGGING_CONTROL", "levelname": "CRITICAL", "message": "type NoneType doesn't define __round__ method exception raised in MARKET_LOGGING_CONTROL", "exc_info": .... +\nTypeError: type NoneType doesn't define __round__ method", "event": "&lt;CLEARED_MARKETS [HANDLER]&gt;"}`

---

## 2022-01-18 19:39:53 - general channel

**VT**

No, I'm now analyzing the error handling code, thanks Liam.

---

## 2022-01-18 07:46:55 - general channel

**liam**

Looks to be network or server side, quite common, are you using the error handling example?

---

## 2022-01-17 22:33:08 - general channel

**VT**

Betfair Stream:

Traceback (most recent call last):

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 230, in _receive_all

    part = self._socket.recv(self.buffer_size)



  File "C:\anaconda3\lib\ssl.py", line 1226, in recv

    return self.read(buflen)

  File "C:\anaconda3\lib\ssl.py", line 1101, in read

    return self._sslobj.read(len)

ConnectionResetError: [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto



During handling of the above exception, another exception occurred:

---

## 2022-01-17 21:05:54 - issues channel

**liam**

Yeah, only reason you would be missing a response is if there is an unhandled exception in the thread but fairly sure we handle all 

---

## 2022-01-17 20:51:03 - general channel

**VT**

Does anyone know what this error is?



Traceback (most recent call last):

  File "C:...\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 230, in _receive_all

    part = self._socket.recv(self.buffer_size)

---

## 2022-01-17 13:34:04 - random channel

**Oliver Varney**

everyone else having a few account errors come through ?

---

## 2022-01-17 07:10:44 - random channel

**Mo**

[@U016TGY3676](@U016TGY3676), it's very common to want to have a random sequence that can be reproduced. For example, this might help with debugging or ensuring some backtest results are comparable. Typically this is done by setting the random seed and if that was combined with your use of `random.choice` then that can be considered a complete solution to the problem at hand. The method I posted has a couple of advantages that I can see:



1. No need to _remember_ to set the seed or what seed you should use

2. Will produce the same results for everyone

Coming back to my point about debugging, 2. is very useful. If someone comes on here with a bug in their program that ran on a random assignment of market IDs then, provided this canonical method for that assignment existed and was used, I could run the code and generate the same bug without needing to know anything about the state of their random number generator. And coming back to 1., if they didn't use this method and they weren't aware of this nuance they might not have set the seed and no one would ever know what random number generator state produced the bug.

---

## 2022-01-16 18:16:05 - general channel

**NC**

```UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 581: character maps to &lt;undefined&gt;```

I'm encountering this error when trying to stream the historical data from a file on disk. I've copied the code from examplestreaminghistorical.py and changed the file_path for the historical stream, to that of my .bz2 file (also tried for .tar with similar result). I guess I've misunderstood something. Any ideas?

---

## 2022-01-16 07:23:57 - general channel

**liam**

They will charge if you go over the transaction limit, they won’t take issues with you using small stakes providing you aren’t taking advantage of rounding and doing it on low odds (recent update on the API gives a cryptic error message on this now anyway) 

---

## 2022-01-15 12:33:56 - strategies channel

**foxwood**

I'm developing some analysis based on the example datacollectinwom.py and am gathering lists of data per runner for graphing etc. I hadn't allowed for getting a None price from non-runners so it blew up (expected behaviour lol). However, that got me thinking about some key assumptions I had made and I wonder if they were safe, particularly with non-runners - maybe those with more knowledge could comment.

Assumptions:

1) the strategy callback argument "market_book" is the same object as could be accessed at "market.market_book"

2) the strategy callback "check_market_book" is made for every "mcm" streaming packet received and if that returns True then "process_market_book" is called - this means the strategy is offered every packet

3) for each callback all the data from the supplied market/market_book pointers has been updated to reflect the changes implied by the packet

4) the list of runners in the market_book and their index order is invariant ie runner Fred will be at the same index in "market_book" from first recording through to closed market



I think the first three are correct but not sure relying on the index position is safe - perhaps selection_id has to be used as a dict key for my saved lists which would slow things down quite a bit - important if it was a live betting strategy ?



I have noticed that BF change the "sort_priority" field for runners when there are withdrawals but not sure how/if that impacts flumine.



One area of difference I have found is with "market.market_book.market_definition.runners" which appears to be in BF sort order with N/R at the end whereas "market.market_catalogue.runners" and "market.market_book.runners" appear to remain in fixed positions regardless of withdrawal.

---

## 2022-01-15 09:30:23 - random channel

**Newbie99**

Apologies as this is a bit open ended, but I'm not understanding what went wrong here, last night around 1 am, out of (seemingly) no-where it looks like I suddenly got latency warnings and then eventually the process killed:



```{"asctime": "2022-01-15 01:00:05,664", "levelname": "INFO", "message": "Placing new LAY order for runner ('Jaime Jamel', 35971913, 0), runner exposure is: {'selection_id': 35971913, 'handicap': 0, 'if_win': 0.539, 'runner_matched_stake': 0.0, 'runner_matched_exposure': 0.0, 'min_market_exposure': -18.509999999999998} and limit is: 0.3."}

{"asctime": "2022-01-15 01:00:05,664", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.193372878", "selection_id": 35971913, "handicap": 0, "id": "138615012056645370", "customer_order_ref": "7c44d7544ce40O138615012056645370", "bet_id": null, "date_time_created": "2022-01-15 01:00:05.664573", "publish_time": "2022-01-15 01:00:05.647000", "market_version": null, "async": false, "trade": {"id": "7a2c3bee-759e-11ec-b096-02054918c7c6", "strategy": "betting_market_lay", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138615012056645370"], "offset_orders": [], "notes": "R3 5f Allw,2022-01-15 01:02:00,WIN,Flat,US,Charles Town,False,False,None,False,Jaime Jamel,2.64,2479.75,8,1,False,None,0,Charles Town (US) 14th Jan,31175177,7,{'strategy_name': 'betting_market_lay', 'selection_id': 35971913, 'handicap': 0, 'price_percentage': 0.768, 'min_valid_external_value': 0.8, 'current_back_price': 48, 'current_mid_price': 56.5, 'current_lay_price': 65, 'previous_back_price': 50, 'previous_mid_price': 62.5, 'previous_lay_price': 75},1", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 50.0, "size": 0.31, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.31, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Pending", "status_log": "Pending", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "R3 5f Allw,2022-01-15 01:02:00,WIN,Flat,US,Charles Town,False,False,None,False,Jaime Jamel,2.64,2479.75,8,1,False,None,0,Charles Town (US) 14th Jan,31175177,7,{'strategy_name': 'betting_market_lay', 'selection_id': 35971913, 'handicap': 0, 'price_percentage': 0.768, 'min_valid_external_value': 0.8, 'current_back_price': 48, 'current_mid_price': 56.5, 'current_lay_price': 65, 'previous_back_price': 50, 'previous_mid_price': 62.5, 'previous_lay_price': 75},1", "market_notes": null}

{"asctime": "2022-01-15 01:00:30,284", "levelname": "INFO", "message": "1.193373059: 0 cleared orders found, more available: False"}

{"asctime": "2022-01-15 01:01:13,244", "levelname": "WARNING", "message": "[FlumineStream: 4002]: Latency high: 0.9758524894714355"}

{"asctime": "2022-01-15 01:01:13,245", "levelname": "WARNING", "message": "[MarketStream: 3001]: Latency high: 0.9100987911224365"}

{"asctime": "2022-01-15 01:01:13,245", "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 0.8022336959838867"}

{"asctime": "2022-01-15 01:12:41,802", "levelname": "INFO", "message": "Deleting requests.Session", "sessions_created": 36, "session": "&lt;requests.sessions.Session object at 0x7f2c6a5195d0&gt;", "session_time_created": 1642208309.3769233, "session_time_returned": 1642208405.607362, "live_sessions_count": 1, "err": true}

{"asctime": "2022-01-15 01:12:41,813", "levelname": "WARNING", "message": "[MarketStream: 3001]: Latency high: 689.2287058830261"}

{"asctime": "2022-01-15 01:12:41,814", "levelname": "WARNING", "message": "[FlumineStream: 4002]: Latency high: 689.5181279182434"}

{"asctime": "2022-01-15 01:12:41,814", "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 689.121832370758"}```

The only change I've made (and so at this stage I'm assuming is the culprit) is to run the market recorder on my live instance, as opposed to my local test instance (previously I recorded locally and kept my live stuff separate), so I added this just before framework.run() on my live code in AWS:



```recorder = MarketRecorder(

            name="MR_horse_greyhounds",

            market_filter=streaming_market_filter(

                    event_type_ids=[7],

                    country_codes=['GB','IE','US','FR', 'AU'],

                    market_types=['WIN', 'PLACE', 'EACH_WAY'],

                ),

            stream_class=DataStream,

            context={

                "local_dir": ai.unprocessed_data,

                "bucket": "fluminetest",

                "force_update": False,

                "remove_file": True,

            },

        )



        framework.add_strategy(recorder)```

Am I potentially trying to record too much in one go and/or from the error am I somehow creating too many sessions (and if so how might I stop this)?



Again apologies for the open ended nature, I'm clearly not understanding something about sessions I feel!

---

## 2022-01-15 07:49:35 - issues channel

**Colin**

Strangely, my script appears to be working much better today. No errors yet. I didn't make any changes that I am aware of that would have addressed the source of the fault.

---

## 2022-01-14 16:31:18 - general channel

**Dario Scardina**

hello everyone :slightly_smiling_face:



Has somebody ever faced this exception



`ERROR Invalid response received: {'accountStatement': bla bla bla...`



with `trading.account.get_account_statement` method?



It seems that json response is not in a valid format...

---

## 2022-01-14 08:21:12 - issues channel

**Colin**

This appears to be the instigating exception,



Traceback (most recent call last):

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py", line 382, in _make_request

    self._validate_conn(conn)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn

    conn.connect()

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connection.py", line 411, in connect

    self.sock = ssl_wrap_socket(

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket

    ssl_sock = _ssl_wrap_socket_impl(

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl

    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py", line 500, in wrap_socket

    return self.sslsocket_class._create(

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py", line 1040, in _create

    self.do_handshake()

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py", line 1309, in do_handshake

    self._sslobj.do_handshake()

socket.timeout: _ssl.c:1112: The handshake operation timed out

---

## 2022-01-14 04:04:50 - issues channel

**Colin**

Hi All. I've tried searching for this and found similar occurrences, but extending the read and connect timeout values didn't seem to help. Any ideas?



Error:

Traceback (most recent call last):

  File "/Users/xxx/Documents/Personal/Python/learn/betfair.py", line 143, in &lt;module&gt;

    trading.login_interactive()

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/betfairlightweight/endpoints/logininteractive.py", line 30, in __call__

    (response, response_json, elapsed_time) = self.request(

  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/betfairlightweight/endpoints/logininteractive.py", line 53, in request

    raise APIError(None, exception=e)

betfairlightweight.exceptions.APIError: None

Params: None

Exception: HTTPSConnectionPool(host='[http://identitysso.betfair.com|identitysso.betfair.com](http://identitysso.betfair.com|identitysso.betfair.com)', port=443): Read timed out. (read timeout=3.05)



Source:

trading = betfairlightweight.APIClient(username=my_username,

                                       password=my_password,

                                       app_key=my_app_key)



    trading.betting.read_timeout = 30

    trading.betting.connect_timeout = 30

    trading.login_interactive()

---

## 2022-01-11 22:14:24 - issues channel

**Andy B**

Morning all, (cross posting here with the Betfair Quants slack channel) I'm getting an error in a script that hasn't given me issues previously and I was wondering if there was a data error causing anyone else grief? I am getting the list of todays greyhound markets and runner ID's but it is getting stuck on Capalaba greys with the following error:

Traceback (most recent call last):

  File "c:\Users\andy\OneDrive\Punting\Scripts\FastTrack\GetAllRaces.py", line 318, in &lt;module&gt;

    Races = market_catalogue_filter(Events['Event ID'][ind], Track)

  File "c:\Users\andy\OneDrive\Punting\Scripts\FastTrack\GetAllRaces.py", line 99, in market_catalogue_filter

    market_catalogues = trading.betting.list_market_catalogue(

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\betting.py", line 233, in list_market_catalogue

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 55, in request

    self._error_handler(response_json, method, params)

  File "C:\Python\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue

Params: {'filter': {'eventIds': ['31170555'], 'marketCountries': ['AU', 'NZ'], 'marketTypeCodes': ['WIN']}, 'marketProjection': ['MARKET_START_TIME', 'RUNNER_DESCRIPTION'], 'sort': 'FIRST_TO_START', 'maxResults': '1 00'}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}

PS C:\Users\andy&gt;

---

## 2022-01-10 19:48:40 - general channel

**Aaron Smith**

does someone have a function at hand that reliably extracts basic runner_data (market_id, selection_id, bsp, result) from a streaming_data file (the ones we get from the market_recorder / pro history data)? Somehow mine ends up only giving me 80% of runners and i thought before debugging that thing i may check if someone is so kind to free me from that work :smile:

---

## 2022-01-10 09:48:14 - general channel

**Peter**

I use Sport Monks and have found them to be very reliable. Compared to other (shall we say budget) services their data is less error prone, and when I've found errors in their historic data, they've been super responsive.



I haven't tried to use the Betfair endpoint recently, I gave up a while ago as it wasn't pretty inaccurate, often putting out the wrong score on the website itself.

---

## 2022-01-10 09:17:18 - general channel

**liam**

Fixed in [https://github.com/liampauling/flumine/pull/550|1.21.1](https://github.com/liampauling/flumine/pull/550|1.21.1) let me know if you have any other issues

---

## 2022-01-10 09:16:55 - issues channel

**liam**

Fixed in [https://github.com/liampauling/flumine/pull/550|1.21.1](https://github.com/liampauling/flumine/pull/550|1.21.1) with `strategies.finish` now called on `__exit__` and self passed to `strategy.finish` so you have access to market/blotter objects

---

## 2022-01-09 10:04:50 - issues channel

**Ruben**

on that same topic, if I wanted to cancell all unmatched orders when a `TerminationEvent` occurs (such as unhandled exception), would `finish()` of the strategy be the right spot?

---

## 2022-01-08 19:04:18 - issues channel

**AndyL**

[@U4H19D1D2](@U4H19D1D2) fyi, periodically seeing an error during backtests, with KeyError: new_price, ive raised #548

---

## 2022-01-08 15:44:09 - issues channel

**river_shah**

Just got a call from betfair, nothing new to add except they are working on fixing for Monday. Payment options will come back automatically (i.e they have not been deleted)

---

## 2022-01-07 14:55:40 - issues channel

**C0rnyFlak3s**

That would be pretty amazing tbh. Would save me a ton of time linking my data to external sources for soccer fixture information. :slightly_smiling_face:

---

## 2022-01-07 14:27:19 - general channel

**liam**

if you can dm the full logs I can have a look but can't debug without tbh

---

## 2022-01-07 14:24:44 - general channel

**Ke**

Everything seems to be fine. No warning or error

---

## 2022-01-07 11:23:00 - issues channel

**liam**

Just realised I have already designed for this, run function uses self as a context manager, so exit gets called on any error, and you can see a few things are already called however `process_end_flumine` isn't. With this added you can add any callbacks in your strategy in the `finish` function

---

## 2022-01-07 11:18:40 - issues channel

**river_shah**

Not sure what the best design here is, but despite plenty of unit testing I have noticed a few of my strategies rarely generate unhandled exceptions. Ideally, a callback if that happens so user code has a chance to log a bunch of state / dump any files etc and then terminate

---

## 2022-01-07 11:15:13 - issues channel

**liam**

There isn't a graceful way of doing it right now, wondering if we gracefully handle any unhandled errors regardless instead

---

## 2022-01-07 11:00:04 - issues channel

**river_shah**

How do I gracefully generate a `TerminationEvent` if any of my code causes an error? Problematic code is not necessarily in a try / except `CRITICAL flumine.utils:utils.py:233`

---

## 2022-01-06 23:42:38 - strategies channel

**birchy**

[@U0160E9HS2G](@U0160E9HS2G) The way I see it is that no model is 100% accurate, so we have to overcome this by using a margin of error big enough to give us confidence that the ends of our probability intervals are +EV. Then we pick the spots where the market overreacts and crosses our approximated +EV prices. The difficult part is optimising the model and narrowing the margin to achieve sufficient volumes of bets that are still +EV.

---

## 2022-01-05 09:48:15 - issues channel

**Aaron Smith**

oh okay, but wouldnt that result in a "int out of range" error rather than "bigint out of range" ?

---

## 2022-01-03 22:48:04 - random channel

**Ruben**

works like a charm, helped me track a bug

---

## 2022-01-02 14:01:31 - issues channel

**mandelbot**

Great I will try. Your fix won't work in this case however because your payout will be calculated based on price requested not bsp. I think you would have to send the call in the appropriate format

---

## 2022-01-02 13:46:04 - issues channel

**Paul**

Short version: the person creating the order has their liability fixed and the amount matched on the other side adjusts. Which if you think about it, is the only sensible thing they can do there

---

## 2022-01-02 13:45:25 - issues channel

**Paul**

On the back side, the backer's stake remains fixed so the 2.22 being asked for at 4.0 would not be increased to 3.33 if the BSP is 3.0

---

## 2022-01-01 11:41:15 - random channel

**liam**

Happy New Year everyone! Thanks for making this such an awesome group :grinning:



Happy with my first goal as flumine has certainly become more stable, failed on the second.



This year looking to make this more of a programming/betting group rather than just python/bflw so maybe a rename and moving some libraries to an organisation. Personally I want to keep things ticking over and look to future proof certain areas. 

---

## 2021-12-31 14:25:38 - strategies channel

**birchy**

In Flumine, what's the recommended way to use

`lookup = (market.market_id, runner.selection_id, runner.handicap)

exposure = market.blotter.selection_exposure(self, lookup)`

If all of our bets are one side only? Let's assume that we've backed OR layed all of the runners and now have an exposure &lt;= 0 for each runner. The current calc accumulates the liabilities at runner level. Is there a way to reset it to avoid validation errors, or is it easier to set `max_selection_exposure` to some big number and self-handle the exposure at market level?

---

## 2021-12-30 18:43:12 - random channel

**Michael**

I agree that trackers are a great product for most people, it's what I get family and friends to buy but if you're putting quite a lot aside then I don't think it's the only game in town. The internal costs in tracker funds are not negligible and the resulting tracking errors do become significant. If you're putting away enough that your transaction costs aren't a big deal then just buying a well diversified portfolio of individual shares gets you the full return on your holdings and spares you the risk associated with some of the synthetic tracking.

---

## 2021-12-30 14:14:09 - issues channel

**nthypes**

How can I enable debug logging? Could find in the docs.

---

## 2021-12-30 13:44:30 - issues channel

**Aaron Smith**

```"EX_BEST_OFFERS"```

works fine with flumine. How did you come to the conclusion its not? Can you show any errors/logs?

---

## 2021-12-30 11:46:57 - random channel

**Oliver Varney**

which looks something like this:

```def patch_open(file_name, read_write):

    if len(file_name) &gt; 4:

        if file_name[-4:] == ".zip":

            archive = zipfile.ZipFile(file_name, read_write)

            name_list = archive.namelist()

            return archive.open(name_list[0], read_write)

        elif file_name[-4:] == ".bz2":

            return smart_open.open(file_name, read_write)

        elif file_name[-3:] == ".gz":

            return smart_open.open(file_name, read_write)

    else:

        raise Exception("Unrecognised file {}".format(file_name))```



---

## 2021-12-29 17:58:06 - issues channel

**thambie1**

Getting errors on the listClearedOrders endpoint

---

## 2021-12-28 09:01:38 - random channel

**Michael**

I recall the discussion - did I really post a spreadsheet? Anyway for anyone who's wondering the take-away is that the lowest percentage is almost always best because otherwise you don't benefit as much from your implied comm. The main exception is if your total charges ratio (or whatever they call it) puts you right on the boundary between the upper PC brackets (40/50/60%) in which case the higher rates might make sense. If you are extremely consistent then your comm rate won't make much difference either way.



There's a separate but related discussion about the degree to which you should value returns now against generating comm to offset future winnings. I'm very much in the _"take the money now"_ camp but a case can be made the other way.

---

## 2021-12-28 09:01:02 - general channel

**S G**

Thanks for your reply Mo, i noticed that some of debug sessions were holding connections. After killing them, it worked OK

---

## 2021-12-28 08:23:39 - general channel

**Mo**

How is logging configured? Most likely you're getting an error on subscription which is not being reported to you

---

## 2021-12-27 15:54:22 - issues channel

**Jimmy**

Thanks [@U4H19D1D2](@U4H19D1D2) - I’ve debug logging on this afternoon to try capture some info but will tweak from the _meta. What's the difference? Can't find it in the docs/comments (sorry)

---

## 2021-12-27 14:04:11 - issues channel

**Jimmy**

Thanks — but given it was matched, not sure it’ll stop the error.

---

## 2021-12-27 14:02:13 - issues channel

**Jimmy**

Weird one. Trying to spot it — the bet was placed at betfair so it wasn’t cancelled or expired but it caused that error above…

---

## 2021-12-27 07:43:04 - general channel

**liam**

What version of bflw? I think we fixed this

---

## 2021-12-27 00:41:20 - general channel

**VT**

I'm getting this error when I run the basic BFLW code for stream market, does anyone know why?

The error happens when I send an order to the market (by an external software).



import queue

import threading

import betfairlightweight

from betfairlightweight.filters import streaming_order_filter



trading = betfairlightweight.APIClient("username", "password", app_key="appKey")

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener)



# create filters

order_filter = streaming_order_filter()



# subscribe

streaming_unique_id = stream.subscribe_to_orders(

    order_filter=order_filter,

    conflate_ms=1

)



# start stream in a new thread (in production would need err handling)

t = threading.Thread(target=stream.start, daemon=True)

t.start()



# check for updates in output queue

while True:

    current_orders = output_queue.get()

    print(current_orders)



===================================================



Exception in thread Thread-10:

Traceback (most recent call last):

  File "C:\anaconda3\lib\threading.py", line 932, in _bootstrap_inner

    self.run()

  File "C:\anaconda3\lib\threading.py", line 870, in run

    self._target(*self._args, **self._kwargs)

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 60, in start

    self._read_loop()

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 219, in _read_loop

    self._data(received_data)

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 258, in _data

    if self.listener.on_data(received_data) is False:

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\listener.py", line 151, in on_data

    self._on_change_message(data, unique_id)

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\listener.py", line 194, in _on_change_message

    self.stream.on_update(data)

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\stream.py", line 73, in on_update

    img = self._process(data[self._lookup], publish_time)

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\stream.py", line 209, in _process

    order_book_cache.update_cache(order_book, publish_time)

  File "C:\anaconda3\lib\site-packages\betfairlightweight\streaming\cache.py", line 587, in update_cache

    runner.matched_backs.update(order_changes["mb"])

TypeError: update() missing 1 required positional argument: 'active'

[&lt;CurrentOrders&gt;]

---

## 2021-12-26 22:21:08 - issues channel

**Jimmy**

Getting this in the logs _sometimes_.



```{"asctime": "2021-12-26 12:21:57,626", "levelname": "CRITICAL", "message": "'NoneType' object has no attribute 'profit' exception raised in 'NoneType' object has no attribute 'profit'", "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/flumine/controls/loggingcontrols.py\", line 34, in run\n    self.process_event(event)\n  File \"/usr/local/lib/python3.8/dist-packages/flumine/controls/loggingcontrols.py\", line 65, in process_event\n    self._process_cleared_orders_meta(event)\n  File \"/home/strategies/loggingcontrol.py\", line 14, in _process_cleared_orders_meta\n    mydb.insert_cleared_order(order.bet_id, order.trade.strategy, order.market_id, order.selection_id, order.trade.id, order.responses.date_time_placed, order.order_type.price, order.average_price_matched, order.order_type.size, order.size_matched, order.cleared_order.profit, order.side, order.elapsed_seconds_executable, order.status.value, order.trade.market_notes, order.trade.notes_str, order.notes_str, False)\nAttributeError: 'NoneType' object has no attribute 'profit'", "event": "&lt;CLEARED_ORDERS_META [LOGGING]&gt;"}```

---

## 2021-12-26 20:37:46 - general channel

**S G**

Based on the below link,

[https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1635427333064000?thread_ts=1635415964.059500&amp;cid=C4HL6EZTQ](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1635427333064000?thread_ts=1635415964.059500&amp;cid=C4HL6EZTQ)



I tried to create the below strategy, but failed. Any ideas?

```strategy = MarketRecorder(

    name=recorder_name,

    market_filter=[

        streaming_market_filter(

            event_type_ids=[2],

            market_types=["SET_BETTING", "MATCH_ODDS"]

        ),

        streaming_market_filter(

            event_type_ids=[2],

            market_types=["SET_WINNER", "NUMBER_OF_SETS"]

        ),

    ],

    stream_class=DataStream,

    context={

        "local_dir": DATA_DIR_TENNIS,

        "force_update": False,

        "remove_file": True,

        "remove_gz_file": False,

    },

)```

I get the below error:

{"asctime": "2021-12-26 20:26:04,798", "levelname": "ERROR", "message": "DataStream 3001 run error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\sg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flumine\\streams\\datastream.py\", line 143, in run\n    self._stream.start()\n  File \"C:\\Users\\sg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 60, in start\n    self._read_loop()\n  File \"C:\\Users\\sg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 212, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"C:\\Users\\sg\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 242, in _receive_all\n    raise SocketError(\nbetfairlightweight.exceptions.SocketError: [Connect: 3002]: Connection closed by server"}

{"asctime": "2021-12-26 20:26:06,813", "levelname": "INFO", "message": "Starting DataStream 3001", "stream_id": 3001, "market_filter": {"eventTypeIds": [2], "marketTypes": ["SET_WINNER", "NUMBER_OF_SETS"]}, "market_data_filter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "conflate_ms": null}

---

## 2021-12-24 05:41:39 - issues channel

**Unknown**

Recently I've started getting the same error. When I run the model in debug the errorenous unrounded amount is even showing up in the betfair message.

---

## 2021-12-22 23:04:14 - random channel

**Jonjonjon**

[@U4H19D1D2](@U4H19D1D2) I'm looking at transactions again, using something like:



`with market.transaction() as t:`

    `t.place_order(order1)`

    `t.place_order(order2)`



Is there a way to get the full transaction to fail if either `order1` or `order 2` fails to validate? From what I know, Betfair will fail both orders if either of them is invalid (please correct me if I'm wrong!). However (and perhaps I'm not using it properly), I am seeing one of the orders being matched (in a backtest) if the other fails.



As a hack, I am using this code but it feels like a bit of an abomination:



```                        with market.transaction() as t:

                            all_valid = all(

                                t._validate_controls(order, OrderPackageType.PLACE)

                                for order in entry_trade.orders

                            )

                            if all_valid:

                                if runner_context.live_trade_count+len(entry_trade.orders)&lt;self.max_live_trade_count:

                                    for order in entry_trade.orders:

                                        t.place_order(order)

                                else:

                                    logger.error('This would invalidate the max trade count')```

---

## 2021-12-22 19:42:41 - issues channel

**Paul**

Dumb question. Am I safe to assume if I'm seeing this when trying to use the market recorder example, I'm using a key for which streaming hasn't been enabled?

```ListenerError(self.listener.connection_id, received_data)\nbetfairlightweight.exceptions.ListenerError: connection_id: 206-221221193700-982041, data: {\"op\":\"status\",\"id\":1004,\"statusCode\":\"FAILURE\",\"errorCode\":\"NOT_AUTHORIZED\",\"errorMessage\":\"AppKey is not configured for service\",\"connectionClosed\":true,\"connectionId\":\"206-221221193700-982041\"}"}```



---

## 2021-12-22 10:02:19 - general channel

**liam**

It's a list of python objects, use your debugger  

---

## 2021-12-22 01:47:08 - issues channel

**Unknown**

I run the script for one month block of racing data, therefore error occurs when selection runs more than once for the month. Please see screenshot attached, runner '25754300' ran 3 times, the first run it won, this explains my output of removed runners having simulated_profit.

---

## 2021-12-22 01:46:23 - issues channel

**JFP**

Found the issue, it is not a Flumine one, it is my error in assembly of dataframe. It occurs when adding runner status and bsp from spList.



The spList is created for all runners in def process_closed_market. I have added status and bsp to df based on selection_id match:

```for L in spList:

    df.loc[df['selection_id'] == L[0], 'bsp'] = L[2]

    df.loc[df['selection_id'] == L[0], 'selection_status'] = L[1]```

---

## 2021-12-22 01:42:12 - issues channel

**Unknown**

I run the script for one month block of racing data, therefore error occurs when selection runs more than once for the month. Please see screenshot attached, runner '25754300' ran 3 times, the first run it won, this explains my output of removed runners having simulated_profit.

---

## 2021-12-22 01:41:28 - issues channel

**JFP**

Found the issue, it is error in assembly of dataframe. It occurs when adding runner status and bsp from spList.



The spList is created for all runners in def process_closed_market. I have added status and bsp to df based on selection_id match:

```for L in spList:

    df.loc[df['selection_id'] == L[0], 'bsp'] = L[2]

    df.loc[df['selection_id'] == L[0], 'selection_status'] = L[1]```

---

## 2021-12-21 18:22:29 - issues channel

**Aaron Smith**

(not directly bflw/flumine related): does anyone have a clue why i would be able to download s3objects from local, but running same code on ec2 gives a FileNotFoundError ?

---

## 2021-12-21 09:58:01 - issues channel

**liam**

Probably another bug in flumine :man-facepalming:

---

## 2021-12-21 09:08:40 - issues channel

**mandelbot**

So I'm trying to place a limit back bet to a target payout, but I am getting the following error `"Unknown error __init__() missing 1 required positional argument: 'size' in process_market_book"` my order looks like this :

```order = trade.create_order(

    side="BACK",

    order_type=LimitOrder(price=get_price(runner.ex.available_to_back,0), bet_target_type="BACKERS_PROFIT", bet_target_size=50)

)```

Not sure why I have to give a 'size' if I'm betting to a target payout. The relevant betfair documentation doesn't seem to require a size parameter [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders#placeOrders-BettoPayoutorProfit/Liability](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders#placeOrders-BettoPayoutorProfit/Liability)

---

## 2021-12-21 08:00:08 - issues channel

**liam**

I think you would get an error anyway trying to do that instead of cancel_order with no reduction 

---

## 2021-12-21 07:40:00 - issues channel

**Ruben**

maybe I explained it wrong; so, in the flumine BetfairOrder, order.size_remaining is 0.8799999 instead of 0.88 (which is what the webpage shows as remaining). So when I execute the cancel with size_reduction=0.88, I get the error, since flumine thinks the size remaining is 0.879999

---

## 2021-12-21 07:24:42 - issues channel

**liam**

I’m confused, if the size remaining is 0.88, if you try and reduce it by that you will get an error anyway 

---

## 2021-12-20 22:48:09 - issues channel

**Bradley**

Hacking into Liam's beautiful code and make it print stuff, it now tells me:



betfairlightweight.streaming.betfairstream b'{"op":"status","id":2003,"statusCode":"SUCCESS","connectionClosed":false,"connectionsAvailable":1}\r\n'

betfairlightweight.streaming.betfairstream b'{"op":"status","id":2002,"statusCode":"FAILURE","errorCode":"SUBSCRIPTION_LIMIT_EXCEEDED","errorMessage":"trying to subscribe to 208 markets whereas max allowed number was: 200","connectionClosed":false,"connectionId":"207-201221224727-809762"}\r\n'

---

## 2021-12-20 20:45:54 - issues channel

**Ruben**

I think so as well, no real way to fix it

---

## 2021-12-20 20:38:59 - issues channel

**Aaron Smith**

the rounding error you are seeing probably has nothing to do with flumine either, but with float types in python in general. You can read up on floating point arithmetic for more about this (i myself didnt bother though :smile: )

---

## 2021-12-20 20:33:42 - issues channel

**Aaron Smith**

i wouldnt worry much about it. Given how many ppl use flumine without having any issue with this, i d assume there wont be any. If there are, you can always create an issue on github and liam will probably be happy to fix it

---

## 2021-12-20 19:22:17 - issues channel

**Ruben**

I am getting a flumine error when trying to reduce the size of an order. The available size is 0.88 (verified on the webpage), but internally, flumine thinks it is 0.879999999..... and hence throws the "Size reduction too large!" error when trying to reduce the size by 0.88. Is there any way to avoid these numerical issues?

---

## 2021-12-20 11:47:06 - random channel

**charlie_v**

Can't this be the one exception...

---

## 2021-12-20 10:21:34 - issues channel

**Martin Chambers**

Hi all,  Just working the examples given and am having an issues placing a bet.  Am getting the error code below.



Error: {'code': -32602, 'message': 'DSC-0018'}



Any ideas from the code below what I am not doing right?  Appreciate the help.



```# update for test

market_id = "1.192536055"

selection_id = 14884478



def place_order():

    # placing an order

    limit_order = filters.limit_order(size=2.00, price=5.00, persistence_type="LAPSE")

    instruction = filters.place_instruction(

        selection_id=selection_id,

        handicap=0,

        side="WIN",

        order_type="LIMIT",

        limit_order=limit_order,

    )

    place_orders = trading.betting.place_orders(

        market_id=market_id, instructions=[instruction]  # list

    )



    print(place_orders.status)

    for order in place_orders.place_instruction_reports:

        print(

            "Status: %s, BetId: %s, Average Price Matched: %s "

            % (order.status, order.bet_id, order.average_price_matched)

        )



place_order()```

---

## 2021-12-19 10:31:46 - random channel

**Ruben**

cool, thanks liam. Ideally I'd be able to point it to the log file that flumine generates and use that to monitor types of errors and stuff. will look into it

---

## 2021-12-19 08:27:52 - general channel

**liam**

Remove the retry decorator and the error should raise 

---

## 2021-12-19 03:07:40 - general channel

**Zach Godsell**

When using the streaming error handling that is provided in the examples. My stream only provides the following and never retrieves any market data. I feel like I am missing something simple.



`INFO:__main__:Starting MarketStreaming`

`INFO:__main__:Starting MarketStreaming`

`INFO:__main__:Starting MarketStreaming`

`INFO:__main__:Starting MarketStreaming`

`INFO:__main__:Starting MarketStreaming`

---

## 2021-12-17 22:40:22 - issues channel

**thambie1**

I've accidentally done it, you get an error message that clearly tells you that the connection is being refused due to location

---

## 2021-12-17 22:36:55 - issues channel

**birchy**

[@UBS7QANF3](@UBS7QANF3), I presume that if you try to connect from a banned country, that Betfair allow a connection but throw back an error message?

---

## 2021-12-17 21:24:12 - issues channel

**Bradley**

Good evening. I is new to this and am is having issue with running this most excellent code. Please could you suggest what I should do to make this function?



`Traceback (most recent call last):`

  `File "/home/xxxx/PycharmProjects/flumine_client/venv/lib/python3.8/site-packages/flumine/streams/marketstream.py", line 44, in run`

    `self._stream.start()`

  `File "/home/xxxx/PycharmProjects/flumine_client/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 60, in start`

    `self._read_loop()`

  `File "/home/xxxx/PycharmProjects/flumine_client/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 207, in _read_loop`

    `received_data_raw = self._receive_all()`

  `File "/home/xxxx/PycharmProjects/flumine_client/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 229, in _receive_all`

    `raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))`

`betfairlightweight.exceptions.SocketError: [Connect: 2009]: Socket The read operation timed out`

---

## 2021-12-16 21:43:31 - issues channel

**Jonjonjon**

Is there anything obviously wrong with this market filter? When I use it, I get back markets with country code GB, and marketTypeCode WIN. I'm aware that this is probably a user error, but I can't work out what my error is:



`{'eventTypeIds': [7], 'marketCountries': ['AU', 'NZ'], 'marketTypeCodes': ['PLACE']}`

---

## 2021-12-16 12:44:02 - general channel

**Peter**

I thought "that can't be too difficult" then took a look at the now very old script I have running as a daily cron job to do it. Hmmmm.



I'll stick it up here in case it helps. Ignore references to workspaces and the database stuff that uses my custom helper. Also my "trading" == your "client". Hope it helps ...



```import os

import sys

import json

import betfairlightweight

from datetime import datetime, timedelta

from helpers.DatabaseHelpers import database



WORKSPACE_PREFIX = os.getenv("WORKSPACE_PREFIX")

DATABASE_TABLE = "betfair_statement_lines"

SQL = """

    INSERT INTO {}

    (refId, amount, avgPrice, betSize, betType, betCategoryType, commissionRate, eventId, eventTypeId, fullMarketName, grossBetAmount, marketName, marketType, placedDate,

     selectionId, selectionName, handicap, startDate, transactionType, transactionId, winLose, deadHeatPriceDivisor, avgPriceRaw)

    VALUES ({})

""".format(DATABASE_TABLE, ('%s,' * 23)[:-1])



def processing_date():

    if len(sys.argv) &gt; 1:

        return sys.argv[1]

    else:

        return str(datetime.today() - timedelta(days=1))[:10] # returns date as a string without time



def download_account_statement(date_str):

    db = database()

    existing_lines = db.fetch_all('SELECT refId, winLose FROM {} where left(placedDate, 10) = "{}"'.format(DATABASE_TABLE, date_str))

    process = True

    from_record = 0

    while process:

        print(date_str, from_record, "-", from_record + 99)

        start_time = date_str + "T00:00:00Z"

        end_time = date_str + "T23:59:59Z"

        time_range = betfairlightweight.filters.time_range(from_=start_time, to=end_time)

        ast = trading.account.get_account_statement(

            from_record=from_record,

            item_date_range=time_range,

            include_item="ALL",

        )

        txns = []

        for a in ast.account_statement:

            line = json.loads(a.item_class_data["unknownStatementItem"])

            if (int(a.ref_id), line["winLose"]) not in existing_lines:

                txns.append(list({**{"refId": a.ref_id, "amount": a.amount}, **line}.values()))

        result = db.execute_many(SQL, txns)

        if result: print(result)

        from_record += 100

        process = ast.more_available

    db.close()



trading = betfairlightweight.APIClient(os.getenv("BETFAIR_USERNAME"), os.getenv("BETFAIR_PASSWORD"), app_key=os.getenv("BETFAIR_LIVE_KEY"), certs=WORKSPACE_PREFIX + "certs")

trading.login()



download_account_statement(processing_date())```

---

## 2021-12-15 22:40:04 - issues channel

**KG**

[!here](!here) *outage notification* :rotating_light: related to yesterday’s unplanned outage, there will be two planned *one minute outages* this morning; during each minute any bets placed will return errors, so please be aware that this might be a test of your error handling! apologies for this, hopefully the bad run finishes soon! :confounded:



*the two one minute outages will happen between 6:45 - 7:45 BST Thursday, 16 December* 

---

## 2021-12-15 22:18:48 - random channel

**John**

Yeah, this is a brilliant podcast! Got me interested in cyber warfair. And I ended up with this one lately [https://www.amazon.co.uk/This-They-Tell-World-Ends/dp/B08WBSNV1R/ref=sr_1_1?crid=1O49TOE6LGL7N&amp;keywords=this+is+how+they+tell+me+the+world+ends&amp;qid=1639606533&amp;sprefix=this+is+how%2Caps%2C732&amp;sr=8-1|https://www.amazon.co.uk/This-They-Tell-World-Ends/dp/B08WBSNV1R/ref=sr_1_1?crid=1O49[…]d+ends&amp;qid=1639606533&amp;sprefix=this+is+how%2Caps%2C732&amp;sr=8-1](https://www.amazon.co.uk/This-They-Tell-World-Ends/dp/B08WBSNV1R/ref=sr_1_1?crid=1O49TOE6LGL7N&amp;keywords=this+is+how+they+tell+me+the+world+ends&amp;qid=1639606533&amp;sprefix=this+is+how%2Caps%2C732&amp;sr=8-1|https://www.amazon.co.uk/This-They-Tell-World-Ends/dp/B08WBSNV1R/ref=sr_1_1?crid=1O49[…]d+ends&amp;qid=1639606533&amp;sprefix=this+is+how%2Caps%2C732&amp;sr=8-1)

---

## 2021-12-15 12:10:16 - general channel

**D C**

GPS was kicking up around 1130 but thought it was fixed. I suppose its been a while since the last cockup.

---

## 2021-12-15 12:09:28 - general channel

**liam**

Yep lots of errors 

---

## 2021-12-15 09:35:03 - general channel

**Oliver Varney**

[https://www.jetbrains.com/help/pycharm/remote-debugging-with-product.html](https://www.jetbrains.com/help/pycharm/remote-debugging-with-product.html)

---

## 2021-12-15 09:33:58 - general channel

**Oliver Varney**

I think they have remote debugging if thats what you mean

---

## 2021-12-15 08:54:40 - general channel

**liam**

Found the [https://github.com/liampauling/flumine/pull/539/commits/9d41d1486bd22cb7d80317774a88efa0ecd279b8|bug](https://github.com/liampauling/flumine/pull/539/commits/9d41d1486bd22cb7d80317774a88efa0ecd279b8|bug), simulation code wasn't executing when a cancel/update/replace was in flight, looks like its been here since the beginning :man-facepalming:



Resorted to going through order by order in excel to find this..

---

## 2021-12-14 10:40:12 - general channel

**Oliver Varney**

May be worth just spending 1-2 hours watching a few tutorials on how to set up python, setting up an IDE and debugging, and python basics. Then try to get one of the examples going and come back with specific questions at that point.

---

## 2021-12-14 10:38:28 - general channel

**Oliver Varney**

I think your fine on the install as its likely that you would of got an import error. As liam mentioned it probably just ran the code and exited but as it was doing nothing, nothing happened.

---

## 2021-12-14 10:30:01 - general channel

**Oliver Varney**

do you have any logs / error messages you can share ?

---

## 2021-12-13 00:48:40 - general channel

**Martin Chambers**

I can see some data being stored in my tmp file now, (and no errors in Visual Studio - so I must be underway!  Will take some time now and see if I can get a simple strategy working.  Appreciate your help guys, awesome!

---

## 2021-12-12 20:35:23 - general channel

**liam**

Anyone else getting a lot of connection errors?

---

## 2021-12-12 07:15:07 - random channel

**Peter**

How did you manage that without getting a subscription limit exceeded error?

---

## 2021-12-12 00:42:04 - general channel

**Martin Chambers**

[@U016TGY3676](@U016TGY3676) OK, thanks for that Birchy.  Having some success, but looks like I need to have certs installed (was trying to do it without it to get rolling.  The error message is: Exception: [WinError 3] The system cannot find the path specified: '/certs/'

---

## 2021-12-11 16:17:04 - random channel

**birchy**

Anyone here ever been locked out of an AWS VPS instance? In my case, it's a Lightsail instance, which is basically an idiot's version of EC2. Can't login via SSH from any of my machines OR from the AWS management web page/console. Tried to reboot from AWS console but it failed. Ended up having to "stop" the instance from AWS but that also hung for a good 10+ minutes. Have been using this server for 6+ months and not had anything like it happen before.

---

## 2021-12-08 03:02:19 - issues channel

**Tom**

yep that looks to have completely fixed it. Thanks heaps liam

---

## 2021-12-07 21:06:50 - general channel

**birchy**

Bugger, I have a strategy leak. Was wondering why my bets were arriving at slightly different times. So something like this:

```for runner in market_book.runners:

    atb = get_price(runner.ex.available_to_back, 0)

    trade = Trade(

        market_book.market_id,

        runner.selection_id,

        runner.handicap,

        self,

    )

    # create order

    order = trade.create_order(

        side="BACK",

        order_type=LimitOrder(atb, self.context["stake"]),

    )

    # place order for execution

    market.place_order(order)```

Should be done like this instead....???

```with market.transaction() as batch:

    for runner in market_book.runners:

        atb = get_price(runner.ex.available_to_back, 0)

        trade = Trade(

            market_book.market_id,

            runner.selection_id,

            runner.handicap,

            self,

        )

        # create order &amp; add to batch

        order = trade.create_order(

            side="BACK",

            order_type=LimitOrder(atb, self.context["stake"]),

        )

        batch.place_order(order)

    batch.execute()```



---

## 2021-12-07 15:51:58 - general channel

**liam**

open up your debugger and have a look in `market_book.market_definition.runners`

---

## 2021-12-07 15:48:44 - general channel

**Jeff Waters**

I googled Betfair market definitions, and got this page: [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Type+Definitions](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Type+Definitions),



selectionId and runnerName are listed next to one another.



If I write print(runner.selection_id), I get the id of the runner. However, when I write print(runner.runnerName), Pycharm gives me an unresolved attribute error message.



How do I get around this, please?

---

## 2021-12-07 15:10:42 - general channel

**Jeff Waters**

Hi [@UUCD6P13J](@UUCD6P13J)



I've amended my code - line 74 and 75 in [https://github.com/JeffW12345/runbacktests-python-file/blob/main/runbacktests.py](https://github.com/JeffW12345/runbacktests-python-file/blob/main/runbacktests.py).



However, when I run the test print in process_market_book, I get told:



 _AttributeError: 'NoneType' object has no attribute 'runners'"}_



What do you suggest, please?



It is possible that me using multi-processing is what's causing the problem?



Thanks,



Jeff

---

## 2021-12-06 21:14:41 - strategies channel

**liam**

Famous last words, one way ticket to a day wasted debugging :joy:

---

## 2021-12-06 20:24:05 - issues channel

**Newbie99**

This error has come up a few times recently, when the market cleared event is processed:



```

{"asctime": "2021-12-06 14:30:14,617", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/worker.py\", line 234, in _get_cleared_market\n    group_by=\"MARKET\",\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.192009763'], 'customerStrategyRefs': ['ip-172-31-4-105'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-10290844-0055b9d69e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-10290844-0055b9d69e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.192009763'], 'customerStrategyRefs': ['ip-172-31-4-105'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-10290844-0055b9d69e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-10290844-0055b9d69e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

All I'm doing is the following (using the Closed Market Logging example):



```    def _process_cleared_markets(self, event):

        for market in event.event.orders:

            market_id = market.market_id

            file_path = market_closed_report_path + '/' + str(market_id) + '_cleared_market_data.json'

            cleared_market_data = {'market_id': market_id,

                                  'market_profit': market.profit,

                                  'market_com': market.commission

                                 }



            check_and_create_json(file_path, cleared_market_data)```

But the error looks like Flumine is making an incorrectly constructed API call to Betfair if I'm reading that correctly?

---

## 2021-12-06 07:45:41 - issues channel

**birchy**

Bit of a weird problem this morning. Went to restart my marketrecorder that's been running for months and am getting this on startup:

`Traceback (most recent call last):

  File "data_recorder.py", line 118, in &lt;module&gt;

    framework.run()

  File "/home/ubuntu/.local/lib/python3.6/site-packages/flumine/flumine.py", line 29, in run

    self._process_raw_data(event)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/flumine/baseflumine.py", line 203, in _process_raw_data

    strategy.process_raw_data(clk, publish_time, datum)TypeError: process_raw_data() takes 3 positional arguments but 4 were given`

Not on my pc, so unable to debug ATM.

Flumine: 1.20.13

Bflw: 2.15.2

---

## 2021-12-05 22:13:17 - general channel

**Jeff Waters**

Hi [@U4H19D1D2](@U4H19D1D2)



I've tried adding it via process_market_book:



```def process_market_book(self, market, market_book) -&gt; None:

    catalogue = mc.MarketCatalogueMiddleware()

    catalogue.add_market(market)```

However, when I later try to reach the market catalog in my results output method like so, I get told: _AttributeError: 'NoneType' object has no attribute 'runners'_



```for market in framework.markets:

    print(len(market.market_catalogue.runners))```

Am I making any obvious mistakes that are jumping out at you, please?

---

## 2021-12-05 15:56:52 - random channel

**Mo**

Essentially there is a good deal of randomisation. Yes you'll get the benefit of both processes running in parallel but they won't be fixed to a particular vCPU (unless you configure it that way yourself) and the CPUs will be shared with everything else running on the machine

---

## 2021-12-03 10:51:26 - issues channel

**liam**

I also added a regression by mistake on the validation, 1.20.13 will fix this

---

## 2021-12-02 05:48:22 - general channel

**ThomasJ**

[@U4H19D1D2](@U4H19D1D2) In `simulated.py &gt;  _def_ _calculate_process_traded` would you please explain the reason for the 'divide by 2' in the 1st line of the method.



`_def_ _calculate_process_traded(_self_, _publish_time_: int, _traded_size_: float) -&gt; None:`

`        _traded_size_ = _traded_size_ / 2`

        `if _self_._piq - _traded_size_ &lt; 0:`

            `size = _traded_size_ - _self_._piq`

            `size = round(min(_self_.size_remaining, size), 2)`

            `if size:`

`                _self_._update_matched(`

                    `[`

`                        _publish_time_,`

`                        _self_.order.order_type.price,`

                        `size,`

                    `]  # todo takes the worst price, i.e what was asked`

                `)`

`            _self_._piq = 0`

        `else:`

`            _self_._piq -= _traded_size_`

            `if logger.isEnabledFor(logging.DEBUG):`

                `logger.debug(`

                    `"Simulated order {0} PIQ: {1}".format(_self_.order.id, _self_._piq)`

                `)`

---

## 2021-12-01 16:28:39 - random channel

**Newbie99**

Sort of on this subject, there are some scenarios that come up and I'm curious how other people go about this:



1. Orders don't appear to settle properly at market level. So this appears to result in the orders settling correctly at bet level when the market closes, but when calling listClearedOrders at the market level it doesn't exist (this normally appears to get fixed after a couple of days, but it occasionally does drag on longer).

2. A market gets settled, all appears to be correct, but then Betfair re-settle at a later date.

Both are fairly uncommon, but do occur occasionally, I'm just wondering if there is any way to detect if a market is re-settled, or is it simply a case of calling listClearedOrders periodically and doing a lookback (and presumably taking settled bets with the most recently settled time if a bet with the same id already exists in my DB)?



I'm guessing it is the latter, but just wanted to be sure.

---

## 2021-11-30 22:06:40 - general channel

**PeterLe**

Hi [@U013K4VNB6D](@U013K4VNB6D) here is one of mine:

# My Betfair File Scraper



import wget

import traceback

from urllib.error import HTTPError

from os import path, mkdir, remove

from datetime import datetime, timedelta

import shutil

import os



# If set to True, it will re-download and overwrite existing files

OVERWRITE = False



DATE_INPUT_FORMAT = '%d/%m/%Y'



URL = '[https://promo.betfair.com/betfairsp/prices/](https://promo.betfair.com/betfairsp/prices/)'



SP_DATA_PATH = r'A:\Users\User-1\Data\BetfairSPData'



GREYHOUND_FOLDER = 'Greyhound'

HORSERACING_FOLDER = 'Horseracing'



PREFIX_LOCATION_MAP = {'dwbfgreyhoundplace': path.join(GREYHOUND_FOLDER, 'Greyhound_Place'),

'dwbfgreyhoundwin': path.join(GREYHOUND_FOLDER, 'Greyhound_Win'),

'dwbfpricesireplace': path.join(HORSERACING_FOLDER, 'IREHorseRacing_Place'),

'dwbfpricesirewin': path.join(HORSERACING_FOLDER, 'IREHorseRacing_Win'),

'dwbfpricesukwin': path.join(HORSERACING_FOLDER, 'UKHorseRacing_Win'),

'dwbfpricesukplace': path.join(HORSERACING_FOLDER, 'UKHorseRacing_Place')}



TEMP_FOLDER = 'Temp'



if __name__ == '__main__':



# Check if target folders exist and make sure temp folders are emptied



folders = list(PREFIX_LOCATION_MAP.values())

temp_folders = [path.join(x, TEMP_FOLDER) for x in folders]



for location in [GREYHOUND_FOLDER, HORSERACING_FOLDER] + folders + temp_folders:

folder_path = path.join(SP_DATA_PATH, location)

if location in temp_folders:

try:

shutil.rmtree(folder_path)

except FileNotFoundError:

pass

if not path.exists(folder_path):

mkdir(folder_path)



# Get date input



dt_start = dt_end = None



while dt_start is None:

try:

date_input = input('Please enter the start date of the Files you want to download: ').strip()

dt_start = datetime.strptime(date_input, DATE_INPUT_FORMAT)

except ValueError:

print('Could not parse the date.')



while dt_end is None:

try:

date_input = input('Please enter the end date of the Files you want to download: ').strip()

dt_end = datetime.strptime(date_input, DATE_INPUT_FORMAT)

except ValueError:

print('Could not parse the date.')



# Generate a range of dates



dates = [dt_start + timedelta(days=x) for x in range((dt_end - dt_start).days + 1)]



# Download files to temp folders



for date in dates:

date_str = datetime.strftime(date, '%d%m%Y')



for prefix in PREFIX_LOCATION_MAP:

try:

filename = '{}{}.csv'.format(prefix, date_str)

print(filename)

destination = path.join(SP_DATA_PATH, PREFIX_LOCATION_MAP[prefix], TEMP_FOLDER, filename)



if path.exists(destination):

if OVERWRITE:

remove(destination)

else:

continue



wget.download(URL + filename, destination, )

except HTTPError as http_error:

print('HTTP Error:', http_error.code)

except:

print(traceback.format_exc())



# Concatenate files



for prefix in PREFIX_LOCATION_MAP:

filename = '{}{}-{}.csv'.format(prefix,

datetime.strftime(dt_start, '%d%m%Y'),

datetime.strftime(dt_end, '%d%m%Y'))

file_path = path.join(SP_DATA_PATH, PREFIX_LOCATION_MAP[prefix], filename)



with open(file_path, 'w') as destination:

folder_path = os.path.join(SP_DATA_PATH, PREFIX_LOCATION_MAP[prefix], TEMP_FOLDER)

start = 0

for name in os.listdir(folder_path):

with open(os.path.join(folder_path, name)) as source:

lines = source.readlines()

# Column names should be added just once

destination.writelines(lines[start:])

start = 1

shutil.rmtree(folder_path)

---

## 2021-11-30 21:36:22 - issues channel

**liam**

First try rotating, do you get a network spike or drop during the time of the errors?

---

## 2021-11-30 12:15:55 - issues channel

**C0rnyFlak3s**

Has anyone experienced issues with purchasing data from betfair so far? I am currently running into a problem where on the last step (confirming the purchase) I get an error code: 0x05479P . Unfortunately the support response either doesn’t help or is slow to begin with. They for now just told me to clear the cache and cookies, but without success. Any ideas? :slightly_smiling_face:

---

## 2021-11-29 21:11:47 - issues channel

**Martin Karlsson**

The EOF error suddenly occured when the bot tried to cancel an order. Before that, the same type of action had been performed multiple times flawlessly and I can’t figure out what was different this time.

---

## 2021-11-29 21:07:50 - issues channel

**Martin Karlsson**

But I did encounter a new error that I have not noticed before:



ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:1129)



For some reason this particular error broke the error handling and did not lead to a reconnect.



I searched for the error here on Slack and it seems like more people have encountered it but I could not find any solution?



By the way: I really appreciate your work with Betfairlightweight!

---

## 2021-11-29 20:57:26 - issues channel

**Martin Karlsson**

The error handling is done in MyMarketStreaming() and MyOrderStreaming(). These two classes are variants of the example in [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py |examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py |examplestreamingerrhandling.py).



I have been running it for a day now and it seems to be working as I hoped. One typical error occured in market streaming (read time out) and the connection retried and successfully reconnected.

---

## 2021-11-28 17:57:41 - issues channel

**liam**

Yep that will work but you have no error handling and fairly sure .start is blocking from memory 

---

## 2021-11-27 23:15:41 - issues channel

**Martin Karlsson**

How do I stream both order and market updates at the same time?



I've tried to modify the example in [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py) but I'm too much of a novice to get it right... =(



My approach has been to create two separate Streaming classes like the one in the above example – one for markets and one for orders. These classes share the same output_queue.



I then check if the output received is of instance MarketBook or CurrentOrders to separate the workflow.



```# Getting market stream

market_streamer = MyMarketStreamer(

  client=self.connection.trading,

  cm_queue=cm_queue,

  market_filter=market_filter,

  market_data_filter=market_data_filter,

)



# Getting order stream

order_streamer = MyOrderStreamer(

  client=self.connection.trading,

  cm_queue=cm_queue,

)



# Starting the streams

market_streamer.start()

order_streamer.start()



# Receiving the stream

while True:

   outputs = cm_queue.get()



   for output in outputs:

      if isinstance(output, MarketBook):

         self.handle_market_changes(mcm=output.streaming_update)

      elif isinstance(output, CurrentOrders):

         self.handle_order_changes(ocm=output.streaming_update)```

This seems to be working just fine except for when it comes to the error handling: then it just stops without retrying.



Maybe this should be done in a completely different manner?



Any help would be greatly appreciated!

---

## 2021-11-27 15:50:17 - issues channel

**mandelbot**

I am trying to open a new connection but keep getting "MAX_CONNECTION_LIMIT_EXCEEDED" errors. I only have two instances of flumine running and 1 connection via website. What could be causing this issue?

---

## 2021-11-27 13:44:41 - general channel

**mon mon**

That's true - the issue is that I'm hitting the 200 subscription limit.

Looking back through old posts the common fix seems to be 'ask BF for more' !

---

## 2021-11-26 19:31:02 - general channel

**Peter**

“Sports betting is a game where finding edges is fairly easy but _getting matched_ for sizable sums is near impossible”



This is exactly the problem and why sports hedge funds don’t work. Capital isn’t the problem, deploying it is.



I’ve almost lost count of the number of firms that have started and failed in similar manners. In aggregate they have lost millions.



I really wish the markets were ten times bigger, but they are not. So I’ve never felt the need to raise capital and neither has any other successful trader I’ve met.



It’s a self defeating proposition in my mind. You give away an edge and get a fraction of the return in lieu of using money you don’t need.

---

## 2021-11-26 17:36:47 - issues channel

**Aaron Smith**

on aws i get:

url: (58) could not load PEM client certificate, OpenSSL error error:140AB18E:SSL routines:SSL_CTX_use_certificate:ca md too weak, (no key found, wrong pass phrase, or wrong file format?)

---

## 2021-11-26 17:22:14 - issues channel

**Aaron Smith**

yeah, i wanted to check the return value, but shouldnt the error still show for the client.login() or does it not because its in an try/except?

---

## 2021-11-26 17:21:01 - issues channel

**Mo**

It's going to be more useful than some Python code where you discard both the return value and the exception...

---

## 2021-11-26 17:18:41 - issues channel

**Aaron Smith**

```def get_betfair_client():

    client = betfairlightweight.APIClient(BETFAIR_USER_EMAIL,

                                           BETFAIR_PASSWORD,

                                           app_key=BETFAIR_APP_KEY,

                                           cert_files=CERT_PATHS,

                                           lightweight=False)

        client.login()

    except:

        try:

            time.sleep(1)

            client.login()

        except:

            try:

                time.sleep(1)

                client.login()

            except:

                logging.warning('log in failed')

                return

            

    return client



client = get_betfair_client()

assert client```

---

## 2021-11-26 17:04:34 - issues channel

**Aaron Smith**

[@U016TGY3676](@U016TGY3676) did you get any error msg when your certs expired?

---

## 2021-11-26 17:01:54 - issues channel

**birchy**

[@U01DVUAE2G1](@U01DVUAE2G1) presuming you haven't changed the login code, SSL paths, etc it _might_ be that your certs have expired at Betfair's end. I had to rebuild &amp; reload mine earlier this year.

For debugging, if using pycharm, you can set a breakpoint and step into the Flumine code to follow the rabbit hole. :rabbit:

---

## 2021-11-26 16:57:57 - issues channel

**Aaron Smith**

I am using certs to log in, i dont get any error message, even though it looks like i should.

---

## 2021-11-26 16:00:49 - issues channel

**Aaron Smith**

I ve been reconstructing some things and have been offline for a few days. Now i tried to get things running again, but the log in fails. Its the same code as before. How would i go about debugging this?

---

## 2021-11-26 11:23:32 - random channel

**Mo**

I've been having that error for months if not years but haven't investigated

---

## 2021-11-24 23:20:37 - general channel

**thambie1**

When debugging a historic market, occasionally I'd like to watch footage of the match and line it up with the market movements. Anyone have a suggestion on where to get such footage for football matches?

---

## 2021-11-24 13:26:02 - general channel

**mon mon**

I seem to have the same issue with backtest_multi.py example that few others have mentioned, in that I get a "UnicodeDecodeError: 'utf-8' codec can't decode byte......"  error, even though the example uses smart_open.

Has anyone pinned down a solution to this? It works fine if I'm doing a standard (not 'multi') backtest.

---

## 2021-11-23 20:27:49 - issues channel

**AP**

If anyone is interested, changing this:



```with futures.ProcessPoolExecutor(max_workers=48) as pool:

        all_futures = [

            pool.submit(

                run_backtest,

                market=market

            )

            for market in markets

        ]



    for i, future in enumerate(futures.as_completed(all_futures)):

        try:

            print('Future %i of %i completed' % (i + 1, len(all_futures)))

        except:

            print('Error %i of %i' % (i + 1, len(all_futures)))```

---

## 2021-11-23 07:03:51 - issues channel

**mandelbot**

So it seems MarketOnCloseOrders aren't being cleared properly on flumine because no price

`{"asctime": "2021-11-23 06:57:50,183", "levelname": "ERROR", "message": "_process_cleared_orders_meta: 'MarketOnCloseOrder' object has no attribute 'price'", "order": "Order 251408671038: Execution complete", "error": "'MarketOnCloseOrder' object has no attribute 'price'"}`

Maybe this is why they aren't making it to the logging control?

---

## 2021-11-22 21:29:05 - issues channel

**AP**

```import smart_open

import os

import time

import logging

from unittest.mock import patch

from concurrent import futures

from pythonjsonlogger import jsonlogger

from flumine import FlumineBacktest, clients



from inplay_bot.backtest.strategies.data_collection import DataCollectWOM

from inplay_bot.backtest import MARKET_IDS



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))





def run_backtest(market):

    client = clients.BacktestClient()

    client.min_bet_validation = False

    framework = FlumineBacktest(client=client)



    strategy = DataCollectWOM(

            market_filter={

                "markets": [market],

                "listener_kwargs": {

                    "seconds_to_start": 600,

                    "calculate_market_tv": True,

                    "cumulative_runner_tv": True,

                },

            },

            context={

                "update_seconds": 5,

            }

    )



    framework.add_strategy(strategy)



    with patch("builtins.open", smart_open.open):

        framework.run()





if __name__ == "__main__":

    path = "/home/antonypapadimitriou/betfair"

    markets = []

    win_market_ids = MARKET_IDS



    for root, dirs, files in os.walk(path):

        for file in files:

            if file.split(".bz2")[0] in win_market_ids:

                markets.append(os.path.join(root, file))



    with futures.ProcessPoolExecutor(max_workers=48) as pool:

        all_futures = [

            pool.submit(

                run_backtest,

                market=market

            )

            for market in markets

        ]



    for i, future in enumerate(futures.as_completed(all_futures)):

        try:

            print('Future %i of %i completed' % (i + 1, len(all_futures)))

        except:

            print('Error %i of %i' % (i + 1, len(all_futures)))```

---

## 2021-11-22 21:28:27 - issues channel

**AP**

Here are some logs, there are no errors:

```{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding market middleware &lt;flumine.markets.middleware.SimulatedMiddleware object at 0x7f81a8794640&gt;"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding market middleware &lt;flumine.markets.middleware.SimulatedMiddleware object at 0x7f81a8794730&gt;"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding market middleware &lt;flumine.markets.middleware.SimulatedMiddleware object at 0x7f81a8794820&gt;"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}

{"asctime": "2021-11-22 21:27:56,178", "levelname": "INFO", "message": "Adding client control MAX_TRANSACTION_COUNT"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control ORDER_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding strategy DataCollectWOM"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control MARKET_VALIDATION"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}

{"asctime": "2021-11-22 21:27:56,179", "levelname": "INFO", "message": "Adding trading control STRATEGY_EXPOSURE"}```

---

## 2021-11-22 21:26:48 - issues channel

**AP**

```import csv

import logging

import os

from flumine.strategy.strategy import BaseStrategy

from flumine.utils import get_sp, get_price

from inplay_bot.util import calculate_vwap_runner_book



logger = logging.getLogger(__name__)



FIELDNAMES = [

    "publish_time",

    "market_id",

    "market_venue",

    "market_name",

    "market_seconds_to_start",

    "market_total_matched",

    "active_runners",

    "selection_id",

    "selection_back",

    "selection_lay",

    "selection_wom_one",

    "selection_wom_two",

    "selection_wom_three",

    "selection_vwap",

    "selection_ltp",

    "selection_total_matched",

    "selection_status",

    "selection_actual_sp",

]





class DataCollectWOM(BaseStrategy):

    """

    Collect market/runner data every

    x update_seconds.

    """



    def __init__(self, *args, **kwargs):

        BaseStrategy.__init__(self, *args, **kwargs)

        self.local_dir = "/home/antonypapadimitriou/betfair_data_collection"



    def add(self) -&gt; None:

        self.context["_data"] = []

        self.context["pt"] = 0

        # check local dir

        if not os.path.isdir(self.local_dir):

            raise OSError("File dir %s does not exist" % self.local_dir)



    def check_market_book(self, market, market_book) -&gt; bool:

        if market_book.status != "OPEN":

            return False

        if market_book.inplay:

            return False

        if "data" not in market.context:

            market.context["data"] = {}

        # check update seconds

        update_seconds = self.context["update_seconds"]

        pt = self.context["pt"]

        if market_book.publish_time_epoch - pt &gt; (update_seconds * 1000):

            self.context["pt"] = market_book.publish_time_epoch

            return True

        return False



    def process_market_book(self, market, market_book) -&gt; None:

        for runner in market_book.runners:

            if runner.status == "ACTIVE":

                # get prices

                back, lay = self._get_back_lay(runner)

                # calculate WOM

                wom_one = self._calculate_wom(runner, 1)

                wom_two = self._calculate_wom(runner, 2)

                wom_three = self._calculate_wom(runner, 3)

                # calculate VWAP

                vwap = calculate_vwap_runner_book(runner.ex.traded_volume)

                # store data in context

                data = {

                    "publish_time": market_book.publish_time,

                    # market

                    "market_id": market.market_id,

                    "market_venue": market_book.market_definition.venue,

                    "market_name": market_book.market_definition.name,

                    "market_seconds_to_start": market.seconds_to_start,

                    "market_total_matched": market_book.total_matched,

                    "active_runners": market_book.market_definition.number_of_active_runners,

                    # selection

                    "selection_id": runner.selection_id,

                    # current state

                    "selection_back": back,

                    "selection_lay": lay,

                    "selection_wom_one": wom_one,

                    "selection_wom_two": wom_two,

                    "selection_wom_three": wom_three,

                    "selection_vwap": vwap,

                    "selection_ltp": runner.last_price_traded,

                    "selection_total_matched": runner.total_matched,

                    # after

                    "selection_status": None,

                    "selection_actual_sp": None,

                }

                self.context["_data"].append(data)



    def process_closed_market(self, market, market_book):

        # get runner status (status and BSP)

        status = {}

        for runner in market_book.runners:

            status[runner.selection_id] = (runner.status, get_sp(runner))

        # write data to csv

        filename = os.path.join(self.local_dir, f"{market_book.market_id.split('.')[-1]}.csv")

        is_new = not os.path.exists(filename)

        with open(filename, "a", newline="") as f:

            writer = csv.DictWriter(f, delimiter=",", fieldnames=FIELDNAMES)

            if is_new:

                writer.writeheader()

            for d in self.context["_data"]:

                _status = status.get(d["selection_id"])

                d["selection_status"], d["selection_actual_sp"] = _status

                writer.writerow(d)

        self.context["_data"].clear()



    @staticmethod

    def _get_back_lay(runner_book, level: int = 0) -&gt; tuple:

        if runner_book is None:

            return None, None

        back = get_price(runner_book.ex.available_to_back, level)

        lay = get_price(runner_book.ex.available_to_lay, level)

        return back, lay



    @staticmethod

    def _calculate_wom(runner_book, depth: int) -&gt; float:

        total_atb, total_atl = 0, 0

        for i in range(0, depth):

            # back

            p = runner_book.ex.available_to_back[i]

            total_atb += p["size"]

            # lay

            p = runner_book.ex.available_to_lay[i]

            total_atl += p["size"]

        if total_atb + total_atl &gt; 0:

            return round(total_atb / (total_atb + total_atl), 4)

        else:

            return 0```

---

## 2021-11-21 12:45:39 - issues channel

**John**

Also get

```InvalidResponse: Invalid response received: 

&lt;title&gt;ngErrorRedirect&lt;/title&gt;```

Is it related to the purchase of data?

---

## 2021-11-21 12:37:21 - issues channel

**John**

I have narrowed down from March 30 2017 to March 31 2017 and still got the same error

---

## 2021-11-20 23:13:16 - issues channel

**John**

```JSONDecodeError: expected value at line 2 column 1: line 2 column 1 (char 1)```



---

## 2021-11-20 23:12:33 - issues channel

**John**

Hi folks, I am new to this forum. I have an issue very similary to the *[https://app.slack.com/team/U02KWHK2H89|C0rnyFlak3s](https://app.slack.com/team/U02KWHK2H89|C0rnyFlak3s)* one.  However, I use the betfairlightweight library and the code from the examples.  Here is the code snippet and the error I get:

---

## 2021-11-20 09:45:11 - general channel

**James T**

Sorry “doesn’t reflect”. Typo I fixed now. 

---

## 2021-11-16 09:29:50 - general channel

**Newbie99**

Actually that could still produce a TypeError if None

---

## 2021-11-16 09:27:30 - general channel

**Newbie99**

[@U4H19D1D2](@U4H19D1D2) should line 76 in that example be:



1 / get_price(runner.ex.available_to_lay, 0)



rather than:



1 / r.ex.available_to_lay[0]["price"]



As won't the latter produce an Error if there is no price for that runner on the lay side?

---

## 2021-11-15 21:17:39 - issues channel

**C0rnyFlak3s**

I have a problem with the Historical API downloading my historical data. I am communicating via the requests lib in python and commands like ‘GetMyData’ or ‘GetCollectionOptions’ work fine, however once I try to run ‘DownloadListOfFiles’ with my filter as input the API returns with an error which is not specified. I am currently using the Delay Application Key and try to download free historical Data which I already “purchased” (in reality it was a free data set). Any ideas?

---

## 2021-11-15 09:45:41 - general channel

**liam**

ideally but not fixed

---

## 2021-11-12 19:26:17 - issues channel

**Paul**

`Params: {'marketId': '1.190674050', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 20216110, 'side': 'LAY', 'limitOrder': {'price': '23', 'size': '10', 'betTargetType': 'PAYOUT'}}]}` results in:

```Exception: None

Error: {'code': -32099, 'message': 'ANGX-0002', 'data': {'APINGException': {'requestUUID': 'ie2-ang26a-prd-11021016-0015bdce7c', 'errorCode': 'INVALID_INPUT_DATA', 'errorDetails': 'One or more inputs to the operation were invalid'}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0002', 'data': {'APINGException': {'requestUUID': 'ie2-ang26a-prd-11021016-0015bdce7c', 'errorCode': 'INVALID_INPUT_DATA', 'errorDetails': 'One or more inputs to the operation were invalid'}, 'exceptionname': 'APINGException'}}, 'id': 1}```



---

## 2021-11-12 19:25:07 - issues channel

**Paul**

I'm trying to lay to a payout as per [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders#placeOrders-BettoPayoutorProfit/Liability](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/placeOrders#placeOrders-BettoPayoutorProfit/Liability) but getting an error I can't see through

---

## 2021-11-11 16:03:35 - strategies channel

**liam**

I found my UK stuff didn't work out the box also much harder to catch errors/issues due to the market being so illiquid

---

## 2021-11-11 12:59:13 - issues channel

**captainonionhead**

Just to follow up - having restarted, it has just passed the 2 hour mark with no errors yet, so looks like that was the issue.  Thanks again!

---

## 2021-11-11 11:19:22 - issues channel

**liam**

so bumping that should fix it

---

## 2021-11-11 10:24:48 - issues channel

**captainonionhead**

I don't see any error messages from the market streams so it only seems to apply to the market-catalogue polling?

---

## 2021-11-11 10:21:45 - issues channel

**captainonionhead**

This is the first error in the logs and it is a UK account

---

## 2021-11-11 10:19:32 - issues channel

**liam**

you getting any other errors in the logs before this?

---

## 2021-11-11 10:15:00 - issues channel

**captainonionhead**

Morning, I have a market recorder based upon the flumine example.  It keeps receiving `INVALID_SESSION_INFORMATION` errors from the market-catalogue polling thread after it has been running for a while.

Is this expected - do I simply need to catch the exception and login again or is there something more fundamentally wrong with my setup?

Thanks!

---

## 2021-11-10 09:44:57 - general channel

**Newbie99**

My code is correct, its just that there are data limits.



What data do you need for the market_book?



I'll re-do it quickly so it doesn't error, but it won't show you much!

---

## 2021-11-10 04:04:07 - general channel

**VT**

Thanks for the code but it didn't work here, besides being a solution that seems inefficient to me, I still received:



'errorCode': 'TOO_MUCH_DATA'



I would like to list all football games that are in-play, live with the ball in play. I would like to get the ID of these events only.



It would be the same events found on the Betfair website when we click on in-play &gt; football



If anyone can help, I still haven't found a solution.



Thanks

---

## 2021-11-05 22:56:25 - strategies channel

**Adrian**

thanks yeah i've wrapped my head around liam's version of wom. i didnt get that error with mine

---

## 2021-11-05 22:49:15 - strategies channel

**Adrian**

[@U4H19D1D2](@U4H19D1D2)

&gt; {"asctime": "2021-11-05 22:49:00,368", "levelname": "CRITICAL", "message": "Unknown error list index out of range in process_market_book (1.186625686)", "exc_info": "Traceback (most recent call last):\n  File \"/Users/adrian/opt/anaconda3/envs/betfair/lib/python3.8/site-packages/flumine/utils.py\", line 204, in call_strategy_error_handling\n    return func(market, market_book)\n  File \"/Users/adrian/Projects/betfair/code/dataanalysis/flumine-strategy-development-master/strategies/datacollectwom.py\", line 60, in process_market_book\n    wom_one = _calculate_wom(runner, 1)\n  File \"/Users/adrian/Projects/betfair/code/dataanalysis/flumine-strategy-development-master/strategies/datacollectwom.py\", line 115, in _calculate_wom\n    p = runner_book.ex.available_to_lay[i]\nIndexError: list index out of range"}

---

## 2021-11-03 18:56:46 - issues channel

**V**

Remind me what the play is when you hit a SUBSCRIPTION_LIMIT_EXCEEDED error? Email Betfair to have it bumped or add more processes?

---

## 2021-11-03 07:56:18 - issues channel

**Peter C**

Fair enough, thanks Liam. I see the socket errors regularly, but it's unusual for them to appear to lead to max connection errors and require a restart. Seems ok after a restart though

---

## 2021-11-03 07:47:47 - issues channel

**Peter C**

Thanks for checking. I'm getting socket read operation timed out/connection reset by peer which is leading to max connection limit exceeded errors on the market/order stream. Seems ok after a restart, but it's not behaviour I've seen before

---

## 2021-11-03 07:35:11 - issues channel

**Peter C**

Is anyone else getting api errors this morning? I have some errors I don't usually see on one of my connections

---

## 2021-11-02 10:46:09 - betfair-news channel

**Neil T (Betfair)**

HI [@UFTBRB3F1](@UFTBRB3F1) - I have received an update from our Exchange Ops team and although they understand why this would be useful, they have no plans to introduce a direct contact address for customers.  The current process ensures that any contacts regarding errors (etc) are logged and monitored through our CRM system.   If you contact CS Chat via *[https://support.betfair.com/app/home/](https://support.betfair.com/app/home/) &gt; Get In Touch* the team should report any issues directly to the relevant Exchange Ops team.   Also, feel free to contact [mailto:BDP@betfair.com|BDP@betfair.com](mailto:BDP@betfair.com|BDP@betfair.com) (Monday-Friday) if you notice any market-related issues.

---

## 2021-11-01 19:28:07 - strategies channel

**Ruben**

so in the website the lay appears with the same size of the back i placed through the api, but looking at the marketbook in the debugger, the available_to_lay size is smaller than the size of the back I placed

---

## 2021-11-01 10:22:16 - betfair-news channel

**Neil T (Betfair)**

Hi [@U01U24AG35W](@U01U24AG35W) - See the answer from our API dev team -  "_This would be an artefact of settlement kicking off that moves the bets away from trading db into the longer-term store. Any price change notifications triggered during this process will result in attempts to reconstruct the market view based on no bets being available and would result in this kind of notification being sent. There is no straightforward way to suppress this end of market clear-out messages, so not sure yet how to signal this to customers. It can be classified as a bug, but it’s a behaviour that has existed for some time. We'll have  a think about if there is a definitive way to stop this or at least signal it appropriately to customers"_

---

## 2021-10-31 18:55:24 - strategies channel

**Ruben**

nvm, was an issue on my end due to using the debugger

---

## 2021-10-31 18:10:11 - general channel

**liam**

Yeah socket would timeout and raise an error causing the resubscribe 

---

## 2021-10-31 18:00:03 - general channel

**casper**

for example, in the examplestreamingerrhandling.py would this throw BetfairError and attempt to resubscribe using latest clk?

---

## 2021-10-31 17:58:13 - general channel

**casper**

in streaming, if no message of any kind is received (i.e. no data update or ChangeType.Heartbeat messages) for more than heartbeat interval, would an error be raised?

---

## 2021-10-31 09:22:49 - issues channel

**Ruben**

In the documentation, it sais that this error means "Problem parsing the parameters, or a mandatory parameter was not found"

---

## 2021-10-31 09:22:26 - issues channel

**Ruben**

Good morning, whenever I try to place a passive limit order, I am getting the following error `"ERROR": "Execution error": nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0: {'code': -32602, 'message': 'DSC-0018'}`

---

## 2021-10-29 21:45:10 - general channel

**Tom**

Hi Does anyone have the json output of runners? I can't seem to find an example on the repo for getting the odds dict or list.

```@shared_task

def parse_runners(market, items):

    """Parses runners from MarketCatalogue object"""

    runners = []

    for runner_item in items:

        with open('runners.json','w') as outfile:

            json.dumps(items,outfile)

        with open('runners2.json','w') as outfile:

            json.dumps(runner_item,outfile)

        runner, created = Runner.objects.update_or_create(

            selection_id=runner_item['selectionId'],

            defaults={

                'market': market,

                # default

                'name': runner_item['runnerName'].upper(),

                'sort_priority': runner_item['sortPriority'],

                'handicap': runner_item['handicap'],

                'runner_id': runner_item['metadata']['runnerId'],

            }

        )

        if created:

            [http://logger.info|logger.info](http://logger.info|logger.info)(f'Created {runner}')

        else:

            logger.debug(f'Updated {runner}')

        runners.append(runner)

    return runners```

Using the above code I have I can get runner_id's and save to my db.  I can't seem to print the json object and see the response to traverse through. Does anyone have a sample json response of list marketcatalogue so I can see where the odds are hiding?

---

## 2021-10-29 12:07:09 - issues channel

**liam**

Simple fix [https://github.com/liampauling/flumine/pull/520/files](https://github.com/liampauling/flumine/pull/520/files)

---

## 2021-10-28 14:19:34 - issues channel

**liam**

Can you create an issue, I think this could be fixed with a code change in flumine

---

## 2021-10-28 14:09:39 - betfair-news channel

**Neil T (Betfair)**

Hi [@UFTBRB3F1](@UFTBRB3F1) - I've raised this request to the Exchange Ops team and will let you know what can be done here.  It would make sense to offer a no-reply email address so that error notifications can be sent directly to our Ops team

---

## 2021-10-28 11:12:44 - general channel

**EJono**

I've had an increase recently in the number of markets I am able to stream from 200 to 1000 after being advised here to email Betfair for an increase which has helped tremendously with testing out one of my strategies on all football games listed. During the week this is more than enough to cover all market_type=MATCH_ODDS,  event_type_id=1 markets set up in the streaming filter but at the weekend the number of FB matches often goes above this to ~1100-1300. At such times unless I'm specifying the marketIds I would like to place I get an error message from flumine suggesting I am attempting to exceed my market stream allowance of 1000. I was wondering if there is a good way of closing markets or setting up an additional filter to cap the number of markets to 1000 (in closest to market open order) whilst I wait for Betfair to get back to me about further increasing my streamable markets?



Cheers!

---

## 2021-10-28 10:38:22 - issues channel

**JC**

Running that gives AttributeError: 'NoneType' object has no attribute 'utcnow'. It did fix it by adding the context manager in source but this may mess up other things? Seems ok for just generating dataframes but not sure about simulated orders etc.

---

## 2021-10-27 16:58:31 - issues channel

**JC**

managed to get it to work by adding the context manager in source code before line `for event in stream_gen():` in backtest.py. Using more standard context manager, e.g.

```with framework.simulated_datetime.real_time():

    with mock.patch("builtins.open", smart_open.open):

        framework.add_strategy(strategy)

        framework.run()```

, results in errors.

---

## 2021-10-27 16:03:04 - issues channel

**JC**

Just been trying to run a backtest by patching open with smart_open and passing a list of s3 market file paths into the market filter. On every file after the first I get RequestTimeTooSkewed error again. Think this is because of _readloop() in FlumineHistoricalGeneratorStream using the SimulatedDateTime object when it tries to open the file?

---

## 2021-10-24 15:51:17 - issues channel

**river_shah**

To confirm, this works, dependency resolution error goes away

---

## 2021-10-22 16:47:57 - betfair-news channel

**liam**

Ok, from my side it would be helpful to know what wrong so that I can better prepare for something similar. From writing tests to changing logic to make code more resilient, often things break but can be hard to fix/replicate after the fact due to not even knowing what caused it 

---

## 2021-10-22 11:36:25 - general channel

**Vinny Banks**

LoginError: API login: INVALID_USERNAME_OR_PASSWORD

---

## 2021-10-22 11:32:05 - general channel

**Vinny Banks**

Now I have a login error

---

## 2021-10-22 11:09:49 - issues channel

**Robbie Bennett**

betfair streaming problems for anyone else? getting socket timeout errors this morning

---

## 2021-10-22 11:07:41 - betfair-news channel

**Neil T (Betfair)**

Hi [@UBS7QANF3](@UBS7QANF3) - yes it is possible for a bet to be placed if a TIMEOUT occurs.  See the below guidance from the API docs regarding this - _"The order timed out &amp; the status of the bet is unknown. * *If a TIMEOUT error occurs on a *placeOrders/replaceOrders* request, you should check *listCurrentOrders* to verify the status of your bets before placing further orders. *Please Note:* Timeouts will occur after 5 seconds of attempting to process the bet but please allow up to 15 seconds for a timed out order to appear. After this time any unprocessed bets will automatically be Lapsed and no longer be available on the Exchange."_

---

## 2021-10-22 10:47:30 - general channel

**Vinny Banks**

Morning guys. New to slack so cut me some if I'm barking up the wrong tree. I am trying to build an auto bet machine using Python. I have created the certs and exported them but keep getting the following error message



APIError: None

Params: None

Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3991)')))



Also, when I try to upload it to my security area on my betfair account it is saying it's invalid. Is the Cert generation out of date and I'm missing something? Any hints or tips would be appreciated

---

## 2021-10-22 06:42:00 - issues channel

**river_shah**

[@U4H19D1D2](@U4H19D1D2) some open source packages I am using are dependent on `tenacity (&lt;=7.0.0)` is `tenacity (==8.0.1)` a hard requirement for flumine or can we relax please? getting dependency resolution issues and want to fix. thanks

---

## 2021-10-21 13:23:36 - betfair-news channel

**Neil T (Betfair)**

*Section 1: Betting - General Conditions*

Betfair provides a platform upon which you can enter into various betting transactions in relation to the markets available on our site ("Markets").

Where customers bet with each other on the Exchange, Betfair acts as a facilitator and does not act as a counterparty. However, Betfair may act as a counterparty on the Exchange but only in the following limited situations:

• for wagers between Australasian Customers. Betfair also offers Tote bets, as well as singles (which we call "˜Fixed Odds") and "Multiples" bets at odds fixed by us.

• for Betfair's Starting Price ('SP' or 'Betfair SP') on the Exchange. The Betfair SP is calculated by Betfair, by balancing all SP bets and other Exchange bets when the market is suspended at the 'off' of the relevant event. Betfair group may act as risk counterparty to SP bets if necessary to ensure a fair SP. The Betfair personnel involved in determining the SP in such circumstances will have no undeclared personal or other interest in the SP in question. When you place a bet at SP you are betting against other Betfair customers. However during the reconciliation of the Betfair SP, Betfair acts as counterparty in order to balance liabilities between Betfair SP bets and other Exchange bets; and

• occasionally (and such bets represent a tiny fraction of the overall volume of betting activity on the Exchange), in one of the two following circumstances:

    ◦ on less liquid markets to improve “liquidity” and stimulate market activity (“liquidity” is the amount of money available for you to bet on each selection). We may do this on ancillary markets (particularly when the market is first made available) or on markets on less popular events. The rationale for providing this liquidity is to enhance the betting proposition for our customers; and

in order to reduce the Betfair group’s liability against a particular outcome. We may do this on a high-profile event where our sportsbook has a very large exposure to that outcome.

---

## 2021-10-20 13:10:00 - issues channel

**Laing Clark**

Error: {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie1-ang27a-prd-09020828-006d651ee0', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0007', 'data': {'APINGException': {'requestUUID': 'ie1-ang27a-prd-09020828-006d651ee0', 'errorCode': 'INVALID_APP_KEY', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}

---

## 2021-10-20 13:09:58 - issues channel

**Laing Clark**

The exact error is:

---

## 2021-10-20 13:01:15 - issues channel

**Laing Clark**

Hey guys, im new and trying to jump into this betfairlightweight module. I have successfully plugged in the right data to the initial  python code provided by betfair with the command trading.login() successfully loging into my account and returning the expected LoginResource response. However, my issue is that If I do anything else, such as use the code provided in the next step of the tutorial I get an error code to the affect of INVALID_APP_KEY. Not what I was expecting considering the bindings to the variable 'trading' work with the initial login function. I know I'm a noob but can somebody point my in the right direction.

---

## 2021-10-19 12:27:54 - issues channel

**JC**

Sorry - another issue that has come up in backtesting is that if I add custom Middleware that retrieves scores data from S3, I get: `'An error occurred (RequestTimeTooSkewed) when calling the GetObject operation: The difference between the request time and the current time is too large.'`

I think this might be because of flumine monkeypatching datetime?

---

## 2021-10-16 12:19:33 - general channel

**liam**

I normally have issues with other parts like running out of the free tier for sentry due to the number of errors 

---

## 2021-10-16 12:13:57 - general channel

**D C**

I was getting 503 errors on the stream about 10 mins ago and killed my bots. Not tried since will restart just before racing starts

---

## 2021-10-16 12:10:03 - general channel

**liam**

Hmm, I haven’t had any errors on this, probably concerning 

---

## 2021-10-16 12:09:02 - general channel

**Mo**

Not sure [@ULDAVFDRP](@ULDAVFDRP), the missing market and event names were causing fatal errors all over my platform. A silly thing not to be robust against but it does reflect how unusual it is (haven't had to deal with such an issue in over three years)

---

## 2021-10-13 14:58:42 - general channel

**Jono**

Related to a flumine based question i asked a while back, ive recently got the streamable market limit increased from 200 to 1000 and off the back off advice from [@ULDAVFDRP](@ULDAVFDRP) kept my market filter wide for my startegy. I then work out which markets to place on using logic inside check_market_book, and in middleware etc beyond the initial strategy set up which specifies the only the event_type=1 and market_type=MATCH_ODDS. I was wondering the best way to manually stop market books being streamed from markets i am not interested in, after framework.run() and prior to them closing automatically at market close. At the moment i am capping the number markets desired for placing to a fixed number currently 20 and then using



self.remove_market(market.market_id)



inside check_market_book to halt the streaming information correlating to these excess markets. However i can still see in a background worker using len(flumine.markets) that there still remains ~600 markets and so I was wondering if im actually correctly removing them, and if im not what is the best way to do so? and best location ie inside middleware, worker, etc as opposed to in check_market_book? Furthermore if i wanted to start up streaming a new market post run() how would i go about this?



Thank you!

---

## 2021-10-11 10:29:48 - general channel

**liam**

it will never be placed as you will get an error due to the market not being open on placement

---

## 2021-10-11 08:19:39 - general channel

**liam**

Can you create a github issue for this and we can look to fix it?

---

## 2021-10-10 18:47:42 - strategies channel

**ShaunW**

Sounds good to me [@UNQGKT0CR](@UNQGKT0CR) and how I do it, although not being a Flumine guy I don't know if there's a slicker way to do it with that. And you can get a MVWAP by refreshing your T1-snapshot with one of a certain age rather than one from a fixed time like at the off, if you wanted too.

---

## 2021-10-08 12:24:19 - issues channel

**liam**

It will handle the batching to go under the limit, using a transaction will fix this 

---

## 2021-10-05 14:38:34 - general channel

**EJono**

Can any action be taken of orders of status: VIOLATION ? Can funds be tied up or be unable to be cancelled as the result of an order having this status? 



I'm working on fixing the issues that cause this order status occurring but when they do it seems they cannot be cancelled through market.cancel_order(order, force=True)

---

## 2021-10-05 11:20:53 - general channel

**liam**

both, for live you will have a single `Market` object with two different MarketBooks being sent through it (same marketId but different data because of the data filter) something to be aware of that might not impacting anything and tbh its on my list to isolate and fix the potential issue

---

## 2021-10-05 11:06:44 - general channel

**liam**

I would email bdp/Neil as he might be able to share more details and yes things are a bit hacky when it comes to requesting both as bflw will serialise based on the priority Lee has shared, this was meant to be temporary but I am not sure how best to output to the user whilst matching a conventional marketBook request. However the data for both is in the cache if you want to pull it out.



Have you tried testing yourself with a quiet market? Set debug to true on the logs and see the updates coming in

---

## 2021-09-29 14:23:55 - general channel

**liam**

the controls are there to protect and prevent something stupid, by forcing you are overriding the controls so you are on your own, I would enable logging and fix the issue

---

## 2021-09-29 14:18:29 - general channel

**Jono**

hmmmm potentially the third one although having seen these errors flag up before i put in some measures to stop them from happening with getValidBetSize checks adnd imported fumine util funcs like price_ticks_away, get_nearest_price etc but at some points there may be exceptions slipping through so ill be sure to tighten up the logging i have in place to identify when the controls are breached. Once an order is of status VIOLATION does exist tho, what are the consequences of utilising "force=True" specifically when all i want to do is simply cancel the remaining amount? basically if order.status == VIOLATION:  "market.cancel_order(order, force=True)"  exactly as liam originally posted. Could this have consequences i should be aware of? i know the validate control checks are there for good reason

---

## 2021-09-29 13:56:44 - general channel

**liam**

Need to see python logs as per the examples (this isn't the loggingcontrol) Could have failed on any of the default controls, have a look at the controls directory to see them

---

## 2021-09-29 13:35:57 - general channel

**Jono**

sorry i dont have anything particularly insightful to hand log wise other then times of different market transactions taking place and a list of the different orders placed . Need to make better use of the logging worker. the documentation has a comment inside the OrderStatus class stating beside VIOLATION definition that # order never placed due to failing controls

could you possibly elaborate on what this means? Is it something that is generated from both failed placings on betfair due to incorrect instructions sent to the api and/or breaches of the strategy variables ie max_live_trade_count?

---

## 2021-09-28 13:22:57 - general channel

**liam**

```import os

import sys

import zipfile

import gzip

import boto3

from io import BytesIO

from concurrent import futures

from tqdm import tqdm



"""

Move s3 to s3

"""



s3_client = boto3.client("s3")



BUCKET = "flumine"

NEW_PREFIX = "marketdata/marketBook"

OLD_PREFIX = "marketdata/streaming/{0}"

# threading

WORKERS = 4

CHUNKS = 10





def chunks(l: list, n: int) -&gt; list:

    for i in range(0, len(l), n):

        yield l[i : i + n]





def upload_object(object, key, metadata):

    return s3_client.put_object(

        Body=object,

        Bucket=BUCKET,

        Key=key,

        Metadata=metadata,

    )





def create_new_compressed_file(zf, contained_file):

    with zf.open(contained_file, "r") as f:

        file_compressed = gzip.compress(f.read())

    return file_compressed





def process_files(files):

    for file in files:

        # download file

        response = s3_client.get_object(Bucket=BUCKET, Key=file["Key"])

        _zip_data = response["Body"].read()

        try:

            with zipfile.ZipFile(BytesIO(_zip_data)) as zf:

                for contained_file in zf.namelist():

                    market_id = contained_file

                    gz_object = create_new_compressed_file(zf, contained_file)

                    key = "{0}/{1}.gz".format(NEW_PREFIX, market_id)

                    upload_object(gz_object, key, response["Metadata"])

        except Exception as e:

            print("Error in market {0}".format(market_id), e)





def process(event_type_id):

    print("Starting process on eventTypeId: {0}".format(event_type_id))

    old_prefix = OLD_PREFIX.format(event_type_id)

    paginator = s3_client.get_paginator("list_objects_v2")

    page_iterator = paginator.paginate(

        Bucket=BUCKET, Prefix=NEW_PREFIX

    )

    processed = []

    for page in page_iterator:

        for object in page["Contents"]:

            file_path = os.path.basename(object["Key"])

            processed.append(file_path[:-3])



    print("{0} files already processed".format(len(processed)))



    event_type_ids = [7]

    for event_type_id in event_type_ids:

        print(event_type_id)

        pcs, skp = 0, 0

        page_iterator = paginator.paginate(

            Bucket=BUCKET, Prefix=OLD_PREFIX.format(event_type_id)

        )

        for page in page_iterator:

            for object in page["Contents"]:

                file_path = os.path.basename(object["Key"])

                if file_path[:-4] not in processed:

                    pcs += 1

                else:

                    skp += 1

        print("{0} files to process ({1} skipped)".format(pcs, skp))

    return



    page_iterator = paginator.paginate(

        Bucket=BUCKET, Prefix=old_prefix

    )

    skp = 0

    files_to_process = []

    for page in page_iterator:

        for object in page["Contents"]:

            file_path = os.path.basename(object["Key"])

            if file_path[:-4] not in processed:

                files_to_process.append(object)

            else:

                skp += 1

    print("{0} files to process ({1} skipped)".format(len(files_to_process), skp))



    with futures.ThreadPoolExecutor(max_workers=WORKERS) as executor:

        _process_jobs = []

        for files in chunks(files_to_process, CHUNKS):

            _process_jobs.append(executor.submit(process_files, files=files))

        for job in tqdm(futures.as_completed(_process_jobs), total=int(len(files_to_process)/CHUNKS)):

            job.result()  # wait for result

    print("{0} files processed".format(len(files_to_process)))





if __name__ == "__main__":

    event_type_id = sys.argv[1]

    process(event_type_id)```

---

## 2021-09-27 17:21:21 - issues channel

**Newbie99**

[https://github.com/liampauling/flumine/blob/cd1e981c57baef58a529b624a17a7877cc67c676/flumine/execution/baseexecution.py#L127](https://github.com/liampauling/flumine/blob/cd1e981c57baef58a529b624a17a7877cc67c676/flumine/execution/baseexecution.py#L127)



Just re-visiting an issue from a while back, that I was never able to solve (related to [https://github.com/liampauling/flumine/issues/455](https://github.com/liampauling/flumine/issues/455)).



For the above, I get stuck in some infinite loops when using replace, so I'm just thinking out loud, whether as a sort of hacky quick fix, if I were to create a custom event when the instruction_report.bet_id attribute does not exist, I could presumably pick this up with a logging control and handle the logic there. Does that sound plausible (I don't see anywhere else in the source code where the error is captured, so there's no obvious other way to go about this currently)?



Also as a side note, for the replace element, should there be a check to ensure the order does exist (i.e. should line 151 be the same as line 142/143)?

---

## 2021-09-21 21:32:24 - issues channel

**gbettle**

Evening all. I have hacked-together a bit python to fetch Horse Racing today\tomorrow - see attached.



It's been working for several weeks. Until tonight, when I'm suddenly getting the following error. Is 503 an issue with my network?



PS C:\Users\garry\betfair\examples&gt;  &amp; 'C:\Users\garry\AppData\Local\Programs\Python\Python38\python.exe' 'c:\Users\garry\.vscode\extensions\ms-python.python-2021.9.1246542782\pythonFiles\lib\python\debugpy\launcher' '51302' '--' 'c:\Users\garry\betfair\examples\temp_racecards.py'

2021-09-22 1300 Redcar Try Racing Tv For Free Now Nursery Handicap (4) £9500.00 1 Gnat Alley, 2 Pneumatic, 3 Iur Cinn Tra

2021-09-22 1315 Goodwood Ryan Canter Club Future Stayers' Ebf Maiden Stakes (2) £20000.00 1 Age Of Sail, 2 War Horse, 3 Schmilsson

2021-09-22 1330 Redcar Free Month Of Racing Tv Nursery Handicap (6) £6200.00 1 Sweet Madness, 2 Bro, 3 Sunsets Dreamers

Traceback (most recent call last):

  File "c:\Users\garry\betfair\examples\temp_racecards.py", line 84, in &lt;module&gt;

    race_cards = trading.race_card.get_race_card(market_ids=[market_id])

  File "C:\Users\garry\AppData\Local\Programs\Python\Python38\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 64, in get_race_card

    (response, response_json, elapsed_time) = self.request(

  File "C:\Users\garry\AppData\Local\Programs\Python\Python38\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 118, in request

    check_status_code(response)

  File "C:\Users\garry\AppData\Local\Programs\Python\Python38\lib\site-packages\betfairlightweight\utils.py", line 34, in check_status_code

    raise StatusCodeError(response.status_code)

betfairlightweight.exceptions.StatusCodeError: Status code error: 503

---

## 2021-09-21 08:48:53 - strategies channel

**Adrian**

I feel my brain ceasing up :exploding_head: but i think i'm starting to get it. i'll look into getting the debugger going. thanks for all your help everyone :grin:

---

## 2021-09-21 08:33:52 - strategies channel

**Beeblebrox**

I think the best thing is to pick a market that this happens on and use the debugger to step through it to see what's happening.  It's difficult to explain as it's a bit counter-intuitive.

---

## 2021-09-21 08:21:59 - issues channel

**Jorge**

I am only using letters at the moment. And in this case I would get an error when placing the bet as far as I know

---

## 2021-09-19 09:23:27 - issues channel

**liam**

That fix for your issue birchy has introduced this

---

## 2021-09-19 09:20:11 - issues channel

**Oliver Varney**

double check but I think its that as it should error if thats the case

---

## 2021-09-19 09:11:40 - issues channel

**birchy**

debug breakpoints here: [https://github.com/liampauling/flumine/blob/40d82ec69c333afa034c12763acc07ba3e76be31/flumine/markets/market.py#L118](https://github.com/liampauling/flumine/blob/40d82ec69c333afa034c12763acc07ba3e76be31/flumine/markets/market.py#L118)

Where `self.market_book` is actually a `dict` ?

---

## 2021-09-19 09:07:18 - issues channel

**Oliver Varney**

that error suggest your accessing a dictionary with like its an attribute of a class

---

## 2021-09-18 18:20:53 - issues channel

**Aaron Smith**

[@ULDAVFDRP](@ULDAVFDRP) thanks, but i already changed those manually for each instance (this is what fixed it last time :smile: )

---

## 2021-09-18 17:36:43 - issues channel

**Aaron Smith**

Also at the same time i tried installing betfairlightweight[speed], which failed at the ciso8601 package, so i only have the orjson one

---

## 2021-09-17 14:47:17 - strategies channel

**birchy**

Yes, was thinking about using something along those lines with a fixed time as the fallback.

---

## 2021-09-17 09:25:37 - issues channel

**liam**

Now fixed

---

## 2021-09-16 21:01:34 - issues channel

**Jonjonjon**

This fixed it:

git checkout 1898838431a74fde504d8eb0fe017ab61a3556bc

---

## 2021-09-16 17:40:58 - strategies channel

**birchy**

Anyone got any advice for increasing matching rates? So I have a horses inplay strategy that uses price signals. For post-race analysis, I plot the "what if" cumulative P&amp;L of 100% match rate vs my actual cumulative P&amp;L (which is ~50% match rate). The theoretical 100% match rate gives a lovely straight upwards line, so that does at least show that I'm not pissing _directly_ into the wind. This strategy is right in the thick of the action, so fairly time sensitive.

Obviously increasing the cancellation "age" of the bet is an option, but that does seem to result in increased adverse selection. I'm considering using a more dynamic cancelling procedure (i.e. signal driven rather than a fixed time). The other option is moving my price closer to the middle of the spread, but backtests suggest that's going to reduce my edge closer to 0EV. My signals are fairly optimal, well... they're somewhere in the middle of the high volume/low margin : low volume/high margin range. Soooo many combinations. Doing my head in TBH. :face_with_rolling_eyes:

---

## 2021-09-16 14:59:07 - issues channel

**Dado**

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue

Params: {'filter': {'marketIds': [{'1.187040331': u'30849498'}, {'1.187056991': u'30851394'}, {'1.186998604': u'30845997'}, {'1.186998738': u'30845996'}, {'1.186998872': u'30845995'}, {'1.186999006': u'30845994'}, {'1.186998336': u'30845998'}, {'1.186998470': u'30845999'}, {'1.186997502': u'30845827'}, {'1.186997636': u'30845826'}, {'1.186997770': u'30845825'}, {'1.186997100': u'30845844'}, {'1.186997368': u'30845828'}, {'1.172966865': u'30009984'}, {'1.187019793': u'30847722'}, {'1.187051669': u'30850656'}]}, 'maxResults': 1000, 'marketProjection': ['EVENT', 'RUNNER_DESCRIPTION']}

Exception: None

Error: {u'message': u'DSC-0018', u'code': -32602}

Full Response: {u'jsonrpc': u'2.0', u'id': 1, u'error': {u'message': u'DSC-0018', u'code': -32602}}

---

## 2021-09-16 14:58:49 - issues channel

**Dado**

everythings was as always but now I got this error:

---

## 2021-09-16 09:37:24 - issues channel

**liam**

anyone else getting a lot of connection errors?

---

## 2021-09-14 12:15:21 - general channel

**George**

but it's failing on the `decode` with the AttributeError

---

## 2021-09-14 12:10:06 - general channel

**George**

specifically:

AttributeError: 'StreamReader' object has no attribute 'decode'

---

## 2021-09-13 10:17:26 - random channel

**D C**

I love cricket and use to play it a lot but T20 doesn't hold my interest as a spectacle but I see the appeal of it from trading perspectives. I used to bet a lot on test matches but based on knowledge, not analytics. For me I would not know where to start modelling it properly as it is essentially more about bowler versus batsman matchups and that in itself holds a lot of variation. It is something I would love to get into though but you have to be wary of the match fixing element - you see some terrible examples at times but I suppose no worse than in tennis.

---

## 2021-09-12 11:30:44 - general channel

**Stefan**

[@U013K4VNB6D](@U013K4VNB6D) yes I can understand that but you are C# developer as well, and before python betfair api wrapper library betfair itself offered C# libraries, What you use now is not actually framework. Yes, I use python as well no some many but am able to code something to support my ML, actually to use ML you do not have to know any python. I tried to write today some code I did exactly in 3 other programming languages yesterday, but failed to do so, and it is just initialization of 2 objects, what I managed to do, but calling 2 async/Task method I failed, so I leave python for now as 4 example of using betfair framework.

---

## 2021-09-11 17:36:09 - random channel

**thambie1**

Possibly. I shudder to think how bad things must be if their matching engine is throwing errors

---

## 2021-09-11 17:28:57 - random channel

**thambie1**

I got an ERROR_IN_MATCHER error for the first time, other than that, not seeing anything

---

## 2021-09-11 13:14:41 - strategies channel

**Unknown**

I was just looking at the GPS data from this race..

The attached is a screenshot from a playback..Everything seemed to be updating with the exception of the progress data on "Hoo ya Mal". It never changed through the race. yet everything else did ie stride freq etc

I was wondering if the "Start" signal is set for each selection and it was just this single horse that didnt have it set? Or whether the "start Signal" is set for the whole market? Would you know [@U4H19D1D2](@U4H19D1D2)

---

## 2021-09-11 10:47:07 - random channel

**Aaron Smith**

oh okay, however it managed to only grab the greyhounds at least, so i should probably fix it, but its unlikely to be the solution to how AUS made it through that filter

---

## 2021-09-11 09:53:39 - issues channel

**ricky**

This morning my betfair API return error message SUBSCRIPTION_LIMIT_EXCEEDED,  my max allowed number changed from 2000 to 1000 now? Anyone have the same issue?

---

## 2021-09-10 18:05:21 - general channel

**Peter**

If you're using Flumine or BFLW for streaming, use the streaming market filter. If you're just making API calls with BFLW use the market filter. In either case you can skip them all together and just pass a dict with the relevant parameters if you prefer.



There are two filters because the permitted parameters for streaming are more restrictive than for the API. So using the streaming filter will trigger an error if you try to use (for example) competition_ids, which is a valid parameter for API calls.

---

## 2021-09-10 12:38:47 - general channel

**George**

thanks. if you mean the error handling example using tenacity i've just implemented something very similar. is the socket timeout equivalent to missed heartbeats, or should I try to handle missed heartbeats separately?

---

## 2021-09-09 20:21:48 - strategies channel

**Jack**

Thanks [@U4H19D1D2](@U4H19D1D2) - error was `'Market' object has no attribute 'market_definition'` which of course makes sense given your reply.

The reason I went with `market.market_definition.race_type == "Hurdle"` is because it works in my logging controller I use that under `_process_closed_market()`  so I thought it was part of the market object during the race.

Certainly also makes sense for this to be in `check_market_book` !

---

## 2021-09-09 09:44:27 - random channel

**Jonjonjon**

I finally implemented it. It fixed my disk space issue. Thanks Liam!

---

## 2021-09-09 06:35:53 - strategies channel

**liam**

What errors? These are the list of raceTypes which you can also use on the market filter 



Hurdle, Flat, Bumper, Harness, Chase

---

## 2021-09-09 04:12:03 - issues channel

**Unknown**

Hi All, I'm an API newbie and am having trouble getting the non-interactive login working.  I have followed the instructions on Betfair for generating certificates using XCA, I have deleted and started over numerous times to ensure exact instructions were followed, but each time I run login code I get the below exception:

---

## 2021-09-08 21:29:02 - strategies channel

**Jack**

Sorry for the noob question - how would I filter out Hurdle races within a flumine strategy? I was using

```    def process_market_book(self, market, market_book):

        if market.market_definition.race_type == "Hurdle":

            return```

But I have realised it must be added to the market book later on because this is throwing tonnes of errors out.

---

## 2021-09-08 19:30:28 - issues channel

**Ke**

seems to work for me. no longer see the error now

---

## 2021-09-08 16:16:24 - general channel

**Newbie99**

for example:



```socketio.run(app, debug=False, host='0.0.0.0', port=1234)```



---

## 2021-09-08 16:15:51 - general channel

**Jono**

sorry [@UFTBRB3F1](@UFTBRB3F1) could you clarify exactly what you mean? Is there a _debug=_ variable i havent been aware of all this time thats worth making a quick note of :scream:

---

## 2021-09-08 15:54:43 - general channel

**Newbie99**

if you go down that route...make sure you set debug to False....otherwise you end up with 2 processes and duplicate bets....er not that I ever did that of course....:woozy_face:

---

## 2021-09-08 14:11:36 - issues channel

**liam**

Notes/context are all local objects so you would need to store them elsewhere, simple fix is don't restart

---

## 2021-09-08 13:49:32 - issues channel

**liam**

Should now be fixed in 1.19.13 can you check?



The issue is due to the ordering of the market files, I do this before processing which is why I hadn't seen it before. Full commit [https://github.com/liampauling/flumine/commit/0e94dd0a00533c52176746c56c7610ec698da6a2|here](https://github.com/liampauling/flumine/commit/0e94dd0a00533c52176746c56c7610ec698da6a2|here) where you can see the ordering and slight logic change to handle any long running markets

---

## 2021-09-08 12:51:48 - general channel

**D C**

I think someone asked this recently but I can't find it anywhere in any thread. I've just changed from stream subscription using market ID list to a coarser filter. Yesterday it silently failed on me - the silence likely a bug in my logging setup but I suspect that the number of markets in my filter changed as new markets were added (seemed to fail around 6pm UTC). Because my logging failed I am not sure how to catch it so does anyone know what actually happens when this occurs. The socket was not disconnected so I presumably kept getting heartbeats and zero data (no market data files were produced after the "failure" time). Recommended solution was to ask for a bump in the market limit per connection which I will do but just curious as to what actually happens when this occurs as I am basically just making an assumption here.

---

## 2021-09-08 11:24:47 - general channel

**Unknown**

I've adapted [@U01SCPDTV5J](@U01SCPDTV5J)'s multiprocessing code to my back test code and I've excluded from consideration JSON files beginning with '2'. As a result, I'm now processing about 3 markets a second, which is fantastic.



However, the results summary code that I used previously no longer works, as the interpreter seems to think that there are no markets in the blotter. I've put the revised code on GitHub - [https://github.com/JeffW12345/betfair-backtesting/blob/main/runbacktests.py#L95](https://github.com/JeffW12345/betfair-backtesting/blob/main/runbacktests.py#L95).



I can't work out why, and when I try to use the debug tool I get an error message (attached).



Any suggestions would be much appreciated.



Thanks



Jeff

---

## 2021-09-07 19:22:22 - general channel

**Beeblebrox**

It's happening in real time and with live data.  In theory it should be the same as backtesting, but who knows what errors you might have made that won't show up with historic data, but will in live data?  It's just a safety net to stop you losing a load of money.

---

## 2021-09-07 14:44:02 - general channel

**Jeff Waters**

No, they are stored in a folder on my C drive.



Because the files are in different folders within the PRO folder, I modified the get_markets method, as I was getting a 'file not found' error message:



```def get_markets(data_dir):

    markets = []

    for dir_, _, files in os.walk(data_dir):

        for file_name in files:

            dirName = Path(dir_).absolute()

            rel_file = os.path.join(dirName, file_name)

            markets.append(rel_file)

    return markets```

I wouldn't have thought that would slow things down, though?



Apart from that, you and I were running the same code.



The fact that you guys aren't seeing any major errors or omissions suggests to me the the slow speed is hardware-related?

---

## 2021-09-07 14:21:44 - general channel

**Jeff Waters**

I don't know if it's relevant, but when I ran the program I got loads of messages like the following:



*{"asctime": "2021-09-07 10:55:53,215", "levelname": "CRITICAL", "message": "Unknown error can only concatenate str (not \"int\") to str in process_market_book (1.145082711)", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\water\\anaconda3\\envs\\bet-project\\lib\\site-packages\\flumine\\utils.py\", line 204, in call_strategy_error_handling\n    return func(market, market_book)\n  File \"C:\\Users\\water\\PycharmProjects\\bet-project\\teststrategy.py\", line 47, in process_market_book\n    print(\"Number of bets placed so far: \" + len(market.blotter))\nTypeError: can only concatenate str (not \"int\") to str"}*



and





*{"asctime": "2021-09-07 10:55:53,215", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.145082712", "selection_id": 17069875, "handicap": 0, "id": "138503049532150426", "customer_order_ref": "d0d1ab6db12de-138503049532150426", "bet_id": null, "date_time_created": "2018-07-01 07:42:37.024000", "publish_time": null, "trade": {"id": "2bac1299-0fca-11ec-91ad-00e62d0401a8", "strategy": "TestStrategy", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138503049532150426"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 42, "size": 10, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 10.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}*



and



*{"asctime": "2021-09-07 10:55:53,230", "levelname": "WARNING", "message": "Order has violated: STRATEGY_EXPOSURE Error: Potential selection exposure (410.00) is greater than strategy.max_selection_exposure (105)", "control": "STRATEGY_EXPOSURE", "error": "Potential selection exposure (410.00) is greater than strategy.max_selection_exposure (105)", "order": {"market_id": "1.145082712", "selection_id": 17069875, "handicap": 0, "id": "138503049532150426", "customer_order_ref": "d0d1ab6db12de-138503049532150426", "bet_id": null, "date_time_created": "2018-07-01 07:42:37.024000", "publish_time": null, "trade": {"id": "2bac1299-0fca-11ec-91ad-00e62d0401a8", "strategy": "TestStrategy", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138503049532150426"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 42, "size": 10, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 10.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: STRATEGY_EXPOSURE Error: Potential selection exposure (410.00) is greater than strategy.max_selection_exposure (105)", "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}}*



I also got loads of 'market closed' and 'market cleared' 'INFO' messages.



Are they to be expected, or do they hint at a problem with the code?

---

## 2021-09-07 14:16:10 - general channel

**Adrian**

which i did when you asked which version but then i introduced another error after

---

## 2021-09-07 11:28:56 - general channel

**liam**

100 markets:



```start time = 07/09/2021 11:25:17

Total profit post-commission: 468.04



finish time = 07/09/2021 11:26:44```

Bugfix in the strategy, logging set to CRITICAL and this fix to the get_markets



```def get_markets(data_dir):

    markets = []

    for dir_, _, files in os.walk(data_dir):

        for file_name in files:

            rel_file = os.path.join(data_dir, file_name)

            markets.append(rel_file)

    return markets ```

---

## 2021-09-07 11:22:18 - general channel

**liam**

Change logging to critical to speed things up, error line 47 in the strategy, should be

```str(len(market.blotter))```

---

## 2021-09-07 11:19:42 - issues channel

**Peter C**

[@U4H19D1D2](@U4H19D1D2) sorry I now get the error

`AttributeError: 'Flumine' object has no attribute 'add_middleware'`

Do I need to import the add_middleware function from somewhere?

---

## 2021-09-07 11:03:55 - issues channel

**liam**

Quick fix for your example would be



```client = clients.BacktestClient(

    transaction_limit=None,

)```

---

## 2021-09-06 11:00:14 - issues channel

**Oliver Varney**

same applies without looking deeply id stick a break point in or wrap that property with a try and except and catch the exception and find out what is None and why. Can you not isolate that market and step through the process of creating the order then replacing it

---

## 2021-09-06 10:48:05 - issues channel

**Oliver Varney**

yes but the process of replacing the order looking at that error stack uses the property size_remaining, which in turn uses self.order.order_type.size

---

## 2021-09-06 10:41:43 - issues channel

**Oliver Varney**

that error translates to your adding/taking away  None and a integer together i.e. None - 5. So it looks self.order.order_type.size is None or one of the other variable it takes away in that property. Have you created an order with size None by accident (if thats possible)?

---

## 2021-09-06 10:34:58 - issues channel

**Adrian**

I am getting this weird error while backtesting and it is halting the script when it occurs

```{"asctime": "2021-09-06 09:28:44,051", "levelname": "CRITICAL", "message": "Trade error in 081dd302-0ef4-11ec-a5d6-1e0062368792", "exc_info": "Traceback (most recent call last):\n  File \"/Users/adrian/opt/anaconda3/envs/betfair/lib/python3.8/site-packages/flumine/execution/simulatedexecution.py\", line 142, in execute_replace\n    place_instruction_report = replacement_order.simulated.place(\n  File \"/Users/adrian/opt/anaconda3/envs/betfair/lib/python3.8/site-packages/flumine/backtest/simulated.py\", line 68, in place\n    self.size_voided += self.size_remaining\n  File \"/Users/adrian/opt/anaconda3/envs/betfair/lib/python3.8/site-packages/flumine/backtest/simulated.py\", line 379, in size_remaining\n    self.order.order_type.size\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'int'"}```

---

## 2021-09-05 22:35:15 - general channel

**Jeff Waters**

I've tried to add filters to only include British races and win races (based on filters used in the the example code at [https://github.com/liampauling/flumine](https://github.com/liampauling/flumine)):



```strategy = TestStrategy(

    market_filter={"markets": marketsToProcess},

    country_codes=["GB"],

    market_types=["WIN"],

    max_order_exposure=1000,

    max_selection_exposure=105,

)```

However, I got an error message:



*TypeError: __init__() got an unexpected keyword argument 'country_codes'*



Presumably, that was because I wasn't using market_filter=streaming_market_filter, as in the example (as I was using historical data rather than live data).



Is there any way of filtering out particular types of races when using historical data, other than putting something like

```if market.country_code != "GB":

    continue```

in the process_market_book method?



Thanks



Jeff

---

## 2021-09-05 17:10:12 - strategies channel

**birchy**

That makes sense [@UGV299K6H](@UGV299K6H) . I've found that level liabilities generally produce inferior results compared to plain old level stakes. As you say, your average punter is likely betting £2/3/5/10 rather than £2.36. The main exception being those using hedging software, cash out, etc.

---

## 2021-09-05 11:39:18 - random channel

**Mo**

Yeah I can't think of a case where it wasn't a fixed amount. You're basically placing a bet at incredible value. For these season long positions it's pretty difficult to get on in size either on Betfair or with bookmakers so hard to hedge on that basis even if you want to. We tended to work out the potential impact of individual match results on the position and hedge in those markets

---

## 2021-09-05 11:34:31 - random channel

**liam**

Do the company’s get paid a fixed amount / did you ever take a position? 

---

## 2021-09-05 11:20:56 - random channel

**Mo**

You have to be careful because the financial incentives can make match fixing much more attractive

---

## 2021-09-04 22:47:00 - issues channel

**infinite digital**

Hello,



I am seeing the following error:



```MarketStream 2007 run error

Traceback (most recent call last):

  File "D:\apps\programming\python\lib\site-packages\flumine\streams\marketstream.py", line 44, in run

    self._stream.start()

  File "D:\apps\programming\python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 60, in start

    self._read_loop()

  File "D:\apps\programming\python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 219, in _read_loop

    self._data(received_data)

  File "D:\apps\programming\python\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 260, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 206-040921214509-3414396, data: {"op":"status","statusCode":"FAILURE","errorCode":"TIMEOUT","errorMessage":"Connection is not subscribed and is idle: 15000 ms","connectionClosed":true,"connectionId":"206-040921214509-3414396"}```

I can access other API methods using BFLW.



What is wrong?



Thank you!

---

## 2021-09-04 21:10:11 - issues channel

**Ke**

The current_transaction_count_total seems to be accumulating all the time. I'm running back testing for 1 month data. The first 20 days are all ok and starts to throw error as current_transaction_count_total&gt;5000, while my strategy should not generate more than 200 orders every hour. Therefore, I'm wondering does current_transaction_count_total only count the transaction in last 1 hour in the simulation?

---

## 2021-09-04 07:13:24 - issues channel

**Mo**

I get these errors pretty regularly when scraping the account statement. They go away after a while

---

## 2021-09-04 06:29:19 - issues channel

**Peter**

Hmm. Could be a problem resurfacing at the Betfair end: [https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/34290-getaccountstatement-unexpected-error](https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/34290-getaccountstatement-unexpected-error)

---

## 2021-09-04 06:19:04 - issues channel

**Peter**

My error logs this morning are full of errors like this:



`ERROR:flumine.worker:_get_cleared_market error`

`Traceback (most recent call last):`

  `File "/home/ec2-user/.local/lib/python3.7/site-packages/flumine/worker.py", line 232, in _get_cleared_market`

    `group_by="MARKET",`

  `File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/endpoints/betting.py", line 434, in list_cleared_orders`

    `(response, response_json, elapsed_time) = self.request(method, params, session)`

  `File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 55, in request`

    `self._error_handler(response_json, method, params)`

  `File "/home/ec2-user/.local/lib/python3.7/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 81, in _error_handler`

    `raise self._error(response, method, params)`

`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders`

`Params: {'betStatus': 'SETTLED', 'marketIds': ['1.187240733'], 'customerStrategyRefs': ['ip-172-31-5-190'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'}`

`Exception: None`

`Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-09020828-000312861c', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}`

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang30b-prd-09020828-000312861c', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`



Latest version of Fumine (1.19.12) and BFLW (2.13.2), and the trades are working fine.



I'm wondering whether anybody else has any idea what could be triggering these "unexpected errors" in the __get__cleared_market() method.



It might be connected to the from and to dates not being set in the API call, but as this is happening internally to Flumine, I'm don't know how to ensure that they get set.

---

## 2021-09-03 21:27:10 - issues channel

**Jonjonjon**

I fixed it for now by killing a few stray jobs. I guess I need to be more careful.

---

## 2021-09-03 21:09:03 - issues channel

**Jonjonjon**

I keep getting this error:



MAX_CONNECTION_LIMIT_EXCEEDED



Is it easy to get increased?

---

## 2021-09-03 10:56:18 - issues channel

**liam**

impossible for me to debug without some code tbh but I (and many others) use this all the time with no issues so its likely to be your code

---

## 2021-09-03 10:25:48 - issues channel

**Adrian**

Ok i got the logs working on both strat and loggingcontrol (sorry for confusion, i thought it only worked on one at a time). There is an apparent "max transaction count" error. But that should only last 1 hour. These markets span 2 months. Its seems once it hits that limit it never clears, so the csv export stops there

---

## 2021-09-02 20:36:55 - general channel

**Ke**

Can i make worker to be activated by event, say market close or open, rather than a fixed time interval?

---

## 2021-09-02 15:08:00 - strategies channel

**Jack**

[@UGV299K6H](@UGV299K6H)/[@U016TGY3676](@U016TGY3676) All makes sense thank you. Out of interest, and without asking you to spill any secret sauce, what kind of additional things would you be looking at to encompass a robust process?



In this case for context this strategy is:

• pre-play

• purely price-driven (that is to say no data is being used outside of the market stream info)

• bet-sizes are fixed minimum stake £2

I have no strategies running so certainly no profits being made just yet :joy: any advice appreciated.

---

## 2021-09-02 12:23:13 - strategies channel

**Michael**

The sort of error I mean would be something where your code is fine but your underlying reasoning is faulty, for example using a forward looking data field.

---

## 2021-09-02 11:55:49 - strategies channel

**Jack**

[@UGV299K6H](@UGV299K6H) wouldn't the logical error be caught by the backtest itself? Or is there an example of an error that would only present itself in a live scenario?

---

## 2021-09-02 11:44:46 - strategies channel

**Michael**

Remember that MC won't alert you either to a logical error in your strategy or an overfit on your data. Either one of those will return a fantastic looking result on your MC test and a crushing loss in real life.

---

## 2021-08-26 16:54:24 - general channel

**Pedro Lima Monteiro**

Hi again.

Taking advantage of you all being so kind here I am with yet another doubt.

I managed to successfully connect to the betfair streaming API using the streaming error handling example and I am currently running this example, with some small changes, without any problems.

The thing I am struggling with now is that I am processing the incoming data and storing it in a NoSQL document database similar to MongoDB (not using any type of async python code while doing so) and the timestamps I am getting from the incoming data are getting more and more behind in time the longer I keep the streaming running. Reaching the point where, after 15 minutes running, I was receiving messages with an 8 minute delay.

That being said, is there any way to avoid this situation? Maybe using async python code? As a not so experienced python programmer, every bit of help is appreciated.

Thanks in advance!

---

## 2021-08-26 08:59:35 - issues channel

**liam**

Good spot, this is a bug that I am fixing now

---

## 2021-08-26 08:58:58 - general channel

**liam**

have a look at the [https://github.com/liampauling/betfair/blob/0dbd551272d66ea1e4efe8f8c695b54099567265/betfairlightweight/baseclient.py#L96|code](https://github.com/liampauling/betfair/blob/0dbd551272d66ea1e4efe8f8c695b54099567265/betfairlightweight/baseclient.py#L96|code) every time you set the sessionToken you reset the login time, yes making sure you keep_alive will prevent errors but just don't use that property if you are sharing tokens around trading objects

---

## 2021-08-26 08:28:21 - general channel

**liam**

catch the errors? use flumine? the sessionToken is stored in the trading object (nothing to do with requests) so you would need to persist to disk or similar

---

## 2021-08-26 08:13:41 - general channel

**Jono**

whats the best way to use an existing active login session after a crash or error has caused the most recent code run to fail or timeout? Ive seen you can pass the trading object a requests.Session that should allow for this but im not certain how i can pass this after an error that caused the code to halt and have to start from a blank slate. Is there a straightforward way of using the trading object from betfairlightweight to start things off again utilising an active session from the least information say login details, app_key and the session_token of the last successful login?

---

## 2021-08-26 07:53:31 - general channel

**Peter**

Yes [@U0122TPQABW](@U0122TPQABW) 2 milliseconds difference on the pt is exactly what I mean and I was surprised at that too, but probably shouldn't have been. The Betfair API allows quite a lot of control over the filters (whether we take advantage of that or not), so it makes sense that we have streams unique to the recipient, and that updates can't be collated and dispatched simultaneously.



I'm like you I like to track down each error message or oddity to understand what's going on in case it's a pointer to an underlying problem that I can solve. However, we also need a certain tolerance for data integrity issues, because we see a lot of them and I'd see this as being at the benign end of the spectrum.



Picking it apart though, markets are added to the stream by Betfair and picked up by Flumine when that happens. In the cases you're citing it looks like you're simply detecting actions taken at the Betfair so beyond your control. However they're happening after you've uploaded the recorded data to S3, so that file will not contain the extra img.

---

## 2021-08-25 18:47:55 - general channel

**azevedo**

Thank you very much [@U9JHLMZB4](@U9JHLMZB4) [@U4H19D1D2](@U4H19D1D2)! If I get a connection issue would that appear in the logs? (I don't see any warning, errors, or any "connection" containing messages)



I basically get the following patterns with Flumine re-adding the removed market later and then just having this one line with img true in the end.

```# Initial Closure

{"asctime": "2021-08-25 15:00:59,330", "levelname": "INFO", "message": "[MarketStream: 2001] 1.186826857 removed, 202 markets in cache"}

{"asctime": "2021-08-25 15:00:59,331", "levelname": "INFO", "message": "Market 1.186826857 closed", "market_id": "1.186826857", "event_id": "30831054", "event_type_id": "4339", "event_name": "Monmore (F/C) 25th Aug", "market_type": "FORECAST", "market_start_datetime": "2021-08-25 14:58:00", "country_code": "GB", "venue": "Monmore", "race_type": null, "orders_cleared": false, "market_cleared": false, "closed": true}

{"asctime": "2021-08-25 15:00:59,331", "levelname": "INFO", "message": "Closing market 1.186826857"}

... a few more messages saying successfully loaded to s3, then market_cleared etc.



# Then an hour later removing the market (I have left default 3600s market expiration setting)

{"asctime": "2021-08-25 16:05:40,133", "levelname": "INFO", "message": "Removing market 1.186826857", "client": ...}

{"asctime": "2021-08-25 16:05:40,133", "levelname": "INFO", "message": "Market removed", "market_id": "1.186826857"}

{"asctime": "2021-08-25 16:05:43,538", "levelname": "INFO", "message": "Removing: /home/ubuntu/betfair_market_recorder/a182664f/1.186826857.gz, age: 3884.06s"}

{"asctime": "2021-08-25 16:05:43,538", "levelname": "INFO", "message": "Removing: /home/ubuntu/betfair_market_recorder/a182664f/1.186826857, age: 3884.21s"}



# Then shortly after in 12 mins, it's adding the market again

{"asctime": "2021-08-25 16:17:49,782", "levelname": "INFO", "message": "Adding: 1.186826857 to markets"}

{"asctime": "2021-08-25 16:17:49,785", "levelname": "INFO", "message": "Market 1.186826857 closed", "market_id": "1.186826857", "event_id": null, "event_type_id": null, "event_name": null, "market_type": null, "market_start_datetime": "1970-01-01 00:00:00", "country_code": null, "venue": null, "race_type": null, "orders_cleared": false, "market_cleared": false, "closed": true}

{"asctime": "2021-08-25 16:17:49,785", "levelname": "INFO", "message": "Closing market 1.186826857"}

... few more lines saying market cleared, then removed etc.```

---

## 2021-08-25 17:32:39 - general channel

**Peter**

Compared my stream to yours for this market. My last message was identical to your initial closure message with the exception of the __stream__id, which I believe is inserted by BFLW and isn't anything to do with Betfair and the timestamp (mine with 2 milliseconds later than yours. I didn't get a 2nd closure message.



This appears to support [@U4H19D1D2](@U4H19D1D2)'s hypothesis that it's a connection issue causing the whole market image to be resent.

---

## 2021-08-25 15:20:44 - general channel

**Pedro Lima Monteiro**

Was not using such example. Trying it as we speak.

Was using the plain streaming example one can find on the website.

I will post further feedback if I get the same/other errors.

Thanks a lot.

---

## 2021-08-25 15:12:14 - general channel

**liam**

any latency warnings before this? Are you using the error handling example? where are you located?

---

## 2021-08-25 15:04:35 - general channel

**Pedro Lima Monteiro**

Hi again.

So I managed to get the stream up and running with the addition of my proxy's IP.

However, after 30 minutes or so of being up, I got the following error:

`betfairlightweight.exceptions.SocketError: [Connect: 2]: Socket The read operation timed out`

After which the client was broken and I had to restart it.

Any ideas on how to avoid this problem? Or should I just accept it and try to restart it automatically?

Thanks.

---

## 2021-08-23 12:31:04 - general channel

**Steve**

Guess that's the fix - but it's frustrating not being able to find the underlying logic.

---

## 2021-08-23 08:39:09 - general channel

**liam**

Hard to debug this, would have thought you would want this code in `strategy.process_closed_market` as this will be once the market has closed

---

## 2021-08-23 08:36:53 - issues channel

**liam**

Is that giving you a critical error? I (and many) separate data recording and strategy instances to prevent this, regarding the dropouts just get a better connection :wink:

---

## 2021-08-23 07:17:56 - issues channel

**Adrian**

Is there an easy way to check if the market data recorded files are whole and complete? With all my connection dropouts there's probably more incomplete markets that I can filter out manually



Also, when backtesting, is this normal? ""Order has violated: MARKET_VALIDATION Error: Market is not open" this seems to be breaking it

Thanks

---

## 2021-08-22 13:42:25 - random channel

**thambie1**

What exactly is fixed PC? Just a higher commission rate?

---

## 2021-08-22 13:18:25 - random channel

**Mo**

Anyone on the fixed rate PC?

---

## 2021-08-21 23:37:13 - issues channel

**Jeff Waters**

Thanks Jack.



That's a valid point, but since I wrote my original code, I have added the check_market_book() method, after Lee pointed out that it was missing: [https://github.com/JeffW12345/betfair-backtester/blob/master/teststrategy.py#L26](https://github.com/JeffW12345/betfair-backtester/blob/master/teststrategy.py#L26). Thanks for the suggestion, though.



I wonder whether I need to invoke the FlumineBacktest class, given that it contains an error handling method that calls process_market_book? [https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/flumine/backtest/backtest.py#L141](https://github.com/liampauling/flumine/blob/6f0541d2ba57ab0cbf9389a560e9a41d1ad01cfc/flumine/backtest/backtest.py#L141)



I'm going to head in. Thanks for your help and patience, guys. :slightly_smiling_face: Night.

---

## 2021-08-21 23:20:53 - strategies channel

**Adrian**

So my big idea of 3 months work has failed. I've tried multiple angles to get it working. Feelsbadman. I don't know what I can salvage from it, apart from some knowledge of how machine learning works and the general idea bflw/flumine. And being able to read/write Python came from learning all this too.



It was an ambitious project and a cool idea but in the end just didn't work out how i intended. I'm not sure where to go from here, whether to pursue ML from a completely different angle or just drop it altogether and focus on execution. I have some ideas around execution that I've seen while manually "trading" but feel too deflated at the moment to bother.

---

## 2021-08-21 22:23:14 - issues channel

**Jeff Waters**

Hi Beeblebrox



There were bugs in the code in the process_market_book method, including the one you mentioned. Thanks for flagging that up.



However, it seems that the code in that method is not actually being called from anywhere. When I put a print command on the top line of that method, the print statement doesn't appear.



I'll have a look at it in the morning - I suspect this is a case where looking at things with fresh eyes would help! :slightly_smiling_face:

---

## 2021-08-21 21:08:47 - issues channel

**Beeblebrox**

Have you run it under the debugger to see what's happening?  I suspect one of the problems is because you're checking if `market.seconds_to_start == 60` and it never actually equals exactly 60.  I think there are probably other issues with what you've currently got, but that would be the first thing to look at using the debugger.

---

## 2021-08-21 12:49:01 - issues channel

**Jeff Waters**

Yes, I did, but the fact that there was a problem with the SSL didn't really give me much of a clue as to how to fix the problem (or indeed if I could fix it). :slightly_smiling_face:



Incidentally, I've tried re-creating the project using Conda as the virtual environment (as per [https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003511399-SSL-module-not-available-unable-to-install-packages?page=1#community_comment_360001528719|https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003511399-SSL-module-not-available-unable-to-install-packages?page=1#comm[…]28719](https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003511399-SSL-module-not-available-unable-to-install-packages?page=1#community_comment_360001528719|https://intellij-support.jetbrains.com/hc/en-us/community/posts/360003511399-SSL-module-not-available-unable-to-install-packages?page=1#comm[…]28719)), but now Betfair Lightweight and flumine don't appear in the list of available packages.



I'll also try your suggestion of installing the SSL package.



As I mentioned yesterday, I can run my code by going into the virtual environment via powershell, but it would be nice if I could find a way of running it directly from an IDE.



Cheers

---

## 2021-08-21 12:36:26 - issues channel

**Mo**

It’s impossible to ask this without sounding like an asshole but: did you read the error message?

---

## 2021-08-21 12:25:15 - issues channel

**Unknown**

Hi



I've tried installing flumine and Betfair Lightweight to my virtual directory via Pycharm, but I got error messages (see attached).



I'm using Python 3.8.



I'm just flagging this up in case it isn't a known issue.

---

## 2021-08-20 20:46:29 - general channel

**Jack**

Just added a fix for a memory leak

---

## 2021-08-20 20:26:14 - issues channel

**Jack**

That would be in the strategy Class. Example here of the order being created [https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/examples/strategies/lowestlayer.py#L57](https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/examples/strategies/lowestlayer.py#L57)

Your conditions will go in `process_market_book()` and it's up to you to bring into that whatever you need for your logic.

I'd recommend just taking a look at the LowestLayer example and if you know how, use the debugger in VSCode or Pycharm (other IDE's are available) to step through the code line by line. It's the best way to get a feel for what's actually happening.

---

## 2021-08-20 19:22:37 - issues channel

**PeterLe**

[@U013K4VNB6D](@U013K4VNB6D) I just read the posts above; if you're not using Pycharm, Id recommend it. Im new to python too, but it just seems easier to use, debug and visually more pleasing (its free too)

---

## 2021-08-20 15:38:33 - issues channel

**Jack**

On a `MARKET_BOOK` event, Flumine calls `_process_market_books()`  [https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/flumine.py#L26](https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/flumine.py#L26)



Then this calls `process_market_book()`  through an error handling function here as best I can tell [https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/backtest/backtest.py#L145](https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/backtest/backtest.py#L145)

---

## 2021-08-20 15:28:44 - general channel

**liam**

I do the latter (normally) and then just error handle any requests 

---

## 2021-08-20 12:32:24 - issues channel

**Jeff Waters**

Thanks Mo. I think that fixed it.



I followed those instructions. I wasn't able to run the program using the shell in IDLE:



&gt;&gt;&gt; python backtest.py

SyntaxError: invalid syntax



However, when I run the program by running 'powershell' in cmd, I now no longer get that error message.



Thanks also to everyone who has replied.

---

## 2021-08-20 12:08:08 - issues channel

**Jeff Waters**

No - unless it notices there is a virtual environment and does so automatically. I've tried running it without a virtual environment and get the same error message.



I wonder whether there is a gremlin somewhere on my computer that's causing this issue. It might be worth me using Google Colaboratory and see if I have any more joy running the program on their servers?

---

## 2021-08-20 11:08:34 - issues channel

**Jeff Waters**

I've just deleted my previous virtual environment, and set up a new one using Conda. I then tried to install flumine in it, but it thinks that it's already been installed:



*(flum) C:\Bet-Project-Code&gt;pip install flumine*

*Collecting flumine*

  *Using cached flumine-1.19.9-py3-none-any.whl (115 kB)*

*Collecting python-json-logger==2.0.2*

  *Using cached python_json_logger-2.0.2-py3-none-any.whl (7.4 kB)*

*Requirement already satisfied: requests in c:\users\water\anaconda3\envs\flum\lib\site-packages (from flumine) (2.25.1)*

*Collecting tenacity==8.0.1*

  *Using cached tenacity-8.0.1-py3-none-any.whl (24 kB)*

*Collecting betfairlightweight==2.13.1*

  *Using cached betfairlightweight-2.13.1-py3-none-any.whl (63 kB)*

*Requirement already satisfied: idna&lt;3,&gt;=2.5 in c:\users\water\anaconda3\envs\flum\lib\site-packages (from requests-&gt;flumine) (2.10)*

*Requirement already satisfied: certifi&gt;=2017.4.17 in c:\users\water\anaconda3\envs\flum\lib\site-packages (from requests-&gt;flumine) (2021.5.30)*

*Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in c:\users\water\anaconda3\envs\flum\lib\site-packages (from requests-&gt;flumine) (4.0.0)*

*Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in c:\users\water\anaconda3\envs\flum\lib\site-packages (from requests-&gt;flumine) (1.26.6)*

*Installing collected packages: tenacity, python-json-logger, betfairlightweight, flumine*

*Successfully installed betfairlightweight-2.13.1 flumine-1.19.9 python-json-logger-2.0.2 tenacity-8.0.1*



Also, I'm still getting the same error message. Any suggestions appreciated.

---

## 2021-08-20 10:38:59 - issues channel

**Jeff Waters**

Fair enough, thanks Jon.



I think I've now managed to successfully install flumine within the virtual environment. However, I'm still having the same error message as before.



I'm probably overlooking something blindingly obvious, but if anyone has any suggestions, they would be much appreciated. :slightly_smiling_face:

---

## 2021-08-20 08:52:03 - random channel

**Jeff Waters**

Interesting discussion on match fixing with an ex mafia boss: [https://www.youtube.com/watch?v=9uGfeivlVFo](https://www.youtube.com/watch?v=9uGfeivlVFo)

---

## 2021-08-20 08:36:05 - issues channel

**Jeff Waters**

Thanks Mandelbot.



What is the flumine bin?



I've just added 'import flumine' to my code, but I now get told:



  File "C:\Bet-Project-Code\backtest.py", line 9, in &lt;module&gt;

    import flumine

ModuleNotFoundError: No module named 'flumine'

---

## 2021-08-20 08:10:01 - issues channel

**Unknown**

Hi



I've written a program that imports flumine. However, when I try to run it, I get an error message:



*Traceback (most recent call last):*

  *File "C:\Bet-Project-Code\backtest.py", line 9, in &lt;module&gt;*

    *from flumine import BaseStrategy*

*ModuleNotFoundError: No module named 'flumine'*



I definitely have flumine installed, as when I go 'pip install flumine' via CMD, I get told that I have (see screenshot). Also, I've checked my Python version number using the powershell, and I am on version 3.8.10 (in case that's relevant).



What do you guys suggest?



Thanks in advance.



Jeff

---

## 2021-08-19 19:50:24 - issues channel

**Michael**

It's not like [@UBS7QANF3](@UBS7QANF3)'s saying anything outlandish that's how it works. If your operation is well designed and you don't hit any exceptional circumstances you can expect it to last a long time.



As far as markets changing goes - yes they change but usually gradually. There are occasional step changes like the introduction of cross-matching (I struggle to thing of a second example) and you get weird situations like the pandemic but generally it's a slow evolution.

---

## 2021-08-19 10:08:50 - issues channel

**Rach**

I am using betfairlightweight for Order Streaming, all working fine, but today I am not able to get the bets I place in 1 specific market... Has this happened to any of you? or should I dig in case I have a bug

---

## 2021-08-18 16:49:27 - issues channel

**Mo**

You got the error trying to download that much through the API? If so, try a smaller date range, like one month at a time

---

## 2021-08-18 16:32:59 - issues channel

**thambie1**

Website downloads can be flaky too in my experience. And it's quite painful when you're midway through a 5gb download and it fails. I'd suggest sticking with the API. I implemented some automated error catching and retries, which after many iterations works pretty flawlessly

---

## 2021-08-18 16:20:04 - issues channel

**Van**

Hitting an `ngErrorRedirect` when trying to using historic data API, anyone seen this?

---

## 2021-08-17 11:00:56 - strategies channel

**Van**

Would this be a viable strategy?

1. Use ML or other method to determine fixtures to predict high likelihood of one or both teams scoring.

2. If 0-0 at half time, lay the draw.

3. Trade out as soon as the first goal is scored.

---

## 2021-08-16 19:08:47 - general channel

**Raymond Heaton**

Thank you [@U02B9K2PFBN](@U02B9K2PFBN) for your post, its a good work around for the mean time. I got the same but with '4027' as the error.

---

## 2021-08-16 14:36:19 - issues channel

**liam**

Spoken to Neil and seems to be a known issue due to a security release this morning, not sure on when it will be fixed but it seems to be random (I haven't had any issues)

---

## 2021-08-16 11:04:08 - issues channel

**George**

I've started getting a lot of 'Connection reset by peer' errors this morning. I am using a script that logs in to the API at the start. Is it because I am failing to log-out when the script terminates? Or is it just a bad day at the BF servers

---

## 2021-08-16 10:51:18 - issues channel

**liam**

[@U01U24AG35W](@U01U24AG35W) this is now fixed in the latest releases, depending on the data package used, bflw:

```listener = StreamListener(

    calculate_market_tv=True,

    cumulative_runner_tv=True,

)```

flumine:

```strategy = LowestLayer(

    market_filter={"markets": markets, "listener_kwargs": {"calculate_market_tv": True, "cumulative_runner_tv": True}},

)```

---

## 2021-08-15 07:34:20 - general channel

**Peter**

[@UBS7QANF3](@UBS7QANF3) The plotly issues that I reported earlier may be due to a conflict in the version requirements for Flumine (5.0.3) and plotly (&gt;=6.2.0), which I now believe to be the source of the plotly errors that I encountered when running everything up in a fresh container.

---

## 2021-08-15 01:38:27 - issues channel

**AR**

Hi

I am trying to place my first set of bets through the API, using  BFLW, and am getting a failure response. The error code is:

placeBackBet(trading, market_id, selection_id, 5, min_odds)

Bet Place on selection 22511750 is FAILURE

```{'elapsed_time': 0.7760229110717773, '_datetime_created': datetime.datetime(2021, 8, 14, 22, 19, 1, 765910), '_datetime_updated': datetime.datetime(2021, 8, 14, 22, 19, 1, 765910), '_data': {'status': 'FAILURE', 'errorCode': 'BET_ACTION_ERROR', 'marketId': '1.186418033', 'instructionReports': [{'status': 'FAILURE', 'errorCode': 'INVALID_ODDS', 'instruction': {'selectionId': 22511750, 'limitOnCloseOrder': {}, 'orderType': 'LIMIT_ON_CLOSE', 'side': 'BACK'}}]}, 'market_id': '1.186418033', 'status': 'FAILURE', 'customer_ref': None, 'error_code': 'BET_ACTION_ERROR', 'place_instruction_reports': [&lt;betfairlightweight.resources.bettingresources.PlaceOrderInstructionReports object at 0x00000150A20C8DC0&gt;]}```

seems the error is INVALID_ODDS - however I have used code from the  github to do the rounding, and I can physically place bets on the

website using the price increments I have rounded to. Also, I can run this as a LIMIT order with no issues - so seems I am doing something wrong in specifying a Limit On Close. Does anyone have some example code of placing a LIMIT_ON_CLOSE order?

---

## 2021-08-14 14:26:56 - issues channel

**thambie1**

Does anyone know if there's a delay between transferring between wallets and having the money accessible to trade? I made a transfer almost an hour ago, yet still get INSUFFICIENT_FUNDS errors from the api when I go below the pre-transfer account value

---

## 2021-08-13 15:13:32 - general channel

**Jan**

Error: Widgets module plotlywidget is not supported

---

## 2021-08-13 10:05:36 - general channel

**Michael**

The error you shared earlier comes from a certificate error. I found it easier to create the certificates with OpenSSL rather than xca as I got these errors when I was using xca to generate certificates. I couldn't find the documentation which stated what the specific error meant, but got enough from google to understand it was certificates causing the problem.

---

## 2021-08-13 09:54:44 - general channel

**Jan**

[@U9JHLMZB4](@U9JHLMZB4) that issue is fixed in colab with mo's previous solution (selecting from the list), but that renders the cell empty

---

## 2021-08-13 09:07:50 - general channel

**Unknown**

Hi Mo Yes there must be some documentation online that explains these specific errors. Anyway you can still login without the certificate if you want to keep working on your code. Just use the `trading.login_interactive()`  function instead of  the `trading.loogin()`  function and comment out `certs=certs_path` in the

```betfairlightweight.APIClient( username=my_username,

password=my_password,

app_key=my_app_key,

#certs=certs_path

)    ```

 function. See screenshot image attached. Screenshot image is take from: [https://github.com/liampauling/betfair](https://github.com/liampauling/betfair)

---

## 2021-08-13 09:07:26 - general channel

**Unknown**

Hi Mo Yes there must be some documentation online that explains these specific errors. Anyway you can still login without the certificate if you want to keep working on your code. Just use the `trading.login_interactive()`  function instead of  the `trading.loogin()` * *function* *and comment out* *`certs=certs_path` in the

```betfairlightweight.APIClient( username=my_username,

password=my_password,

app_key=my_app_key,

#certs=certs_path

)    ```

* *function. See screenshot image attached. Screenshot image is take from: [https://github.com/liampauling/betfair](https://github.com/liampauling/betfair)

---

## 2021-08-13 08:34:39 - general channel

**Mo**

Looks like the same root cause even if the error code is different: some kind of problem with certificate generation

---

## 2021-08-13 08:13:18 - general channel

**Joe Fanning**

I'm having a similar problem:  except I'm getting 4046 instead of 4022:   SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4046)    Is there documentation online for fixing these errors?

---

## 2021-08-13 06:59:31 - general channel

**Mo**

[@U029JM0BJLB](@U029JM0BJLB) I've not used collab before but looks like uploaded gives you a dictionary of filename to file contents so you need to change the dashboard creation cell to something like `betfairviz.create_dashboard(list(uploaded.keys())[0])`. While this "works" in that there is no error and there is clearly some processing involved, the cell output is empty

---

## 2021-08-12 21:05:51 - general channel

**Jan**

One q to you though, what kind of market files are you passing in? I'm only doing soccer and only working with the pro files, they always throw an error when being parsed.

---

## 2021-08-12 10:28:01 - general channel

**ThomasJ**

I've been doing the Flumingo Tango and the Middleware step has my head in a complete spin. My dance partner is Ms Historical Data from the Backtest Lowestlayer school. :smile:



PART A

So a Trade/Order Package is created and placed in the backtest handler queue.

After the appropriate delay the code winds it's way down to `class Simulated &gt; def place &gt; elif available_to_lay &lt;= price` which is where the matched/not-matched decision is made.

If a match occurs then that order is not looked at again from a matching perspective. All good.



PART B

But if a match does not occur then that order has a size_remaining != 0 and Middleware takes an interest.

For every marketbook update, Middleware calculates RunnerAnalytics, and I will focus on 'traded'.

In `class RunnerAnalytics &gt; def _calculate_traded` the traded values are calculated as deltas compared to prior marketbook update (or empty {} if runner is not included in latest marketbook update).

After RunnerAnalytics, because `order.status == OrderStatus.EXECUTABLE` and `size_remaining != 0`, the code ends up in `class Simulated &gt; def _calculate_process_traded`, which is where I get totally bamboozled.



`_traded_size_ = _traded_size_ / 2`

        `if _self_._piq - _traded_size_ &lt; 0:`

            `size = _traded_size_ - _self_._piq`

            `size = round(min(_self_.size_remaining, size), 2)`

            `if size:`

`                _self_._update_matched(`

                    `[`

`                        _publish_time_,`

`                        _self_.order.order_type.price,`

                        `size,`

                    `]  # todo takes the worst price, i.e what was asked`

                `)`

`            _self_._piq = 0`

        `else:`

`            _self_._piq -= _traded_size_`

            `logger.debug(`

                `"Simulated order {0} PIQ: {1}".format(_self_.order.id, _self_._piq)`

            `)`



1. Why are unmatched orders not just left in the backtest handler queue to wait for a match, or of course killed after 2 secs?

2. No doubt there is a good answer for Q1 so can someone please explain how the trade deltas matching works in middleware.

---

## 2021-08-11 12:25:08 - random channel

**MacrcoPolo**

But plz someone who knows more plz fix me

---

## 2021-08-10 15:21:31 - general channel

**Jono**

bit of a strange one i would like to perform a single run of the logic in my "process_orders" function at the start of the flumine strategy run in order to perform some actions involving "EXECUTION_COMPLETE" orders. The reason being ive managed to get the logic of the strat im testing in a semi working condition and a large part of it involves placing follow up bets inside the process_orders func. However when im restarting the strat very often the orders that came before are matched and are therefore no longer causing this function to run. Additionally none of these bets are of the "EXECUTABLE" status so i cant rely on the 0.25s auto run. In essence this means no other follow up bets are placed for the strat. Any ideas how best to go about fixing this problem either through an initial sort of forced run of "process_orders" or otherwise? Cheers!

---

## 2021-08-09 18:57:04 - issues channel

**Aaron Smith**

If i recall correctly, basic data doesnt have volume information, which would be needed for a backtest, so that would surely thorw some errors

---

## 2021-08-09 18:54:08 - issues channel

**Aaron Smith**

[@U02AEDQ2KB8](@U02AEDQ2KB8) not sure if this is what causes the error, but a BASIC plan seems insufficient for backtesting. You would need pro data to simulate a real market

---

## 2021-08-09 18:34:43 - issues channel

**admiral**

Hi all, I'm trying to use historic data I've downloaded using the BASIC plan for soccer with FlumineBacktest and running into encoding errors, is this an issue other people have seen?

---

## 2021-08-09 16:25:58 - general channel

**thambie1**

Harder to read code, harder to debug, harder to guarantee it works as you expect, slower

---

## 2021-08-09 12:12:51 - random channel

**Oliver Varney**

[@U4H19D1D2](@U4H19D1D2) getting his Monday Caan fix :joy:

---

## 2021-08-06 15:52:15 - random channel

**liam**

Yeah I do a fair amount of frontend stuff, normally for POC or fixing other peoples shit :wink:

---

## 2021-08-06 12:40:49 - issues channel

**thambie1**

Flumine may not, Betfair certainly does! This is an error that the Betfair API would return, and flumine would surface

---

## 2021-08-05 00:59:52 - strategies channel

**Adrian**

[@UBS7QANF3](@UBS7QANF3) [@U4H19D1D2](@U4H19D1D2) this type of error Liam, it's obviously not something you can backtest for right? So would you only see the adjustments you need to make after a few weeks? Or any other strategies where backtesting isn't feasible, there must be some visual or statistical indication?

---

## 2021-08-04 14:17:21 - strategies channel

**Jono**

If a stream ending error is encountered during a flumine strategy, should restarting the same strategy in the same environment allow for it to pick up exisitng bets where it left off? for example i am currently holding a partially matched back position in a market and part of the strategy is to either lay this same selection/cancel remaining amount but a crash (not related to flumine) occurred. Im wondering how to incorporate this back bet into the strategy from the earliest point proceeding the restart, as previous testing i have performed have shown that flumine starts from a blank slate upon starting up again.



Additionally is it safe to open a seperate thread within process_market_book/process_orders or is this best to do with a background worker? Id like to send requests to a separate api every minute or so

---

## 2021-08-04 13:41:41 - strategies channel

**Mo**

So this handles the case when the order stream update comes in before the price update. One way to avoid the case where the price stream update comes in before the order update is to not make any decisions while you have orders in flight - do you do that?



Doing things this way also means you cannot treat a negative size after removing your orders as an error state and must rely on other protections to avoid you e.g. losing track of orders

---

## 2021-08-03 23:03:46 - issues channel

**Unknown**

Trying to get a file list of historic data and I keep getting the following error as well as JSON decode error. Is there any reason? I copied the code from the examples?

---

## 2021-08-03 09:46:30 - random channel

**liam**

But doesn't that then make error handling harder? As I assume its easy to send a null value through to a model but if the entire class is null you would have to handle?

---

## 2021-08-03 08:54:57 - general channel

**Mo**

I think it depends on your background and initial starting resources. I can see how it would have been a good move for you [@U01DCR5PXDY](@U01DCR5PXDY) but you are an exceptional case in my opinion :wink:

---

## 2021-08-03 08:53:24 - general channel

**Jonjonjon**

(Is it permitted to share recorded files here, for debugging purposes?)

---

## 2021-07-30 17:20:48 - issues channel

**Dirk**

It doesn't return anything, but also no error. Is there a way to check if it works?

---

## 2021-07-30 17:06:10 - issues channel

**Dirk**

I was trying to google and saw someone that got the exact same error in 2019 but no one replied to it

---

## 2021-07-30 17:05:00 - issues channel

**Dirk**

Yes I saw that and asked some people but either they also still had the error or they didn't use windows

---

## 2021-07-30 16:24:16 - issues channel

**Dirk**

Hey guys. A couple of days ago I tried to login to the API for the first time. I am using Python on windows and used XCA to make the certificates. At the moment of logging in, using the following code, I get an error:



`trading = betfairlightweight.APIClient(username=my_username,`

                                          `password=my_password,`

                                          `app_key=my_app_key,`

                                          `certs=certs_path)`

`trading.login()`



The error I get is (this is only the last part of the error code, it is way bigger than this):

`APIError: None` 

`Params: None` 

`Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4022)')))`



I've heard from others that it might have to do with the certificates, but I redid the full process like it is prescribed on the manual. Is there anyone with any tips/followup questions?

---

## 2021-07-30 16:15:17 - issues channel

**James McKenzie**

getting:



```betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders 

Params: {'betStatus': 'SETTLED', 'eventTypeIds': ['7'], 'settledDateRange': {'from': '2021-07-30T15:00:17.112414', 'to': '2021-05-01T15:00:17.112415'}} 

Exception: None 

Error: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang29b-prd-05120754-009afb31a1', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang29b-prd-05120754-009afb31a1', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}```

---

## 2021-07-30 09:17:24 - issues channel

**Andy B**

I had the same thing a couple of days ago.  Some markets don't have place betting and throw this same error when you try.  Is it possible that you tried to place a bet type that doesn't exist?

---

## 2021-07-29 19:59:01 - general channel

**liam**

This could be a bug where a previous cancel/update/replace was a violation although I think that was fixed recently 

---

## 2021-07-29 11:44:03 - general channel

**Steve**

I can try. I've never used the debugger before.

---

## 2021-07-29 11:39:42 - general channel

**Oliver Varney**

hmm, can you replicate it and log / view through the debugger?

---

## 2021-07-29 11:37:26 - general channel

**Oliver Varney**

the issue it seems is the status of the order if that the line code throwing the exception. Is the bet still unmatched in the market?

---

## 2021-07-29 11:03:41 - random channel

**Mo**

What do you mean “stuck”? What’s the error message?

---

## 2021-07-29 10:26:29 - general channel

**Oliver Varney**

I think the message on the raise could be a little clearer, maybe raise OrderUpdateError(f"Incorrect order status : {self.status}. Only orders with status: {OrderStatus.EXECUTABLE} can be cancelled")

---

## 2021-07-29 10:02:12 - issues channel

**Adrian**

[@UBS7QANF3](@UBS7QANF3) i am getting this error:

``` if \"Pace\" in market.market_catalogue.market_name:\nAttributeError: 'NoneType' object has no attribute 'market_name'"}```

---

## 2021-07-29 08:23:51 - general channel

**Steve**

If you have any order which has been placed on the exchange and is Executable but has a VIOLATION status - how do you cancel it from the exchange? I keep getting this error:

raise OrderUpdateError("Current status: %s" % self.status)

flumine.exceptions.OrderUpdateError: Current status: OrderStatus.VIOLATION

---

## 2021-07-29 04:07:25 - issues channel

**Adrian**

Anyone know how I can check the market name? I put `market_data_filter = streaming_market_data_filter(`

        `fields=["EX_MARKET_DEF", "EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP"]`

    `)`

and tried to fetch it with

`market_book.market_definition.event_name`

but I am getting None error. What is the correct command to get the market name?

---

## 2021-07-28 16:02:54 - general channel

**Michael**

Has anyone managed to get their certs working on a MAC? I can create working certificates on windows with xca and openssl on but when I try to create one with either  openssl or xca on mac I keep getting certificate errors when loading them in the api. Is there any additional steps I'm missing (bar changing the cetificates uploaded on betfair) ?

---

## 2021-07-26 23:13:37 - general channel

**Unknown**

Hi [@UBS7QANF3](@UBS7QANF3), thanks for your reply. I changed 3 things in the script (so I used the downloaded script and didn't add my own strategy): 1) added `from multiprocessing import Process, freeze_support` at the top; 2) added

```if __name__ == '__main__':

    freeze_support()```

at line 65; and 3) pointed `root_folder` to my data folder with the 3 bz2 files and removed (at line 77 ) `if x.endswith('.bz2')` . The error message I have from pycharm is:

`The above exception was the direct cause of the following exception:`



`Traceback (most recent call last):`

  `File "C:\betfair\API\bf_betting\backtest_multi_orig.py", line 96, in &lt;module&gt;`

    `all_dfs.append(future.result())`

  `File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\concurrent\futures\_base.py", line 438, in result`

    `return self.__get_result()`

  `File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\concurrent\futures\_base.py", line 390, in __get_result`

    `raise self._exception`

`UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 41: character maps to &lt;undefined&gt;`



If I switched to the folder with decompressed files, it is working fine (placing orders from the laylowest example strategy). So I asssume the file format/compression is the problem (I could well be wrong). Any pointers will be highly appreciated.

---

## 2021-07-26 20:39:04 - general channel

**liam**

Why does it look like that (float)? Is this a flumine bug?

---

## 2021-07-26 20:14:09 - general channel

**Matthieu Labour**

Here is my use case. On disk, I have market book data that look like `{"op": "mb", "clk": null, "pt": 1626986519.301084, "mc": [{"id": "1.185558123..."` . Please, do note pt. When replaying them w/ flumine/backtest, `publish_time` will be None [https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py#L587](https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/bettingresources.py#L587). I tested the change above and it fixes the issue.

---

## 2021-07-26 18:31:17 - general channel

**Matthieu Labour**

Would you be open that I open a PR with the following code change to [https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/baseresource.py#L23](https://github.com/liampauling/betfair/blob/master/betfairlightweight/resources/baseresource.py#L23)

Add the following

```        elif isinstance(value, numeric_types):

            try:

                return datetime.datetime.utcfromtimestamp(value)

            except (ValueError, OverflowError, OSError):

                return```

---

## 2021-07-25 23:35:18 - general channel

**Unknown**

Hi [@U012ZFYR19V](@U012ZFYR19V) and [@UPMUFSGCR](@UPMUFSGCR), it took me a while to make the backtest_multi.py work for me, but so far it's looking great, so thanks very much! I needed to add "`freeze_support()`" to make it work, otherwise it throws an error. I am not able to plug in the bz2 files directly (I got error message like "`UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 41: character maps to &lt;undefined&gt;`"), so have to decompress them manually. Guess I am missing something. Please could you give me a pointer?

---

## 2021-07-25 16:41:34 - general channel

**Oliver Varney**

Learning again :man-facepalming:. Id though the default would be False if its advisable to be off or am I thinking about it the wrong way round. Does anything need setting in flumine then. Its this just the raw stream logging, i.e. if listener_kwargs dict debug is false will the order logging continue ? currently  im not setting anything

---

## 2021-07-25 16:19:48 - general channel

**liam**

But yeah don’t debug in prod 

---

## 2021-07-25 16:19:26 - general channel

**liam**

There is also a [https://github.com/liampauling/betfair/blob/6991a6a51363bae5fe5940f647b5cf7a4e7113cb/betfairlightweight/streaming/listener.py#L95|flag](https://github.com/liampauling/betfair/blob/6991a6a51363bae5fe5940f647b5cf7a4e7113cb/betfairlightweight/streaming/listener.py#L95|flag) on the listener as well to completely remove the overhead, even though debug might be disabled there is a cost in sending a large dict to the debug call 

---

## 2021-07-25 16:14:55 - general channel

**Mo**

Unless you've set the log level to debug for betfairlightweight it's not being logged anyway

---

## 2021-07-25 16:05:51 - general channel

**liam**

So that logging call is for debugging the raw messages that come through the steam 

---

## 2021-07-25 16:03:56 - general channel

**George**

sorry not sure what that means. it's where the logger debug call is made so that is what determines where the messages are written to.

---

## 2021-07-24 20:36:10 - general channel

**liam**

That’s odd the only way you would get that error is if the order is not executable but you have an if statement handling that although it looks like it isn’t actually in the if? Or has the formatting on the message fucked it?

---

## 2021-07-24 11:41:28 - general channel

**Jono**

Is flumine set up to be able to pick up orders already placed in the event of a stream ending error? Similarly is there a way of using it to process generic orders placed ie bets placed through the api not placed using flumine for a strategy or those placed on the exchange manually

---

## 2021-07-24 11:34:24 - general channel

**Jono**

Traceback (most recent call last):

pythonbbauto-skrimming_1  |   File "/usr/local/lib/python3.9/site-packages/flumine/utils.py", line 233, in call_process_orders_error_handling

pythonbbauto-skrimming_1  |     strategy.process_orders(market, strategy_orders)

pythonbbauto-skrimming_1  |   File "/usr/src/app/syndicate_middleware/syndicateMiddlewareMain.py", line 232, in process_orders

pythonbbauto-skrimming_1  |     market.cancel_order(order)

pythonbbauto-skrimming_1  |   File "/usr/local/lib/python3.9/site-packages/flumine/markets/market.py", line 84, in cancel_order

pythonbbauto-skrimming_1  |     return t.cancel_order(order, size_reduction)

pythonbbauto-skrimming_1  |   File "/usr/local/lib/python3.9/site-packages/flumine/execution/transaction.py", line 69, in cancel_order

pythonbbauto-skrimming_1  |     order.cancel(size_reduction)

pythonbbauto-skrimming_1  |   File "/usr/local/lib/python3.9/site-packages/flumine/order/order.py", line 314, in cancel

pythonbbauto-skrimming_1  |     raise OrderUpdateError("Current status: %s" % self.status)

---

## 2021-07-24 11:19:51 - general channel

**liam**

What errors you getting? 

---

## 2021-07-24 09:22:41 - general channel

**Jono**

i was wondering the best way/practice to cancel any unmatched bets on a market using flumine? The reason i am asking is that although i am aware that the runner context should only allow 1 active bet per market per selection, upon running the strategy i am currently testing out it seems to place another order. Thus i would like to cancel the unmatched bet placed previously by the strategy so i dont unnecessarily increase my exposure whilst getting to grips with flumine. Below is the codfe i belived should have cancelled any outstanding orders i have but this is causing errors at "market.cancel_order(order)". Any help very much appreciated thank you!



`def process_orders(self, market, orders):`

`        [http://logging.info|logging.info](http://logging.info|logging.info)("Processing orders: %s"%(orders))`

        `for order in orders:`

`    `

            `try:`

`                [http://logging.info|logging.info](http://logging.info|logging.info)("Order: %s"%(order.__dir__))`

                `for key, value in order.__dict__.items():`

`                    [http://logging.info|logging.info](http://logging.info|logging.info)("%s : %s"%(key, value))`

            `except:`

`                [http://logging.info|logging.info](http://logging.info|logging.info)("Couldn't log order dict in method above")`





            `if order.status == OrderStatus.EXECUTABLE:`

`                [http://logging.info|logging.info](http://logging.info|logging.info)("Order executable")`



            `market.cancel_order(order)`                

`            `

`            [http://logging.info|logging.info](http://logging.info|logging.info)("Order cancelled supposedly")`

---

## 2021-07-23 08:16:11 - issues channel

**Oliver Varney**

Union[Generator[List[dict]], None],None] ? Edit: actually maybe not as I guess the file opening is not handled and would just throw an error technically.

---

## 2021-07-22 15:33:36 - random channel

**Oliver Varney**

is it possible for someone to pull the funds from their betfair account before an incorrect settlement is fixed ?

---

## 2021-07-22 07:48:48 - issues channel

**liam**

If you can share more on the error / something, might be able to debug the issue but it seems like it’s your network 

---

## 2021-07-21 09:05:23 - issues channel

**liam**

Can you message me the full error?

---

## 2021-07-21 09:03:06 - issues channel

**liam**

looked like an error in the worker, thats handled

---

## 2021-07-21 09:02:52 - issues channel

**Adrian**

&gt; \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/betting/json-rpc/v1 (Caused by NewConnectionError('&lt;urllib3.connection.HTTPSConnection object at 0x7fc7002636a0&gt;: Failed to establish a new connection: [Errno 65] No route to host'))"}

---

## 2021-07-21 09:02:01 - issues channel

**Adrian**

hmm the dropout error is too big

---

## 2021-07-20 14:18:41 - issues channel

**Luka**

[@UPMUFSGCR](@UPMUFSGCR) I am running it on AWS so the errors I am getting are just those things I create print statements for. I have a version of the code that I can run locally, which may help me with debugging

---

## 2021-07-20 11:22:59 - issues channel

**Jonjonjon**

Is there more error information order than FAILURE?

---

## 2021-07-20 11:21:19 - issues channel

**Luka**

Hi there, just joined the Slack channel - but having been using betfairlight for some time now. I m having some good success with the bot that I have built, but my bets are only getting placed every now and then. I have just found out about `order.status` which is very helpful, as I previously had no visibility there.



I am getting a response of FAILURE on some of the bets that I am placing. I have double checked that the `market_id` is correct by checking the website for that market. I am not sure how to double check that the `selection_id` is correct though.



Does anyone else have any tips for debugging this FAILURE and figuring out why it is happening? The strange thing is that some of my bets are being placed, so the script definitely works some of the time.

---

## 2021-07-20 07:44:15 - general channel

**Greg**

Hi all. I have a simple issue that is driving me (chemo brain :slightly_smiling_face: )  nuts. the bot I have written is going ok from a functionality perspective but I am curious about the replace_order method. I have a cpl of questions but here is the code :

```def process_orders(self, market, orders: list) -&gt; None:

    for order in orders:

        if order.status == OrderStatus.EXECUTABLE:

            if order.elapsed_seconds and order.elapsed_seconds &gt; 5:

                if order.size_matched == 0:

                    market.replace_order(order, new_price=1.02)```

[1.]Can the new_price= be supplied with a variable (defined earlier in another function (I can't seem to get this to work anyway (unresolved reference error)but was curious re syntax violation or something)? e.g. new_price=best_lay_price (or other variable name). [2]. Does the replace order simply take the existing order and try again with the same stake at the new price(assume it does but just checking) [3.] How do you update the new_price to be at the best lay price or best back price (is this possible) ? .Thanks and apologies for the numpty coder here but I've hit the wall on an otherwise nice little bot (thanks Liam for this platform-its great). Cheers

---

## 2021-07-17 09:51:17 - general channel

**Oliver Varney**

could you not run it in debug mode and just stick breakpoints in if your looking to review the current state (whilst testing)?

---

## 2021-07-17 09:38:52 - general channel

**Jonjonjon**

If the place is sent before the cancel is confirmed, could there be a chance that both get filled? If so, that could be the cause.



There used to be a bug in exposure calculation when backing and then laying, but it was fixed a few months ago.

---

## 2021-07-16 16:24:50 - issues channel

**Jono**

im receiving an odd error when trying to place a LAY bet on an upcoming football game on the standard "MATCH_ODDS" market regarding its persistence type. Im getting this error: " 'errorCode': 'INVALID_PERSISTENCE_TYPE' " which is strange because im passing exactly this string "PERSIST" as the persistence parameter.  additionally the same code has successfully placed bets with this persistence type many times previously both today and the past few weeks. Any idea why this might be causing problems now?

---

## 2021-07-16 11:04:13 - general channel

**river_shah**

betfair down:

```betfairlightweight.exceptions.LoginError: API login: INTERNAL_ERROR```



---

## 2021-07-15 12:40:13 - issues channel

**Mo**

Sorry I am not a Windows user so can’t help you with the specifics of the generation but the error message definitely suggests this is the problem. Hopefully someone else who has successfully generated certificates on Windows can help you further 

---

## 2021-07-15 12:26:23 - issues channel

**Unknown**

Hi everyone, may I ask a question here ? Following the git advice, I am setting up the account. It comes this error.

---

## 2021-07-13 22:13:59 - strategies channel

**Michael**

In my experience (more than a decade at this) you don't suddenly get caught. Markets evolve but not faster than you can adapt to them. Obvious exceptions for new technology or whatever but in the normal run of things it all stays quite still.

---

## 2021-07-13 17:14:12 - random channel

**Newbie99**

[https://nypost.com/2021/07/13/wimbledon-being-investigated-for-alleged-match-fixing/?utm_medium=SocialFlow&amp;utm_source=NYPTwitter&amp;utm_campaign=SocialFlow|https://nypost.com/2021/07/13/wimbledon-being-investigated-for-alleged-match-fixin[…]medium=SocialFlow&amp;utm_source=NYPTwitter&amp;utm_campaign=SocialFlow](https://nypost.com/2021/07/13/wimbledon-being-investigated-for-alleged-match-fixing/?utm_medium=SocialFlow&amp;utm_source=NYPTwitter&amp;utm_campaign=SocialFlow|https://nypost.com/2021/07/13/wimbledon-being-investigated-for-alleged-match-fixin[…]medium=SocialFlow&amp;utm_source=NYPTwitter&amp;utm_campaign=SocialFlow)

---

## 2021-07-10 18:35:42 - general channel

**Michael**

I'm trying to use bfwl for the first time, whilst trying to login I get the following error "HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:4024)')))". I presume this is coming from the certs being incorrect, I followed the xca certificate generation, has anything changed on this that I'm missing? [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA)

---

## 2021-07-08 19:39:33 - random channel

**D C**

Maybe a bot error submitting lots of bets at 2.0 in quick succession with failure to check that they were already placed? Seems to have fat fingered the entire ladder and then kept on going.

---

## 2021-07-08 14:47:47 - issues channel

**Matthieu Labour**

Hi, [https://github.com/liampauling/flumine/blob/master/flumine/utils.py#L50](https://github.com/liampauling/flumine/blob/master/flumine/utils.py#L50). Could we test for the case where `mc` does not exist and `marketDefinition` does not exist so that we ignore the line as opposed to throw an exception? Happy to contribute a PR if you are ok with the change.

---

## 2021-07-08 10:38:59 - general channel

**Ivan Zhou**

not sure if I am doing something wrong im running

```import logging



import betfairlightweight





# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (don't need username/password)

trading = betfairlightweight.APIClient("username", "password")



# race card login

trading.race_card.login()

# update

market_id = "1.185112813"



# race card request (provide list / returns list)

race_cards = trading.race_card.get_race_card(market_ids=[market_id])

print(race_cards)```

---

## 2021-07-08 08:44:21 - issues channel

**Jonjonjon**

I'm trying to work out how to assess whether or not there's a bug in my code, or whether I genuinely only received a single update for that market.

---

## 2021-07-08 08:40:07 - issues channel

**Jonjonjon**

I'm trying to debug my local version of the marketrecorder.

For 1.184990419, I only have 1 row of data. For other files, I usually get a zip file when they close. Do other uses running that script have more than 1 line for that market?

---

## 2021-07-07 12:16:01 - general channel

**Neil T (Betfair)**

Yes, if a non-virtual update results in a corresponding virtual update calculated by the cross-matching algorithm.  Exception would be if cross-matching wasn't active on a market (this would be signified by the crossMatching bool field returned via the MarketDefiniton in the Stream API or listMarketBook.

---

## 2021-07-07 11:18:50 - random channel

**James**

Thanks Peter. I'm beginning to think there's an issue with yahoo as this throws an error.

---

## 2021-07-07 07:54:20 - random channel

**Peter**

Your code as written should be returning a "TypeError: fetch() got an unexpected keyword argument 'date_gte'" message. Query style search criteria need to be wrapped in an AND, OR or NOT function. This works for me



```from imap_tools import AND

...

for msg in mailbox.fetch(AND(date_gte=datetime.date(2021, 6, 1))):```

---

## 2021-07-05 22:39:50 - random channel

**Newbie99**

Is there a way to delay Middleware adding a market until the market catalogue has been updated?



This (as always) is very niche...but some markets (e.g. [https://www.betfair.com/exchange/plus/politics/market/1.160740937|1.160740937](https://www.betfair.com/exchange/plus/politics/market/1.160740937|1.160740937)) runners can be settled, whilst the market remains active. The middleware appears to be pulling in some orders on a runner that has been settled in the Betfair GUI, so the exposure is showing incorrectly.



I tried to filter out orders for runners where runner.status != 'ACTIVE' and this appeared to work, but then I noticed it quite often errored as the market_book hasn't always loaded into the market.



I thought it would be a simple sleep(x) but that doesn't appear to work as presumably all it does is stop the Framework kicking off in the first place for x seconds.



So, is this possible and I'm missing the obvious way to delay it, or is it simply not doable?

---

## 2021-07-04 12:23:52 - strategies channel

**PeterLe**

Thanks [@UUE6E1LA1](@UUE6E1LA1) thats interesting. I do think that peoples backgrounds and normal MO's do have a big part to play in this. Ive never used backtesting (until very recent) and although Ive not reached the lofty heights that some on here have, Ive been very successful.  Back in the 80's and 90's I worked on some very large computer systems and we were taught a process called kepner tregoe (I think NASA used it too), which we used in trouble shooting to define the problem before beginning to fix it. Some of the large computer systems had hundreds of modules in them and quite often you could spend many hours just defining the problem. I still use some of those techniques that ingrained in me even today.

I think if I could distil why some people are successful and not others, it is the way people see the problem and the task to be solved. They merely think differently

---

## 2021-07-04 11:03:03 - strategies channel

**D C**

I agree [@UPMUFSGCR](@UPMUFSGCR) but you don't buy a book, read the first chapter then start another one do you? MAybe the book is crap but you won't know until you finish it. It's a risk you take. You can't possibly know something is shite before you experience it first hand. I've said I spent ages trying to force MACD to "work" with no success. Maybe someone else has but I have no idea. Point is that nobody successful is going to tell him exactly where to look or what to do. I mean look at BFLW/flumine for example - I don't use it myself, but the existence of this is saving people literally hundreds of hours in itself. Not just the labour required to write that software, but the many additional hours debugging it so that people can now use it safe in the knowledge that it is reliable for the task. Fact is that it is not easy and spending a day on an idea before discarding it is not a route to success unless you get VERY lucky indeed. Just my opinion.

---

## 2021-07-03 10:42:20 - issues channel

**Adrian**

Could someone tell me where would be the appropriate place to insert a resource intensive algo into flumine? I tried placing it in process_market_book but that led to this error: "WARNING", "message": "High latency between current time and MarketBook publish time". Thanks!

---

## 2021-07-02 23:46:29 - general channel

**ShaunW**

Thx all, same here, stand back and the differences melt away.  I'll leave it alone I think. I don't like introducing exceptions unless I can see some sort of real world reason for them.

---

## 2021-07-02 15:19:00 - general channel

**ShaunW**

Question to fans of the dishlickers, is there anything inherently different about morning dog racing? Time of day isn't something I'd usually factor in but for dogs, I might reluctantly have to. Getting the morning and the rest of the day to look similar resultswise has been like sqeezing a balloon, fix one part and another part bulges out of shape. The only thing I can think of is that you need to be pretty hardcore or not have much of a life to bet on the morning dogs, so maybe the significant participants have a different profile and it affects the overall behaviour? Is it to do with race quality? Maybe there's no difference and my issue is somewhere else. Any thoughts or similar experience?

---

## 2021-07-01 22:05:11 - strategies channel

**AndyL**

hi [@UEA14GBRR](@UEA14GBRR) sorry been busy with day job today! So when I said height i meant it, so my spike if thats what we call it, is defined as any change in midprice after 10seconds. Then using the methods [@UBS7QANF3](@UBS7QANF3)  [@U4H19D1D2](@U4H19D1D2) [@UGV299K6H](@UGV299K6H) suggested i analyse across the whole dataset returns vs spike height, then returns vs seconds from start,  then returns vs wom, then returns vs selection volume change over 10seconds, then....etc. The main "fix" is the 10seconds, although I have tried several variations on that, but it's a bit trickier to compare that one. From all these orthogonal variables i plot graphs to visualise affect vs returns...

I think you probably do similar i am sure...

Anyway ive made some progress this evening, wom variable helping [@U01PQ9SR9MJ](@U01PQ9SR9MJ) and ill plod on...but no late nights for me!

Cheers

---

## 2021-06-28 12:33:22 - random channel

**Matthieu Labour**

I came across this BBC podcast about Tennis Fixing. [https://www.bbc.co.uk/sounds/play/p03g25cn](https://www.bbc.co.uk/sounds/play/p03g25cn).

---

## 2021-06-28 09:27:44 - issues channel

**liam**

:joy:  debugger is your friend!

---

## 2021-06-28 09:26:58 - issues channel

**liam**

ie `runner.sp.actual_sp` quick look at the resource using the debugger would tell you straight away

---

## 2021-06-28 07:20:10 - issues channel

**Adrian**

```order_type=LimitOrder(lay, self.context[\"stake\"]),\nKeyError: 'stake'"}```

I get this error when running lowest layer. Is "stake" supposed to be declared somewhere in the strategy?

---

## 2021-06-27 22:28:11 - strategies channel

**D C**

You can fit linear regression to any data but it might not be the right thing to do. You can take data from a quadratic curve and fit a straight line to it but there is no point because it isn't linear. You can solve for the parameters of gradient and intercept that minimise the error but that line is as much use as a waterproof teabag when it comes to describing your data points.

---

## 2021-06-25 16:12:50 - random channel

**Mo**

I don’t use flumine but I can’t think of a reason why the format would have changed. I am thinking you had a connection issue or something that caused a partial json object to be output or some such. If you could work out the file (just put a print statement somewhere indicating which file is being processed) then you could examine the file for obvious errors like these

---

## 2021-06-25 16:11:12 - random channel

**PeterLe**

Im not sure [@UBS7QANF3](@UBS7QANF3) It doesnt provide enough detail in the error message. Should files recorded in that period (july 2019) work ok with the latest version of Flumine, if so, Ill work through it. Thanks

---

## 2021-06-25 16:02:36 - random channel

**PeterLe**

Folks quick question please: Im running a backtest on some recent recorded data and all is well (but I only have 229 Markets) , yet when I also try to run it some old recorded markets (I have more data from this period - around July 2019) I get an error such as this:

 raise JSONDecodeError("Extra data", s, end)

json.decoder.JSONDecodeError: Extra data: line 2 column 1 (char 1508)



Im just wondering has the structure changed somehow or is it an error in my code?  Ie has the data that Flumine records changed in any way?) Thanks in advance

---

## 2021-06-25 15:49:14 - strategies channel

**Michael**

I'm not saying it's not useful, just that I think you have to ask yourself what you're hoping to get from it and that I think forecasting your profits is a poor application. It's better applied to (say) the optimisation of execution prices, in which case you're comparing back-test to back-test and the comparison between real and simulated results doesn't really arise.



Certainly the type of strategy will make a difference to how simulated and real results compare but even if the simulated matching was perfect it and couldn't possibly accommodate your effect on the market. Every participant alters the market and the more you're betting the bigger your effect. Although overfitting is a separate issue it's worth remembering that even a perfect matching simulation will do absolutely nothing to help you with that. For most newer players the over-fitting errors are likely to eclipse anything to do with simulated matching.

---

## 2021-06-25 10:17:09 - general channel

**flxbe**

I noticed that the flumine stream implementation uses two threads per stream:

1. The stream itself (MarketStream or OrderStream), since it subclasses threading.Thread

2. The output_thread within the stream, which pipes the updates into the flumine handler_queue

I am trying to understand the reasons for this design decision. Are there any benefits e.g. regarding error handling I am not seeing?

---

## 2021-06-25 10:04:27 - random channel

**azevedo**

[@UBS7QANF3](@UBS7QANF3) another match fix?

---

## 2021-06-24 10:37:31 - general channel

**liam**

Error is telling you the problem

---

## 2021-06-24 10:36:37 - general channel

**Adrian**

[@UBS7QANF3](@UBS7QANF3) I am getting this error: ModuleNotFoundError: No module named 'strategies'

Any ideas?

---

## 2021-06-23 10:44:39 - issues channel

**Newbie99**

I tried replicating, with the replacement price lower than the best back price, but that produces a 'BET_LAPSED_PRICE_IMPROVEMENT_TOO_LARGE' and it works fine, the above is slightly different, in that its a BET_TAKEN_OR_LAPSED error I need to replicate, which is tough! I'll create a placeholder issue and will add if I can come up with more/better info.

---

## 2021-06-23 09:29:51 - issues channel

**Newbie99**

[@U4H19D1D2](@U4H19D1D2) I've noticed something else about the Replace function (I'm guessing most people just cancel and place a new order, which perhaps I should do!), below the replace fails as the bet has already had an action on it, that error makes sense, however after this the order is never removed from the blotter and the status remains as OrderStatus.REPLACING until I kill the process. This of course means no further orders can be placed on this runner as the blotter thinks there is 1 order remaining. This is obviously a pretty rare occurrence, but I've noticed it a few times and I think the below shows the process flow, but at the end presumably a better outcome would be that the order is removed (i.e. set to EXECUTION_COMPLETE) instead?



This is going to be very tricky to replicate, but if you agree its a bug I'll raise an issue (this is in live btw not simulation).



```{"asctime": "2021-06-22 18:50:10,695", "levelname": "INFO", "message": "execute_replace", "trading_function": "replace", "elapsed_time": 0.05340576171875, "response": {"customerRef": "abcf9b20d38a11ebbbac02054918c7c6", "status": "FAILURE", "errorCode": "BET_ACTION_ERROR", "marketId": "1.183248116", "instructionReports": [{"status": "FAILURE", "errorCode": "BET_TAKEN_OR_LAPSED", "cancelInstructionReport": {"status": "FAILURE", "errorCode": "BET_TAKEN_OR_LAPSED", "instruction": {"betId": "236404314713"}}, "placeInstructionReport": {"status": "FAILURE", "errorCode": "RELATED_ACTION_FAILED"}}]}, "order_package": {"id": "abcf9b20-d38a-11eb-bbac-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f148822e790&gt;", "market_id": "1.183248116", "orders": ["236404314713"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}

{"asctime": "2021-06-22 18:50:10,701", "levelname": "INFO", "message": "Trade status update: Pending", "id": "511443a4-d388-11eb-bbac-02054918c7c6", "strategy": "politics_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["236404314713"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Pending", "status_log": "Pending, Live, Pending, Live, Pending, Live, Pending"}

{"asctime": "2021-06-22 18:50:10,707", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.183248116", "selection_id": 5191378, "handicap": 0.0, "id": "236404314713", "customer_order_ref": "3203239236f2d-236404314713", "bet_id": "236404314713", "date_time_created": "2021-06-22 18:33:19.422805", "publish_time": null, "trade": {"id": "511443a4-d388-11eb-bbac-02054918c7c6", "strategy": "politics_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["236404314713"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Pending", "status_log": "Pending, Live, Pending, Live, Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 1000.0, "size": 0.09, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.09, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Executable", "status_log": "Executable, Replacing, Executable, Replacing, Executable, Replacing, Executable, Replacing, Executable", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}

{"asctime": "2021-06-22 18:50:10,718", "levelname": "INFO", "message": "Order status update: Replacing", "market_id": "1.183248116", "selection_id": 5191378, "handicap": 0.0, "id": "236404314713", "customer_order_ref": "3203239236f2d-236404314713", "bet_id": "236404314713", "date_time_created": "2021-06-22 18:33:19.422805", "publish_time": null, "trade": {"id": "511443a4-d388-11eb-bbac-02054918c7c6", "strategy": "politics_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["236404314713"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Pending", "status_log": "Pending, Live, Pending, Live, Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 1000.0, "size": 0.09, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.09, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Replacing", "status_log": "Executable, Replacing, Executable, Replacing, Executable, Replacing, Executable, Replacing, Executable, Replacing", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "", "market_notes": null}

{"asctime": "2021-06-22 18:50:10,718", "levelname": "INFO", "message": "Trade status update: Live", "id": "511443a4-d388-11eb-bbac-02054918c7c6", "strategy": "politics_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["236404314713"], "offset_orders": [], "notes": "", "market_notes": null, "status": "Live", "status_log": "Pending, Live, Pending, Live, Pending, Live, Pending, Live"}

{"asctime": "2021-06-22 18:50:10,719", "levelname": "INFO", "message": "Thread pool submit", "trading_function": "execute_replace", "session": "&lt;requests.sessions.Session object at 0x7f144b600050&gt;", "latency": 0.0001, "order_package": {"id": "abdbd200-d38a-11eb-bbac-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f148822e790&gt;", "market_id": "1.183248116", "orders": ["236404314713"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}, "thread_pool": {"num_threads": 32, "work_queue_size": 1}}

{"asctime": "2021-06-22 18:50:10,719", "levelname": "CRITICAL", "message": "Execution unknown error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/execution/betfairexecution.py\", line 243, in _execution_helper\n    response = trading_function(order_package, http_session)\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/execution/betfairexecution.py\", line 214, in replace\n    instructions=order_package.replace_instructions,\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/orderpackage.py\", line 152, in replace_instructions\n    return [order.create_replace_instruction() for order in self]\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/orderpackage.py\", line 152, in &lt;listcomp&gt;\n    return [order.create_replace_instruction() for order in self]\n  File \"/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/order.py\", line 394, in create_replace_instruction\n    bet_id=self.bet_id, new_price=self.update_data[\"new_price\"]\nKeyError: 'new_price'", "trading_function": "replace", "exception": "'new_price'", "order_package": {"id": "abdbd200-d38a-11eb-bbac-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f148822e790&gt;", "market_id": "1.183248116", "orders": ["236404314713"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}}

{"asctime": "2021-06-22 18:50:10,719", "levelname": "INFO", "message": "1 order packages executed in transaction", "market_id": "1.183248116", "order_packages": [{"id": "abdbd200-d38a-11eb-bbac-02054918c7c6", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f148822e790&gt;", "market_id": "1.183248116", "orders": ["236404314713"], "order_count": 1, "package_type": "Replace", "customer_strategy_ref": "ip-172-31-4-105", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0, "async": false}], "transaction_id": 10}

{"asctime": "2021-06-22 18:50:10,722", "levelname": "INFO", "message": "Deleting requests.Session", "sessions_created": 14, "session": "&lt;requests.sessions.Session object at 0x7f144b600050&gt;", "session_time_created": 1624387784.7466655, "session_time_returned": 1624387810.701893, "live_sessions_count": 0, "err": true}```



---

## 2021-06-23 07:53:49 - general channel

**PeterLe**

[@U01S1VB9X9P](@U01S1VB9X9P) I may be wrong, but Im sure I had this error at one point; could it be two step auth??

---

## 2021-06-23 01:42:31 - general channel

**Adrian**

Hi - hope this is the right place to ask. Don't want to fill up the chat with my newbie questions. I have an active login with BFLW as per:

`trading.session_expired`

```False```

But when I run the example Flumine strategy as per:

`framework.run()`

```LoginError: API login: CERT_AUTH_REQUIRED```

That's the error I get. Is there a separate login class or function I'm not aware of? I'm using this for my credentials:

`trading = betfairlightweight.APIClient(username=user.name,`

                                       `password=user.password,`

                                       `app_key=user.key,`

                                       `certs=user.certs)`



`client = clients.BetfairClient(trading)`

`framework = Flumine(client=client)`

Which logs me in fine but not with Flumine. I am only using the demo API not the paid one so that's maybe affecting it since the Flumine example is trying to place a bet but the demo API doesn't have that functionality.

Thoughts?

TIA!

---

## 2021-06-22 22:40:34 - general channel

**Paul**

I make more trading on exchange games than I do on sports at the moment. Hope to get some time at screen to fix that at the weekend.

---

## 2021-06-22 14:52:58 - issues channel

**Betbot Coder**

[https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py|this example code](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py|this example code) from Liam appears to also generate same error so unless it's my login credentials, I guess yes it must be the API. Let me know if anyone else having same issue, ta

---

## 2021-06-22 14:25:40 - issues channel

**Mo**

It's _probably_ just the historic endpoint being flaky but the error messages are so cryptic you might also be using incorrect arguments

---

## 2021-06-22 14:22:17 - issues channel

**Betbot Coder**

InvalidResponse: Invalid response received:

[!DOCTYPE html](!DOCTYPE html)

&lt;html&gt;

&lt;head&gt;

&lt;meta name="viewport" content="width=device-width" /&gt;

&lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

&lt;div&gt;

Error

&lt;/div&gt;

&lt;script defer src="[https://static.cloudflareinsights.com/beacon.min.js](https://static.cloudflareinsights.com/beacon.min.js)" data-cf-beacon='{"rayId":"ASDASD","token":"XXX","version":"2021.5.2","si":10}'&gt;&lt;/script&gt;

&lt;/body&gt;

&lt;/html&gt;

---

## 2021-06-22 14:15:06 - issues channel

**Betbot Coder**

Hi all! First off big thanks to Liam and all for writing and maintaining these functions, very much appreciated! So issue at the moment is, I'm trying to run the trading.historic.get_file_list function but getting a JSONDecodeError: Expecting value: line 2 column 1 (char 1). It has previously worked fine but I haven't run it for a few weeks and now it's just not working, and I can't see why from the documentation. I found [https://github.com/liampauling/betfair/issues/144|this page](https://github.com/liampauling/betfair/issues/144|this page) with comment from Liam saying it's when Betfair is playing up - is that still the case or am I doing something wrong on my code?

---

## 2021-06-22 07:32:18 - general channel

**Adrian**

`runner.ex.available_to_back`

```[&lt;betfairlightweight.resources.bettingresources.PriceSize at 0x7fe4a0094af0&gt;,

 &lt;betfairlightweight.resources.bettingresources.PriceSize at 0x7fe4a0094a60&gt;]```

`runner.ex.available_to_back[0]`

```&lt;betfairlightweight.resources.bettingresources.PriceSize at 0x7fe4a0094af0&gt;```

`runner.ex.available_to_back[0]["prices"]`

```TypeError: 'PriceSize' object is not subscriptable```

What am I doing wrong?

---

## 2021-06-20 10:39:28 - strategies channel

**PeterLe**

[@U4H19D1D2](@U4H19D1D2) /All, So how might you go about doing this in practice? Lets say you had a laying system and one key variable you wanted to test (fill/kill). 

If the Fill/Kill was too fast, (and it can be) you would miss opportunities and too slow you’d get taken to the cleaners.

Over the years I have reached what I think is near an optimum through trail and error. 

What would be the steps you would take in practice (could you only do this by backtesting?) Or maybe you would use backtesting to get in a range and then fine tune by live testing perhaps?

Thanks in advance

---

## 2021-06-17 07:39:01 - strategies channel

**birchy**

To add to the above, that strategy took several months to develop but is built upon market knowledge I've gained over the years and was NOT a "backtest today, go live tomorrow" strategy. As with all strategies, it started with a sensible idea but then I had to implement it and overcome lots of anomalies, execution issues and unforseen bugs. And then, when it worked as I wanted, I simply WAITED. I didn't touch anything, I didn't start "tweaking" parameters and I didn't obsessively check my P&amp;L every 5 minutes. Doing nothing is the hardest part. Learn that level of patience and everything else will fall into place.

---

## 2021-06-16 15:20:57 - strategies channel

**PeterLe**

"Current BOTS came out of Peterle suggestion?? :confused: No not quite what I said??

Im not quite sure what you mean, but if it was reference to "why not run both" then sure, If they are known well proven strategies.  I run 9 strategies each day and some only have a small ROI. but they all add up.



This initial piece of advice still holds true 8th June:



[@U01PJ5YMFBJ](@U01PJ5YMFBJ) In my opinion, you are missing an important step. Michael  has already given you the answer; he said: I"f you want to be really successful it's not about finding some magic combination of obvious parameters, it's about coming to some kind of understanding of market dynamics that other people don't have”

I don’t think you will better that advice. In the many years Ive been doing this, the single stand out attribute/trait of the very successful people Ive met or spoken to is encapsulated in that statement. They think differently having acquired that understanding. Fix that first (yes it may take you years), then move to step two, You cant fast track it

---

## 2021-06-16 07:52:43 - strategies channel

**Michael**

0.1% ? Yeah maybe you can work with that if you are experienced but you've got so little room for error that you really can't afford any mistakes or fudges. Any strategy you design WILL have less edge in real life than in testing because all testing tends toward over-fitting, you should build the assumption of an over-fit into your process. The more experienced you are the less allowance you need, with no disrespect I'd suggest you make a big allowance.

---

## 2021-06-15 20:15:37 - strategies channel

**AndyL**

Obviously backtest, so small slippage or error and ....!

---

## 2021-06-15 11:22:59 - issues channel

**Scott**

Sorry, assume I’m a moron.. where would I find the error message 

---

## 2021-06-15 11:22:08 - issues channel

**Mo**

It helps to have an actual error message

---

## 2021-06-15 09:54:24 - issues channel

**Andy B**

Cheers, I spent so long looking at the error that I lost of sight of some simple troubleshooting.

---

## 2021-06-15 07:40:08 - issues channel

**Andy B**

Hi All, I'm working my through the python API tutorial on [https://betfair-datascientists.github.io/api/apiPythontutorial/](https://betfair-datascientists.github.io/api/apiPythontutorial/) and I keep running into the same issue with the process_runner_books function.  Just wondering if I am missing something as more often than not I get an 'IndexError: list index out of range' error at this line:

best_back_prices = [runner_book.ex.available_to_back[0].price

                        if runner_book.ex.available_to_back[0].price

The odd thing for me is that it does work for some market_id's, so that has me wondering if there are specific market types that need to be filtered to prevent this error.  I've re-read the doco countless times, and I'm not seeing something I missed, although it is entirely likely\possible that I did.  Any chance someone has had the same issue and found a resolution?

---

## 2021-06-11 17:33:04 - strategies channel

**liam**

Error between keyboard and chair regarding speed, flumine/bflw is capable of about 1k markets per minute out the box 

---

## 2021-06-08 23:58:04 - issues channel

**rjj**

I've tried

```date_range = time_range(from_='20210607', to='20210608')```

But that throws an exception betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders

Params: {'betStatus': 'SETTLED', 'settledDateRange': {'from': '20210607', 'to': '20210608'}}

Exception: None

---

## 2021-06-08 12:50:42 - general channel

**liam**

At a guess it’s erroring on startup, logs tell you anything? It’s likely the thread / restart is hiding the error so remove the retry or try and catch it 

---

## 2021-06-08 12:01:25 - general channel

**Brian**

Hi guys, looking for a little assistance (bear with me as I'm still pretty new to this :slightly_smiling_face:)... I'm using Liam's very helpful error handling example script ([https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)) but I seem to have a bit on an issue in that once the loop has gone through all of the market books and starts over, it doesn't seem to be picking up updated odds from that point, like it keeps going over the stream it initially created at that point in time. Maybe this is expected behavior and there's still something I'm missing, but if there is I'd really appreciate some help figuring out what it is. I tried to move the start of the loop higher to incorporate the creation of the stream... which does work... but creates way too many logins per hour which Betfair aren't happy about. Any assistance would be hugely appreciated!

---

## 2021-06-08 10:59:14 - strategies channel

**Jonjonjon**

I do horses pre-event. I'm currently taking your prior advice of going back to basics, and re-working my pricing model. It's been making a London software developers' salary for a few years, but when I revisited it, I found that due to a bug, the code doesn't actually produce a number a lot of the time, so once that is fixed I will return to my IP quest.

---

## 2021-06-08 09:29:48 - strategies channel

**PeterLe**

[@U01PJ5YMFBJ](@U01PJ5YMFBJ) In my opinion, you are missing an important step. [@UGV299K6H](@UGV299K6H)  has already given you the answer; he said: I"f you want to be really successful it's not about finding some magic combination of obvious parameters, it's about coming to some kind of understanding of market dynamics that other people don't have”



I don’t think you will better that advice. In the many years Ive been doing this, the single stand out attribute/trait of the very successful people Ive met or spoken to is encapsulated in that statement. They think differently having acquired that understanding. Fix that first (yes it may take you years), then move to step two, You cant fast track it

---

## 2021-06-05 15:00:43 - random channel

**Newbie99**

It was the order_id!



The replacement order has the same order_id as the initial order, so when this gets added to the blotter, the first bet_id is removed.



My short term fix is just order_id = current_order.bet_id (just for the orders picked up by middleware).



Not sure if there is a better approach than that (could generate a new hash or something, not really sure what the correct/best way is).

---

## 2021-06-05 13:53:12 - general channel

**Phil Anderson**

[@U016TGY3676](@U016TGY3676) Yes you were right, even with everything rounded in excel it was still causing errors.  For example it was getting odds of 1.800000000000001. I've just extracted it from excel into python using round in python on top of the VBA rounding and seems to be working fine for now. I'll go the lookup table route if it fails again, but was easiest option with what I'd already done :crossed_fingers:

---

## 2021-06-04 19:17:00 - general channel

**birchy**

I've generally found that using the built-in rounding functions cause difficult to find price errors, so my go-to now is _always_ a lookup table as a sanity check.  In excel, I would simply port [https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/flumine/utils.py#L78|THIS](https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/flumine/utils.py#L78|THIS) to VBA

---

## 2021-06-04 17:32:34 - general channel

**Phil Anderson**

Realised there's an error_code function. And it's throwing out an invalid odds error. So it's a problem with the excel calculations that I thought I'd sorted by rounding but for some reason it's still giving some results as multiple decimal places. I'll have to go back and find the problem. Or round it in python once I've extracted it. Thanks for the input, hopefully I can take it from here

---

## 2021-06-04 15:33:32 - general channel

**Mo**

Almost certainly user error

---

## 2021-06-04 15:29:34 - random channel

**Newbie99**

[@UEA14GBRR](@UEA14GBRR) it was just a reference to a conversation on here the other day about how Betfair aren't consistent with their approach on this topic, I suspect everyone on here accepts to some degree, so long as something can be bet on, some people will try to fix events, as you say, its just the way it is.

---

## 2021-06-04 10:58:45 - issues channel

**James McKenzie**

I removed the strategy that pushes to redis and just ran a market recorder. I got the following when scraping GB races:





```{"asctime": "2021-06-04 05:02:46,633", "levelname": "WARNING", "message": "_get_cleared_market StatusCodeError", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flumine/worker.py\", line 228, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 48, in request\n    check_status_code(response)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/utils.py\", line 34, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 503", "trading_function": "list_cleared_orders", "response": "Status code error: 503"}

{"asctime": "2021-06-04 05:03:01,545", "levelname": "ERROR", "message": "get_account_details error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flumine/clients/betfairclient.py\", line 50, in _get_account_details\n    return self.betting_client.account.get_account_details()\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/account.py\", line 54, in get_account_details\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 48, in request\n    check_status_code(response)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/utils.py\", line 34, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 503", "error": "Status code error: 503"}

{"asctime": "2021-06-04 05:03:02,638", "levelname": "ERROR", "message": "get_account_funds error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/flumine/clients/betfairclient.py\", line 56, in _get_account_funds\n    return self.betting_client.account.get_account_funds()\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/account.py\", line 35, in get_account_funds\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 48, in request\n    check_status_code(response)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/utils.py\", line 34, in check_status_code\n    raise StatusCodeError(response.status_code)\nbetfairlightweight.exceptions.StatusCodeError: Status code error: 503", "error": "Status code error: 503"}```

the process is currently hanging

---

## 2021-06-03 14:54:24 - issues channel

**Newbie99**

Being across 2 sessions (i.e. after a shutdown), this is a very tricky one to debug!



Will try to do a forced update of Flumine, although pretty sure I'm using the latest version.



Will work on trying to pinpoint the issue.

---

## 2021-06-03 10:41:32 - issues channel

**liam**

So the connection error is on the account details endpoint, whats the setup here in terms of number of markets?

---

## 2021-06-03 10:38:19 - issues channel

**James McKenzie**

Hi guys, I have a Betfair account that's been set up by a client who is based in Asia. I have been told that all betfair code needs to be ran from a Hong Kong server. I am running into connection problems when I run some flumine based price scraping code from an AWS server in HK. I see a huge ramp up in the latency and then a fairly nasty connection error message:



```{"asctime": "2021-06-02 12:37:54,900", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 0.5828690528869629"}                                                                        

{"asctime": "2021-06-02 12:40:35,503", "levelname": "INFO", "message": "[MarketStream: 2001] 1.184035567 removed, 139 markets in cache"}                                                                    

{"asctime": "2021-06-02 12:45:32,223", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 5.051729917526245"}                                                                         

{"asctime": "2021-06-02 12:46:17,490", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 50.812371015548706"}                                                                        

{"asctime": "2021-06-02 12:46:55,148", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 88.5535352230072"}                                                                          

{"asctime": "2021-06-02 12:47:41,872", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 133.0834095478058"}                                                                         

{"asctime": "2021-06-02 12:48:34,090", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 182.7278220653534"}                                                                         

{"asctime": "2021-06-02 12:50:47,754", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 297.83341121673584"}                                                                        

{"asctime": "2021-06-02 12:56:28,947", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 664.3587987422943"}                                                                         

{"asctime": "2021-06-02 12:57:00,334", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 695.7359499931335"}                                                                         

{"asctime": "2021-06-02 12:58:46,348", "levelname": "ERROR", "message": "get_account_details error", "exc_info": "Traceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/urllib3/connec

tion.py\", line 159, in _new_conn\n    conn = connection.create_connection(\n  File \"/usr/lib/python3/dist-packages/urllib3/util/connection.py\", line 61, in create_connection\n    for res in socket.geta

ddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/usr/lib/python3.8/socket.py\", line 918, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gai

error: [Errno -3] Temporary failure in name resolution\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages

/urllib3/connectionpool.py\", line 665, in urlopen\n    httplib_response = self._make_request(\n  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 376, in _make_request\n    self._v

alidate_conn(conn)\n  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 996, in _validate_conn\n    conn.connect()\n  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", l

ine 314, in connect\n    conn = self._new_conn()\n  File \"/usr/lib/python3/dist-packages/urllib3/connection.py\", line 171, in _new_conn\n    raise NewConnectionError(\nurllib3.exceptions.NewConnectionEr

ror: &lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f7c3bde0c10&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution\n\nDuring handling of the above exception,

 another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/requests/adapters.py\", line 439, in send\n    resp = conn.urlopen(\n  File \"/usr/lib/python3/d

ist-packages/urllib3/connectionpool.py\", line 719, in urlopen\n    retries = retries.increment(\n  File \"/usr/lib/python3/dist-packages/urllib3/util/retry.py\", line 436, in increment\n    raise MaxRetr

yError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/account/json-rpc/v1 (Ca

used by NewConnectionError('&lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f7c3bde0c10&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n\nDuring handli

ng of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 

36, in request\n    response = [http://session.post|session.post](http://session.post|session.post)(\n  File \"/usr/lib/python3/dist-packages/requests/api.py\", line 116, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"/usr/l

ib/python3/dist-packages/requests/api.py\", line 60, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/usr/lib/python3/dist-packages/requests/sessions.py\", line 533, in 

request\n    resp = self.send(prep, **send_kwargs)\n  File \"/usr/lib/python3/dist-packages/requests/sessions.py\", line 646, in send\n    r = adapter.send(request, **kwargs)\n  File \"/usr/lib/python3/di

st-packages/requests/adapters.py\", line 516, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retrie

s exceeded with url: /exchange/account/json-rpc/v1 (Caused by NewConnectionError('&lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f7c3bde0c10&gt;: Failed to establish a new connection: [Errno -3] Te

mporary failure in name resolution'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages

/flumine/clients/betfairclient.py\", line 50, in _get_account_details\n    return self.betting_client.account.get_account_details()\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightwe

ight/endpoints/account.py\", line 54, in get_account_details\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.8/site-packages/

betfairlightweight/endpoints/baseendpoint.py\", line 43, in request\n    raise APIError(None, method, params, e)\nbetfairlightweight.exceptions.APIError: AccountAPING/v1.0/getAccountDetails \nParams: {} \

nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/account/json-rpc/v1 (Caused by NewConnectionError('&lt;urllib3.connection.VerifiedHTTPSConnection o

bject at 0x7f7c3bde0c10&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))", "error": "AccountAPING/v1.0/getAccountDetails \nParams: {} \nException: HTTPSConnection

Pool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Max retries exceeded with url: /exchange/account/json-rpc/v1 (Caused by NewConnectionError('&lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f7c3bde0c10&gt;: F

ailed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"}             

{"asctime": "2021-06-02 12:58:46,360", "levelname": "WARNING", "message": "[FlumineStream: 2001]: Latency high: 801.6888477802277"}

Killed```

Does anyone have any ideas about the cause of the problem and how I might resolve it. Much appreciated.

---

## 2021-06-02 09:27:50 - issues channel

**Newbie99**

[@U4H19D1D2](@U4H19D1D2) I am really struggling to replicate this! But the timeline is as follows (which may or may not help):



1. LAY order for £3 @ 1.39 created

2. 2.67 matched @ 1.39

3. Replace moves the price to 1.43 (so 33p now remains @ 1.43)

4. Flumine shutdown (as in killed by me, stopped overnight, not a socket error)

5. Flumine restarts and the trade no longer appears in the blotter

From what I can see, a trade simply being replaced shows up correctly, so although I can't prove it, it looks like its something to do with the size (possibly its failing a check somewhere and I haven't spotted where yet)?

---

## 2021-06-01 12:49:36 - general channel

**Phil Anderson**

Thanks. I gave that a shot but get TypeError: 'CurrentOrders' object is not iterable

---

## 2021-05-31 14:17:52 - strategies channel

**Dave**

`The hard part is estimating your true edge` - yup this has been a primary concern for me in terms of using Kelly. I usually take quite a generous margin over my forecast, so consider a relatively large margin of error essentially.

---

## 2021-05-29 23:23:25 - general channel

**John**

Thanks [@U4H19D1D2](@U4H19D1D2). Here is the init function of my strategy class



```class strategy_test(BaseStrategy):





    def __init__(self, *args, **kwargs):

       BaseStrategy.__init__(self, *args, **kwargs)



       # date time

       now = datetime.now()

       dt_string = now.strftime("%Y%m%d")



       # setup logging

       path_file_log = os.path.abspath(os.path.join(cwd, "../log/", strategy_id + f"_{dt_string}" + ".log"))

       logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%Y-%m-%d %I:%M:%S | ', level=logging.DEBUG,

                           filename=path_file_log)

       [http://logging.info|logging.info](http://logging.info|logging.info)("Log file: " + path_file_log)```

Any pointer to output a log file to a local drive will be appreciated.

---

## 2021-05-27 19:21:57 - general channel

**liam**

Fairly sure betfair don’t have the ability to do this (unless things have changed) Are you sure it wasn’t a network/server disconnect and then a subscription error on reconnect?

---

## 2021-05-27 15:31:56 - random channel

**Michael**

Haha, no I agree. You're really planning for the general case rather than the exceptions so you're apt to get caught out by something like this (although it doesn't look like I was in this case). For my part I incorporate a lot of market signals in my GPS operation so I expect that mitigates things to an extent.

---

## 2021-05-27 14:02:18 - issues channel

**kieran**

I tried both and am getting the same error.

---

## 2021-05-27 09:41:33 - general channel

**thambie1**

I believe I had a higher limit at the time, but yes. I was disconnected long after initiating the connection, with the error clearly specifying that the issue was the number of subscribed markets

---

## 2021-05-26 11:50:33 - issues channel

**kieran**

Hi, Apologies I am getting the same issue. I'm a Python beginner.  I'm not fully sure what "var on the flumine client" means or what the fix is? Any guidance would be appreciated.

---

## 2021-05-25 12:59:39 - random channel

**Mo**

A flag in the market book is troublesome because often the damage will already have been done (you want existing bets voided, not future bets avoided). It also might encourage _more_ betting as people try to get the right side of the fix

---

## 2021-05-25 12:52:54 - random channel

**D C**

Is it not troublesome from a legal perspective though if they declare the reason for voiding as suspected match fixing? That way if players ever got wind of it they might have grounds to sue etc? And Betfair would have to declare the reason for voiding otherwise they would be accused of dodgy antics themselves. For what it's worth [@UBS7QANF3](@UBS7QANF3) I completely agree with your sentiment buy I can see the difficulty their end.

---

## 2021-05-25 12:50:00 - random channel

**Mo**

My point is that bookmakers have a tool they can deploy in this situation which is that they can choose to remove the match and void bets placed on it. As exchange users, we cannot do this even if we strongly believe match fixing is taking place. I think Betfair should be more proactive in the most egregious cases to protect their customers in the same way that bookmakers are protected - and to protect themselves!!

---

## 2021-05-25 12:32:39 - random channel

**Jonjonjon**

Would match fixing show up in the data?

---

## 2021-05-25 12:21:56 - random channel

**Jonjonjon**

Could users ever be punished for making money from fixed markets?

---

## 2021-05-25 12:21:30 - random channel

**Jonjonjon**

I don't see how users can be expected to detect match fixing. If I'd seen that video of Stefano out of context, I'd have just thought he was a really bad player.

---

## 2021-05-25 11:54:41 - random channel

**Mo**

A couple more points on the match fixing issue:



1. Saying you won’t void a market for suspected match fixing, only definite match fixing is essentially saying you won’t ever void a market for match fixing. Anything definitive will only come as the result of an investigation by the authorities and probably subject to an appeals process. By the time you have a definitive answer, the money will be long gone. This is why I think they should be voiding markets before they are settled

2. The more I think about it, the worse the optics look of keeping the exchange market open when all other mainstream bookmakers have stopped taking bets. How do you possibly justify that to the authorities? I don’t think you can abdicate the responsibility for preventing your platform being used by organised crime by saying it’s down to users to detect when this is likely to be happening

---

## 2021-05-25 10:33:53 - issues channel

**Tony**

I get that error

---

## 2021-05-25 09:56:57 - issues channel

**Tony**

Hi I was hoping that someone might be able to help or point me in the right direction. When I try to connect to the betfair stream I get the following error:

```"errorCode":"INVALID_SESSION_INFORMATION","errorMessage":"Session must be 'Bearer &lt;session&gt;' for a WebApp","connectionClosed":true,```



---

## 2021-05-25 08:03:49 - random channel

**Jonjonjon**

Thanks for sharing [@UBS7QANF3](@UBS7QANF3). How can you tell if a match is a fix? I don't watch any sports, so apologies if it's a dumb question.

---

## 2021-05-25 07:24:26 - random channel

**Mo**

Here are three examples of why it doesn't feel like Betfair is my "partner".



Firstly, I think Betfair should be doing a lot more to protect customers from match fixing. There have been some blatant tennis match fixes recently which hurt us. I reported them to my account manager who has passed them on to the "integrity team" but nothing ever comes of this. Their policy is not to void markets based on allegations alone which I think is dangerous and may ultimately cost them as by keeping the market open they are facilitating the match fixing:



&gt; Ultimately we don’t suspend betting as customers use the product with the expectations that they will be able to manage their positions. Market suspension would be detrimental to this, especially in the cases where the volume is substantial.

The volume is substantial because you have organised crime syndicates using your product!



&gt; The difference between this and the sportsbook is that we choose not to offer bets on the Sportsbook if we suspect a problem, whereas on the Exchange it’s up to customers to make that judgement for themselves. It may be obvious in some cases, but obvious isn’t enough to go by until it has been proven after investigation by the governing body. 

This seems like madness to me. It's not hard to notice that every other bookmaker has stopped taking bets on a match and to suspend and void the market in these situations. I think it's far better to err on the side of caution rather than risk supporting organised crime.



There is the particular case of Teymuraz Gabashvili, a player who is so bent that Betfair has not offered markets on his matches for years. Recently, they had markets on one of his matches, it was a fix and it cost us 5 figures. Well, they are back to not offering markets on his matches but did they void the market and refund our loss? No. My suspicion is that someone in market ops fucked up in creating that market in the first place. I didn't think it was necessary to have our own filter to prevent trading his matches because it's been Betfair policy for YEARS not to offer his matches. Was there any communication they would change that policy? No.



Secondly, we've had so many problems recently with Betfair being late to create tennis markets, sometimes missing matches completely, other times only creating them once they've turned in play which inevitably means they end up having poor liquidity. It seems to me that it essentially boils down to:



1. Poor integration with data feed providers. These have been WTA matches and the provider for these changed this year. Something with the integration is preventing these markets from being automatically created

2. Lack of coverage from the market ops team. The problems normally happen on a Saturday morning; Saturdays tend to be days with lots of qualfiiers being played for the upcoming tournaments for the week. The schedule for the day typically gets published in the early hours of Saturday but if there are any issues with the automatic creation of markets it's not until around the middle of the day that these actually get resolved by which time some matches will have been missed. Seems like it's driven by whenever the guys working on Saturday get into the office

3. Some weird regulatory issue where only the Australian team can create Australian markets. But the Australian team doesn't have 24/7 coverage so when they've failed to create the markets but it's the middle of the night for them all we can do is twiddle our thumbs

My point here (aside from concerns about their technical capabilities re: integration) is that I have no problems making sure our systems are working at 7 am on a Saturday so I bloody well expect Betfair to be doing the same. Yeah, I get it, not everyone has the same work life balance as me but for an organisation the size of Flutter it's well within their capabilities to provide 24/7 coverage on these teams. There's always sport being played somewhere.



Thirdly, site outages. We've all been hurt by these. Betfair can have a meltdown over multiple days but you can be damn sure they won't have any problems taking your premium charge.



In summary, if this was something resembling a true partnership I would expect:



1. Betfair to care more about protecting its (premium) customers. They don't care (enough) if you get hurt for 5 figures in a match fix because they still get their juicy commission/PC on the increased volume

2. Betfair to pursue the same technical excellence that I aspire to. They don't care (enough) if I miss out on trading a few tennis markets because what could be hundreds of pounds in EV for me is a drop in the ocean for them

3. Betfair technical teams to provide 24/7 coverage

4. Some compensation when their services fail

---

## 2021-05-22 10:01:45 - issues channel

**Newbie99**

Ah I think I may have got it!



```socketio.run(app, debug=False, port=5678)```

If debug is set to True apparently that starts a concurrent process, so setting that to False appears to allow it to work correctly (well based on a very quick test anyway)!

---

## 2021-05-22 09:56:10 - general channel

**liam**

Need some error catching on that 

---

## 2021-05-22 09:51:44 - issues channel

**Newbie99**

Playing around more, its appears the thread itself isn't an issue (i.e. if I start Flumine in a thread that behaves correctly, however if I start Flask it does not).



```from flask_socketio import SocketIO, emit

from flask import Flask, render_template

import time

import os

import threading

from startup import startup



run_flask = False



if __name__ == '__main__':



    print('Process ID_a' + str(os.getpid()))

    def f():        

        import time

        global snapshot

        time.sleep(0.1)

        lock = threading.Lock()

        with lock:

            snapshot = {}

            print('Process ID_b' + str(os.getpid()))

            ''' Initiates and runs all Flumine Framework elements '''

            startup()



    t1 = threading.Thread(target=f)

    t1.start()

    time.sleep(0.1)



    if run_flask is True:

        ''' When this runs it causes the problem (i.e. a new process which duplicates the above thread) '''

        app = Flask(__name__)

        app.config['SECRET_KEY'] = 'secret!'

        app.config['DEBUG'] = True



        # turn the flask app into a socketio app

        socketio = SocketIO(app, async_mode=None, logger=True, engineio_logger=True)



        @app.route('/')

        def index():

            # only by sending this page first will the client be connected to the socketio instance

            return render_template('index.html')



        @socketio.on('ping')

        def handle_message(*_args, **_kwargs):

            print(snapshot)

            emit('market_update', {'market_update': snapshot})



        @socketio.on('connect')

        def test_connect():

            print('Client connected')



        @socketio.on('disconnect')

        def test_disconnect():

            print('Client disconnected')



        socketio.run(app, debug=True, port=5678)```

I haven't figured it out yet, but clearly I need to change this approach somehow, will post if I figure it out (just in case it helps anyone else) and if anyone happens to have any suggestions, please shout (and appreciate the time you spent looking at this [@U4H19D1D2](@U4H19D1D2) , apologies if it was a bit of a wild goose chase)!

---

## 2021-05-21 10:41:37 - issues channel

**liam**

there is a bug here somewhere though I think as flumine should try and handle this better but I can't see it right now

---

## 2021-05-21 09:13:22 - issues channel

**liam**

Just released [https://github.com/liampauling/flumine/pull/439|1.18.12](https://github.com/liampauling/flumine/pull/439|1.18.12) with a fix to a race condition, I am not 100% that this is the issue you are seeing but looks like I introduced a race condition on start up, now refactored

---

## 2021-05-20 12:32:51 - issues channel

**liam**

My default is disabling network but I think you get a connection error 

---

## 2021-05-20 06:21:13 - general channel

**Peter**

nohup and &amp; has created streams for me that have have run for over a year untouched for me. I'd almost like a problem as I'd like to switch to Docker, but if they ain't broke I don't want to fix them.

---

## 2021-05-19 20:10:04 - strategies channel

**MacrcoPolo**

You can limit to a fixed number of iterations if you want to get an approximation that is reasonable in a short time

---

## 2021-05-19 18:43:56 - strategies channel

**Paul**

OK, so I think I found something on extending the stuff I fixed in the wiki article. Laying is an entirely new thing I know I couldn’t find anything on, but I’ll do some digging around tonight and tomorrow based on stuff I was doing at the time

---

## 2021-05-19 11:46:26 - general channel

**Dave**

two things that have caused my flumine to die: oom kills and segfault due to dodgy JSON libraries. Latter might be fixed now so maybe it was the former. Otherwise my flumine instance runs for months with no issues.

---

## 2021-05-18 10:29:35 - issues channel

**liam**

np, check the middleware isn't erroring

---

## 2021-05-18 01:55:21 - random channel

**ShaunW**

Syndicates reduce the per head fixed costs like curating data sources, and splits the ancilliary dev like monitoring and reporting. So it's not just a case of setting up in your back bedroom when you see their model because the cost of running it on your own might well outstrip what it earns, even if you have the time do all it involves. Being a one-man-band at any job is tougher than having a team, especially balancing doing the work and looking for the next work, probably where syndicates excel. We'd all like someone else to do the stats and the coding so we can muse all day, Voila! A business is born, but it's sports betting so let's call it a syndicate.

---

## 2021-05-17 23:08:52 - issues channel

**Newbie99**

I seem to have the latest version of flumine, so its not that.



Removing the logic does remove the errors as expected, but seems to produce a lot of latency warnings on startup (may just be co-incidence as I'm not sure why that would be...it did take a long time to cycle through everything)!



```WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time

{"asctime": "2021-05-17 22:06:31,634", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.167249195", "latency": 2.0103297233581543, "pt": "2021-05-17T22:06:29.624000"}```

---

## 2021-05-17 22:54:01 - issues channel

**Newbie99**

[@U4H19D1D2](@U4H19D1D2) when running that middleware example I get a ton of these errors (is it possible there is no error catching if there are no completed orders for that market/strategy combo as that appears to be the case, but I could be wrong)?



```{"asctime": "2021-05-17 21:51:02,008", "levelname": "CRITICAL", "message": "Unknown error  in &lt;middleware_example.OrdersMiddleware object at 0x000001D04E45E580&gt; (1.180015935)", "exc_info": "Traceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\flumine\\utils.py\", line 220, in call_middleware_error_handling\n    middleware(market)\n  File \"D:\\Python38\\lib\\site-packages\\flumine\\markets\\middleware.py\", line 16, in __call__\n    raise NotImplementedError\nNotImplementedError"}

INFO:flumine.baseflumine:Adding: 1.180957876 to markets

{"asctime": "2021-05-17 21:51:02,011", "levelname": "INFO", "message": "Adding: 1.180957876 to markets"}

CRITICAL:flumine.utils:Unknown error  in &lt;middleware_example.OrdersMiddleware object at 0x000001D04E45E580&gt; (1.180957876)

Traceback (most recent call last):

  File "D:\Python38\lib\site-packages\flumine\utils.py", line 220, in call_middleware_error_handling

    middleware(market)

  File "D:\Python38\lib\site-packages\flumine\markets\middleware.py", line 16, in __call__

    raise NotImplementedError

NotImplementedError```

---

## 2021-05-17 21:10:11 - issues channel

**Newbie99**

I think I'm misunderstanding how to implement middleware (I put that in before framework.run()) and get the following error, where should I be calling this from?



```    framework.add_market_middleware(OrdersMiddleware())

TypeError: __init__() missing 1 required positional argument: 'flumine'```

---

## 2021-05-17 15:04:54 - issues channel

**liam**

so its a quick fix where it will snap the order stream every 5s (default) however you would need some logic/delay to stop and orders being placed on initial startup, does that make sense?

---

## 2021-05-17 15:00:14 - issues channel

**liam**

Yeah so its caused by the order stream starting before the market stream has loaded/processed all markets which means you get the warning regarding the missing local market. Easy fix would be to delay the start of the order stream but this would still cause issues because you would then potentially have the same issue during the start delay. I think better fix is for me to figure out this [https://github.com/liampauling/flumine/blob/05182a42c654f505b12f176bcbe7d37edbf099c5/flumine/streams/orderstream.py#L65|todo](https://github.com/liampauling/flumine/blob/05182a42c654f505b12f176bcbe7d37edbf099c5/flumine/streams/orderstream.py#L65|todo) so that it effectively retries to add the live orders

---

## 2021-05-17 14:23:05 - issues channel

**Newbie99**

[@ULDAVFDRP](@ULDAVFDRP) I have made progress here:



```    def process_market_book(self, market, market_book):

        # process marketBook object



        ''' Adds existing market orders (from a previous session) into the current strategy  '''

        for order in self.existing_orders:

            if order.customer_order_ref is not None and order.market_id == market.market_id:

                if order.bet_id not in [o.bet_id for o in market.blotter._live_orders]:

                    print('Adding Bet_id: ', order.bet_id, ' to blotter for market: ', market.market_id)

                    trade = Trade(order.market_id, order.selection_id, order.handicap, self)

                    order_id = order.customer_order_ref[STRATEGY_NAME_HASH_LENGTH + 1:]

                    order = trade.create_order_from_current(order, order_id)

                    order.status = OrderStatus.EXECUTABLE

                    market.blotter.__setitem__(customer_order_ref=order.customer_order_ref, order=order)



        print(market.blotter._live_orders)```

So by trying that approach it adds the order that was created in a previous session into the blotter...however it also then adds a duplicate into the blotter....but importantly does not send a request to try and place this on the exchange (at least from what I can see...it definitely hasn't placed any and I'm not seeing any errors to suggest its trying to).



So it feels like this approach is close, by chance [@U4H19D1D2](@U4H19D1D2) can you see what I might need to tweak here to pick up the previous session order and not create a duplicate in the current live blotter?

---

## 2021-05-17 06:28:02 - general channel

**Greg**

Thanks [@ULDAVFDRP](@ULDAVFDRP) . I have done BA automation for years (bots are running for weeks as we speak) and can see what is delivered in the amount_available_to_back in terms of price and size(when I print the output) but for some reason I can't extract it so instead of price=20 I should have something like price=ex.available_to_back[0].price (in my head) but the ex has an error so I have something wrong somewhere. learning python as one goes is very hard for the 50 yr old brain

---

## 2021-05-17 06:05:45 - general channel

**Greg**

been sitting here for hours and can't for the life of me figure out 1. how to lay at the back price (or x ticks above it). I tried reading into the 'available_to_back' results obtained for each runner but have failed. The utils.py 'get_nereast_price' function is above my pay grade. Someone got a manual? :slightly_smiling_face: Might have to pay someone at this rate. Can anyone tell me how I lay on the back side as a start please : e.g. side="LAY", order_type=LimitOrder(price=20, size=5) thanks

---

## 2021-05-14 18:19:38 - issues channel

**Phil Anderson**

Hi, can someone help me with MARKET_ON_CLOSE persistence type please?

I keep getting failed placement when I change from LAPSE or PERSIST to MARKET_ON_CLOSE.

I'm still testing on delayed key. Could this be the problem? I couldnt find anything to say I shouldnt be able to.

Below is code I've been using, and only changinh persistence type



```limit_order = filters.limit_order(

    price=12.5, size=2, persistence_type="MARKET_ON_CLOSE"

)

instruction = filters.place_instruction(

    order_type="LIMIT",

    selection_id=runner.selection_id,

    side="BACK",

    limit_order=limit_order,

)

place_orders = trading.betting.place_orders(

    market_id=j.market_id, instructions=[instruction], # list

)```



---

## 2021-05-14 18:17:33 - issues channel

**liam**

Good spot, mind creating a GitHub issue for that so we can get it fixed?

---

## 2021-05-14 17:55:24 - issues channel

**Peter**

Unlike for order size, there's no rounding error check for liabilities.

---

## 2021-05-14 17:54:54 - issues channel

**Peter**

`def _validate_betfair_liability(self, order):`

        `if order.order_type.liability is None:`

            `self._on_error(order, "Order liability is None")`

        `elif order.order_type.liability &lt;= 0:`

            `self._on_error(order, "Order liability is less than 0")`

---

## 2021-05-14 10:24:15 - issues channel

**liam**

either that or my error monitoring has gone to shit

---

## 2021-05-14 10:20:43 - strategies channel

**D C**

I really want to throw multinomial logistic regression at it but I am not sure what the right approach is here as there are not a fixed amout of runners per race. I am comfortable with regular logistic regression but never actually performed multinomial. Any mathematicians here have any suggestions on how to use it on horses? Is partitioning the dataset into distinct sets that contain races with the same number of runners the way to go? Shame we can't get TPD and inplay markets on the dogs. Can you imagine the carnage there.....

---

## 2021-05-14 09:13:51 - issues channel

**Lee**

I just had a SocketError too

---

## 2021-05-14 08:57:22 - issues channel

**Peter**

`{"asctime": "2021-05-14 07:41:57,530", "levelname": "ERROR", "message": "OrderStream 1003 run error", "exc_info": "Traceback (most recent call last):`

  `File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 225, in _receive_all`

    `part = self._socket.recv(self.buffer_size)`

  `File \"/usr/local/lib/python3.9/ssl.py\", line 1226, in recv`

    `return self.read(buflen)`

  `File \"/usr/local/lib/python3.9/ssl.py\", line 1101, in read`

    `return self._sslobj.read(len)`

`socket.timeout: The read operation timed out`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

  `File \"/usr/local/lib/python3.9/site-packages/flumine/streams/orderstream.py\", line 45, in run`

    `self._stream.start()`

  `File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 60, in start`

    `self._read_loop()`

  `File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 207, in _read_loop`

    `received_data_raw = self._receive_all()`

  `File \"/usr/local/lib/python3.9/site-packages/betfairlightweight/streaming/betfairstream.py\", line 229, in _receive_all`

    `raise SocketError(\"[Connect: %s]: Socket %s\" % (self._unique_id, e))`

`betfairlightweight.exceptions.SocketError: [Connect: 1004]: Socket The read operation timed out"}`

---

## 2021-05-14 08:52:07 - issues channel

**Peter**

Seeing a lot of API errors this morning during order placement. Orders are getting through after connections are aborted and reset, but it sort of feels like BFLW is overcoming flakiness in the Exchange API by sheer persistence.

---

## 2021-05-13 09:01:55 - random channel

**Misha**

I have stuffed up one rollout. System for processing cheques and applications for the first Telstra float/IPO (like British Telecom) in 1997 (I think). We (me and one other guy) were developing the software to link all the document imaging, cheque scanning, application entry to process $20B of applications in 4 weeks. Naturally, the client requested changes while we were live. One change that I implemented managed to zero out all application amounts for batches post my rollout. Imagine my surprise/horror when one of the data entry operators showed me a screen that had applications worth $0. And then another. And another. Managed to rollback, find the batches affected, and fix it. Not the most relaxing day of my career :joy:

---

## 2021-05-13 00:55:59 - strategies channel

**Greg**

Hi [@U016TGY3676](@U016TGY3676) -are you talking about this example : [https://github.com/liampauling/flumine/blob/master/examples/marketrecorder.py](https://github.com/liampauling/flumine/blob/master/examples/marketrecorder.py) ? I have an error on the "from strategies.marketrecorder import MarketRecorder" line. ...strategies is an unresolved reference and I can't seem to fix it. Any advice appreciated. Cheers

---

## 2021-05-12 20:13:44 - strategies channel

**ShaunW**

There might only be a finite of set of parameters but each can be viewed in many ways. Eg time, is that the time frame you're active, time between refreshing bets or time to measure price moves or acceleration. And price, is that %implied chance or relative to others, and is that touch price or one of the many fair pricing models (vwap vpoc MA WoM type things). There's more than enough permutations to last a lifetime. And more you're involved the more variations you find but like a lot of complex problems look for the elegant simple solutions.    Don't waste money using trial and error in live, you can be pretty sure before you commit cash.

---

## 2021-05-12 13:16:30 - strategies channel

**Aaron Smith**

[@U010GM77S4W](@U010GM77S4W) eh yea of course, switched them around there it seems :smile: is fixed

(looks like it doesnt fix it in the quote though)

---

## 2021-05-12 09:25:11 - strategies channel

**Jonjonjon**

[@U01DPK9PGMC](@U01DPK9PGMC) That's quite a great suggestion. I've recently been having problems with slow backtests, as my strategy recalculates "fair value" with every market book update. But I could probably just calculate "fair value" at a single fixed time (e.g. 5 minutes before the race), and then start analysing the performance of the fair value signals.

---

## 2021-05-11 10:17:42 - strategies channel

**Peter C**

I am not the person best placed to answer but the favourite/longshot bias is talked about extensively in 'efficiency of racetrack betting markets' from both a tote pool/fixed odds perspective. I think in terms of a tote pool it is talked about in terms of punters preferring high risk/high reward bets and so over betting on those horses. Not sure why it persists in a fixed odds environment

---

## 2021-05-11 07:22:26 - issues channel

**Greg**

added the jsonlogger and saw an error re size of bet.Aussie currency needs min bet of $6 not 2 :face_with_hand_over_mouth:..thanks for the pointer to the logs

---

## 2021-05-11 02:25:35 - issues channel

**Greg**

Hi all. Having a go (be gentle -have only been studying Python for 3 months-so here come the very dumb questions:laughing:) at logging in with the delayed key/Flumine. Managed to login  run the example strategy (using AU markets-[https://liampauling.github.io/flumine/](https://liampauling.github.io/flumine/)) I have set paper trading to True but that, changing the price entry (see LimitOrder below) point, changing _runner.last_price_traded &lt; 10_ and setting the filter to AU instead of GB are about the only changes I have made. Unfortunately I get not output at all-or errors. 'Couple of questions to kick off with : *1*.I have seen references on this channel to the delayed key (despite mine being created after April 8th 2020 so should have access to streaming )being utterly useless and I wondered if this is the problem? i.e.: is the delayed key pointless and does it effectively prevent anything from working? *2*. Does Flumine (being a fully featured/ backtesting platform) effectively supersede BFLW (I know BFLW is a dependency for Flumine) ? *3*. The example strategy has an (LAY) order parameter of _order_type=LimitOrder(price=1.01,size=2.00)_ I tried to change the price to &lt;10 for example but get an error. How do you set a price range for multiple runners in Flumine using limit orders? Thanks in advance.Apologies for the basic questions and I'll try limit them as I go. Cheers

---

## 2021-05-08 00:14:21 - strategies channel

**birchy**

Oh. Bugger. I've somehow ended up concentrating on "micro" markets within each individual race and tbh, have struggled to find the golden eggs within them. Up until ~12 months ago, I was always a firm believer in looking at aggregated markets and picking off those spots where "abnormalities" occurred. Since diverting to the streaming API, I somehow took a wrong turning and ended up inside some warp zone where I've dismissed everything I did previously. Shit. :man-facepalming:

Thank you [@UGV299K6H](@UGV299K6H), I've just realised that I already know what I need to be looking for but have been looking in the wrong places.

---

## 2021-05-07 10:49:12 - issues channel

**Newbie99**

Yeah I've reported a few bugs around replace,  [@U4H19D1D2](@U4H19D1D2) has fixed everything now though (although override the min size check on a replace as that still doesn't work for me, i.e. it violates, but no-one else has been able to replicate that so its closed).

---

## 2021-05-07 09:32:17 - issues channel

**Jonjonjon**

I've found a potential bug in in exposure calculations, if Flumine attempts to replace an order. I've raised an issue and will take a look at fixing it at some point:



[https://github.com/liampauling/flumine/issues/423](https://github.com/liampauling/flumine/issues/423)

---

## 2021-05-05 11:07:19 - general channel

**liam**

Unless you are async best practise is to remove any blocking io/network requests from your strategies main thread, this will prevent latency or network errors causing issues

---

## 2021-05-02 11:17:04 - random channel

**birchy**

{"asctime": "2021-05-01 01:05:59,816", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/flumine/worker.py\", line 232, in _get_cleared_market\n    group_by=\"MARKET\",\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182752035'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-04190756-002ab3f9ad', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-04190756-002ab3f9ad', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182752035'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-04190756-002ab3f9ad', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-04190756-002ab3f9ad', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}

{"asctime": "2021-05-01 09:13:50,608", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/flumine/worker.py\", line 232, in _get_cleared_market\n    group_by=\"MARKET\",\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182736400'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang26b-prd-04190756-002b4d66d5', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang26b-prd-04190756-002b4d66d5', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182736400'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang26b-prd-04190756-002b4d66d5', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang26b-prd-04190756-002b4d66d5', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}

{"asctime": "2021-05-01 10:42:17,013", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/flumine/worker.py\", line 232, in _get_cleared_market\n    group_by=\"MARKET\",\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182736390'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang28a-prd-04270851-0008c9b97e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang28a-prd-04270851-0008c9b97e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182736390'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang28a-prd-04270851-0008c9b97e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang28a-prd-04270851-0008c9b97e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}

---

## 2021-05-01 19:00:36 - random channel

**birchy**

Are occasional ANGX-0006 "UNEXPECTED ERROR" API messages anything to be concerned about? I've always assumed these were just an acceptable error due to the nature of Betfairs slight flakiness?

---

## 2021-04-30 12:19:26 - issues channel

**Oliver Varney**

not seeing anything in the logs atm, what error, 503?

---

## 2021-04-30 10:32:14 - strategies channel

**James T**

Thanks for the shout out [@UQL0QDEKA](@UQL0QDEKA), but you’re definitely overstating any help I’ve given you. You’ve done well recently purely due to your own self-motivation.



Generally, to do well, I think you either need to have the right background (programming, finance, maths, or have worked for syndicates) or you will need some advice and/or mentoring from someone who has. One exception to that rule is [@UGV299K6H](@UGV299K6H) though. Michael did you start with programming right from the start or did you use other methods of automation?



Personally it came to me as a hobby while working in banking. My first strategy didn’t work, and I was lucky with my second, so I was up and running within 3-4 months. Markets were probably easier to crack 10 years ago though. At first it did seem like a fun hobby or puzzle to be solved, and to see how far I could push it. But now after 10 years it definitely does feel more job-like to me and just the easiest way for me to make good money with the least effort. 



Long term it’s always relatively difficult though I think. You can’t expect edges to last forever so it’s a constant process of adapting and developing. So once the interest does disappear it can be hard to maintain the same level of profitability. A lot of it is luck and trial and error in digging for profitable strategies though, so you need a thick skin to continue through patches of “missed shots”. 

---

## 2021-04-30 06:30:18 - strategies channel

**Oliver Varney**

Id be interested to see what the big guys respond to this [@U01PJ5YMFBJ](@U01PJ5YMFBJ) as everyone journey is different. For me at least it was an idea, that started as a hobby and I guess the end goal of making money if I was lucky but obviously at the time I was clueless about the landscape (and still am at times it feels).  After some small trail and error I found an edge but it took little a longer for a real break through which ultimately lead to this being a full time gig. I think like most things in life when you struggling to achieve a goal it looks very hard / impossible until you do it, then your mind switches and thinks that isn't so hard and sets a newer even harder goal to achieve.  I guess a last point is, that its quite easy to get drawn into a mind set where your comparing yourself against others, which sometimes can be good for motivation and to show you what is possible but setting a series of smaller more manageable goals that you can consistently hit is going to push you forward best

---

## 2021-04-28 12:34:47 - issues channel

**moseley82**

Hey guys, hoping somebody might be able to help me here... trying to use a script that I've not used for probably 6ish weeks now and I'm getting this error:



`Params: {'marketIds': [['1.182032085']], 'priceProjection': {'priceData': ['EX_BEST_OFFERS'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}` 

`Exception: None` 

`Error: {'code': -32602, 'message': 'DSC-0018'}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}`



Which happens when trying to execute this part of my script:



`market_books_1x2 = trading.betting.list_market_book(market_ids=[market_matchodds],price_projection=price_filter)`



After looking up the error I can see DSC-0018 means "A parameter marked as mandatory was not provided". Does anybody know if something has changed recently that I now need to account for?



Thanks!

---

## 2021-04-26 14:51:24 - general channel

**Phil Anderson**

Yes, thats exactly what I'm trying to do. I tried taking out the bet target type, but then get an error msg when I run it: 'errorCode': 'INVALID_INPUT_DATA', 'errorDetails': 'One or more inputs to the operation were invalid'



Forgive me if it's something simple, but I'm new to this and I'm still trying to get to grips with it.

---

## 2021-04-22 09:08:52 - strategies channel

**Dave**

I think that it's a very difficult problem to fix given how extraordinary the pandemic effect has been. I have decided to just ditch the period Jan - Sept 2020 altogether for my more complex models. Then again our models must be very different...for _most_ of my models, anything further back than 6 months starts losing a lot of predictive power.

---

## 2021-04-22 07:09:06 - strategies channel

**IndikaE**

Football question: I have noticed that the hometeam win frequency has fallen a lot across all leagues since matches starting being played without crowds(no big surprise there). My model is performing alright, but much worse than in backtesting(using Jan-may data 2020). Towards the end of that period I see a performance decrease even in backtest(when some leagues started reopening with no crowd?). My training set stops in December 2019. I must do my split along the time axis, otherwise I will surely be leaking. How have other people been dealing with this significant change in base distribution of home/away wins? Do you have data on crowd attendance, and is that enough to fix it? I don’t like that this whole period should probably be held out when retraining in the future, so I’m building a new model that will predict probabilities relative to baseline win frequencies instead. I can only imagine that this has been debated before, so sorry if I’m reviving a dead topic.

---

## 2021-04-21 10:07:23 - issues channel

**Peter C**

Weird, when I debug I get an SP of 'none'. I bet I'm doing something stupid somewhere, I'll have a dig and uncover it. Thank you for your help

---

## 2021-04-21 06:35:22 - issues channel

**thambie1**

Thanks for the confirmation... time to debug

---

## 2021-04-19 10:47:30 - issues channel

**liam**

do you get a lot of those errors? as they aren't good

---

## 2021-04-19 10:47:13 - issues channel

**liam**

havent used a filter yet, this was just from updating the worker errors to warnings

---

## 2021-04-19 10:25:51 - issues channel

**liam**

yeah wasn't bad at about 150 errors

---

## 2021-04-19 09:06:55 - issues channel

**Peter C**

Yeah I'm getting errors

---

## 2021-04-18 13:42:37 - general channel

**MacrcoPolo**

Almost certainly a path error

---

## 2021-04-18 07:17:49 - general channel

**Razvan Gheorghe**

I got this error when I try to run framework.run()

---

## 2021-04-18 07:17:16 - general channel

**Razvan Gheorghe**

File "&lt;stdin&gt;", line 1, in &lt;module&gt;

NameError: name 'framework' is not defined

---

## 2021-04-16 16:45:33 - issues channel

**Jono**

are there any steps in the certs production steps laid out in:



[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA)



which are outdated? I keep recieving an error that im fairly confident relates to the private key being incorrect specifically this error: "`HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(9, '[SSL] PEM lib (_ssl.c:3991)')))`"



the ploading of the relevant crt file to bf was successful and the trading client is able to find the corresponding .pem file but unfortunately the above problem is stopping me from getting further. Is there a preferred way of setting up certs that i should be following rather than this or what is listed in the bf docs? Alternatively is there a way to run flumine with an interactive login so i can forego the certs?

---

## 2021-04-16 14:12:42 - issues channel

**Unknown**

i believe i have set up the certs folder correctly but i keep receiving this error when trying to login()



"   Exception: [WinError 3] The system cannot find the path specified: '/certs/'   "



I have the certs folder at the same level as the python file executing. I receive the same error when performing the example strategy listed in the docs in both vscode and jupyter here are what the two directories look like. Is there something basic/obvious im setting up wrong?

---

## 2021-04-16 10:01:26 - issues channel

**liam**

I have made a first step of reducing the errors in flumine itself, v1.18.3 just released but I have this filter as a starting point

```class DuplicateFilter(logging.Filter):

    def __init__(self, *args, **kwargs):

        super(DuplicateFilter, self).__init__(*args, **kwargs)

        self._logs = []

        self.level = logging.WARNING  # todo

        self.log_count = 100  # todo



    def filter(self, record):

        if record.levelno &gt; self.level:

            current_log = (record.module, record.levelno, record.msg)

            if current_log in self._logs:

                return False

            self._logs.append(current_log)

        return True```

---

## 2021-04-15 15:48:53 - strategies channel

**James T**

If your strategy is based on stats or analytics on data of a fixed period, like calculating a moving average or something, then that does require a little rethinking since streaming data arrives at irregular intervals. 

---

## 2021-04-15 08:46:35 - issues channel

**Jorge**

I got: `AttributeError: 'bytes' object has no attribute 'encode'`  in that line

---

## 2021-04-14 17:16:02 - issues channel

**Jorge**

Hi [@U4H19D1D2](@U4H19D1D2), I'm checking the updated marketrecorder example using gzip compression and there is a bug [https://github.com/liampauling/flumine/blob/66089f81a8d5cd7f74ffe2d864745e823cb6bf51/examples/strategies/marketrecorder.py#L191|here](https://github.com/liampauling/flumine/blob/66089f81a8d5cd7f74ffe2d864745e823cb6bf51/examples/strategies/marketrecorder.py#L191|here) , I guess should be changed by

```market_catalogue_compressed = gzip.compress(

    market.market_catalogue.json()

)```

---

## 2021-04-14 10:15:59 - random channel

**James T**

Yeah, I doubt front line support will be any help. I expect if it affects enough people then they’ll notice and someone will fix it. Odd issue though. 

---

## 2021-04-12 21:30:33 - issues channel

**Alessio**

but don't quote me on that, that's an error_code i never saw

---

## 2021-04-12 15:46:16 - issues channel

**Newbie99**

When trying to place an order using:



```trade = Trade(

           market_id=market.market_id,

           selection_id=selection_id,

           handicap=handicap,

           strategy=self,

       )

   order = trade.create_order(

       side=direction, order_type=LimitOrder(price=price, size=stake, persistence_type=persistence_type)

   )



order_placed = market.place_order(order)```

I am trying to catch errors as follows:



```if order_placed is False:

	# Do stuff```

I just noticed an order (correctly) failing due to BPE, so this is expected behaviour and from logs I can see the following:



```{"asctime": "2021-04-12 13:39:15,049", "levelname": "INFO", "message": "Order Place: FAILURE", "bet_id": null, "order_id": "138375275548404227", "status": "FAILURE", "error_code": "BET_LAPSED_PRICE_IMPROVEMENT_TOO_LARGE"}```

However, from place_order in execution.transaction thought the above would return True or False and I could catch the error that way and do whatever I need, but it doesn’t appear to be catching for failures in live (I could have sworn this worked in paper trading, but haven’t been able to replicate yet), it does return True for successfully placed orders, but doesn’t return False.



 So, what is the correct way to catch these errors, as I’m clearly mis-reading the code?

---

## 2021-04-12 09:32:18 - general channel

**liam**

[@U019HMPCQT0](@U019HMPCQT0) [@U0155J92A7Q](@U0155J92A7Q) there was a bug, I hadn't noticed as I delete all files on cleanup, small fix in [https://github.com/liampauling/flumine/blob/66089f81a8d5cd7f74ffe2d864745e823cb6bf51/examples/strategies/marketrecorder.py#L110|1.18.2](https://github.com/liampauling/flumine/blob/66089f81a8d5cd7f74ffe2d864745e823cb6bf51/examples/strategies/marketrecorder.py#L110|1.18.2) that checks the txt file exists. The reason it checks for the gz first is that we know a market has closed if that is the case, we can't rely on checking the txt file as it might be a very slow market.

---

## 2021-04-11 15:17:35 - general channel

**Jorge**

Yes, I get those error logs around 1-5 times per day. I don't know what's the issue. I guess you are using `force_update=True` and `remove_file=True`?

---

## 2021-04-11 14:19:10 - general channel

**Taking Value**

Has anyone had any issues with flumine trying to delete the the same file twice during clean up when using it to record data? Got the following in the logs. Not certain where the issue is. It was working brilliantly until this occurred.

```{"asctime": "2021-04-10 13:35:39,550", "levelname": "INFO", "message": "Removing: /home/ubuntu/Recorder-test/race_records/33f72766/1.181722823, age: 3784.94s"}

{"asctime": "2021-04-10 13:35:39,551", "levelname": "INFO", "message": "Market removed", "market_id": "1.181722823"}

{"asctime": "2021-04-10 13:41:57,120", "levelname": "INFO", "message": "Removing: /home/ubuntu/Recorder-test/race_records/33f72766/1.181722823, age: 4162.5s"}

FileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/Recorder-test/race_records/33f72766/1.181722823'```

---

## 2021-04-08 16:41:01 - general channel

**Phil Anderson**

Hi. New here. Just trying to get my head round it all.

Is there a way to only get tomorrow's data without inputting the specific date?

Just playing around with some code I found in examples.

```market_start_time={"to": "{0}T23:45:00Z".format(datetime.date.today())}```

This seems to get everything up until 23:45 today

```market_start_time={"from": "2021-04-09T00:00:00Z", "to": "2021-04-09T23:45:00Z"}```

And this will get everything for tomorrow.

But is there to do the same but without having to change the date every day?

Also what is the .format part of the code for? If I put specific date, it seems to work with or without it, but in the first example if I take it out I get an error

---

## 2021-04-08 16:38:50 - general channel

**William Martin**

So I've abandoned trying to get data via the api to build the mvp of the new betting product I want to create.



Im trying to get the historical data for soccer for April but when I try and unzip its saying there are errors with the files. do I need something special to unzip a .tar?

---

## 2021-04-07 08:02:02 - general channel

**liam**

flumine [https://github.com/liampauling/flumine/blob/master/HISTORY.rst#1180-2021-04-07|v1.18.0](https://github.com/liampauling/flumine/blob/master/HISTORY.rst#1180-2021-04-07|v1.18.0) now released, a few depreciations as warned in v1.17, cleared order now available (thanks [@U01MPC0GUK1](@U01MPC0GUK1)), a pretty major backtesting bug and now the ability to process event data as per live, big thanks to [@U01B8031PM1](@U01B8031PM1) on sponsoring this development and allowing it to be open source :smile:



Small change required to allow event processing:

```strategy = ExampleStrategy(

    market_filter={"markets": [..], "event_processing": True},

)```

The `Market` object has a helper method for accessing other linked event markets (live and simulated):

```place_market = market.event["PLACE"]```

This allows you for example to backtest win/place in racing or all football markets as per live, this also only seems to add around 5% in processing time. I don't think there is anything else out there on the market which allows backtesting like this :sunglasses:

---

## 2021-04-06 22:15:32 - issues channel

**Jonjonjon**

Should [https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/strategy/strategy.py#L203-L206|this code](https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/strategy/strategy.py#L203-L206|this code):



        `if runner_context.trade_count &gt;= self.max_trade_count:`

            `order.violation_msg = "strategy.validate_order failed: trade_count ({0}) &gt;= max_trade_count ({1})".format(`

                `runner_context.trade_count, self.max_live_trade_count`

            `)`



Become



        `if runner_context.trade_count &gt;= self.max_trade_count:`

            `order.violation_msg = "strategy.validate_order failed: trade_count ({0}) &gt;= max_trade_count ({1})".format(`

                `runner_context.trade_count, self._*max_trade_count*_`

            `)`

---

## 2021-04-04 21:16:45 - random channel

**Jonjonjon**

[@UBS7QANF3](@UBS7QANF3). Yes. Via steam. And I tried a load of different suggested fixes from Protondb. In the end I decided I should spend more time gambling on horses instead.

---

## 2021-04-04 21:15:52 - random channel

**Mo**

Were you playing through Steam? Did you look it up on protondb and apply any recommended fixes?

---

## 2021-04-04 06:59:16 - random channel

**liam**

There is a [https://github.com/liampauling/flumine/pull/406/commits/b956086b177fbcbfef68d805d77798a6e249cd9c|bug](https://github.com/liampauling/flumine/pull/406/commits/b956086b177fbcbfef68d805d77798a6e249cd9c|bug) which I found last week which means there is a chance they won’t be if two identical strategies are executed in the same framework, should be releasing 1.18.0 soon with a fix 

---

## 2021-04-03 17:55:39 - random channel

**Lee**

is there believed to be much fixing in racing?

---

## 2021-04-02 13:51:56 - general channel

**liam**

Potential race conditions that I haven’t had enough sleep to debug 

---

## 2021-04-01 10:00:19 - general channel

**Oliver Varney**

exchange isnt looking great still listmarketcatalogue errors ....

---

## 2021-04-01 00:09:21 - general channel

**Misha**

Anyone successful in Australia with fixed odds agencies uses "bowler" accounts (friends, colleagues, etc). It's the only way to be able to bet with all but a small number of agencies. One person I know has been through about 50 accounts with one agency

---

## 2021-03-31 08:29:23 - issues channel

**Oliver Varney**

Does each 503 exception count as an event

---

## 2021-03-31 08:28:29 - issues channel

**liam**

just exceptions, its the 503 from my workers which has maxed me out

---

## 2021-03-31 08:25:26 - issues channel

**Oliver Varney**

do you use it for logging or just exceptions ?

---

## 2021-03-29 18:02:04 - general channel

**river_shah**

do you have an example on how to poll the betgenius feed instead please? currently I am using this:

```import logging



from flumine.events.events import CustomEvent



logger = logging.getLogger(__name__)





def poll_in_play_service(context: dict, flumine, event_id: str) -&gt; None:

    trading = flumine.client.betting_client



    response = trading.in_play_service.get_scores(event_ids=[event_id])

    if response is None:

        logger.warning(

            "poll_in_play_service",

            extra={"response": response, "event_id": event_id},

        )

    for score in response:

        flumine.handler_queue.put(CustomEvent(score, callback))





def callback(flumine, event):

    # update market context

    score = event.event

    for market in flumine.markets:

        if market.event_id == str(score.event_id):

            logger.debug(

                "Updated market {0} with event {1} scores data".format(

                    market.market_id, market.event_id

                )

            )

            market.context["score"] = score```



---

## 2021-03-28 00:50:27 - general channel

**Sam Asin**

I can't decide if this is good enough that I should be really suspicious I'm doing something wrong, I looked for an error and haven't found one yet. Or is that a pretty expected result from basic elo/glicko

---

## 2021-03-25 08:25:58 - strategies channel

**PeterLe**

Yes thanks Gents; I was just making a cuppa and thought this was more easily calculated that I first thought. So to keep things simple assume I was using a fixed stake and i know that for eg a MC simulation on past results were 10% (ie MC beats strategy) then i would create a go forward model and use a random number generator. Then run over a large number of iterations and count the longest sequence of losing runs ? This would be better actually that trying to calculate it in monetary terms as the loss would be proportionate to the profits at that time. Thanks again.

---

## 2021-03-23 18:22:54 - issues channel

**river_shah**

nice, was in the park for a workout. everything failed safe, +1 for flumine

---

## 2021-03-23 16:57:56 - strategies channel

**Michael**

I think it might be worth considering your methodology. Every time you 'filter' or change your strategy then check again it becomes more likely that you'll over-fit and no MC will detect that - I'm sure that's what [@U016TGY3676](@U016TGY3676) experienced, it's what inevitably happens if you iterate strategy changes over a fixed data set. A different way to interrogate the soundness of your strategy might be to isolate the individual conjectures that it's based on and see if you can evidence them using simple reasoning, graphs and so on. In other words - step back from your bets and find ways to check if the underlying strategy is based on sound thinking.

---

## 2021-03-23 10:07:24 - strategies channel

**Michael**

Code bug. Switch it off and fix that.

---

## 2021-03-23 10:06:51 - strategies channel

**mandelbot**

Yes It's been betting 4 pounds because the strategy is firing 2 pounds twice, not sure how to fix that...

---

## 2021-03-22 20:58:34 - random channel

**Paul**

The fact it “failed” does not mean it failed. It would not take much to back all those selections on the exchange, scatter around the impression of a gamble, watch the price move in, lay off on the exchanges and pocket the change. Wouldn’t surprise me if we don’t see more of this if people have figured out how to spook bookies...

---

## 2021-03-22 19:21:00 - strategies channel

**Michael**

The reason I asked about your existing betting is that that might be a simpler way of calibrating your confidence. If you did the same type of thing that you did last time then you'll probably get the same type of result. All the statistical tests are wide open to error if your development process is weak because so many development pathways move inexorably towards excessive overfitting. I think it's also worth asking what more or less confidence would do for you in terms of informing your actions. In all likelihood the best approach will be to just give it a go with minimal stakes, having more confidence wouldn't make starting off more aggressively into a good idea and having less confidence probably won't stop you from having a go even if only for the sake of learning.  You probably already know in your gut whether having a go is a good idea. Think carefully about your reasoning and where your value comes from, if you can say that your reasoning is sound and you can identify why you expect your bets to have value then you're good to go.

---

## 2021-03-22 09:34:39 - general channel

**Misha**

It would be a very small fraction of a %. I would estimate less than 0.01% POT. Given that POT% is all over the shop, it wouldn't even measure as a rounding error

---

## 2021-03-21 11:27:28 - general channel

**D C**

So [@U016535QCJ2](@U016535QCJ2) as you use FoK and are placing huge numbers of bets maybe you can answer my question that I have not yet asked Betfair. As most people don't like FoK as implemented by Betfair seems nobody else can have as good a stab at the answer as you do. For a failed FoK bet, are you charged for a SINGLE  transaction or does it act as 2 (place bet/ cancel bet) ?

---

## 2021-03-21 10:11:22 - general channel

**Unknown**

I have the data to show it doesn't matter (would be less than a rounding error). I don't waste time duplicating functionality that would make no measurable difference to profitability

---

## 2021-03-19 18:51:44 - general channel

**Lee**

i've not done this as there's not much i can do to start it again apart from restarting the whole flumine process, also the retry has always fixed things quicker than i could

---

## 2021-03-19 16:28:27 - general channel

**river_shah**

How do I signal a backtest framework to terminate gracefully please? This is giving:

```flumine.handler_queue.put(TerminationEvent(flumine))

AttributeError: 'list' object has no attribute 'put'```

---

## 2021-03-18 08:51:16 - random channel

**Oliver Varney**

morning, apologies if this is a basic question, im trying to get my head around how to improve my version control with SQL. I am wondering how people structure this with something like git. What does the workflow look like? How do you apply changes through environments. what should I track and what shouldnt I (i.e. everything including small data fixes?)

---

## 2021-03-17 08:42:39 - strategies channel

**Alessio**

(although flumine is robust enough since strategies run into separate exception blocks, I still find it better)

---

## 2021-03-17 08:42:02 - strategies channel

**Alessio**

Also, tbh, while liam graciously fixed a related bug last week, I think running a recorder in a different process from your strategies is better. 1) you can record more than you actually bet on 2) in case one of the two starts having trouble doesn't affect the other one

---

## 2021-03-16 15:33:50 - issues channel

**Aaron Smith**

Hey guys! I got this error:

```{"asctime": "2021-03-16 15:10:03,427", "levelname": "ERROR", "message": "[MarketStream: 2002]: MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s)."}```

and now i m slightly confused on what exactly counts as a connection :smile:

---

## 2021-03-16 12:49:40 - issues channel

**James McKenzie**

Hi guys, I have an AUS betfair account that I just have an app key, username and password for. Im trying to scrape race cards for AUS races and hitting the error -

```betfairlightweight.exceptions.RaceCardError: Unable to find appKey```

seems the app key is being found from a request response in the RaceCard.login method. Does anyone know why I am getting this error and can I fix it by just editing the login method to take the app key that I have. Cheers.

---

## 2021-03-16 10:00:49 - general channel

**D C**

SE - standard error. Like a standard deviation you can apply around a point estimate. From memory most maximum likelihood estimates thrown out by a linear model are shown to be normally distributed.

---

## 2021-03-15 20:43:03 - issues channel

**IndikaE**

Long story short: I need danish authentication , and I figured out how to do that. I handle it in the ApiClient by using the .set_session_token() - no issue there. But then I pass the bflw ApiClient to a BetfairClient and start a Flumine instance with this client. But then Flumine by default runs the login procedure for self.client - and then everything blows up - because normal login does not work for danish authentication. I fixed it by simply commenting out self.client.login() in the enter method of BaseFlumine. Everything seems to work fine. However, I would like to know if there could be some hidden issue with this method of authentication. Does anyone know of a better(less hacky) way around this? If this method is indeed ok, then maybe the framework should detect when the client has the session token set, and just skip login? 

---

## 2021-03-12 14:41:46 - issues channel

**Peter C**

Thanks. I did try that so my error must be somewhere else. Cheers

---

## 2021-03-11 22:52:06 - random channel

**Misha**

There are no such thing as market results based on the fixed rules of a game. It's an area where if you do this, sports betting has no financial equivalent

---

## 2021-03-11 18:36:02 - random channel

**river_shah**

fixed it

---

## 2021-03-10 17:13:57 - general channel

**user34**

I'm sorry if the answer to this question is already in the chat or examples, but I am looking to migrate my betfairlightweight strategy to flumine for hopefully better reliability and logging and I am having a hard time figuring out how to do this. My comfort zone for coding is very much defining functions that process specific inputs so this could be something in Python I am missing. My current set-up has separate processes that i) identify appropriate event ids in the next day, ii) identify the relevant market ids from those event ids and manage streaming subscriptions, and iii) receives data from the streams at fixed intervals and decides whether to place bets or cancel existing bets.

---

## 2021-03-09 09:52:16 - general channel

**D C**

Why not? I mean prematurely closing a market that subsequently has to be reversed due to a disallowed goal in a top league game has to be seen as a bad error. Suspend the market for sure but do it completely until the decision becomes irreversible. I don't know how it is actually done internally so maybe VAR is just not compatible with Betfair market settlement right now. Even more reason to provide us with unmanaged markets as a side market. We get it with NFL - someone "scores" market goes crazy, play gets reviewed and reversed - all without a market suspension. I just don't get why football is treated in such a different manner. Fine keep the managed markets but at least give us an option with unmanaged ones.

---

## 2021-03-09 09:47:29 - general channel

**D C**

You could forgive a dodgy inplayfeed if you knew the market management was sound at the Betfair end. I suppose overall it works but they make some shocking errors with disallowed goals etc since VAR came to the party.

---

## 2021-03-09 08:05:13 - issues channel

**liam**

Now fixed and released in bflw/flumine

---

## 2021-03-08 14:03:13 - random channel

**Newbie99**

This is possibly more of a maths question, than a Python one and hopefully quite a simple one, but my brain appears to be malfunctioning.



All I am trying to do, is create a function that returns the win probability for a and b (be they runners or teams) for a series n length (for now not allowing draws) on the assumption the series ends after one a or b reaches the target number of games (e.g. 3 out of 5, 4 out of 7 etc) and therefore  when calculating for a, a always has to win the final game (and vice versa).



This is what I've come up with, however what's bugging me is that the summed probabilities keeps increasing the higher number of games in the series, so I'm trying to get my head round whether I've made a coding mistake or if there is a mathematical reason for this that I've missed?



```from math import ceil, pow, comb



def calc_win_probability(n, p_a, p_b=False):



    if p_b is False:

        p_b = 1-p_a



    g = ceil(n/2)

    prob_list = []

    for i in range(g,n+1):

        a = (comb(i,g-1) * pow(p_a,g-1) * pow(p_b,(i - (g-1)))) * p_a

        b = (comb(i,g-1) * pow(p_b,g-1) * pow(p_a,(i - (g-1)))) * p_b

        prob_list.append({'games': i, 'prob_a_win': a, 'prob_b_win': b, 'combined_prob': a+b})



    return {'overall_prob': sum([p['combined_prob'] for p in prob_list]) ,'prob_list': prob_list}



t = calc_win_probability(7,2/3,1/3)



for x in t['prob_list']:

    print(x,'\n','----------------------------------------------------------')

print({'total_prob': t['overall_prob']})```

---

## 2021-03-08 13:01:26 - issues channel

**birchy**

[@U4H19D1D2](@U4H19D1D2) Think this may be a bug, as the declarations say that `total_matched` should be `float` , however I can confirm that I'm seeing `None` :

[https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/resources/bettingresources.py#L560](https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/resources/bettingresources.py#L560)



[https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/resources/bettingresources.py#L478](https://github.com/liampauling/betfair/blob/f370d111d2e7adf1ca4221fc8cc4b028e4b2b2f8/betfairlightweight/resources/bettingresources.py#L478)

---

## 2021-03-08 11:51:50 - issues channel

**liam**

Should be fixed in 1.17.8

---

## 2021-03-07 17:41:48 - issues channel

**birchy**

[@U4H19D1D2](@U4H19D1D2) think I've found the problem. Been through the logs and discovered a couple of intermittent critical errors due to a bug in my strategy code. Just to clarify, does Flumine reload the orders on restart?

---

## 2021-03-06 19:09:05 - issues channel

**Alessio**

oh that's not that trivial to fix

---

## 2021-03-06 19:05:38 - issues channel

**liam**

Ideally no, tricky bug as we want the blotter function to be called if there are orders I.e real strategy live on that market 

---

## 2021-03-06 18:59:19 - issues channel

**Alessio**

(happy to fix it)

---

## 2021-03-06 18:56:46 - issues channel

**liam**

You should be able to just need to fix this bug, issue is in the blotter where it is trying to update the orders with the runner status, if the raw data stream closes first then it calls the close market func and errors 

---

## 2021-03-06 18:53:56 - issues channel

**Aaron Smith**

i m getting the same error when ever i add the S3 recorder to my framework (not immediatly, but eventually)

---

## 2021-03-06 18:47:36 - issues channel

**Alessio**

And then boom:

```File "/usr/local/lib/python3.7/site-packages/flumine/baseflumine.py", line 244, in _process_close_market

market.blotter.process_closed_market(event.event)

 File "/usr/local/lib/python3.7/site-packages/flumine/markets/blotter.py", line 61, in process_closed_market

  for runner in market_book.runners:

AttributeError: 'dict' object has no attribute 'runners'```



---

## 2021-03-06 14:52:53 - strategies channel

**D C**

The TRUE probability, whilst unknown is fixed.

---

## 2021-03-06 14:35:54 - strategies channel

**Michael**

Having said the above - I think I know where your confusion is coming from. Let me explain what I think you're thinking and why it's wrong: Say you had a 3 runner horse race that you knew nothing else about, you could reasonably price all runners at 3 and if you then evaluated that prediction in an information vacuum over many events it would turn out to be correct because one runner of the 3 will always win. If you 'paper traded' in your own private exchange then hypothetical bets at odds &gt; 3 would show a profit. Great, all your predictions look perfect, 3 is always 0EV.  Meanwhile someone else is looking at the same 3 runner races but they have access to some basic information about the relative quality of each horse that allows them to better price the runners. Will they agree that all horses are correctly priced at 3?  No. They will make some other model and generate from it a 0EV price that will be different to yours. Let's assume they validate that by testing over many markets so that it performs perfectly. So from your perspective (information blind) it looks like 3 is always 0EV and from his with some limited information he's generating 0EV prices that are not 3. That can make it look like there's more than one 0EV price - but that's an error. Consider what happens if you bet against him in an exchange, you've priced every horse at 3 but he knows better. Where's your 0EV now? You're backing any price he'll offer you that's &gt;3 and he's putting a deposit on a Ferrari. In this case both players have an ESTIMATE for 0V which looks perfect when evaluated internally but it turns out that one estimate is better than the other. That's because the notion of a 'true' 0EV price is predicated on a hypothetical state where all possible information is known. Anything else is an estimate that gets as close to that 'truth' as possible. I think your mistake comes from a failure to recognise that whilst your estimates of 0EV can reconcile perfectly when evaluated internally they wouldn't stand up to superior information and ultimately to perfect 'true' information.

---

## 2021-03-06 14:07:26 - strategies channel

**D C**

100% this -&gt; "_*There are many beginners reading this forum, it's confusing and damaging for them to have you repeating this error as if it's a fact.*_". Saying that a true value/0EV price does not exist is basically saying that you don't know anything about or don't believe in probability theory and statistical inference and it is dangerous to propagate that notion to people new to the game who may not have the confidence to call out this flawed thinking.

---

## 2021-03-06 13:52:54 - strategies channel

**Michael**

Saying that you don't know whether X price has positive, negative or zero value isn't the same as insisting that 0EV doesn't exist, it's just recognising that you don't know it. There are many beginners reading this forum, it's confusing and damaging for them to have you repeating this error as if it's a fact. When you say that there is _'no single "right" price for a runner'_ you're arguing that there is either no 0EV price or more than one. The former conjecture (the idea that there is no 0EV price) is impossible to reconcile with the idea of +EV and -EV as you obviously can't have both without a mid-point. The latter (more than one 0EV price) would imply that a given price can simultaneously be both -EV and +EV, in other words both the layer and the backer can make a profit on the same bet, this can't be true either on a single instance or on hypothetical repetitions.  So: Since there can't be less than one 0EV price and there can't be more than one how many 0EV prices are there for a particular bet at a particular instant? ONE

---

## 2021-03-05 15:21:00 - general channel

**liam**

you will get an error through the stream when trying to subscribe

---

## 2021-03-05 11:19:42 - issues channel

**Lee**

yeah getting a couple of errors here and there since around 9ish. API and streaming timeout issues

---

## 2021-03-04 08:47:45 - issues channel

**Misha**

[@UBS7QANF3](@UBS7QANF3) - imagine if it took you 24 hours to fix a problem with your system. How hard is it to get a fairly "simple" call working?

---

## 2021-03-04 08:44:54 - issues channel

**Mo**

Ah just got a reply from Neil, yeah it's a known issue that they're hoping to fix this morning

---

## 2021-03-03 21:31:57 - issues channel

**Lee**

user error for my first error

---

## 2021-03-03 21:25:58 - issues channel

**Mo**

Every account I try to scrape seems to hit this at some point:

```{'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0003', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'ie1-aanbf04b-prd-02080927-001532aeaa', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}}}, 'id': 1}```

---

## 2021-03-03 21:24:32 - issues channel

**Lee**

yeah i'm getting timeout errors

---

## 2021-03-03 09:29:12 - general channel

**captainonionhead**

Hmm, thanks, that fits with what I was expecting but I must be doing something wrong as I'm only ever getting one Trade of orders placed (because I check runner_context.live_trade_count in process_market_book() as per the example but it doesn't reset back to zero when the orders have matched).

More debugging to do - thanks for your help!

---

## 2021-03-03 09:14:42 - issues channel

**liam**

hmm, without debugging going to be tricky unless you can replicate a simple example strategy

---

## 2021-03-02 18:05:52 - issues channel

**mandelbot**

I'm having some trouble using `market.context` . My process is I record to `market.context`, using `round(market.seconds_to_start)`as a key, a list including for example total_matched and price. The problem is when I attempt to call the context I always get a keyerror. When I print `market.context` I can see that the data I want is there but it seems im not referencing it correctly?

---

## 2021-03-02 13:23:58 - issues channel

**Newbie99**

Ok cool, I added a check to that test script (i.e. not to place a new order if there is an existing order).



No errors.



Tried on my main script.



Also no errors.



So at a glance, it appears you have caught it!

---

## 2021-03-02 12:57:38 - issues channel

**Newbie99**

yeah, that test script is non-sensical, its just to demo this issue :slightly_smiling_face:



I now get this error:



`{"asctime": "2021-03-02 12:56:07,189", "levelname": "WARNING", "message": "validate_order failed: live_trade_count (1) &gt;= max_live_trade_count (1)"}`

---

## 2021-03-02 10:45:40 - issues channel

**liam**

For me this errors because you continually try to replace the order, so get the `prices match` error

---

## 2021-03-02 08:35:37 - issues channel

**liam**

Could be this bug [https://github.com/liampauling/flumine/issues/354](https://github.com/liampauling/flumine/issues/354) mixed with this one [https://github.com/liampauling/flumine/issues/290](https://github.com/liampauling/flumine/issues/290)

---

## 2021-03-01 20:15:21 - strategies channel

**Atho55**

Evening all. This is my 1st post and would like to canvas a few opinions if that`s ok. Do any of you use any available data to project forward potential bets where the race outcome decides if it`s a win or loss? Simple Back or Lay bets to a fixed stake. Like this for the week coming. The Rank is at the top and assumes all meetings/all races follow the script for that day.

---

## 2021-03-01 20:02:43 - issues channel

**Peter C**

I don't believe either because orders placed within a few seconds of each other are matched at both ends of the 300-1000 elapsed seconds scale. I'll try setting to debug and see what I get.

---

## 2021-03-01 20:00:23 - issues channel

**liam**

Is that coinciding with market closure? or a suspension? If you set simulated logging to debug you can see when the orders get matched 

---

## 2021-03-01 18:00:48 - issues channel

**liam**

Haha, the only bug I know of was the replace one fixed today! 

---

## 2021-03-01 17:56:34 - issues channel

**Newbie99**

Also using 1.17.5, once I get a violation for an order below min size then this warning appears and can't place a subsequent order, is this intended behaviour (I would have assumed once you try to place a correctly sized order, the message should go and the order should flow upstream)?



This is just paper trading (in case that makes a difference).



Correctly failed order:

```{"asctime": "2021-03-01 16:18:18,238", "levelname": "WARNING", "message": "Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency", "control": "ORDER_VALIDATION", "error": "Order size is less than min bet size (2) or payout (10) for currency", "order": {"market_id": "1.179865560", "selection_id": 38527720, "handicap": 0, "id": "138339079234466185", "customer_order_ref": "869aeb021cad4-138339079234466185", "bet_id": "100000000162", "date_time_created": "2021-03-01 16:12:03.446618", "publish_time": "2021-03-01 16:12:03.626000", "trade": {"id": "933fb664-7aa8-11eb-a42d-2016d8944b85", "strategy": "simple_back_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138339078008452709", "138339079234466185"], "notes": "", "market_notes": "190,330,340", "status": "Live", "status_log": "Pending, Live, Pending, Live"}, "order_type": {"order_type": "Limit", "price": 180.0, "size": 0.05, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.05, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-03-01 16:12:03.447618", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Pending, Executable, Violation", "violation_msg": "Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency", "simulated": {"profit": 0.0, "piq": 3.65, "matched": []}}}```

Correctly sized order that fails to place, due to previous violation:

```{"asctime": "2021-03-01 16:25:39,365", "levelname": "WARNING", "message": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure", "control": "STRATEGY_EXPOSURE", "error": "strategy.validate_order failure", "order": {"market_id": "1.179865560", "selection_id": 38527720, "handicap": 0, "id": "138339087393647136", "customer_order_ref": "869aeb021cad4-138339087393647136", "bet_id": null, "date_time_created": "2021-03-01 16:25:39.364713", "publish_time": null, "trade": {"id": "c2a66a1f-7aaa-11eb-a8f0-2016d8944b85", "strategy": "simple_back_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138339087393647136"], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 290.0, "size": 0.06, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.06, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure", "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}}}```

---

## 2021-03-01 16:55:46 - issues channel

**liam**

there was a bug with replace fixed this morning, what version are you on now?

---

## 2021-03-01 10:51:05 - issues channel

**IndikaE**

Hi. First post here - been lurking for a while. I absolutely love flumine, and I am preparing to deploy my first strategy. I just noticed, that after upgrading to flumine 1.17.4 that I started to hit the transaction limit(5000) when backtesting on around 1000 markets. My strategy usually places only 1-10 orders per market. I initially thought that I had a problem with the monkey patching of datetime, so that the control would use actual system time(this would explain the limit kicking in). However, after debugging a bit, now I don’t believe that to be the case(patched time seems to be ok). My markets are passed and processed in random chronological order, could this be causing trouble in the max transaction limit control? Also the first error occurs with a transaction_count of 6152, not 5001, as I would have expected. As I saw that some changes to this control were made with the latest version, I thought it might be an issue, but I absolutely cannot rule out that I am doing something wrong here. 

---

## 2021-03-01 09:49:09 - random channel

**Dave**

Maybe there is a fixed initial cost for alarms and any additional alarms are negligible in cost. I'll dig

---

## 2021-02-28 19:01:20 - issues channel

**Jaume Colom Ferrer**

`DEBUG:urllib3.connectionpool:[https://historicdata.betfair.com:443](https://historicdata.betfair.com:443) "POST /api/DownloadListOfFiles HTTP/1.1" 302 None`

`DEBUG:urllib3.connectionpool:[https://historicdata.betfair.com:443](https://historicdata.betfair.com:443) "GET /home/ngErrorRedirect HTTP/1.1" 200 None`

---

## 2021-02-28 19:01:13 - issues channel

**Jaume Colom Ferrer**

I am trying to download historic files, but its returning me a 302 http error

---

## 2021-02-27 02:04:28 - issues channel

**birchy**

Did a `pip` Flumine upgrade earlier am now getting lots of errors in my backtest code:

```File "...snip.../tradingcontrols.py", line 22, in _validate

if order.EXCHANGE == ExchangeType.BETFAIR:

AttributeError: 'Market' object has no attribute 'EXCHANGE'```

Not sure if this is a bug or whether I need to make any further changes to my strategy code? Have added the `RunnerContext` check as discussed between [@U4H19D1D2](@U4H19D1D2) and [@UFTBRB3F1](@UFTBRB3F1) above. Note that I'm not using `market.replace_order()` ...these errors are from plain old `market.place_order(order)`

---

## 2021-02-26 22:03:06 - general channel

**thambie1**

Do you guys find Betfair properly honors the stream subscription heartbeatMs field, which sets the minimum period during which you expect a message from the stream? Tried setting the field, and am not getting regular messages. After some debugging, I think the issue is on Betfair's end.

---

## 2021-02-26 17:15:05 - issues channel

**Newbie99**

```{"asctime": "2021-02-26 15:42:09,137", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.179756075", "selection_id": 28040651, "handicap": 0, "id": "138336469255121051", "customer_order_ref": "6012fe3b915f7-138336469255121051", "bet_id": "100000000018", "date_time_created": "2021-02-26 15:42:05.512104", "publish_time": "2021-02-26 15:42:05.763000", "trade": {"id": "2d6ee89a-7849-11eb-841c-2016d8944b85", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138336469255121051"], "notes": "", "market_notes": "11,11.5,11.5", "status": "Pending", "status_log": "Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 10.5, "size": 1.57, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 1.57, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-02-26 15:42:05.716102", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Execution complete", "status_log": "Pending, Executable, Replacing, Execution complete", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 139.7, "matched": []}}

INFO:flumine.execution.baseexecution:Order Cancel: SUCCESS

{"asctime": "2021-02-26 15:42:09,138", "levelname": "INFO", "message": "Order Cancel: SUCCESS", "bet_id": "100000000018", "order_id": "138336469255121051", "status": "SUCCESS", "error_code": null}

INFO:flumine.execution.baseexecution:Order Replace: SUCCESS

{"asctime": "2021-02-26 15:42:09,139", "levelname": "INFO", "message": "Order Replace: SUCCESS", "bet_id": null, "order_id": "138336469291386029", "status": "SUCCESS", "error_code": null}

INFO:flumine.order.order:Order status update: Violation

{"asctime": "2021-02-26 15:42:09,140", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.179756075", "selection_id": 28040651, "handicap": 0, "id": "138336469291386029", "customer_order_ref": "6012fe3b915f7-138336469291386029", "bet_id": "100000000057", "date_time_created": "2021-02-26 15:42:09.138602", "publish_time": null, "trade": {"id": "2d6ee89a-7849-11eb-841c-2016d8944b85", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138336469255121051", "138336469291386029"], "notes": "", "market_notes": "11,11.5,11.5", "status": "Pending", "status_log": "Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 11.0, "size": 1.57, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 1.57, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-02-26 15:42:09.139609", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 254.41, "matched": []}}

WARNING:flumine.controls:Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure

{"asctime": "2021-02-26 15:42:09,141", "levelname": "WARNING", "message": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure", "control": "STRATEGY_EXPOSURE", "error": "strategy.validate_order failure", "order": {"market_id": "1.179756075", "selection_id": 28040651, "handicap": 0, "id": "138336469291386029", "customer_order_ref": "6012fe3b915f7-138336469291386029", "bet_id": "100000000057", "date_time_created": "2021-02-26 15:42:09.138602", "publish_time": null, "trade": {"id": "2d6ee89a-7849-11eb-841c-2016d8944b85", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138336469255121051", "138336469291386029"], "notes": "", "market_notes": "11,11.5,11.5", "status": "Pending", "status_log": "Pending, Live, Pending"}, "order_type": {"order_type": "Limit", "price": 11.0, "size": 1.57, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 1.57, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-02-26 15:42:09.139609", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure", "simulated": {"profit": 0.0, "piq": 254.41, "matched": []}}} ```

---

## 2021-02-26 10:29:39 - issues channel

**Newbie99**

[@U4H19D1D2](@U4H19D1D2) in flumine 1.17.2 I saw there's a mention of a bug fix around potential exposure, I'm seeing a lot of these:



```INFO:flumine.order.order:Order status update: Violation

{"asctime": "2021-02-26 10:17:21,505", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.179742967", "selection_id": 28253114, "handicap": 0, "id": "138336274415049218", "customer_order_ref": "6012fe3b915f7-138336274415049218", "bet_id": null, "date_time_created": "2021-02-26 10:17:21.504921", "publish_time": null, "trade": {"id": "d00f5a01-781b-11eb-8ae9-2016d8944b85", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138336274415049218"], "notes": "", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 16.0, "size": 1.0, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 1.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Violation", "status_log": "Violation", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}}

WARNING:flumine.controls:Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failure```

When by my calcs I shouldn't be anywhere near a violation. I'm placing orders using market.place(order) as opposed to strategy.place and this is paper trading if it makes a difference.



Is it possible a bug remains, or perhaps more likely is there another change I need to make (I read through the change logs but I appear to have missed something)?

---

## 2021-02-26 08:53:13 - general channel

**liam**

yep, have a look at the `on_data` func, it updates these values / error handles before it gets down to the operation type on line 131

---

## 2021-02-25 10:52:09 - strategies channel

**Lee**

But i don't really know how to scale so been learning through a bit of trial and error

---

## 2021-02-24 15:36:23 - issues channel

**Aaron Smith**

yea should be an easy fix, just didnt know it would react like that. Thanks liam :slightly_smiling_face:

---

## 2021-02-24 15:35:37 - issues channel

**liam**

yeah that could be the problem, simple to fix no?

---

## 2021-02-24 15:10:44 - issues channel

**Aaron Smith**

Hey guys, i m still struggeling with my Latency issue, i have little clue how to "debug" this. I thought i d just put out all my current warning logs, maybe someone can make any sense of it, i d be grateful :smile: first: the latency issue seemingly isnt the result of to much processing per market update, even when i m not processing anything, i still eventually get the same problem. The framework is running on an ec2 instance, which i thought should be rather stable. Its a linux instance, so OS time should be in sync with an NTP server.

Problem: _"[MarketStream: 2001]: Latency high: 1.0108046531677246"_

Latency can go up to 6s.



That said, my suspicous logs:

• sometimes i get _"Market &lt;market_id&gt; not present when closing"_, i dont know why it happens, timewise it doesnt seem to correlate with the _Latency high_ warning.

• And now the probably bigger problem:

```{"asctime": "2021-02-23 21:19:59,560", "levelname": "ERROR", "message": "[MarketStream: 4001]: SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 12930 markets whereas max allowed number was: 200"}

{"asctime": "2021-02-23 21:20:10,572", "levelname": "ERROR", "message": "MarketStream run error", "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py\", line 216, in _receive_all\n    part = self._socket.recv(self.buffer_size)\n  File \"/usr/lib64/python3.7/ssl.py\", line 1056, in recv\n    return self.read(buflen)\n  File \"/usr/lib64/python3.7/ssl.py\", line 931, in read\n    return self._sslobj.read(len)\nsocket.timeout: The read operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/flumine/streams/marketstream.py\", line 32, in run\n    self._stream.start()\n  File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py\", line 59, in start\n    self._read_loop()\n  File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py\", line 198, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py\", line 220, in _receive_all\n    raise SocketError(\"[Connect: %s]: Socket %s\" % (self._unique_id, e))\nbetfairlightweight.exceptions.SocketError: [Connect: 4002]: Socket The read operation timed out"}

{"asctime": "2021-02-23 21:20:12,575", "levelname": "WARNING", "message": "[Listener: 4002]: stream already registered, replacing data"}```

These 3 fellas are getting logged right behind each other. The first few hours everything seems fine, until eventually these show up. I m not sure why it tries to subscribe to 12k (its always roughly 12k) markets, thats at least not what i m telling it to do. The fact it doesnt give this error the first few hours makes me feel like something bad is stacking up in the background (allthough if this was to log as soon as i hit &gt;200 markets, the jump from 200 to 12k seems kinda big). I know its not you guys job to solve my probs, but maybe some smart being immediatly has an idea of whats up - i d surely appreciate it :slightly_smiling_face:

---

## 2021-02-24 13:08:29 - general channel

**river_shah**

`AttributeError: 'Flumine' object has no attribute 'config'` where do I need to change  the hostname so that two instances of the framework running on the same host don’t trample on each other’s orders please?

---

## 2021-02-24 11:28:32 - general channel

**liam**

FYI flumine [https://github.com/liampauling/flumine/blob/master/HISTORY.rst#1171-2021-02-24|1.17.1](https://github.com/liampauling/flumine/blob/master/HISTORY.rst#1171-2021-02-24|1.17.1) released with transaction control fix and `blotter.strategy_selection_orders` function added

```{

    "asctime": "2021-02-24 11:00:54,794",

    "levelname": "INFO",

    "message": "Execution new hour",

    "filename": "clientcontrols.py",

    "funcName": "_check_hour",

    "module": "clientcontrols",

    "process": 6,

    "threadName": "MainThread",

    "current_transaction_count_total": 387,

    "current_transaction_count": 357,

    "current_failed_transaction_count": 30,

    "total_transaction_count": 831,

    "total_failed_transaction_count": 61,

    "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7fd48db7adc0&gt;"

}```

---

## 2021-02-23 11:41:25 - general channel

**liam**

invalid bet size would be picked up at the control level which would be an error

---

## 2021-02-23 09:19:26 - general channel

**liam**

fix inbound [https://github.com/liampauling/flumine/pull/376](https://github.com/liampauling/flumine/pull/376)

---

## 2021-02-22 18:03:33 - general channel

**river_shah**

`"status": "FAILURE", "errorCode": "LOSS_LIMIT_EXCEEDED"`

---

## 2021-02-22 16:43:48 - general channel

**Mo**

[https://www.betfair.com/aboutUs/Betfair.Charges/#TranCharges2](https://www.betfair.com/aboutUs/Betfair.Charges/#TranCharges2)



&gt; *What is a failed transaction?*

&gt; An action that leads to an API error, resulting in a failed bet placement, failed cancellation or other failed transaction. Full descriptions of each failed transaction type can be found in the link below:

&gt; [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-ExecutionReportErrorCode](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-ExecutionReportErrorCode)

---

## 2021-02-22 11:01:43 - general channel

**Unknown**

see [https://github.com/liampauling/flumine/blob/0b0bb9d8b7a2ca94c05996284692bccaede679c1/flumine/execution/betfairexecution.py#L205|here](https://github.com/liampauling/flumine/blob/0b0bb9d8b7a2ca94c05996284692bccaede679c1/flumine/execution/betfairexecution.py#L205|here) to how you can get the full traceback, ie. flumine will give it to you by default on all errors, just don't set level to info or warning as it will just kill your CPU (learnt that the hard way!)

---

## 2021-02-22 10:56:55 - general channel

**liam**

i set level to error



```    if sentry:

        # sentry

        sentry_logging = LoggingIntegration(

            level=level,  # Capture info and above as breadcrumbs

            event_level=event_level,  # Send errors as events

        )

        sentry_sdk.init(

            dsn="",

            integrations=[sentry_logging],

            release="flumine-prod@{0}".format(version),

            environment=environment,

        )

        with sentry_sdk.configure_scope() as scope:

            scope.user = {"id": instance_id}

            scope.set_tag("application", instance)

            scope.set_tag("flumine", flumine.__version__)```

---

## 2021-02-22 10:56:06 - general channel

**Oliver Varney**

are you logging betfair trade errors responses and stuff along these lines?

---

## 2021-02-22 10:53:54 - general channel

**liam**

i then use the slack plugin so I get notifications on errors, I have done but it was in beta and started slowing things down for me so i left it but it was very cool

---

## 2021-02-22 10:49:07 - general channel

**Oliver Varney**

Morning chaps, just looking into improving exception handling / logging /performance monitoring etc, and I know [@U4H19D1D2](@U4H19D1D2) and other use sentry. Other then their site is there any good resources people would recommend?

---

## 2021-02-21 14:21:31 - general channel

**river_shah**

what is the graceful way to tell the framework to shutdown please? I have a handle to the framework in the strategy. Calling this causes errors

```self.framework._process_end_flumine()

self.framework.__exit__()

CRITICAL Unknown error API logout FAIL: INPUT_VALIDATION_ERROR```



---

## 2021-02-21 06:05:21 - issues channel

**liam**

[@UFTBRB3F1](@UFTBRB3F1) that was fixed a while ago by checking if the update is a snap or not. [@U01DVUAE2G1](@U01DVUAE2G1) you probably right here although its difficult to debug as betfair will start to conflate if you are not pulling off the socket quick enough. However if you are getting the 2s warning then you are either maxing your CPU or you are processing the updates too slow. If you get the `Latency High..` warning you either have network or CPU issues.

They are just supposed to be warnings to highlight potential issues, they could probably be improved in the codebase or by the user elsewhere, I did create an [https://github.com/liampauling/flumine/issues/338|issue](https://github.com/liampauling/flumine/issues/338|issue) to track this better to allow easier tracing/profiling

---

## 2021-02-20 11:58:57 - random channel

**Misha**

Fixed, Tote, and Betfair

---

## 2021-02-20 11:56:57 - random channel

**James T**

To check turnover charge races I used to have a fixed venue list but that always had mistakes and even Betfair seemed inconsistent when asked. Now I just check the market description rules for the string “this is a racing nsw turnover charge market”. 

---

## 2021-02-19 14:06:10 - general channel

**Michael**

I didn't try too hard with finding the error.

---

## 2021-02-19 08:09:38 - general channel

**captainonionhead**

Thanks Mo - I guess I'd expected that there wasn't a fixed boundary for this but was wondering if it would be problematic if I was to be making minimum-sized bets until I'd got a better feel for how everything moves or if the volume of bets I made was relatively small whilst I'm developing and testing.

---

## 2021-02-18 11:42:42 - random channel

**Aaron Smith**

Should probs have fixed it long ago, but i hate doing that kinda stuff :smile:

---

## 2021-02-18 11:42:13 - random channel

**Aaron Smith**

my last OS update made a big chaos aswell. My VS is no longer showing syntax-mistakes live (have to safe for it to show any errors) and even then, it seems like it misses 90% of errors. Also no more auto-complete. My terminal lost all its colours and no longer tells me which git branch i m in. I read some stack-overflow, but couldnt find the root cause and basically decided to postpone fixing that (has been a month now :smile: ) and now i m just very careful while writing code :smile:

---

## 2021-02-18 10:13:34 - random channel

**tobsve**

```logging.basicConfig(level=logging.DEBUG)```

What if you sett to above?

---

## 2021-02-18 08:22:07 - general channel

**Angelos**

hi there, i really like the strategy builder in [https://github.com/liampauling/flumine/blob/master/flumine/strategy/strategy.py|flumine](https://github.com/liampauling/flumine/blob/master/flumine/strategy/strategy.py|flumine) and i’m giving a go now!



i’m wondering if there’s a way to configure it to *not use* the streaming API and run the framework on a fixed interval instead?



alternatively, is there a way to configure the stream to trigger the fetch every minute?

---

## 2021-02-18 07:09:20 - general channel

**KG**

thanks [@UBS7QANF3](@UBS7QANF3) - I amended with the patch, still getting the same error though - any chance you can cast your eyes over my code and see if you can catch my mistake? I'm not a python native, but trying to get the library to work:



```import logging



from unittest.mock import patch

import smart_open



import betfairlightweight

from betfairlightweight import StreamListener



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



# create trading instance (don't need username/password)

trading = betfairlightweight.APIClient("username", "password")



# create listener

listener = StreamListener(max_latency=None)



# create historical stream (update file_path to your file location)

stream = trading.streaming.create_historical_generator_stream(

    file_path="../_data/2021_01_JanRacingPro.tar",

    listener=listener,

)



with patch("builtins.open", smart_open.open):   

    gen = stream.get_generator()



    for market_books in gen():

        for market_book in market_books:

            print(market_book)```

---

## 2021-02-18 06:38:35 - general channel

**KG**

hey guys. has anyone used bflw to read in the PRO historical data sets from their TAR form? I'm following the [https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py|sample code](https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py|sample code) and getting the following error, which I assume is due to the TAR format?



```UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 569: character maps to &lt;undefined&gt;```

---

## 2021-02-17 10:10:16 - general channel

**Jono**

Hi there. Ive been messing around with pulling through account statements using bflw but am occasionally running into problem an INVALID_APP_KEY error. Do you know if the delayed key is unable to access this endpoint/resource for some reason or should this not affect account retrieval?

---

## 2021-02-17 08:22:56 - general channel

**Alessio**

eexactly. now I tried Ray ~ a few months ago, but the main problem is that if you get an exception you are not guaranteed to understand where it happened

---

## 2021-02-16 18:42:18 - random channel

**birchy**

[@UQL0QDEKA](@UQL0QDEKA) have you not heard of Martingale? :rolling_on_the_floor_laughing:

Seriously though, fractional Kelly is the way forward. Rather than using the _actual_ bank for calculating, I would use a fixed bank size and update daily/weekly/every 1000 bets/whatever.

---

## 2021-02-16 17:11:04 - random channel

**Aaron Smith**

the only fix point this could ever have (a point where stakes remain the same) is when (total) earnings remain the same

---

## 2021-02-16 13:24:28 - general channel

**Unknown**

I got an error when I added  EX_BEST_OFFERS_DISP, I think that's just for streaming ?

I found an extra option called virtualise though for the Price Filter, doesn't seem to make much difference though.

I'll do some more digging though, thanks for your help.

---

## 2021-02-16 12:04:39 - issues channel

**Jonjonjon**

Apologies for forgetting to post the error:



  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/backtest.py", line 44, in run`

    `self._process_market_books(events.MarketBookEvent(event))`

  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/backtest.py", line 84, in _process_market_books`

    `middleware(market)  # todo err handling?`

  `File "/home/jon/PycharmProjects/flumine/flumine/markets/middleware.py", line 67, in _call_`

    `self._process_simulated_orders(market, market_analytics)`

  `File "/home/jon/PycharmProjects/flumine/flumine/markets/middleware.py", line 142, in _process_simulated_orders`

    `order.simulated(market.market_book, runner_analytics)`

  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/simulated.py", line 44, in _call_`

    `self._process_sp(market_book.publish_time_epoch, runner)`

  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/simulated.py", line 230, in _process_sp`

    `size = round(remaining_risk / (actual_sp - 1.0), 2)`

`TypeError: unsupported operand type(s) for -: 'str' and 'float'`

---

## 2021-02-16 09:41:42 - issues channel

**Lee**

looks fixed now

---

## 2021-02-16 09:23:17 - issues channel

**liam**

What errors?

---

## 2021-02-15 21:08:52 - issues channel

**jhaa**

I have this unseen error in my logs from calling:





```current_orders = self.trading.betting.list_current_orders(market_ids=[stream_market.get_market_id()],

                                                          from_record=from_record)```



---

## 2021-02-15 21:08:12 - issues channel

**jhaa**

Traceback (most recent call last):

  File "/home/code/venv/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 113, in process_response

    return resource(elapsed_time=elapsed_time, **result)

  File "/home/code/venv/lib/python3.6/site-packages/betfairlightweight/resources/bettingresources.py", line 695, in __init__

    self.orders = [CurrentOrder(**i) for i in kwargs.get("currentOrders")]

  File "/home/code/venv/lib/python3.6/site-packages/betfairlightweight/resources/bettingresources.py", line 695, in &lt;listcomp&gt;

    self.orders = [CurrentOrder(**i) for i in kwargs.get("currentOrders")]

TypeError: __init__() missing 1 required positional argument: 'regulatorCode'

---

## 2021-02-14 18:31:46 - issues channel

**Newbie99**

when its a banned country it just says you can't from that location (or the API errors)

---

## 2021-02-14 18:14:30 - issues channel

**Jonjonjon**

I hope they fix it for you quickly!

---

## 2021-02-11 12:03:02 - strategies channel

**Michael**

[@U0128E7BEHW](@U0128E7BEHW) yeah assumes some small fixed stake. In my case that's about £5 for that type of betting.

---

## 2021-02-10 22:14:50 - random channel

**Misha**

Australia does have a fixed upper limit of 24, so per country it might be OK

---

## 2021-02-08 12:16:18 - random channel

**Jonjonjon**

Could we set up our own Oracle and fix the results?

---

## 2021-02-05 17:42:43 - issues channel

**river_shah**

```  File "/usr/local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 229, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 1021]: Socket The read operation timed out```



---

## 2021-02-05 17:02:18 - issues channel

**river_shah**

[@U4H19D1D2](@U4H19D1D2) can bflw and flumine allow interactive login please for streaming? if I don’t pass a cert path and use `trading.login_interactive()` the framework throws exception.

---

## 2021-02-04 18:40:37 - issues channel

**river_shah**

```2021-02-04 18:38:21.901 INFO  [OrderStream: 1001]: connection_id: 202-040221183821-2787044

2021-02-04 18:38:21.901 INFO  [MarketStream: 2001]: connection_id: 204-040221183821-2814581

2021-02-04 18:38:32.806 ERROR MarketStream run error

Traceback (most recent call last):

  File "/home/xxx/.local/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 225, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "/apps/python/3.7.9/lib/python3.7/ssl.py", line 1056, in recv

    return self.read(buflen)

  File "/apps/python/3.7.9/lib/python3.7/ssl.py", line 931, in read

    return self._sslobj.read(len)

socket.timeout: The read operation timed out



During handling of the above exception, another exception occurred:```

Logins fine (can list market catalogue etc) but then get this when trying to stream. Not sure where to start debugging.

---

## 2021-02-04 17:01:29 - issues channel

**Lee**

na, was getting the ca too weak error

---

## 2021-02-04 16:23:16 - issues channel

**Lee**

I think i need to regenerate my cert again as i get ssl errors on later versions of openssl. If i upload another certificate under the Security settings page, will it add a second cert or replace my existing?

---

## 2021-02-04 13:29:41 - issues channel

**mandelbot**

`{"asctime": "2021-02-04 13:26:56,741", "levelname": "ERROR", "message": "poll_market_catalogue error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/flumine/worker.py\", line 132, in poll_market_catalogue\n    \"MARKET_DESCRIPTION\",\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py\", line 233, in list_market_catalogue\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue \nParams: {'maxResults': 25, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'filter': {'marketIds': ['1.178881473', '1.178881478', '1.178881488', '1.178881493', '1.178777677', '1.178777679', '1.178777426', '1.178833494', '1.178847880', '1.178847882', '1.178777194', '1.178883033', '1.178883028', '1.178883003', '1.178883008', '1.178883023', '1.178883018', '1.178883013', '1.178848742', '1.178848744', '1.178848702', '1.178848700', '1.178777963', '1.178777027']}} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang18a-prd-01140948-002d67ab25', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang18a-prd-01140948-002d67ab25', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_market_catalogue", "response": "SportsAPING/v1.0/listMarketCatalogue \nParams: {'maxResults': 25, 'marketProjection': ['COMPETITION', 'EVENT', 'EVENT_TYPE', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA', 'MARKET_START_TIME', 'MARKET_DESCRIPTION'], 'filter': {'marketIds': ['1.178881473', '1.178881478', '1.178881488', '1.178881493', '1.178777677', '1.178777679', '1.178777426', '1.178833494', '1.178847880', '1.178847882', '1.178777194', '1.178883033', '1.178883028', '1.178883003', '1.178883008', '1.178883023', '1.178883018', '1.178883013', '1.178848742', '1.178848744', '1.178848702', '1.178848700', '1.178777963', '1.178777027']}} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang18a-prd-01140948-002d67ab25', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang18a-prd-01140948-002d67ab25', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}`

---

## 2021-02-04 13:29:17 - issues channel

**mandelbot**

hrms seems like im getting some timeout errors

---

## 2021-02-04 13:26:02 - issues channel

**liam**

what are your logs saying? any errors / restarts?

---

## 2021-02-04 07:29:52 - issues channel

**Peter C**

For anyone searching for this in the future the issue was that I hadn't imported the logging and therefore couldn't see the error message

---

## 2021-02-04 07:24:01 - random channel

**Mo**

Detecting strange market prices also has value for detecting match fixes but you do need to be careful as [@U016535QCJ2](@U016535QCJ2) says because to find value you need to disagree with the market

---

## 2021-02-03 20:40:15 - issues channel

**Peter C**

I'm trying to access live data for the first time - using the quickstart example from the docs. I import the example strategy, and start(self) runs, but then check_market_book doesn't appear to be called, but the program continues to run with no error. Has anyone experienced this before?

---

## 2021-02-02 09:44:59 - issues channel

**liam**

yeah I use it a lot, you need to be careful when calling `market.place_order` as it doesn't call `strategy.validate_order` the PR I am working on fixes this by removing the `strategy.place_order` call completely

---

## 2021-01-30 16:01:13 - issues channel

**birchy**

Oh bugger. I guess the way forward is to poll listMarketCatalogue and specify the market id's in `streaming_market_filter`?

---

## 2021-01-30 15:48:47 - issues channel

**liam**

No market time in the def? That’s odd, upgrading flumine to 1.16.1 might fix 

---

## 2021-01-30 15:38:55 - issues channel

**mandelbot**

im getting the following error when running backtests with the latest flumine and bflw

```Traceback (most recent call last):

  File "C:\Users\Admin\AppData\Local\Programs\Python\Python39\Lib\site-packages\flumine\examples\backtest2gh.py", line 54, in &lt;module&gt;

    framework.run()

  File "C:\Users\Admin\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\backtest\backtest.py", line 42, in run

    for event in stream_gen():

  File "C:\Users\Admin\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\streams\historicalstream.py", line 148, in _read_loop

    data = stream_snap()

  File "C:\Users\Admin\AppData\Local\Programs\Python\Python39\lib\site-packages\flumine\streams\historicalstream.py", line 67, in snap

    cache.market_definition["marketTime"]

KeyError: 'marketTime'```



---

## 2021-01-29 19:02:58 - general channel

**Alessio**

(the error was on my side to start, but still..)

---

## 2021-01-29 08:57:42 - general channel

**Misha**

I'm surprised that Mo bets on more matches than me - there basically isn't anything left apart from the ITF matches with no liquidity. I even bet on early ITF, which most people think is crazy (possible match fixing)

---

## 2021-01-28 17:55:59 - strategies channel

**liam**

`The trigger was a guy running a ridiculous bot on the API on one of his unfunded sub accounts.



It was doing a martingale over and over again, going from tiny to huge stakes in a cycle. The max stake on the exchange was some very large number, I don’t remember what, but bigger than 2e31.



Two things happened at the exact same moment: this martingale bot tried to place some huge bet way over the numeric max (and crucially, over that subaccount’s exposure limit) this caused a numeric error inside the trading engine exposure checking code.



This bet was rejected and you never saw it: all good. Unfortunately, the long dormant bug activated and allowed another bet which was not over the numeric max stake but was over the exposure limit for the account (it had nothing like the 20m to bet in it) to skip the exposure check.



Because it was a valid stake and the exposure check was missed, it went into the market and became good value pretty quickly. The nature of the bug meant that both bets had to be placed effectively at the same time, otherwise the tiny window of time that the numeric error opened up for the second bet to skip the exposure check would be closed again.



All involved in all aspects of handling this bug at the time were given the usual spiel of secrecy, which was fair because the bug was exploitable for a little while until fixed.



However, it was fixed long ago (although similar bugs probably existed because the codebase was very difficult to reason over) and now that whole trading system has been rewritten in a more modern language with a safer architecture (and it’s much much faster). I imagine there are all sorts of bugs in it, but they won’t be this type.`

---

## 2021-01-28 17:48:46 - general channel

**river_shah**

can you please step through debug and check if you get sensible numbers here: `runner_book.ex.traded_volume: RunnerBook`

---

## 2021-01-28 09:12:35 - issues channel

**thambie1**

Yeah, that parts easy. The part I need to put some effort into is handling the business logic afterwards. In this particular case, how should be bot handle the case where my account funds knowledge is stale? Keep betting normal sizes, and risk getting an insufficient funds error? Keep betting, and not have my fail safes regarding losing too much money too quickly?

---

## 2021-01-28 09:01:27 - issues channel

**liam**

yeah I am getting errors

---

## 2021-01-28 08:59:47 - issues channel

**Oliver Varney**

the dev status site says its fixed now I think, it looked like a getAccountFunds issue

---

## 2021-01-27 14:01:16 - general channel

**liam**

```MARKET INFORMATION



For further information please see Rules &amp; Regs.



Who will finish 1st or 2nd in this race? NON RUNNERS DO NOT CHANGE THE PLACE TERMS. Should the number of runners be equal to or less than the number of places available as set out above in these rules all bets will be void. Betfair Non-Runner Rule applies. This market will turn IN PLAY at the off with unmatched bets (with the exception of bets for which the "keep" option has been selected) cancelled once the Betfair SP reconciliation process has been completed. Betting will be suspended at the end of the race. This market will initially be settled on a First Past the Post basis. However we will re-settle all bets should the official result at the time of the "weigh-in" announcement differ from any initial settlement. BETS ARE PLACED ON A NAMED HORSE. Dead Heat rules apply.```

---

## 2021-01-24 19:23:27 - general channel

**birchy**

I'm not really qualified enough to be specific, but as I understand it, bflw was the original implementation of the streaming API and users then had to consume the data &amp; JSON dicts themselves for handling strategies, bet placement, etc. That also means you have to do your own error handling, connection handling, etc. I believe Flumine has been developed on top of bflw in order to address those issues and create a much simpler interface for end users, particularly where strategy development and backtesting is concerned.

---

## 2021-01-21 15:37:40 - issues channel

**liam**

test it by raising a random error or disconnecting from the internet

---

## 2021-01-21 15:28:39 - issues channel

**jhaa**

supposedly it writes the error message

---

## 2021-01-21 15:24:59 - issues channel

**liam**

Only way this could fail without logs is if it errors on that login call 

---

## 2021-01-21 15:20:50 - issues channel

**jhaa**

```class SafeStreamingThread(threading.Thread):

    def __init__(

        self,

        client: betfairlightweight.APIClient,

        market_filter: dict,

        market_data_filter: dict,

        conflate_ms: int = None,

        streaming_unique_id: int = 1000,

        queue = None,

        listener = None

    ):

        threading.Thread.__init__(self, daemon=True, name=self.__class__.__name__)

        self.client = client

        self.market_filter = market_filter

        self.market_data_filter = market_data_filter

        self.conflate_ms = conflate_ms

        self.streaming_unique_id = streaming_unique_id

        self.stream = None

        self.output_queue = queue

        self.listener = listener #StreamListener(output_queue=self.output_queue)



    @retry(wait=wait_exponential(multiplier=1, min=2, max=20))

    def run(self) -&gt; None:

        [http://logging.info|logging.info](http://logging.info|logging.info)("Starting MarketStreaming")

        self.client.login()

        self.stream = self.client.streaming.create_stream(

            unique_id=self.streaming_unique_id, listener=self.listener

        )

        try:

            self.streaming_unique_id = self.stream.subscribe_to_markets(

                market_filter=self.market_filter,

                market_data_filter=self.market_data_filter,

                conflate_ms=self.conflate_ms,

                initial_clk=self.listener.initial_clk,  # supplying these two values allows a reconnect

                clk=self.listener.clk,

            )

            self.stream.start()

        except BetfairError:

            logging.error("MarketStreaming run error", exc_info=True)

            raise

        except Exception:

            logging.critical("MarketStreaming run error", exc_info=True)

            raise

        [http://logging.info|logging.info](http://logging.info|logging.info)("Stopped MarketStreaming {0}".format(self.streaming_unique_id))



    def stop(self) -&gt; None:

        if self.stream:

            self.stream.stop()```



---

## 2021-01-21 15:10:58 - issues channel

**jhaa**

so without error message I do not know where to start looking

---

## 2021-01-21 15:10:02 - issues channel

**jhaa**

as in the thing thre an exception without printing/logging the error message

---

## 2021-01-21 15:08:15 - issues channel

**jhaa**

I have a slow thread and a fast thread that do different things and have different urgencies. A week ago I could see in the logs that the slow thread stopped working because I only had output from the fast thread in the logs. Today it was the other way around. There are no error messages.

---

## 2021-01-21 15:05:46 - issues channel

**jhaa**

well I do not know where to start looking in the code if there is no error message... I use tenacity the way it is used here:  [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)

---

## 2021-01-21 15:01:29 - issues channel

**jhaa**

Every other day one of the threads in my bot stops working without throwing an error or crashing the whole thing. I suspect tenacity might be the reason why I get no error message. I use the example that restarts the order and market streams. Any suggestion what might cause this or anybody has experienced similar?

---

## 2021-01-21 13:29:53 - issues channel

**liam**

Getting place errors, anyone else?

---

## 2021-01-20 12:18:09 - general channel

**Mo**

You'll get a BET_TAKEN_OR_LAPSED error for that cancellation

---

## 2021-01-19 19:05:09 - issues channel

**liam**

Yeah, if you have the response that would be great to see what the error is 

---

## 2021-01-19 19:03:46 - issues channel

**jhaa**

I have a bunch of football fixtures in a database and query the inplay scores using the event_ids. Some of those fixtures are accumulators or specials which cause the query to return an error:



`Traceback (most recent call last):`

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 108, in process_response

    return [resource(elapsed_time=elapsed_time, **x) for x in result]

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 108, in &lt;listcomp&gt;

    return [resource(elapsed_time=elapsed_time, **x) for x in result]

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/resources/inplayserviceresources.py", line 193, in __init__

    self.score = Score(**kwargs.get("score"))

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/resources/inplayserviceresources.py", line 87, in __init__

    self.home = HomeAwayBase(**home)

TypeError: __init__() missing 1 required positional argument: 'name'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File "/home/code/PycharmProjects/betfair_jhaa/v2/core/StreamEngine.py", line 247, in query_inplay_scores

    scores = [http://self.trading.in|self.trading.in](http://self.trading.in|self.trading.in)_play_service.get_scores(event_ids=event_ids)

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/endpoints/inplayservice.py", line 99, in get_scores

    return self.process_response(

  File "/home/code/PycharmProjects/venv/lib/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 110, in process_response

    raise InvalidResponse(response=result)

betfairlightweight.exceptions.InvalidResponse: Invalid response received:

---

## 2021-01-18 18:39:36 - issues channel

**Diniz**

I'm getting this error atm: urllib3.exceptions.SSLError: Client private key is encrypted, password is required

---

## 2021-01-18 17:58:42 - issues channel

**Diniz**

Not really, I get the same errors.

Do the certificates need to have a specific name? I'm just passing the folder where they are

---

## 2021-01-17 21:03:19 - general channel

**Taking Value**

Additional quick question - Is there an API out there that can be used to get data such as prize money and class for a horse race. I was getting it via the betfair racing post API but the script I was using decided to switch its self off a few months ago and I didn't realise(_ok it *may* have been poorly designed and I *might* be at fault_) . Corrected the error but I have a 3 month hole in my data I need to fill.

---

## 2021-01-15 09:41:55 - general channel

**Jono**

so what are the values that are returned when i access these attributes in the code? Since this doesnt cause errors are they place holder numbers

---

## 2021-01-14 17:00:57 - random channel

**Mick**

No, I'm just getting HTTP ERROR 403

---

## 2021-01-14 09:43:29 - issues channel

**Newbie99**

As in the logic within the function? Its completely possible its not perfect, but what I don't understand is, given I check the order is Executable at multiple points, how can the status be incorrect (even if say I'm trying to cancel when I mean to replace, it wouldn't throw that error)?

---

## 2021-01-14 09:43:29 - issues channel

**liam**

Recommend [http://sentry.io|sentry.io](http://sentry.io|sentry.io) btw as you would then get the full traceback with a lot more info although that error could be improved

---

## 2021-01-14 09:34:30 - issues channel

**Newbie99**

```{"asctime": "2021-01-14 09:12:30,117", "levelname": "INFO", "message": "Order status update: Cancelling", "market_id": "1.177891689", "selection_id": 16786966, "handicap": 0, "id": "138299083469138870", "customer_order_ref": "6012fe3b915f7-138299083469138870", "bet_id": "221690469430", "date_time_created": "2021-01-14 09:12:26.913912", "publish_time": "2021-01-14 09:12:26.886000", "trade": {"id": "9ef0aa3a-5648-11eb-a0bb-02f9e1e2dd3a", "strategy": "simple_lay_mm", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138299083469138870"], "notes": "", "market_notes": "8.4,8.8,8.6", "status": "Live", "status_log": "Pending, Live"}, "order_type": {"order_type": "Limit", "price": 8.2, "size": 2.08, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 2.08, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": "2021-01-14 09:12:27.117261", "elapsed_seconds_executable": null}, "runner_status": null, "status": "Cancelling", "status_log": "Pending, Executable, Cancelling", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}}

INFO:flumine.streams.orderstream:Stopped OrderStream 1001

{"asctime": "2021-01-14 09:12:30,117", "levelname": "INFO", "message": "Stopped OrderStream 1001"}

INFO:flumine.streams.marketstream:Stopped MarketStream 2001

{"asctime": "2021-01-14 09:12:30,118", "levelname": "INFO", "message": "Stopped MarketStream 2001"}

INFO:flumine.execution.baseexecution:Shutting down Execution (SimulatedExecution)

{"asctime": "2021-01-14 09:12:30,118", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

INFO:flumine.execution.baseexecution:Shutting down Execution (BetfairExecution)

{"asctime": "2021-01-14 09:12:30,119", "levelname": "INFO", "message": "Shutting down Execution (BetfairExecution)"}

INFO:flumine.worker:BackgroundWorker keep_alive shutting down

{"asctime": "2021-01-14 09:12:30,119", "levelname": "INFO", "message": "BackgroundWorker keep_alive shutting down", "worker_name": "keep_alive", "function": "&lt;function keep_alive at 0x7f7644889680&gt;"}

INFO:flumine.streams.orderstream:Stopped output_thread (OrderStream 1001)

{"asctime": "2021-01-14 09:12:30,365", "levelname": "INFO", "message": "Stopped output_thread (OrderStream 1001)"}

INFO:flumine.streams.marketstream:Stopped output_thread (MarketStream 2001)

{"asctime": "2021-01-14 09:12:32,043", "levelname": "INFO", "message": "Stopped output_thread (MarketStream 2001)"}

INFO:flumine.worker:BackgroundWorker poll_account_balance shutting down

{"asctime": "2021-01-14 09:12:34,120", "levelname": "INFO", "message": "BackgroundWorker poll_account_balance shutting down", "worker_name": "poll_account_balance", "function": "&lt;function poll_account_balance at 0x7f76448967a0&gt;"}

INFO:flumine.worker:BackgroundWorker poll_market_catalogue shutting down

{"asctime": "2021-01-14 09:12:38,120", "levelname": "INFO", "message": "BackgroundWorker poll_market_catalogue shutting down", "worker_name": "poll_market_catalogue", "function": "&lt;function poll_market_catalogue at 0x7f7644896710&gt;"}

INFO:flumine.worker:BackgroundWorker poll_cleared_orders shutting down

{"asctime": "2021-01-14 09:12:42,121", "levelname": "INFO", "message": "BackgroundWorker poll_cleared_orders shutting down", "worker_name": "poll_cleared_orders", "function": "&lt;function poll_cleared_orders at 0x7f7644896830&gt;"}

INFO:flumine.baseflumine:Exiting flumine

{"asctime": "2021-01-14 09:12:46,214", "levelname": "INFO", "message": "Exiting flumine", "client": {"id": "74093be2", "exchange": "Betfair", "betting_client": "APIClient", "chargeable_transaction_count": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxOrderCount object at 0x7f7643506d50&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": false}, "markets": {"market_count": 262, "open_market_count": 259}, "streams": ["&lt;OrderStream(OrderStream, stopped daemon 140145877423872)&gt;", "&lt;MarketStream(MarketStream, stopped daemon 140145869031168)&gt;"], "logging_controls": [], "threads": ["&lt;_MainThread(MainThread, started 140146403047232)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 140145910994688)&gt;", "&lt;BackgroundWorker(poll_account_balance, started daemon 140145902601984)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 140145894209280)&gt;", "&lt;BackgroundWorker(poll_cleared_orders, started daemon 140145885816576)&gt;"]}

Traceback (most recent call last):

  File "jumps.py", line 187, in &lt;module&gt;

    framework.run()

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/flumine.py", line 32, in run

    self._process_current_orders(event)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/baseflumine.py", line 238, in _process_current_orders

    strategy.process_orders(market, strategy_orders)

  File "/home/ec2-user/trading/env/projects/simple_book.py", line 418, in process_orders

    rf.cancel_and_replace_orders(self, orders, market)

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 3563, in cancel_and_replace_orders

    back_all_runners_without_back_price

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 3699, in replace_all_orders

    self.replace_order(market, order, back_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/strategy/strategy.py", line 146, in replace_order

    market.replace_order(order, new_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/markets/market.py", line 70, in replace_order

    order.replace(new_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/order.py", line 332, in replace

    raise OrderUpdateError("Current status: %s" % self.status)

flumine.exceptions.OrderUpdateError: Current status: OrderStatus.CANCELLING

(env) [ec2-user@ip-172-31-8-45 projects]$       ```

---

## 2021-01-14 09:31:57 - issues channel

**Newbie99**

This is confusing me a bit, I've been getting this a lot over the last couple of days (seemingly out of the blue). Whilst the error is self explanatory, what I'm not understanding is how it occurs, as I check the order status before any cancel or replace:



```Traceback (most recent call last):

  File "jumps.py", line 187, in &lt;module&gt;

    framework.run()

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/flumine.py", line 32, in run

    self._process_current_orders(event)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/baseflumine.py", line 238, in _process_current_orders

    strategy.process_orders(market, strategy_orders)

  File "/home/ec2-user/trading/env/projects/simple_book.py", line 418, in process_orders

    rf.cancel_and_replace_orders(self, orders, market)

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 3563, in cancel_and_replace_orders

    back_all_runners_without_back_price

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 3699, in replace_all_orders

    self.replace_order(market, order, back_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/strategy/strategy.py", line 146, in replace_order

    market.replace_order(order, new_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/markets/market.py", line 70, in replace_order

    order.replace(new_price)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/order/order.py", line 332, in replace

    raise OrderUpdateError("Current status: %s" % self.status)

flumine.exceptions.OrderUpdateError: Current status: OrderStatus.CANCELLING```

---

## 2021-01-13 21:05:07 - strategies channel

**D C**

Most academics are in the game for their passion for the subject matter - not the application to making money. Exceptions of course exist but you won't get far in academia without at least a lot of passion for your subject matter. Brains help too but hard work and deep interest drives it for most academics I have worked with.

---

## 2021-01-13 10:57:13 - issues channel

**liam**

simulation limitation pending a fix [https://github.com/liampauling/flumine/blob/2adcd24379e07dfc1a017ffcc7895d99102814ee/flumine/backtest/simulated.py#L37](https://github.com/liampauling/flumine/blob/2adcd24379e07dfc1a017ffcc7895d99102814ee/flumine/backtest/simulated.py#L37)

---

## 2021-01-12 12:37:31 - strategies channel

**liam**

Latter, 90% of the time is processing the market so you should take advantage of this and put in as many strategies as you can. If you have issues then you will probably have issues live and you need to fix 

---

## 2021-01-12 09:11:29 - general channel

**Carsten**

betfairlightweight.exceptions.AppKeyError:

---

## 2021-01-12 08:51:26 - general channel

**Carsten**

when running the code as is in example i get this :

 trading.set_session_token(session_token[0])

IndexError: list index out of range

---

## 2021-01-11 22:23:16 - issues channel

**Newbie99**

```{"asctime": "2021-01-11 22:06:46,792", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.177838493", "selection_id": 25383704, "handicap": 0, "id": "138296955628176706", "customer_order_ref": "869aeb021cad4-138296955628176706", "bet_id": "221534743900", "trade": {"id": "f3590071-5458-11eb-b622-2016d8944b85", "strategy": "simple_back_mm", "status": "TradeStatus.LIVE", "orders": ["138296954581483634", "138296954616777215", "138296955628176706"], "notes": "", "market_notes": "13.5,14,13.5"}, "order_type": {"order_type": "Limit", "price": 13.5, "size": 0.2, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.01, "size_remaining": 0.19, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 13.5}, "status": "Violation", "status_log": "Pending, Executable, Replacing, Violation"}

INFO:flumine.order.trade:Trade status update: Complete

{"asctime": "2021-01-11 22:06:46,793", "levelname": "INFO", "message": "Trade status update: Complete", "id": "f3590071-5458-11eb-b622-2016d8944b85", "strategy": "simple_back_mm", "status": "TradeStatus.COMPLETE", "orders": ["138296954581483634", "138296954616777215", "138296955628176706"], "notes": "", "market_notes": "13.5,14,13.5"}

WARNING:flumine.controls:Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency

{"asctime": "2021-01-11 22:06:46,794", "levelname": "WARNING", "message": "Order has violated: ORDER_VALIDATION Error: Order size is less than min bet size (2) or payout (10) for currency", "control": "ORDER_VALIDATION", "error": "Order size is less than min bet size (2) or payout (10) for currency", "order": {"market_id": "1.177838493", "selection_id": 25383704, "handicap": 0, "id": "138296955628176706", "customer_order_ref": "869aeb021cad4-138296955628176706", "bet_id": "221534743900", "trade": {"id": "f3590071-5458-11eb-b622-2016d8944b85", "strategy": "simple_back_mm", "status": "TradeStatus.COMPLETE", "orders": ["138296954581483634", "138296954616777215", "138296955628176706"], "notes": "", "market_notes": "13.5,14,13.5"}, "order_type": {"order_type": "Limit", "price": 13.5, "size": 0.2, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.01, "size_remaining": 0.19, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 13.5}, "status": "Violation", "status_log": "Pending, Executable, Replacing, Violation"}}```

With Flumine, the above violates (obviously because its less than GBP 10), however using the REST API it is possible to replace small orders, so should it work from Flumine, or is the above expected behaviour (specifically on a replace)?



If so, other than quickly placing and cancelling, is there a smarter way to submit small orders (I know this comes up every now and again, but I thought the replace approach was the correct one and I'd never really had much of a need when streaming before)?

---

## 2021-01-11 11:04:51 - general channel

**river_shah**

problem fixed. the issue was that docker container `openssl.cnf` was missing this section:

```[ ssl_client ]

basicConstraints = CA:FALSE

nsCertType = client

keyUsage = digitalSignature, keyEncipherment

extendedKeyUsage = clientAuth```

appending it fixes docker login issue

---

## 2021-01-11 10:28:28 - general channel

**river_shah**

```        except requests.ConnectionError as e:

&gt;           raise APIError(None, exception=e)

E           betfairlightweight.exceptions.APIError: None

E           Params: None

E           Exception: HTTPSConnectionPool(host='[http://identitysso-cert.betfair.com|identitysso-cert.betfair.com](http://identitysso-cert.betfair.com|identitysso-cert.betfair.com)', port=443): Max retries exceeded with url: /api/certlogin (Caused by SSLError(SSLError(398, '[SSL: CA_MD_TOO_WEAK] ca md too weak (_ssl.c:3911)')))```



---

## 2021-01-11 08:14:20 - general channel

**liam**

Just released a beta of [https://github.com/liampauling/betfair/pull/371|2.12.0b0](https://github.com/liampauling/betfair/pull/371|2.12.0b0) which contains the streaming refactor, using [@UBS7QANF3](@UBS7QANF3) benchmark looking at the following improvements:



```# lightweight (2.3x improvement)

#  master: 6.860s (100%|██████████| 10/10 [00:06&lt;00:00,  1.46it/s])

#  2.12.0: 2.998s (100%|██████████| 10/10 [00:02&lt;00:00,  3.34it/s])



# Non lightweight (3.4x improvement)

#  master: 36.005s (100%|██████████| 10/10 [00:35&lt;00:00,  3.60s/it])

#  2.12.0: 10.625s (100%|██████████| 10/10 [00:10&lt;00:00,  1.06s/it])



# Non lightweight with flumine patching/listener/stream (2.8x improvement)

#  master: 13.896s (100%|██████████| 10/10 [00:13&lt;00:00,  1.39s/it])

#  2.12.0: 5.005s (100%|██████████| 10/10 [00:04&lt;00:00,  2.00it/s])```

A quick [https://github.com/liampauling/flumine/pull/361|test](https://github.com/liampauling/flumine/pull/361|test) on flumine and this equates to around a 2.3x speed improvement which is massive and equates to flumine running through a market faster than the current lightweight implementation! CPU has also halved when running live which is a nice bonus.



Going to stay in beta until I can test this properly in production but I have carried out some regression tests on various markets throughout (hasn't just been optimised for this one market) However feel free to test when backtesting and let me know if there any bugs.

---

## 2021-01-10 18:40:01 - strategies channel

**Dave**

Generally fixed stake, and due to the events I'm forecasting the odds are quite short (usually prices &lt;2). And yeah, my backtest definitely factors in spread and volumes so low liquidity events generally get skipped over

---

## 2021-01-09 15:19:26 - strategies channel

**liam**

[https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/baseflumine.py#L48|Here](https://github.com/liampauling/flumine/blob/707a81990d1c51d64e964c781c5e700fe58646de/flumine/baseflumine.py#L48|Here) you can see how it’s added, if you then debug on a market update and have a look at `market.context` you will see the simulated data which under runners? has what you are after and more 

---

## 2021-01-08 10:24:56 - issues channel

**jhaa**

I could just replicate the same thing on a different fixture

---

## 2021-01-07 12:23:51 - general channel

**Misha**

Errors come and go. I never worry unless I get a heap of them over an extended period of time

---

## 2021-01-07 12:23:03 - general channel

**ash**

I think i errored out on a accountfunds call a few minuets ago..  but the I have done that call again since and stream seems to be working for me right now?

---

## 2021-01-07 12:17:22 - general channel

**Misha**

Getting a few API errors at the moment

---

## 2021-01-07 12:17:10 - general channel

**Lee**

yeah, got a few errors from the api calls

---

## 2021-01-07 12:16:15 - general channel

**D C**

Anyone else getting stream 503 errors right now???

---

## 2021-01-05 23:08:39 - random channel

**Sam Asin**

but now i know where to look to try to fix this

---

## 2021-01-05 10:15:33 - issues channel

**Alessio**

(it's logging in correctly, working everything, but i get those keep alive errors)

---

## 2021-01-05 10:03:28 - issues channel

**Alessio**

Hey [@U4H19D1D2](@U4H19D1D2) how did you choose the 1200 seconds for the API keep_alive? I am seeing repeatedly this stuff:

`{"asctime": "2021-01-05 09:56:39,831", "levelname": "ERROR", "message": "keep_alive error", "exc_info": "Traceback (most recent call last):\n File \"/usr/local/lib/python3.7/site-packages/flumine/worker.py\", line 97, in keep_alive\n  resp = client.keep_alive()\n File \"/usr/local/lib/python3.7/site-packages/flumine/clients/betfairclient.py\", line 32, in keep_alive\n  return self.betting_client.keep_alive()\n File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/keepalive.py\", line 30, in __call__\n  (response, response_json, elapsed_time) = self.request(session=session)\n File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/keepalive.py\", line 56, in request\n  self._error_handler(response_json)\n File \"/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/keepalive.py\", line 63, in _error_handler\n  raise self._error(response)\nbetfairlightweight.exceptions.KeepAliveError: API keepAlive FAIL: NO_SESSION", "trading_function": "keep_alive", "response": "API keepAlive FAIL: NO_SESSION"}`

---

## 2021-01-05 08:52:00 - general channel

**bogdan**

I think if double quotes were important, I would get an error.

---

## 2021-01-05 07:55:25 - issues channel

**Mick**

Doh!... it's actually printed as part of the message... it's TIMEOUT_ERROR

---

## 2021-01-05 07:50:59 - issues channel

**Mick**

Just got Error code from betfairlightweight -32099... is there somewhere to look up the meaning of the error codes?

---

## 2021-01-04 22:29:59 - issues channel

**Alessio**

log_violation_errors is an extra bool that makes them pop

---

## 2021-01-04 12:24:18 - general channel

**Oliver Varney**

I think [@U01A8EKD545](@U01A8EKD545) example will be the easiest by the looks, depends if you need to rebuild the trade or not. The trade class does a fair bit of functionality for me (but I think im very much the exception to how I use this class)

---

## 2021-01-03 16:26:07 - issues channel

**nthypes**

```line 35, in process_market_book\n    s = runner.last_price_traded - runner.sp.near_price\nTypeError: unsupported operand type(s) for -: 'float' and 'str'"}```

---

## 2021-01-03 13:06:30 - issues channel

**liam**

Could they make that error message any more cryptic 

---

## 2021-01-03 12:57:44 - issues channel

**JC**

this is the start of the log

`{"asctime": "2021-01-03 12:45:09,144", "levelname": "ERROR", "message": "Execution error", "trading_function": "place", "response": "SportsAPING/v1.0/placeOrders \nParams: {'marketId': '1.177514173', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 24003006, 'side': 'BACK', 'handicap': 0, 'limitOrder': {'price': 2.02, 'persistenceType': 'LIMIT', 'size': 4}, 'customerOrderRef': 'ec2e3b2b42f12-138289707090911470'}], 'customerRef': '833f4dc64dc111eb97cd0a1ab5524ac8', 'customerStrategyRef': 'ip-172-31-40-12', 'async': False} \nException: None \nError: {'code': -32602, 'message': 'DSC-0018'} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}", "order_package": {"id": "833f4dc6-4dc1-11eb-97cd-0a1ab5524ac8", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f59562b9a50&gt;", "market_id": "1.177514173", "orders": ["138289707090911470"], "package_type": "Place", "customer_strategy_ref": "ip-172-31-40-12"}}`

---

## 2021-01-03 12:51:09 - issues channel

**JC**

I'm running a strategy via flumine and getting the following response error from Betfair, anyone got any idea what might be going wrong? The strategy worked fine in backtesting



`{"asctime": "2021-01-03 12:50:30,712", "levelname": "ERROR", "message": "Execution error"`



`\nException: None \nError: {'code': -32602, 'message': 'DSC-0018'} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}`

---

## 2021-01-03 12:28:05 - general channel

**steve**

this?



APIError: SportsAPING/v1.0/listMarketBook

Params: {'marketIds': ['1.177514198'], 'priceProjection': {'priceData': ['SP_AVAILABLE', 'SP_TRADED', 'EX_BEST_OFFERS', 'EX_ALL_OFFERS', 'EX_TRADED', 'SP_PROJECTED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}

---

## 2021-01-03 12:27:16 - general channel

**steve**

i keep getting



APIError: SportsAPING/v1.0/listMarketBook



is there another bit of code i might be missing? works ok without the SP_PROJECTED

---

## 2021-01-03 10:45:25 - general channel

**liam**

[@UBS7QANF3](@UBS7QANF3) when you get a second can you try issue373 again on your machine? With a small change required on the listener I am getting the following (same file)



```listener = StreamListener(max_latency=None, lightweight=True, debug=False, update_clk=False)```

```# master: 6.879s  (100%|██████████| 10/10 [00:06&lt;00:00,  1.46it/s])

# 373: 3.640s  (100%|██████████| 10/10 [00:03&lt;00:00,  2.75it/s])```

This is even without c/rust libraries :sunglasses:

---

## 2021-01-02 14:58:08 - general channel

**Unknown**

Considering a non-PC scenario.



Only average fee of 6% over profits. Looks like the break-even is BSP*+0.22*



Maybe my calculation is wrong?



I simulated a back bet on excel using a fixed stake on every runner selection on 2018-2020 races.

---

## 2021-01-02 11:30:47 - general channel

**liam**

On the subject of performance just been [https://github.com/liampauling/betfair/pull/374/commits/52e439d3b6ee6bd3ca585bd7bd4cacf1ac40168e|refactoring](https://github.com/liampauling/betfair/pull/374/commits/52e439d3b6ee6bd3ca585bd7bd4cacf1ac40168e|refactoring) the marketCache in the bflw streaming code, seen huge reduction in function calls and thus runtime by only serialising the runner data when there has been an update. This will also fix the issue you raise [@ULDAVFDRP](@ULDAVFDRP) with removed runners sometimes not being present in the book



[@UBS7QANF3](@UBS7QANF3) hoping to look at your PR on refactoring the Available class as well soon (sorry been distracted recently)

---

## 2021-01-02 10:04:52 - general channel

**D C**

Exception handling in some languages is quite expensive but I don't know much about how Python operates. It's a good question though and that specific example likely has different answers for different languages (C for example has no exception handling mechanism)

---

## 2021-01-02 10:04:51 - general channel

**liam**

[https://stackoverflow.com/questions/2522005/cost-of-exception-handlers-in-python](https://stackoverflow.com/questions/2522005/cost-of-exception-handlers-in-python)

---

## 2021-01-02 10:04:35 - general channel

**Michael**

I do it a lot for building dictionaries too - like try dictionary[key] except KeyError (then insert the key). Any comments?

---

## 2021-01-02 09:56:03 - general channel

**Michael**

Some of [@U0128E7BEHW](@U0128E7BEHW)'s comments from yesterday made me think about my default programming habits and whether they were right. For example I tend to do try/except in place of an 'if' conditional where I expect the condition to almost always be met, e.g. try X/Y except ZeroDivisionError instead of X/Y if y &gt; 0. Is this a bad habit or a good one? I've obviously picked it up somewhere but is it well founded?

---

## 2021-01-02 08:41:15 - general channel

**Mo**

You should drop the `1.` prefix and store the market IDs as integers in your database (IMHO)

---

## 2021-01-02 08:26:27 - general channel

**Newbie99**

(note though you seem to have to prefix a '1' on that historical data 'event_id' for it to equal a standard 'market_id', so in MySQL, something like this:



```a.market_id = concat('1.',b.event_id)```

---

## 2021-01-01 12:53:12 - issues channel

**Misha**

If you use decimals you can do value comparison (equals). Not do with floating point as rounding errors can leave inexact values

---

## 2021-01-01 12:48:59 - issues channel

**Misha**

Decimals are encoded exactly, so no rounding errors (nothing to do with language). Short for binary coded decimal

---

## 2020-12-31 21:42:35 - random channel

**Oliver Varney**

Yup ive had issues cancelling orders in an incorrect state, I haven't found my bug yet, so I just added further code on top of flumine to prevent my inability to be half decent at coding and not making mistakes :man-facepalming:

---

## 2020-12-31 19:13:06 - general channel

**liam**

Debug it 

---

## 2020-12-31 18:23:21 - general channel

**Graham**

I'm apparently far too stupid to follow a well documented git repo.

```UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 13: character maps to &lt;undefined&gt;```



---

## 2020-12-31 14:08:48 - issues channel

**Alessio**

(applied ML also include really doing it, as in clean your data, look at errors, etc etc..)

---

## 2020-12-31 10:26:03 - random channel

**river_shah**

pycharm fixed their god awful jupyter integration. it really is now the best single ide for development and data exploration (that I am have used)

---

## 2020-12-31 09:52:05 - issues channel

**mandelbot**

How can I write errors/orders from a strategy to a text file?

---

## 2020-12-31 08:05:51 - random channel

**Oliver Varney**

yer they can definitely improve it, but was decent vs trying to view stuff in the standard debugger

---

## 2020-12-31 08:03:46 - random channel

**Oliver Varney**

Cant remember exactly what the standard version has vs it but it has stuff like viewing pandas data frames , coverage for testing, threading debugging and performance stuff. Maybe not worth it for a developer of my skill but yes, the debugging tools are much better. Im surprised you dont have it. I think its only a few quid a month. They have monthly rolling options so id recommend trying it for a month and then binning it if you dont think its worth it

---

## 2020-12-29 21:33:58 - issues channel

**Alessio**

let's say you go for a very simple strategy, in a binary market (say, over/under X) always back Under, fixed small stakes (say, 5 bucks)

---

## 2020-12-28 11:07:05 - general channel

**Misha**

Certainly when I was last doing Australian racing (2017), Betfair last price matched was better than the Tote or any combination of agency fixed prices (I did do that analysis over 5 years of data)

---

## 2020-12-25 19:33:18 - general channel

**bogdan**

I wonder if it is an error from betfair..

---

## 2020-12-25 19:02:30 - general channel

**bogdan**

TypeError: market_filter() got an unexpected keyword argument 'country_codes'

---

## 2020-12-24 11:58:39 - strategies channel

**Ruben**

Good morning everyone, I'm trying to test my first strategy with fixed stakes, and I would like to add an exposure control so that the maximum amount I bet into any selection is, for example, 5 EUR.



For back bets, I believe this would be equivalent to limiting the max exposure of the selection to 5, but for lay bets its a bit trickier since it the exposure depends on the odds.



Since I would like this control to happen in the same place for both back/lay bets, is the best way to go about this to just implement an instance of TradingControl that specifically handles this "max bet stakes"? This could be as simple as just allowing to bet once per selection_id, with fixed stakes.

---

## 2020-12-23 12:26:41 - issues channel

**mandelbot**

Not sure what mandatory field im missing?



```{"levelname": "ERROR", "message": "Execution error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\execution\\betfairexecution.py\", line 196, in _execution_helper\n    response = trading_function(order_package, http_session)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\execution\\betfairexecution.py\", line 39, in place\n    return order_package.client.betting_client.betting.place_orders(\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\betfairlightweight\\endpoints\\betting.py\", line 500, in place_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/placeOrders \nParams: {'marketId': '1.17', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 2, 'side': 'BACK', 'handicap': 0, 'limitOrder': {'price': 6.0, 'persistenceType': 'LAPSE', 'size': 2, 'timeInForce': 30}, 'customerOrderRef': '662fae5f621ab-138280164330968924'}], 'customerRef': 'aa6e175d451311ebaa7f020100017805', 'customerStrategyRef': 'ID17805', 'async': False} \nException: None \nError: {'code': -32602, 'message': 'DSC-0018'} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}", "trading_function": "place", "response": "SportsAPING/v1.0/placeOrders \nParams: {'marketId': '1.17', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 2, 'side': 'BACK', 'handicap': 0, 'limitOrder': {'price': 6.0, 'persistenceType': 'LAPSE', 'size': 2, 'timeInForce': 30}, 'customerOrderRef': '662fae5f621ab-138280164330968924'}], 'customerRef': 'aa6e175d451311ebaa7f020100017805', 'customerStrategyRef': 'ID17805', 'async': False} \nException: None \nError: {'code': -32602, 'message': 'DSC-0018'} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}", "order_package": {"id": "aa6e175d-4513-11eb-aa7f-020100017805", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x000001F891D98820&gt;", "market_id": "1.177217695", "orders": ["138280164330968924"], "package_type": "Place", "customer_strategy_ref": "ID17805", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 1}}```

---

## 2020-12-23 11:53:41 - issues channel

**Mick**

My main challenge with my system is actually to get as much money on as early as possible when there are the biggest mistakes in the market. If I could bet at the bookies without being gubbed I'd bet the evening before. Sadly the exchanges are almost deserted at that time or offering silly odds. So now I'm thinking about 7? 8? 9?am ... looking for a sweet spot balancing market errors with liquidity.

---

## 2020-12-23 09:08:51 - issues channel

**Michael**

So back to your original question - I'd say the basic data LTP is a totally reasonable way to estimate your ability to do that and analyse its effect on your returns and I wouldn't apply any transformation to is as you're potentially just introducing and unnecessary error.

---

## 2020-12-23 08:49:11 - issues channel

**liam**

using fixed kelly should remove some of the volatility but cashing out is only giving money away, I profit off this so I shouldn't really tell you not to but...

---

## 2020-12-23 08:46:57 - issues channel

**liam**

fixed stakes? or based on liability?

---

## 2020-12-22 13:23:20 - random channel

**Oliver Varney**

although the calender view doesnt even have todays races. actually think its updated here [https://www.britishhorseracing.com/racing/fixtures/upcoming/](https://www.britishhorseracing.com/racing/fixtures/upcoming/)

---

## 2020-12-22 13:21:00 - random channel

**liam**

Am I correct in thinking no fixtures till the 26th after today?

---

## 2020-12-19 13:38:37 - random channel

**Michael**

Just to be clear I haven't read through all the discussion above, that wasn't directed at any individual and like I said 'there will be exceptions'. Just my observation after having met more than my share of winning and losing gamblers.

---

## 2020-12-19 13:21:36 - random channel

**Michael**

There will be exceptions but on the whole winners tend to quite comfortable with the term 'gambling'. They don't need to justify their choices because the money does that. The various euphemisms are usually more popular with losers as they support denial.

---

## 2020-12-19 05:31:26 - issues channel

**liam**

Odd, happy to accept a pr if it fixes it 

---

## 2020-12-18 14:10:35 - random channel

**bb**

Just watched the replay and the winner jumping left severely hampered the progress of the second place horse at the final flight. My guess is people would be trading expecting it to go to stewards and the result be overturned, but given it was horse error rather than jockey error causing the interference it couldn't be protested and the market settled

---

## 2020-12-18 11:00:58 - issues channel

**Misha**

Transient errors happen - have had a handful of 520s over the past 24 hours. Perfectly normal as a client (who knows why the server is generating them)

---

## 2020-12-18 10:39:42 - issues channel

**Mick**

I find that trading.keep_alive() usually works fine but occasionally it produces "betfairlightweight.exceptions.StatusCodeError: Status code error: 520" - any ideas?

---

## 2020-12-18 06:34:46 - issues channel

**liam**

Huh? This doesn’t look like a bflw error to me, the setup file is valid and works on py3.6

---

## 2020-12-18 00:08:46 - issues channel

**Matthieu Labour**

Hello all.

Would it be possible to rename `_requires` into, for example, `extra_requires`

at the following location [https://github.com/liampauling/betfair/blob/master/setup.py#L10](https://github.com/liampauling/betfair/blob/master/setup.py#L10)

The reason is that I am running into an error with python 3.6.9

```Traceback (most recent call last):                                                                               

  File "/home/xxx/.local/lib/python3.6/site-packages/pkg_resources/_vendor/packaging/requirements.py", line 99, in __init__                                                                                   req = REQUIREMENT.parseString(requirement_string)                             

  File "/home/xxx/.local/lib/python3.6/site-packages/pkg_resources/_vendor/pyparsing.py", line 1654, in parseString                                                                                           raise exc                                                                                ```

Generally, what is the best way to make a request for changes, report an issue and contribute? Should I, for example, create an issue on github? Can I create a PR, add reviewers, merge?

Thank you!

---

## 2020-12-17 15:44:07 - issues channel

**birchy**

Does betfair enable XM by default in streaming data? Reason I ask is because I've been using Flumine MarketRecorder to save data for backtesting and just discovered that all of my data has `cross_matching=True` which is a bit if an "oh, bugger" moment for me. The `listMarketBook` API docs state that XM is OFF by default and I've always expected that behaviour unless I had specifically set the flag `virtualise=True` in order to enable it...which I haven't.

---

## 2020-12-15 08:16:22 - issues channel

**liam**

I fixed this so fairly sure that is just telling you that you are placing that many per backrest hour, have you tried bumping the 5k limit on the client although I would make sure you actually want to be placing that many?

---

## 2020-12-15 07:49:21 - issues channel

**mandelbot**

`"levelname": "ERROR", "message": "Transaction limit reached", "transaction_count": 11668, "transaction_limit": 5000, "client": "&lt;flumine.clients.backtestclient.BacktestClient object at 0x000001B5B3C7EFD0&gt;"}`

---

## 2020-12-15 07:43:05 - issues channel

**mandelbot**

How come I'm getting `"levelname": "WARNING", "message": "Order has violated: MAX_ORDER_COUNT Error: Max Order Count has been reached (9837) for current hour"` in backtests even though I have `max_trade_count = 100` ? Is it counting bets per simulated time or actual time?

---

## 2020-12-14 23:05:11 - strategies channel

**Misha**

Big swings, lot of stats, standard playing rules now (with a few minor exceptions)

---

## 2020-12-12 10:38:09 - strategies channel

**D C**

It is popular for everyone to talk about this in the context of ML stuff now, but it is most easy to explain in the context of polynomial approximation versus interpolation of a set of (x,y) pairs of data. It is also context dependent - there are times where interpolation is what you want even though this is overfitting (every residual is zero by definition). In the sense of approximation though it is usually crap. Fitting requires more thought than that. For example, you can sling a least-squares linear regression at data but model assumptions are that the error is normally distributed - you can still fit it but it breaks model assumptions. Just because you can doesn't mean you should. You have a couple of outliers in your data set and that totally screws a least-squares approximation in the sense of how useful it is. In such cases fitting a l1 approximation gives you a much better way to go. It is basically a trade off between too many parameters in your model (huge flexibility) amd too few (comparatively rigid form). Both ends of the spectrum give a shite representation of the underlying functional relationship between response and explanatory variables. But how you get at that functional relationship should be governed by the error distribution of your measurements.

---

## 2020-12-12 09:45:01 - strategies channel

**Michael**

.....actually I can think of some exceptions but broadly I think that's right.

---

## 2020-12-11 18:56:56 - issues channel

**Artur Gräfenstein**

no error from Ukraine

---

## 2020-12-11 13:41:31 - strategies channel

**liam**

It is cancelled and you get an error, check out the docs.

---

## 2020-12-08 16:59:49 - general channel

**river_shah**

writing a unittest and trying to mock a book. this gives type errors by the `get_price` function. could you please guide me on how to mock this correctly:

---

## 2020-12-08 08:42:25 - strategies channel

**Oliver Varney**

in the old days I used a single fixed stake across all ranges but that was when I could match against the exchanges money, meaning huge wins on long odds

---

## 2020-12-08 08:33:55 - strategies channel

**liam**

Just rereading this, [@ULDAVFDRP](@ULDAVFDRP) does this mean you use fixed stakes across the odds range? If so do you not hit market capacity issues? / large draw downs?

---

## 2020-12-07 17:09:20 - issues channel

**Oliver Varney**

[@UE72WCRR8](@UE72WCRR8) I had a latency issue due to some dodgey code (for which i have fixed now). My experience of what will happen if your check + process functions in flumine take longer to process then the stream takes to update is a steady increasing in backlogged market books. you can add a latency check in these flumine functions not to process the market book if the latency is greater than X s (so you catch up). Id assume it would be much more preferable to fix the code to be able to keep up with the stream.

---

## 2020-12-07 08:23:41 - strategies channel

**jp**

Remember that Kelly is optimal only if you consider a fixed bank size. I you are in a position where you can adjust your bank size to the profitability of your strategy, Kelly may not be the right tool to decide bet size.

---

## 2020-12-07 08:09:06 - strategies channel

**liam**

From what I have found the majority use fixed Kelly (I do) at a certain percentage 

---

## 2020-12-06 08:17:29 - general channel

**Will Morrison**

Thanks Mo! I was just searching that page as you sent it. That should fix me right up!

---

## 2020-12-05 14:46:25 - issues channel

**Gabriel**

aah, okay, so if i want to remain unmatched till the end, i have to use 1.01, then put a ridicolous hight stake, so that once it goes to bsp, that stake is reduced by dividing it by actual_bsp so that the liability remains fixed?

---

## 2020-12-05 14:45:21 - issues channel

**liam**

I can release v1.14.13 now which will fix your first issue

---

## 2020-12-04 21:52:53 - general channel

**Charlie 303**

So I have a coarse streaming filter which amounts to about 800 markets and I need runner metadata for each of these markets.  My first thought was to start with list_market_catalogue (using same coarse filter and RUNNER_METADATA projection) to build the index, then start the stream and apply updates matching the event ids.  However, I get the APING 'too much data' error on list_market_catalogue.  Applying a max_results=200 to the list_market_catalogue call seems to work, but it doesnt appear there's any pagination feature so I'm wondering how to get the remaining ~600 markets?

---

## 2020-12-04 18:06:20 - issues channel

**Gabriel**

There was exactly 1 log regarding this order:

```{"asctime": "2020-12-04 17:43:32,949", "levelname": "CRITICAL", "message": "Unknown error 'MarketOnCloseOrder' object has no attribute 'size' in strategy_process_market_book &lt;bound method MyStrat.process_market_book of &lt;strategy_object object at 0x7f7981f08dd0&gt;&gt; 1.176351611", "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 391, in size_remaining\n



    return self.current_order.size_remaining or 0.0\n



AttributeError: 'NoneType' object has no attribute 'size_remaining'\n



\n



During handling of the above exception, another exception occurred:\n



\n



Traceback (most recent call last):\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/utils.py\", line 208, in call_process_market_book\n



    strategy_process_market_book(market, market_book)\n



  File \"/home/jenkins-slave-strat/workspace/ProdTest/my_strat.py\", line 208, in process_market_book\n



    self.place_order(market, order)\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/strategy/strategy.py\", line 134, in place_order\n



    market.place_order(order)\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/markets/market.py\", line 53, in place_order\n



    order.place(self.market_book.publish_time)\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 289, in place\n



    self.placing()\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 86, in placing\n



    self._update_status(OrderStatus.PENDING)\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 81, in _update_status\n



    [http://logger.info|logger.info](http://logger.info|logger.info)(\"Order status update: %s\" % self.status.value, extra=[http://self.info|self.info](http://self.info|self.info))\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 266, in info\n



    \"size_remaining\": self.size_remaining,\n



  File \"/usr/local/lib/python3.7/site-packages/flumine/order/order.py\", line 396, in size_remaining\n



    return self.order_type.size\nAttributeError: 'MarketOnCloseOrder' object has no attribute 'size'"}```

For some reason it tries to get the size, which an MarketOnCloseOrder doesnt have

---

## 2020-12-04 11:39:21 - issues channel

**Gabriel**

I tried making an MarketOnCloseOrder and gave it a liability. Error says it needs a size. In the docs it says it only needs a liability, also how would a size help if its a 'lay' order, where size cant really be determined as it doesnt know the price yet?

---

## 2020-12-03 21:20:51 - random channel

**Misha**

[@U919M37DL](@U919M37DL) - not really. The odd match is probably fixed, and that would usually be at a lower level. But there are almost 20,000 matches per year to bet on, and the dodgy ones might be a handful

---

## 2020-12-03 16:08:45 - issues channel

**Aaron Smith**

```{"asctime": "2020-12-03 15:00:04,154", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.176309310", "selection_id": 28615071, "handicap": 0, "id": "138263004041538760", "customer_order_ref": "strat-138263004041538760", "bet_id": null, "trade": {"id": "3979446e-3578-11eb-b83b-0a13a1974215", "strategy": "strat", "status": "TradeStatus.LIVE", "orders": ["138263004041538760"], "notes": "", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 2.22, "size": 6.76, "persistence_type": "LAPSE", "time_in_force": "FILL_OR_KILL", "min_fill_size": 0.01, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 6.76, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}



{"asctime": "2020-12-03 15:00:04,155", "levelname": "INFO", "message": "1 order packages created", "order_packages": [{"id": "39799d2e-3578-11eb-b83b-0a13a1974215", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f9ca51b9b10&gt;", "market_id": "1.176309310", "orders": ["138263004041538760"], "package_type": "Place", "customer_strategy_ref": "ip-172-31-34-22", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}], "bet_delay": 0}



{"asctime": "2020-12-03 15:00:04,156", "levelname": "INFO", "message": "New requests.Session created", "sessions_created": 1, "session": "&lt;requests.sessions.Session object at 0x7f9c9c29ce90&gt;", "session_time_created": 1607007604.1561081, "session_time_returned": 1607007604.1561098}



{"asctime": "2020-12-03 15:00:04,329", "levelname": "INFO", "message": "[OrderStream: 1001]: 1.176309310 added, 3 markets in cache"}



{"asctime": "2020-12-03 15:00:04,330", "levelname": "WARNING", "message": "Order 218390745703 not present in blotter", "bet_id": "218390745703", "market_id": "1.176309310", "customer_strategy_ref": "ip-172-31-34-22", "customer_order_ref": "strat-138263004041538760"}



{"asctime": "2020-12-03 15:00:04,338", "levelname": "INFO", "message": "execute_place", "trading_function": "place", "elapsed_time": 0.18191218376159668, "response": {"customerRef": "39799d2e357811ebb83b0a13a1974215", "status": "SUCCESS", "marketId": "1.176309310", "instructionReports": [{"status": "SUCCESS", "instruction": {"selectionId": 28615071, "handicap": 0.0, "limitOrder": {"size": 6.76, "price": 2.22, "minFillSize": 0.01, "timeInForce": "FILL_OR_KILL"}, "customerOrderRef": "strat-138263004041538760", "orderType": "LIMIT", "side": "BACK"}, "betId": "218390745703", "placedDate": "2020-12-03T15:00:04.000Z", "averagePriceMatched": 2.236449704142012, "sizeMatched": 6.76, "orderStatus": "EXECUTION_COMPLETE"}]}, "order_package": {"id": "39799d2e-3578-11eb-b83b-0a13a1974215", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x7f9ca51b9b10&gt;", "market_id": "1.176309310", "orders": ["138263004041538760"], "package_type": "Place", "customer_strategy_ref": "ip-172-31-34-22", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}}



{"asctime": "2020-12-03 15:00:04,339", "levelname": "INFO", "message": "Trade status update: Pending", "id": "3979446e-3578-11eb-b83b-0a13a1974215", "strategy": "strat", "status": "TradeStatus.PENDING", "orders": ["138263004041538760"], "notes": "", "market_notes": "2.24,2.26,None"}



{"asctime": "2020-12-03 15:00:04,339", "levelname": "INFO", "message": "Order Place: SUCCESS", "bet_id": null, "order_id": "138263004041538760", "status": "SUCCESS", "error_code": null}



{"asctime": "2020-12-03 15:00:04,339", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.176309310", "selection_id": 28615071, "handicap": 0, "id": "138263004041538760", "customer_order_ref": "strat-138263004041538760", "bet_id": "218390745703", "trade": {"id": "3979446e-3578-11eb-b83b-0a13a1974215", "strategy": "strat", "status": "TradeStatus.PENDING", "orders": ["138263004041538760"], "notes": "", "market_notes": "2.24,2.26,None"}, "order_type": {"order_type": "Limit", "price": 2.22, "size": 6.76, "persistence_type": "LAPSE", "time_in_force": "FILL_OR_KILL", "min_fill_size": 0.01, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 6.76, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 2.236449704142012}, "status": "Executable", "status_log": "Pending, Executable"}



{"asctime": "2020-12-03 15:00:04,340", "levelname": "INFO", "message": "Trade status update: Live", "id": "3979446e-3578-11eb-b83b-0a13a1974215", "strategy": "strat", "status": "TradeStatus.LIVE", "orders": ["138263004041538760"], "notes": "", "market_notes": "2.24,2.26,None"}



{"asctime": "2020-12-03 15:00:04,580", "levelname": "WARNING", "message": "Order 218390745703 not present in blotter", "bet_id": "218390745703", "market_id": "1.176309310", "customer_strategy_ref": "ip-172-31-34-22", "customer_order_ref": "strat-138263004041538760"}```

---

## 2020-12-03 12:39:58 - issues channel

**liam**

A log entry of that order will help as you can see the status and status log, debugger would be even better as you will be able to see the place response and the current_status (which will tell you everything)

---

## 2020-12-03 12:38:38 - issues channel

**Aaron Smith**

well, the logs are a big mess right now, as i still wasnt able to fix the repeated log of the market.blotter warning. I am checking for if an order is complete somewhere within my strat already and just added a log under _if order.complete-section_ and _else-section_. It always goes to else, i feel like the logs will just add confusion with how messy they are :smile:

---

## 2020-12-03 09:58:16 - issues channel

**mandelbot**

You were right it is a None, was still returning an error because the back != None was in the same if statement.

---

## 2020-12-03 09:52:57 - issues channel

**liam**

Wrap in a try and except and log what back is on the error 

---

## 2020-12-03 09:49:45 - issues channel

**mandelbot**

I set a condition to back != None and back &gt; 1.3 and still getting that error.

---

## 2020-12-03 09:10:33 - issues channel

**mandelbot**

any idea why i sometimes get this error in backtests?

```{"asctime": "2020-12-03 09:07:03,177", "levelname": "CRITICAL", "message": "Unknown error [&lt;class 'decimal.ConversionSyntax'&gt;] in strategy_process_market_book &lt;bound method test.process_market_book of &lt;strategies.test.test object at 0x000001E1A1A639D0&gt;&gt; 1.174842429", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\utils.py\", line 208, in call_process_market_book\n    strategy_process_market_book(market, market_book)\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\flumine\\examples\\strategies\\test.py\", line 47, in process_market_book\n    price_ticks_away(back, -20) and \\\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\utils.py\", line 125, in price_ticks_away\n    price_index = PRICES.index(as_dec(price))\n  File \"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\flumine\\utils.py\", line 55, in as_dec\n    return Decimal(str(value))\ndecimal.InvalidOperation: [&lt;class 'decimal.ConversionSyntax'&gt;]"}```

---

## 2020-12-02 17:04:21 - issues channel

**liam**

I will add a proper error anyway when it’s accessed incorrectly as it is a bit odd 

---

## 2020-12-02 16:51:35 - issues channel

**Ryan Clapham**

Evening, for some reason I am getting the error 'AttributeError: 'dict' object has no attribute 'price'' Could a fresh pair of eyes have a look over my code please

---

## 2020-12-02 15:26:13 - issues channel

**birchy**

[@U4H19D1D2](@U4H19D1D2) Just had this on a Flumine fresh install on a Lightsail instance:

```File "/home/ubuntu/.local/lib/python3.8/site-packages/betfairlightweight/endpoints/login.py", line 53, in request

    raise APIError(None, exception=e)

betfairlightweight.exceptions.APIError: None

Params: None

Exception: [('SSL routines', 'SSL_CTX_use_certificate', 'ca md too weak')]```

Seems to be OpenSSL related: [https://stackoverflow.com/questions/52218876/how-to-fix-ssl-issue-ssl-ctx-use-certificate-ca-md-too-weak-on-python-zeep|StackOverflow Link](https://stackoverflow.com/questions/52218876/how-to-fix-ssl-issue-ssl-ctx-use-certificate-ca-md-too-weak-on-python-zeep|StackOverflow Link)

OpenSSL version 1.1.1

Flumine version 1.14.12

BetfairLightWeight version 2.10.2



Working fine on my production instance which has exactly the same setup and same certs?



Only difference I can find so far is:

```Linux 5.4.0-1029-aws #30~18.04.1-Ubuntu SMP

Linux 5.4.0-1029-aws #30-Ubuntu SMP```

Ubuntu 18.04 working fine, Ubuntu 20.04 is throwing the error.

---

## 2020-12-02 12:47:29 - general channel

**Mo**

I guess you get match fixing at all levels

---

## 2020-12-01 22:02:34 - general channel

**Lennart**

That's good to know. No big debugging session for now - thanks a lot!

---

## 2020-12-01 20:44:31 - general channel

**Lennart**

Hey everyone, got another noob question -  Looks like I'm getting prices/odds through trading.betting.list_market_book() that are off from what I can see directly on Betfair's website. Generally it seems that these prices are better than those on the website. For instance, I might get 5.6 to back when I'm seeting 5.3 on the website. This is for in-game football matches, if that makes a difference.

Is this at all possible or should I be digging into/debugging my code?

---

## 2020-12-01 16:40:31 - issues channel

**jhaa**

So I had my bots running for a few weeks without any issues. This morning around 5AM there were a few disconnects. I use the tenacity example StreamingThread for the reconnection handling.  One bot that trades like 70 markets restarts the order thread and market thread without issues for any markets.



The other bot trades 30 markets and does not get appropriate order updates for two of those markets and therefor keeps placing the same bet again and again until no funds are left in the account. They run the same code(one bflw 2.92 and the other 2.80 though, 2.92 broke).



I am running out of ideas how to debug this. ANy suggestion?

---

## 2020-12-01 11:12:32 - general channel

**Twatter**

[@U01EYDA8345](@U01EYDA8345) Thanks for sharing! I've been clicking through some pages and it looks like a great tool. Just looking at some of the fixture pages for football and they have odds posted (e.g. [https://s5.sir.sportradar.com/mi002/en/1/season/77179/fixtures](https://s5.sir.sportradar.com/mi002/en/1/season/77179/fixtures)) Don't suppose you know where these odds are from?

---

## 2020-12-01 10:44:48 - general channel

**Artur Gräfenstein**

For example: “[https://stats.fn.sportradar.com/en/Europe:Berlin/gismo/config_tree_mini/41/0/1/](https://stats.fn.sportradar.com/en/Europe:Berlin/gismo/config_tree_mini/41/0/1/)” this will lead in an error. But placing a big customers name “ibcbet” from asia: “[https://stats.fn.sportradar.com/ibcbet/en/Europe:Berlin/gismo/config_tree_mini/41/0/1/](https://stats.fn.sportradar.com/ibcbet/en/Europe:Berlin/gismo/config_tree_mini/41/0/1/)” you will get the config three for soccer.

---

## 2020-12-01 10:05:22 - general channel

**Misha**

Fiddler is the best I have seen, for which there is an updated application, Fiddler Everywhere - [https://www.telerik.com/blogs/fiddler-everywhere-web-debugging-official-release](https://www.telerik.com/blogs/fiddler-everywhere-web-debugging-official-release)

---

## 2020-11-30 14:10:37 - general channel

**Oliver Varney**

in terms of python web frameworks (and visualisation of raw data) does anyone have any favourites/ recommendations? Currently just using basic Flask to serve json, for debugging, but likely to look to improve this a little more in the future.

---

## 2020-11-29 18:49:07 - issues channel

**Oliver Varney**

Are you sure you created the orders through flumine on the same computer, with the same strategy name ? the strategy name hash doesnt look like it has a match if the strategy returned is None, or you havent added a strategy if that's possible, or the order does not had an customer_order_ref. can you use the debugger to check the value of strategy_name_hash is in strategies.hashes.get(strategy_name_hash)

---

## 2020-11-29 18:02:40 - random channel

**liam**

No idea tbh, get a debugger in it to confirm that it is a dictionary MarketBook and not something else 

---

## 2020-11-29 17:43:24 - random channel

**liam**

If not can you debug or print what market_book is on that line?

---

## 2020-11-29 17:36:42 - issues channel

**Aaron Smith**

Thanks. I m a little hesitant with overwriting stuff in the flumine framework for now, as i want to keep it as close to the original as i can to not have to rethink everything that i tweaked whenever i m getting some error. When i feel more comfortable with the framework, that may change.

Regarind the order: It must have been an order created by flumine and it must ve been a matched order, as i was only using Fill_or_Kill orders. It is only a handful of orders that are repeaditly logged. The warnings also occured on the first time i started flumine (so before any restart), looping over 3 diffrent orders

---

## 2020-11-29 17:30:46 - random channel

**Newbie99**

I've been getting this all day and I can't figure it out, as it appears to occur when _process_close_market runs (which I haven't changed from the pip install of flumine)?



```  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/flumine.py", line 44, in run

    self._process_close_market(event)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/baseflumine.py", line 264, in _process_close_market

    market.blotter.process_closed_market(event.event)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/markets/blotter.py", line 86, in process_closed_market

    for runner in market_book.runners:

AttributeError: 'dict' object has no attribute 'runners'```

---

## 2020-11-29 16:56:38 - issues channel

**Aaron Smith**

Hello folks! I m having an error i currently cant explain, its certainly not an issue of flumine itself, but maybe one of you guys can help me out anyway :slightly_smiling_face:

I keeps getting the following warning:

```{"asctime": "2020-11-28 21:23:28,772", "levelname": "WARNING", "message": "Order 217999225444 not present in blotter", "bet_id": "217999225444", "market_id": "1.176099484", "customer_strategy_ref": "ip-xxx-xx-xxx-xx", "customer_order_ref": "stratname-138258912423034860"}```

I dont see how i managed to get orders which are not in the blotter, as with markets.place_order any order should automatically be added to the blotter?

Also on a complete diffrent topic: Sometimes i get prints and [http://logging.info|logging.info](http://logging.info|logging.info)() outputs in the console output, but mostly not. How can i choose which kind of outputs i want to get in my console?

Its is entirely possible i m overlooking the obvious, i m new to coding (corona made me do it :smile: )

Thanks to anyone taking the time to help me :slightly_smiling_face:

---

## 2020-11-27 10:45:27 - random channel

**Misha**

I also have 3 web pages to check: one for errors, one for alerts, and one for all applications that have been running over the past week

---

## 2020-11-27 10:38:41 - random channel

**Mo**

On the flip side, I find that seeing some of the summary statistics I look at like bet count or total staked per match can help to reveal subtle issues that aren't caught by error reporting

---

## 2020-11-27 08:58:53 - issues channel

**Jonjonjon**

Ah, sorry. html encoding error:



`Oops no service available at [https://api.betfair.com/exchange/betting/json-rpc/v1](https://api.betfair.com/exchange/betting/json-rpc/v1)`

`&lt;urlopen error [Errno -2] Name or service not known&gt;`

`Traceback (most recent call last):`

  `File "/home/content/28/xxx/html/xxx/helpers.py", line 66, in callAping_direct`

    `).encode('utf-8'))`

  `File "/usr/local/lib/python2.7/urllib2.py", line 126, in urlopen`

    `return _opener.open(url, data, timeout)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 400, in open`

    `response = self._open(req, data)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 418, in _open`

    `'_open', req)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 378, in _call_chain`

    `result = func(*args)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 1215, in https_open`

    `return self.do_open(httplib.HTTPSConnection, req)`

  `File "/usr/local/lib/python2.7/urllib2.py", line 1177, in do_open`

    `raise URLError(err)`

`URLError: &lt;urlopen error [Errno -2] Name or service not known&gt;`

---

## 2020-11-27 08:56:10 - issues channel

**liam**

so the error is todays date?

---

## 2020-11-27 08:45:06 - issues channel

**Jonjonjon**

Is there a quick fix for that? Or do I need to port my code?

---

## 2020-11-27 08:42:50 - issues channel

**Jonjonjon**

On an old server, which hasn't been ported to BFLW, I am getting this error message:



`Oops no service available at [https://api.betfair.com/exchange/betting/json-rpc/v1](https://api.betfair.com/exchange/betting/json-rpc/v1) Traceback (most recent call last): File "/home/content/28/xxx/html/xxx/helpers.py", line 66, in callAping_direct ).encode('utf-8')) File "/usr/local/lib/python2.7/urllib2.py", line 126, in urlopen return _opener.open(url, data, timeout) File "/usr/local/lib/python2.7/urllib2.py", line 400, in open response = self._open(req, data) File "/usr/local/lib/python2.7/urllib2.py", line 418, in _open '_open', req) File "/usr/local/lib/python2.7/urllib2.py", line 378, in _call_chain result = func(*args) File "/usr/local/lib/python2.7/urllib2.py", line 1215, in https_open return self.do_open(httplib.HTTPSConnection, req) File "/usr/local/lib/python2.7/urllib2.py", line 1177, in do_open raise URLError(err) URLError: 2020-11-27`

---

## 2020-11-26 13:07:25 - issues channel

**Ryan Clapham**

Hi, I was wondering if someone could help me. I seem to be getting a KeyError. At the minute its KeyError: 36413516. I am cycling through all win, place and eachway markets and recording prices into a dictionary. I did not know if its something to do with not showing the non-runners. Take the 14:33 Lingfield for example. On the win market reeceltic is showing as a non-runner but on the place and eachway market its not showing at all.

---

## 2020-11-26 12:51:10 - general channel

**Oliver Varney**

yes the debugger

---

## 2020-11-26 12:49:49 - general channel

**A**

What editor is this? Is that a debugger?

---

## 2020-11-25 15:32:57 - general channel

**Lee**

I wouldn't just copy and paste that code, add some error handling around reading the file/parsing to json etc

---

## 2020-11-25 15:28:19 - general channel

**ricky**

MarketCatalogue(**json.loads(f.read())) return error, because MarketCatalogue is undefinition.

---

## 2020-11-24 22:55:38 - general channel

**A**

Hello all. Just getting started with Flumine and BFLW, really pleased to have stumbled on this project and community. Looking to see if I can swing trade the horses. First question (been bugging me for a while), what does NG stand for in API-NG?!

---

## 2020-11-24 20:00:56 - issues channel

**liam**

I spent a day once with a similar error 

---

## 2020-11-24 19:57:05 - issues channel

**brightcake**

Did any of you guys experience this error when trying to use multiprocessing?

```AttributeError: Can't get attribute 'abc' on &lt;module '__main__' from 'abc_d.py'&gt;```



---

## 2020-11-24 17:43:26 - general channel

**birchy**

This is preplay bot. It will obviously run 24/7 once debugged. I was just curious why it didn't pick up where it left off when restarted. I don't fully understand the internals of Flumine as it's a bit of a black box for end users. Just wondering if the cache could be pickled and reloaded?

---

## 2020-11-24 10:49:05 - general channel

**sartux**

Hi guys,

I created a very trivial script that takes the last 100 operations and writes them to a MySQL table, in order to create a statistic of the account.



```balance = trading.account.get_account_statement()

b = json.loads(balance.json())

gc = b['accountStatement']

cc = json_normalize(gc)```

until a few hours ago it worked correctly, now I get it as an error



```TypeError: __init__() missing 1 required positional argument: 'marketName'```



I investigated the exception and the only difference is this new record



                "legacyData": {

                    "avgPrice": 0.0,

                    "betSize": 0.0,

                    "betType": "B",

                    "betCategoryType": "E",

                    "eventId": 0,

                    "eventTypeId": 0,

                    "fullMarketName": "Credit",

                    "grossBetAmount": 0.0,

                    "marketType": "NOT_APPLICABLE",

                    "placedDate": "2020-11-24T09:26:32.000Z",

                    "selectionId": 0,

                    "startDate": "0001-01-01T00:00:00.000Z",

                    "transactionType": "ACCOUNT_CREDIT",

                    "transactionId": 0,

                    "winLose": "RESULT_FIX",

                    "avgPriceRaw": 0.0

                },



could it be that the method goes into exception for this reason?



maybe I'm wrong in the analysis of the problem, possibly how can I simply extract the last 100 operations?

---

## 2020-11-23 21:58:57 - general channel

**D C**

It is fixed now (at least for me). Happened last week (well that was when I noticed it. For me it got horse racing market totals all wrong but ONLY on the web page. Downloading excel dump for it and calculating totals gave correct results, but the web page itself refused to calculate the correct totals. And ONLY for horses. Totally bizarre behaviour, but it does work for me now and matches the API results. Would love to know what it didn't work because every market total was correct but it could not sum them correctly.

---

## 2020-11-23 21:55:46 - strategies channel

**D C**

[@U01EYDA8345](@U01EYDA8345) You will never get to the point where everything is modelled to perfection but this could be a philosophical argument as much as a tech argument. Perhaps if we can model things on a quantum level it could happen but in practical terms that is intractible. Even it if were possible, could quantum mechanics predict human behaviour such as corruption for thigs like match or spot fixing?? Maybe one day but we will all be in the ground by then!! As for using 1000 parameters, modelling favours less parameters for their greater generality. Consider a fairly simple mathematical example where you want to approximate a set of data using a polynomial curve - if you choose the degree of polynomial equal to the number of points, you get an interpolation (where the curve passes through every point) but this is seldom any good at predicting the general shape of the data points - better to choose a lower degree curve that is able to be acceptably "close" to the data. The first case is termed overfitting and building linear statistical models favours choosing SMALLER amount of parameters but ones that help "explain" the data wherever possible. I cannot speak for machine learning methods as I am a novice in that area. As for bookies they don't need to be that accurate in pricing (well soft books) because they will just ban winners. Pinnacle use profitable/savvy customers to adjust their prices accordingly but I believe that they have pretty good analytics too (just from what I hear).

---

## 2020-11-23 21:19:36 - general channel

**Misha**

I saw a tweet from someone a day ago that suggests that it might be fixed

---

## 2020-11-23 16:46:25 - strategies channel

**D C**

Yeah but you can't predict things like a fat finger error any more than you can predict a runner will fall at the next fence. But as Michael says, the price should always come back to 0EV.

---

## 2020-11-22 00:53:32 - strategies channel

**Dave**

The way I see it - not all participants in the market are looking to make money from every bet they offer or take, or consider EV in the same way as you might do. People skew from what would be considered your "true price" for all sorts of reasons: hedging existing risk (reducing exposure to a more palatable level, maybe having operational issues etc), or doing silly "offset greening by fixed X ticks"-type things. Computation of the true price also depends on your strategy - if you are predicting the outcome of the event then you'll be applying different techniques to predicting price change over the next X seconds. This also means that not every bet has a "winner" and a "loser" - the person you were matched with may just have a different target they are wagering on, and therefore the bet can have positive expected value to both sides as the target of their forecast is diffeeent. So you don't even need "mugs" to profit on - you just need to be able to pick a reasonable target to forecast (price movement, event outcomes etc), and figure out what data can provide you with decent signals to make your forecast.

---

## 2020-11-21 22:25:25 - issues channel

**Jonjonjon**

Has anyone ever seen this error when using the `multiprocessing` module to run several flumine backtests?



```_pickle.PicklingError: Can't pickle &lt;class 'datetime.datetime'&gt;: it's not the same object as datetime.datetime```



---

## 2020-11-21 17:50:23 - strategies channel

**birchy**

Good point, I've been using _some_ previous prices but only a handful as I wanted to avoid using stale info, particularly with the assumption that the GPS players will be correction any errors?

---

## 2020-11-21 10:06:18 - issues channel

**Lee**

the `_load` method is called on [https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/marketrecorder.py#L89|here](https://github.com/liampauling/flumine/blob/fdcf9961330f9807f18029ad7120999d0d62af93/examples/strategies/marketrecorder.py#L89|here), step through in a debugger where it goes after it’s called

---

## 2020-11-20 18:32:18 - issues channel

**ricky**

def _load(self, market, zip_file_dir: str, market_definition: dict) -&gt; None:

	print('load start in MarketRecorder')

	file_directory = os.path.join(

						zip_file_dir,

						"marketCatalogue",

						)

	if market and self.context.get("load_market_catalogue", True):

		if market.market_catalogue is None:

			logger.warning(

				"No marketCatalogue data available for %s" % market.market_id

			)

			return

		try:

			with open(file_directory, "a") as f:

				f.write(market.market_catalogue.json())

			[http://logger.info|logger.info](http://logger.info|logger.info)(

				"%s successfully loaded marketCatalogue to s3" % market.market_id

			)

		except (BotoCoreError, Exception) as e:

			logger.error("Error loading to s3: %s" % e)

---

## 2020-11-19 19:16:57 - issues channel

**Oliver Varney**

most likely either ending up with a number that is not on the ladder, order some kind of number that has round errors

---

## 2020-11-19 19:08:50 - issues channel

**Unknown**

Does anyone know what this error means?

I seem to be getting it when flumine is exiting the main loop

---

## 2020-11-19 14:08:58 - general channel

**Michael**

There will be exceptions but it's an 'in general' thing.

---

## 2020-11-18 23:38:00 - issues channel

**Josh**

Look for circular references that should be handled with `weakref` . I've found these using `gc.garbage` with `DEBUG_SAVEALL` turned on.

---

## 2020-11-18 18:22:56 - strategies channel

**Alessio**

tbh (and here i'm just speaking out of cheap words instead of hard data, but ..) maybe the real fix would be to change the scheme we do these things: now we are having an asynchronous system where the listener updates the book and the market book reader is another thread, that way you have a contention point. another way would be to have a pipeline style where the strategies run in the thread that updates the book, however you may introduce latency if you do any other shit there between one update and the next one (albeit that should be measurable, not sure how much computation there is and one could move to a  lossy view where you batch all the latest updates that weren't read and are in the queue)

---

## 2020-11-18 14:38:09 - general channel

**Lee**

But like [@ULDAVFDRP](@ULDAVFDRP) said, i wouldn't bother with closing the market early, i think it will cause more problems/bugs in the long run

---

## 2020-11-17 19:25:35 - strategies channel

**Mo**

Fixed the memory leak but I think there's another bug

---

## 2020-11-16 13:40:00 - random channel

**Oliver Varney**

I ran into a too many login error the other day and got a temp ban :joy: more likely linked to some buggy code

---

## 2020-11-16 04:36:44 - random channel

**AP**

Hi Liam, I have managed to deploy my lambda function but there seems to be a permissions error when trying to download my certs from s3. I have fiddled around with adding permissions but yet to have any success, did you have any issues here?

---

## 2020-11-15 23:08:22 - general channel

**Jonjonjon**

[@U4H19D1D2](@U4H19D1D2) Do you think it would be beneficial to add logging telling users why validation has failed in here?



[https://github.com/liampauling/flumine/blob/4dff28ab03969d8d17a9a031d8db5169df929794/flumine/strategy/strategy.py#L141-L158](https://github.com/liampauling/flumine/blob/4dff28ab03969d8d17a9a031d8db5169df929794/flumine/strategy/strategy.py#L141-L158)

---

## 2020-11-15 19:33:52 - general channel

**Newbie99**

its also worth noting, when checking for prices to build in some error handling to account for null values (e.g. if the market is 1000 / or / 1.01)

---

## 2020-11-13 20:11:19 - issues channel

**thambie1**

I didn't receive any emails either. Around 4pm is when my bot started throwing errors.

---

## 2020-11-13 15:44:28 - strategies channel

**Twatter**

Error handling will be much easier though... just add my favourite line of code to it and you're set... "ON ERROR RESUME NEXT"

---

## 2020-11-13 11:43:07 - issues channel

**liam**

I emailed Neil and I can see that things look to be getting fixed

---

## 2020-11-12 19:40:38 - strategies channel

**Mo**

I’m sure you could sort out debugging with gdb but I have no idea how to do that with a Python C extension

---

## 2020-11-12 19:37:55 - strategies channel

**liam**

My current process is try and write some C, build, then run and then get a cryptic error, is there a better process?

---

## 2020-11-12 14:41:23 - issues channel

**lil_algo**

Hi! I'm looking for some help. When trying to log in using betfiarligthweight I get the error message:

```LoginError: API login: AUTHORIZED_ONLY_FOR_DOMAIN_SE```

I have found the locale parameter, but what should I give it? I have tried 'SE' and '.se'

---

## 2020-11-12 12:01:23 - general channel

**Jorge**

Streaming kept working for me fine, but keep_alive NG call failed at 10:28, it succeded at 10:29 though :slightly_smiling_face:

---

## 2020-11-12 11:04:52 - general channel

**Misha**

Apparently it's fixed anyway

---

## 2020-11-12 10:56:31 - general channel

**Phil**

[!here](!here) betfair doing load testing, causing issues, should be fixed shortly

---

## 2020-11-12 10:56:17 - general channel

**Johnny**

main website had an ssl error too... but that seems to be fixed now

---

## 2020-11-12 10:54:00 - general channel

**azevedo**

[!here](!here) hey guys, I’m getting certificate_verify_failed error all of a sudden when trying to connect to streaming. (it’s the same code that’s been running for a while and ran this morning; and the certificate shouldn’t expire until next year) 



has anyone had that before? what could that be due?

---

## 2020-11-12 06:25:27 - issues channel

**Oliver Varney**

cant cancel and it throws an error when I try and update the price both through api and website

---

## 2020-11-11 18:47:59 - issues channel

**liam**

Set logging to debug and see what is sent 

---

## 2020-11-11 17:52:16 - issues channel

**Josh**

Should an order with the following specification



```"limitOnCloseOrder": {

                    "liability": 17.0,

                    "price": 1.7

                },```

come back with a "INVALID_ODDS" error? Should it be "1.70"?

---

## 2020-11-11 17:23:45 - issues channel

**mandelbot**

Why do I get this seemingly contradictory response when backtesting?

```

{"asctime": "2020-11-11 17:20:32,589", "levelname": "ERROR", "message": "[MarketStream: 0] Unable to add 1.174790521 to cache due to marketDefinition not being present (make sure EX_MARKET_DEF is requested)"}

{"asctime": "2020-11-11 17:20:32,589", "levelname": "INFO", "message": "[MarketStream: 0] 1.174790521 added, 1 markets in cache"}```



---

## 2020-11-10 19:07:42 - general channel

**Mo**

Was the fix just checking the funds before the delay?

---

## 2020-11-10 18:54:10 - general channel

**liam**

Used to be a bug where the funds validation would occur after the delay, this meant you could place an order and if you didn’t want it to enter the matcher transfer all your funds to another wallet and the place request would error 

---

## 2020-11-10 14:41:42 - general channel

**Remi**

you are capped at 200 without errors?

---

## 2020-11-10 14:40:09 - general channel

**liam**

error on subscription, try it

---

## 2020-11-10 14:39:44 - general channel

**Remi**

Say I subscribe to all of soccer but I have a limit of 200. Does betfair or bflw choose which subset I subscribe to or do I just get errors?

---

## 2020-11-10 09:13:32 - issues channel

**Jorge**

It's the dict I usually use to log my applications: contains 2 handlers

```dict_log_config = {

    "version": 1,

    "handlers": {

        "consoleHandler": {

            "level": "DEBUG",

            "class": "logging.StreamHandler",

            "formatter": "standard",

            "stream": '[ext://sys.stdout](ext://sys.stdout)',

        },

        "fileHandler": {

            "level": "DEBUG",

            "class": "logging.FileHandler",

            "formatter": "standard",

            "filename": log_path,

        }

    },

    "loggers": {

        "": {  # root logger

            "handlers": ["consoleHandler", "fileHandler"],

            "level": "DEBUG",

        }

    },

    "formatters": {

        "standard": {

            "format": "%(asctime)s | %(levelname)s | %(message)s"

        }

    }

}```



---

## 2020-11-10 09:11:06 - issues channel

**Jorge**

I am running the error handling example: [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py), it works with

```logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))```

but it doesn't work for me when I change this line by _logging.config.dictConfig(dict_log_config)_

---

## 2020-11-09 08:30:06 - issues channel

**Jorge**

Hi guys, I am not able to pip install betfairlightweight[speed]... I get the error:

• _maturin failed_

      _Caused by: Cargo metadata failed. Do you have cargo in your PATH?_

Can anyone help me?

---

## 2020-11-05 09:32:01 - issues channel

**liam**

:thumbsup:  i have now released 1.14.4, testing my side and things look good, lots of bugs fixed in that release :slightly_smiling_face:

---

## 2020-11-05 09:31:09 - issues channel

**Jonjonjon**

You're right. A good `git pull` fixed it. Apologies for the false accusation.

---

## 2020-11-05 08:02:24 - random channel

**liam**

I follow gitops, merge to master, test, build, push to ECR and then some lambdas to deploy to servers based on a json config file. The beauty of this is that I can spend 5 minutes fixing a bug and merge to master and that’s it, CI/CD is then automated with a few slack notifications on success / error.



I deploy about 3/4 times a week due to framework updates, strategy adjustments or new strategies for testing. I have about 15 instances running during the day at the moment each running 1/2 instances of my framework. 



RDS for my API and data lake with API Gateway used for a small django app.

---

## 2020-11-01 15:27:04 - random channel

**liam**

Yeah I have had this, work fine with python and rejected by GO with a cryptic error message, took me a full day before I tried creating a new key and it started working :man-facepalming: 

---

## 2020-11-01 14:09:49 - random channel

**D C**

Has anyone had to regenerate their SSL cert and key files? I upgraded my linux install recently and my nodejs stuff no longer works unless I roll back to an old nodejs version. The issue is inside openssl I think and the error is "*ca md too weak*". Some research suggests that this is because my cert and key files were generated with too old a version of SSL and this now causes issues with later versions of openssl. Is this something that you guys have had to do from time to time? For now it is not an issue overall, but I dont want to be running old versions of node for too long just to keep things going.

---

## 2020-10-31 17:02:00 - strategies channel

**liam**

It will error, can’t remember off the top of my head what the error code is though 

---

## 2020-10-30 15:16:31 - general channel

**jp**

[@U919M37DL](@U919M37DL) You can also get infinity size for virtual prices in some rare cases. Neil has confirmed that this is a bug in computation of virtual prices (and it did not sound as something they prioritized to fix)

---

## 2020-10-30 11:38:59 - issues channel

**liam**

bflw had a bug where `send` was used instead of `sendall` which meant in some cases not all bytes where sent not sure if C has something similar

---

## 2020-10-30 11:35:52 - issues channel

**liam**

```2020-10-30 11:34:31,767 | ERROR | [MarketStream: None]: TIMEOUT: Timed out trying to read message make sure to add \r\n

Read data : {"op":"marketSubscription","id":1000,"marketFilter":{"eventTypeIds":["1","7"],"marketTypes":["WIN","PLACE"],"countryCodes":["AU"],"raceTypes":["Flat"]},"marketDataFilter":{"fields":["EX_BEST_OFFERS","EX_TRADED","EX_TRADED_VOL","EX_LTP","EX_MARKET_DEF"],"ladderLevels":5},"initialClk":null,"clk":null,"conflateMs":null,"heartbeatMs":null,"segmentationEnabled":true}

Exception in thread Thread-1:```

---

## 2020-10-30 11:31:04 - issues channel

**Misha**

I will if it becomes an issue. At the moment I see it less that once a day, and I get the odd error every now and again anyway

---

## 2020-10-30 11:20:02 - issues channel

**Misha**

So no idea what is different, because I have logged every error in all my systems for the last 3 years, and I can confirm that October 21 is the first time I have ever seen it

---

## 2020-10-30 11:11:18 - issues channel

**Misha**

Has anyone encountered this error returned from the streaming API via a StatusMessage: "Failure (Timeout - Timed out trying to read message make sure to add \r\n Read data : {&lt;conflateMs&gt;:0,&lt;heartbeatMs&gt;:5000,&lt;id&gt;:28,&lt;marketDataFilter&gt;:{&lt;fields&gt;:[&lt;EX_BEST_OFFERS_DISP&gt;,&lt;EX_LTP&gt;,..."?

---

## 2020-10-30 09:43:56 - general channel

**dan2002**

Ok. I will appreciate if you let me know once this issue with simulation is fixed. Thanks.

---

## 2020-10-30 08:26:47 - general channel

**liam**

You are correct, there was no handling for size reduction in the simulated execution, created a PR to fix it [https://github.com/liampauling/flumine/pull/305](https://github.com/liampauling/flumine/pull/305)

---

## 2020-10-29 20:35:44 - issues channel

**birchy**

Also, should that be using `pd.price` instead of `pd['price']` ? PyCharm is flagging the latter as an error, but `pd.price` fails in an external project:

```for runner in market_book.runners:

    for pd in runner.ex.traded_volume:

        print(pd['price'], pd['size']) # OK

        print(pd.price, pd.size) # error```

---

## 2020-10-29 19:51:11 - issues channel

**Mo**

Suggestions:



1) The comment for ticks_spread implies you’re calculating PRICES.index(as_dec(price1)) - PRICES.index(as_dec(price2))

2) You should return None on exception in ticks_spread rather than implying the prices are identical

3) I’d explicitly return None on exception in runner_vwap

4) I’d call the functions calculate_ticks_spread and calculate_runner_vwap

---

## 2020-10-29 07:59:49 - issues channel

**JonM**

Boom!  `lightweight` parameter fixes it.  Thanks [@UBS7QANF3](@UBS7QANF3).  Another bit of flimsiness in my code identified and fixed!

---

## 2020-10-29 07:56:39 - general channel

**liam**

[@U01BBMTK6R3](@U01BBMTK6R3) fairly sure you will get the INVALID_PROFIT_RATIO error if trying to cancel 1.51 of a 1.01 order, what do the logs say?

---

## 2020-10-28 22:49:13 - issues channel

**JonM**

`Traceback (most recent call last):`

  `File "&lt;input&gt;", line 1, in &lt;module&gt;`

  `File "xxxxxxx/python3.8/site-packages/betfairlightweight/endpoints/account.py", line 87, in get_account_statement`

    `return self.process_response(`

  `File "/xxxxxxxxxxx/python3.8/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 115, in process_response`

    `raise InvalidResponse(response=result)`

`betfairlightweight.exceptions.InvalidResponse: Invalid response received: {'accountStatement': [{'refId': '215131991392', 'itemDate': '2020-10-28T20:20:27.000Z'.......` 

---

## 2020-10-28 22:46:50 - issues channel

**JonM**

Anybody noticed anything odd with the accounts API this evening?  My nightly account scraper is throwing errors on what looks like a perfectly acceptable response:

---

## 2020-10-28 13:09:29 - issues channel

**liam**

i think you can assume that the order stream / logic is pretty solid and the error is probably on your logic (assuming betfair weren't having issues)

---

## 2020-10-28 13:06:52 - issues channel

**jhaa**

10/28 10:29:48 OrderStreaming run error

Traceback (most recent call last):

  File "/home/code/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 216, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "/usr/lib/python3.8/ssl.py", line 1226, in recv

    return self.read(buflen)

  File "/usr/lib/python3.8/ssl.py", line 1101, in read

    return self._sslobj.read(len)

socket.timeout: The read operation timed out



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "/home/code/dev/betfair_jhaa/v2/core/SafeStreamingThread.py", line 60, in run

    self.stream.start()

  File "/home/code/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 59, in start

    self._read_loop()

  File "/home/code/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 198, in _read_loop

    received_data_raw = self._receive_all()

  File "/home/code/venv/lib/python3.8/site-packages/betfairlightweight/streaming/betfairstream.py", line 220, in _receive_all

    raise SocketError("[Connect: %s]: Socket %s" % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 568]: Socket The read operation timed out



...



10/28 10:30:08 Starting OrderStreaming

10/28 10:30:08 [Connect: 568]: connection_id: 108-281020093008-805670

10/28 10:30:08 [Subscription: 569]: SUCCESS (9 connections available)

10/28 10:30:08 [Subscription: 568]: SUCCESS (9 connections available)

10/28 10:30:08 [Stream: 568]: 54 oc resubscribed

---

## 2020-10-28 13:05:06 - issues channel

**liam**

Sounds like the problem is the lack of local state / error handling on the order stream working

---

## 2020-10-28 12:53:46 - issues channel

**jhaa**

I use this [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)



I have a bizarre bug where every other day there is a timeout and when the OrderStream restarts I do not seem to get orders for certain markets. For example earlier today there were connection issues and the bot was trading 61 markets, 2 of those the placed orders were not recorded and the bot kept placing the order again and again until it ran out of funds. The other 59 markets showed no such behaviour.



Has anybody seen stuff like this?

---

## 2020-10-28 11:01:56 - general channel

**river_shah**

is it possible to get a more detailed error message?

---

## 2020-10-28 11:00:16 - general channel

**river_shah**

I downloaded a lot of files, now I keep getting this when I invoke `trading.historic.get_file_list`

```[!DOCTYPE html](!DOCTYPE html)



&lt;html&gt;

&lt;head&gt;

    &lt;meta name="viewport" content="width=device-width" /&gt;

    &lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

    &lt;div&gt; 

        Error

    &lt;/div&gt;

&lt;/body&gt;

&lt;/html&gt;```

---

## 2020-10-28 08:52:32 - general channel

**river_shah**

```file_list = trading.historic.get_file_list(...)

requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://historicdata.betfair.com|historicdata.betfair.com](http://historicdata.betfair.com|historicdata.betfair.com)', port=443): Read timed out. (read timeout=16)```



---

## 2020-10-27 04:39:52 - issues channel

**Misha**

Here are the API errors: [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-InstructionReportErrorCode](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-InstructionReportErrorCode)

---

## 2020-10-27 04:37:17 - issues channel

**Misha**

You get different error messages if it goes through to the API

---

## 2020-10-27 04:01:33 - issues channel

**Misha**

That's not a Betfair API error

---

## 2020-10-27 03:58:10 - issues channel

**AP**

Hi all,



Just wondering if this error is from a flumine setting or my own account?



```"message": "Order has violated ORDER_VALIDATION and will not be placed", "control": "ORDER_VALIDATION", "error": "Order size is less than min bet size (5) or payout (30) for currency"```

---

## 2020-10-26 11:43:43 - general channel

**dan2002**

I wrote the orders (status, size matches etc) into a csv  after extending loggingcontrol, I got different order status, size matched etc each time I run backtesr.py on debug mode.

---

## 2020-10-26 11:25:41 - general channel

**dan2002**

when I tried to output the back test Order list  of backtesr.py to cvs through logging control in flumine, I get different order history each time on release mode, and in debug mode order history is consistent. My question is that are we supposed to get the same order list each time we run backtesr.py? Anyone can share an example of  a csv logging control? Thanks.

---

## 2020-10-25 18:57:23 - issues channel

**RichL**

Perhaps make it optional? try: import orjson / except ImportError: import json ?

---

## 2020-10-25 15:40:11 - issues channel

**Vitaly**

After updating flumine to 1.14.0. I've received error in my marketlogger:

Traceback (most recent call last):

  File "marketlogger.py", line 47, in &lt;module&gt;

    framework.run()

  File "/home/lvv77/.local/lib/python3.6/site-packages/flumine/flumine.py", line 44, in run

    self._process_close_market(event)

  File "/home/lvv77/.local/lib/python3.6/site-packages/flumine/baseflumine.py", line 269, in _process_close_market

    strategy.process_closed_market(market, event.event)

  File "/home/lvv77/bf6/strategies/marketrecorder.py", line 71, in process_closed_market

    file.write(market.market_catalogue.json())

TypeError: write() argument must be str, not bytes

---

## 2020-10-24 08:23:50 - issues channel

**mandelbot**

hrms, why do I get a 'TOO_MUCH_DATA' exception even though I'm filtering the market catalogue and have max_results &lt; 1000?

---

## 2020-10-22 06:49:01 - general channel

**liam**

There was a bug where the latency warnings were being shown incorrectly on snapped data but his has been fixed. However if you are just recording data you shouldn’t be getting high CPU, have you set the streaming_timeout? Should be None for data recording 

---

## 2020-10-21 21:17:44 - general channel

**ricky**

Apologise, I havent used the lastest version of flumine. Occasionally when inplay football began, my CPU loading was over 100%, and memory usage is 16.4%.

I use Ubuntu 20.04. Any suggestion what tool i can use for debugging the root cause of high CPU load? My initial thought was the filesystem (nautilus), becasue i keep recording data into a file, but i have not way to prove it becuase it happened occasionally.

---

## 2020-10-20 16:14:56 - issues channel

**river_shah**

stack overflow coming back with minimal suggestions. wondering if anyone has any ideas:

```➜  / pip install flumine

Collecting flumine

  Using cached flumine-1.14.0-py3-none-any.whl (95 kB)

Collecting betfairlightweight==2.9.0

  Using cached betfairlightweight-2.9.0-py3-none-any.whl (60 kB)

Collecting python-json-logger==2.0.0

  Using cached python-json-logger-2.0.0.tar.gz (8.2 kB)

Collecting tenacity==5.0.3

  Using cached tenacity-5.0.3-py2.py3-none-any.whl (38 kB)

Collecting requests

  Using cached requests-2.24.0-py2.py3-none-any.whl (61 kB)

Collecting orjson==3.4.0; sys_platform == "darwin" or sys_platform == "linux"

  Using cached orjson-3.4.0.tar.gz (655 kB)

  Installing build dependencies ... done

  Getting requirements to build wheel ... done

    Preparing wheel metadata ... error

    ERROR: Command errored out with exit status 1:

     command: /usr/local/bin/python3.9 /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pip/_vendor/pep517/_in_process.py prepare_metadata_for_build_wheel /var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/tmp8bxpoz4e

         cwd: /private/var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/pip-install-kfkcy84b/orjson

    Complete output (13 lines):

    :boom: maturin failed

      Caused by: Cargo metadata failed. Do you have cargo in your PATH?

      Caused by: Error during execution of `cargo metadata`: error: failed to run `rustc` to learn about target-specific information



    Caused by:

      process didn't exit successfully: `rustc - --crate-name ___ --print=file-names -Z mutable-noalias --crate-type bin --crate-type rlib --crate-type dylib --crate-type cdylib --crate-type staticlib --crate-type proc-macro --print=sysroot --print=cfg` (exit code: 1)

      --- stderr

      error: the option `Z` is only accepted on the nightly compiler





    Checking for Rust toolchain....

    Running `maturin pep517 write-dist-info --metadata-directory /private/var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/pip-modern-metadata-h04wo8ou --interpreter /usr/local/bin/python3.9 --manylinux=off --strip=on`

    Error: Command '['maturin', 'pep517', 'write-dist-info', '--metadata-directory', '/private/var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/pip-modern-metadata-h04wo8ou', '--interpreter', '/usr/local/bin/python3.9', '--manylinux=off', '--strip=on']' returned non-zero exit status 1.

    ----------------------------------------

ERROR: Command errored out with exit status 1: /usr/local/bin/python3.9 /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pip/_vendor/pep517/_in_process.py prepare_metadata_for_build_wheel /var/folders/0v/x5pftd6d6_v9ylh2rnjsn8f80000gn/T/tmp8bxpoz4e Check the logs for full command output.```



---

## 2020-10-17 23:28:09 - issues channel

**AP**

I am deploying a function app (serverless) on Azure and got the following error related to orjson when deploying:



```Collecting orjson==3.4.0; sys_platform == "darwin" or sys_platform == "linux" (from betfairlightweight-&gt;-r requirements.txt (line 14))

  Downloading [https://files.pythonhosted.org/packages/ca/ab/cece004aaae000741d059dcb9b1f6f62a6a5ecb2e11b3ecca09e6180c327/orjson-3.4.0.tar.gz](https://files.pythonhosted.org/packages/ca/ab/cece004aaae000741d059dcb9b1f6f62a6a5ecb2e11b3ecca09e6180c327/orjson-3.4.0.tar.gz) (655kB)

  Installing build dependencies: started

  Installing build dependencies: finished with status 'done'

    Complete output from command python setup.py egg_info:

    Traceback (most recent call last):

      File "&lt;string&gt;", line 1, in &lt;module&gt;

      File "/opt/hostedtoolcache/Python/3.6.12/x64/lib/python3.6/tokenize.py", line 452, in open

        buffer = _builtin_open(filename, 'rb')

    FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-install-muey9qtb/orjson/setup.py'```

---

## 2020-10-16 10:19:37 - random channel

**Misha**

All the fixed odds bookmakers have 2 places up to 7 runners, and 3 for larger fields

---

## 2020-10-16 10:16:53 - random channel

**Twatter**

Not used to Aus racing - are there a fixed number of runners?

---

## 2020-10-16 09:36:47 - general channel

**Rob (NZ)**

when I put it at 500 it was coming back with a error

---

## 2020-10-16 09:12:42 - issues channel

**Newbie99**

shouldn't throw an error though surely?

---

## 2020-10-16 09:10:23 - issues channel

**Newbie99**

I'm getting a:



```Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang15b-prd-09230859-00277b1814', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} 

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang15b-prd-09230859-00277b1814', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}```

Just looking for: Aussie horse racing win only, so I'm guessing Betfair are up to their old tricks, not removing markets again perhaps?

---

## 2020-10-15 14:01:42 - random channel

**Newbie99**

Not sure if the issues with the trackpads have been fixed, or whether the XPS 13 uses the same as the 15, but they are awful (there are a few reviews around on youtube etc that talk about this so its a known issue)

---

## 2020-10-13 10:31:37 - issues channel

**Lee**

orjson strikes again

```       Collecting orjson==3.4.0; sys_platform == "darwin" or sys_platform == "linux" (from betfairlightweight==0.0.0b21-&gt;-r /tmp/build/requirements/base.txt (line 4))

       Downloading [https://files.pythonhosted.org/packages/ca/ab/cece004aaae000741d059dcb9b1f6f62a6a5ecb2e11b3ecca09e6180c327/orjson-3.4.0.tar.gz](https://files.pythonhosted.org/packages/ca/ab/cece004aaae000741d059dcb9b1f6f62a6a5ecb2e11b3ecca09e6180c327/orjson-3.4.0.tar.gz) (655kB)

       Complete output from command python setup.py egg_info:

       Traceback (most recent call last):

       File "&lt;string&gt;", line 1, in &lt;module&gt;

       File "/app/.heroku/python/lib/python3.7/tokenize.py", line 447, in open

       buffer = _builtin_open(filename, 'rb')

       FileNotFoundError: [Errno 2] No such file or directory: '/tmp/pip-build-29ykcrms/orjson/setup.py'

       

----------------------------------------

       Command "python setup.py egg_info" failed with error code 1 in /tmp/pip-build-29ykcrms/orjson/```



---

## 2020-10-12 21:28:23 - issues channel

**Unknown**

Any ideas why MarketRecorder seems to have stopped loading to S3? I've noticed this several times now and restarting the bot fixes it. Still running at present but looks like it's only saved one file since 3rd October. Logging is set to WARNING and there's nothing on there that rings any alarm bells. Haven't checked the actual files as I'm not on the PC right now. Or could it be AWS display being a bit wanky?

---

## 2020-10-12 11:10:23 - strategies channel

**Michael**

I look at a whole bunch of things separately: Profit on each transaction if fully matched at flat stakes, proportion of that realised and so on. Optimising stakes for similar transactions is just profit. I also run a fixed 'benchmark' simulation on every market so that I can compare groups of markets in terms of their overall capacity for getting value bets in and try to control for the background performance of markets in that way (to factor out things like the post lockdown surge). It get quite complex though.

---

## 2020-10-11 20:04:49 - general channel

**mandelbot**

Is there a way to place a lay bet at SP at a fixed bet size regardless of liability?

---

## 2020-10-10 15:44:29 - general channel

**ricky**

Question on the max number of connections / sockets in flumine,

i used flumine for price recording, becasue i want to manage customised price calculation for different market, i need create few instance of PriceRecorder as example below:



my_event_id = [30050835]

strategy1 = PriceRecorder(

    market_filter = betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["1"], market_types=["MATCH_ODDS", "OVER_UNDER_25"], event_ids=my_event_id

    ),

    market_data_filter = betfairlightweight.filters.streaming_market_data_filter(

        fields=["EX_BEST_OFFERS", "EX_MARKET_DEF", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP"], ladder_levels=3

    ),

)



my_event_id = [30050836]

strategy2 = PriceRecorder1(

    market_filter = betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["1"], market_types=["MATCH_ODDS", "OVER_UNDER_25"], event_ids=my_event_id

    ),

    market_data_filter = betfairlightweight.filters.streaming_market_data_filter(

        fields=["EX_BEST_OFFERS", "EX_MARKET_DEF", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP"], ladder_levels=3

    ),

)



framework.add_strategy(strategy1)

framework.add_strategy(strategy2)

...



When i tested with 10 or more strategies, I got exceed max number of connection error, expect 10 got 11. I thought there is not limitation in terms of number of strategies? in this example, Did each strategies create separate socket connection to befair? any possible work around?

---

## 2020-10-09 21:41:19 - issues channel

**Misha**

There can be errors in the supplied data - probably missing updates

---

## 2020-10-09 21:12:03 - issues channel

**Lee**

I've grabbed a couple of market id's from yesterday which causes the exception `1.173953839` and `1.173953766`

---

## 2020-10-09 20:20:47 - issues channel

**Jonjonjon**

[@UUCD6P13J](@UUCD6P13J) Do you have any tips on how I can reproduce the error?

---

## 2020-10-09 17:34:34 - issues channel

**Lee**

Just come across this error on flumine==1.13.0

```  File "/Users/leeunsworth/git/sports-betting/.venv/lib/python3.7/site-packages/flumine/markets/blotter.py", line 135, in selection_exposure

    unmatched_exposure = calculate_unmatched_exposure(ub, ul)

  File "/Users/leeunsworth/git/sports-betting/.venv/lib/python3.7/site-packages/flumine/utils.py", line 164, in calculate_unmatched_exposure

    lay_exp = sum((i[0] - 1) * -i[1] for i in ul)

  File "/Users/leeunsworth/git/sports-betting/.venv/lib/python3.7/site-packages/flumine/utils.py", line 164, in &lt;genexpr&gt;

    lay_exp = sum((i[0] - 1) * -i[1] for i in ul)

TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'```

---

## 2020-10-09 07:10:37 - random channel

**Mo**

I didn’t say anything about a fixed bankroll. The entire point is to compound the winnings. 

---

## 2020-10-08 22:40:57 - issues channel

**Newbie99**

```{"asctime": "2020-10-08 21:05:56,243", "levelname": "ERROR", "message": "_get_cleared_markets error", "exc_info": "Traceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 381, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 978, in _validate_conn\n    conn.connect()\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connection.py\", line 362, in connect\n    self.sock = ssl_wrap_socket(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 384, in ssl_wrap_socket\n    return context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"D:\\Python38\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"D:\\Python38\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"D:\\Python38\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nsocket.timeout: _ssl.c:1106: The handshake operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n    resp = conn.urlopen(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 726, in urlopen\n    retries = retries.increment(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\util\\retry.py\", line 403, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\packages\\six.py\", line 735, in reraise\n    raise value\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n    httplib_response = self._make_request(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 384, in _make_request\n    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n    raise ReadTimeoutError(\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 36, in request\n    response = [http://session.post|session.post](http://session.post|session.post)(\n  File \"D:\\Python38\\lib\\site-packages\\requests\\api.py\", line 119, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\api.py\", line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n    r = adapter.send(request, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 529, in send\n    raise ReadTimeout(e, request=request)\nrequests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\flumine\\worker.py\", line 200, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 45, in request\n    raise APIError(None, method, params, e)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.173991824'], 'customerStrategyRefs': ['BlueOcean'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.173991824'], 'customerStrategyRefs': ['BlueOcean'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=3.05)"}



{"asctime": "2020-10-08 21:12:32,721", "levelname": "ERROR", "message": "get_account_funds error", "exc_info": "Traceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 381, in _make_request\n    self._validate_conn(conn)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 978, in _validate_conn\n    conn.connect()\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connection.py\", line 362, in connect\n    self.sock = ssl_wrap_socket(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 384, in ssl_wrap_socket\n    return context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"D:\\Python38\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"D:\\Python38\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"D:\\Python38\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nsocket.timeout: _ssl.c:1106: The handshake operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n    resp = conn.urlopen(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 726, in urlopen\n    retries = retries.increment(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\util\\retry.py\", line 403, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\packages\\six.py\", line 735, in reraise\n    raise value\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n    httplib_response = self._make_request(\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 384, in _make_request\n    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n  File \"D:\\Python38\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n    raise ReadTimeoutError(\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 36, in request\n    response = [http://session.post|session.post](http://session.post|session.post)(\n  File \"D:\\Python38\\lib\\site-packages\\requests\\api.py\", line 119, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\api.py\", line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n    r = adapter.send(request, **kwargs)\n  File \"D:\\Python38\\lib\\site-packages\\requests\\adapters.py\", line 529, in send\n    raise ReadTimeout(e, request=request)\nrequests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Python38\\lib\\site-packages\\flumine\\clients\\betfairclient.py\", line 56, in _get_account_funds\n    return self.betting_client.account.get_account_funds()\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\account.py\", line 35, in get_account_funds\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"D:\\Python38\\lib\\site-packages\\betfairlightweight\\endpoints\\baseendpoint.py\", line 45, in request\n    raise APIError(None, method, params, e)\nbetfairlightweight.exceptions.APIError: AccountAPING/v1.0/getAccountFunds \nParams: {} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)", "error": "AccountAPING/v1.0/getAccountFunds \nParams: {} \nException: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=6.05)"}```

---

## 2020-10-08 22:40:57 - issues channel

**Newbie99**



Have been getting these errors over the last 24 hours (using Flumine live), has anyone else seen similar, or is it just likely to be a timeout caused by a network issue from my end?

---

## 2020-10-08 20:23:04 - random channel

**liam**

All bets are independent regardless of the underlying market, just because you placed that first bet doesn’t make the second different in terms of its eventual ev. 



I don’t agree with your probabilities surrounding your hedged scenario and I don’t understand how this proves you can increase your wealth based on a fixed bank because your backtest uses a new bankroll on each execution.

---

## 2020-10-08 19:27:38 - issues channel

**liam**

Yeah that looks the same as what I am seeing, plan on having a fix in beta soon 

---

## 2020-10-08 19:19:04 - random channel

**Michael**

1: All profitable betting that is sustained over a large number of bets is dependant on those bets having positive expected value at the time of placement on aggregate and there is no exception to this.

---

## 2020-10-08 09:47:03 - general channel

**river_shah**

thanks for commits, taking a look. no worries I will fix the inspector warnings (on my local end). i see correct usage now.

---

## 2020-10-08 09:45:16 - general channel

**liam**

The issue you are seeing is that the inspector hasn't detected the patch, not sure we can fix that?

---

## 2020-10-07 19:20:00 - random channel

**PeterLe**

Enjoyed reading the posts this afternoon. Just to throw my hat into the ring, although there are always exceptions to the rule, there are many very successful long term traders who have used nothing more complicated that GCSE maths (probably not even that), myself included. Ive said it before that if I were to sell my strategy on Ebay, people would probably want their money back when I disclosed it! :grinning: Simplicity is often overlooked IMHO

---

## 2020-10-06 15:48:31 - general channel

**Jonjonjon**

Using this code:



```import datetime

import uuid





def from_uuid_time(uuid_time):

    return datetime.datetime(1582, 10, 15) + datetime.timedelta(microseconds=uuid_time//10)





print('Modifying 3rd digit')

d0 = from_uuid_time(13842839081240720)

d1 = from_uuid_time(13942839081240720)

print(d0)

print(d1)

print(d1-d0)```

I get this output:



`1626-08-26 19:18:28.124072`

`1626-12-20 13:05:08.124072`

`115 days, 17:46:40`



So it looks like if I use the 1st two characters of the order id for my own prefix, then I should be safe from clashes for 115 days.:grinning:

---

## 2020-10-06 14:34:06 - general channel

**Jonjonjon**

e.g.



new_order.id = my_prefix + new_order.id[:-len(my_prefx)

---

## 2020-10-06 10:09:36 - issues channel

**birchy**

Have just checked `/var/log/syslog` and no errors there. `/var/log/messages` has not been used since 2012 in Ubuntu machines.

---

## 2020-10-05 21:57:38 - issues channel

**birchy**

Not sure if this is related, but I've noticed my marketrecorder is stopping unexpectedly every 4 or 5 days. Only thing I can find in the logs is that it reports high latency for a couple of hours and then exits with no other errors logged. Could it be a memory issue? Have just restarted with `logging.level = WARNING` to try and narrow it down a bit.

Flumine 1.12.3

Orjson 3.3.0

Edit: have just upgraded Flumine to 1.13.0

---

## 2020-10-05 19:28:48 - issues channel

**Lee**

Hi, what issues/errors are you getting?

---

## 2020-10-05 18:19:32 - general channel

**ricky**

[@UUCD6P13J](@UUCD6P13J) "market.market_catalogue" i got error said undefined variable "market" inside in the PriceRecorder class.

---

## 2020-10-04 14:15:29 - issues channel

**Unknown**

If I point flumine/examples/backtest.py at the attached file, I get this error:



`Traceback (most recent call last):`

  `File "/home/jon/PycharmProjects/flumine/examples/backtest.py", line 34, in &lt;module&gt;`

    `framework.run()`

  `File "/home/jon/PycharmProjects/flumine/flumine/backtest/backtest.py", line 44, in run`

    `for event in stream_gen():`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/betfairstream.py", line 342, in _read_loop`

    `yield self.listener.snap()`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/listener.py", line 43, in snap`

    `return self.stream.snap(market_ids)`

  `File "/home/jon/PycharmProjects/flumine/flumine/streams/historicalstream.py", line 70, in snap`

    `cache.create_resource(self.unique_id, self._lightweight)`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/cache.py", line 219, in create_resource`

    `data = self.serialise`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/cache.py", line 270, in serialise`

    `"runners": [`

  `File "/home/jon/PycharmProjects/betfair/betfairlightweight/streaming/cache.py", line 272, in &lt;listcomp&gt;`

    `self.market_definition_runner_dict[`

`KeyError: (15431638, 0)`



The data was recorded using Flumine. I have a feeling it might be because I did not start recording the data as soon as the market became available.



I can get around it by deleting all data, until I have a marketDefinition update containing  a list of runners, but that is time consuming and hacky.

---

## 2020-10-01 11:49:46 - issues channel

**liam**

lots of errors coming in my end

---

## 2020-09-30 09:10:31 - general channel

**river_shah**

cool, thanks for clarifying and I will check if I can force an error.

---

## 2020-09-30 09:09:41 - general channel

**liam**

And yep you can’t cancel because it doesn’t have an Id, it should error?

---

## 2020-09-28 16:29:51 - general channel

**darren b**

This is to use the betfair .bz2 price files right? I'm running it but can't get past an 'inplay' KeyError. Any suggestions on what might be causing it? Thanks

---

## 2020-09-27 19:47:12 - random channel

**Jonjonjon**

But perhaps any overhead in learning/implementing redis would be more costly than the benefits of using it. It's good to have all your code in one place. If I have separate analytical code, it could double up my chances of errors.

---

## 2020-09-25 17:13:59 - issues channel

**D**

that was my next assumption :sweat_smile:  i’m running this on Mac at the minute, My project is living at `~/Apps/Betfair` so `/` is going for my disk root, which rightfully gives me a read only error. :thinking_face: do i pu them somewhere like `/etc/ssl` and use that as the cert path? I’ve seen elsewhere having these stored in environment files would make sense when time come to push it live

---

## 2020-09-25 15:49:58 - issues channel

**D**

hi, sorry if this is a question that gets asked loads. I’ve built a web app using the betfair api already in laravel  - I realise now that python would be a much better fit :eyes:  anyway,  ive got a working app key and i’ve uploaded a new .crt to my account in betfair  I’m getting the `Exception: [Errno 2] No such file or directory: '/certs/'` error, even though I’ve generated a .crt, .csr and a .key file. I’ve also copied the /certs directory to every single directory within my project directory I’m on mac so `/certs/` is read only if `/` is referring to my actual root filesystem. I’ve copied the certs folder to my home directory and tried pdating the path to `~/certs` but thats giving me the same error as well

---

## 2020-09-25 13:20:11 - issues channel

**richard**

Really sorry, probably a stupid question here, but I’m having issues with creating the filter to cancel orders. My code:

betId = *‘212122833595’*

 instructions_filter = betfairlightweight.filters.cancel_instruction(bet_id=str(betId))

 print(instructions_filter)

 result = trading.betting.cancel_orders(instructions=instructions_filter)

 print(result._data)

But I’m getting this error:

“betfairlightweight.exceptions.APIError: SportsAPING/v1.0/cancelOrders

Params: {‘instructions’: {‘betId’: ‘212122833595’}}

Exception: None

Error: {‘code’: -32602, ‘message’: ‘DSC-0018’}

Full Response: {‘jsonrpc’: ‘2.0’, ‘error’: {‘code’: -32602, ‘message’: ‘DSC-0018’}, ‘id’: 1}” Can anyone tell me what I’m doing wrong - I’m looking to cancel just this specific bet?

---

## 2020-09-25 10:15:24 - issues channel

**liam**

which is fine and shouldn't raise this error

---

## 2020-09-24 21:45:46 - strategies channel

**Newbie99**

(that said, if there is an all in one that has football and/or tennis as well for a fixed price, pretty happy with that too, but not essential)

---

## 2020-09-24 18:29:51 - issues channel

**Newbie99**

[@U013R0E7SUV](@U013R0E7SUV) are you using AWS by chance? I'm now getting the same error, with crazy latency times on a t3.mico, on a t2.micro running an older version no issues it seems (also locally no issues).

---

## 2020-09-24 10:44:14 - general channel

**liam**

If you have BPE disabled, you get an error if BPE is used to get you matched, e.g. you ask for a BACK at 5.0 but the best price is now 5.2 you would get an error with the size fully lapsed regardless of the amount available at 5.2

---

## 2020-09-24 10:11:58 - general channel

**liam**

no you get an error

---

## 2020-09-24 01:03:21 - general channel

**Taking Value**

Can I just check, is the base listener a lot faster than stream listener? I switched to the error handling code that [@UBS7QANF3](@UBS7QANF3) very kindly pointed me in the direction of. Its great but it uses the stream listener and it keeps flashing latency warnings at me. I am only using it for recording data at the moment so its not an issue but presumably it is an issue when its being used to place bets.

---

## 2020-09-23 13:31:16 - general channel

**Twatter**

This URL seem to list all eventIds for Betfairs Horse racing, but haven't figured out the URL to get data per Event yet:

[https://betfair.betstream.betgenius.com/betstream-view/getMappedFixtures/v1/product/betgeniushorseracing/sport/horseracing.json](https://betfair.betstream.betgenius.com/betstream-view/getMappedFixtures/v1/product/betgeniushorseracing/sport/horseracing.json)

---

## 2020-09-23 08:59:00 - general channel

**Lee**

I use flumine and it handles all the network errors for you 

---

## 2020-09-23 05:37:43 - general channel

**Mo**

Error handling example: [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)

---

## 2020-09-23 00:02:28 - general channel

**Taking Value**

My script that was collecting horse racing market data stopped executing Tuesday (or late Monday evening). Wondered if anyone recorded something similar (as in was it a BF issue or was it client side)? In situations like this what method do people use to re-connect and continue recording? I have a fix but it might involve spamming BF with re-subscription requests which I'm guessing might piss them off in a scenario where their API is actually down.

---

## 2020-09-22 16:20:33 - general channel

**D C**

Winner was almost at the back. Looks like one of those offset errors again.

---

## 2020-09-22 03:33:51 - random channel

**Chris**

I realize I need to log + trial and error here but I am hoping to avoid the bulk of the churn by getting a second set of eyes on this guesstimate

---

## 2020-09-18 10:17:46 - issues channel

**liam**

I get a few errors on AWS, I think its betfair tbh and yes it will reconnect

---

## 2020-09-18 10:16:02 - issues channel

**Lee**

[@U0128E7BEHW](@U0128E7BEHW) I'm using DO too and seeing a couple of these Timeout errors every few days. I'm getting them on both the streams and worker api calls.

---

## 2020-09-18 07:05:52 - general channel

**jp**

Note that if you aggregate commission by EVENT or EVENT_TYPE, there is a bug in the computation of commission from Betfair's side. This is reported to the BDP team but still not resolved.

---

## 2020-09-17 10:09:28 - general channel

**Jonjonjon**

Thanks DC. This is almost making my heard pound. I think it only really started for me a few weeks ago. I had a trading error in my favour for £5x, amongst many other trivial trades, but the total for the day only showed £4x, which definitely did not agree.

---

## 2020-09-17 09:12:40 - general channel

**Jono**

I am receiving an error  at the "for market books in gen()" line regarding a unicode error: 'charmap' codec can't decode byte 0x8f in position 159: character maps to &lt;undefined&gt;. So i was wondering if any processing has to be performed on the downloaded files prior to executing this script and/or parsing historical data?

---

## 2020-09-16 21:43:45 - issues channel

**Chris**

Hey guys -



I just had an error that originated from there being an order with status EXECUTION_COMPLETE in the market.blotter.live_orders object. My rough expectation was that the only orders I would see in the market.blotter.live_orders object would have a pending status (PENDING, CANCELLING, UPDATING, REPLACING) or the EXECUTABLE status.



Are my expectations wrong here (execution_complete is a valid status for an order in the live_orders object)? Or, was this error a timing / race condition issue that I should be accounting for (i.e. I tried to use the live_orders object before the order could be removed from the live orders object)?

---

## 2020-09-16 21:40:50 - general channel

**liam**

Dave the issue is you will get a full image on restart, this probably isn’t an issue as it seems the betfair data is full of it but you need to be aware and hence the new directory. But you can change the recorder to not do this if you want, easy to test  



I just start it off and forget about it, it will handle any betfair errors or network issues, only time you need to stop is to add more strategies or upgrade 

---

## 2020-09-15 16:44:53 - issues channel

**jhaa**

when I hand this function a single market_id instead of a list it does not give an error

---

## 2020-09-15 09:04:01 - general channel

**Misha**

Exceptions to this are big races where volume is there early and you can bet with size early and not move prices (e.g. the Melbourne Cup in Australia)

---

## 2020-09-15 08:52:31 - general channel

**Misha**

Fixed agencies seemed to offer good value early though

---

## 2020-09-14 23:03:26 - general channel

**birchy**

[@U016535QCJ2](@U016535QCJ2) looks very similar, so probably another closely guarded secret.

I find this interesting: `Each horse is allocated a reduction factor, based on its *likely chance of winning the race*`

[https://support.betfair.com/app/answers/detail/a_id/408/c/483/](https://support.betfair.com/app/answers/detail/a_id/408/c/483/)

I would _like_ to think that Betfair are using some sophisticated algorithm to calculate this value as it might effectively be a "true" price. What I don't understand is why Betfair use a fixed value for the reduction factor as surely it would be far more efficient to use the actual price of the runner when it gets withdrawn?

---

## 2020-09-14 22:23:51 - general channel

**Misha**

It will be similar to this - [https://help.tab.com.au/s/article/Tabcorp-Schedule-of-Deductions-for-Fixed-Odds-Racing-Betting](https://help.tab.com.au/s/article/Tabcorp-Schedule-of-Deductions-for-Fixed-Odds-Racing-Betting)

---

## 2020-09-14 19:02:05 - issues channel

**jhaa**

how likely is a switch to orjson going to fix that issues where the queue gets stuck when there are too many markets in the stream?

---

## 2020-09-14 19:01:21 - issues channel

**jhaa**

ok that was a simple fix

---

## 2020-09-14 17:54:30 - issues channel

**jhaa**

i just did a fresh venv on a new vps with latest bflw and i get:



TypeError: Type is not JSON serializable: numpy.float64

---

## 2020-09-14 15:39:43 - general channel

**Peter**

Betfair times can be a bit confusing. Suspend time doesn't indicate a delay. Based on my observations I believe that it is the time that Betfair expects the markets to be suspended prior to going in-play (though the actual time that this happens will depend on the punctuality at the venue). So basically the same as startTIme, which is usually the same as marketTime - though very occasionally I've seen differences and haven't been able to work out whether they're meaningful or errors.

---

## 2020-09-14 07:01:21 - random channel

**Peter**

[@UFTBRB3F1](@UFTBRB3F1) I think you're going to be out of luck. This for the 18:15 works, `race_cards = trading.race_card.get_race_result(market_ids=['1.172974372'])` but stick '1.172950042' in there instead and it's still throwing an http 500 (server error) response. So def. a problem at the Betfair end and one likely to affect everybody.

---

## 2020-09-13 20:17:57 - random channel

**Newbie99**

By chance does anyone have the race result (in the format from the racecard end point) for the 18:45 from Musselburgh yesterday ('1.172950042').



For some reason I can get every other race, but that one throws up an error (I'm guessing Betfair did something at their end) and purely for OCD purposes it would be handy to have it if anyone has it to hand?



```Traceback (most recent call last):

  File "D:/Python37/webpages/bingo.py", line 41, in &lt;module&gt;

    race_cards = trading.race_card.get_race_result(market_ids=['1.172950042'])

  File "D:\Python38\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 94, in get_race_result

    (response, response_json, elapsed_time) = self.request(

  File "D:\Python38\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 113, in request

    check_status_code(response)

  File "D:\Python38\lib\site-packages\betfairlightweight\utils.py", line 31, in check_status_code

    raise StatusCodeError(response.status_code)

betfairlightweight.exceptions.StatusCodeError: Status code error: 500```

---

## 2020-09-11 17:25:30 - general channel

**jhaa**

I have a newish bot running that uses the streaming. It runs fine for a few days without any flaws and then it goes beserk and trades markets inplay even though it is build to not to do that and it places bets multiple times because it assumes that they were not places yet.



I had the bet placement issue previously and sort of fixed that by removing ujson.



Any idea what might cause this? It sort of looks like something is wrong further down the software stack or I get wrong stuff through the stream

---

## 2020-09-11 15:57:46 - general channel

**Chris**

I see the correct oc / mb message make it in the door and the corresponding market (1.72246112) get added to the OrderStream and Stream. However, I don't see that market get added to flumine.baseflumine until a later mc message that gets processed _after_ the oc message. Is it possible that the implementation depends on the mc message arriving first?



2020-09-11 14:44:08,606 - flumine.baseflumine - INFO - Adding trading control ORDER_VALIDATION

2020-09-11 14:44:08,606 - flumine.baseflumine - INFO - Adding trading control STRATEGY_EXPOSURE

2020-09-11 14:44:08,607 - flumine.baseflumine - INFO - Adding client control MAX_ORDER_COUNT

2020-09-11 14:44:08,607 - flumine.baseflumine - INFO - Adding strategy NaiveMarketMakerStrategy

2020-09-11 14:44:08,607 - flumine.streams.streams - INFO - Creating new &lt;class 'flumine.streams.marketstream.MarketStream'&gt; (2000) for strategy NaiveMarketMakerStrategy

2020-09-11 14:44:08,607 - flumine.baseflumine - INFO - Starting flumine

2020-09-11 14:44:08,609 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

2020-09-11 14:44:09,372 - urllib3.connectionpool - DEBUG - [https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

2020-09-11 14:44:09,377 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): [http://api.betfair.com:443|api.betfair.com:443](http://api.betfair.com:443|api.betfair.com:443)

2020-09-11 14:44:10,085 - urllib3.connectionpool - DEBUG - [https://api.betfair.com:443](https://api.betfair.com:443) "POST /exchange/account/json-rpc/v1 HTTP/1.1" 200 176

2020-09-11 14:44:10,088 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): [http://api.betfair.com:443|api.betfair.com:443](http://api.betfair.com:443|api.betfair.com:443)

2020-09-11 14:44:10,653 - urllib3.connectionpool - DEBUG - [https://api.betfair.com:443](https://api.betfair.com:443) "POST /exchange/account/json-rpc/v1 HTTP/1.1" 200 158

2020-09-11 14:44:10,656 - flumine.worker - INFO - BackgroundWorker keep_alive starting

2020-09-11 14:44:10,656 - flumine.worker - DEBUG - BackgroundWorker keep_alive executing

2020-09-11 14:44:10,656 - flumine.worker - INFO - BackgroundWorker poll_account_balance starting

2020-09-11 14:44:10,656 - flumine.worker - INFO - BackgroundWorker poll_market_catalogue starting

2020-09-11 14:44:10,657 - flumine.worker - INFO - BackgroundWorker poll_cleared_orders starting

2020-09-11 14:44:10,657 - flumine.streams.streams - INFO - Starting streams..

2020-09-11 14:44:10,657 - flumine.streams.orderstream - INFO - Starting OrderStream

2020-09-11 14:44:10,657 - flumine.streams.orderstream - INFO - Starting output_thread &lt;Thread(OrderStream_output_thread, initial daemon)&gt;

2020-09-11 14:44:10,658 - betfairlightweight.streaming.listener - INFO - Register: orderSubscription 1001

2020-09-11 14:44:10,658 - betfairlightweight.streaming.stream - INFO - [Stream: 1001]: "OrderStream" created

2020-09-11 14:44:10,658 - flumine.streams.marketstream - INFO - Starting MarketStream

2020-09-11 14:44:10,658 - flumine.streams.marketstream - INFO - Starting output_thread &lt;Thread(MarketStream_output_thread, initial daemon)&gt;

2020-09-11 14:44:10,659 - betfairlightweight.streaming.listener - INFO - Register: marketSubscription 2001

2020-09-11 14:44:10,659 - betfairlightweight.streaming.stream - INFO - [Stream: 2001]: "MarketStream" created

starting strategy 'ExampleStrategy'

2020-09-11 14:44:11,333 - betfairlightweight.streaming.betfairstream - DEBUG - [Subscription: 2002] Sending: '{"op": "authentication", "id": 2002, "appKey": "bOP9A5Vmp8n8K48d", "session": "XIlFe2j97G/m11sC7MXvyXllXn+/pQA3q/6nRSlqnf8="}\r\n'

2020-09-11 14:44:11,333 - betfairlightweight.streaming.betfairstream - DEBUG - [Subscription: 2002] Sending: '{"op": "marketSubscription", "id": 2001, "marketFilter": {"marketIds": ["1.172246112"]}, "marketDataFilter": {"fields": ["EX_ALL_OFFERS", "EX_TRADED", "EX_TRADED_VOL", "EX_LTP", "EX_MARKET_DEF", "SP_TRADED", "SP_PROJECTED"]}, "initialClk": null, "clk": null, "conflateMs": null, "heartbeatMs": null, "segmentationEnabled": true}\r\n'

2020-09-11 14:44:11,335 - betfairlightweight.streaming.listener - INFO - [Connect: 2001]: connection_id: 103-110920144408-1944934

2020-09-11 14:44:11,335 - betfairlightweight.streaming.betfairstream - DEBUG - [Subscription: 1002] Sending: '{"op": "authentication", "id": 1002, "appKey": "bOP9A5Vmp8n8K48d", "session": "XIlFe2j97G/m11sC7MXvyXllXn+/pQA3q/6nRSlqnf8="}\r\n'

2020-09-11 14:44:11,335 - betfairlightweight.streaming.betfairstream - DEBUG - [Subscription: 1002] Sending: '{"op": "orderSubscription", "id": 1001, "orderFilter": {"includeOverallPosition": false, "customerStrategyRefs": ["DESKTOP-PUCIJ46"], "partitionMatchedByStrategyRef": true}, "initialClk": null, "clk": null, "conflateMs": null, "heartbeatMs": null, "segmentationEnabled": true}\r\n'

2020-09-11 14:44:11,336 - betfairlightweight.streaming.listener - INFO - [Connect: 1001]: connection_id: 104-110920144408-1957086

2020-09-11 14:44:11,455 - betfairlightweight.streaming.listener - INFO - [Subscription: 1002]: SUCCESS (9 connections available)

2020-09-11 14:44:11,455 - betfairlightweight.streaming.listener - INFO - [Subscription: 1001]: SUCCESS (9 connections available)

2020-09-11 14:44:11,463 - betfairlightweight.streaming.listener - INFO - [Subscription: 2002]: SUCCESS (8 connections available)

*2020-09-11 14:44:11,475 - betfairlightweight.streaming.listener - DEBUG - [Subscription: 1001]: SUB_IMAGE: {'op': 'ocm', 'id': 1001, 'initialClk': 'FI60s4gDFZzFy4EDFcDZ+IUDFMup9YoDFLfurYQD', 'clk': 'AAAAAAAAAAAAAA==', 'conflateMs': 0, 'heartbeatMs': 5000, 'pt': 1599835448156, 'ct': 'SUB_IMAGE', 'oc': [{'id': '1.172246112', 'orc': [{'fullImage': True, 'id': 56323, 'smc': {'DESKTOP-PUCIJ46': {'mb': [[1.31, 9], [1.3, 9]]}}}]}]}*

*2020-09-11 14:44:11,475 - betfairlightweight.streaming.stream - INFO - [OrderStream: 1001] 1.172246112 added, 1 markets in cache*

*2020-09-11 14:44:11,476 - betfairlightweight.streaming.stream - INFO - [Stream: 1001]: 1 oc added*

2020-09-11 14:44:11,479 - betfairlightweight.streaming.listener - INFO - [Subscription: 2001]: SUCCESS (8 connections available)

2020-09-11 14:44:11,503 - betfairlightweight.streaming.listener - DEBUG - [Subscription: 2001]: SUB_IMAGE: {'op': 'mcm', 'id': 2001, 'initialClk': 'whrdibCSB8wa//HplwfFGo7WiZkH', 'clk': 'AAAAAAAA', 'conflateMs': 0, 'heartbeatMs': 5000, 'pt': 1599835448182, 'ct': 'SUB_IMAGE', 'mc': [{'id': '1.172246112', 'marketDefinition': {'bspMarket': False, 'turnInPlayEnabled': True, 'persistenceEnabled': True, 'marketBaseRate': 5, 'eventId': '29969294', 'eventTypeId': '1', 'numberOfWinners': 1, 'bettingType': 'ODDS', 'marketType': 'MATCH_ODDS', 'marketTime': '2020-09-12T16:30:00.000Z', 'suspendTime': '2020-09-12T16:30:00.000Z', 'bspReconciled': False, 'complete': True, 'inPlay': False, 'crossMatching': True, 'runnersVoidable': False, 'numberOfActiveRunners': 3, 'betDelay': 0, 'status': 'OPEN', 'runners': [{'status': 'ACTIVE', 'sortPriority': 1, 'id': 56323}, {'status': 'ACTIVE', 'sortPriority': 2, 'id': 48317}, {'status': 'ACTIVE', 'sortPriority': 3, 'id': 58805}], 'regulators': ['MR_INT'], 'countryCode': 'GB', 'discountAllowed': True, 'timezone': 'GMT', 'openDate': '2020-09-12T16:30:00.000Z', 'version': 3356134545, 'priceLadderDefinition': {'type': 'CLASSIC'}}, 'rc': [{'atb': [[10, 422.04], [10.5, 556.23], [9.8, 141.82], [9.4, 2], [1.01, 73767.48], [9.6, 20], [1.04, 18699.25], [1.02, 62403.5], [1.03, 44624.06], [2, 1.47], [1.1, 10000], [1.05, 14000], [1.09, 10000], [1.08, 10000], [1.07, 14000], [1.06, 14000]], 'atl': [[11, 120.65], [11.5, 603.9], [12, 511.84], [12.5, 568.7], [15.5, 17.5], [13.5, 749.87], [1000, 7.9], [14, 422.21], [13, 490.67], [15, 117.5], [16, 2]], 'trd': [[11, 3916], [10.5, 1267.23], [11.5, 7465.42], [13.5, 60.63], [13, 168.73], [12.5, 5668.28], [12, 9072.82], [10, 22.17], [9.6, 10.32], [9.8, 29.56]], 'ltp': 11, 'tv': 27681.16, 'id': 48317}, {'atb': [[1.32, 8095.3], [1.29, 36848.2], [1.3, 27113.82], [1.31, 9545.35], [1.01, 148763.48], [1.27, 30772.3], [1.28, 34136.61], [1.04, 18699.25], [1.24, 30010.9], [1.22, 25824.06], [1.02, 137403.5], [1.25, 50201.35], [1.23, 20937.03], [1.26, 50513.1], [1.03, 59624.06], [1.21, 25], [1.09, 10100], [1.1, 10000], [1.08, 10000], [1.07, 14000], [1.06, 14000], [1.05, 14000]], 'atl': [[1.33, 1193.27], [1.34, 1675.23], [1.35, 2113.48], [1.4, 20], [1.38, 600], [1.36, 1436.29], [2, 11.85], [1.45, 6.53], [1.8, 3.66], [1000, 5.05], [10, 82]], 'trd': [[1.32, 13620.02], [1.33, 42973.12], [1.34, 1499.87], [1.31, 36034.48], [1.29, 31452.81], [1.3, 64317.62], [1.27, 3095.66], [1.28, 22549.18]], 'ltp': 1.32, 'tv': 215542.76, 'id': 56323}, {'atb': [[6.6, 103.43], [6.4, 449.32], [6.2, 499.94], [5.8, 2], [5.9, 139.33], [6, 464.6], [1.01, 43.45], [1.03, 2], [3.5, 5]], 'atl': [[6.8, 391.26], [7.2, 1193.74], [7, 1406.89], [7.8, 708.38], [1000, 7.9], [8, 677.37], [7.4, 1667.71], [7.6, 892.78], [950, 2.2], [13.5, 2]], 'trd': [[6.6, 4780.12], [6.8, 11467.19], [6.4, 1194.02], [6.2, 26.38], [7, 12286.69], [7.4, 1110.62], [7.2, 3942.68], [7.6, 127.79], [6, 8], [7.8, 0.2]], 'ltp': 6.6, 'tv': 34943.69, 'id': 58805}], 'img': True, 'tv': 278167.61}]}

2020-09-11 14:44:11,503 - betfairlightweight.streaming.stream - INFO - [MarketStream: 2001] 1.172246112 added, 1 markets in cache

2020-09-11 14:44:11,505 - betfairlightweight.streaming.stream - INFO - [Stream: 2001]: 1 mc added

2020-09-11 14:44:11,506 - flumine.baseflumine - INFO - Adding: 1.172246112 to markets

---

## 2020-09-11 15:18:04 - general channel

**liam**

[@UUCD6P13J](@UUCD6P13J) that is only for backtesting, if you want BPE off you need to manually do it on the site at the account level, need to add an error / validation on this 

---

## 2020-09-10 21:40:22 - issues channel

**Jonjonjon**

[@U4H19D1D2](@U4H19D1D2) I have situations where I have backed a horse at high odds. Then I try to lay the horse at lower odds. StrategyExposure prevents me from doing so, in a way that I believe is unjustified.



e.g. If I back £2 @ 1000, I should be able to lay £2 @ 500, as that is decreasing my exposure. However, I can't do that in this unit test:



```@mock.patch("flumine.controls.tradingcontrols.StrategyExposure._on_error")

def test_validate_selection2(self, mock_on_error):

    mock_market = mock.Mock()

    blotter = Blotter(mock_market)

    mock_market.blotter = blotter



    mock_strategy = mock.Mock()

    mock_lookup = mock.Mock()



    mock_matched_order = mock.Mock()

    mock_matched_order.order_type.ORDER_TYPE = OrderTypes.LIMIT

    mock_matched_order.side = 'BACK'

    mock_matched_order.order_type.size = 2

    mock_matched_order.size_matched = 2

    mock_matched_order.average_price_matched = 1000.

    mock_matched_order.id = 123

    mock_matched_order.trade.strategy = mock_strategy

    mock_matched_order.lookup = mock_lookup



    blotter._orders = {123:mock_matched_order}



    self.mock_flumine.markets.markets = {"1.234": mock_market}



    order = mock.Mock()

    order.trade.strategy = mock_strategy

    order.trade.strategy.max_order_exposure = float('inf')

    order.trade.strategy.max_selection_exposure = 10

    order.order_type.ORDER_TYPE = OrderTypes.LIMIT

    order.side = "LAY"

    order.order_type.size = 2

    order.order_type.price = 500.

    order.lookup = mock_lookup

    order_package = mock.Mock()

    order_package.market_id = "1.234"

    order_package.package_type = OrderPackageType.PLACE

    order_package.__iter__ = mock.Mock(return_value=iter([order]))



    self.trading_control._validate(order_package)



    self.assertEqual(0, mock_on_error.call_count)```

Apologies in advance if I've made a mistake and am making a false accusation.

---

## 2020-09-10 11:35:55 - general channel

**Lee**

Some of my API calls in `_process_order`  LoggingControl failed to post to an API successfully (a bug i've now fixed), but is there a way to fill these in? I was trying to use `list_cleared_orders` but as it's missing the flumine trade property i'm not sure how i'll know which strategy placed that order.

---

## 2020-09-09 14:09:24 - general channel

**Newbie99**

```{"asctime": "2020-09-09 13:09:03,511", "levelname": "ERROR", "message": "[Subscription: 2002] SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 9243 markets whereas max allowed number was: 200"}```

---

## 2020-09-09 14:08:16 - general channel

**Newbie99**

In theory you do subscribe to everything by doing that...but in reality your connection is immediately killed and you get an error

---

## 2020-09-09 09:56:56 - general channel

**D C**

[@U013MLED3V1](@U013MLED3V1) There are a multitude of ways you could deal with this but only you know what precisely defines a peak and you need to work on that basis. For example, you say in that example the middle point is the peak but only you know why that plot has just ONE peak instead of 3 or 0. Also depends on what you are trying to do with it and if you need it in real time (in which case you are restricted to causal filter/analysis) or a retrospective analysis. . If I were dealing with this problem myself the first thing I would do is pin down parameters that will define your peaks and go from there. I guess that depends on the problem you are trying to solve too - you might need to try something different if you are looking to identify a cricket sniper error or a fat finger order than if you were looking for the top of a price oscillation in a pre-race horse market.

---

## 2020-09-06 12:58:24 - general channel

**Mo**

No, you need to fix your code. Looks like you’re trying to access the third runner in a two runner market. But that’s all I can say without seeing it

---

## 2020-09-06 12:46:05 - general channel

**ricky**

The error happened after steaming udpate, i read each items from process_runner_books(runner_book).

Log shows "pandas/core/series.py. line 871, __getitem result = self.index.get_value(self, key)"

Key Error:2

---

## 2020-09-06 12:37:17 - general channel

**liam**

/ you need to handle betfair and network errors like the example above does

---

## 2020-09-06 12:36:48 - general channel

**liam**

Whats the error?

---

## 2020-09-06 12:35:33 - general channel

**ricky**

Hi everyone, i am trying to collect "MATCH_ODDS" and "OVER_UNDER_25" football match data into a single txt file.  I am streaming from a single thread, however, after sometime the program stop with error. (i tried set both

"output_queue = queue.Queue()" and "output_queue = None" without luck)



I can stream separate "MATCH_ODDS" or "OVER_UNDER_25" market without error, My question is do i need two threads to handle each market streaming data? Any existing example handle multiple thread streaming?

---

## 2020-09-06 06:25:08 - general channel

**liam**

If you set logging to debug you can see the updates / heartbeats 

---

## 2020-09-06 00:37:52 - issues channel

**birchy**

Agree with [@U0128E7BEHW](@U0128E7BEHW). Python Memory Error triggers the OOM process killer on Linux systems. Usually happens if you're appending to a list/dict/etc but forgetting to remove old entries and/or limiting the size. For lists, it's simply a case of doing something like `mylist = mylist[-1000:]`

---

## 2020-09-05 23:08:17 - issues channel

**Ruben**

there's something that is keeping me a bit worried....I run my market recorder on a very modest server (1 GB RAM), and yesterday the python process suddenly stopped, without any errors/warnings in the log, nor in stdout. I have no clue what could have caused this, any ideas?

---

## 2020-09-05 19:43:02 - issues channel

**Jonjonjon**

Ah, please ignore that. I fixed it. I have very bad infrastructure and a legacy bot does not use BFLW. It is on an old server that I don't have time to move. And I accidently killed the proxy server I used this morning. My own fault for being disorganised.

---

## 2020-09-05 19:34:23 - issues channel

**Jonjonjon**

Has anyone seen this issue before?



Oops no service available at [https://api.betfair.com/exchange/betting/json-rpc/v1](https://api.betfair.com/exchange/betting/json-rpc/v1) HTTP Error 502: Bad Gateway Traceback

---

## 2020-09-05 15:04:40 - general channel

**Oliver Varney**

Can anyone help me with more information on the error code ERROR_IN_ORDER. All the docs say is, "The action failed because the parent order failed". Probably something silly im doing but not sure where to start

---

## 2020-09-03 17:05:01 - issues channel

**Jon**

Anyone else currently getting "betfairlightweight.exceptions.LoginError: API login: CLOSED"?

---

## 2020-09-03 09:57:36 - general channel

**Mo**

I’ll treat you as the exception that proves the rule 

---

## 2020-09-03 09:54:01 - general channel

**Taking Value**

I'm storing whole race as a single document. Bit of meta data before hand to make the document identifiable but then all the runner changes sit in an array in a single key value pair. I must admit I didn't think it would come close to 16MB for a race but Mongo is spitting the error at me. I guess I could easily store each runner change as its own document, they are tagged with the race id after all.

---

## 2020-09-02 13:08:36 - general channel

**Misha**

That's not bad (I have customised software that I developed myself), but my main question is: how do you "eyeball" the data generated by the system? So not error data, actual system captured data (like you store on AWS)

---

## 2020-09-02 12:59:33 - general channel

**liam**

So sentry will tell me if an error has been caught or unhandled, if it’s really bad I get a slack notification. I use CloudWatch for day to day logs / checking on things 

---

## 2020-09-01 13:09:08 - random channel

**PeterLe**

Just a reminder; the new transaction conditions kick in today : _What are the changes?_

_•            5,000 Transactions per hour – the first 5,000 transactions within any given hour will be free of charge._  

_ _

_•            £0.002 cost per transaction – each transaction that exceeds the 5,000 transactions per hour threshold will incur a cost of £0.002._

_ _

_•            Commission Generated Offset – we will offset any fee against any commission generated (Commission Paid + Implied Commission)/2._

_ _

_•            Transaction = Bet Placed or Failed Transaction._

_ _

_A placed bet consists of any bet that is matched, cancelled or lapsed._

_Failed transaction is an action that results in a bet not being placed on the Betfair Exchange. Full descriptions of each failed transaction type can be found in the link below:_

_[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-ExecutionReportErrorCode](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-ExecutionReportErrorCode)_

---

## 2020-09-01 09:18:53 - general channel

**Mathias Tejs**

Depending on your setup (e.g. if you're jobs are in python), celery can be a good choice. For instance, it's got flower for monitoring job status in a GUI out of the box, and it handles automatic restart on errors, storing task results and so on.

---

## 2020-09-01 07:30:20 - issues channel

**Mo**

Welcome. Can you paste the error message?

---

## 2020-08-31 12:57:35 - general channel

**Angelos**

hi there,



i just started looking into betfair libraries and i’m so glad i found this community



got stuck with a few things, could you give me some pointers please?



i just switched from the traditional api to the streaming one but i get a

```data: {"op":"status","id":2,"statusCode":"FAILURE","errorCode":"NOT_AUTHORIZED","errorMessage":"AppKey is not configured for service"```

i’m currently using the delayed key just to play for now

---

## 2020-08-31 11:54:13 - issues channel

**Misha**

It's not a general Betfair issue as I have been hammering the API for years and I have never seen a "NO_APP_KEY" error (and I have logged every error to a database for the last 3 years)

---

## 2020-08-31 11:40:22 - issues channel

**qwerty.nat**

Anyone ever had any issues sending data too fast to the REST endpoint ?

`{"faultcode":"Client","faultstring":"ANGX-0004","detail":{"APINGException":{"requestUUID":"ie1-ang12a-prd-08061002-003376d0e9","errorCode":"NO_APP_KEY","errorDetails":""},"exceptionname":"APINGException"}}`

even if it is something as simple as listEventTypes (  `[https://api.betfair.com/exchange/betting/rest/v1.0/listEventTypes/](https://api.betfair.com/exchange/betting/rest/v1.0/listEventTypes/)"`  ) I get the error above, If i put a sleep in between the 2 calls they will both work,  managed to replicate it with a quick 'c' libcurl app as well, so it's not bflw issue, but a general betfair issue i think. more curious than anything else

---

## 2020-08-29 23:14:10 - issues channel

**jhaa**

i have not really debugged this, fortunately it is on one of my testing sub accounts

---

## 2020-08-29 23:13:21 - issues channel

**jhaa**

using v1.35 u ujson I get errors where the bot gets wrong exposure numbers from the feed and keeps placing bets

---

## 2020-08-28 11:16:44 - general channel

**Jono**

# login

trading.login_interactive()

# event_type_ids_list = [1]

event_ids = [29975922]





live_events_with_scores = trading.scores.list_available_events(event_ids=event_ids)

for live_event in live_events_with_scores:



    print(live_event.__dict__)

    # event_ids.append(live_event.event_id)





# score request (provide list / returns list)

scores = [http://trading.in|trading.in](http://trading.in|trading.in)_play_service.get_scores(event_ids=event_ids)

print(scores)

for score in scores:

    print(

        score,

        score.description,

        score.status,

        "%s-%s" % (score.score.home.score, score.score.away.score),

    )  # view resources or debug to see all values available

---

## 2020-08-28 08:41:30 - random channel

**liam**

really not sure on this, if you can try changing logging to debug there might be some more info (you will get a lot of logs!)

---

## 2020-08-27 18:10:53 - random channel

**mlpanda**

Hey [@U4H19D1D2](@U4H19D1D2), in the tennis example you provided ([https://github.com/liampauling/flumine/pull/264/files|example](https://github.com/liampauling/flumine/pull/264/files|example)) you hardcoded the market_id. When I try to treat it similarly to horse racing, i.e. automatically obtain all markets, Flumine doesn't seem to be able to find any tennis markets. I tried with country_codes=["IT"] first since there is an Italian challenger match, but also tried including a bunch like below:



```strategy = TestStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["2"],

        country_codes=['AX', 'AL', 'DZ', 'AS', 'AD', 'AO', 'AI', 'AQ', 'AG', 'AR', 'AM', 'AW', 'AU', 'AT', 'AZ', 'BS', 'BH', 'BD', 'BB', 'BY', 'BE', 'BZ', 'BJ', 'BM', 'BT', 'BO', 'BQ', 'BA', 'BW', 'BV', 'BR', 'IO', 'BN', 'BG', 'BF', 'BI', 'CV', 'KH', 'CM', 'CA', 'KY', 'CF', 'TD', 'CL', 'CN', 'CX', 'CC', 'CO', 'KM', 'CG', 'CD', 'CK', 'CR', 'CI', 'HR', 'CU', 'CW', 'CY', 'CZ', 'DK', 'DJ', 'DM', 'DO', 'EC', 'EG', 'SV', 'GQ', 'ER', 'EE', 'SZ', 'ET', 'FK', 'FO', 'FJ', 'FI', 'FR', 'GF', 'PF', 'TF', 'GA', 'GM', 'GE', 'DE', 'GH', 'GI', 'GR', 'GL', 'GD', 'GP', 'GU', 'GT', 'GG', 'GN', 'GW', 'GY', 'HT', 'HM', 'VA', 'HN', 'HK', 'HU', 'IS', 'IN', 'ID', 'IR', 'IQ', 'IE', 'IM', 'IL', 'IT', 'JM', 'JP', 'JE', 'JO', 'KZ', 'KE', 'KI', 'KP', 'KR', 'KW', 'KG', 'LA', 'LV', 'LB', 'LS', 'LR', 'LY', 'LI', 'LT', 'LU', 'MO', 'MG', 'MW', 'MY', 'MV', 'ML', 'MT', 'MH', 'MQ', 'MR', 'MU', 'YT', 'MX', 'FM', 'MD', 'MC', 'MN', 'ME', 'MS', 'MA', 'MZ', 'MM', 'NR', 'NP', 'NL', 'NC', 'NZ', 'NI', 'NE', 'NG', 'NU', 'NF', 'MK', 'MP', 'NO', 'OM', 'PK', 'PW', 'PS', 'PA', 'PG', 'PY', 'PE', 'PH', 'PN', 'PL', 'PT', 'PR', 'QA', 'RE', 'RO', 'RU', 'RW', 'BL', 'SH', 'KN', 'LC', 'MF', 'PM', 'VC', 'WS', 'SM', 'ST', 'SA', 'SN', 'RS', 'SC', 'SL', 'SG', 'SX', 'SK', 'SI', 'SB', 'SO', 'ZA', 'GS', 'SS', 'ES', 'LK', 'SD', 'SR', 'SJ', 'SE', 'CH', 'SY', 'TW', 'TJ', 'TZ', 'TH', 'TL', 'TG', 'TK', 'TO', 'TT', 'TN', 'TR', 'TM', 'TC', 'TV', 'UG', 'UA', 'AE', 'GB', 'US', 'UM', 'UY', 'UZ', 'VU', 'VE', 'VN', 'VG', 'VI', 'WF', 'EH', 'YE', 'ZM', 'ZW'],

        market_types=["WIN"],

    ),

    market_data_filter=streaming_market_data_filter(fields=["EX_LTP", "EX_ALL_OFFERS", "EX_MARKET_DEF", "EX_TRADED"]),

    max_order_exposure=10000,

    max_selection_exposure=105,

    context={"stake": 100},

)```

When I run this, `framework.markets._markets` is empty. Might be a stupid mistake on my side, but if I change the event_type_id to "7" then I do get a bunch of markets. Any idea why this is happening?



I haven't included your scores fixes in the example above as I don't see it helping given that it finds the event_id from the market_id - and if the market_id is never present it wouldn't matter.

---

## 2020-08-27 12:44:46 - issues channel

**Ruben**

Good morning, I was running the example marketrecorder.py, and it worked fine for ~20 minutes; then I started seeing "INVALID_SESSION_INFORMATION" errors in the log, that come from the "poll_market_catalogue()" method of the worker.py

---

## 2020-08-27 10:33:55 - random channel

**liam**

not released yet as it will be in `1.11.2` waiting for a fix from Lee but I can't remember what it was

---

## 2020-08-26 17:18:40 - general channel

**liam**

I like to break down like Mike with simple maths, either by modelling the market and finding value or simply placing orders where you think there might be value. The former requires some stats which gets boring very quickly and the latter requires a lot of trial and error and after the time analysis which I prefer 

---

## 2020-08-26 16:09:19 - strategies channel

**liam**

FYI fixed in this [https://github.com/liampauling/flumine/commit/11f67d2b3cebc927835252451306a5c53a89b3c9|commit](https://github.com/liampauling/flumine/commit/11f67d2b3cebc927835252451306a5c53a89b3c9|commit)

---

## 2020-08-26 16:02:01 - random channel

**liam**

So the above will fix it, just tempted to rewrite `process.py` so its not an issue (never liked it)

---

## 2020-08-26 15:55:02 - random channel

**Unknown**

This fixes it, the issue is caused by the fact there are no orders live in the market so `_process_current_orders` is never executed and the trade never completed, adding the following fixes it just not sure if that is the way I want to fix it

---

## 2020-08-26 15:52:18 - random channel

**liam**

I see the problem, not quite sure how to fix it at the moment

---

## 2020-08-26 12:01:43 - issues channel

**ricky**

All, I saw this happended in thinly traded market with total match around £90000, i was using bestAvailableToLay price value from "runner_book.ex.available_to_lay[0].price". My program continuous monitoring the traded volumn when the price variety, in this case the price change from 2.54 to 280.0 then back to 2.64, i didnt see traded volomn changed:joy:.

(its possible a bug in my program, but most case it was works ok)



Could anyone guide me how to get display price? Maybe i can compare the display price with virtual price.

---

## 2020-08-26 10:44:00 - random channel

**birchy**

[@U4H19D1D2](@U4H19D1D2) I've never spoken to anyone other than Neil for bug fixes/clarification, etc regarding the API. I know it's a 2 way street, but I couldn't ask for something I didn't know existed (ie the premium team) and tbh, I would have thought the onus is on THEM to be initiating those kind of conversations. My lifetime account is in the black, but probably not significantly enough to be noticed.

---

## 2020-08-25 13:12:09 - issues channel

**Lee**

started getting the following exception

```  File "/Users/leeunsworth/git/sports-trading/.venv/lib/python3.7/site-packages/flumine/markets/middleware.py", line 63, in __call__

    self._process_simulated_orders(market, market_analytics)

  File "/Users/leeunsworth/git/sports-trading/.venv/lib/python3.7/site-packages/flumine/markets/middleware.py", line 125, in _process_simulated_orders

    order.simulated(market.market_book, runner_analytics)

  File "/Users/leeunsworth/git/sports-trading/.venv/lib/python3.7/site-packages/flumine/backtest/simulated.py", line 49, in __call__

    market_book.publish_time_epoch, runner_analytics.traded

AttributeError: 'NoneType' object has no attribute 'traded'```

---

## 2020-08-25 12:37:15 - random channel

**liam**

`Yes, its due to the use of "Bangor-on-Dee" instead of "Bangor" and is causing mapping failures at our side.



The change was made to the venue name to fix a different feed related issue but we don't yet have dual mapping (for both Bangor &amp; Bangor-on-Dee) on the GPS API from our side so the data won't be coming through for todays Bangor meeting.  This will be addressed as part of the current ongoing GPS API v2 work and I expect this to be in place in time for the next Bangor-on-Dee meeting on the 30th September.`

---

## 2020-08-25 09:20:02 - general channel

**liam**

I havent had any errors

---

## 2020-08-25 09:17:42 - general channel

**Jonjonjon**

Is anyone having issues placing orders this morning? I have an insufficient funds error, trying to place £50 of liability on an account with over £1k of unused exposure.

---

## 2020-08-24 20:34:19 - random channel

**Newbie99**

```{"asctime": "2020-08-24 19:29:22,513", "levelname": "WARNING", "message": "Order has violated ORDER_VALIDATION and will not be placed", "control": "ORDER_VALIDATION", "error": "Order size is less than min bet size (2) or payout (10) for currency", "order": {"market_id": "1.172363533", "selection_id": 19763676, "handicap": 0, "id": "138175901625116463", "customer_order_ref": "27cfde50caeb3-138175901625116463", "bet_id": null, "trade": {"id": "1ce2672e-e640-11ea-9229-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138175901625116463"], "notes": "1.172363533,2020-08-24 19:30:00,2020-08-24 19:29:22.551000,OPEN,False,19763676,Hush Buffy,0,2.88,2.88,2.9,2.84,2.92,384.1600000000001,39.120000000000005,2.9232699537837674,2.9232699537837674,-0.00016599506431987516,-0.0018108429044144984,0,-0.43546624108134707,-1.0,-1.020314057737078,-1.0,-1.020314057737078,0.012721252976427583,2.82,2.9,2.82", "market_notes": "2.88,2.9,2.88"}, "order_type": {"order_type": "Limit", "price": 2.9, "size": 0.73, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Violation", "status_log": "Pending, Violation"}}

{"asctime": "2020-08-24 19:29:22,515", "levelname": "WARNING", "message": "Empty package, not executing", "id": "1ce28e3d-e640-11ea-905c-2016d8944b85", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x000001BC1E36D100&gt;", "market_id": "1.172363533", "orders": ["138175901625116463"], "package_type": "Place", "customer_strategy_ref": "BlueOcean", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}```

---

## 2020-08-24 16:35:43 - random channel

**liam**

can you put the debugger here [https://github.com/liampauling/flumine/blob/master/flumine/order/process.py#L69](https://github.com/liampauling/flumine/blob/master/flumine/order/process.py#L69)

---

## 2020-08-24 16:25:35 - random channel

**Newbie99**

[@U4H19D1D2](@U4H19D1D2), I haven't been able to replicate the issue with pending orders from the other day, but came across this today and wanted to check the correct way it's intended to be handled:



```{"asctime": "2020-08-24 15:11:49,150", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.172319685", "selection_id": 26578374, "handicap": 0, "id": "138175747090349752", "customer_order_ref": "27cfde50caeb3-138175747090349752", "bet_id": null, "trade": {"id": "21e4feb7-e61c-11ea-8071-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138175747090349752"], "notes": "1.172319685,2020-08-24 15:15:00,2020-08-24 15:11:48.783000,OPEN,False,26578374,Phoenix Strike,0,32,32,34,30,36,1116.3899999999999,4.0,34.20734773394412,34.20734773394412,-0.00017030046190238602,-0.015229531148119538,0,-0.34410707742395563,-1.0,-0.9994686305661997,-1.0,-0.9994686305661997,0.04510370240413563,32,36,32", "market_notes": "32,34,32"}, "order_type": {"order_type": "Limit", "price": 32, "size": 2, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Violation", "status_log": "Pending, Violation"}

{"asctime": "2020-08-24 15:11:49,151", "levelname": "WARNING", "message": "Order has violated STRATEGY_EXPOSURE and will not be placed", "control": "STRATEGY_EXPOSURE", "error": "Order exposure (62) is greater than strategy.max_order_strategy (20)", "order": {"market_id": "1.172319685", "selection_id": 26578374, "handicap": 0, "id": "138175747090349752", "customer_order_ref": "27cfde50caeb3-138175747090349752", "bet_id": null, "trade": {"id": "21e4feb7-e61c-11ea-8071-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138175747090349752"], "notes": "1.172319685,2020-08-24 15:15:00,2020-08-24 15:11:48.783000,OPEN,False,26578374,Phoenix Strike,0,32,32,34,30,36,1116.3899999999999,4.0,34.20734773394412,34.20734773394412,-0.00017030046190238602,-0.015229531148119538,0,-0.34410707742395563,-1.0,-0.9994686305661997,-1.0,-0.9994686305661997,0.04510370240413563,32,36,32", "market_notes": "32,34,32"}, "order_type": {"order_type": "Limit", "price": 32, "size": 2, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Violation", "status_log": "Pending, Violation"}}```

So that order failed validation, which makes sense, all looks correct...however,

```runner_data = strategy.get_runner_context(market_id=market_book.market_id,

    selection_id=runner['selection_id'],

            handicap=runner['handicap'])

live_trade_count = runner_data.live_trade_count```

live_trade_count returned 1 until the close.



If an order fails validation, does the live_trade_count need to be manually adjusted and is that intentional?

---

## 2020-08-24 10:10:38 - general channel

**ricky**

[@UUCD6P13J](@UUCD6P13J) Instead of use market_id i changed to country code (otherwise i got error SUBSCRIPTION_LIMIT_EXCEEDED above 200), but nothing change.

I still can not see "OVER_UNDER_25" data when i print everything from market_books

---

## 2020-08-21 17:33:42 - general channel

**Lee**

what error message do you get?

---

## 2020-08-21 13:22:40 - general channel

**D C**

I've used it for close to 20 years now and I would say that you can advertise it as type safe but any language with an operation labelled reinterpret_cast (never mind having to support the C style cast) just can't be. Maybe in the hands of the perfect programmer who knows every line of the ever changing language standards AND never makes an error you could consider it type safe, but in practical terms it is not. For sure it is an improvement on C though I agree there but the fact that is has to support C leads to issues. You can access private members directly from a pointer to object - and this is directly attributable to having to support C language features. I guess we won't end up agreeing on this - it's just my opinion on writing my own bad code and reviewing other people's bad code over the years.

---

## 2020-08-20 19:18:16 - general channel

**john walsh**

All I am happy about is that it was not a coding error by me. Onward and upward.  Plenty of other things work to keep me happy.

---

## 2020-08-19 20:38:51 - issues channel

**JojoBeans**

I've tried that and I seem to be further along but now I'm getting betfairlightweight.exceptions.ListenerError: connection_id: 107-190820193544-1162785, data: {"op":"status","id":2,"statusCode":"FAILURE","errorCode":"NOT_AUTHORIZED","errorMessage":"AppKey is not configured for service","connectionClosed":true,"connectionId":"107-190820193544-1162785"}

Thanks for all the help!

---

## 2020-08-19 19:25:36 - issues channel

**JojoBeans**

The output looks like

```---------------------------------------------------------------------------

SocketError                               Traceback (most recent call last)

&lt;ipython-input-48-10c95a06d625&gt; in &lt;module&gt;

     21 )

     22 

---&gt; 23 betfair_socket.start()  # blocking



~/anaconda3/envs/py36_new/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py in start(self)

     57             self._connect()

     58             self.authenticate()

---&gt; 59         self._read_loop()

     60 

     61     def stop(self) -&gt; None:



~/anaconda3/envs/py36_new/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py in _read_loop(self)

    200         """

    201         while self._running:

--&gt; 202             received_data_raw = self._receive_all()

    203             if self._running:

    204                 self.receive_count += 1



~/anaconda3/envs/py36_new/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py in _receive_all(self)

    232                     raise SocketError(

    233                         "[Connect: %s]: Connection closed by server"

--&gt; 234                         % (self._unique_id,)

    235                     )

    236                 else:



SocketError: [Connect: 2]: Connection closed by server```



---

## 2020-08-19 15:22:55 - general channel

**Twatter**

Fascinating area of research.. I wonder how accurate a set of cameras could be at tracking the horses - if there was one or two fixed cameras at certain positions to track horses and instaed of facial recognition perform pattern+colour recognition on the jockeys.. although I'm guessing the delay of processing the feed would be a bit pointless..

---

## 2020-08-19 14:42:24 - general channel

**Peter**

True, But I think Misha's point is addressing the accuracy of GPS as a technology in general. Using the signals from multiple satellites to triangulate the position of a moving object in real-time necessarily comes with a margin of error that tends to be glossed over a bit in the marketing materials of those selling the systems.

---

## 2020-08-19 12:59:59 - strategies channel

**JC**

Just doing some backtesting on a strategy using flumine and seem to have run into an order violation error related to MAX_ORDER_COUNT, as the total number of orders for this hour has exceeded 1016. I can't imagine my strategy would reach this number in an hour in real time, just wondering if this limit should be disabled for backtesting, and what the safest way to disable it would be? Cheers

---

## 2020-08-19 08:19:08 - random channel

**liam**

```{"asctime": "2020-08-19 07:16:22,242", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.172171556", "selection_id": 8329902, "handicap": 0, "id": "138171141822420430", "customer_order_ref": "27cfde50caeb3-138171141822420430", "bet_id": null, "trade": {"id": "e28912a4-e1eb-11ea-86ee-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138171141822420430"], "notes": "", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 10, "size": 2, "persistence_type": "MARKET_ON_CLOSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}

{"asctime": "2020-08-19 07:16:22,242", "levelname": "INFO", "message": "1 order packages created", "order_packages": [{"id": "e28930c2-e1eb-11ea-86ee-a0999b054753", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x104826b20&gt;", "market_id": "1.172171556", "orders": ["138171141822420430"], "package_type": "Place", "customer_strategy_ref": "Liams-MBP", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}]}

{"asctime": "2020-08-19 07:16:22,243", "levelname": "INFO", "message": "New requests.Session created", "sessions_created": 1, "session": "&lt;requests.sessions.Session object at 0x10485e850&gt;", "session_time_created": 1597821382.243398, "session_time_returned": 1597821382.2433999}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "execute_place", "trading_function": "place", "elapsed_time": 0.24187803268432617, "response": {"customerRef": "e28930c2e1eb11ea86eea0999b054753", "status": "SUCCESS", "marketId": "1.172171556", "instructionReports": [{"status": "SUCCESS", "instruction": {"selectionId": 8329902, "handicap": 0.0, "limitOrder": {"size": 2.0, "price": 10.0, "persistenceType": "MARKET_ON_CLOSE"}, "customerOrderRef": "27cfde50caeb3-138171141822420430", "orderType": "LIMIT", "side": "BACK"}, "betId": "208759879486", "placedDate": "2020-08-19T07:16:22.000Z", "averagePriceMatched": 0.0, "sizeMatched": 0.0, "orderStatus": "EXECUTABLE"}]}, "order_package": {"id": "e28930c2-e1eb-11ea-86ee-a0999b054753", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x104826b20&gt;", "market_id": "1.172171556", "orders": ["138171141822420430"], "package_type": "Place", "customer_strategy_ref": "Liams-MBP", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "Trade status update: Pending", "id": "e28912a4-e1eb-11ea-86ee-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.PENDING", "orders": ["138171141822420430"], "notes": "", "market_notes": "3.05,3.15,3.1"}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "Order Place: SUCCESS", "bet_id": null, "order_id": "138171141822420430", "status": "SUCCESS", "error_code": null}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.172171556", "selection_id": 8329902, "handicap": 0, "id": "138171141822420430", "customer_order_ref": "27cfde50caeb3-138171141822420430", "bet_id": "208759879486", "trade": {"id": "e28912a4-e1eb-11ea-86ee-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.PENDING", "orders": ["138171141822420430"], "notes": "", "market_notes": "3.05,3.15,3.1"}, "order_type": {"order_type": "Limit", "price": 10, "size": 2, "persistence_type": "MARKET_ON_CLOSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Executable", "status_log": "Pending, Executable"}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "Trade status update: Live", "id": "e28912a4-e1eb-11ea-86ee-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138171141822420430"], "notes": "", "market_notes": "3.05,3.15,3.1"}```

---

## 2020-08-18 22:58:25 - issues channel

**JojoBeans**

I keep getting the following error trying to run the example code

```SocketError: [Connect: 2]: Connection closed by server```

Any ideas on what could be causing it?

---

## 2020-08-18 20:43:12 - random channel

**Newbie99**

hmm....no error interestingly, I get the pending logs then...nothing else (I have publish time ticking along so can see its still going)

---

## 2020-08-18 20:33:56 - random channel

**Newbie99**

```{"asctime": "2020-08-18 19:33:11,458", "levelname": "INFO", "message": "New requests.Session created", "sessions_created": 1}

{"asctime": "2020-08-18 19:33:11,459", "levelname": "INFO", "message": "Stopped OrderStream 1001"}

{"asctime": "2020-08-18 19:33:11,510", "levelname": "INFO", "message": "Stopped output_thread (OrderStream 1001)"}

{"asctime": "2020-08-18 19:33:11,511", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

Traceback (most recent call last):

{"asctime": "2020-08-18 19:33:11,512", "levelname": "INFO", "message": "Stopped MarketStream 2001"}

  File "D:\Python38\lib\site-packages\flumine\flumine.py", line 35, in run

    self._process_order_package(event)

  File "D:\Python38\lib\site-packages\flumine\baseflumine.py", line 155, in _process_order_package

    order_package.client.execution.handler(order_package)

  File "D:\Python38\lib\site-packages\flumine\execution\baseexecution.py", line 42, in handler

    self._thread_pool.submit(func, order_package, http_session)

AttributeError: 'BetfairExecution' object has no attribute '_thread_pool'



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:/Python37/webpages/flumine_examples/example.py", line 285, in &lt;module&gt;

    framework.run()

  File "D:\Python38\lib\site-packages\flumine\flumine.py", line 53, in run

    logger.error("Unknown item in handler_queue: %s" % str(event))

  File "D:\Python38\lib\site-packages\flumine\baseflumine.py", line 348, in __exit__

    self.simulated_execution.shutdown()

  File "D:\Python38\lib\site-packages\flumine\execution\baseexecution.py", line 117, in shutdown

    self._thread_pool.shutdown(wait=True)

AttributeError: 'SimulatedExecution' object has no attribute '_thread_pool'```

---

## 2020-08-18 20:25:28 - random channel

**liam**

Remove the use of the thread pool in execution.baseexecution.py and call the function directly, you should get an error

---

## 2020-08-18 20:14:11 - random channel

**liam**

I think there is an error in the thread pool that isn’t being caught [https://github.com/liampauling/flumine/issues/256|https://github.com/liampauling/flumine/issues/256](https://github.com/liampauling/flumine/issues/256|https://github.com/liampauling/flumine/issues/256)

---

## 2020-08-18 00:33:56 - issues channel

**qwerty.nat**

Just did a pip install flumine. filled in my login details in the example market recorder application to test all is ok.

`trading = betfairlightweight.APIClient(username="user",password="pass",app_key="slkfj", certs="/path/to/cert",lightweight=True)`

It fails after running for about 30 seconds,

`Traceback (most recent call last):`

  `File "marketrecorder.py", line 36, in &lt;module&gt;`

    `framework.run()`

  `File "/home/nathan/.local/lib/python3.8/site-packages/flumine/flumine.py", line 23, in run`

    `self._process_market_catalogues(event)`

  `File "/home/nathan/.local/lib/python3.8/site-packages/flumine/baseflumine.py", line 200, in _process_market_catalogues`

    `market = self.markets.markets.get(market_catalogue.market_id)`

`AttributeError: 'dict' object has no attribute 'market_id'`

If i set lightweight to False in the APIClient it all works without any error.

---

## 2020-08-17 13:51:10 - issues channel

**liam**

Now [https://github.com/liampauling/flumine/commit/6b036f9a9e2bd92f927c739c6703ead90049f7a2|fixed](https://github.com/liampauling/flumine/commit/6b036f9a9e2bd92f927c739c6703ead90049f7a2|fixed) bug in the integration test meant it went unnoticed

---

## 2020-08-17 13:43:42 - general channel

**liam**

This works for me

```import smart_open

import zipfile

from io import BytesIO



bucket_name = 'flumine'



for key, content in smart_open.s3_iter_bucket(bucket_name, prefix="marketdata/streaming/7", workers=0):

    print(key)

    with zipfile.ZipFile(BytesIO(content)) as zf:

        for contained_file in zf.namelist():

            with zf.open(contained_file) as f:

                print(f.readlines())

    exit()```

---

## 2020-08-14 19:12:38 - issues channel

**Twatter**

[@U0154JA98TH](@U0154JA98TH) Try using Jsonlint to verify it... it doesn't like it since:

```Error: Parse error on line 6:

...nstructions": [{			'selectionId': '3789

----------------------^

Expecting 'STRING', '}', got 'undefined'```



---

## 2020-08-14 17:59:39 - issues channel

**mlpanda**

What is the error message? From looking at it, it looks fine - except I'm not sure whether the use of ' instead of " could cause an error. How about that you try with " everywhere

---

## 2020-08-13 12:27:58 - issues channel

**Mo**

That would fix this problem but I guarantee you there are situations where other required fields are missing

---

## 2020-08-13 12:24:03 - issues channel

**Remi**

Today I am getting the following error:

```betfairlightweight/resources/accountresources.py", line 88, in __init__

    self.legacy_data = LegacyData(**legacyData)

TypeError: __init__() missing 1 required positional argument: 'marketName'```

---

## 2020-08-12 12:54:08 - issues channel

**liam**

Can you see if `_process__sp` is being called via the debugger?

---

## 2020-08-12 12:40:05 - issues channel

**Lee**

I think i might not be understanding the MarketOnCloseOrder correctly. I'm trying to take SP just before going inplay but can't seem to get any money matched (flumine backtesting). I've removed my trigger and try to place an order on all runners and still get zero matched.

I've also set my strategy exposure high and not getting any voilation errors on the orders in the logs.

I'm creating an order using the following

```order = trade.create_order(

    side="BACK", order_type=MarketOnCloseOrder(liability=20)

)```

Any idea where i'm going wrong or if it's just a misunderstanding



here's a log too

```{"asctime": "2020-08-12 11:32:33,047", "levelname": "INFO", "message": "Order status update: Execution complete", "market_id": "1.170576255", "selection_id": 19436243, "handicap": 0, "id": "138165247530344110", "customer_order_ref": "890b98c67ce74-138165247530344110", "bet_id": "100000000007", "trade": {"id": "83599e5e-dc8f-11ea-80ef-d45d6453ef52", "strategy": "xxxxxxx", "status": "TradeStatus.LIVE", "orders": ["138165247530344110"], "notes": "", "market_notes": "15.5,16,15.5"}, "order_type": {"order_type": "Market on close", "liability": 20}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Execution complete", "status_log": "Pending, Executable, Execution complete"}```

---

## 2020-08-10 17:49:07 - general channel

**PeterLe**

Thanks fixed it now (I replaced from datetime import datetime with :

```import datetime```

much appreciated

---

## 2020-08-10 17:44:16 - general channel

**PeterLe**

Thanks for that, I also had to add in :

```from datetime import datetime```

but I get this error: market_start_time={"to": "{0}T23:45:00Z".format(datetime.date.today())}

AttributeError: 'method_descriptor' object has no attribute 'today'

---

## 2020-08-09 10:35:14 - issues channel

**liam**

Ah bollocks, that fixes it for backtesting but not for paper trading 

---

## 2020-08-09 10:34:09 - issues channel

**liam**

Fixed in 1.10.5 in this commit [https://github.com/liampauling/flumine/commit/37ca7312707e7a66ac5776126354dee13829995b|https://github.com/liampauling/flumine/commit/37ca7312707e7a66ac5776126354dee13829995b](https://github.com/liampauling/flumine/commit/37ca7312707e7a66ac5776126354dee13829995b|https://github.com/liampauling/flumine/commit/37ca7312707e7a66ac5776126354dee13829995b)

---

## 2020-08-09 10:32:49 - issues channel

**liam**

This was a bug I thought I fixed, which version you using?

---

## 2020-08-09 00:09:14 - strategies channel

**ricky**

# create queue

output_queue = None



market_filter = streaming_market_filter(

    event_type_ids=["1"], market_types=["MATCH_ODDS"], market_ids=["1.171324077"]

)

market_data_filter = streaming_market_data_filter(

    fields=["EX_BEST_OFFERS", "EX_MARKET_DEF", "EX_TRADED"], ladder_levels=10

)



# create stream listener

listener = betfairlightweight.StreamListener(output_queue=output_queue)



# create stream

stream = trading.streaming.create_stream(listener=listener)



market_books = listener.snap(

    market_ids=["1.171324077"]

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# create streaming object

streaming = Streaming(trading, market_filter, market_data_filter)



# start streaming (runs in new thread and handles any errors)

streaming.start()



...

while True:

    market_books = streaming.output_queue.get()

    print(market_books)

---

## 2020-08-08 15:17:26 - issues channel

**Ruben**

anyone ever got a "NO_SESSION" error when calling keep_alive()? after several successful keep_alive() calls

---

## 2020-08-08 10:35:30 - general channel

**john walsh**

I am getting this message for each entry "[&lt;betfairlightweight.resources.bettingresources.PriceSize object at 0x0B4D7A30&gt;]".  Does anybody know how to fix it?

---

## 2020-08-07 18:47:41 - issues channel

**mlpanda**

You just saved me a stressful weekend of debugging wrong things :tada:

---

## 2020-08-07 17:58:52 - issues channel

**mlpanda**

Hey, has anyone had issues with getting last_price_traded/total_matched through Flumine?

I am using the fields ["EX_ALL_OFFERS", "EX_MARKET_DEF", "EX_TRADED"] which should be sufficient, so I think the issue is related to login. Note that I do get the market_id, publish_time and selection_id.



For logging in, I have tried both interactive and non-interactive login. If I stop the run and try e.g. client._get_account_details() I do get an "INVALID_APP_KEY" error, however if I manually try to login with trading.login() it returns "SUCCESS".



I am using the app_key from [https://docs.developer.betfair.com/visualisers/api-ng-account-operations/](https://docs.developer.betfair.com/visualisers/api-ng-account-operations/) which historically has worked fine. I did notice that trading.login() returns a session_token which is different from the one in the link above. Any suggestions would be super helpful, thanks.

---

## 2020-08-06 22:05:55 - strategies channel

**Ruben**

yes, that also, thanks for your tips, i'll start the debugger

---

## 2020-08-06 22:02:52 - strategies channel

**Mo**

This sounds more like a bug than a poor model

---

## 2020-08-06 20:19:00 - issues channel

**liam**

I think I might have to do that with bflw, how did you get it to print so much info about the error? MarketCatalogue race market :+1:

---

## 2020-08-06 19:42:56 - issues channel

**Mo**

Understandable. Well if someone can find one then I can take a look at trying to fix it

---

## 2020-08-06 17:59:51 - issues channel

**Josh**

[@U4H19D1D2](@U4H19D1D2) Are you still seeing segfaults from ujson? I noticed your comment on a github issue on the ujson repo back on June 17th. I started to run into the same thing on v3.0.0. Not sure if 3.1.0 fixes it or maybe you've just gone back to the stdlib json module.

---

## 2020-08-06 14:17:47 - strategies channel

**D C**

That response you got was interesting though. Watching the render replays back over hundreds of races now I have seen that kind of vector offset type error. Interesting that they associate it with an old device. I would love to know more about their hardware and how it works internally.

---

## 2020-08-06 14:10:57 - strategies channel

**D C**

To me looked like a constant offset error like calibration problem. Not compared with the race replay yet though

---

## 2020-08-05 22:27:48 - general channel

**birchy**

What's the best way to achieve interprocess control between bots in python? I basically have a strategy that locks into one market until closure and then moves on to the next available market. If I run multiple instances of the same bot, what's the easiest way to avoid them locking onto the same market? I currently pickle the market ids and check the pickle file to confirm that no other bots are already working on the market but it's a bit clunky and I'd like to use something less error prone.

---

## 2020-08-04 19:18:58 - general channel

**Oliver Varney**

okay, hmm what function/ whereabouts in the code should I look for debugging?

---

## 2020-08-04 08:24:16 - general channel

**liam**

can you turn debug logs on and see if any logout requests are being made?

---

## 2020-08-04 08:14:58 - general channel

**Oliver Varney**

Error: {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang21b-prd-05190827-00895cdc7c', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0003', 'data': {'APINGException': {'requestUUID': 'ie2-ang21b-prd-05190827-00895cdc7c', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}

---

## 2020-08-04 08:13:33 - general channel

**Oliver Varney**

I did just update my package and had to make some code edits elsewhere but im getting an exception in the poll_market_catalogue

---

## 2020-08-03 11:49:19 - general channel

**Lee**

slightly odd, 1.10.2 was on pypi 10mins ago

```$ pip install flumine==1.10.2

ERROR: Could not find a version that satisfies the requirement flumine==1.10.2 (from versions: 0.1.1, 0.1.2, 0.2.0, 0.2.2, 0.2.3, 0.3.0, 0.5.0b0, 0.5.1b0, 0.5.2b0, 0.5.3b0, 0.6.0, 0.6.1, 0.7.0, 0.8.0, 0.8.1, 0.9.0, 1.0.0b1, 1.0.0b2, 1.0.0b3, 1.0.0b4, 1.0.0b5, 1.0.0b6, 1.0.0b7, 1.0.0, 1.1.0, 1.2.0, 1.3.0, 1.4.0, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.5.5, 1.5.6, 1.5.7, 1.6.0, 1.6.1, 1.6.2, 1.6.3, 1.6.4, 1.6.5, 1.6.6, 1.6.7, 1.6.8, 1.7.0, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0, 1.10.1)```

---

## 2020-08-02 12:29:40 - strategies channel

**Michael**

I think it depends how you do it. Your bets have an effect on the market and if your two strategies are similar then they'll be competing with each-other, so if you're effectively running two bots simultaneously then you'll confuse things (at best). Depending on how you're operating it'd be better to make sure that only one version is executing at a time. If you're trying to optimise prices with a fixed trigger then that's easy and you can do a very simple a v b, if you're trying to optimise a trigger then you can't. In that case I'd either run them on separate markets or (more often) just measure the relative performance of each strategy looking deeply at the various metrics and comparing both data sets to the hypothetical performance of a fixed strategy that shows how promising the markets were but doesn't place any bets at all.

---

## 2020-08-01 19:07:44 - random channel

**Lee**

This works fine for me, but doesn’t update if i go back to an existing function with the params already filled out, will only update when i delete a param. Happy to share any settings if that may help.

But I have had quite a few other bugs over the last month of two.  The main one now being moving code around messes up the indentation.

---

## 2020-08-01 09:43:06 - random channel

**Disco**

I have this version too, will check it later. Since updating, I've been having problems with color scheme applying very slowly, and real time code check/suggestions being slow too (while cpu load is normal. Didn't have it in preview versions, seems like a bug)

---

## 2020-08-01 09:13:10 - random channel

**Mo**

Need some help from any PyCharm professional owners...



I have a problem with the documentation popup window feature when typing in the Python console. I start typing a function and the documentation appears. Great. Now I open brackets to start specifying arguments and the documentation disappears - the documentation window says "No documentation found.". At exactly the time when I want to see it so I know what the arguments are and what they do. There are various settings involved such as the delay before the popup appears, whether to show the documentation on mouse move, whether to auto-update from source etc.



Does anyone have any idea what I'm talking about and how to fix it?!

---

## 2020-08-01 00:17:44 - general channel

**birchy**

True to my word...

I now have GitHub setup with a private repo. As you suggested, doing minor edits in the browser is fine for those occasional quick fixes. Regarding deployment on vps, I would prefer to only get the latest source when a bot is (re)started. The VPS is purely a deployment machine, so all edits will be done externally.

So I created a SSH key and loaded it into GitHub. I then ran a git clone from the VPS to download my source code ready for deployment. Bot deployed, slippers fitted, scrumpy poured. All good so far...

Following a new commit, I decide to restart a bot. Git clone fails due to folder existing already, so I delete the folder, git clone and start the bot.

It's all working as expected, however the git clone over ssh feels a bit hacky, particularly having to delete the local folder in order to allow a clone. Also, having to start ssh-agent service and then adding the key in order to connect to GitHub feels like a workaround given that I normally create a SSH config file and simply do "ssh lightsail" to gain access to the server.



Is there a nicer way of doing this?

---

## 2020-07-30 22:27:12 - issues channel

**mlpanda**

Hey, has anyone had the issue of receiving an empty list when using the historical data example in betfair lightweight: [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py)



In `my_data` I have the following data purchased:

`{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-05-01T00:00:00', 'purchaseItemId': 48406}`



But when I use the following function:

```# get file list

file_list = trading.historic.get_file_list(

    "Horse Racing",

    "Advanced Plan",

    from_day=1,

    from_month=5,

    from_year=2020,

    to_day=31,

    to_month=5,

    to_year=2020,

    market_types_collection=["WIN", "PLACE"],

    countries_collection=["GB", "IE"],

    file_type_collection=["M"],

)

print(file_list)```

I get an empty list in `file_list`. If I try to expand the dates to e.g. `to_month=6` I get an error (probably because I haven't purchased data for June), but I'm puzzled why I get an empty list for the above example.

---

## 2020-07-30 12:43:24 - issues channel

**Unknown**

I think I have been looking at this too long, can someone spot my error? it is something to do with the marketStartTime filter parameter - Resolved thanks -



I forgot the T and Z in the datetime format i.e ("%Y-%m-%d*T*%H:%M:%S*Z*")

---

## 2020-07-29 16:39:11 - general channel

**Oliver Varney**

Is the logging in flumine just there so people can set the level, debug and print to the console. Am I right in assuming that the expectation is to define output files, levels, format etcs ?

---

## 2020-07-29 09:51:17 - issues channel

**Newbie99**

I couldn't find a 'RELATED_ACTION_FAILED' error code in the docs

---

## 2020-07-29 09:50:48 - issues channel

**Newbie99**

The error just suggests the instruction somehow isn't populated for the report

---

## 2020-07-29 09:50:18 - issues channel

**Newbie99**

```

Replace Error: RELATED_ACTION_FAILED

Exception in thread Thread-1:

Traceback (most recent call last):

  File "/usr/lib64/python3.7/threading.py", line 926, in _bootstrap_inner

    self.run()

  File "/usr/lib64/python3.7/threading.py", line 870, in run

    self._target(*self._args, **self._kwargs)

  File "racing.py", line 568, in combined_queue

    replaced_orders_report = rf.replace_orders(market_id, replace_list, market_info, trading, filters)

  File "/home/ec2-user/trading/env/projects/racing_functions.py", line 1941, in replace_orders

    'selection_id': place_instruction_report.instruction.selection_id,

AttributeError: 'NoneType' object has no attribute 'selection_id'```

---

## 2020-07-29 09:50:12 - issues channel

**Newbie99**

Has anyone ever seen this?



When replacing I get this error (very occasionally):

---

## 2020-07-29 09:47:58 - issues channel

**L**

I have been getting these errors intermittently as well and have been ignoring them

---

## 2020-07-29 08:18:59 - issues channel

**Lee**

Can i ignore these occasional SocketErrors in flumine? `SocketError: [Connect: 2002]: Socket [Errno 104] Connection reset by peer"`

---

## 2020-07-28 15:46:57 - issues channel

**Aaron**

uninstall and reinstall requests on your im assuming ubuntu EC2 instance. Few threads on SO indicate this may be the fix

---

## 2020-07-28 15:26:27 - issues channel

**mlpanda**

Any suggestions why this code snippet



```market_catalogues = trading.betting.list_market_catalogue(

    filter=filters.market_filter(

        event_type_ids=["7"],  # filter on just horse racing

        market_countries=["GB"],  # filter on just GB countries

        market_type_codes=["WIN"],  # filter on just WIN market types

    ),

    market_projection=[

        "MARKET_START_TIME",

        "RUNNER_DESCRIPTION",

        "EVENT",

    ],  # runner description required

    max_results=100,

)```

gives me the error



`Exception: Timeout value connect was (3.05, 16), but it must be an int or float.`



It's rather strange as it works on my local mac, but when I run it on an EC2 instance in AWS (location: London) it fails with the above message. I'm also located in London locally, so seems odds.



Any suggestions would be very much appreciated :)

---

## 2020-07-27 21:42:21 - issues channel

**Jonjonjon**

I get this issue running the tests for Flumine:



  `File "/home/jon/PycharmProjects/flumine/flumine/streams/historicalstream.py", line 70, in snap`

    `cache.create_resource(self.unique_id, None, self._lightweight)`

`TypeError: create_resource() takes 3 positional arguments but 4 were given`



I have master branches from betfairlightweight and flumine on my computer.



Do I need to checkout specific versions to make it work?

---

## 2020-07-27 11:15:18 - general channel

**Oliver Varney**

so if error_handler gets called on every new raw data, exposes  status here shouldnt add any overhead?

---

## 2020-07-27 11:11:51 - general channel

**liam**

```_error_handler```

---

## 2020-07-27 10:50:51 - general channel

**liam**

yes the order status would stay in a pending state on a http error, flumine will try and make the request again (max 3 times) before giving up

---

## 2020-07-27 09:01:44 - issues channel

**liam**

[https://github.com/liampauling/betfair/pull/323|2.7.0](https://github.com/liampauling/betfair/pull/323|2.7.0) ready to go today, anything else need to be fixed?

---

## 2020-07-27 08:48:29 - issues channel

**liam**

here is the fix, see commit message for details [https://github.com/liampauling/betfair/pull/322/commits/4e173b4b22e01f18dbf8e7703de9b6c702950152](https://github.com/liampauling/betfair/pull/322/commits/4e173b4b22e01f18dbf8e7703de9b6c702950152)

---

## 2020-07-26 23:23:47 - general channel

**birchy**

I work as a PLC programmer in my full time job and we use Dropbox for everything, so I'm familiar with using it, which is why I replicated a similar setup with my own VPC.

I totally agree that I need to update my way of thinking and start using a proper version control system as I now have a lot more projects. For my needs, a centralised system seems to be the best fit.

All I need to do now is work out the easiest way to:

a) get Pycharm to automatically sync to subversion or similar when using my main dev machine

b) do simple edits/bug fixes from an Android device with automatic syncing

c) pull the code into my VPS and launch the bot. I normally use a script for this as I compile to pyc, copy to ~/ and launch, so I could potentially use that to pull the latest version before launching

d) be able to carry out minor edits from within the VPS when logged in via SSH

Does that sound feasible, or am I still pissing in the wind?

---

## 2020-07-26 13:24:00 - strategies channel

**Misha**

I would also suspect that streaming updates aren't within a 1 ms margin of error either, so trying to shave a ms or two would be pointless

---

## 2020-07-26 13:18:54 - strategies channel

**Misha**

They seem to run some sort of software to ensure the ping time doesn't get below about 10 ms, which you can get either from London or Dublin. And 1 ms is within the margin of error

---

## 2020-07-25 16:51:28 - general channel

**Jorge**

I'm just not a big fan of threading in Python. My main concern is error handling in the daemon thread

---

## 2020-07-25 12:15:49 - general channel

**Michael**

I don't think betfair markets have changed in any fundamental way in that time. Liquidity waxes and wains on this or that sport but basic market mechanics seem fixed to me.

---

## 2020-07-25 10:49:14 - issues channel

**Mark**

Happy weekend chaps!

I've been using the examplestreaminghistorical.py from BFLW to run through some of the historical data files offered by Betfair recently. It's been working great.. except when I run through a Greyhound file where a reserve runner replaces the original. This seems to happen at least once per meeting and the whole thing chokes.



I haven't touched anything except the location of each data file (obviously!) According to the Traceback, it's tripping up over a number of processes and I haven't a clue where to start.



I've updated BFLW to 2.6.0 and I'm using the out-of-the-box examplestreaminghistorical.py without modification.



Has anyone else come across the same thing and can point me in the right direction? Cheers!



```Traceback (most recent call last):

  File "G:/python/scratchpad/examplestreaminghistorical.py", line 34, in &lt;module&gt;

    for market_books in gen():

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 326, in _read_loop

    if self.listener.on_data(update) is False:

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\listener.py", line 127, in on_data

    self._on_change_message(data, unique_id)

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\listener.py", line 167, in _on_change_message

    self.stream.on_update(data)

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\stream.py", line 59, in on_update

    self._process(data[self._lookup], publish_time)

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\stream.py", line 152, in _process

    market_book_cache.create_resource(

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\cache.py", line 218, in create_resource

    data = self.serialise

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\cache.py", line 267, in serialise

    "runners": [

  File "C:\Users\Mark\AppData\Local\Programs\Python\Python38-32\lib\site-packages\betfairlightweight\streaming\cache.py", line 269, in &lt;listcomp&gt;

    self.market_definition_runner_dict[

KeyError: (27395886, 0)



Process finished with exit code 1```

---

## 2020-07-24 14:49:08 - issues channel

**Jon**

don't get how there can be an index error when just doing a for ... in

---

## 2020-07-24 14:48:33 - issues channel

**Jon**

```&lt;ipython-input-241-74dcdf18ad7c&gt; in &lt;listcomp&gt;(.0)

      8                         if runner_book.ex.available_to_back[0].price

      9                         else 1.01

---&gt; 10                         for runner_book

     11                         in runner_books]

     12     best_back_sizes = [runner_book.ex.available_to_back[0].size



IndexError: list index out of range```



---

## 2020-07-24 14:47:51 - issues channel

**Jon**

i get

```---------------------------------------------------------------------------

KeyError                                  Traceback (most recent call last)

&lt;ipython-input-252-bb440a3eeded&gt; in &lt;module&gt;

     10 )

     11 

---&gt; 12 market_book_to_data_frame(market_books[0])



&lt;ipython-input-235-a1a850e150a8&gt; in market_book_to_data_frame(market_book)

     15             'size': price_size['size']

     16         }

---&gt; 17         for runner in market_book['runners']

     18         for side in ['Back', 'Lay']

     19         for depth, price_size in enumerate(runner.get('ex', {}).get(f'availableTo{side}', []))



C:\ProgramData\Anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy)

    467         elif isinstance(data, abc.Iterable) and not isinstance(data, (str, bytes)):

    468             if not isinstance(data, (abc.Sequence, ExtensionArray)):

--&gt; 469                 data = list(data)

    470             if len(data) &gt; 0:

    471                 if is_list_like(data[0]) and getattr(data[0], "ndim", 1) == 1:



&lt;ipython-input-235-a1a850e150a8&gt; in &lt;genexpr&gt;(.0)

     17         for runner in market_book['runners']

     18         for side in ['Back', 'Lay']

---&gt; 19         for depth, price_size in enumerate(runner.get('ex', {}).get(f'availableTo{side}', []))

     20     )



KeyError: 'publishTime'```



---

## 2020-07-24 14:42:26 - issues channel

**Jon**

thanks. okay now get no error but just blank output

---

## 2020-07-24 14:40:41 - issues channel

**Jon**

```---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-234-4f4cb3a4297e&gt; in &lt;module&gt;

      3 )

      4 

----&gt; 5 market_book_to_data_frame(market_books)



&lt;ipython-input-232-a1a850e150a8&gt; in market_book_to_data_frame(market_book)

     15             'size': price_size['size']

     16         }

---&gt; 17         for runner in market_book['runners']

     18         for side in ['Back', 'Lay']

     19         for depth, price_size in enumerate(runner.get('ex', {}).get(f'availableTo{side}', []))



TypeError: list indices must be integers or slices, not str```

---

## 2020-07-24 14:24:09 - issues channel

**Mo**

What IDE are you using? I'd recommend PyCharm and you can use the debugger to inspect the MarketBook object

---

## 2020-07-24 14:20:08 - issues channel

**Jon**

and also when i iterate with something like

    `best_lay_sizes = [runner_book.ex.available_to_lay[0].size`

                      `if runner_book.ex.available_to_lay[0].size`

                      `else 1.01`

                      `for runner_book`

                      `in runner_books]`

i get

```AttributeError: 'NoneType' object has no attribute 'available_to_back'```



---

## 2020-07-24 09:43:46 - issues channel

**liam**

confused as to why that is being called so many times, hard to debug without seeing code which obviously might be tricky without revealing your strategies

---

## 2020-07-23 12:50:38 - issues channel

**liam**

[@U013R0E7SUV](@U013R0E7SUV) you must have some sort of memory leak, without seeing the code it will be hard to debug but bflw streaming code shoudln't be the cause

---

## 2020-07-23 12:01:05 - issues channel

**Michael**

Either way a change in name fixed it

---

## 2020-07-23 10:08:23 - issues channel

**PeterLe**

No I havent Liam. My other accounts (which work fine) are all the same name with the exception of the last digit. Id like to keep them using the same naming convention if poss. Ive dropped Neil an email now so Ill see what he can suggest. Thanks for the help gents.

---

## 2020-07-23 09:59:01 - issues channel

**PeterLe**

Morning folks

A quick question please

Ive just added three new sub accounts (ie in addition to other sub accounts i have under the master account) and wanting to create the keys.

I log into the first new account, open a new chrome tab and then navigate to API Account operations. I can see the SSIOD OK.

I click on createDeveloperAppKeys and then adjacent I type in the account user name into the text box "Application Name"

When i click "Execute" I get an error "Exception in response: Exception: AccountAPINGException Error Code: UNEXPECTED_ERROR Error details: "

Ive got other sub acounts and i dont recall having an issues when I set them up?

(I appreciate that the Application Name has to be unique).

I just wondered if anyone had any ideas please? (Maybe the sub accounts have to be verified before you can create keys etc?) I could contact Neil, but dont want to bother him if Im doing something stupid!

Thanks in advance

Peter

---

## 2020-07-22 20:08:28 - strategies channel

**birchy**

oh... I must of been lucky then, as I've not had any noticeable issues other than regular connection errors, but I've always assumed that was a betfair issue rather than Tagadab? What's the latency like on EC2?

---

## 2020-07-22 13:00:30 - general channel

**D C**

I guess I can try and detect an excessive lag and block placement of bets if a certain threshold is exceeded. Truth be told most of the problems I get are positional errors rather than lag problems. Thanks for advice anyway

---

## 2020-07-22 12:52:09 - general channel

**D C**

This aimed at GPS users - I was watching the first Yarmouth race in my render software and the final suspension inplay occurred when my stuff clocked an eighth of a furlong left to go. Of course this could be errors in my stuff or betfair being trigger happy with early suspend, but just a word of warning to anyone using GPS. Unfortunately I cannot check the lag times easily at present but if the same happens in the next I will be killing my GPS bot for the rest of the day. Any confirmation of this from other users would be very welcome

---

## 2020-07-21 20:35:19 - general channel

**liam**

Zero exceptions, I and about 300 others don’t pay above 1000

---

## 2020-07-21 19:40:33 - general channel

**liam**

Master account and zero exceptions is the line from my AM

---

## 2020-07-21 13:04:10 - general channel

**JT**

Hi Mo, sorry to be jumping on this thread. I have been trying to get scores on tennis matches that are showing scores on the website, but seem to be getting 503 / connection errors. I am using the

---

## 2020-07-21 11:50:09 - issues channel

**JC**

When working with the inplayservice endpoint in bflw, if I don't set `_lightweight_=True` for my trading instance, the JSON response returned triggers an InvalidResponse exception (I think due to single quotes being used for strings instead of double?). Not sure if I'm missing something here. Also when working with the scores API for tennis, `trading.scores.list_available_events()` returns an empty list. Not sure if this is because my key isn't authorised or whether there actually are no matches on the scores API atm lol.

---

## 2020-07-20 18:24:29 - general channel

**liam**

Btw paper trading is now implemented so you can simulate trading against live markets, makes debugging matching a lot easier as you can use the betfair site 

---

## 2020-07-20 14:37:22 - random channel

**Newbie99**

You get an error and they fail

---

## 2020-07-20 14:34:49 - random channel

**Jono**

Just a general question about bet placement, if an order is requested at odds outside of betfairs tick brackets how are these bets handled? do they immediately fail and give an error response or are they rounded at betfairs end?

---

## 2020-07-20 14:18:41 - random channel

**Newbie99**

Just be a bit careful with this year's model, I had to send 2 back because of defective trackpad's and looking at you tube and other reviews it seems to be an issue with the 2020 XPS 15 (not sure if the whole line up uses the same trackpad). So personally based on that, I wouldn't get a 2020 XPS until they announce they've fixed that issue.

---

## 2020-07-15 16:22:08 - general channel

**Oliver Varney**

looks like BaseControl._on_error call order.violation, maybe a good place to add a param in order?

---

## 2020-07-14 15:27:26 - general channel

**liam**

yeah class variables are dangerous, can be hard to debug

---

## 2020-07-14 11:04:18 - issues channel

**liam**

_While we have snapshots disabled (for performance reasons), this will happen whenever we do a release or restart. This is a defect that we have listed to fix at a future date._



_In the meantime, the dev team will look at an alternative solution e.g. excluding closed markets from the initial image._

---

## 2020-07-11 12:11:57 - issues channel

**Unknown**

Whats the best approach to dealing with a socket error? Delete the current subscription and create a new one?

---

## 2020-07-08 16:00:28 - issues channel

**liam**

This should now be fixed, from Neil:



_market definition issue was fixed as part of a release on Friday evening (3rd July)._

---

## 2020-07-08 12:43:53 - general channel

**liam**

It’s open to abstraction, you could handle this either in the trade itself .create_order (check others or raise error) or maybe in strategy.validate_order 

---

## 2020-07-06 22:51:15 - issues channel

**birchy**

~Hi All,~

~"errorMessage":"AppKey is not configured for service"~

~Have been running bots for years but only just getting into streaming. Any ideas?~

Scratch that! I have a main account and a sub-account. Turns out that my main account is enabled for streaming but sub-account isn't.

---

## 2020-07-05 18:33:18 - random channel

**SrFabio**

I don't see any error there. Does it cashout for less than  the min return? I've not used this endpoint before (but I'm extremely tempted to!)

---

## 2020-07-05 17:47:43 - random channel

**Newbie99**

Another cashout question....



```import requests as rq

import json



def cash_out(session_token, market_id, min_return, ai.acckey):



    url = ('[https://cashout-service.betfair.com/cashout-service/transactional/v1.0/cashout?_ak=](https://cashout-service.betfair.com/cashout-service/transactional/v1.0/cashout?_ak=)' + str(ai.acckey)

                          + '&amp;alt=json&amp;currencyCode=GBP&amp;marketId=' + str(market_id) + '&amp;quotePercentage=100&amp;quoteValue=' + str(min_return))

    header = {'X-Application': ai.acckey, 'X-Authentication': session_token, 'content-type': 'application/json'}

    response = [http://rq.post|rq.post](http://rq.post|rq.post)(url, headers=header)

    if response.status_code == 200:

        return json.loads(response.content.decode('utf-8'))

    else:

        return None```

The above works, however whatever I put in as min_return it just cashes out regardless, so can anyone spot where the error lies (this is just tweaking the example posted here the other day btw, so I am assuming the endpoint is the preferred one for the UK exchange)?



ai.acckey = appkey for the avoidance of doubt

---

## 2020-07-03 19:15:30 - issues channel

**Alex A**

They’ve now fixed and released this.

---

## 2020-07-03 10:31:09 - issues channel

**Jonatan (skyw)**

If it this solution and it is as I asked above I still don't think it's fixed correctly 

[https://github.com/liampauling/flumine/commit/bc532c5b5cc3392b07d057b4e269826ced8b742f|https://github.com/liampauling/flumine/commit/bc532c5b5cc3392b07d057b4e269826ced8b742f](https://github.com/liampauling/flumine/commit/bc532c5b5cc3392b07d057b4e269826ced8b742f|https://github.com/liampauling/flumine/commit/bc532c5b5cc3392b07d057b4e269826ced8b742f)

---

## 2020-07-03 08:05:39 - issues channel

**liam**

This should have been fixed in v1.8.0 with the other bug, have you tried upgrading?

---

## 2020-07-01 17:54:24 - issues channel

**Martin Johansson**

LoginError: API login: AUTHORIZED_ONLY_FOR_DOMAIN_SE

---

## 2020-07-01 15:01:21 - general channel

**liam**

If you use your debugger, you can see it in

```runner.ex.traded_volume```

---

## 2020-07-01 12:14:38 - issues channel

**Andrey Yunoshev**

[@U4H19D1D2](@U4H19D1D2) the new one 'RuntimeError: dictionary changed size during iteration'  [https://github.com/liampauling/flumine/issues/228](https://github.com/liampauling/flumine/issues/228)

---

## 2020-06-30 19:20:03 - general channel

**liam**

Big [https://forum.developer.betfair.com/filedata/fetch?id=32354|changes](https://forum.developer.betfair.com/filedata/fetch?id=32354|changes) in transaction charges 



```Transaction Charge Changes

Over the years, the Exchange has processed an increasing number of transactions at an ever-increasing cost to infrastructure and stability.

Therefore, from 1st September 2020, Betfair will be changing the thresholds of the Transaction Charge. The changes are as follows:

• The new limit of “free” transactions will be set at 5,000 transactions per hour. o A “transaction” shall include all bets placed and all failed transactions.

• Every transaction that exceeds the limit will incur a cost of £0.002 (a fifth of a penny). o This cost will be offset by a user’s commission generated.

• There will be no exemptions from this charge.

We have modelled the new charge to disincentivise wasteful transactional behaviour and promote platform stability on a level playing field. It is possible to trade multiple events and markets without ever incurring any of these charges.

Your account manager will be in touch if you would have incurred these charges in the past, giving you an opportunity to update trading strategies and fix bugs before the charge goes live on 1st September.```

---

## 2020-06-30 17:53:26 - general channel

**liam**

I don't think that is the problem, as a removed runner will stay in the book and catalogue, that error is in reference to your placeInstructionReport not having an instruction

---

## 2020-06-30 17:22:49 - general channel

**Newbie99**

`File "D:\Python37\webpages\racing_functions.py", line 1175, in &lt;listcomp&gt;`

    `runner_name = [runner.runner_name for runner in market_catalogue.runners if runner.selection_id == place_instruction_report.instruction.selection_id]`

`AttributeError: 'NoneType' object has no attribute 'selection_id'`



Appreciate that's not much use to anyone...but I think it is to do with when a runner is removed, so just wanted to do a logic check.



If a runner is removed, is the selection_id then removed from the market_catalogue, but remains in the market_book as non-active (well I know the second part, but its the market_catalogue behaviour I just wanted to check)?

---

## 2020-06-30 17:21:09 - general channel

**Newbie99**

Sometimes, I get an error similar to the below:

---

## 2020-06-30 11:46:44 - general channel

**sartux**

I found the error, I have to use 'averagePriceMatched'



can you tell me the types of orderType with the differences? I can't find the documentation

---

## 2020-06-29 18:27:17 - issues channel

**liam**

Looks like a fix was deployed this morning so it is now at least consistent  [@U0131E2H1SP](@U0131E2H1SP) [https://forum.developer.betfair.com/forum/developer-program/announcements/32066-retrospective-api-release-to-prevent-minimum-bet-abuse-19th-june|https://forum.developer.betfair.com/forum/developer-program/announcements/32066-retrospective-api-release-to-prevent-minimum-bet-abuse-19th-june](https://forum.developer.betfair.com/forum/developer-program/announcements/32066-retrospective-api-release-to-prevent-minimum-bet-abuse-19th-june|https://forum.developer.betfair.com/forum/developer-program/announcements/32066-retrospective-api-release-to-prevent-minimum-bet-abuse-19th-june)

---

## 2020-06-29 13:12:15 - issues channel

**D C**

Inplay near the end. I was getting a best back price of 2.86 when the best lay price was 1.01. Could be an error in my GUI but I have not seen this before

---

## 2020-06-29 10:38:12 - issues channel

**Dylan**

Hey! fairly new to the project however, I'm getting a SUBSCRIPTION_LIMIT_EXCEEDED error, would the assumption be that my filters are too broad? What controls this?

```ERROR:betfairlightweight.streaming.listener:[Subscription: 1] SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 345 markets whereas max allowed number was: 200

INFO:betfairlightweight.streaming.listener:[Subscription: 1]: FAILURE (1 connections available)



#main.py

market_filter = streaming_market_filter(

    event_type_ids=["7"], country_codes=["AU"], market_types=["WIN"]

)

market_data_filter = streaming_market_data_filter(

    fields=["EX_MARKET_DEF"], ladder_levels=3

)```

---

## 2020-06-29 10:06:40 - general channel

**sartux**

I tried and received the same error as yesterday (500 generic error)



I sent the POST variables via urllib, where am I wrong?

---

## 2020-06-29 10:06:37 - general channel

**sartux**

```url = "[https://cashout-service.betfair.it/cashout-service/transactional/v1.0/cashout](https://cashout-service.betfair.it/cashout-service/transactional/v1.0/cashout) "

values = {'appKey': '#######',

          'marketId': marketId,

          'quotePercentage': 100,

          'quoteValue': 0}



data = urllib.parse.urlencode(values)

data = data.encode('ascii')  # data should be bytes

req = urllib.request.Request(url, data)

with urllib.request.urlopen(req) as response:

    the_page = response.read()

    print(the_page)```

  File "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/urllib/request.py", line 649, in http_error_default

    raise HTTPError(req.full_url, code, msg, hdrs, fp)

urllib.error.HTTPError: HTTP Error 500: Server Error

---

## 2020-06-28 20:12:44 - general channel

**sartux**

```td = trading.betting.list_current_orders(lightweight=True)



for i,dd in td['currentOrders']:

    print(dd['marketId'])```

Where is the error?

ValueError: too many values to unpack (expected 2)

---

## 2020-06-28 14:04:53 - issues channel

**liam**

Haven’t seen this before, can you create a GitHub issue and I will try and fix 

---

## 2020-06-28 14:01:59 - issues channel

**Andrey Yunoshev**

```AU

PLACE ORDER BACK

INFO:flumine.order.order:Order status update: Pending

PLACE ORDER LAY

INFO:flumine.order.order:Order status update: Pending

INFO:flumine.markets.blotter:1 order packages created

	BACK/PENDING 0.0 price, 0.0 size

	LAY/PENDING 0.0 price, 0.0 size

INFO:flumine.execution.betfairexecution:execute_place

INFO:flumine.order.trade:Trade status update: Pending

INFO:flumine.execution.baseexecution:Order Place: SUCCESS

INFO:flumine.order.order:Order status update: Executable

INFO:flumine.order.trade:Trade status update: Live

INFO:flumine.order.trade:Trade status update: Pending

INFO:flumine.execution.baseexecution:Order Place: SUCCESS

INFO:flumine.order.order:Order status update: Executable

INFO:flumine.order.trade:Trade status update: Live

INFO:flumine.order.order:Order status update: Execution complete

INFO:flumine.order.trade:Trade status update: Complete

REPLACE PRICE, FROM 4.0 TO 3.7

INFO:flumine.order.order:Order status update: Replacing

	BACK/REPLACING 0.0 price, 0.0 size

	LAY/EXECUTION_COMPLETE 3.7 price, 2.16 size

INFO:flumine.markets.blotter:1 order packages created

INFO:flumine.execution.betfairexecution:execute_replace

INFO:flumine.order.trade:Trade status update: Pending

INFO:flumine.execution.baseexecution:Order Cancel: SUCCESS

INFO:flumine.order.order:Order status update: Execution complete

INFO:flumine.execution.baseexecution:Order Replace: SUCCESS

INFO:flumine.order.order:Order status update: Pending

INFO:flumine.order.order:Order status update: Executable

INFO:flumine.order.trade:Trade status update: Live

INFO:flumine.streams.orderstream:Stopped OrderStream 1001

INFO:flumine.streams.marketstream:Stopped MarketStream 2001

INFO:flumine.streams.marketstream:Stopped output_thread (MarketStream 2001)

INFO:flumine.execution.baseexecution:Shutting down Execution (SimulatedExecution)

INFO:flumine.execution.baseexecution:Shutting down Execution (BetfairExecution)

INFO:flumine.streams.orderstream:Stopped output_thread (OrderStream 1001)

INFO:flumine.baseflumine:Exiting flumine

Traceback (most recent call last):

  File "./pydogs/greyscout2live.py", line 727, in &lt;module&gt;

    framework.run()

  File "/usr/local/lib/python3.7/site-packages/flumine/flumine.py", line 32, in run

    self._process_current_orders(event)

  File "/usr/local/lib/python3.7/site-packages/flumine/baseflumine.py", line 183, in _process_current_orders

    strategy_orders = market.blotter.strategy_orders(strategy)

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/blotter.py", line 27, in strategy_orders

    return [order for order in self if order.trade.strategy == strategy]

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/blotter.py", line 27, in &lt;listcomp&gt;

    return [order for order in self if order.trade.strategy == strategy]

RuntimeError: dictionary changed size during iteration```

---

## 2020-06-28 13:01:53 - general channel

**fjt1973**

So this is my handler, very basic to return the balalce of my account.



def lambda_handler(event, context):

    # TODO implement

    trading = betfairlightweight.APIClient(username=my_username,

                                       password=my_password,

                                       app_key=my_app_key,

                                       certs=certs_path)



    trading.login()

    account_funds = trading.account.get_account_funds()

    balance = account_funds.available_to_bet_balance

    return balance

    #return {

    #    'statusCode': 200,

    #    'body': json.dumps('Hello from Lambda!')

    #}



And this is the execution results



Response:

{

  "errorMessage": "None \nParams: None \nException: join() argument must be str or bytes, not 'tuple'",

  "errorType": "APIError",

  "stackTrace": [

    "  File \"/var/task/lambda_function.py\", line 33, in lambda_handler\n    trading.login()\n",

    "  File \"/opt/python/lib/python3.7/site-packages/betfairlightweight/endpoints/login.py\", line 31, in __call__\n    self.url, session=session\n",

    "  File \"/opt/python/lib/python3.7/site-packages/betfairlightweight/endpoints/login.py\", line 53, in request\n    raise APIError(None, exception=e)\n"

  ]

}



Request ID:

"f4b6780c-fb3a-485f-881d-3fc75f1cfddd"



Function Logs:

START RequestId: f4b6780c-fb3a-485f-881d-3fc75f1cfddd Version: $LATEST

[ERROR] APIError: None

Params: None

Exception: join() argument must be str or bytes, not 'tuple'

Traceback (most recent call last):

  File "/var/task/lambda_function.py", line 33, in lambda_handler

    trading.login()

  File "/opt/python/lib/python3.7/site-packages/betfairlightweight/endpoints/login.py", line 31, in __call__

    self.url, session=session

  File "/opt/python/lib/python3.7/site-packages/betfairlightweight/endpoints/login.py", line 53, in request

    raise APIError(None, exception=e)

END RequestId: f4b6780c-fb3a-485f-881d-3fc75f1cfddd

REPORT RequestId: f4b6780c-fb3a-485f-881d-3fc75f1cfddd	Duration: 19.17 ms	Billed Duration: 100 ms	Memory Size: 128 MB	Max Memory Used: 85 MB	Init Duration: 782.62 ms

---

## 2020-06-28 11:50:30 - general channel

**fjt1973**

Exception: join() argument must be str or bytes, not 'tuple'

Traceback (most recent call last):

  File "/var/task/lambda_function.py", line 37, in lambda_handler

    trading.login()

  File "/opt/python/lib/python3.7/site-packages/betfairlightweight/endpoints/login.py", line 31, in __call__

    self.url, session=session

  File "/opt/python/lib/python3.7/site-packages/betfairlightweight/endpoints/login.py", line 53, in request

    raise APIError(None, exception=e)

---

## 2020-06-28 11:50:24 - general channel

**fjt1973**

[@U4H19D1D2](@U4H19D1D2) is BFL compatible with AWS Lambda? I've uploaded BFL as a package into AWS Layers but I'm getting the following error.

---

## 2020-06-27 17:12:51 - issues channel

**Lee**

is there a reason why i sometimes get the market catalogue response? my understanding was i'd get an error response if i was requesting too much data or calling too quickly. all 3 requests are the same

```&gt;&gt;&gt; trading.betting.list_market_catalogue(

    filter=filters.market_filter(

        event_type_ids=[7],

        market_countries=["GB"],

        market_type_codes=["WIN"],

        market_ids=["1.171017510"],

    ),

    market_projection=["RUNNER_METADATA"],

)

[]

&gt;&gt;&gt; trading.betting.list_market_catalogue(

    filter=filters.market_filter(

        event_type_ids=[7],

        market_countries=["GB"],

        market_type_codes=["WIN"],

        market_ids=["1.171017510"],

    ),

    market_projection=["RUNNER_METADATA"],

)

[&lt;MarketCatalogue&gt;]

&gt;&gt;&gt; trading.betting.list_market_catalogue(

    filter=filters.market_filter(

        event_type_ids=[7],

        market_countries=["GB"],

        market_type_codes=["WIN"],

        market_ids=["1.171017510"],

    ),

    market_projection=["RUNNER_METADATA"],

)

[]```

---

## 2020-06-26 15:57:42 - issues channel

**D C**

No errors-  just no orders matched (or none reported)

---

## 2020-06-26 15:56:05 - issues channel

**Jonatan (skyw)**

How does this manifest itself except from, "it should've been more messages", are messages conflated or are there delay, or that downstream error present?

---

## 2020-06-23 02:25:40 - issues channel

**Paul Smith**

[@UFTBRB3F1](@UFTBRB3F1) whenever you get back a ERROR_IN_ORDER there should always be an accompanying reason.  This could be INVALID_BET_SIZE or MARKET_SUSPENDED, etc.  You need to check the reasn for the error.  Sometimes it can be a late scratching that has been removed from the market and you have updated your list of selections to see this change.

---

## 2020-06-22 16:30:40 - issues channel

**liam**

Yeah this can sometimes happen, gave up trying to get betfair to fix 

---

## 2020-06-22 15:55:07 - issues channel

**Newbie99**

Placing a single bet, I just got back an Error Code of 'ERROR_IN_ORDER', which is a fairly common one to see, but normally it is because another order has an 'INVALID_BET_SIZE' or something along those lines.



In this case however, that was the only error code (and it was just the lone bet)...looking at the timestamp it was sent just before the market was suspended (i.e. I received a market_book update @ 15:27:16.626763, with the next one coming @ 15:27:16.721394, showing it had been suspended (the place order instruction was sent just before the update).



Is that error consistent with the bet being rejected due to a market being suspended (I'm assuming this is correct behaviour, but just wanted to check due to the non-descriptive error message)?

---

## 2020-06-22 08:20:18 - issues channel

**JK**

i tried doing `client.betting.read_timeout = 45` where client is an `APIClient` object, but that returned

```Error: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-05191058-003bfd', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-05191058-003d', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}```

---

## 2020-06-22 08:14:26 - issues channel

**JK**

```Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 387, in _make_request

    six.raise_from(e, None)

  File "&lt;string&gt;", line 2, in raise_from

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 383, in _make_request

    httplib_response = conn.getresponse()

  File "/usr/lib/python3.6/http/client.py", line 1356, in getresponse

    response.begin()

  File "/usr/lib/python3.6/http/client.py", line 307, in begin

    version, status, reason = self._read_status()

  File "/usr/lib/python3.6/http/client.py", line 268, in _read_status

    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")

  File "/usr/lib/python3.6/socket.py", line 586, in readinto

    return self._sock.recv_into(b)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py", line 317, in recv_into

    raise timeout('The read operation timed out')

socket.timeout: The read operation timed out



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/adapters.py", line 449, in send

    timeout=timeout

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 641, in urlopen

    _stacktrace=sys.exc_info()[2])

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/util/retry.py", line 368, in increment

    raise six.reraise(type(error), error, _stacktrace)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/packages/six.py", line 686, in reraise

    raise value

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 603, in urlopen

    chunked=chunked)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 389, in _make_request

    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/urllib3/connectionpool.py", line 307, in _raise_timeout

    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)

urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=16)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 43, in request

    timeout=(self.connect_timeout, self.read_timeout)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/api.py", line 116, in post

    return request('post', url, data=data, json=json, **kwargs)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/api.py", line 60, in request

    return session.request(method=method, url=url, **kwargs)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/sessions.py", line 533, in request

    resp = self.send(prep, **send_kwargs)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/sessions.py", line 646, in send

    r = adapter.send(request, **kwargs)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/requests/adapters.py", line 529, in send

    raise ReadTimeout(e, request=request)

requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=16)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "get_new_bets_minutely.py", line 159, in &lt;module&gt;

    main1()

  File "get_new_bets_minutely.py", line 48, in main1

    include_item_description = "true"

  File "/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py", line 288, in list_cleared_orders

    (response, elapsed_time) = self.request(method, params, session)

  File "/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 48, in request

    raise APIError(None, method, params, e)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders 

Params: {'recordCount': 500, 'fromRecord': 1500, 'includeItemDescription': 'true', 'settledDateRange': {'to': None, 'from': None}, 'betStatus': 'SETTLED'} 

Exception: HTTPSConnectionPool(host='[http://api.betfair.com|api.betfair.com](http://api.betfair.com|api.betfair.com)', port=443): Read timed out. (read timeout=16)```

---

## 2020-06-22 08:10:47 - general channel

**Newbie99**

`ERROR: flumine 1.7.0 has requirement betfairlightweight==2.4.0, but you'll have betfairlightweight 2.5.0 which is incompatible.`

---

## 2020-06-22 07:35:57 - issues channel

**liam**

by default bflw has it set to 15s, I use this endpoint a lot and have never hit a timeout, whats your connection like? Is it a requests timeout? (whats the traceback look like?)

---

## 2020-06-22 07:23:30 - issues channel

**JK**

hey guys, i hit listClearedOrders every 15 mins to get my recent bets and add them to a database, but recently ive been getting a timeout error. Anyone know how to fix this/anyone else been having the same issue?

---

## 2020-06-21 16:06:36 - general channel

**gprokisch**

Hi guys. Any idea how I can fix this error: INVALID_SESSION_INFORMATION

---

## 2020-06-20 18:30:52 - issues channel

**Mo**

You’re not seeing either a socket error or an SSL error so you must have successfully sent a complete SSL frame

---

## 2020-06-20 18:22:19 - issues channel

**Mo**

I don’t think a network error would present at the application layer like that 

---

## 2020-06-20 18:20:02 - issues channel

**Jonatan (skyw)**

I would guess network error

---

## 2020-06-20 18:19:44 - issues channel

**Jonatan (skyw)**

I looked at the code and you add it! Probably some part not being sent then. Not code error I believe

---

## 2020-06-20 18:19:11 - issues channel

**liam**

As per the docs betfair use the delimiter so I am not sure what is going on here, it’s very tricky to debug/replicate 

---

## 2020-06-20 18:12:55 - issues channel

**Jonatan (skyw)**

One have to establish a protocol, either some delimiter or fixed size messages?

---

## 2020-06-20 17:55:07 - issues channel

**liam**

Hmm, I have also seen this and thought it was fixed with the use of `sendall` on the socket but I guess it’s not fixed it 

---

## 2020-06-20 17:52:43 - issues channel

**Ruben**

Quick question: a while ago I run a piece of code that created a market stream subscription to some event ids, and I got the error when trying to create the subscription stream "INVALID_INPUT, unable to un-marshall". Some hours later, I ran the same code again, and it worked fine

---

## 2020-06-20 15:45:54 - general channel

**Andrey Yunoshev**

[https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1592659131481300](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1592659131481300)



here, I have back order with price 9.0 and size 2, and trying replace for new price 8.6



and where i accually new order creating?



I see following code



```    def replace(self, new_price: float) -&gt; None:

        if self.order_type.ORDER_TYPE in [OrderTypes.LIMIT, OrderTypes.LIMIT_ON_CLOSE]:

            if self.order_type.price == new_price:

                raise OrderUpdateError("Prices match")

            elif self.status != OrderStatus.EXECUTABLE:

                raise OrderUpdateError("Current status: %s" % self.status)

            self.update_data["new_price"] = new_price

            self.replacing()

        else:

            raise OrderUpdateError(

                "Only LIMIT or LIMIT_ON_CLOSE orders can be replaced."

            )



```



Its just change order status, but can not find where replacting accually happens

I use 1.7.0

---

## 2020-06-20 13:50:07 - general channel

**liam**

Bflw is just a wrapper so up to user in how to implement a min bet order, flumine doesn’t have the ability yet so no bugs here :wink:

---

## 2020-06-20 13:43:10 - general channel

**Stefan**

I hope your python library is not so buggy implemented, I think you know who I am on betfair forum.

---

## 2020-06-18 09:31:08 - issues channel

**Lee**

are the betfair api docs down for everyone? i'm getting an nginx error page

---

## 2020-06-18 05:26:02 - general channel

**gprokisch**

Hi guys, I had deployed a script using Google cloud but I'm getting this error [https://stackoverflow.com/questions/25817167/betfair-api-betting-restricted-location-when-logging-in-from-google-app-engine|BETTING_RESTRICTED_LOCATION](https://stackoverflow.com/questions/25817167/betfair-api-betting-restricted-location-when-logging-in-from-google-app-engine|BETTING_RESTRICTED_LOCATION) cause google ip address, in my local computer it's works fine.

---

## 2020-06-18 00:05:00 - issues channel

**Unknown**

I put .. but still with error

---

## 2020-06-17 19:06:52 - issues channel

**Mo**

What file? What error?

---

## 2020-06-17 19:03:37 - issues channel

**jaderson felipe**

I downloaded the file and unzipped it ... but when I try to open it using PANDAS I always get an error ... could someone help me?

---

## 2020-06-17 16:41:58 - issues channel

**Mo**

And what error do you get trying to use it?

---

## 2020-06-17 13:54:34 - issues channel

**EJono**

When I direct it straight to one of the bz2 files it comes across a Unicode error

---

## 2020-06-16 20:02:29 - general channel

**Disco**

For Chrome, if I remember correctly, there was an extension which allowed to debug websockets easier

---

## 2020-06-15 16:19:16 - issues channel

**Jonatan (skyw)**

I have also got connection reset error from betfair, as you i also assumed it was the number of markets that I had subscribed to, when increasing the  number of subscriptions the error went away.

---

## 2020-06-15 14:37:50 - issues channel

**Sandy Caskie**

```ERROR: Command errored out with exit status 1:

  command: /Users/Sandy/anaconda3/bin/python /Users/Sandy/anaconda3/lib/python3.6/site-packages/pip install --ignore-installed --no-user --prefix /private/var/folders/1y/7v8fvfy51_sfdx_r21tgkq5h0000gn/T/pip-build-env-r8el7tjn/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i [https://pypi.org/simple](https://pypi.org/simple) -- 'setuptools&gt;=42' wheel 'setuptools_scm[toml]&gt;=3.4'

    cwd: None

 Complete output (41 lines):

 Traceback (most recent call last):

  File "/Users/Sandy/anaconda3/lib/python3.6/runpy.py", line 193, in _run_module_as_main

   "__main__", mod_spec)

  File "/Users/Sandy/anaconda3/lib/python3.6/runpy.py", line 85, in _run_code

   exec(code, run_globals)

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/__main__.py", line 19, in &lt;module&gt;

   sys.exit(_main())

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/cli/main.py", line 73, in main

   command = create_command(cmd_name, isolated=("--isolated" in cmd_args))

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/commands/__init__.py", line 96, in create_command

   module = importlib.import_module(module_path)

  File "/Users/Sandy/anaconda3/lib/python3.6/importlib/__init__.py", line 126, in import_module

   return _bootstrap._gcd_import(name[level:], package, level)

  File "&lt;frozen importlib._bootstrap&gt;", line 994, in _gcd_import

  File "&lt;frozen importlib._bootstrap&gt;", line 971, in _find_and_load

  File "&lt;frozen importlib._bootstrap&gt;", line 955, in _find_and_load_unlocked

  File "&lt;frozen importlib._bootstrap&gt;", line 665, in _load_unlocked

  File "&lt;frozen importlib._bootstrap_external&gt;", line 678, in exec_module

  File "&lt;frozen importlib._bootstrap&gt;", line 219, in _call_with_frames_removed

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/commands/install.py", line 24, in &lt;module&gt;

   from pip._internal.cli.req_command import RequirementCommand

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/cli/req_command.py", line 21, in &lt;module&gt;

   from pip._internal.req.constructors import (

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/req/__init__.py", line 11, in &lt;module&gt;

   from .req_file import parse_requirements

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/req/req_file.py", line 25, in &lt;module&gt;

   from pip._internal.req.constructors import (

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/req/constructors.py", line 28, in &lt;module&gt;

   from pip._internal.req.req_install import InstallRequirement

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/req/req_install.py", line 30, in &lt;module&gt;

   from pip._internal.operations.install.wheel import install_wheel

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/pip/_internal/operations/install/wheel.py", line 10, in &lt;module&gt;

   import compileall

  File "/Users/Sandy/anaconda3/lib/python3.6/compileall.py", line 20, in &lt;module&gt;

   from concurrent.futures import ProcessPoolExecutor

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/concurrent/futures/__init__.py", line 8, in &lt;module&gt;

   from concurrent.futures._base import (FIRST_COMPLETED,

  File "/Users/Sandy/anaconda3/lib/python3.6/site-packages/concurrent/futures/_base.py", line 381

   raise exception_type, self._exception, self._traceback

             ^

 SyntaxError: invalid syntax

 ----------------------------------------

ERROR: Command errored out with exit status 1: /Users/Sandy/anaconda3/bin/python /Users/Sandy/anaconda3/lib/python3.6/site-packages/pip install --ignore-installed --no-user --prefix /private/var/folders/1y/7v8fvfy51_sfdx_r21tgkq5h0000gn/T/pip-build-env-r8el7tjn/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i [https://pypi.org/simple](https://pypi.org/simple) -- 'setuptools&gt;=42' wheel 'setuptools_scm[toml]&gt;=3.4' Check the logs for full command output.```

I then uninstalled betfairlightweight and tried re-installing but got the same error. Looking online this seems like an internal error regarding pip any idea why this could happen?

---

## 2020-06-15 14:27:43 - issues channel

**liam**

```logging.getLogger("betfairlightweight").setLevel(logging.DEBUG)```

---

## 2020-06-15 14:25:20 - issues channel

**mandelbot**

debug logs, I dont know what that is. But I will look it up. In the mean time i will switch to a linux! Thanks liam.

---

## 2020-06-15 14:24:11 - issues channel

**liam**

can you run with debug logs on? Might be tricky to debug this as it look os specific

---

## 2020-06-15 14:22:32 - issues channel

**mandelbot**

Happened again, one python this time

`{"asctime": "2020-06-15 13:19:45,614", "levelname": "ERROR", "message": "DataStream run error", "exc_info": "Traceback (most recent call last):\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 220, in _receive_all\n    part = self._socket.recv(self.buffer_size)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ssl.py\", line 1226, in recv\n    return self.read(buflen)\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\ssl.py\", line 1101, in read\n    return self._sslobj.read(len)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\flumine\\streams\\datastream.py\", line 113, in run\n    self._stream.start()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 59, in start\n    self._read_loop()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 202, in _read_loop\n    received_data_raw = self._receive_all()\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\betfairlightweight\\streaming\\betfairstream.py\", line 224, in _receive_all\n    raise SocketError(\"[Connect: %s]: Socket %s\" % (self._unique_id, e))\nbetfairlightweight.exceptions.SocketError: [Connect: 3002]: Socket [WinError 10054] An existing connection was forcibly closed by the remote host"}`

`{"asctime": "2020-06-15 13:19:45,614", "levelname": "WARNING", "message": "[Stream: 1001]: Latency high: 302.40696835517883"}`

---

## 2020-06-15 14:02:20 - issues channel

**mandelbot**

I noticed one of them wasn't reporting any logs, so when I hit return it dumped a bunch of latency errors

---

## 2020-06-15 14:00:41 - issues channel

**mandelbot**

no latency errors and recording markets

---

## 2020-06-15 13:13:30 - issues channel

**Sandy Caskie**

I am trying to get the price historical data for back and lay for horse racing events prior to the race start. I have been able to download the historical data using the GitHub repository [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py). I have then tried to view this data using the code from this repository [https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py). Though when I do this I receive the following error:



```AttributeError: 'Streaming' object has no attribute 'create_historical_generator_stream'```

When I look at the downloaded historical data file and read it as .txt file I can see it has the last traded price per runner. Therefore it appears that the downloaded file does have the data I am looking for. Though I cannot see a date-time stamp or if it is back or lay price for the traded price. Therefore I have two questions:



1. Is this the correct method to get back and lay price data up until the race starts?

2. Has this attribute name been changed or something? That is why I am getting this error.

---

## 2020-06-14 12:44:47 - general channel

**Sandy Caskie**

Got it! I think anyway lol. No error and returned &lt;LoginResource&gt;



These things never work when I stay up late and try do them.



I think what happened was the .key file was not associated with .crt file when I created them. Therefore the error key values mismatch was returned.

---

## 2020-06-14 09:09:39 - issues channel

**Peter**

I've having similar (possibly the same) problems with [@UPMUFSGCR](@UPMUFSGCR)’s backtest_mult script. that is the exception appears to be being thrown in the ___get__result method in concurrent/futures/_base class, but the exception I'm seeing is rather more specific: "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc0 in position 15: invalid start byte".  As this is being thrown deep in a module with which I'm not familiar, I'm wondering whether anybody else has any ideas about this. I've tried importing multiprocessing and setting the start method to fork and I get the same exception whether I run it as a script or in Jupyter.

---

## 2020-06-14 01:11:39 - issues channel

**Unknown**

I'm having the same error message come up but am running as a script:

---

## 2020-06-13 18:53:24 - general channel

**Sandy Caskie**

Yes, that is the new error I am getting:



```APIError: None 

Params: None 

Exception: [('x509 certificate routines', 'X509_check_private_key', 'key values mismatch')]```



---

## 2020-06-13 18:43:49 - general channel

**Sandy Caskie**

Ok I've now created the .crt file. Though I now get the following error:



```APIError: None 

Params: None 

Exception: [('PEM routines', 'PEM_read_bio', 'no start line'), ('SSL routines', 'SSL_CTX_use_PrivateKey_file', 'PEM lib')]```



---

## 2020-06-13 18:32:13 - general channel

**Sandy Caskie**

```APIError: None 

Params: None 

Exception: Certificate folder not found in /Users/Sandy/Desktop/CodingLightWeight/Certificate```

---

## 2020-06-13 18:31:25 - general channel

**Lee**

whats the new error?

---

## 2020-06-13 18:30:52 - general channel

**Sandy Caskie**

When I created the certificate both a .key and .pem file were created. These have been put in the same folder, which is I have given a path to as variable certs_path. Though this error persists.

---

## 2020-06-13 18:17:23 - general channel

**Sandy Caskie**

I am now moving over to the blw. I have set up my certificate key as outlined here [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Certificate+Generation+With+XCA).



I have uploaded a .pem file to *Automated Betting Program Access* on the Betfair security page.



I then use the following code to access my account using blw:



```# Change this certs path to wherever you're storing your certificates

certs_path = r'/Users/Sandy/Desktop/CodingLightWeight/TestApp1.pem'



# Change these login details to your own

my_username = "XXXXX"

my_password = "XXXXX"

my_app_key = "XXXXX"



trading = betfairlightweight.APIClient(username=my_username,

                                       password=my_password,

                                       app_key=my_app_key,

                                       certs=certs_path)



trading.login()```

The path is to the .pem file I created. Though I get the following error:



```APIError: None 

Params: None 

Exception: Certificate folder not found in /Users/Sandy/Desktop/CodingLightWeight/TestApp1.pem```

I appear to be missing something due to the above error. Can anyone help?

---

## 2020-06-13 06:51:47 - issues channel

**mandelbot**

I'm not sure to be honest. I guess so? Ideally I'd place the markets in folders by date and then have it pick up where it left off after a restart. I wouldn't run more than one instance on the same market in that case. Though I guess this is a bit error prone. How are you able to run them 24/7? Is it because you use an S3 recorder?

---

## 2020-06-12 14:34:48 - issues channel

**Rich**

```num_of_markets = 3



class HistoricalGeneratorStreamTarBz(HistoricalGeneratorStream):

    """Copy of 'Betfair Stream' for parsing historical data (no threads).

    RB: Edited for reading tarred/bzipped files

    """

    def _read_loop(self):

        tar = tarfile.open("D:/BetfairHorseMarketsDetailed.tar")

        i = 0

        self._running = True

        for member in tar.getmembers():

            bzf=tar.extractfile(member)

            f = bz2.open(bzf)

            i += 1

            if i &gt; num_of_markets: #change this to get more than 3 markets!

                self.stop()

                break

            content=f.readlines()

            for update in content:

                if self.listener.on_data(update) is False:

                    self.stop()

                    raise ListenerError("HISTORICAL", update)

                if not self._running:

                    break

                else:

                    yield self.listener.snap()

            else:

                self.stop()



stream = HistoricalGeneratorStreamTarBz('', listener)

gen = stream.get_generator()```

---

## 2020-06-12 13:56:04 - strategies channel

**Dave**

It is effectively the same thing [@UGV299K6H](@UGV299K6H) , at least in my case where I use fixed stake. My returns / amount invested is the same as (my strike rate - implied strike rate)/implied strike rate

---

## 2020-06-11 16:44:15 - issues channel

**Unknown**

```{

    "asctime": "2020-06-11 12:17:19,379",

    "levelname": "ERROR",

    "message": "_get_cleared_markets error",

    "filename": "accounthandler.py",

    "funcName": "_get_cleared_markets",

    "module": "accounthandler",

    "process": 6,

    "threadName": "account_handler",

    "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n    httplib_response = self._make_request(conn, method, url,\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 386, in _make_request\n    six.raise_from(e, None)\n  File \"[string](string)\", line 2, in raise_from\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 382, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/usr/local/lib/python3.8/site-packages/sentry_sdk/integrations/stdlib.py\", line 102, in getresponse\n    rv = real_getresponse(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.8/http/client.py\", line 1332, in getresponse\n    response.begin()\n  File \"/usr/local/lib/python3.8/http/client.py\", line 303, in begin\n    version, status, reason = self._read_status()\n  File \"/usr/local/lib/python3.8/http/client.py\", line 264, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n  File \"/usr/local/lib/python3.8/socket.py\", line 669, in readinto\n    return self._sock.recv_into(b)\n  File \"/usr/local/lib/python3.8/ssl.py\", line 1241, in recv_into\n    return self.read(nbytes, buffer)\n  File \"/usr/local/lib/python3.8/ssl.py\", line 1099, in read\n    return self._sslobj.read(len, buffer)\nConnectionResetError: [Errno 104] Connection reset by peer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/requests/adapters.py\", line 413, in send\n    resp = conn.urlopen(\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 648, in urlopen\n    retries = retries.increment(method, url, error=e, _pool=self,\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/util/retry.py\", line 347, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/packages/six.py\", line 685, in reraise\n    raise value.with_traceback(tb)\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n    httplib_response = self._make_request(conn, method, url,\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 386, in _make_request\n    six.raise_from(e, None)\n  File \"[string](string)\", line 2, in raise_from\n  File \"/usr/local/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\", line 382, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/usr/local/lib/python3.8/site-packages/sentry_sdk/integrations/stdlib.py\", line 102, in getresponse\n    rv = real_getresponse(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.8/http/client.py\", line 1332, in getresponse\n    response.begin()\n  File \"/usr/local/lib/python3.8/http/client.py\", line 303, in begin\n    version, status, reason = self._read_status()\n  File \"/usr/local/lib/python3.8/http/client.py\", line 264, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n  File \"/usr/local/lib/python3.8/socket.py\", line 669, in readinto\n    return self._sock.recv_into(b)\n  File \"/usr/local/lib/python3.8/ssl.py\", line 1241, in recv_into\n    return self.read(nbytes, buffer)\n  File \"/usr/local/lib/python3.8/ssl.py\", line 1099, in read\n    return self._sslobj.read(len, buffer)\nrequests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/betfairlightweight-0.0.0b13-py3.8.egg/betfairlightweight/endpoints/baseendpoint.py\", line 36, in request\n    response = session.post(\n  File \"/usr/local/lib/python3.8/site-packages/requests/api.py\", line 110, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/requests/api.py\", line 56, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/requests/sessions.py\", line 488, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/requests/sessions.py\", line 609, in send\n    r = adapter.send(request, **kwargs)\n  File \"/usr/local/lib/python3.8/site-packages/requests/adapters.py\", line 473, in send\n    raise ConnectionError(err, request=request)\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/equine-1.11.2-py3.8.egg/equine/account/accounthandler.py\", line 130, in _get_cleared_markets\n    cleared_markets = client.betting_client.betting.list_cleared_orders(\n  File \"/usr/local/lib/python3.8/site-packages/betfairlightweight-0.0.0b13-py3.8.egg/betfairlightweight/endpoints/betting.py\", line 438, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/usr/local/lib/python3.8/site-packages/betfairlightweight-0.0.0b13-py3.8.egg/betfairlightweight/endpoints/baseendpoint.py\", line 43, in request\n    raise APIError(None, method, params, e)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.170718126'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))",

    "trading_function": "list_cleared_orders",

    "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.170718126'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))"

}```

---

## 2020-06-11 16:39:02 - issues channel

**liam**

13:17:19 is when I started getting errors

---

## 2020-06-11 16:32:38 - issues channel

**mandelbot**

Anyone have any error messages from the API around the exact time it crashed? Betfair claiming to me the crash was at 13:25 but it was clearly around 13:18

---

## 2020-06-11 16:14:48 - issues channel

**liam**

Yeah I think your right, just hate the idea of an error like this

---

## 2020-06-11 15:16:34 - issues channel

**Mo**

You’d need to have compiled with debug symbols to see the source file name and line number 

---

## 2020-06-11 15:15:33 - issues channel

**liam**

nice, found it, ujson causing issues, anyone able to translate?

```Jun 11 14:03:07 ip-172-31-38-187 kernel: python[5081]: segfault at 0 ip 00007f4b75638a49 sp 00007f4b6cff76f0 error 4 in ujson.cpython-38-x86_64-linux-gnu.so[7f4b7562f000+14000]```

---

## 2020-06-11 15:10:22 - issues channel

**liam**

Anyone know how to get the error when this happens? (docker/python)

```14:03:07

Segmentation fault (core dumped)```

---

## 2020-06-11 14:48:29 - issues channel

**Remi**

`"errorCode":"ERROR_IN_MATCHER"`

---

## 2020-06-10 20:51:58 - random channel

**JonJonJon**

I don't think it's the bit I fixed. This comes after. I think it's because it gets called so many times.



My profiler is not providing any details worth sharing.



As a baseline, after my prior changes, it takes 32s for the backtest, cumtime 4.5s for size_matched.



If I change the code to the below, then it becomes 28 seconds for the backtest, cumtime 1.1s for size_matched ( I know the numbers don't quite add up, but I'm also using my PC to play some music off youtube which might affect things)

```@property

def size_matched(self) -&gt; float:

    return self.simulated.size_matched or 0.0```

So it could be because the original size_matched calls current_order, which has the "if" statement to return self.simulated:



```    @property

    def current_order(self) -&gt; Union[CurrentOrder, Simulated]:

        if self.simulated:

            return self.simulated

        elif self.responses.current_order:

            return self.responses.current_order

        elif self.responses.place_response:

            return self.responses.place_response```

Perhaps the use of the @property is slow?



But the repeated test of "if self.simulated" is unnecessary, especially when it essentially comes down to a test of whether or not config.simulated is True or False.

---

## 2020-06-10 20:34:38 - random channel

**liam**

I think it’s the simulated.size_matched that sits under, but then you fixed that, have you profiled / if so can you share the breakdown?

---

## 2020-06-08 11:52:49 - issues channel

**Andrey Yunoshev**

Hi, right, I understand currently place lay and back orders for the same runner not possible? Is it a significant issue? Or can it be fixed? Or some workaround?

---

## 2020-06-06 19:29:19 - general channel

**brightcake**

I seem to get hit with a 'TOO_MUCH_DATA' error code

---

## 2020-06-06 16:18:09 - random channel

**Jonatan (skyw)**

If I install bflw, and then run mypy on my code which depends on bflw I will get an error that missing stubs or something like that.

---

## 2020-06-06 11:50:30 - random channel

**liam**

For back bets the liability is technically the size but for lays you can only select the liability. This is to prevent you setting a size of x and the BSP being calculated at 1000 or similar (due to error / slow start from the suspend guy) you would therefore have a massive exposure (something betfair couldn’t calculate before BSP is reconciled)

---

## 2020-06-06 11:35:36 - general channel

**liam**

Recommend backtesting when testing strategies, debugger is helpful in investigating objects, have a search as we were discussing it the other week 

---

## 2020-06-05 14:28:06 - issues channel

**Dave Simonds**

Theres a bit more to it than just smashing the server… I’ve probably not explained things very well. Sometimes when betfair publish their markets there is no delay, and then its a simple as getting your bet on quick, I’m pleased to say my code-base is quite good at this and I’m first to market more often than not. If all markets were published and in a ready state then I would not need to retry, and like i said if 1 retry is effectively 150 attempts (150 runners across 10 markets published simultaneously) you really rack up the errors quite quickly

---

## 2020-06-05 14:16:15 - issues channel

**Dave Simonds**

sounds weird reading that back, but id rather try once and be at the front of the queue, over thrying 5 times, racking up errors, pissing off Betfair &amp; still being beaten to market

---

## 2020-06-05 13:42:48 - issues channel

**Dave Simonds**

Hi everyone, been a member for a month or so, great insightful group, really happy to be here.



I do have a quick question….“TOO_MANY_REQUESTS” error.

This was introduced a few months back (just before the lockdown) and until now i’ve not really paid too much attention to it…. however its screwing me over big time now that racing is back. Your orders basically get denied if you attempt more than 1000 per second



I was just wondering is this something that applies across the board or is it only for non PC users? I remember someone once saying upper-tier PC users don’t pay a transactions charge and this kind of feels similar.



This really sucks because it looks like i am going to lose my only viable strategy, I’ve had a great 18 months out of it but to see things end because of a crappy rule change is a real shame

---

## 2020-06-02 14:51:23 - general channel

**Andrey Yunoshev**

fix it, now work without extra request. thanks for help

---

## 2020-06-02 14:11:19 - general channel

**Andrey Yunoshev**

&gt;flumine seems to be getting some users



this is a lot of work, and most importantly is done by a person who understands the subject

I, as usual, wrote the parser myself, and then I caught bugs - and then I decided to google it :)



in general, at the moment, it bothers me a little that everything is slow - it takes 2-3 hours to process a month of greyhounds records

on the other hand, it's almost 10 gigabytes of data :)



I have a couple more questions - you can somehow immediately get the name of the runners?

currently, I call client.betting_client.betting.list_market_catalogue in check_market_book



And second, for backtesting, I do not receive any market with CLOSED status - for getting WIN/LOSE runners status - but need dig more, possible my bug

---

## 2020-06-02 14:06:03 - issues channel

**liam**

the error was due to the dodgy dictcomp on a dictionary that is changing based on new markets, removing it should solve any further issues as far as i can see

---

## 2020-06-02 14:03:48 - issues channel

**Lee**

I’m just wondering if it’s going to move the error to somewhere else. Do you have a way to reproduce it?

---

## 2020-06-02 13:41:10 - issues channel

**liam**

i think its hard to replicate as the exception is occurring when the view gets changed when the the dictcomp is processing

---

## 2020-06-02 13:20:39 - issues channel

**liam**

[@U013R0E7SUV](@U013R0E7SUV) I have no idea how that can cause a RuntimeError, my understanding of dicts is that `items()` prevents this as it returns a list

---

## 2020-06-02 12:47:14 - issues channel

**liam**

Can you create an issue on github? Its a quick fix

---

## 2020-06-02 12:33:55 - issues channel

**Andrey Yunoshev**

```Exception in thread MarketStream_output_thread:

Traceback (most recent call last):

  File "/usr/local/lib/python3.7/site-packages/flumine/streams/marketstream.py", line 47, in handle_output

    block=True, timeout=self.streaming_timeout

  File "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py", line 178, in get

    raise Empty

_queue.Empty



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py", line 926, in _bootstrap_inner

    self.run()

  File "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py", line 870, in run

    self._target(*self._args, **self._kwargs)

  File "/usr/local/lib/python3.7/site-packages/flumine/streams/marketstream.py", line 51, in handle_output

    market_ids=self.flumine.markets.open_market_ids

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/markets.py", line 44, in open_market_ids

    return [m.market_id for m in self.markets.values() if not m.closed]

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/markets.py", line 40, in markets

    return {key: value for key, value in self._markets.items()}

  File "/usr/local/lib/python3.7/site-packages/flumine/markets/markets.py", line 40, in &lt;dictcomp&gt;

    return {key: value for key, value in self._markets.items()}

RuntimeError: dictionary changed size during iteration```

---

## 2020-06-02 09:12:42 - general channel

**Peter**

Should double counting of liquidity be "fixed"? In markets with lots of liquidity the effect is usually marginal. In thinner markets, I sometimes take the offered price if it looks like value and immediately see more dripped in (presumably by somebody with an algo that has counter view). So trying to fix double counting may simply add complexity to a situation in order to create results that are sometimes right, sometime wrong and sometimes don't matter.

---

## 2020-06-02 09:07:35 - general channel

**liam**

welcome a PR to fix that!

---

## 2020-06-01 19:27:59 - general channel

**liam**

Maintenance [https://forum.developer.betfair.com/forum/developer-program/announcements/31577-planned-maintenance-outage-tuesday-2nd-june-07-30-%E2%80%93-08-30-bst|tomorrow](https://forum.developer.betfair.com/forum/developer-program/announcements/31577-planned-maintenance-outage-tuesday-2nd-june-07-30-%E2%80%93-08-30-bst|tomorrow), 0730-0830 BST, usually a good excuse to test any error handling!

---

## 2020-06-01 12:11:09 - random channel

**Jonatan (skyw)**

[@UBS7QANF3](@UBS7QANF3) I've used vs code for python, I did not like the experience. For me everything is just not as good.

• Visuals, easier to navigate project explorer, notice errors in code

• Easier to refactor code

• Less buggy, Microsoft Language  Server just felt buggy and slow overall

• A lot better auto imports

---

## 2020-06-01 09:37:24 - random channel

**Troy Edwards**

This sounds right SrFabio

1. I place a high odds (or low odds) bet 

2. I then reduce this size calling the CancelBetfairOrder. In Australia min is $5 bet so I can cancel $4 of it to place a $1 bet

3. Then I change the odds such that the bet is matched using RepaceBetfairOrder

I have been doing this for a while (2 months - 200 bets a day) and have not got in trouble as [@UBS7QANF3](@UBS7QANF3) mentioned.  Maybe its ok in Oz :wink:



    '##################################################################################################

    '### PLACE LOW VALUE BETFAIR ORDER - IF SUCCESSFUL RETURNS BET ID                               ###

    '###    IF BET IS UNDER $5 LETS SAY $1                                                          ###

    '###        WE NEED TO SEND AN UNMATCHED LAY BET AT ODDS 1.01 FOR $5                            ###

    '###        WE THEN CALL CANCEL-ORDER AND REDUCE THIS LAY BET TO $1                             ###

    '###        WE THEN CALL REPLACE ORDER WITH OUR ORIGINAL ODDS                                   ###

    '##################################################################################################

    Public Function PlaceLowBetSizeBetfairOrder(sMarketID As String, sSelectionID As String, dBetOdds As Double, dBetSize As Double, BetSide As Side, BetPersistence As PersistenceType, Optional customerStrategyRef As String = Nothing) As ReplaceExecutionReport

        PlaceLowBetSizeBetfairOrder = Nothing

        Try

            Dim BetfairMinBet As Integer = 5

            Dim placeBet As PlaceExecutionReport = Nothing

            Select Case BetSide

                Case Side.BACK

                    'PLACE $5 BET AT HIGH ODDS WHICH WE BE UNMATCHED, SO $5 @ 1.01

                    placeBet = PlaceBetfairOrder(sMarketID, sSelectionID, "500", BetfairMinBet, BetSide, BetPersistence, customerStrategyRef)



                Case Side.LAY

                    'PLACE $5 BET AT LOW ODDS WHICH SO THAT IT WILL BE UNMATCHED, SO $5 @ 1.01

                    placeBet = PlaceBetfairOrder(sMarketID, sSelectionID, "1.01", BetfairMinBet, BetSide, BetPersistence, customerStrategyRef)

            End Select



            If placeBet.Status = ExecutionReportStatus.SUCCESS Then

                'NOW REDUCE THE BET FROM $5 @ 500 TO &lt;dBetSize&gt; @ 500 - THIS WILL KEEP THE SAME BET ID

                Dim myReduceSizeBet As CancelExecutionReport = THREAD_CancelBetfairOrder(sMarketID, placeBet.InstructionReports(0).BetId, BetfairMinBet - dBetSize)



                If myReduceSizeBet.Status = ExecutionReportStatus.SUCCESS Then

                    'NOW INCREASE THE ODDS BACK TO WHAT WAS ORIGINALLY REQUESTED SO &lt;dPriceOdds&gt; @ 500 TO &lt;dBetSize&gt; @ &lt;dPriceOdds&gt;



                    'NOTE WE WILL NOW GET A NEW BET ID AS WE ARE CHANGING THE QUEUE POSITION

                    Dim myReplaceBet As ReplaceExecutionReport = THREAD_ReplaceBetfairOrderChangeOdds(sMarketID, myReduceSizeBet.InstructionReports(0).Instruction.BetId, Math.Round(dBetOdds, 2))

                    PlaceLowBetSizeBetfairOrder = myReplaceBet

                End If

            End If



        Catch ex As System.Exception

            Debug.Print("PlaceLowBetSizeBetfairOrder " &amp; ex.Message)

            THREAD_BF.InUse = False

        End Try

    End Function

---

## 2020-05-31 20:29:27 - issues channel

**PeterLe**

Great many thanks guys; I haven't used the debugger before, So I need to go away and learn that and the definitions. Thanks again

---

## 2020-05-31 20:22:45 - issues channel

**Ruben**

Pycharm has a great debugger, it allows you to stop the code at any point and inspect the values of your variables, execute code line-by-line, step into your own functions and much more

---

## 2020-05-31 20:17:13 - issues channel

**liam**

Using the debugger you can interrogate the objects 

---

## 2020-05-31 20:16:56 - issues channel

**liam**

[https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html|https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html](https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html|https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html)

---

## 2020-05-31 20:08:33 - issues channel

**liam**

Debugger is your friend here, what IDE are you using?

---

## 2020-05-29 17:26:31 - general channel

**jhaa**

I am getting an internal error because I had exposure moved to a new account. Not sure how relevant this is but maybe this should be caught or is of interest to anyone:



  File "/home/code/venv/lib/python3.6/site-packages/betfairlightweight/resources/bettingresources.py", line 505, in &lt;listcomp&gt;

    self.orders = [RunnerBookOrder(**i) for i in orders] if orders else []

TypeError: __init__() missing 1 required positional argument: 'placedDate'

---

## 2020-05-27 20:30:16 - general channel

**Lee**

I just got one of the exceptions for something which i think works as a good warning. NotImplementedError on execute_replace :slightly_smiling_face:

---

## 2020-05-26 20:16:46 - issues channel

**Lee**

Using the S3MarketRecorder class i seem to be missing half the markets at the same venue compared to the betfair historic data. I'm not seeing any error messages. Any idea what might be happing here or how to debug it?



*Missing data counts*

```date	    venue	  betfair	recorder

21/04/2020	Albion	  16	    8

21/04/2020	Globe	  14	    7

21/04/2020	Menangle  16	    8```

*Using the following filters*

```market_recorder.S3MarketRecorder(

    market_filter=filters.streaming_market_filter(

        event_type_ids=["7"],

        market_types=["WIN"],

        country_codes=["US", "AU", "GB"],

    ),

    market_data_filter=streaming_market_data_filter(

        fields=[

            "EX_BEST_OFFERS_DISP",

            "EX_TRADED",

            "EX_TRADED_VOL",

            "EX_LTP",

            "EX_MARKET_DEF",

            "SP_TRADED",

            "SP_PROJECTED",

        ],

        ladder_levels=3,

    ),

    stream_class=datastream.DataStream,

    context={

        "local_dir": "/tmp",

        "bucket": "my-bucket-name",

        "force_update": False,

        "remove_file": True,

    },



)```

---

## 2020-05-24 15:51:12 - general channel

**Sandy Caskie**

Ok so I went on my account with Global Sports API and use the swagger editor to load data endpoints. This works fine but when I try to load the object names such as  "[https://www.globalsportsapi.com/ODATAv1/HorseRacingSample/performances](https://www.globalsportsapi.com/ODATAv1/HorseRacingSample/performances)?" (I removed my app key) I get an internal service error. Is this a problem at there end?

---

## 2020-05-24 13:26:50 - strategies channel

**VT**

[@UPMUFSGCR](@UPMUFSGCR) I work as a trader at Betfair for 3 years, full time, I see the market changing and improving every season, correcting the value of the odds according to the time and what happens on the field, without a doubt this is more difficult today than 3 years for those who trade live, I notice repetitive behaviors and this is what I try to automate with bots, but when I start investigating the past data (2 - 4 seasons) the market errors are small and the exorbitant 6% rate of Betfair consumes most of the "errors and gaps" in the market.

---

## 2020-05-23 00:18:28 - general channel

**VT**

Hi, I'm in the final stage of developing my BOT and now I need to automate and I still don't know how to do that, it's nothing exceptional just cheap json feed for live statistics + previous performance database + a little scraping.



I don't want to leave my computer on 24 hours a day running the system. Any suggestions for (cheap) servers that work and have no problem with the IP? ( my account is from Brazil).

---

## 2020-05-22 11:45:47 - strategies channel

**SrFabio**

For CFDs I used 2 different brokers, one would set a fixed fee for opening/closing orders which would make it much more expensive than the other for smaller orders, but had better spreads and a better service overall, the other was much better in terms of promotions and leverage - was also dodgy AF lol. Nowadays the rules have changed by some EU regularions and leverage is capped ar 1:30...I used to have 1:500 and 1:1000 xD

---

## 2020-05-22 11:37:21 - general channel

**Lee**

how did you debug it, using something like cprofilev?

---

## 2020-05-22 11:35:05 - general channel

**liam**

[@U013R0E7SUV](@U013R0E7SUV) [@UUCD6P13J](@UUCD6P13J) it was a very simple fix! It was basically the gc trying to collect the outout_queue which was just filling up with events, one line fix :wink: [https://github.com/liampauling/flumine/pull/168](https://github.com/liampauling/flumine/pull/168)

---

## 2020-05-22 09:47:25 - issues channel

**Newbie99**

I've never tried a 'FILL_AND_KILL' order before, so was just playing around, but I keep getting an error, suggesting the param's are wrong (FILL_OR_KILL works fine).



Params: {'marketId': '1.170485933', 'instructions': [{'orderType': 'LIMIT', 'selectionId': 28385567, 'side': 'BACK', 'limitOrder': {'price': 1000, 'persistenceType': 'LAPSE', 'size': 5, 'timeInForce': 'FILL_AND_KILL', 'minFillSize': 3}, 'customerOrderRef': '1.170485933_28385567_1'}], 'customerStrategyRef': 'manual_orders'}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}



Presumably FILL_AND_KILL is not the correct value to pass here, does anyone know what the correct one would be?

---

## 2020-05-21 08:02:29 - general channel

**liam**

can you share either order.simulated in a debugger or

```order.simulated.__dict__```

---

## 2020-05-20 11:55:37 - general channel

**liam**

shouldn't, get_price will return None if price isn't available, can you debug?

---

## 2020-05-20 11:52:47 - general channel

**liam**

error handling, that list could be empty

---

## 2020-05-19 21:31:01 - general channel

**Jonjonjon**

I have cloned the repo. And put it into my own branch. But I get this error when trying to push my new branch:



fatal: Authentication failed for '[https://github.com/liampauling/flumine.git/](https://github.com/liampauling/flumine.git/)'



Am I supposed to fork the code, and push to that?

---

## 2020-05-19 12:03:54 - strategies channel

**SrFabio**

Would you not be interested to see if different staking would considerably alter the profitability of your strategy? From what this book has shown (despite being a simple Montecarlo simulation) using a "better" staking approach allowed for a much sustainable bankroll growth rate  vs traditional flat stake of fixed percent stakes

---

## 2020-05-14 18:35:31 - issues channel

**brightcake**

seem to be getting this error 'errorCode': 'INVALID_SESSION_INFORMATION' when trying to initiate an instance of 'trading.betting.list_event_types'. It seems to work fine outside of an object but as soon as I encase it within a class it gives me this strange behaviour. Does anyone know what this could be?

---

## 2020-05-13 22:43:40 - issues channel

**Dave**

However in this case my lay is risk reducing, so it shouldn't error right? Should I be specifying my maxselectionexposure as a negative value?

---

## 2020-05-13 22:42:50 - issues channel

**Dave**

back selection A with a stake of 2, so exposure is -2. If I then lay it at odds of, say, 1.5, my liability on this lay is 1. If I have max selection exposure as say, 2, then it does: if -2 - 1 &lt; -2 then error.

---

## 2020-05-12 20:21:44 - general channel

**Jonjonjon**

[@U4H19D1D2](@U4H19D1D2) Could we update HistoricalGeneratorStream to be able to decompress bz2 files on the fly? It's not a big change:



```    def _read_loop(self):



        self._running = True



        with _open(self.directory) as f:

            for update in f:

                if self.listener.on_data(update) is False:

                    # if on_data returns an error stop the stream and raise error

                    self.stop()

                    raise ListenerError("HISTORICAL", update)

                if not self._running:

                    break

                else:

                    yield self.listener.snap()

            else:

                # if f has finished, also stop the stream

                self.stop()





def _open(filename):

    if filename.endswith('.bz2'):

        [http://logger.info|logger.info](http://logger.info|logger.info)('Opening bz2 file: %s' % filename)

        return bz2.open(filename, 'rb')

    else:

        return open(filename, 'r')```



---

## 2020-05-12 14:51:06 - general channel

**liam**

playing with fire if you handle in the same loop, you need to handle errors from the stream and you would be blocking so risk the queue filling up, do you use the err streaming example? [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py)

---

## 2020-05-11 17:09:28 - general channel

**liam**

FYI flumine dev branch can now handle place/cancel simulated execution, added an example strategy, lots likely to change / beware of bugs

---

## 2020-05-11 10:01:54 - issues channel

**liam**

print(order._data) or inspect it in the debugger to see what the error is

---

## 2020-05-11 09:58:29 - general channel

**liam**

yeah you can get a 503, which is basically everything is fucked and we will send you updates when its fixed, bflw handles this

---

## 2020-05-08 09:21:53 - issues channel

**liam**

If so could you share a market? Want to try and debug this issue, I am hoping there is an easy fix

---

## 2020-05-07 12:59:01 - general channel

**D C**

5 minutes ago. NG says OPEN, stream reports OPEN on first image, the suspended immediately afterwards. Thats verified stepping through debugger

---

## 2020-05-07 12:30:15 - general channel

**D C**

Is anyone getting errors in market status over the stream API for Hanover racing today? I want to rule out an issue in my code. No other locations affected, just Hanover reporting ALL races suspended. They are not suspended and this is confirmed through site login and API-NG. Anyone else seeing this too?

---

## 2020-05-06 14:50:56 - random channel

**footysystems**

The site own used to fix it but it's been out for 5 weeks and no sign of coming back no contact with owner or anything

---

## 2020-05-06 10:40:08 - issues channel

**Newbie99**

If I'm understanding the docs correctly, this is likely an error at Betfair's end, not mine, so there's not much I can do about it, other than wait it out!

---

## 2020-05-06 10:39:40 - issues channel

**Newbie99**

Has anyone else been getting error messages this morning?

---

## 2020-05-06 10:39:29 - issues channel

**Newbie99**

`ERROR:betfairlightweight.streaming.listener:[Subscription: None] UNEXPECTED_ERROR: Unknown error`

`ERROR:streaming_errors:MarketStreaming run error`

`Traceback (most recent call last):`

  `File "D:\Python37\webpages\streaming_errors.py", line 46, in run`

    `self.stream.start()`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 59, in start`

    `self._read_loop()`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 209, in _read_loop`

    `self._data(received_data)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 250, in _data`

    `raise ListenerError(self.listener.connection_id, received_data)`

`betfairlightweight.exceptions.ListenerError: connection_id: XXXXXXX, data: {"op":"status","statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"Unknown error","connectionClosed":true,"connectionId":"XXXXXXX"}`

---

## 2020-05-06 08:17:03 - random channel

**Mo**

Haven’t had any problems like that. There’s a problem with sound on the TRX40 chipset which means my rear microphone jack doesn’t work nor my sound front panel but it sounds like it’ll be fixed in kernel 5.7 :crossed_fingers:

---

## 2020-05-03 22:46:42 - random channel

**Jonatan (skyw)**

Yeah I hardcoded the "seconds", did not bother to lookup how to get the stats into variables.



You have to do you own calculations  based on your time. and size of your data. I should fix that ...

---

## 2020-05-02 07:40:24 - general channel

**Unknown**

if you include logging (`logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))`) the error tells you the problem, add `EX_MARKET_DEF` to the filter

---

## 2020-04-30 10:16:40 - strategies channel

**AP**

This may not relate at all but I did an internship at an options market making firm and I found that they barely used ML models at all, most of their systems and strategies were designed from good old fashioned empirical research and trial and error

---

## 2020-04-29 10:19:35 - general channel

**Cagdas Yetkin**

```"statusCode":"FAILURE",

"errorCode":"NOT_AUTHORIZED",

"errorMessage":"AppKey is not configured for service"```

when I do a test run using the link you gave above, I am getting this kind of error. what to do in this case? is it a paid service?

---

## 2020-04-25 21:21:22 - issues channel

**Jonjonjon**

I've had that error before if I re-run the same code within  a Python process in an interactive tool, such as Jupyter. e.g. when jumping around and executing different code snippets. But it went away when I ran the code as a standalone script or application.

---

## 2020-04-25 20:31:13 - issues channel

**liam**

Just searched that error and jupyter comes up as a potential reason, wouldn’t be surprised if it’s occurring with spyder as well 

---

## 2020-04-25 19:43:03 - issues channel

**user34**

File "/anaconda3/lib/python3.6/site-packages/betfairlightweight/streaming/listener.py", line 91, in __init__

    super(StreamListener,self).__init__(max_latency)



TypeError: super(type, obj): obj must be an instance or subtype of type

---

## 2020-04-25 19:42:55 - issues channel

**user34**

I have just updated to version 2.3.0 and now get the following new error:

---

## 2020-04-24 09:48:14 - random channel

**Jonjonjon**

I had those errors a few weeks ago when my buggy code did not shutdown processes correctly.

---

## 2020-04-24 08:38:17 - general channel

**liam**

:slightly_smiling_face: want to push people in handling the errors or the thread will just die with the user non the wiser

---

## 2020-04-24 08:10:09 - random channel

**Newbie99**

Just going back to the high latency warnings, I got some strange ones last night (which might just be a limitation of my machine, in which case so be it, but wanted to get the opinion of others):



`CRITICAL:streaming_errors:MarketStreaming run error`

`MemoryError`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "D:\Python37\lib\site-packages\betfairlightweight\resources\bettingresources.py", line 504, in __init__`

    `self.ex = RunnerBookEX(**ex) if ex else None`

  `File "D:\Python37\lib\site-packages\betfairlightweight\resources\bettingresources.py", line 377, in __init__`

    `self.available_to_lay = [PriceSize(**i) for i in availableToLay]`

`MemoryError`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "D:\Python37\webpages\streaming_errors.py", line 46, in run`

    `self.stream.start()`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 59, in start`

    `self._read_loop()`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 209, in _read_loop`

    `self._data(received_data)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 248, in _data`

    `if self.listener.on_data(received_data) is False:`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\listener.py", line 127, in on_data`

    `self._on_change_message(data, unique_id)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\listener.py", line 167, in _on_change_message`

    `self.stream.on_update(data)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\stream.py", line 59, in on_update`

    `self._process(data[self._lookup], publish_time)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\stream.py", line 153, in _process`

    `self.unique_id, market_book, self._lightweight`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 229, in create_resource`

  `File "D:\Python37\lib\site-packages\betfairlightweight\resources\bettingresources.py", line 585, in __init__`

    `self.runners = [RunnerBook(**i) for i in kwargs.get("runners")]`

`MemoryError`

---

## 2020-04-18 16:57:22 - general channel

**liam**

Debug logs will tell you 

---

## 2020-04-18 16:55:12 - general channel

**liam**

Set logging to debug so you can see all the updates coming through 

---

## 2020-04-17 17:27:23 - general channel

**jhaa**

is what I did somewhere to debug at some point

---

## 2020-04-17 16:26:04 - random channel

**Amanda**

(Sharecast News) - Paddy Power Betfair owner Flutter Entertainment said revenue had been more resilient than expected despite the cancellation of many sports due to the coronavirus pandemic, bolstered by a continuation of US and Australian horse racing.

Total revenue rose 16% to ?547m for the three months to March 31. Racing in Ireland and the UK was suspended last month, leading to a 32% slump in revenue since the ban was imposed, Flutter said on Friday.



The company said last month it could take a hit of up to ?110m to earnings if sports fixing restrictions due to the coronavirus remain in place until the end of August. It generated about 78% of its revenues through bets placed on global sporting events.



Flutter last week said said its final dividend would be paid out in shares rather than cash as it sought to bolster its finances in the face of the pandemic. The company had planned to pay 133p a share.



Flutter has seen its share price slump by 25% as sports fixtures were cancelled and the government imposed a lockdown forcing the closure of non-essential shops.

---

## 2020-04-14 20:37:38 - general channel

**Lee**

Yeah, it was okay. Lost 26p. Had a few double bets i need to fix. Will fix that and try again tomorrow evening

---

## 2020-04-13 16:54:03 - issues channel

**Josh**

[Errno 13] Permission denied error still appears

---

## 2020-04-13 16:47:46 - issues channel

**Josh**

Just done a quick search and found a similar problem with historic stream data. Had the "[Errno 13] Permission denied:" error. File has been unzipped and full path passed in to code. Any thoughts appreciated. Cheers

---

## 2020-04-11 21:32:01 - general channel

**Ruben**

I have one quick question: When trying to log in, I am this exception from the api "AUTHORIZED_ONLY_FOR_DOMAIN_ES"

---

## 2020-04-10 18:58:08 - strategies channel

**Christian Tox**

Could do stuff like that or scrape other sites, at cost of delay and not error proof

---

## 2020-04-09 07:02:34 - issues channel

**JK**

Thanks a lot! It's now reading it, but getting another issue:

```INFO:betfairlightweight.streaming.stream:[Stream: HISTORICAL]: "MarketStream" created

Traceback (most recent call last):

  File "C:\Users\jhgwa\Documents\101-layer\stream_[http://listener.py|listener.py](http://listener.py|listener.py)", line 74, in &lt;module&gt;

    stream.start()

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://betfairstream.py|betfairstream.py](http://betfairstream.py|betfairstream.py)", line 286, in start

    self._read_loop()

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://betfairstream.py|betfairstream.py](http://betfairstream.py|betfairstream.py)", line 294, in _read_loop

    if self.listener.on_data(update) is False:

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://listener.py|listener.py](http://listener.py|listener.py)", line 115, in on_data

    self._on_change_message(data, unique_id)

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://listener.py|listener.py](http://listener.py|listener.py)", line 148, in _on_change_message

    self.stream.on_update(data)

  File "C:\Users\jhgwa\AppData\Local\Continuum\anaconda3\lib\site-packages\betfairlightweight\streaming\[http://stream.py|stream.py](http://stream.py|stream.py)", line 51, in on_update

    if latency &gt; self._max_latency:

TypeError: '&gt;' not supported between instances of 'float' and 'NoneType'```

Have you seen this one before? To do with the `max_latency` param?

---

## 2020-04-09 06:53:54 - issues channel

**JK**

still get the same permission denied error after unzipping :disappointed:

---

## 2020-04-09 06:41:30 - issues channel

**JK**

Hey guys, ive got some historic stream data in bz2 files, 1 per market, but im having trouble reading it. Im using the example script at [https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py)



My main code looks like this



```# create listener

listener = HistoricalListener(max_latency=None)



# create historical stream, update directory to file location

stream = trading.streaming.create_historical_stream(

    directory='../data/Jan/1/29636351',

    listener=listener,

)



# start stream

stream.start()```

But I am getting the error `[Errno 13] Permission denied: '../data/Jan/1/29636351` , anyone else had this issue? Have googled to no avail. Is this the correct way to write the data to txt?

---

## 2020-04-08 18:27:03 - issues channel

**Christian Tox**

Yea that's what I expected too. If I



`print(trading.session_token)`



it returns the correct token. But trading.login_interactive still gives same error

---

## 2020-04-08 18:22:09 - issues channel

**Christian Tox**

Hmm I go:

`session_token = "token string"`

`trading = betfairlightweight.APIClient(username= "username", password="password", app_key="app key")`

`trading.set_session_token(session_token=session_token)`

`trading.login_interactive()`



And get it again:

`betfairlightweight.exceptions.LoginError: API login: DANISH_AUTHORIZATION_REQUIRED`

---

## 2020-04-08 14:46:59 - issues channel

**Christian Tox**

Hi, to be clear, I did this upon receiving the error:



`trading = betfairlightweight.APIClient(username="", password="", app_key="")` 

`trading.login_interactive()`



then got error



`betfairlightweight.exceptions.LoginError: API login: DANISH_AUTHORIZATION_REQUIRED`



thank you.

---

## 2020-04-08 14:39:39 - issues channel

**Christian Tox**

Hello totally new, sorry for newbie question: trying to do interactive login from Denmark and get "betfairlightweight.exceptions.LoginError: API login: DANISH_AUTHORIZATION_REQUIRED".



Looking at the developer docs I found that: "*Please note:* *Danish residents* cannot use the Non-Interactive (bot) login method due to the NEMID requirement which is only supported by the [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Interactive+Login+-+Desktop+Application|Interactive Login - Desktop Application](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Interactive+Login+-+Desktop+Application|Interactive Login - Desktop Application) method". [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login)



 Is it still possible for me to use betfairlightweight ?

---

## 2020-04-06 19:15:25 - general channel

**Jonjonjon**

Is there a problem with Horse Racing on Betfair today? If I click on any of the US or AUS races, I get a 404 error

---

## 2020-04-05 20:28:30 - issues channel

**Unknown**

No worries. The historic data API is a bit cryptic with its error messages unfortunately 

---

## 2020-04-05 20:26:03 - issues channel

**Max**

I would have expected an error message like "No data available on your account"; `ngErrorRedirect` will do

---

## 2020-04-04 23:59:31 - issues channel

**Max**

Hi all, could anyone help me debug this error? I'm running the historical examples from [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py). Everything works until `get_file_list`: [https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py#L38-L52](https://github.com/liampauling/betfair/blob/master/examples/examplehistoricdata.py#L38-L52)



It fails with this error; any ideas?



```---------------------------------------------------------------------------

JSONDecodeError                           Traceback (most recent call last)

/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/historic.py in request(self, method, params, session)

    164         try:

--&gt; 165             response_data = response.json()

    166         except ValueError:



/usr/local/lib/python3.7/site-packages/requests/models.py in json(self, **kwargs)

    896                     pass

--&gt; 897         return complexjson.loads(self.text, **kwargs)

    898 



/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/__init__.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)

    347             parse_constant is None and object_pairs_hook is None and not kw):

--&gt; 348         return _default_decoder.decode(s)

    349     if cls is None:



/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py in decode(self, s, _w)

    336         """

--&gt; 337         obj, end = self.raw_decode(s, idx=_w(s, 0).end())

    338         end = _w(s, end).end()



/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/decoder.py in raw_decode(self, s, idx)

    354         except StopIteration as err:

--&gt; 355             raise JSONDecodeError("Expecting value", s, err.value) from None

    356         return obj, end



JSONDecodeError: Expecting value: line 4 column 1 (char 6)



During handling of the above exception, another exception occurred:



InvalidResponse                           Traceback (most recent call last)

&lt;ipython-input-40-107c6aa3e9f7&gt; in &lt;module&gt;

     11     market_types_collection=["WIN", "PLACE"],

     12     countries_collection=["GB", "IE"],

---&gt; 13     file_type_collection=["M"],

     14 )

     15 print(file_list)



/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/historic.py in get_file_list(self, sport, plan, from_day, from_month, from_year, to_day, to_month, to_year, event_id, event_name, market_types_collection, countries_collection, file_type_collection, session)

    114         params = clean_locals(locals())

    115         method = 'DownloadListOfFiles'

--&gt; 116         (response, elapsed_time) = self.request(method, params, session)

    117         return response

    118 



/usr/local/lib/python3.7/site-packages/betfairlightweight/endpoints/historic.py in request(self, method, params, session)

    165             response_data = response.json()

    166         except ValueError:

--&gt; 167             raise InvalidResponse(response.text)

    168 

    169         return response_data, elapsed_time



InvalidResponse: Invalid response received: 





[!DOCTYPE html](!DOCTYPE html)



&lt;html&gt;

&lt;head&gt;

    &lt;meta name="viewport" content="width=device-width" /&gt;

    &lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

    &lt;div&gt; 

        Error

    &lt;/div&gt;

&lt;/body&gt;

&lt;/html&gt;```

---

## 2020-04-03 15:29:29 - issues channel

**Josh**

Yes installed and unfortunately had the same error, cheers liam I will keep checking back

---

## 2020-04-03 15:20:04 - issues channel

**Josh**

Hi all, hope everyone is safe and well. 



When trying to pip install betfairlightweight I get an error reading



Failed building wheel for ciso8601

Failed building wheel for ujson



Just wondered if anyone could shed some light on this

---

## 2020-04-03 09:40:42 - general channel

**Oliver Varney**

does that error also throw when you put sizes through that that are like 3 decimal places and longer ?

---

## 2020-04-03 09:38:56 - general channel

**liam**

2.009 will give you that error

---

## 2020-04-03 09:38:35 - general channel

**Oliver Varney**

Is £2 the smallest order amount you can put through? If you have partials left over that are smaller then that will you get an 'INVALID_BET_SIZE' error. Or does that error throw in different circumstances ?

---

## 2020-04-02 12:40:20 - issues channel

**D C**

If you want highly accurate position info I have found the GPS coords to exhibit significant error at times. On a close finish the data is often useless inside the final half furlong. In particular there often seems to be a periodically constant offset present in some of the GPS coords. I have recorded quite a few videos of races where the final GPS result is not accurate at all, but the market does tell you when that is the case.

---

## 2020-04-02 12:20:45 - general channel

**Lee**

The error is telling you what’s wrong 

---

## 2020-04-02 12:18:56 - general channel

**Jeff**

On line 66 of example do I need to point it to the historical data file? These are the errors I am getting: C:\Users\Jeff\PycharmProjects\GitHubExample\venv\Scripts\python.exe C:/Users/Jeff/PycharmProjects/GitHubExample/GitHubExample.py

INFO:betfairlightweight.streaming.listener:Register: marketSubscription 0

INFO:betfairlightweight.streaming.stream:[Stream: 0]: "HistoricalStream" created

Traceback (most recent call last):

  File "C:/Users/Jeff/PycharmProjects/GitHubExample/GitHubExample.py", line 71, in &lt;module&gt;

    stream.start()

  File "C:\Users\Jeff\PycharmProjects\GitHubExample\venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 295, in start

    self._read_loop()

  File "C:\Users\Jeff\PycharmProjects\GitHubExample\venv\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 301, in _read_loop

    with open(self.directory, "r") as f:

FileNotFoundError: [Errno 2] No such file or directory: '/Users/liampauling/Downloads/Sites 3/xdw/api/c0a022d4-3460-41f1-af12-a0b68b136898/BASIC-1.132153978'



Process finished with exit code 1

---

## 2020-04-02 11:04:47 - general channel

**Lee**

There will also be lots of bugs along the way where there won’t be any tutorials, thats the art of programming.

Learning how the language works and how to read libraries helps

---

## 2020-03-31 10:20:09 - issues channel

**liam**

just use the MarketRecorder if you want to save locally but I will be honest if you really need programming experience (basic is fine) to use these libraries. The errors are telling you the problem

---

## 2020-03-31 10:17:08 - issues channel

**mandelbot**

```Doh! Thanks, that was dumb. Although now I'm getting these: Traceback (most recent call last):

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\marketrecorder.py", line 46, in &lt;module&gt;

    framework.add_strategy(strategy)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\flumine\baseflumine.py", line 66, in add_strategy

    self.strategies(strategy)  # store in strategies

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\flumine\strategy\strategy.py", line 26, in _call_

    strategy.add()

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\strategies\marketrecorder.py", line 155, in add

    self.s3.head_bucket(Bucket=self._bucket)  # validate bucket/access

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\client.py", line 316, in _api_call

    return self._make_api_call(operation_name, kwargs)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\client.py", line 612, in _make_api_call

    http, parsed_response = self._make_request(

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\client.py", line 632, in _make_request

    return self._endpoint.make_request(operation_model, request_dict)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\endpoint.py", line 102, in make_request

    return self._send_request(request_dict, operation_model)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\endpoint.py", line 132, in _send_request

    request = self.create_request(request_dict, operation_model)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\endpoint.py", line 115, in create_request

    self._event_emitter.emit(event_name, request=request,

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\hooks.py", line 356, in emit

    return self._emitter.emit(aliased_event_name, **kwargs)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\hooks.py", line 228, in emit

    return self._emit(event_name, kwargs)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\hooks.py", line 211, in _emit

    response = handler(**kwargs)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\signers.py", line 90, in handler

    return self.sign(operation_name, request)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\signers.py", line 160, in sign

    auth.add_auth(request)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\botocore\auth.py", line 357, in add_auth

    raise NoCredentialsError

botocore.exceptions.NoCredentialsError: Unable to locate credentials```

---

## 2020-03-31 09:53:24 - issues channel

**mandelbot**

So im trying to run the example marketrecorder.py but I get the following error:

Traceback (most recent call last):

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\marketrecorder.py", line 46, in &lt;module&gt;

    framework.add_strategy(strategy)

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\flumine\baseflumine.py", line 66, in add_strategy

    self.strategies(strategy)  # store in strategies

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\lib\site-packages\flumine\strategy\strategy.py", line 26, in _call_

    strategy.add()

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\strategies\marketrecorder.py", line 154, in add

    super().add()

  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python38\Lib\site-packages\flumine\examples\strategies\marketrecorder.py", line 37, in add

    raise OSError("File dir %s does not exist" % self.local_dir)

OSError: File dir /tmp does not exist



I tried to create the dir in question but get the same. What am I missing? Appologies for the dumb question, I'm new to python and coding and am still trying to understand how this library works.

---

## 2020-03-30 13:02:45 - general channel

**liam**

```    def _get_cleared_orders(self, event, client):

        from_record = 0

        while True:

            try:

                cleared_orders = client.betting_client.betting.list_cleared_orders(

                    bet_status="SETTLED",

                    from_record=from_record,

                    market_ids=[event.market_id],

                    customer_strategy_refs=[config.hostname],

                )

            except BetfairError as e:

                logger.error(

                    "_get_cleared_orders error",

                    extra={"trading_function": "list_cleared_orders", "response": e},

                    exc_info=True,

                )

                time.sleep(10)

                self.equine.account_queue.put(event)

                return



            [http://logger.info|logger.info](http://logger.info|logger.info)(

                "{0} cleared orders found, more available: {1}".format(

                    len(cleared_orders.orders), cleared_orders.more_available

                )

            )



            self.equine.log_control(ClearedOrdersEvent(event.market_id, cleared_orders))

            self.equine.handler_queue.put(

                ClearedOrdersEvent(event.market_id, cleared_orders)

            )



            from_record += 1000

            if not cleared_orders.more_available:

                break

        return len(cleared_orders.orders)```

---

## 2020-03-26 16:22:05 - issues channel

**brightcake**

`Traceback (most recent call last):`

  `File "C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\historic.py", line 199, in request`

    `response_json = json.loads(response.content.decode("utf-8"))`

`ValueError: Expected object or value`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

  `File "C:\Users\user\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py", line 3319, in run_code`

    `exec(code_obj, self.user_global_ns, self.user_ns)`

  `File "&lt;ipython-input-10-03764898e36f&gt;", line 14, in &lt;module&gt;`

    `file_type_collection=["M"]`

  `File "C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\historic.py", line 148, in get_file_list`

    `(response, response_json, elapsed_time) = self.request(method, params, session)`

  `File "C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\historic.py", line 201, in request`

    `raise InvalidResponse(response.text)`

`betfairlightweight.exceptions.InvalidResponse: Invalid response received:` 

`[!DOCTYPE html](!DOCTYPE html)`

`&lt;html&gt;`

`&lt;head&gt;`

    `&lt;meta name="viewport" content="width=device-width" /&gt;`

    `&lt;title&gt;ngErrorRedirect&lt;/title&gt;`

`&lt;/head&gt;`

`&lt;body&gt;`

    `&lt;div&gt;` 

        `Error`

    `&lt;/div&gt;`

`&lt;/body&gt;`

`&lt;/html&gt;`

---

## 2020-03-26 16:12:09 - issues channel

**liam**

full error?

---

## 2020-03-26 16:08:32 - general channel

**mandelbot**

when I try to run the above example I get the following error. Traceback (most recent call last):

  File "C:\Users\Administrator\Desktop\Python\marketrecorder.py", line 8, in &lt;module&gt;

    from strategies.marketrecorder import S3MarketRecorder

ModuleNotFoundError: No module named 'strategies'

am I on an incorrect version or something?

---

## 2020-03-26 15:40:12 - issues channel

**brightcake**

Can't seem to use the get_file_list method - tried using the example in the github repo and get a betfairlightweight.exceptions.InvalidResponse: Invalid response received: error

---

## 2020-03-23 22:25:59 - issues channel

**Jonatan (skyw)**

`error: Microsoft Visual C++ 14.0 is required. Get it with "Build Tools for Visual Studio": [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)`

---

## 2020-03-23 22:22:59 - issues channel

**Jason**

Ive been struggling to install Betfairlightweight for the last few days. Im using pycharm



`Collecting betfairlightweight==2.2.0`

  `Using cached betfairlightweight-2.2.0-py3-none-any.whl (60 kB)`

`Collecting ujson==2.0.1`

  `Using cached ujson-2.0.1.tar.gz (7.1 MB)`

  `Installing build dependencies: started`

  `Installing build dependencies: finished with status 'done'`

  `Getting requirements to build wheel: started`

  `Getting requirements to build wheel: finished with status 'done'`

  `Installing backend dependencies: started`

  `Installing backend dependencies: finished with status 'done'`

    `Preparing wheel metadata: started`

    `Preparing wheel metadata: finished with status 'done'`

`Collecting requests&lt;=2.23.0`

  `Using cached requests-2.23.0-py2.py3-none-any.whl (58 kB)`

`Collecting ciso8601==2.1.3`

  `Using cached ciso8601-2.1.3.tar.gz (15 kB)`

`Requirement already satisfied: certifi&gt;=2017.4.17 in c:\users\justin\anaconda3\envs\build\lib\site-packages (from requests&lt;=2.23.0-&gt;betfairlightweight==2.2.0) (2019.11.28)`

`Collecting chardet&lt;4,&gt;=3.0.2`

  `Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)`

`Collecting urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1`

  `Using cached urllib3-1.25.8-py2.py3-none-any.whl (125 kB)`

`Collecting idna&lt;3,&gt;=2.5`

  `Using cached idna-2.9-py2.py3-none-any.whl (58 kB)`

`Building wheels for collected packages: ujson, ciso8601`

  `Building wheel for ujson (PEP 517): started`

  `Building wheel for ujson (PEP 517): finished with status 'error'`

  `Building wheel for ciso8601 (setup.py): started`

  `Building wheel for ciso8601 (setup.py): finished with status 'error'`

  `Running setup.py clean for ciso8601`

`Failed to build ujson ciso8601`



  `ERROR: Command errored out with exit status 1:`

   `command: 'C:\Users\Justin\anaconda3\envs\Build\python.exe' 'C:\Users\Justin\AppData\Roaming\Python\Python37\site-packages\pip\_vendor\pep517\_in_process.py' build_wheel 'C:\Users\Justin\AppData\Local\Temp\tmpswrbz18z'`

       `cwd: C:\Users\Justin\AppData\Local\Temp\pycharm-packaging\ujson`

  `Complete output (5 lines):`

  `running bdist_wheel`

  `running build`

  `running build_ext`

  `building 'ujson' extension`

  `error: Microsoft Visual C++ 14.0 is required. Get it with "Build Tools for Visual Studio": [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)`

  `----------------------------------------`

  `ERROR: Failed building wheel for ujson`

  `ERROR: Command errored out with exit status 1:`

   `command: 'C:\Users\Justin\anaconda3\envs\Build\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '"'"'C:\\Users\\Justin\\AppData\\Local\\Temp\\pycharm-packaging\\ciso8601\\setup.py'"'"'; __file__='"'"'C:\\Users\\Justin\\AppData\\Local\\Temp\\pycharm-packaging\\ciso8601\\setup.py'"'"';f=getattr(tokenize, '"'"'open'"'"', open)(__file__);code=f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' bdist_wheel -d 'C:\Users\Justin\AppData\Local\Temp\pip-wheel-_l78ovpi'`

       `cwd: C:\Users\Justin\AppData\Local\Temp\pycharm-packaging\ciso8601\`

  `Complete output (14 lines):`

  `running bdist_wheel`

  `running build`

  `running build_py`

  `package init file 'ciso8601\__init__.py' not found (or not a regular file)`

  `creating build`

  `creating build\lib.win-amd64-3.7`

  `creating build\lib.win-amd64-3.7\ciso8601`

  `copying ciso8601\__init__.pyi -&gt; build\lib.win-amd64-3.7\ciso8601`

  `copying ciso8601\py.typed -&gt; build\lib.win-amd64-3.7\ciso8601`

  `warning: build_py: byte-compiling is disabled, skipping.`

  

  `running build_ext`

  `building 'ciso8601' extension`

  `error: Microsoft Visual C++ 14.0 is required. Get it with "Build Tools for Visual Studio": [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)`

  `----------------------------------------`

  `ERROR: Failed building wheel for ciso8601`

`ERROR: Could not build wheels for ujson which use PEP 517 and cannot be installed directly`

---

## 2020-03-22 21:25:42 - issues channel

**Newbie99**

I'm getting the following:



  `File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\betting.py", line 157, in list_market_catalogue`

    `(response, elapsed_time) = self.request(method, params, session)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 51, in request`

    `check_status_code(response)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\utils.py", line 17, in check_status_code`

    `raise StatusCodeError(response.status_code)`

`betfairlightweight.exceptions.StatusCodeError: Status code error: 400`



Which I'm guessing, is possibly due to to large a single listMarketCatalogue call on startup to get runner names (I can't see the error code in the docs, but that would make sense).



I was trying to keep the calls down to a minimum, but what is the best way to avoid this, is it just a case of call once per market on startup (once started is fine as then I only need to call on any runner changes)?

---

## 2020-03-21 14:02:26 - issues channel

**kense**

Tried to 'pip install --upgrade betfairlightweight' after it had installed with the 'install flumine' but got the same error.

---

## 2020-03-21 14:00:53 - issues channel

**kense**

"ERROR: Could not build wheels for ujson which use PEP 517 and cannot be installed directly"

---

## 2020-03-21 13:59:50 - issues channel

**kense**

Just for info, I tried to "pip install betfairlightweight" and found that it returned an error when attempting to build the wheel for ujson (it was collecting ujson-2.0.1). When I did a "pip install flumine" afterwards, it installed ujson without any issues, but it was version 1.35 (and also included betfairlightweight 2.1.0 rather than 2.2.0). Apologies if you're already aware...

---

## 2020-03-19 18:11:55 - strategies channel

**Fab**

[https://www.amazon.co.uk/Kelong-Kings-Confessions-prolific-match-fixer/dp/9630891220/ref=sr_1_1?keywords=kelong+kings&amp;qid=1584641507&amp;sr=8-1](https://www.amazon.co.uk/Kelong-Kings-Confessions-prolific-match-fixer/dp/9630891220/ref=sr_1_1?keywords=kelong+kings&amp;qid=1584641507&amp;sr=8-1)

---

## 2020-03-19 18:10:05 - strategies channel

**Fab**

I recently read the book Kelong Kings, it’s about football match fixing orchestrated by Singaporean/Chinese syndicates.



It’s quite possible in Asia (if you have the right contacts) to bet huge sums of money even on lowly matches. So those figures you mention are not surprising.



A far cry from the European bookies we’re used to dealing with :grinning:

---

## 2020-03-19 17:43:10 - strategies channel

**Mo**

```from bisect import bisect_left, bisect_right

from decimal import Decimal

from typing import Optional, Tuple, Union



BETFAIR_TICKS = [

    1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09,  1.1, 1.11, 1.12, 1.13, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19,

    1.2,  1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29,  1.3, 1.31, 1.32, 1.33, 1.34, 1.35, 1.36, 1.37, 1.38,

    1.39, 1.4,  1.41, 1.42, 1.43, 1.44, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5,  1.51, 1.52, 1.53, 1.54, 1.55, 1.56, 1.57,

    1.58, 1.59, 1.6,  1.61, 1.62, 1.63, 1.64, 1.65, 1.66, 1.67, 1.68, 1.69, 1.7,  1.71, 1.72, 1.73, 1.74, 1.75, 1.76,

    1.77, 1.78, 1.79, 1.8,  1.81, 1.82, 1.83, 1.84, 1.85, 1.86, 1.87, 1.88, 1.89, 1.9,  1.91, 1.92, 1.93, 1.94, 1.95,

    1.96, 1.97, 1.98, 1.99, 2,    2.02, 2.04, 2.06, 2.08, 2.1,  2.12, 2.14, 2.16, 2.18, 2.2,  2.22, 2.24, 2.26, 2.28,

    2.3,  2.32, 2.34, 2.36, 2.38, 2.4,  2.42, 2.44, 2.46, 2.48, 2.5,  2.52, 2.54, 2.56, 2.58, 2.6,  2.62, 2.64, 2.66,

    2.68, 2.7,  2.72, 2.74, 2.76, 2.78, 2.8,  2.82, 2.84, 2.86, 2.88, 2.9,  2.92, 2.94, 2.96, 2.98, 3,    3.05, 3.1,

    3.15, 3.2,  3.25, 3.3,  3.35, 3.4,  3.45, 3.5,  3.55, 3.6,  3.65, 3.7,  3.75, 3.8,  3.85, 3.9,  3.95, 4,    4.1,

    4.2,  4.3,  4.4,  4.5,  4.6,  4.7,  4.8,  4.9,  5,    5.1,  5.2,  5.3,  5.4,  5.5,  5.6,  5.7,  5.8,  5.9,  6,

    6.2,  6.4,  6.6,  6.8,  7,    7.2,  7.4,  7.6,  7.8,  8,    8.2,  8.4,  8.6,  8.8,  9,    9.2,  9.4,  9.6,  9.8,

    10,   10.5, 11,   11.5, 12,   12.5, 13,   13.5, 14,   14.5, 15,   15.5, 16,   16.5, 17,   17.5, 18,   18.5, 19,

    19.5, 20,   21,   22,   23,   24,   25,   26,   27,   28,   29,   30,   32,   34,   36,   38,   40,   42,   44,

    46,   48,   50,   55,   60,   65,   70,   75,   80,   85,   90,   95,   100,  110,  120,  130,  140,  150,  160,

    170,  180,  190,  200,  210,  220,  230,  240,  250,  260,  270,  280,  290,  300,  310,  320,  330,  340,  350,

    360,  370,  380,  390,  400,  410,  420,  430,  440,  450,  460,  470,  480,  490,  500,  510,  520,  530,  540,

    550,  560,  570,  580,  590,  600,  610,  620,  630,  640,  650,  660,  670,  680,  690,  700,  710,  720,  730,

    740,  750,  760,  770,  780,  790,  800,  810,  820,  830,  840,  850,  860,  870,  880,  890,  900,  910,  920,

    930,  940,  950,  960,  970,  980,  990,  1000

]

BETFAIR_DECIMAL_TICKS = [round(Decimal(t), 2) for t in BETFAIR_TICKS]



class Side(Enum):

    BACK = 'back'

    LAY = 'lay'



    @property

    def other_side(self):

        other_side = Side.LAY if self is Side.BACK else Side.BACK



        return other_side



def make_price_betfair_valid(price: Union[Decimal, float, int], side: Side) -&gt; Optional[Union[Decimal, float, int]]:

    if isinstance(price, Decimal):

        ticks = BETFAIR_DECIMAL_TICKS

    elif isinstance(price, float) or isinstance(price, int):

        ticks = BETFAIR_TICKS

    else:

        raise TypeError('price must be of type Decimal or float or int.')



    if side == Side.BACK:

        fun = bisect_left

        offset = 0

    elif side == Side.LAY:

        fun = bisect_right

        offset = -1

    else:

        raise TypeError('side must be of type Side')



    index = fun(ticks, price) + offset



    if index &lt; 0 or index &gt; len(ticks) - 1:

        return None



    return ticks[index]```



---

## 2020-03-19 11:05:27 - issues channel

**brightcake**

feel like I might be missing something very obvious here but when I use the trading.historic.get_file_list() method I seem to be getting a timeout error: Exception: HTTPSConnectionPool(host='[http://historicdata.betfair.com|historicdata.betfair.com](http://historicdata.betfair.com|historicdata.betfair.com)', port=443): Read timed out. (read timeout=16)

---

## 2020-03-17 10:19:34 - issues channel

**Peter**

&lt;chuckling&gt;As part of my investigations, I forced an exit by overriding the Historical Stream class and pushing a terminator event onto the handler queue after the loop that reads the markets in the run method. This triggered an API error, when Betfair objected to the attempt to logout (no doubt because I had previously side stepped logging in).&lt;/chuckling&gt;

---

## 2020-03-16 10:42:55 - general channel

**Jonatan (skyw)**

I don't think it should raise an error, you should probably subscribe first then do listcurrentorders then apply streamupdates

---

## 2020-03-16 10:36:48 - general channel

**liam**

raise error if cache already present for a particular market? i.e. before any order data comes from the stream

---

## 2020-03-16 10:24:17 - general channel

**liam**

What edge cases do you foresee? I don't like how the listener is used for market and order data, would probably name the function prime_order_cache so its clear and raise an error if its being used for markets

---

## 2020-03-15 21:28:05 - issues channel

**Newbie99**

I was requesting Market Description via a call to listMarketCatalogue, but even when removing that it still produces the error.

---

## 2020-03-15 21:26:47 - issues channel

**Newbie99**

(still the same error if I take that out)

---

## 2020-03-15 21:20:55 - issues channel

**Newbie99**

just to confirm that is the case:



`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': ['1.129176457', '1.138419916', '1.166407043', '1.120629096', '1.138799270', '1.169458599'], 'priceProjection': {'priceData': ['SP_AVAILABLE', 'SP_TRADED', 'EX_ALL_OFFERS', 'EX_TRADED'], 'exBestOffersOverrides': {}, 'virtualise': False, 'rolloverStakes': False}, 'orderProjection': 'ALL', 'matchProjection': 'NO_ROLLUP'}` 

`Exception: None` 

`Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang06b-prd-02170920-003d06bfaf', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie2-ang06b-prd-02170920-003d06bfaf', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`

---

## 2020-03-15 21:16:45 - issues channel

**Newbie99**

But yes you are of course right, I should fix that!

---

## 2020-03-15 21:15:38 - issues channel

**Newbie99**

but, thats sort of the point, how can 6 markets throw up that error?

---

## 2020-03-15 21:13:37 - issues channel

**Newbie99**

`betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook` 

`Params: {'marketIds': [['1.129176457', '1.138419916', '1.166407043', '1.120629096', '1.138799270', '1.169458599']], 'priceProjection': {'priceData': ['SP_AVAILABLE', 'SP_TRADED', 'EX_ALL_OFFERS', 'EX_TRADED'], 'exBestOffersOverrides': {}, 'virtualise': False, 'rolloverStakes': False}, 'orderProjection': 'ALL', 'matchProjection': 'NO_ROLLUP'}` 

`Exception: None` 

`Error: {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-02180926-003c9436b9', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}` 

`Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0001', 'data': {'APINGException': {'requestUUID': 'ie1-ang11b-prd-02180926-003c9436b9', 'errorCode': 'TOO_MUCH_DATA', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}`

---

## 2020-03-09 22:49:48 - issues channel

**Riley**

[@UPEFBEEL8](@UPEFBEEL8) as [@UBS7QANF3](@UBS7QANF3) said i remember setting up from an Australian google cloud data-centre but still got this error. It is because their address block is still registered in USA and geolocate back to USA

---

## 2020-03-09 15:41:34 - issues channel

**jb**

Hey guys.  I normally use a VPN (at least from the laptop I tinker on), routing either thru Sweden or UK.  I sometimes get `LoginError: API login: BETTING_RESTRICTED_LOCATION` when logging in from either location - which goes away when I switch to the other one.  My account is registered to GB.



Anyone know what's going on - and also if betfair have any sensitivity about using VPNs etc?  Cheers.

---

## 2020-03-09 11:33:56 - issues channel

**Rory**

makes sense ... the errors are handled inside the Thread which is doing the streaming, so you can recover

---

## 2020-03-09 11:29:14 - issues channel

**liam**

Have you seen the error handling / production example?

---

## 2020-03-09 11:27:28 - issues channel

**Rory**

Just curious how people are handling SocketError exceptions using the InPlayService (BetfairStream). The examples have the stream starting in a different Thread, so you never get the chance to recover from those socket errors in the main Thread if the connection drops after the stream has started

---

## 2020-03-08 16:12:46 - strategies channel

**D C**

Could be a bug in my GUI/parsers - hence the question

---

## 2020-03-06 15:35:48 - general channel

**Mo**

Unless you have best execution turned off



```In normal circumstances the placeOrders is an atomic operation.  PLEASE NOTE: if the 'Best Execution' features is switched off, placeOrders can return 'PROCESSED_WITH_ERRORS' meaning that some bets can be rejected and other placed when submitted in the same PlaceInstruction ```



---

## 2020-03-06 15:32:08 - general channel

**liam**

if its not that or a http error then i will try again, as you place more bets you will encounter errors a lot, on all cancel/update/replace/place

---

## 2020-03-05 09:54:54 - issues channel

**Peter**

LOL. That was actually my starting point. I saw in the raw data that the stream IDs that I was passing into my streaming class (based on the error handling example) were being ignored, so worked backwards through the code to see why.

---

## 2020-03-05 09:39:22 - issues channel

**Peter**

[@U4H19D1D2](@U4H19D1D2) I'm trying to understand how unique IDs are used for streaming in BFLW. Although the streaming error handling example shows a class that initialises a unique ID and can overwrite that with a received parameter when the class is instantiated, I'm not seeing anywhere that these are actually used. Instead the streaming subscribe methods (market and order) both start by creating their own unique IDs which are then added to the subscribe message and returned to the streaming error handling class overwriting any that was passed in or initialised when when the class was instantiated. Or am I misunderstanding?

---

## 2020-03-03 21:40:21 - strategies channel

**D C**

If you had a half decent pricing model for the horses, asssuming that final BFSP is indeed efficient you could make a killing value betting alone. The price fluctuations would give you a decent window of opportunity if you had something moderately accurate. I tried myself years ago scraping RP website to get a database going with the view to doing a multinomial logistic regression on it but I found too many errors in the data. Might be easier these days with something like proform but I suspect that it would still be very very hard as there is a lot of "inside" info which probably has far more impact than the publicly available data.

---

## 2020-03-02 09:21:32 - general channel

**liam**

v2.1.0 now released with a few improvements and bug fixes (including one I introduced in 2016 that has somehow gone unnoticed..) [https://github.com/liampauling/betfair/blob/master/HISTORY.rst#release-history](https://github.com/liampauling/betfair/blob/master/HISTORY.rst#release-history)

---

## 2020-02-29 22:07:37 - general channel

**jhaa**

I get occasional 'INVALID_SESSION_INFORMATION' in list_market_book which for now kills my bot and restarts it. Why do I likely get that error? Is that a server restart that requires a new login?

---

## 2020-02-29 19:55:43 - general channel

**Peter**

Came a cropper today. Despite Betfair's promise to write to users who would fall foul of the new restrictions on stream connections, they didn't, at least not to me. So this afternoon I started to have new connections rejected. So I'm going to need to rework my soccer streams to aggregate them into a small number of connections. In looking into this I see in the docs that "A maximum consumption limit (exceeding this will result in an error with details of the limit: ErrorCode.SUBSCRIPTION_LIMIT_EXCEEDED)", which I suspect is what caught me out today. But are there any limits on the number of markets types / country codes to which one can subscribe in a single stream? Are there any practical limits that those of you already using more aggregated streams would recommend (e.g. to avoid overloading CPUs for busy markets)?

---

## 2020-02-29 17:03:39 - general channel

**liam**

You can remove the errors by upping the latency on the listener 

---

## 2020-02-26 19:19:28 - general channel

**Chris**

Aaaah my bad, I switched to the generator stream by accident while trying to fix something else, thanks :slightly_smiling_face:

---

## 2020-02-26 19:08:16 - general channel

**Chris**

Previously I could just hit debug in pycharm and it would take me to the first breakpoint in the code, but now it just ends so I guess a seperate thread is being created for the streamer right?

---

## 2020-02-26 18:58:44 - general channel

**Chris**

hey all, I notice _async has been removed in the recent update.. Is there a way to not have the streamer go into a seperate process so I can debug?

---

## 2020-02-26 15:50:00 - issues channel

**Unknown**

For anyone interested, they found a bug where a matched SP bet caused issues with listing current orders. They’re pushing a fix through end of this week/start of next week. 

---

## 2020-02-25 20:26:32 - general channel

**liam**

Yep that’s correct, chucked the update in there whilst debugging and found it useful so left it 

---

## 2020-02-25 12:49:44 - issues channel

**hugo**

note that the thread wont be stopped if all that happens on the main thread is an exception is thrown

---

## 2020-02-24 19:52:22 - issues channel

**jb**

ha yes I did this but turned it off as I couldn't get in and debug (with ipython `%debug`, which is my usual)

---

## 2020-02-24 19:46:23 - issues channel

**liam**

Failing? You getting errors? Streaming isn’t really designed for interactive ide’s 

---

## 2020-02-24 16:20:43 - strategies channel

**James T**

I think with any kind of data source there’s always a risk of errors, so basically you need to manage your risk around that, and sometimes there’s not a huge amount you can do about it, but having the data feed is still better than not. 

---

## 2020-02-24 16:13:36 - strategies channel

**D C**

Well yeah I thought that they would average out but the errors I am getting often look like what you would see on a calibration error. I am (rightly or wrongly) expecting any error to be bivariate guassian with mean as the "true" position

---

## 2020-02-24 16:08:22 - strategies channel

**D C**

You notice any odd errors in the positions? I'm pretty sure my rendering code is as accurate but I get some very strange offset errors at times. Obviously I can't rule out bugs (who can) - do you see these things too?

---

## 2020-02-22 19:38:14 - general channel

**Oliver Varney**

still not fixed from a month ago when it happened to me

---

## 2020-02-22 08:00:59 - issues channel

**liam**

[@UPMUFSGCR](@UPMUFSGCR) just use bflw :slightly_smiling_face:



```from requests import session



session = requests.Session()

s.proxies = {

  "http": http_proxy,

  "https": https_proxy,

}



trading = betfairlightweight.APIClient(

    "username", 

    "password", 

    app_key="app_key", 

    session=session,

)```

although that error looks like something is wrong with the proxy/settings

---

## 2020-02-21 23:06:05 - issues channel

**Jonjonjon**

Does anyone here use Squid as a proxy server to connect to Betfair?



I have set up a proxy server, and am attempting to download some event types using the following example code, but it gives me this error:



URLError: &lt;urlopen error Tunnel connection failed: 503 Service Unavailable&gt;



```headers = {'X-Application': APPKEY, 'X-Authentication': SESSION_TOKEN, 'content-type': 'application/json'}

event_type_req = '{"jsonrpc": "2.0", "method": "SportsAPING/v1.0/listEventTypes", "params": {"filter":{ }}, "id": 1}'



req = urllib2.Request(API_NG_URL, event_type_req, headers)

req.set_proxy(https_proxy, 'https')

req.set_proxy(http_proxy, 'http')

response = urllib2.urlopen(req)

print response.read()```



---

## 2020-02-20 08:10:06 - issues channel

**liam**

:thumbsup:  out of interest did the market fix itself in the end do you know?

---

## 2020-02-19 19:04:27 - general channel

**jb**

Hello everyone.  Been lurking for a while, and playing with the great library [@U4H19D1D2](@U4H19D1D2) made (thanks for making it available!).  A couple of noobish questions.



First, I'm trying to use the historic data.  How are you guys consuming the compressed files?



I am unzipping them in 2 stages: `tar -xf data.tar` for the whole archive which gives me files with `.bz2` extensions which I decompress with `bzip2 -d` (individually atm).  But even then I can't `json.load()` them (I get a `JSONDecodeError`, saying `Extra data`.



I imagine there's an easier way!

---

## 2020-02-19 16:22:41 - issues channel

**liam**

Yeah we can move the error handling up and disregard the market but you will keep getting updates

---

## 2020-02-19 16:13:49 - issues channel

**liam**

But lots to fix as it will then fail on create_resource 

---

## 2020-02-19 16:04:32 - issues channel

**Mo**

I'm getting `betfairlightweight.exceptions.CacheError: "EX_MARKET_DEF" must be requested to use cache` on a stream where I have requested `EX_MARKET_DEF`. I'm assuming Betfair is sending through data on a market without one. Is there any way to gracefully ignore the data in this situation?

---

## 2020-02-18 04:08:09 - issues channel

**Jack Kaminski**

It still throws an error

---

## 2020-02-18 01:08:01 - issues channel

**Unknown**

Why do I get this error on Ubuntu but not my Mac...

---

## 2020-02-17 09:06:25 - issues channel

**Unknown**

Looks like I have introduced a rather mighty CPU issue when making large API calls with v2, I believe it is to do with they way betfairlightweight uses the requests.Response object, investigating now



edit: now fixed [https://github.com/liampauling/betfair/issues/268](https://github.com/liampauling/betfair/issues/268)

---

## 2020-02-17 03:27:36 - issues channel

**AP**

TypeError: __init__() missing 1 required positional argument: 'placedDate'

---

## 2020-02-15 22:12:31 - general channel

**Jonjonjon**

This is bit embarrasing, but I only have permissions to run scripts on that machine. I don't have UI access or shell access.:expressionless:



I'm now paying the price for using an exceptionally cheap way to get started on my betting career.

---

## 2020-02-15 22:10:04 - general channel

**Mo**

If the theory is correct that this IP is now being recognised as in a restricted location then you will be prevented from logging in with a more descriptive error message than PERMISSION_DENIED

---

## 2020-02-15 22:05:12 - general channel

**Mo**

You mean you were able to login without an error?

---

## 2020-02-15 21:33:28 - general channel

**Mo**

If you log out and login again do you get an error?

---

## 2020-02-15 20:20:17 - general channel

**Jonjonjon**

Has anyone seen anything like this before? The bot generating this error has been running without modification for years, and has suddenly stopped working because of this:



{u'status': u'FAILURE', u'errorCode': u'PERMISSION_DENIED', u'instructionReports': [{u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 23333488, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 20077280, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 11124, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 26016330, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 24986924, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 22034022, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 391245, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 23054357, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 23955673, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 5842556, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}, {u'status': u'FAILURE', u'errorCode': u'ERROR_IN_ORDER', u'instruction': {u'handicap': 0.0, u'orderType': u'LIMIT', u'selectionId': 23955744, u'limitOrder': {u'price': 1.13, u'persistenceType': u'LAPSE', u'size': 400.0}, u'side': u'LAY'}}], u'marketId': u'1.168853098'}

---

## 2020-02-11 18:19:36 - general channel

**Alex F**

```

runfile('C:/Users/alexa/Desktop/repos/bet/betfair/examples/examplestreaminghistorical.py', wdir='C:/Users/alexa/Desktop/repos/bet/betfair/examples')

INFO:betfairlightweight.streaming.stream:[Stream: HISTORICAL]: "MarketStream" created

Traceback (most recent call last):



  File "C:\Users\alexa\Desktop\repos\bet\betfair\examples\examplestreaminghistorical.py", line 67, in &lt;module&gt;

    for i in g:



TypeError: 'method' object is not iterable```

---

## 2020-02-11 18:18:50 - general channel

**Mo**

What's the full error you get?

---

## 2020-02-11 18:14:20 - general channel

**Alex F**

gotcha. redid it -&gt;     for i in g:



TypeError: 'method' object is not iterable

---

## 2020-02-10 20:52:59 - general channel

**Alex F**

hi, i have managed to run the historic data downloader, however, i am honestly clueless how to make sense of the bz2 files.  i have tried running the historic data streaming, but without success. i set directory to the directory of the folder and get access denied, i target a single bz2 file and receive UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 74: character maps to &lt;undefined&gt;. any help is much appreciated!

---

## 2020-02-10 15:30:07 - general channel

**liam**

I see, fix would be to += rather than replace in the cache but I and many collect their own data direct from the stream where it isn't cumulative. For those using the ADVANCED data (not sure why you would waste your money on it) you will need to create a custom listener/cache

---

## 2020-02-08 08:14:18 - issues channel

**Alex F**

Error Loading extension section ssl_client

1696:error:22097082:X509 V3 routines:do_ext_nconf:unknown extension name:../openssl-1.1.1d/crypto/x509v3/v3_conf.c:78:

1696:error:22098080:X509 V3 routines:X509V3_EXT_nconf:error in extension:../openssl-1.1.1d/crypto/x509v3/v3_conf.c:47:name=name_opt, value=ca_default

---

## 2020-02-08 08:13:55 - issues channel

**Alex F**

i get the following error:

---

## 2020-02-06 18:40:38 - issues channel

**Jonatan (skyw)**

Should be easy to lookup the error codes though?

---

## 2020-02-06 18:17:49 - issues channel

**Alex F**

$ openssl req -new -config openssl.cnf -key client-2048.key -out client-2048.csr

unable to find 'distinguished_name' in config

problems making Certificate Request

16256:error:0E06D06C:configuration file routines:NCONF_get_string:no value:../openssl-1.1.1d/crypto/conf/conf_lib.c:273:group=req name=distinguished_name

any clues, please ?

---

## 2020-02-06 17:10:40 - issues channel

**hugo**

```oss $ python3

Python 3.7.3 (default, Oct  7 2019, 12:56:13)

[GCC 8.3.0] on linux

Type "help", "copyright", "credits" or "license" for more information.

&gt;&gt;&gt; from itertools import izip_longest

Traceback (most recent call last):

  File "&lt;stdin&gt;", line 1, in &lt;module&gt;

ImportError: cannot import name 'izip_longest' from 'itertools' (unknown location)

&gt;&gt;&gt;

oss $ python

Python 2.7.16 (default, Oct  7 2019, 17:36:04)

[GCC 8.3.0] on linux2

Type "help", "copyright", "credits" or "license" for more information.

&gt;&gt;&gt; from itertools import izip_longest

&gt;&gt;&gt;```



---

## 2020-02-06 17:08:37 - issues channel

**Alex F**

ERROR: Command errored out with exit status 1:

     command: 'C:\Users\alexa\Anaconda3\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '"'"'C:\\Users\\alexa\\AppData\\Local\\Temp\\pip-install-jajffrml\\version\\setup.py'"'"'; __file__='"'"'C:\\Users\\alexa\\AppData\\Local\\Temp\\pip-install-jajffrml\\version\\setup.py'"'"';f=getattr(tokenize, '"'"'open'"'"', open)(__file__);code=f.read().replace('"'"'\r\n'"'"', '"'"'\n'"'"');f.close();exec(compile(code, __file__, '"'"'exec'"'"'))' egg_info --egg-base 'C:\Users\alexa\AppData\Local\Temp\pip-install-jajffrml\version\pip-egg-info'

         cwd: C:\Users\alexa\AppData\Local\Temp\pip-install-jajffrml\version\

    Complete output (7 lines):

    Traceback (most recent call last):

      File "&lt;string&gt;", line 1, in &lt;module&gt;

      File "C:\Users\alexa\AppData\Local\Temp\pip-install-jajffrml\version\setup.py", line 4, in &lt;module&gt;

        from version import __version__

      File "C:\Users\alexa\AppData\Local\Temp\pip-install-jajffrml\version\version.py", line 2, in &lt;module&gt;

        from itertools import izip_longest

    ImportError: cannot import name 'izip_longest' from 'itertools' (unknown location)

    ----------------------------------------

ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.

---

## 2020-02-06 17:06:25 - issues channel

**Mo**

Paste the error that you get

---

## 2020-02-06 16:57:41 - issues channel

**Alex F**

hey :slightly_smiling_face: i tried installing betfairlightweight, but it fails to build ciso8601, any idea what is up ? also, all i am after is to be able to read nicely the historic data that i have downloaded, is it really worth it to debug everything (ive spent 2 hours already) or just head in a different direction?

---

## 2020-01-31 14:48:49 - issues channel

**Jonatan (skyw)**

Yeah, it does, but next version he still need python3 and python2 is not maintained

Fixing the problem first first for 2.7 then he probably gonna switch anyway :slightly_smiling_face:

---

## 2020-01-31 14:48:27 - issues channel

**Gustav Molander**

Okay nice! Getting some success now, only a single error left:

```ERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: Consider using the `--user` option or check the permissions.```

---

## 2020-01-31 14:45:14 - issues channel

**Gustav Molander**

Im getting the exact same errors when using pip3. Im installing the command tools now!

---

## 2020-01-31 14:43:37 - issues channel

**Jonatan (skyw)**

yeah, but in the error messages I see python 2.7, It might be the case that he needs thos  as well though!

---

## 2020-01-31 14:41:10 - issues channel

**Gustav Molander**

yeah, the default is 2.7. However i tried changing the default with a simlink and also tried pip3, getting similar errors

---

## 2020-01-31 14:39:41 - issues channel

**Unknown**

Alright, thanks. I’ll take a look at venvs.

I have python 3.7.6 but im not sure if pip uses the standard python 2 or  3, I havent changed the default python version.



These are the errors:

---

## 2020-01-31 14:33:47 - issues channel

**hugo**

What errors are you getting?

---

## 2020-01-31 14:32:02 - issues channel

**Gustav Molander**

Hi guys, a nice little channel you have here. :slightly_smiling_face: I just started out with trying to install betfairlightweight. Is there anything special you have to do when using Mac OS (Catalina) regarding python/python3 (pip/pip3) when installing? Im getting a bunch of errors.

---

## 2020-01-27 15:43:01 - issues channel

**liam**

i think i spent a week trying to fix something caused by this before :face_palm:

---

## 2020-01-27 12:50:52 - general channel

**klozovin**

thanks, cool... any bugs/errors you found out just by adding types?

---

## 2020-01-26 19:19:12 - general channel

**liam**

Ive updated it in the v2 branch 

[https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/3425-streaming-bug|https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/3425-streaming-bug](https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/3425-streaming-bug|https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/3425-streaming-bug)

---

## 2020-01-24 17:15:19 - random channel

**Tom Poole**

To Senior DevOps Engineers, perm or contractors looking for some security, who want a new and exciting opportunity within a sports and data streaming organisation, 3d immersive visualisation and gamification of sporting events is the plan. Tech stack - AWS/GCP, Docker, Jenkins, Terraform, Kubernetes and Ansible.  Location - Central London. Competitive salary, exceptional bonus and benefits. Let me know if you want to learn more, or know of anyone that may want a step in the right direction.

---

## 2020-01-21 11:44:33 - general channel

**Mo**

Well one way of dealing with it would be to have a separate thread keeping your session token alive so when the connection is lost and it tries to reconnect with that session token then it’s valid. 



But I think a better way would be to handle the error, relogin and resubscribe

---

## 2020-01-21 11:28:31 - general channel

**ash**

Morning, I have been trying out streaming using how it is set up in the new examplestreamingerrhandling.py and I keep getting this error.

everything works fine but if I get a connection issue, for example, I am getting this:

```    raise SocketError('[Connect: %s]: Connection closed by server' % (self._unique_id,))

betfairlightweight.exceptions.SocketError: [Connect: 1002]: Connection closed by server

21/01/2020 11:00,581 GB __main__ INFO Starting MarketStreaming

21/01/2020 11:00,713 GB betfairlightweight.streaming.listener INFO [Connect: 1002]: connection_id: 202-210120110000-541

21/01/2020 11:00,756 GB betfairlightweight.streaming.listener ERROR [Subscription: 1003] INVALID_SESSION_INFORMATION: UnrecognisedCredentials

21/01/2020 11:00,756 GB __main__ ERROR MarketStreaming run error

Traceback (most recent call last):

  File "/Volumes/2/GitHub/OddsTrading/versionTWO.py", line 115, in run

    self.stream.start()

  File "/Users/ash/anaconda3/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 60, in start

    self._read_loop()

  File "/Users/ash/anaconda3/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 198, in _read_loop

    self._data(received_data)

  File "/Users/ash/anaconda3/lib/python3.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 239, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: 202-210120110000-541, data: {"op":"status","id":1003,"statusCode":"FAILURE","errorCode":"INVALID_SESSION_INFORMATION","errorMessage":"UnrecognisedCredentials","connectionClosed":true,"connectionId":"202-210120110000-541"}

21/01/2020 11:00,759 GB __main__ INFO Starting MarketStreaming```

This is then stuck in the `@retry` loop raising the same error each time.

---

## 2020-01-17 18:06:48 - issues channel

**PeterLe**

Thanks gents, That solved the "ImportError: attempted relative import with no known parent package" problem

---

## 2020-01-17 17:33:31 - issues channel

**Unknown**

Thanks for your help, Im just running it from Pycharm in debug mode at the mo...I was wondering if it was the way the directories are structured? Pls see image

---

## 2020-01-17 16:54:43 - issues channel

**PeterLe**

Still learning Python (programming)  so forgive me if this is simple error...and i expect it is, on my part:-)

betfairlightweight all running OK, certs loaded fine too..

Im able to run some of the examples fine.



Im keen to be able to use flumine (output to a local directory on my PC)

$ PIP install flumine completed



However when I run the code im getting this error :



 File "C:/Users/User-1/Desktop/Python/Flumine/flumine-master/flumine/flumine.py", line 7, in &lt;module&gt;

    from .listener import FlumineListener

ImportError: attempted relative import with no known parent package



line 7 in flumine is :



from .listener import FlumineListener



I get the gist of the error, but not sure how to fix it.

Any help appreciated. Thanks in advance

Peter

---

## 2020-01-11 17:13:54 - general channel

**AP**

```---------------------------------------------------------------------------

RemoteTraceback                           Traceback (most recent call last)

RemoteTraceback: 

"""

Traceback (most recent call last):

  File "C:\Users\antpa\Anaconda3\envs\myenv\lib\site-packages\multiprocess\pool.py", line 119, in worker

    result = (True, func(*args, **kwds))

  File "C:\Users\antpa\Anaconda3\envs\myenv\lib\site-packages\multiprocess\pool.py", line 44, in mapstar

    return list(map(*args))

  File "&lt;ipython-input-11-dbf9aa1bac51&gt;", line 4, in process_betfair_historical_file

NameError: name 'MarketStream' is not defined

"""



The above exception was the direct cause of the following exception:



NameError                                 Traceback (most recent call last)

&lt;ipython-input-19-0f3124f0dfdc&gt; in &lt;module&gt;

----&gt; 1 results = pool.map(process_betfair_historical_file, [file_path for file_path in file_paths])



~\Anaconda3\envs\myenv\lib\site-packages\multiprocess\pool.py in map(self, func, iterable, chunksize)

    264         in a list that is returned.

    265         '''

--&gt; 266         return self._map_async(func, iterable, mapstar, chunksize).get()

    267 

    268     def starmap(self, func, iterable, chunksize=None):



~\Anaconda3\envs\myenv\lib\site-packages\multiprocess\pool.py in get(self, timeout)

    642             return self._value

    643         else:

--&gt; 644             raise self._value

    645 

    646     def _set(self, i, obj):



NameError: name 'MarketStream' is not defined```

---

## 2020-01-11 16:54:41 - general channel

**Jonatan (skyw)**

nice, are you getting them or assuming, I can not see how it would generate IO errors?

---

## 2020-01-11 16:48:59 - general channel

**AP**

I/O errors 

---

## 2020-01-08 08:54:16 - issues channel

**liam**

You can see it working by starting it and then disconnect from wifi/internet, it will then log the errors and attempt to reconnect with exponential backoff, you can then reconnect to the internet and see it reconnect to the stream

---

## 2020-01-08 08:53:05 - issues channel

**liam**

[@US6CDMD7Z](@US6CDMD7Z) I have added a new example which covers error handling and retrying that you and others might find handy, its a simplification of what I use in production and its rock solid :smile: It is in the v2.0 branch that I am working on [https://github.com/liampauling/betfair/blob/task/version-2.0/examples/examplestreamingerrhandling.py](https://github.com/liampauling/betfair/blob/task/version-2.0/examples/examplestreamingerrhandling.py)

---

## 2020-01-07 21:12:38 - issues channel

**Newbie99**

```Traceback (most recent call last):

  File "D:/Python37/webpages/new_betfair.py", line 37, in &lt;module&gt;

    trading.login()

  File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\login.py", line 30, in __call__

    (response, elapsed_time) = self.request(self.url, session=session)

  File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\login.py", line 52, in request

    self._error_handler(response_data)

  File "D:\Python37\lib\site-packages\betfairlightweight\endpoints\login.py", line 57, in _error_handler

    raise self._error(response)

betfairlightweight.exceptions.LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE```

I just received this error...my password hasn't changed and I can log into the Betfair GUI without any issues, so I'm a bit confused, any ideas?

---

## 2020-01-06 20:15:42 - issues channel

**liam**

Ah, if it’s happening every now and again it will be because you are not catching any errors the stream may have. You need to run stream.start in a separate thread with try / except and reconnect on error. It’s common to get timeout or connection closed errors (caused by betfair or internet connection)

---

## 2020-01-06 20:13:07 - issues channel

**DonJ80**

yes, i can. i was printing it, it works, it is only when this error happens, that everything freeze. will changing async to false help? how will printing the time below start.stream help? . have you seen this before? this happens once every 10 to 15 hours. what can i do handle it? ...thanks Liam i appreciate it.

---

## 2020-01-06 20:02:14 - issues channel

**Unknown**

Hi [@U4H19D1D2](@U4H19D1D2) , i have  changed logging to DEBUG, and got the same error. how can i deal with this error? try and except are pointless as you mentioned. how  can i capture this error such that i stop the stream and then resubscribe to the markets.  what do i need to add? ...thanks

---

## 2020-01-05 21:05:48 - general channel

**Alex A**

I’ve been getting 404 errors all weekend trying a non-interactive login, and at first I thought it was Betfair, as they’ve been having site issues, but surely they wouldn’t be down for non interactive logins all weekend?

---

## 2020-01-05 18:13:29 - issues channel

**Unknown**

thanks Liam, i will change  it to DEBUG

---

## 2020-01-05 18:10:30 - issues channel

**liam**

Can you change logging to DEBUG so we can see more?

---

## 2020-01-05 18:10:09 - issues channel

**liam**

I can’t see the error at the moment but can try tomorrow when back on the laptop, the reason the program doesn’t end is because you start the stream in async which creates a new thread. Your program is then blocking on the queue.get, v2 is going to remove async as it results in bad habits / the socket timing out/errors without the main thread catching errors.



Remove that try except as it’s a bit pointless along with the while loop.

---

## 2020-01-05 17:40:31 - issues channel

**DonJ80**

fixed formatting of the code now

---

## 2020-01-05 17:03:15 - issues channel

**Mo**

Can you fix the formatting? It's very hard to read

---

## 2020-01-05 17:00:05 - issues channel

**Unknown**

Hi guys. i keep  getting the same error. how can i deal with this error attached

my code:

```import os

import logging

import queue

from betfairlightweight import filters

import datetime

import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



import pandas as pd

# create trading instance

trading = betfairlightweight.APIClient('username',

                                       'password',

                                       app_key='appkey',

                                       certs='C:\\Users\\')



# login

trading.login()



# make event type request to find horse racing event type

horse_racing_event_type_id = trading.betting.list_event_types(

    filter=filters.market_filter(

        text_query='Horse Racing'

    )

)

# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

trading.login()



t = datetime.datetime.now()+datetime.timedelta(hours=12)



while datetime.datetime.now() &lt; t:

    h_i1 =datetime.datetime.now()

    h_i2 = h_i1 + datetime.timedelta(hours=12)

    # Define a market filter

    thoroughbreds_event_filter = betfairlightweight.filters.market_filter(

        event_type_ids=['7'],

        market_start_time={

            'from': h_i1.strftime("%Y-%m-%dT%TZ"),

            'to': h_i2.strftime("%Y-%m-%dT%TZ")

        }

    )



    # Print the filter

    # thoroughbreds_event_filter



    # Get a list of all thoroughbred events as objects

    thoroughbred_events = trading.betting.list_events(

        filter=thoroughbreds_event_filter

    )



    # Get a list of all thoroughbred events as objects

    hr_thoroughbred_events = trading.betting.list_events(

        filter=thoroughbreds_event_filter

    )



    # Create a DataFrame with all the events by iterating over each event object

    hr_thoroughbred_events_next_12hours = pd.DataFrame({

        'Event Name': [event_object.event.name for event_object in hr_thoroughbred_events],

        'Event ID': [event_object.event.id for event_object in hr_thoroughbred_events],

        'Event Venue': [event_object.event.venue for event_object in hr_thoroughbred_events],

        'Country Code': [event_object.event.country_code for event_object in

                         hr_thoroughbred_events],

        'Time Zone': [event_object.event.time_zone for event_object in hr_thoroughbred_events],

        'Open Date': [event_object.event.open_date for event_object in hr_thoroughbred_events],

        'Market Count': [event_object.market_count for event_object in hr_thoroughbred_events]

    })

    # create queue

    output_queue = queue.Queue()



    # create stream listener

    listener = betfairlightweight.StreamListener(

        output_queue=output_queue,

    )



    # create stream

    stream = trading.streaming.create_stream(

        listener=listener,

    )



    # create filters (GB WIN racing)

    market_filter = streaming_market_filter(

        event_type_ids=['7'],

        event_ids=hr_thoroughbred_events_next_12hours['Event ID'],

        market_types=['WIN'],

    )

    market_data_filter = streaming_market_data_filter(

        fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

        ladder_levels=5,

    )



    # subscribe

    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=1000,  # send update every 1000ms

    )



    # start stream

    stream.start(async_=True)



    # check for updates in output queue



    while datetime.datetime.now() &lt; t:

        try:

            market_books = output_queue.get()

            print(market_books)



            for market_book in market_books:

                print(

                    market_book.streaming_update, 

                    market_book.publish_time,  

                )

        except:

            output_queue = queue.Queue()



            # create stream listener

            listener = betfairlightweight.StreamListener(

                output_queue=output_queue,

            )



            # create stream

            stream = trading.streaming.create_stream(

                listener=listener,

            )



            # create filters 

            market_filter = streaming_market_filter(

                event_type_ids=['7'],

                event_ids=hr_thoroughbred_events_next_12hours['Event ID'],

                market_types=['WIN'],

            )

            market_data_filter = streaming_market_data_filter(

                fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF' ],

                ladder_levels=5,

            )



            # subscribe

            streaming_unique_id = stream.subscribe_to_markets(

                market_filter=market_filter,

                market_data_filter=market_data_filter,

                conflate_ms=1000,  # send update every 1000ms

            )



            # start stream

            stream.start(async_=True)

    t = t + datetime.timedelta(hours=12)```

 but i doesn't  help. i thought if i put a while loop, then when error occurs it will sleep for 1 second and then subscribe to markets as you suggested and then  start the stream again. but still the code enter a state where the message below is displayed and nothing happens. this happens everyday once .  as you can see in Pycharm, the Run tab is still green, also the stop button(red square) is still active, it seems that my code does not capture the error , but the betfairlightweight source code capture it, then something happens and it stays there.why does my try and except  statements can't capture this error? I have to push  the stop button on the top left  and then rerun the code.  have you seen this issue before, any idea how can this be fixed.

---

## 2020-01-05 12:35:31 - general channel

**AP**

```AttributeError: 'RunnerBook' object has no attribute 'available_to_back'```



---

## 2020-01-05 12:33:45 - general channel

**Mo**

What errors?

---

## 2020-01-05 12:32:44 - general channel

**AP**

[https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py) - I am messing around with this example code and am attempting to extract the whole order book for each runner to calculate VWAP etc but I am receiving some errors when using runner.available_to_back etc

---

## 2020-01-04 18:46:10 - general channel

**Alex A**

I’m also getting 404 errors for [https://identitysso-cert.betfair.com/api/certlogin|https://identitysso-cert.betfair.com/api/certlogin](https://identitysso-cert.betfair.com/api/certlogin|https://identitysso-cert.betfair.com/api/certlogin)

---

## 2020-01-02 00:59:07 - general channel

**Unknown**

Hi guys, how can i deal with this error

I used

while time &lt; future time:

....try:

........get updates.

....except:

```stream.stop()

time.sleep(1)

stream.start(async_=True)```

but i doesn't  help. the code stops. i thought if i put a while loop, then when error occurs it will sleep for 1 second and then start the stream again.but still the code stops.  thanks

---

## 2019-12-23 19:18:41 - general channel

**Jonatan (skyw)**

Have gotten the same error, haven't really looked closely what it was. But good to know that it works on windows.

---

## 2019-12-23 17:04:16 - general channel

**Ian**

Evening all - about to ask a what feels like a super easy q but I'm stumped...

Flumine creates zip files, i've been working with these fine on Windows.

Moved to ubuntu and now it doesn't like them - was getting errors from Python's zip library but even on the shell i get

---

## 2019-12-21 23:56:04 - issues channel

**PeterLe**

[@U92CASP1B](@U92CASP1B) Seen this error posted before..advice was :it should be settings={“betfairlightweight”: {“username......

Set certificate_login to true if you have certs setup (you can login without using login_interactive) but don’t recommend it

---

## 2019-12-21 19:09:01 - issues channel

**Jonatan (skyw)**

TypeError: type object argument after ** must be a mapping, not NoneType

```# From source

  @staticmethod

    def _create_client(settings):

        """Returns APIClient based on settings

        or looks for username in os.environ

        """

        if settings:

            return APIClient(**settings.get("betfairlightweight"))

        else:

            username = os.environ.get("username")

            return APIClient(username=username)```

---

## 2019-12-21 17:27:51 - issues channel

**liam**

Error message?

---

## 2019-12-20 16:42:17 - random channel

**Tom**

Hi, I'm using the matchbook API wrapper that some people on here may use. I'm trying to do some optimisation I would like to be able to instead of poll data from the events endpoint by sport_id I'd prefer to pass a list of event_id's to the wrapper function that handles the request.  On matchbooks online documentation you can pass a list of evend_id's and only return data for those markets.  the below code using requests lib returns event's data for three events passed in the querystring.

Is it possible to do the same with  the matchbook wrapper here? [https://github.com/rozzac90/matchbook/blob/master/matchbook/endpoints/marketdata.py](https://github.com/rozzac90/matchbook/blob/master/matchbook/endpoints/marketdata.py)

When I try I get an error

```matchbook.exceptions.ApiError: ['Incorrect request param: id.']```

```    events = api.market_data.get_events(

                                        event_id='1148393114710116,1308951387620017',

                                        states=MarketStates.All,

                                                        per_page=200, offset=0,

                                                        include_event_participants=Boolean.T,

                                                        category_ids=None, price_depth=3,

                                                        side=Side.All, session=None)```







```import requests

url = "[https://api.matchbook.com/edge/rest/events](https://api.matchbook.com/edge/rest/events)"```

```querystring = {"offset":"0","per-page":"20","ids":"1305049710690017,1305058606890017, 1302073817190017","states":"open,suspended,closed,graded","exchange-type":"back-lay","odds-type":"DECIMAL","include-prices":"false","price-depth":"3","price-mode":"expanded","include-event-participants":"false"}```

```headers = {'user-agent': 'api-doc-test-client'}```

```response = requests.request("GET", url, headers=headers, params=querystring)```

```print(response.text)```

---

## 2019-12-14 23:08:39 - general channel

**fjt1973**

Evening All... this has been racking by brains for days. Creation and Uploading of a SSL Certificate! I have a Ubuntu server running, created / uploaded and verification of the certificate works just fine. However, Windows 10, Windows Server 2012 and Windows Server 2016 with certificated created by OpenSSL I get the following error when running the Curl Command from the directory the certificated are sat in "{"loginStatus":"CERT_AUTH_REQUIRED"}". I've even tried running the Curl command from root and putting the in the full path...... Is there something I'm missing!

---

## 2019-12-09 10:52:08 - issues channel

**liam**

[@U5R89SMJ5](@U5R89SMJ5) you were correct about the stream breaking on the 28th, it also impacted me but I didn't realise till the weekend when reviewing some logs, see below from Neil



&gt; This issue was related to a jurisdictional rules update release that was made on 28th November. This had unintended consequences (namely updates stopped being sent to some Stream connections) so the dev team are currently investigating why this happened and won't be making any similar releases until the root cause of the issue has been fixed.

---

## 2019-12-04 21:09:04 - general channel

**liam**

Up to you, are you getting an error?

---

## 2019-12-03 18:02:08 - general channel

**Chris**

```Traceback (most recent call last):

  File "./bfex-grabber-3.py", line 52, in grabber

    available_to_lay = runner.ex.available_to_lay[0].price

IndexError: list index out of range```

---

## 2019-12-03 18:02:07 - general channel

**Chris**

And the error is

---

## 2019-12-03 17:59:24 - general channel

**Chris**

```db = database.cursor()

market_id = db.execute("SELECT match_id FROM bfex_match_ids")

values_list = db.fetchall()



def grabber(market_id):

  market_catalogues = trading.betting.list_market_catalogue(

    filter=filters.market_filter(

      market_ids=[market_id],

  #    in_play_only='false',

    ),

    market_projection=['MARKET_START_TIME', 'RUNNER_DESCRIPTION', 'RUNNER_METADATA'],  # runner description required

    max_results=1

  )



  for market_catalogue in market_catalogues:

    market_books = trading.betting.list_market_book(

      market_ids=[market_catalogue.market_id],

      price_projection=filters.price_projection(

      price_data=filters.price_data(

        ex_best_offers=True

        )

      )

    )



  db = database.cursor()

  sql_insert_query = """UPDATE bfex_match_odds SET selection_odds=%s, selection_back_odds=%s WHERE unique_id=%s"""



  for market_book in market_books:

    for runner in market_book.runners:

      try:

        available_to_back = runner.ex.available_to_back[0].price

        available_to_lay = runner.ex.available_to_lay[0].price

        unique_id = str(runner.selection_id) + market_id

        print(unique_id)

        db.execute(sql_insert_query, (available_to_lay, available_to_back, unique_id))

        print(available_to_lay, available_to_back, unique_id)

      except Exception:

        traceback.print_exc()

        unique_id = str(runner.selection_id) + market_id

        print(unique_id)

        db.execute(sql_insert_query, ("10000.0", "10000.0", unique_id))

        # print("uh-oh")

    database.commit()



def updater(values_list):

  for bfid in values_list:

    try:

      grabber(bfid[0])

    except:

      print("Could not update:")

      print(bfid[0])

      pass



updater(values_list)```

---

## 2019-12-03 10:57:39 - general channel

**liam**

If you want to keep things simple, get(block=False, timeout=120) and then handle the EmptyQueue error 

---

## 2019-12-02 19:33:09 - general channel

**JonJonJon**

Do you know what "turning over a lot" means? I use customer strategy ref, but an actual sub account with a separate balance would be a lot safer, as a bad software bug could empty the account in seconds.

---

## 2019-11-28 13:39:00 - issues channel

**Evaldas**

this is one of those freak errors, and I have no idea what

---

## 2019-11-28 13:37:30 - issues channel

**liam**

Are you setup to catch errors and reconnect? 

---

## 2019-11-28 13:26:08 - issues channel

**Evaldas**

but turns out it doesnt log errors, you live and learn

---

## 2019-11-28 13:25:52 - issues channel

**Evaldas**

Im using it, stdout just as precaustion, for freak errors

---

## 2019-11-28 13:16:11 - issues channel

**Evaldas**

so I must have uncatched error somewhere

---

## 2019-11-28 13:15:07 - issues channel

**hugo**

stderr is where the exceptions get sent to

---

## 2019-11-28 13:03:42 - issues channel

**liam**

It wouldn’t just stop without throwing an error, if you have a connection Id send it to Neil and he can tell you the logs their side 

---

## 2019-11-28 13:01:51 - issues channel

**Evaldas**

thats the part that freaks me out, there is no errors

---

## 2019-11-28 12:54:03 - issues channel

**Evaldas**

Hi, today at about 10:12am all market and order streams just stopped for me. No errors, no timeouts, just nothing. Ive been running this same code for 1+ years, never seen anything like this. Was it just me? I have max_latency=0.5 and heartbeat_ms=3000 on subscribtions. so confused, I have no idea what happened :confused:

---

## 2019-11-26 09:28:01 - general channel

**ash**

I thought it had caused my program to hang, I just had to restart everything, but that must have been an unrelated problem on my side (I had a Mysql error too.) hmm  ok, thanks!

---

## 2019-11-26 09:22:09 - general channel

**liam**

I didn’t get any notification either, 503 is the error betfair give when they stop the stream, it carries on when they have fixed things so no user input required 

---

## 2019-11-12 22:38:46 - general channel

**Leon**

I've been trying to set flumine up for the last couple of nights but have got stuck on what is probably a basic error on my part, but I haven't been able to figure it out. The error I get is -

Traceback (most recent call last):

  File "C:/Users/leonf/PycharmProjects/flumine-master/flumine_test.py", line 17, in &lt;module&gt;

    "certificate_login": False,

  File "C:\Users\leonf\PycharmProjects\flumine-master\flumine\flumine.py", line 21, in __init__

    self.trading = self._create_client(settings)

  File "C:\Users\leonf\PycharmProjects\flumine-master\flumine\flumine.py", line 75, in _create_client

    return APIClient(**settings.get("betfairlightweight"))

TypeError: type object argument after ** must be a mapping, not NoneType



I'm presuming the error is being caused by the "certificate_login": False line (I didn't understand why certs were not required, but based it on the sample github code). An extract of where settings are defined is -

flumine = Flumine(

    recorder=MarketRecorder(

        storage_engine=storage_engine,

        market_filter=market_filter,

    ),

    settings={  # passed to betfairlightweight

        "username": "test",

        "password": "test",

        "app_key": "test",

        "certificate_login": False,

    }

)

with test being replaced by my credentials (obviously!).



Any suggestions would be greatly appreciated please.

(My credentials, app_key, etc work fine connecting in other betfairlightweight scripts)

---

## 2019-11-08 17:11:47 - general channel

**jhaa**

I have some unexpected behaviour in list_cleared_orders(). When I specify event_ids or market_ids I get expected results. However when I filter for runner_ids I get an error: Error: {'code': -32602, 'message': 'DSC-0018'}  which implies a mandatory field was not provided. What field would that be or what am I missing?

---

## 2019-11-03 19:04:49 - general channel

**Chris**

but when I change the directory environment variable to anything I still get forbidden error, not the ‘not found’ error

---

## 2019-11-03 19:04:01 - general channel

**Chris**

Im getting botocore.exceptions.ClientError: An error occurred (403) when calling the HeadBucket operation: Forbidden, despite the access key and secret key being correct (just created new ones)

---

## 2019-11-03 19:03:59 - general channel

**liam**

Are you getting an error?

---

## 2019-10-28 15:03:40 - issues channel

**liam**

np, socket errors are due to either the network or betfair closing the connection so nothing that can be done, you just need to handle them (see general for an example I posted yesterday)

---

## 2019-10-28 15:02:15 - issues channel

**Unknown**

I.e. i am wondering if these errors are leaving me with lots of python processes that are waiting for streams to send events.

---

## 2019-10-28 15:01:02 - issues channel

**JonJonJon**

I also get occasional Socket errors. And suspect that my python scripts are not terminating when the socket errors occur. What does the code aim to do when we get socket error

---

## 2019-10-28 14:56:07 - issues channel

**Unknown**

Has anyone seen this error before?

---

## 2019-10-28 09:25:47 - issues channel

**Rory**

yeah, adding a _handicap_ field to LegacyData fixes it

---

## 2019-10-28 09:24:41 - issues channel

**Rory**

```'legacyData': {'avgPrice': 2.91, 'betSize': 22.06, 'betType': 'B', 'betCategoryType': 'E', 'eventId': 163396437, 'eventTypeId': 1, 'fullMarketName': 'Fixtures 27 Oct / Osasuna v Valencia/ Asian Handicap', 'grossBetAmount': 0.0, 'marketName': 'Asian Handicap', 'marketType': 'A', 'placedDate': '2019-10-25T18:49:37.000Z', 'selectionId': 10543, 'selectionName': 'Osasuna -0.5', 'handicap': -0.5, 'startDate': '2019-10-27T20:00:09.000Z', 'transactionType': 'ACCOUNT_CREDIT', 'transactionId': 0, 'winLose': 'RESULT_WON', 'avgPriceRaw': 2.91}```

---

## 2019-10-28 09:24:29 - issues channel

**Rory**

getting an InvalidResponse error from _trading.account.get_account_statement_ and it's because legacyData has a _handicap_ field, as below

---

## 2019-10-27 17:47:14 - general channel

**liam**

Wrap start in a try except, catch BetfairError and a normal Exception 

---

## 2019-10-27 17:44:35 - general channel

**ash**

Can anybody give me a nudge in the right direction to good ways of dealing with socket.timeout / socket.errors.

excuse If this is simple, but Is there anyway of catching that specific exception and restarting the stream from my main program?

I have tried changing the betfairstrem.py section that throws the exception..

`while self._running and part[-2:] != crlf_bytes:`

`            try:`

`                part = self._socket.recv(self.buffer_size)`

`            except (socket.timeout, socket.error) as e:`

`                if self._running:`

`                    self.stop()`

`                    print('STOP1')`

`                    time.sleep(5)`

`                    self.start()`

`                    # raise SocketError('[Connect: %s]: Socket %s' % (self._unique_id, e))`

`                else:`

`                    return  # 133, prevents error if stop is called mid recv`

but this is erroneous and creating a horrible subscription loop.

---

## 2019-10-25 09:39:26 - general channel

**stefan**

[@UBS7QANF3](@UBS7QANF3) [@U4H19D1D2](@U4H19D1D2) Just to let you know that the service should be working again. They have made some changes, and it has been live for the past 2 weeks. During that time I was able to download again via the website without any issues: `[https://forum.developer.betfair.com/forum/developer-program/historical-data/26927-fixed-historical-data-data-for-nov-18-to-date](https://forum.developer.betfair.com/forum/developer-program/historical-data/26927-fixed-historical-data-data-for-nov-18-to-date)`

---

## 2019-10-14 20:33:11 - issues channel

**liam**

Apparently this is now fixed [https://forum.developer.betfair.com/forum/developer-program/historical-data/26927-fixed-historical-data-data-for-nov-18-to-date](https://forum.developer.betfair.com/forum/developer-program/historical-data/26927-fixed-historical-data-data-for-nov-18-to-date)

---

## 2019-10-14 11:08:01 - issues channel

**Unknown**

No error. It looks like the files download ok. They have the market id as the name and a .bz2 extension but they won't open in 7-zip. When I opened with notepad they all had the same contents (see attached).

---

## 2019-10-14 10:53:51 - issues channel

**liam**

do you get an error?

---

## 2019-10-01 09:06:25 - general channel

**OT**

Yes I can see how that would work. resubscribing does occasionally cause some other errors down the line, but nothing as bad as not getting subscribed at all.

---

## 2019-10-01 08:32:16 - general channel

**OT**

Has anyone ever had betfair stream subscription requests rejected (connection reset by peer) ? I find it works for 12 hours or so and then starts rejecting the requests. I've tried reducing the volume of requests, incase it is some kind of volume-type issue. My software has some architecture flaws, but I'm almost finished with the replacemnt. Just need a quick fix on the old one at the moment ://

---

## 2019-09-27 13:12:58 - general channel

**Newbie99**

I just wanted to check an assumption, if that's okay...



When cancelling (or placing) an order, the report showing it was successful or failed comes back seemingly before the streaming update.



Therefore I always need to track the position at my end and adjust (if need be) once the streaming update comes?



So for example, in this scenario (assume 0 orders have been placed at the start):



1) Order for 50 @ 20 placed

2) Confirmation order has been placed successfully

3) order count = 0 as no streaming update has been sent yet (unless I adjust locally)

4) streaming update is received

5) order count = 1



and for cancellations:



1) Check order exists

2) If order exists, cancel 30 of the 50

3) Confirmation order has been (partially) cancelled successfully

4) order size_remaining = 50 as no streaming update has been sent yet (unless I adjust locally)

5) Streaming update is received

6) order size_remaining = 20



Hopefully that makes sense and is my logic correct (i.e. that I need to track locally and adjust if need be, post streaming update, I can't treat the placed/cancelled report in the same way as a streaming update)?

---

## 2019-09-21 12:38:58 - issues channel

**Justin Fisher**

```

trading.historic.get_my_data()



{'sport': 'Greyhound Racing', 'plan': 'Basic Plan', 'forDate': '2018-05-01T00:00:00', 'purchaseItemId': 32386}

{'sport': 'Greyhound Racing', 'plan': 'Basic Plan', 'forDate': '2018-06-01T00:00:00', 'purchaseItemId': 32386}

{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-05-01T00:00:00', 'purchaseItemId': 32379}

{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-06-01T00:00:00', 'purchaseItemId': 32379}

{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-11-01T00:00:00', 'purchaseItemId': 22726}

{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-12-01T00:00:00', 'purchaseItemId': 22726}



trading.historic.get_collection_options:

 {'marketTypesCollection': [{'name': '', 'count': 1233}, {'name': 'ANTEPOST_WIN', 'count': 46}, {'name': 'DAILY_WIN_DIST', 'count': 1}, {'name': 'EACH_WAY', 'count': 1113}, {'name': 'FORECAST', 'count': 211}, {'name': 'MATCH_BET', 'count': 1165}, {'name': 'OTHER_PLACE', 'count': 6012}, {'name': 'PLACE', 'count': 4157}, {'name': 'RACE_WIN_DIST', 'count': 188}, {'name': 'REV_FORECAST', 'count': 574}, {'name': 'WIN', 'count': 6909}, {'name': 'WITHOUT_FAV', 'count': 222}], 'countriesCollection': [{'name': 'AR', 'count': 17}, {'name': 'AU', 'count': 4671}, {'name': 'BR', 'count': 10}, {'name': 'CL', 'count': 120}, {'name': 'FR', 'count': 591}, {'name': 'GB', 'count': 6612}, {'name': 'IE', 'count': 1608}, {'name': 'IN', 'count': 128}, {'name': 'NZ', 'count': 744}, {'name': 'PE', 'count': 9}, {'name': 'SE', 'count': 185}, {'name': 'SG', 'count': 138}, {'name': 'US', 'count': 6444}, {'name': 'UY', 'count': 12}, {'name': 'ZA', 'count': 542}], 'fileTypeCollection': [{'name': 'E', 'count': 1233}, {'name': 'M', 'count': 20598}]}



trading.historic.get_data_size:

 {'totalSizeMB': 63, 'fileCount': 23680}



trading.historic.get_file_list:



Traceback (most recent call last):

  File "/Users/justinfisher/anaconda3/lib/python3.6/site-packages/betfairlightweight/endpoints/historic.py", line 166, in request

    response_data = response.json()

  File "/Users/justinfisher/anaconda3/lib/python3.6/site-packages/requests/models.py", line 897, in json

    return complexjson.loads(self.text, **kwargs)

  File "/Users/justinfisher/anaconda3/lib/python3.6/json/__init__.py", line 354, in loads

    return _default_decoder.decode(s)

  File "/Users/justinfisher/anaconda3/lib/python3.6/json/decoder.py", line 339, in decode

    obj, end = self.raw_decode(s, idx=_w(s, 0).end())

  File "/Users/justinfisher/anaconda3/lib/python3.6/json/decoder.py", line 357, in raw_decode

    raise JSONDecodeError("Expecting value", s, err.value) from None

json.decoder.JSONDecodeError: Expecting value: line 4 column 1 (char 6)



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "download_data.py", line 48, in &lt;module&gt;

    market_types_collection=['WIN'],

  File "/Users/justinfisher/anaconda3/lib/python3.6/site-packages/betfairlightweight/endpoints/historic.py", line 116, in get_file_list

    (response, elapsed_time) = self.request(method, params, session)

  File "/Users/justinfisher/anaconda3/lib/python3.6/site-packages/betfairlightweight/endpoints/historic.py", line 168, in request

    raise InvalidResponse(response.text)

betfairlightweight.exceptions.InvalidResponse: Invalid response received:





&lt;!DOCTYPE html&gt;



&lt;html&gt;

&lt;head&gt;

    &lt;meta name="viewport" content="width=device-width" /&gt;

    &lt;title&gt;ngErrorRedirect&lt;/title&gt;

&lt;/head&gt;

&lt;body&gt;

    &lt;div&gt;

        Error

    &lt;/div&gt;

&lt;/body&gt;

&lt;/html&gt;

```

---

## 2019-09-16 16:44:49 - general channel

**jhaa**

now I get StatusCodeError 500 . website seems down as well

---

## 2019-09-16 16:33:21 - general channel

**jhaa**

i am getting 'INSUFFICIENT_FUNDS' as an error in PlaceOrders. I try to bet £3 on a horse. I have like £12k available in the account but I have loads of matched and unmatched bets in other sports. What am I missing?

---

## 2019-09-16 07:38:45 - general channel

**liam**

Simple fix is to use the same queue for both and you will see it working 

---

## 2019-09-16 07:31:46 - general channel

**Newbie99**

yep, I had just stripped out the market bits, the full code is:



```import threading

import logging

from datetime import datetime

import mysql.connector

import queue

from new_functions import calc_live_order_risk, view_runners, view_orders, database_run_sp, getprofitandloss, check_queue, \

    set_initial_market_book, inital_position, create_initial_market_book, calc_initial_risk, check_positions, live_positions, create_initial_risk, combine_stream_results

import auto_hedge

import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

    streaming_order_filter,

    market_filter,

    price_data,

    price_projection,

    ex_best_offers_overrides

)

from account_info import accname, accpass, acckey, path, db_host, db_user, db_passwd, db_database

from betfairlightweight.resources.bettingresources import MarketBook, CurrentOrders

from betfairlightweight.endpoints.account import Account

from betfairlightweight.endpoints.betting import Betting

from place_orders import place_order



logging.basicConfig(level=logging.DEBUG)  # change to DEBUG to see log all updates



filters = betfairlightweight.filters



mysql = mysql.connector



logging.basicConfig(level=[http://logging.info|logging.info](http://logging.info|logging.info))



trading = betfairlightweight.APIClient(accname, accpass, acckey, certs=path)

trading.login()



order_queue = queue.Queue()

order_listener = betfairlightweight.StreamListener(output_queue=order_queue)

order_stream = trading.streaming.create_stream(listener=order_listener)

order_filter = streaming_order_filter(

    include_overall_position=True

    # customer_strategy_refs=[""]

    #    partition_matched_by_strategy_ref=None

)

order_stream.subscribe_to_orders(

    order_filter=order_filter)

order_stream.start(async_=True)



market_ids=['1.148222764','1.132099836','1.130856098']



market_queue = queue.Queue()

market_listener = betfairlightweight.StreamListener(output_queue=market_queue)

market_stream = trading.streaming.create_stream(listener=market_listener)

market_filter = streaming_market_filter(

market_ids=market_ids)



market_data_filter = streaming_market_data_filter(

    fields=['EX_ALL_OFFERS', 'EX_MARKET_DEF', 'EX_TRADED', 'EX_LTP'])



market_stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter)



market_stream.start(async_=True)



mb =[]



initial_risk_list = create_initial_risk(trading, filters, market_ids)



def consumer(queue, initial_risk_list):

    while True:

        message = queue.get()

        output = check_queue(message,'market_list', 'order_list', update_time, initial_risk_list)

        live_data = combine_stream_results(output, mb, queue, update_time)





if __name__ == "__main__":

    format = "%(asctime)s: %(message)s"

    logging.basicConfig(format=format, level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO), datefmt="%H:%M:%S")

    pipeline = queue.Queue(maxsize=50)

    c = threading.Thread(target=consumer, args=(pipeline,initial_risk_list))

    c.start()



while True:

    update_time = datetime.now().strftime("%m/%d/%Y, %H:%M:%S")

    order_books = order_queue.get()

    for order_book in order_books:

        print(order_book.streaming_update)

    order_list = {'order_list': view_orders(order_books)}

    pipeline.put(order_list)

    market_books = market_queue.get()

    for market_book in market_books:

        print(market_book.streaming_update)

    runner_list, mb = view_runners(mb, market_books, mysql, db_host, db_user, db_passwd, db_database)

    runner_list = {'runner_list': runner_list}

    pipeline.put(runner_list)

    market_list = {'market_list': mb}

    pipeline.put(market_list)```

---

## 2019-09-15 23:19:26 - general channel

**Newbie99**

actually ignore that, having pasted it, I can clearly see both messages in the debug output!

---

## 2019-09-15 23:18:09 - general channel

**Newbie99**

The above is with logging set to DEBUG

---

## 2019-09-15 23:17:58 - general channel

**Newbie99**

Just managed to replicate again, placed and cancelled an order, came through instantly via the order stream and nothing on via the market stream :disappointed:



```DEBUG:betfairlightweight.streaming.listener:[Subscription: 1]: UPDATE: {'op': 'mcm', 'id': 1, 'clk': 'ALQGAL4FAMAG', 'pt': 1568585572062, 'mc': [{'id': '1.132099836', 'rc': [{'atl': [[6, 2]], 'id': 10317012}]}]}

DEBUG:betfairlightweight.streaming.listener:[Subscription: 1]: UPDATE: {'op': 'ocm', 'id': 1, 'clk': 'AJ4DAMQDAN0BAJECAKYD', 'pt': 1568585572678, 'oc': [{'id': '1.130856098', 'orc': [{'id': 12832766, 'uo': [{'id': '178731051032', 'p': 2.54, 's': 2, 'side': 'B', 'status': 'E', 'pt': 'L', 'ot': 'L', 'pd': 1568585572000, 'sm': 0, 'sr': 2, 'sl': 0, 'sc': 0, 'sv': 0, 'rac': '', 'rc': 'REG_GGC', 'rfo': '', 'rfs': ''}]}]}]}

{'id': '1.130856098', 'orc': [{'id': 12832766, 'uo': [{'id': '178731051032', 'p': 2.54, 's': 2, 'side': 'B', 'status': 'E', 'pt': 'L', 'ot': 'L', 'pd': 1568585572000, 'sm': 0, 'sr': 2, 'sl': 0, 'sc': 0, 'sv': 0, 'rac': '', 'rc': 'REG_GGC', 'rfo': '', 'rfs': ''}]}]}

{'id': '1.132099836', 'rc': [{'atl': [[6, 2]], 'id': 10317012}]}

DEBUG:betfairlightweight.streaming.listener:[Subscription: 1]: UPDATE: {'op': 'mcm', 'id': 1, 'clk': 'AOYGAO0FAPAG', 'pt': 1568585572693, 'mc': [{'id': '1.130856098', 'rc': [{'atl': [[2.54, 19.72]], 'id': 12832766}]}]}

DEBUG:betfairlightweight.streaming.listener:[Subscription: 1]: UPDATE: {'op': 'mcm', 'id': 1, 'clk': 'AK0HAKcGALMH', 'pt': 1568585573555, 'mc': [{'id': '1.130856098', 'rc': [{'atl': [[2.54, 17.72]], 'id': 12832766}]}]}

DEBUG:betfairlightweight.streaming.listener:[Subscription: 1]: UPDATE: {'op': 'ocm', 'id': 1, 'clk': 'ALwDAOMDAPEBAKUCAMwD', 'pt': 1568585573644, 'oc': [{'id': '1.130856098', 'orc': [{'id': 12832766, 'uo': [{'id': '178731051032', 'p': 2.54, 's': 2, 'side': 'B', 'status': 'EC', 'pt': 'L', 'ot': 'L', 'pd': 1568585572000, 'sm': 0, 'sr': 0, 'sl': 0, 'sc': 2, 'sv': 0, 'rac': '', 'rc': 'REG_GGC', 'rfo': '', 'rfs': ''}]}]}]}

{'id': '1.130856098', 'orc': [{'id': 12832766, 'uo': [{'id': '178731051032', 'p': 2.54, 's': 2, 'side': 'B', 'status': 'EC', 'pt': 'L', 'ot': 'L', 'pd': 1568585572000, 'sm': 0, 'sr': 0, 'sl': 0, 'sc': 2, 'sv': 0, 'rac': '', 'rc': 'REG_GGC', 'rfo': '', 'rfs': ''}]}]}

{'id': '1.130856098', 'rc': [{'atl': [[2.54, 19.72]], 'id': 12832766}]}

```



So I placed and cancelled a £2 bet @ 2.54 on 1.130856098, came through the order stream, but only one instance came through the market stream. Interestingly this time it was the cancel order, previously its only been the placement order.

---

## 2019-09-15 18:55:16 - general channel

**liam**

There can only really be two reasons why, a delayed key or the data is being conflated due to you not reading data off the socket quick enough which could be network or resource issues. If conflated betfair will tell you with a conflated flag which you can see with the debug logs 

---

## 2019-09-15 18:24:30 - general channel

**liam**

Debug will show you everything so if you think there is a problem then set it to debug but I don’t think there is 

---

## 2019-09-15 18:22:28 - general channel

**Newbie99**

but just so I don't miss anything, I have the following line:



```logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))```



Does that need to be changed to debug, or is info level okay for what you're looking for (I did try debug initially and obviously saw a ton of messages, but nothing containing conflate = xxx)?

---

## 2019-09-15 10:07:40 - general channel

**Newbie99**

ooops, fixed now :slightly_smiling_face:

---

## 2019-09-13 10:48:33 - general channel

**OT**

Do you guys and girls feel it's safe to coerce betfair's id strings into integers, for stuff like eventtype  .. with the exception of market_id of course which is clearly a bastard string

---

## 2019-09-12 11:35:13 - general channel

**OT**

Will probably rewrite this thing from scratch soon, then I can fix everything.

---

## 2019-09-12 11:32:07 - general channel

**OT**

would probably hit TOO_MUCH_DATA error, too

---

## 2019-09-12 11:27:38 - general channel

**OT**

there's gotta be some kind of meme for when time.sleep(1)  "fixes" your code

---

## 2019-09-12 11:05:17 - general channel

**OT**

just a thread crashing when it hits this error.

---

## 2019-09-12 10:58:06 - general channel

**OT**

if the stream is expecting a fresh subscription, but it gets a delta (because it's already subscribed to that market), might this error occur?

---

## 2019-09-12 10:41:49 - general channel

**OT**

betfairlightweight.exceptions.CacheError: "EX_MARKET_DEF" must be requested to use cache

---

## 2019-09-12 10:41:03 - general channel

**liam**

what error?

---

## 2019-09-12 10:39:25 - general channel

**OT**

I have been battling this error for a long time

---

## 2019-09-12 10:38:30 - general channel

**OT**

I'm just occasionally hitting this cache error, but I am definitely setting EX_MARKET_DEF. I don't actually want to disable the cache, I just want to debug around it. I think it's something to do with a market update coming in while I'm resubscribing to markets.

---

## 2019-09-11 01:42:02 - issues channel

**Rob (NZ)**

[@UBS7QANF3](@UBS7QANF3) do you have any example code of how you use it outside of Betfairlightweight ,   am i right in thinking there is a new variable available in the data so its erroring out as its not expecting it.   Is there anything I could do to help fix it up (i just wonder if others like me who use the example code that betfair provide around python might be in the same boat and im happy to try and help contribute just not how best to make that happen)

---

## 2019-09-10 09:53:05 - issues channel

**Rob (NZ)**

Anyone having any issues with the TypeError: __init__() got an unexpected keyword argument 'avgPriceRaw'



During handling of the above exception, another exception occurred:

---

## 2019-09-10 08:45:12 - general channel

**liam**

Yeah it looks like it, ‘being fixed’ but we have heard that before...

---

## 2019-09-07 13:37:06 - issues channel

**Unknown**

Anyone else ever had an error like this? Looks like the data is being truncated somewhere when being sent over the socket, seems to happen randomly, note that this is a large string as there should be a lot of marketId's in that request as opposed to the two you can see

---

## 2019-09-06 13:13:17 - general channel

**stefan**

Getting an `ObjectMoved` from the API when trying via CURL as well.



```&lt;html&gt;&lt;head&gt;&lt;title&gt;Object moved&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h2&gt;Object moved to &lt;a href="/#/error.html"&gt;here&lt;/a&gt;.&lt;/h2&gt; &lt;/body&gt;&lt;/html&gt;```

---

## 2019-09-06 11:38:13 - issues channel

**liam**

not for streaming as these are fixed known threads

---

## 2019-09-06 10:51:35 - issues channel

**liam**

odd to use an executor when you will have 3 fixed threads

---

## 2019-08-30 16:31:01 - issues channel

**Rory**

```    def grouper(self, iterable, n, fillvalue=None):

        "Collect data into fixed-length chunks or blocks"

        # grouper('ABCDEFG', 3, 'x') --&gt; ABC DEF Gxx"

        args = [iter(iterable)] * n

        return zip_longest(*args, fillvalue=fillvalue)```

---

## 2019-08-30 16:00:50 - issues channel

**Rory**

```AttributeError: No market_book found for match:[Strasbourg v Monaco]```

---

## 2019-08-30 16:00:31 - issues channel

**Rory**

e.g. just ran it and got this from my code ... ```AttributeError: No market_book found for match:[Wigan v Barnsley]```

---

## 2019-08-30 11:56:05 - issues channel

**Newbie99**

Ah found the problem, I recently started switching my code to use threading and I was opening tons of connections (or trying to) just for the order stream, rather than one connection. All fixed now!

---

## 2019-08-29 22:52:24 - issues channel

**Newbie99**

'ERROR:betfairlightweight.streaming.listener:[Subscription: 2] MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s).'



I've just started to get this error now too. It seems a few people are, is this a new thing (in the docs it suggested the limit was 200 markets)?

---

## 2019-08-28 16:25:24 - issues channel

**liam**

2019-08-28 16:25:01,820 | ERROR | [Subscription: 1001] MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s).

---

## 2019-08-28 16:23:47 - issues channel

**liam**

2019-08-28 16:23:26,414 | ERROR | [Subscription: 1001] MAX_CONNECTION_LIMIT_EXCEEDED: You have exceeded your max connection limit which is: 10 connection(s).You currently have: 11 active connection(s).

---

## 2019-08-23 09:40:03 - general channel

**liam**

Thanks to [@UDCDFJ0NS](@UDCDFJ0NS) I created a PR which fixes a pretty major bug with the streaming order cache when betting on handicap markets. I am surprised this hasn't been found before, is there anyone out there using order streaming with handicap markets? [@U4H3EEV45](@U4H3EEV45) [@UBS7QANF3](@UBS7QANF3) [@U5D4ZBEAG](@U5D4ZBEAG)?

---

## 2019-08-20 08:39:52 - general channel

**liam**

Fairly sure that is not possible using the SP data, it’s very basic and full of errors 

---

## 2019-08-16 17:33:30 - general channel

**Rory**

a little bit like Cloud9 ... where you can write a serverless function, debug it, test it and then deploy that same function ... all from within the IDE ... no messing around with different tools

---

## 2019-08-16 17:16:15 - general channel

**Rory**

it would be nice to have a single environment where you did everything, instead of maintaining the same packages/versions/etc between the local machine and container ... there's really a lot of overlap between venv and containers ... both create a separate environment for you to work in ... ideally you'd just use one ... i.e point your IDE at a container that has everything set up ... want to try a new version of Python, then point to a different container .. but of course. debugging with containers is difficult which is why I asked the original question

---

## 2019-08-16 13:00:10 - general channel

**Ian**

I think the debug in container is for large teams - making environment setup for new devs less hassle 

---

## 2019-08-16 12:05:41 - general channel

**liam**

unless you are using a slim/alpine image or something funky I see no benefit in debugging your code in a container. Normally flow is code/debug in an ide -&gt; create container -&gt; run tests using unittest or docker-compose-test -&gt; deploy

---

## 2019-08-16 12:04:23 - general channel

**Rory**

I believe the paid version of PyCharm has remote debugging for Python but I don't feel like shelling out for that :grin:

---

## 2019-08-16 12:03:51 - general channel

**Rory**

I take that to mean actual dev and not just deployments though ... unit tests obviously help but I'm still pretty keen on using a debugger ... and that's what holds me back from doing proper dev on containers (for Python at least. Eclipse has the notion of remote debuggers for Java).

---

## 2019-08-16 11:59:00 - general channel

**Rory**

[@U7R5CEDAL](@U7R5CEDAL) how do you debug Python code running inside a container?

---

## 2019-08-10 23:08:43 - issues channel

**liam**

I have mentioned to Neil that what happens at the moment is unexpected but I will add a fix in the latest release so that it won’t throw an error 

---

## 2019-08-10 00:00:44 - issues channel

**Rob (NZ)**

is that something betfair would look at correcting or is it something we could code around (something like ignore the error and just take the MGA data)

---

## 2019-08-09 10:31:05 - issues channel

**Rob (NZ)**

---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

C:\anaconda\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in process_response(self, response_json, resource, elapsed_time, lightweight)

    106             try:

--&gt; 107                 return [resource(elapsed_time=elapsed_time, **x) for x in result]

    108             except TypeError:



C:\anaconda\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in &lt;listcomp&gt;(.0)

    106             try:

--&gt; 107                 return [resource(elapsed_time=elapsed_time, **x) for x in result]

    108             except TypeError:



C:\anaconda\lib\site-packages\betfairlightweight\resources\bettingresources.py in __init__(self, **kwargs)

    256         self.description = MarketCatalogueDescription(**kwargs.get('description')) if \

--&gt; 257             kwargs.get('description') else None

    258         self.runners = [RunnerCatalogue(**i) for i in kwargs.get('runners', [])]



TypeError: __init__() missing 7 required positional arguments: 'discountAllowed', 'marketBaseRate', 'persistenceEnabled', 'regulator', 'rules', 'rulesHasDate', and 'wallet'



During handling of the above exception, another exception occurred:



InvalidResponse                           Traceback (most recent call last)

&lt;ipython-input-29-d9f9200f7a2b&gt; in &lt;module&gt;

      9     max_results='100',

     10     market_projection = ['MARKET_DESCRIPTION','RUNNER_METADATA','MARKET_START_TIME'],

---&gt; 11     sort='FIRST_TO_START'

     12 )

     13



C:\anaconda\lib\site-packages\betfairlightweight\endpoints\betting.py in list_market_catalogue(self, filter, market_projection, sort, max_results, locale, session, lightweight)

    156         method = '%s%s' % (self.URI, 'listMarketCatalogue')

    157         (response, elapsed_time) = self.request(method, params, session)

--&gt; 158         return self.process_response(response, resources.MarketCatalogue, elapsed_time, lightweight)

    159

    160     def list_market_book(self, market_ids, price_projection=None, order_projection=None,



C:\anaconda\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in process_response(self, response_json, resource, elapsed_time, lightweight)

    107                 return [resource(elapsed_time=elapsed_time, **x) for x in result]

    108             except TypeError:

--&gt; 109                 raise InvalidResponse(response=result)

    110         else:

    111             try:



InvalidResponse: Invalid response received: [{'marketId': '1.161129845', 'marketName': 'R3 2200m Trot S', 'marketStartTime': '2019-08-09T09:00:00.000Z', 'description': {'persistenceEnabled': True, 'bspMarket': True, 'marketTime': '2019-08-09T09:00:00.000Z', 'suspendTime': '2019-08-09T09:00:00.000Z', 'bettingType': 'ODDS', 'turnInPlayEnabled': True, 'marketType': 'WIN', 'regulator': 'MALTA LOTTERIES AND GAMBLING AU

---

## 2019-08-09 10:31:01 - issues channel

**Rob (NZ)**

i think im getting a similar error to [@UFTBRB3F1](@UFTBRB3F1) got...

---

## 2019-08-07 21:02:06 - general channel

**Chris**

still getting the error now though

---

## 2019-08-07 20:47:56 - general channel

**Chris**

DEBUG:botocore.args:The s3 config key is not a dictionary type, ignoring its value of: None

---

## 2019-08-07 20:45:32 - general channel

**Chris**

DEBUG:betfairlightweight.streaming.listener:[Subscription: 1001]: HEARTBEAT: {‘op’: ‘mcm’, ‘id’: 1001, ‘clk’: ‘ALshANI2AOYg’, ‘pt’: 1565207117314, ‘ct’: ‘HEARTBEAT’}

---

## 2019-08-07 20:21:42 - general channel

**liam**

Set logging to debug to see what is going on 

---

## 2019-08-06 08:28:48 - general channel

**richard_h**

Strange started seeing this recently and now I'm logged out for 20 minutes at a time  betfairlightweight.exceptions.LoginError: API login: TEMPORARY_BAN_TOO_MANY_REQUESTS

---

## 2019-08-05 15:06:49 - general channel

**Ian**

i would say on average one error every 24h - max 3 some never

---

## 2019-07-24 09:35:50 - general channel

**liam**

Can you set logging to DEBUG and let it run through?

---

## 2019-07-23 14:35:15 - general channel

**Mo**

[@U4H19D1D2](@U4H19D1D2) what's your plan for a permanent fix for the IPS URL?

---

## 2019-07-23 10:38:36 - general channel

**liam**

Probably not, getting an error?

---

## 2019-07-19 21:27:26 - issues channel

**Newbie99**

Ah yes, sorry, so after the first iteration the len will have shrunk! Okay, dumb error! Thanks!

---

## 2019-07-19 21:01:47 - issues channel

**Newbie99**

I keep getting:



```

Traceback (most recent call last):

  File "D:/Python37/webpages/betfair_python.py", line 178, in &lt;module&gt;

    if y.market_id == market_books[i].market_id:

IndexError: list index out of range

```



line 178 relates to ``` if y.market_id == market_books[i].market_id:``` in the code below



Which is confusing me, as in my code, I thought that this line ```for i in range(len(market_books)):``` should have caught that. So apologies once again, for no doubt a very simplistic error, but can anyone spot where I've gone wrong here?



```

while True:

    combined_books = market_queue.get()

    old_order_market_id_list = []

    new_order_market_id_list = []



    for y in combined_books:

        temp_order_books = []

        temp_market_books = []

        if isinstance(y, MarketBook):

            for market_book in market_books:

                if y.market_id not in market_book.market_id:

                    temp_market_books.append(y)

                else:

                    for i in range(len(market_books)):

                        if y.market_id == market_books[i].market_id:

                            temp_market_books.append(y)

                            del market_books[i]



```

---

## 2019-07-19 10:55:55 - general channel

**liam**

Normally streaming will give a 503 and you just have to wait but you do need to add error handling to start as you get the odd socket closure and connection error which is raised through a bflw exception 

---

## 2019-07-19 10:48:23 - general channel

**Oliver Varney**

do you just have exception handling that tries to reconnect?

---

## 2019-07-18 17:18:50 - general channel

**jhaa**

Do you know how much time I have after the fixture ends to grab the final result?

---

## 2019-07-18 16:48:41 - general channel

**jhaa**

Thanks liam. I tried that before but received a 503 error - assumed it was because the event ended

---

## 2019-07-17 12:54:08 - random channel

**William**

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\threading.py", line 917, in _bootstrap_inner

    self.run()

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\threading.py", line 865, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 198, in _read_loop

    self._data(received_data)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 237, in _data

    if self.listener.on_data(received_data) is False:

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\listener.py", line 115, in on_data

    self._on_change_message(data, unique_id)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\listener.py", line 148, in _on_change_message

    self.stream.on_update(data)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\stream.py", line 55, in on_update

    self._process(data[self._lookup], publish_time)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\stream.py", line 130, in _process

    market_book_cache.update_cache(market_book, publish_time)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 189, in update_cache

    runner.best_display_available_to_back.update(new_data['bdatb'])

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 61, in update

    self.sort()

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 40, in sort

    {'price': volume[self.deletion_select-1], 'size': volume[self.deletion_select]} for volume in self.prices

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 40, in &lt;listcomp&gt;

    {'price': volume[self.deletion_select-1], 'size': volume[self.deletion_select]} for volume in self.prices

IndexError: list index out of range

---

## 2019-07-17 12:53:58 - random channel

**Mo**

What errors?

---

## 2019-07-17 12:53:37 - random channel

**William**

Are there any issues with this API and using EX_BEST_OFFERS_DISP, seem to be getting some errors when it is used in the filters

---

## 2019-07-16 12:11:19 - general channel

**William**

Sorry for all the questions this has been bugging me

---

## 2019-07-15 23:05:02 - general channel

**Filippo Bovo**

[@U4H19D1D2](@U4H19D1D2), sorry, maybe I did not explain myself correctly. It works well on my local machine. Moreover, it works well on the AWS instance if I log out a few minutes after logging in. However, when I try to schedule the start of the market stream the night before on AWS, the day after I get the error when logging out.

---

## 2019-07-15 09:19:11 - general channel

**liam**

[@UHQV8CW1Y](@UHQV8CW1Y) are you saying it works on AWS but not locally? On the buggy instance what version of openssl are you running?

---

## 2019-07-14 22:52:36 - general channel

**Filippo Bovo**

Here is the error that I get:

---

## 2019-07-14 22:52:11 - general channel

**Filippo Bovo**

Hello, everyone. When I log out of Betfair through the APIs after these steps, I get a `ConnectionError`:

1. The day before a match, I set up a scheduler that waits until 30 minutes before the start of a match to begin streaming a market.

2. 30 minutes before the start of the match, the scrip logs in again to Betfair if `trading.session_expired` is true and launches the market stream.

3. As soon as the match turns in-play the stream stops and the scrips logs out of Betfair as `trading.logout()` — at that point I've got the error.



Note that I run the above script in an AWS compute instance and that normally, I don't get errors when I log out.



Does anyone have a hint at why I get the error? Thanks.

---

## 2019-07-12 23:51:04 - general channel

**Newbie99**

apologies...one final dumb question before bedtime...



I was just trying to put a quick fix in, before I delve into a whole new threading solution, but what I thought would be a fairly simple logical process...isn't:



```

while True:

    x = market_queue.get()



    for y in x:

        if type(y) == type(MarketBook):

            print('MarketBook: ', y)

        else:

            if type(y) == type(CurrentOrders):

                print('CurrentOrders: ', y)

            else:

                print('No idea: ', y)

```



I assumed I could neatly split out the single queue like that (for now, I can come up with a better solution later), however it seems to think nothing belongs to either custom class, i.e:



```

No idea:  CurrentOrders

No idea:  CurrentOrders

No idea:  MarketBook

No idea:  MarketBook

```



(I don't get an error, so I believe the custom classes are imported correctly)...so what have I missed here...I know it's going to be something blindingly obvious!

---

## 2019-07-12 08:23:53 - issues channel

**Newbie99**

overnight (about 4:18 this morning), I got the following error, is this likely to be a problem with my code, or something remote (I ask as I've not seen this error before, so it seems odd that it could suddenly appear without me changing anything)?

---

## 2019-07-07 19:38:30 - general channel

**Mo**

[https://support.developer.betfair.com/hc/en-us/articles/115003887111-Why-am-I-receiving-the-error-BETTING-RESTRICTED-LOCATION-](https://support.developer.betfair.com/hc/en-us/articles/115003887111-Why-am-I-receiving-the-error-BETTING-RESTRICTED-LOCATION-)

---

## 2019-07-07 19:23:09 - general channel

**Filippo Bovo**

Has anyone used a Google Cloud instance to log in to the Betfair APIs? I am using a Google Cloud instance based in London (I also double checked that the IP address is based in London and it is). I get the following error when I try to log in `BETTING_RESTRICTED_LOCATION`. Has anyone had a similar experience with Google Cloud? Thanks.

---

## 2019-07-06 20:23:06 - general channel

**Chris**

I seem to be unable to start streams, I get this error ‘ERROR:betfairlightweight.streaming.listener:[Subscription: 2] NOT_AUTHORIZED: AppKey is not configured for service’ :thinking_face:

---

## 2019-06-28 14:18:42 - general channel

**Brenton Collins**

Hello, new to this group. Has anyone had issues with the OverflowError: Maximum recursion level reached python. it is happening when placing a bet in a loop, I can manage to place a bet by punching the data for each bet but as soon as I put it in a list and set the loop going I get an overflow error!!

---

## 2019-06-27 12:42:32 - general channel

**Erdem**

thank you how can i activate my normal api key, just delayed one activated and i am getting "NOT_AUTHORIZED","errorMessage":"AppKey is not configured for service" error

---

## 2019-06-20 21:43:24 - general channel

**Dan**

Traceback (most recent call last):

  File "&lt;input&gt;", line 1, in &lt;module&gt;

  File "C:\Users\danmi\PycharmProjects\bflight\venv\lib\site-packages\betfairlightweight\endpoints\login.py", line 30, in __call__

    (response, elapsed_time) = self.request(self.url, session=session)

  File "C:\Users\danmi\PycharmProjects\bflight\venv\lib\site-packages\betfairlightweight\endpoints\login.py", line 42, in request

    raise APIError(None, exception=e)

betfairlightweight.exceptions.APIError: None

Params: None

Exception: Certificate folder not found in C:/users/danmi/PycharmProjects/bflight/venv/Lib/site-packages/betfairlightweight/certs

---

## 2019-06-20 21:42:20 - general channel

**Dan**

Back with another basic question before I've even getting to login :confused: I get the following error when attempting to login

---

## 2019-06-20 12:00:53 - general channel

**Mo**

(FYI I'm just writing this off the top of my head so there could be some obvious typos or other errors)

---

## 2019-06-15 18:23:44 - general channel

**liam**

Currently rebuilding the API / migrating the data. The background was that historical data was to be accessed through the web app, when released I reverse engineered the API and added to bflw as well as highlighting a few issues to betfair. They responded by fixing and adding the documentation, they then underestimated the load from people automating the downloading thus the refactor. 

---

## 2019-06-13 13:40:50 - issues channel

**stefan**

That's the one with DEBUG log.

---

## 2019-06-13 13:40:44 - issues channel

**stefan**

```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

INFO:betfairlightweight.streaming.stream:[Stream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[Connect: 1]: connection_id: xxx

ERROR:betfairlightweight.streaming.listener:[Subscription: 2] UNEXPECTED_ERROR: Unknown error authenticating

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 917, in _bootstrap_inner

    self.run()

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 865, in run

    self._target(*self._args, **self._kwargs)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 198, in _read_loop

    self._data(received_data)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 239, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: xxx, data: {"op":"status","id":2,"statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"Unknown error authenticating","connectionClosed":true,"connectionId":"xxx"}```

---

## 2019-06-13 13:39:36 - issues channel

**liam**

different error?

---

## 2019-06-13 13:38:55 - issues channel

**stefan**

Logs:```DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): [http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443](http://identitysso-cert.betfair.com:443|identitysso-cert.betfair.com:443)

DEBUG:urllib3.connectionpool:[https://identitysso-cert.betfair.com:443](https://identitysso-cert.betfair.com:443) "POST /api/certlogin HTTP/1.1" 200 87

INFO:betfairlightweight.streaming.stream:[Stream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[Connect: 1]: connection_id: xxx

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 212, in _receive_all

    part = self._socket.recv(self.buffer_size)

  File "C:\ProgramData\Anaconda3\lib\ssl.py", line 1037, in recv

    return self.read(buflen)

  File "C:\ProgramData\Anaconda3\lib\ssl.py", line 913, in read

    return self._sslobj.read(len)

ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 917, in _bootstrap_inner

    self.run()

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 865, in run

    self._target(*self._args, **self._kwargs)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 191, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 216, in _receive_all

    raise SocketError('[Connect: %s]: Socket %s' % (self._unique_id, e))

betfairlightweight.exceptions.SocketError: [Connect: 2]: Socket [WinError 10054] An existing connection was forcibly closed by the remote host```

---

## 2019-06-13 13:36:08 - issues channel

**liam**

/ set logging to DEBUG and share logs

---

## 2019-06-13 13:33:10 - issues channel

**stefan**

Hi all, quick question regarding authentication. I am having trouble to establish a connection using `APIClient`. I am using the sample code `examplestreaming.py` from the repo with my details:



`trading = betfairlightweight.APIClient('xxx', 'xxx', app_key='xxx', cert_files=('./certs/client-2048.crt', './certs/client-2048.key'))`



When connecting I am getting the following error:```INFO:betfairlightweight.streaming.stream:[Stream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[Connect: 1]: connection_id: xxx

ERROR:betfairlightweight.streaming.listener:[Subscription: 2] UNEXPECTED_ERROR: Unknown error authenticating

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 917, in _bootstrap_inner

    self.run()

  File "C:\ProgramData\Anaconda3\lib\threading.py", line 865, in run

    self._target(*self._args, **self._kwargs)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 198, in _read_loop

    self._data(received_data)

  File "C:\ProgramData\Anaconda3\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 239, in _data

    raise ListenerError(self.listener.connection_id, received_data)

betfairlightweight.exceptions.ListenerError: connection_id: xxx, data: {"op":"status","id":2,"statusCode":"FAILURE","errorCode":"UNEXPECTED_ERROR","errorMessage":"Unknown error authenticating","connectionClosed":true,"connectionId":"xxx"}

```



I was able to establish a connection using the sample code from betfair: `[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login#Non-Interactive(bot)login-SamplePythoncode](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Non-Interactive+%28bot%29+login#Non-Interactive(bot)login-SamplePythoncode)`

Also the curl command with the same certificates and credentials is working fine to establish a connection.



Any suggestions/help would be very welcome. Thanks.

---

## 2019-06-11 15:31:37 - general channel

**Mo**

Sorry wasn't it you that posted [https://stackoverflow.com/questions/55420596/index-error-when-using-betfairlightweight](https://stackoverflow.com/questions/55420596/index-error-when-using-betfairlightweight)?

---

## 2019-06-02 21:14:03 - general channel

**Chris**

Trying to display data from a market using Pandas as per the example on the Betfair site (I think I remember seeing these weren't created by anyone here and weren't great, but nonetheless seems the best place to ask), basically have the same problem as this stackoverflow post (but this isn't me), any advice greatly appreciated... [https://stackoverflow.com/questions/55420596/index-error-when-using-betfairlightweight](https://stackoverflow.com/questions/55420596/index-error-when-using-betfairlightweight)

---

## 2019-05-31 07:09:22 - issues channel

**liam**

my issue was that in framework I had a Market class which was storing a history of all prices/analytics, so come the end of a race this had a rather large memory footprint. I was deleting on closure along with what I thought was all references but after a lot of debugging I found i had a reference to it in my logging framework. you can try deleting all closed markets in the cache (listener.stream._cache)

---

## 2019-05-26 09:02:38 - general channel

**liam**

v1.10.0 released which fixes a few bugs (vscode/stop) and a new type of historical data stream (generator) [https://github.com/liampauling/betfair/blob/master/HISTORY.rst](https://github.com/liampauling/betfair/blob/master/HISTORY.rst)

---

## 2019-05-24 17:45:11 - issues channel

**Newbie99**

I keep randomly getting the following error (but not every time, seems to happen 3/5 times for a period then not again for ages, very odd):



```

betfairlightweight.exceptions.InvalidResponse: Invalid response received:

```



Sort of tricky to decipher exactly where its comeing from, possibly from:



```

        market_catalogues = trading.betting.list_market_catalogue(

        market_projection=["RUNNER_DESCRIPTION", "RUNNER_METADATA", "COMPETITION", "EVENT", "EVENT_TYPE",

                           "MARKET_DESCRIPTION", "MARKET_START_TIME"],

        filter=betfairlightweight.filters.market_filter(

        with_orders=["EXECUTION_COMPLETE", "EXECUTABLE"]),

        max_results=800)

```



Also, I think this has only occurred since the last update. Could it be related to the issue in the conversation above by chance, or is that a totally separate issue?

---

## 2019-05-22 09:46:02 - issues channel

**T**

post on here if you get round to fixing this problem when you next release a new version

---

## 2019-05-22 09:08:58 - issues channel

**liam**

when a PR arrives :wink: this doesn't impact me so in no rush to fix but can merge a PR whenever

---

## 2019-05-22 06:55:50 - issues channel

**liam**

Quick fix, use pycharm or wait for a new release 

---

## 2019-05-22 02:03:24 - issues channel

**T**

``` OverflowError                             Traceback (most recent call last)

&lt;ipython-input-56-134ce2a3b2dc&gt; in &lt;module&gt;()

     26     place_orders = trading.betting.place_orders(

     27         market_id=market_id,

---&gt; 28         instructions=[instruction])

     29 

     30     break



C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\betting.py in place_orders(self, market_id, instructions, customer_ref, market_version, customer_strategy_ref, async_, session, lightweight)

    331         params = clean_locals(locals())

    332         method = '%s%s' % (self.URI, 'placeOrders')

--&gt; 333         (response, elapsed_time) = self.request(method, params, session)

    334         return self.process_response(response, resources.PlaceOrders, elapsed_time, lightweight)

    335 



C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in request(self, method, params, session)

     34         """

     35         session = session or self.client.session

---&gt; 36         request = self.create_req(method, params)

     37         date_time_sent = datetime.datetime.utcnow()

     38         try:



C:\Users\user\Anaconda3\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py in create_req(method, params)

     71                 'method': method,

     72                 'params': params,

---&gt; 73                 'id': 1

     74             }

     75         )



OverflowError: Maximum recursion level reached````

---

## 2019-05-22 02:02:55 - issues channel

**T**

I am confronted with this error message:

---

## 2019-05-16 21:34:05 - issues channel

**Newbie99**

I'm getting a weird error, out of the blue (on another machine the script runs fine), any ideas what could have got messed up (betfairlightweight appears to be installed correctly, re-installed just now, but no joy):



```

Traceback (most recent call last):

  File "D:/Python37/webpages/betfair_python.py", line 61, in &lt;module&gt;

    market_stream.start(_async=True)

TypeError: start() got an unexpected keyword argument '_async'



```



Any pointers as to what might be causing this?



For reference, if I were to remove the _async=True then instead of an error it just hangs at:



```

INFO:betfairlightweight.streaming.stream:[Stream: 1]: "OrderStream" created

INFO:betfairlightweight.streaming.stream:[Stream: 1]: "MarketStream" created

INFO:betfairlightweight.streaming.listener:[Connect: 1]: connection_id: 006-160519203236-239625

INFO:betfairlightweight.streaming.listener:[Subscription: 2]: SUCCESS

INFO:betfairlightweight.streaming.listener:[Subscription: 1]: SUCCESS

INFO:betfairlightweight.streaming.stream:[MarketStream: 1] 1.130856098 added, 1 markets in cache

INFO:betfairlightweight.streaming.stream:[Stream: 1]: 1 mc added

```

---

## 2019-04-17 12:25:57 - general channel

**Rob (NZ)**

Cheers Liam... I'll have to learn about the debugger... I'm just using Jupyter notebook

---

## 2019-04-17 11:47:06 - general channel

**liam**

[@UH9MMLXAS](@UH9MMLXAS) use your debugger! It will tell you straight away what’s in those objects 

---

## 2019-04-14 13:03:18 - issues channel

**phil**

and got this error

---

## 2019-04-12 10:32:19 - general channel

**liam**

debugger is your friend

---

## 2019-04-11 13:29:03 - issues channel

**OT**

[@U4H19D1D2](@U4H19D1D2) thanks, I'm debugging it now. I'm suspecting some kind of race between bfl thinking there is a fresh subscription and a delta that's lagging from before the re-subscription. but I haven't found the evidence for it yet.

---

## 2019-04-11 11:56:22 - general channel

**Rob (NZ)**

Overflowerror

---

## 2019-04-11 11:56:14 - general channel

**Rob (NZ)**

Weird I'm now getting a maximum recursion level reached error

---

## 2019-04-11 11:19:09 - general channel

**Rob (NZ)**

But still getting the same error...

---

## 2019-04-11 10:54:54 - issues channel

**OT**

hi all, has anyone else hit this exception: [https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/cache.py#L144](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/cache.py#L144) even though EX_MARKET_DEF has been set in the filter? I usually get it when I'm re-subscribing (ie from an internet outage), I think. but it's pretty intermittent. It could be some kind of race in my code, too.

---

## 2019-04-11 10:41:01 - general channel

**Unknown**

I've taken the other code and changed it over to list_runner_book but getting a error ... totally think is me just making a meal of it though

---

## 2019-04-11 00:56:52 - issues channel

**T**

...OverflowError: Maximum recursion level reached

---

## 2019-04-11 00:54:27 - issues channel

**T**

Just hit an error I've never seen before when trying to place a bet

---

## 2019-04-09 13:02:48 - general channel

**liam**

Open up your debugger and look at the response 

---

## 2019-04-08 00:51:24 - general channel

**Rob (NZ)**

Anyone have a example of placing a fixed liability bet  when laying ...  so just at say current market price...

---

## 2019-04-04 10:17:03 - general channel

**liam**

if you set logging to debug and use a session, make requests every x seconds and increase x by 2 every time you will see that eventually another handshake will be made

---

## 2019-04-04 00:04:09 - general channel

**Rob (NZ)**

Hey all.. thanks for all the help and I'm now able to access and submit to the api ...  I can put on back and  lay bets for a fixed amount... where would the best place to find putting details around placing by liability  and potential that being below the minimum

---

## 2019-04-02 21:23:51 - issues channel

**liam**

Change logging to DEBUG to see more

---

## 2019-04-02 21:12:36 - issues channel

**Paw**

got it fixed (it needed a 1.market_id :)

---

## 2019-03-27 06:48:22 - general channel

**Unknown**

Still getting this error...  will attach the code I'm using also

---

## 2019-03-25 23:07:29 - general channel

**Rob (NZ)**

Not sure if this is the ok to ask so please forgive me if not....  just trying to connect using the example python code on betfair and getting this error...   



 certs_path = r'/"certs"



is getting me 



File "&lt;ipython-input-23-e458ea84454c&gt;", line 11 certs_path = r'/"certs" ^ SyntaxError: EOL while scanning string literal 





Any ideas or pointers... 

---

## 2019-03-24 23:20:56 - issues channel

**Paw**

I'm getting ERROR:betfairlightweight.streaming.listener:[Subscription: 2] NOT_AUTHORIZED: AppKey is not configured for service

---

## 2019-03-23 09:00:48 - issues channel

**liam**

Wait until they fix it, last I heard it was April

---

## 2019-03-16 10:44:01 - general channel

**Unknown**

Trying to understand `time_range` arguments. If I specify the below then I get all day correctly. However, if I pass ```filters.time_range("2019-03-16 11:00:00", "2019-03-16 14:00:00")``` in the hope of getting a smaller window I get a DSC-0018 error. Any ideas please?

---

## 2019-03-15 22:01:03 - general channel

**Newbie99**

I think, this a 2 second question for someone (not streaming related).



```

current_order_list = trading.betting.list_current_orders(

    order_by="BY_MATCH_TIME",

    sort_dir="LATEST_TO_EARLIEST",

    record_count="20",

    lightweight=False)





print(current_order_list._data)

```



That works fine, except I can't seem to work out the correct way to iterate through Bet_id, I assumed I could just do something like:



```

for a in current_order_list:

    for b in a.currentOrders:

        print(b)

```



But that returns:



```

TypeError: 'CurrentOrders' object is not iterable

```



testing a[0] doesn't work either, so clearly I'm missing the correct way to iterate through this, as I've tried various alternatives and I can't figure it out....although I'm sure its a blindingly obvious answer! Would anyone care to put me out of my misery on this one?

---

## 2019-03-04 09:24:00 - issues channel

**ShahGar**

I'm getting MAXCONNECTION LIMIT ERROR after a while of iterating over and streaming data from different markets, which hinders me from making new streaming connections. I guess I have to close the streaming connections at the end of each iteration. But how can I do that? (I've tried stream.stop())

---

## 2019-03-03 21:25:06 - issues channel

**Newbie99**

I have another frustratingly dumb question...all I'm trying to do, is append runner name into market_book, based on selectionId. Logically this shouldn't be difficult, but I keep getting various errors, regardless of which method I use.



All I'm doing is, using the code posted the other day (or very similar):



```

    for market_book in market_books:

       for runner in market_book.runners:



        market_catalogues = trading.betting.list_market_catalogue(

            market_projection=["RUNNER_DESCRIPTION", "RUNNER_METADATA", "COMPETITION", "EVENT", "EVENT_TYPE", "MARKET_DESCRIPTION", "MARKET_START_TIME"],

            filter=betfairlightweight.filters.market_filter(

                market_ids=[market_book.market_id],

            ),

            max_results=100)



        data = []

        for market_catalogue in market_catalogues:

            for runner in market_catalogue.runners:

                data.append(

                    (runner.selection_id, runner.runner_name)

                )

```



That all works fine, but I then want to add runner name into market_book, based on selection_id = selectionId and I can't seem to do it.



Is this just a stupid idea (i.e. am I missing the obvious and market_book(s) is actually immutable?), should I simply be creating a new list and appending that with what I need from market_book(s) and the above 2 column data list, or is it a sensible approach and I'm just don't know how to do it correctly?

---

## 2019-02-23 19:48:38 - issues channel

**Newbie99**

Ok that of course makes sense, I just assumed I wasn't understanding, I thought that's what Liam suggested above, but I think he didn't spot the error in my code.



Okay, yes, logically that makes sense, I was persisting was flawed logic.

---

## 2019-02-20 18:36:23 - issues channel

**Newbie99**

I still get: ```NameError: name 'Queue' is not defined```

---

## 2019-02-20 18:32:47 - issues channel

**Newbie99**

I tried that initially, but for some reason I get an error (I've played around with variants too just to see if I could work it out):



```

ERROR:engineio.server:message handler error

Traceback (most recent call last):

  File "D:/Python37/webpages/betfair_flaskio.py", line 51, in handle_message

    market_books = output_queue.get(False)

  File "D:\Python37\lib\queue.py", line 167, in get

    raise Empty

_queue.Empty



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:\Python37\lib\site-packages\engineio\server.py", line 505, in _trigger_event

    return self.handlers[event](*args)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 590, in _handle_eio_message

    self._handle_event(sid, pkt.namespace, pkt.id, pkt.data)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 526, in _handle_event

    self._handle_event_internal(self, sid, data, namespace, id)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 529, in _handle_event_internal

    r = server._trigger_event(data[0], namespace, sid, *data[1:])

  File "D:\Python37\lib\site-packages\socketio\server.py", line 558, in _trigger_event

    return self.handlers[namespace][event](*args)

  File "D:\Python37\lib\site-packages\flask_socketio\__init__.py", line 258, in _handler

    *args)

  File "D:\Python37\lib\site-packages\flask_socketio\__init__.py", line 641, in _handle_event

    ret = handler(*args)

  File "D:/Python37/webpages/betfair_flaskio.py", line 52, in handle_message

    except queue.empty:

AttributeError: module 'queue' has no attribute 'empty'

```

---

## 2019-02-20 18:05:22 - issues channel

**Newbie99**

haha, the problem I come up against is logging the empty, I can catch other errors, but couldn't work out how to catch the Empty!

---

## 2019-02-20 17:45:18 - issues channel

**seaders**

try and a blank exception grabber is the boldest of bold a developer can do... :smile: At least log what the exception is!

---

## 2019-02-20 17:31:27 - issues channel

**Newbie99**

Tidied up a bit, this appears to work (most of the time), occasionally though I do get an error showing on the client side:



```

@socketio.on('ping')

def handle_message(*_args, **_kwargs):

    try:

            market_books = output_queue.get(False)

    except Exception:

        socketio.sleep(1)

        emit('my_response', {'message': 'pong', 'mb': 'pong'})

    else:

        for market_book in market_books:

            emit('my_response', {'message': 'update', 'mb': market_book.streaming_update})

```



Error messages (client side):



```

GET [http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550683800805-630&amp;sid=0d06865666e74657b6a369ca38adb5f4](http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550683800805-630&amp;sid=0d06865666e74657b6a369ca38adb5f4) 400 (BAD REQUEST)

POST [http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550683801633-631&amp;sid=0d06865666e74657b6a369ca38adb5f4](http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550683801633-631&amp;sid=0d06865666e74657b6a369ca38adb5f4) 400 (BAD REQUEST)

```

---

## 2019-02-20 16:11:46 - issues channel

**Newbie99**

Ok...I think I've figured out why it hangs now...it is to do with output_queue.get() returning an empty value.



I am trying to structure the below to catch (and ignore) an empty outcome (if there are values the queue works fine, which is why it always works first time), however the below returns the error shown in the logs below (which I think confirms my logic is correct, but the way I try to catch it is incorrect):



```

@socketio.on('ping')

def handle_message(*_args, **_kwargs):

    try:

            market_books = output_queue.get(False)

    except output_queue.empty:

            pass

    else:

        for market_book in market_books:

            emit('my_response2', {'message': 'update', 'mb': market_book.streaming_update})

```



Server logs (which I believe confirm my suspicion):



```

ERROR:engineio.server:message handler error

Traceback (most recent call last):

  File "D:/Python37/webpages/betfair_flaskio.py", line 51, in handle_message

    market_books = output_queue.get(False)

  File "D:\Python37\lib\queue.py", line 167, in get

    raise Empty

_queue.Empty



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:\Python37\lib\site-packages\engineio\server.py", line 505, in _trigger_event

    return self.handlers[event](*args)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 590, in _handle_eio_message

    self._handle_event(sid, pkt.namespace, pkt.id, pkt.data)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 526, in _handle_event

    self._handle_event_internal(self, sid, data, namespace, id)

  File "D:\Python37\lib\site-packages\socketio\server.py", line 529, in _handle_event_internal

    r = server._trigger_event(data[0], namespace, sid, *data[1:])

  File "D:\Python37\lib\site-packages\socketio\server.py", line 558, in _trigger_event

    return self.handlers[namespace][event](*args)

  File "D:\Python37\lib\site-packages\flask_socketio\__init__.py", line 258, in _handler

    *args)

  File "D:\Python37\lib\site-packages\flask_socketio\__init__.py", line 641, in _handle_event

    ret = handler(*args)

  File "D:/Python37/webpages/betfair_flaskio.py", line 54, in handle_message

    except output_queue.empty:

TypeError: catching classes that do not inherit from BaseException is not allowed



```

---

## 2019-02-19 14:16:17 - issues channel

**Newbie99**

Ok, I thought I'd test something and its interesting to see where the problem lies.



```

@socketio.on('ping')

def handle_message(*_args, **_kwargs):

    socketio.sleep(1)

    market_books = output_queue.get()

    emit('my_response2', {'message': 'update', 'mb': len(market_books)})

    socketio.sleep(0.5)

    emit('my_response3')

```



That shouldn't clog anything up, yet it still hangs on the last ping (i.e.  the client receives the message with the number of array items, it pings back, it then receives the null response and pings back...then nothing happens).



On the server side, it looks like this:



```

127.0.0.1 - - [19/Feb/2019 14:14:19] "GET /socket.io/?EIO=3&amp;transport=polling&amp;t=1550585641996-6 HTTP/1.1" 200 381 0.000999

INFO:engineio.server:116a710b7ac54ccb89b0c116f4c15675: Received packet MESSAGE data 2["ping"]

INFO:socketio.server:received event "ping" from 116a710b7ac54ccb89b0c116f4c15675 [/]

(5068) accepted ('127.0.0.1', 60202)

INFO:engineio.server:116a710b7ac54ccb89b0c116f4c15675: Received request to upgrade to websocket

127.0.0.1 - - [19/Feb/2019 14:14:20] "GET /socket.io/?EIO=3&amp;transport=polling&amp;t=1550585659960-8&amp;sid=116a710b7ac54ccb89b0c116f4c15675 HTTP/1.1" 200 215 0.291910

INFO:socketio.server:emitting event "my_response3" to b3a33d164b34497f9e9cbafe6df082a3 [/]

INFO:engineio.server:b3a33d164b34497f9e9cbafe6df082a3: Received packet MESSAGE data 2["ping"]

INFO:socketio.server:received event "ping" from b3a33d164b34497f9e9cbafe6df082a3 [/]

INFO:engineio.server:b3a33d164b34497f9e9cbafe6df082a3: Received packet PING data None

INFO:engineio.server:Receive error -- socket is closed

127.0.0.1 - - [19/Feb/2019 14:14:20] "GET /socket.io/?EIO=3&amp;transport=websocket&amp;sid=b3a33d164b34497f9e9cbafe6df082a3 HTTP/1.1" 200 0 178.484812

```



I thought at first perhaps the loop wasn't ending somehow, but that doesn't appear to be the issue...but at least I can see where the problem must lie...just can't figure out the final step, ha!

---

## 2019-02-19 12:05:03 - issues channel

**Newbie99**

No luck with different ports or browsers, I even tried a fresh install on my Surface Go (which admittedly is also Windows 10, but doesn't have much on it). No joy, but I did get different errors, which may be more useful to decypher:



HTTP400: BAD REQUEST - The request could not be processed by the server due to invalid syntax.

(XHR)GET - [http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550577763533-16&amp;sid=a30e5471ac3446018e7290fa00eba7a5](http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550577763533-16&amp;sid=a30e5471ac3446018e7290fa00eba7a5)



 HTTP400: BAD REQUEST - The request could not be processed by the server due to invalid syntax.

(XHR)POST - [http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550577763604-17&amp;sid=a30e5471ac3446018e7290fa00eba7a5](http://localhost:3000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550577763604-17&amp;sid=a30e5471ac3446018e7290fa00eba7a5)



Doesn't make a great deal of sense to me, as the message is logically the same as the previous one that worked fine, but perhaps it needs a line break or something in it?

---

## 2019-02-17 15:28:41 - issues channel

**Newbie99**

I have got that sample code up and running, but for me it behaves the same as the previous effort (almost), in that it sends through the initial price cache as expected, however then it just pings away (i.e. the client console.log shows 'pinging').



The server logs, show:



```

INFO:socketio.server:received event "ping" from 41f1cafd420740b3921c67883d9b0bb0 [/]

INFO:socketio.server:emitting event "my_response" to 41f1cafd420740b3921c67883d9b0bb0 [/]

INFO:engineio.server:41f1cafd420740b3921c67883d9b0bb0: Client is gone, closing socket

INFO:engineio.server:41f1cafd420740b3921c67883d9b0bb0: Client is gone, closing socket

```



The client logs are interesting, as there are some errors that show up (which we never had previously):



```

socket.io.min.js:1 POST [http://localhost:5000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550416830901-24&amp;sid=0e8737cace6149e1abff289ba77e7c24](http://localhost:5000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550416830901-24&amp;sid=0e8737cace6149e1abff289ba77e7c24) 500 (Internal Server Error)

socket.io.min.js:1 GET [http://localhost:5000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550416745904-23&amp;sid=0e8737cace6149e1abff289ba77e7c24](http://localhost:5000/socket.io/?EIO=3&amp;transport=polling&amp;t=1550416745904-23&amp;sid=0e8737cace6149e1abff289ba77e7c24) 400 (BAD REQUEST)

```



and also:



```

socket.io.min.js:2 WebSocket connection to '[ws://localhost:5000/socket.io/?EIO=3&amp;transport=websocket&amp;sid=9ae605a3067b40328159b3072a45112c](ws://localhost:5000/socket.io/?EIO=3&amp;transport=websocket&amp;sid=9ae605a3067b40328159b3072a45112c)' failed: WebSocket is closed before the connection is established.

```

---

## 2019-02-16 20:12:06 - issues channel

**Newbie99**

(I stuck in the 300ms sleep as I got a verbose error on the client and thought that should reduce that risk)

---

## 2019-02-16 18:25:55 - issues channel

**Newbie99**

no errors (I took out all the sleep's too as that would have messed things up with the faster pings).



The server log reads fine...but again it only fires once:



```

INFO:engineio.server:a552c499c6ab49508a89e7982010a99c: Received request to upgrade to websocket

INFO:engineio.server:a552c499c6ab49508a89e7982010a99c: Received packet MESSAGE data 2/test,["ping"]

INFO:socketio.server:received event "ping" from a552c499c6ab49508a89e7982010a99c [/test]

INFO:socketio.server:emitting event "my_response" to a552c499c6ab49508a89e7982010a99c [/test]

INFO:engineio.server:a552c499c6ab49508a89e7982010a99c: Sending packet MESSAGE data 2/test,["my_response","received a ping"]

```

---

## 2019-02-16 17:48:44 - issues channel

**Newbie99**

But thats the issue I guess, I'm not understanding what is necessary to resolve that, I added the socketio.sleep(1) at the end as someone suggested that could free up the CPU and would exit the thread, but that a) seems a bit untidy and b) clearly doesn't do exactly what I need.



So in effect, it sticks there as the server is looking for instruction and nothing is telling it what to do in effect as I don't get any errors, because it pauses there (which is logical from what you say).



But having read up on python loop logic I don't see an obvious solution here, I thought maybe the logic needs to involve a background thread, but although I can get that to fire, I still end up in the same place as it just executes through once.

---

## 2019-02-16 17:39:52 - issues channel

**Newbie99**

```

import os

import logging

import queue

from threading import Thread

from flask import Flask, render_template

from flask_socketio import SocketIO, emit

import betfairlightweight

from betfairlightweight.filters import (

            streaming_market_filter,

            streaming_market_data_filter,

        )



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

username = os.environ.get('username')

trading = betfairlightweight.APIClient(user_name, password, appkey, certs=cert_path)

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(

    output_queue=output_queue,

)



# create stream

stream = trading.streaming.create_stream(

    listener=listener,

)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

        event_type_ids=['7'],

        country_codes=['US'],

        market_types=['WIN'],

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3,

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# start stream

stream.start(_async=True)



# Create a flask app

app = Flask(__name__)

app.config['SECRET_KEY'] = 'secret!'

# Use the flask app to create a socketio decorator

socketio = SocketIO(app)

thread = None



@app.route('/')

def index():

    global thread

    if thread is None:

        thread = Thread(target=handle_message)

        thread.start()

        socketio.sleep(2)

        return render_template('index.html')



@socketio.on('connect', namespace='/test')

def test_connect():

        global thread

        socketio.sleep(1)

        market_books = output_queue.get()

        print(market_books)

        for market_book in market_books:

             print(

             market_book,

             market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

             market_book.streaming_update,  # json update received

             market_book.market_definition,  # streaming definition, similar to catalogue request

             market_book.publish_time  # betfair publish time of update

        )



        for market_book in market_books:

             emit('my_response', {'data': 'connect', 'mb': market_book.streaming_update, 'namespace': '/test'})

        socketio.sleep(1)

@socketio.on('ping', namespace='/test')

def handle_message(*_args, **_kwargs):

    global thread

    while True:

        socketio.sleep(2)

        emit('my_response', {'data': 'pong', 'mb': 'pong', 'namespace': '/test'})

        socketio.sleep(2)

        market_books = output_queue.get()

        print(market_books)



        for market_book in market_books:

            print(

                market_book,

                market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

                market_book.streaming_update,  # json update received

                market_book.market_definition,  # streaming definition, similar to catalogue request

                market_book.publish_time  # betfair publish time of update

            )



        for market_book in market_books:

            emit('my_response', {'data': 'update', 'mb': market_book.streaming_update, 'namespace': '/test'})

        socketio.sleep(1)



if __name__ == '__main__':

    socketio.run(app, debug=True, host='127.0.0.1', port=5000)

stream.stop()

```

---

## 2019-02-16 17:39:36 - issues channel

**Newbie99**

hello again, I have spent a lot of time stepping through the logic in a bit more of a sensible fashion and tidied things up a bit. From a logical point of view, I'm still missing something, the code appears to make sense and doesn't throw up any errors. I've setup a ping from the client, the server then responds with a pong...but only on the first ping. In the console.log on the client after that it pings away, but the server never receives them, which seems odd. I make the assumption that the error is actually along the lines of my server code is not looking for the ping, rather than any issue on the client side. I'm guessing there is an issue with Threads that I'm not understanding, because I can't see what else it could be.

---

## 2019-02-10 14:31:54 - general channel

**jgnz**

ah ok, so its fine to send a handicap of 0? ie its never null on a runner and we dont create an error if you send 0 when placing an order?

---

## 2019-02-10 14:10:40 - general channel

**seaders**

`BET_ACTION_ERROR` means placeOrder docs, and `INVALID_RUNNER`, the instruction therein

---

## 2019-02-10 14:09:49 - general channel

**seaders**

so in your case, `BET_ACTION_ERROR`and `INVALID_RUNNER`

---

## 2019-02-10 14:09:04 - general channel

**seaders**

Main thing, for yourself, is to read specific error for as specific a "hint" as possible

---

## 2019-02-10 14:08:07 - general channel

**jgnz**

and i have to be careful with the errors i get back, they can be misleading

---

## 2019-02-10 11:58:00 - general channel

**jgnz**

anyone able to help with my error that ive posted on the betfair forum [https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/27338-always-getting-invalid_runner-errors-when-trying-to-place_orders](https://forum.developer.betfair.com/forum/sports-exchange-api/exchange-api/27338-always-getting-invalid_runner-errors-when-trying-to-place_orders)

---

## 2019-02-09 23:23:57 - issues channel

**Newbie99**

yep, it didn't, that was the only time I actually had an error....which is the whole confusing thing about python (to me)!



I am trying to rush things of course....but equally, this must be something that everyone on here faces surely when using the wrapper (unless no one else has ever tried to connect to to browser), so if people with far more experience than me can't spot any obvious errors, I suspect you're right I am wasting my time a bit with Python, as a beginner course isn't going to help with websockets and I'm not going to figure this out unless I randomly stumble across a similar example.



That said I'll give PyCharm a go and see if it helps and report back if I make any progress.



Thank you for your help so far though, it has actually been very useful in understanding where the error might be, even if I haven't quite got there yet. From your advice, I can at least work out where the error probably is occurring, so that is much appreciated.

---

## 2019-02-09 21:38:23 - issues channel

**seaders**

and while Visual Studio is okay, I'd probably recommend PyCharm over it, nothing should be running *at all* if you've an indent error

---

## 2019-02-09 20:42:24 - issues channel

**Newbie99**

oh actually no, I'd just messed up an indent...that was causing the error, still just chugs along as if nothing was wrong :disappointed:

---

## 2019-02-09 20:40:07 - issues channel

**Newbie99**

cool thanks, that actually may help as now I'm getting a ton of errors (which counter intuitively I think is good, as whatever wasn't firing presumably now is and was probably structured incorrectly)!

---

## 2019-02-09 20:33:02 - issues channel

**Newbie99**

appreciate you've already helped out a lot, however even with Visual Studio there are no errors thrown up by the debugger....it appears the code is functioning correctly...except of course its not. The issue is around the ping or emit, one or the other (or both) are not behaving as I would expect, but are not throwing up any errors (the debugger just shows the connections to the betfair streaming data as expected).



If I refresh the browser window (which I assume pings the server), the command line console refreshes, so somehow the emit part of the code is not firing. I'm guessing (but it is a guess), its to do with this section:



```

@socketio.on('ping')

def handle_message(_message):

    market_books = output_queue.get()

    print(market_books)

```



But as no error is thrown, I'm not really sure where to go from here!



Apologies again for the dumb questions, 'pure' scripting languages (e.g. Node.js / Python) are new to me and clearly I'm struggling with the logic a bit it would seem!

---

## 2019-02-09 19:48:07 - issues channel

**Newbie99**

I've just never actually had a debugging tool tbh (I'm not a professional coder...although I'm guessing that much is obvious)!!! So have never really thought to go down the debugging tool. With php (which is what I'm far more familiar with), I've never really had an issue with notepad and a browser window. That aside, I'm downloading visual studio as we speak, which will help on the debugging front

---

## 2019-02-09 19:46:13 - issues channel

**seaders**

can you debug any side of what you're programming at all?

---

## 2019-02-09 19:31:25 - issues channel

**seaders**

if you don't have a working debugger, and can't step through your code, you're working blind

---

## 2019-02-09 19:30:48 - issues channel

**Newbie99**

I'm just using the standard Idle, which doesn't work as it doesn't seem to understand the defs at the top (which aren't shown here), i.e. certs, password etc. So debugging doesn't work (or doesn't seem to) as it thinks they are executed simultaneously and gives a syntax error (of course in reality this isn't an issue and that piece of code is fine).



But...that aside, the above doesn't produce any errors, the connection is good as I get the connected message in the browser and can see activity on the command line console.



So, short of downloading an alternative debugger (happy to listen to ideas), I'm just using your suggested code really, which at face value appears to be correct, its just that the ping and emit for whatever reason are not triggering...

---

## 2019-02-09 17:24:07 - issues channel

**Newbie99**

the command line console also reports no errors

---

## 2019-02-09 17:22:40 - issues channel

**Newbie99**

Okay, sorry I'm back again and really confused!



This appears to connect, but doesn't seem to emit any messages:



```

import os

import logging

import queue



from flask import Flask, render_template

from flask_socketio import SocketIO



import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



app = Flask(__name__)

app.config['SECRET_KEY'] = secretkey

socketio = SocketIO(app)



@app.route('/')

def sessions():

    return render_template('index.html')



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

username = os.environ.get('username')

trading = betfairlightweight.APIClient(user_name,password,appkey,certs=cert_path)

trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(

    output_queue=output_queue,

)



# create stream

stream = trading.streaming.create_stream(

    listener=listener,

)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

#    event_type_ids=['7'],

#    country_codes=['GB'],

#    market_types=['WIN'],

    market_ids=['1.130856098'],

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3,

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



#start stream

stream.start(_async=True)





"""while True:

    market_books = output_queue.get()

    print(market_books)



    for market_book in market_books:

        print(

            market_book,

            market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

            market_book.streaming_update,  # json update received

            market_book.market_definition,  # streaming definition, similar to catalogue request

            market_book.publish_time  # betfair publish time of update

        )"""



@socketio.on('ping')

def handle_message(_message):

    market_books = output_queue.get()

    print(market_books)



    for market_book in market_books:

        emit(

            'market_book',

            f'{market_book} '

            f'{market_book.streaming_unique_id} '

            f'{market_book.streaming_update}, '

            f'{market_book.market_definition}, '

            f'{market_book.publish_time} '

        )



if __name__ == '__main__':

    socketio.run(app, debug=True)

```

---

## 2019-02-08 17:12:47 - general channel

**rafaelmarch3**

Hi folks, my digita certificate used to work fine with my python-developed code. Last time I connected was December last year. Now I'm getting a certificate issue:





 betfairlightweight.exceptions.LoginError: API login: CERT_AUTH_REQUIRED



Do you have any idea what may be happening ?

---

## 2019-02-08 17:04:19 - general channel

**rafaelmarch3**

Haven't tested my code since last year, now I'm getting a certificate error that I was not having before. Do you thing this is the cause ?

---

## 2019-02-07 18:50:43 - issues channel

**seaders**

have you a debugger working correctly? have you tried stepping through your code?

---

## 2019-02-07 18:38:51 - issues channel

**Newbie99**

thank you for your code snippet seaders, however maybe I'm being really dense, but it doesn't appear to be working. The client code says io isn't defined, so I tried with the sample code from the Flask page, which doesn't return an error, but still nothing happens. I feel that the problem is probably still with my server code, which is currently as follows. Python is very new to me, so this attempt at editing the streaming example, might be a bit poor, but as I don't get any errors, its a bit tricky to see where the problem is!



[code]

import os

import logging

import queue



import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter,

)



from flask import Flask, render_template

from flask_socketio import SocketIO



# setup logging

logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))  # change to DEBUG to see log all updates



# create trading instance (app key must be activated for streaming)

username = os.environ.get('username')





# create trading instance

trading = betfairlightweight.APIClient(user_name,password,appkey,certs=cert_path)



trading.login()



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(

    output_queue=output_queue,

)



# create stream

stream = trading.streaming.create_stream(

    listener=listener,

)



# create filters (GB WIN racing)

market_filter = streaming_market_filter(

    event_type_ids=['7'],

    country_codes=['GB'],

    market_types=['WIN'],

)

market_data_filter = streaming_market_data_filter(

    fields=['EX_BEST_OFFERS', 'EX_MARKET_DEF'],

    ladder_levels=3,

)



# subscribe

streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=1000,  # send update every 1000ms

)



# start stream

stream.start(_async=True)



"""

Data can also be accessed by using the snap function in the listener, e.g:

    market_books = listener.snap(

        market_ids=[1.12345323]

    )

Errors need to be caught at stream.start, resubscribe can then be used to

prevent full image being sent, e.g:

    streaming_unique_id = stream.subscribe_to_markets(

        market_filter=market_filter,

        market_data_filter=market_data_filter,

        conflate_ms=1000,  # send update every 1000ms

        initial_clk=listener.initial_clk,

        clk=listener.clk,

    )

The streaming unique id is returned in the market book which allows multiple

streams to be differentiated if multiple streams feed into the same queue.

"""



# check for updates in output queue

while True:

    market_books = output_queue.get()

    print(market_books)





    for market_book in market_books:

        print(

            market_book,

            market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

            market_book.streaming_update,  # json update received

            market_book.market_definition,  # streaming definition, similar to catalogue request

            market_book.publish_time  # betfair publish time of update

        )



app = Flask(__name__)

app.config['SECRET_KEY'] = 'secret!'

socketio = SocketIO(app)



if __name__ == '__main__':

    socketio.run(app)



stream = None

queue = None





def get_queue():

    global queue, stream



    if not queue:

        stream, queue =  trading.streaming.create_stream(

    listener=listener,

)

    return queue



@socketio.on('ping')

def handle_message(_message):

    market_books = get_queue().get()

    print(market_books)



    for market_book in market_books:

        emit(

            'market_book',

            f'{market_book} '

            f'{market_book.streaming_unique_id} '

            f'{market_book.streaming_update}, '

            f'{market_book.market_definition}, '

            f'{market_book.publish_time} '

        )





if __name__ == '__main__':

    socketio.run(app)

    stream.stop()



[/code]

---

## 2019-02-06 23:03:27 - issues channel

**Newbie99**

Thanks, however I get exactly the same issue...I don't get any error as such, but it just does nothing. I'm trying to essentially send the output of the example streaming script from Github. The script works fine, I can run it on its own and see the data come back as expected...however whenever I try to put in a any kind of socket connection it simply won't work. I presume there is some kind of conflict that I'm not understanding. Intuitively it seems quite simply, simply send what is shown on the console to a browser...but clearly its not as simple as it seems...although I can not understand why!

---

## 2019-02-03 18:17:49 - general channel

**jhaa**

that creates a different error

---

## 2019-02-02 10:39:38 - general channel

**wsdlwizard**

Thanks for the reply, yes it looks messy I should have said the problem is with the PriceSize bit. I have tried all sorts of combinations. I should be able to instantiate my own CurrentOrder object sholdnt I? The problem I am having is how to write the price,size bit I have tried lists [2.0,3.0] but still get the same type error

---

## 2019-02-02 09:56:27 - general channel

**wsdlwizard**

I am trying to simulate betting and need to instantiate an object of type CurrentOrder. My import is "from betfairlightweight.resources.bettingresources import PriceSize,CurrentOrder"  and my code is "test = CurrentOrder(5.5,'1234567',4.5,'1','2',1.0,'654987',datetime.datetime(2019,1,1,12,0,0),'PERSIST',datetime.datetime(2019,1,1,12,0,0),{'price':2.0,'size':20.0},'3',123456,'BACK',0.0,0.0,0.0,0.0,0.0,'SUCCESS')

" I get the error "TypeError: type object argument after ** must be a mapping, not float " any ideas? Many thanks.

---

## 2019-01-31 23:45:34 - issues channel

**liam**

You need to catch the error and reconnect, if you do a search [@U4H3EEV45](@U4H3EEV45) has shared a way to do it 

---

## 2019-01-31 08:04:18 - issues channel

**Newbie99**

I just get an error message

---

## 2019-01-30 20:38:38 - issues channel

**Newbie99**

ah...okay, that may help. For some reason I can't seem to create a key in open SSL though. There seems to be a script in the Betfair wrapper (as opposed to betfairlighweight), but when I try and invoke SSL, it just returns an error. Python is confusing me a lot!!!

---

## 2019-01-30 18:14:37 - issues channel

**Newbie99**

Hi Liam, just going back to the syntax you kindly sent me, I still can't get it to work. The keys must be fine as I can use the generic Python code on the Betfair site and that works, however with betfairlightweight, I am now getting an error that says:



ssl.SSLError: [SSL] PEM lib (_ssl.c:3824)



Intuitively I feel this could be something to do with my key being a .pem file, not a .key file perhaps? But thats a complete guess.

---

## 2019-01-29 20:10:44 - issues channel

**Newbie99**

so it actually looks like:



&lt;html&gt;&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;HTTP Error Code 400....

---

## 2019-01-29 20:09:46 - issues channel

**Newbie99**

no, the same HTTP ERROR Code 400 unfortunately

---

## 2019-01-29 19:57:31 - issues channel

**Newbie99**

If I'm understanding correctly, then trying that I get the following responses:



replacing --cert with --key, results in the same error

Attempting to change the end results in INVALID_USERNAME_OR_PASSWORD

---

## 2019-01-29 19:42:07 - issues channel

**Newbie99**

Which doesn't seem to make sense as its not one of the expected error codes from the Betfair site

---

## 2019-01-29 19:41:40 - issues channel

**Newbie99**

and I get an HTTP Error Code 400

---

## 2019-01-29 19:41:00 - issues channel

**Newbie99**

Hi,



I'm having real trouble with certs at the moment and having read about a thousand Github pages and various others I'm no closer.



I created certs using XCA and have a .pem and a .crt file. I have uploaded the .crt file to Betfair and enabled it for Bot trading...however thats where it all falls down.



I've tried both the Betfair and Betfairlightweight Python wrappers, but both keep coming up with various error messages, relating to the certs.



For Betfairlightweight, I have no idea where it expects them to be, as there's no certs folder and even if I attempt to change the path, it still doesn't work.



For the Betfair python wrapper, it just produces a similar error, although at least that seems to have a certs folder.



I've tried the following Curl request:



curl -q -k --cert CERT.pem [https://identitysso-cert.betfair.com/api/certlogin](https://identitysso-cert.betfair.com/api/certlogin) -d "username='USERNAME'&amp;password='PASSWORD'" -H "'APPKEY': curlCommandLineTest"

---

## 2019-01-28 19:34:52 - issues channel

**wsdlwizard**

I am getting 'betfairlightweight.exceptions.LoginError: API login: CERT_AUTH_REQUIRED' error after using the wrapper with no problems for months. I renewed my certificates and uploaded them to Betfair and used curl to get a successful login but it still gives me this error. I then did a pip install to see if the wrapper needed updating. Any ideas? Many thanks.

---

## 2019-01-22 00:15:30 - general channel

**Rob**

TypeError: 'type' object does not support item assignment

---

## 2019-01-22 00:15:18 - general channel

**Rob**

it gives the error

---

## 2019-01-21 23:52:53 - general channel

**Rob**

books: List[betfairlightweight.resources.MarketBook] = output_queue.get()

NameError: name 'List' is not defined

---

## 2019-01-21 21:46:01 - general channel

**Rob**

import os

import logging

import queue

import betfairlightweight

from betfairlightweight.filters import (

    streaming_market_filter,

    streaming_market_data_filter

)



#logging.basicConfig(level=[http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))

# OR TO GET MORE INFORMATIOJN logging.basicConfig(level=logging.DEBUG)





trading = betfairlightweight.APIClient('my [mailto:email@mail.com|email@mail.com](mailto:email@mail.com|email@mail.com)', 'my pass', app_key='my app key')

trading.login()

trading.session_token

print(trading.session_token)



# create queue

output_queue = queue.Queue()



# create stream listener

listener = betfairlightweight.StreamListener(

    output_queue=output_queue,

)





 #create filters (GB WIN racing)

market_filter = streaming_market_filter(

    market_ids=["1.153765710"]

)



market_data_filter = streaming_market_data_filter(

    fields=["EX_MARKET_DEF","EX_BEST_OFFERS","EX_LTP"],

    ladder_levels=3,

)



streaming_unique_id = stream.subscribe_to_markets(

    market_filter=market_filter,

    market_data_filter=market_data_filter,

    conflate_ms=0,  # send update every 1000ms

)



# start stream

stream.start(_async=True)





# check for updates in output queue

while True:

    market_books = output_queue.get()

    #print(market_books)



    for market_book in market_books:

        print(market_book.streaming_update

            #market_book.streaming_unique_id,  # unique id of stream (returned from subscribe request)

            #market_book.streaming_update,  # json update received

            #market_book.market_definition,  # streaming definition, similar to catalogue request

            #market_book.publish_time  # betfair publish time of update

        )

---

## 2019-01-11 16:55:06 - general channel

**seaders**

I keep getting an error from my bot saying it can't match teams from, [https://www.betfair.com/exchange/plus/football/competition/5627174](https://www.betfair.com/exchange/plus/football/competition/5627174)

---

## 2018-12-17 16:32:27 - general channel

**seaders**

the old ones are deprecated from Thursday, and if you try to login with them on or after that date, you'll get an `CERT_AUTH_REQUIRED` error from BetFair

---

## 2018-12-12 16:10:30 - general channel

**JMaster**

any recommendation of working debugger?

---

## 2018-12-12 16:09:36 - general channel

**seaders**

(and in general having a good working debugger, with working breakpoints is just essential, *especially* when starting out, I truly can't stress that enough)

---

## 2018-12-12 16:04:20 - general channel

**seaders**

you would, however be *much* better off having a working debugger, and putting a breakpoint at that print statement line, and poking around what "special_bet_events" _is_

---

## 2018-12-03 20:01:10 - general channel

**JMaster**

trading.logininteractive()

Traceback (most recent call last):

  File "&lt;input&gt;", line 1, in &lt;module&gt;

AttributeError: 'APIClient' object has no attribute 'logininteractive'

---

## 2018-12-03 19:58:33 - general channel

**liam**

Do you get the same error with trading.logininteractive()

---

## 2018-12-03 19:57:12 - general channel

**JMaster**

could it be something to do with the directories, in the error it shows venv/lib/.... where as when I did print(trading.cert) the path does not show the same (venv/lib/...)

---

## 2018-12-03 19:52:50 - general channel

**JMaster**

same error, without the brackets

---

## 2018-12-03 19:48:19 - general channel

**JMaster**

I get no errors when I parse this in the console

---

## 2018-12-03 19:23:33 - general channel

**JMaster**

adding certs='...' went through, but still got same error when running trading.login()

---

## 2018-12-03 19:16:34 - general channel

**liam**

Sorry no idea then, you normally get that error if you aren’t sending certs, does it work with curl?

---

## 2018-12-03 19:08:14 - general channel

**JMaster**

[@U4H19D1D2](@U4H19D1D2) I am getting the below - sorry but have no idea how to resolve? Thanks in advance.

trading.login()

Traceback (most recent call last):

  File "&lt;input&gt;", line 1, in &lt;module&gt;

  File "C:\Users\mrmax\Desktop\MRHP\venv\lib\site-packages\betfairlightweight\endpoints\login.py", line 30, in __call__

    (response, elapsed_time) = self.request(self.url, session=session)

  File "C:\Users\mrmax\Desktop\MRHP\venv\lib\site-packages\betfairlightweight\endpoints\login.py", line 52, in request

    self._error_handler(response_data)

  File "C:\Users\mrmax\Desktop\MRHP\venv\lib\site-packages\betfairlightweight\endpoints\login.py", line 57, in _error_handler

    raise self._error(response)

betfairlightweight.exceptions.LoginError: API login: CERT_AUTH_REQUIRED

---

## 2018-12-03 02:11:03 - general channel

**JMaster**

however when I run trading.login()   --&gt;  betfairlightweight.exceptions.LoginError: API login: CERT_AUTH_REQUIRED

---

## 2018-12-02 12:24:29 - general channel

**Donkey**

alright, onto the next issue…

`"statusCode":"FAILURE","errorCode":"NOT_AUTHORIZED","errorMessage":"AppKey is not configured for service"`

Any idea how to enable this one please?

---

## 2018-12-02 11:22:20 - general channel

**Donkey**

If I follow [https://github.com/liampauling/betfair/wiki/Tutorial](https://github.com/liampauling/betfair/wiki/Tutorial)  using just username/password then I get:

`betfairlightweight.exceptions.AppKeyError: AppKey not found in .bashprofile for ABCD, add or pass to APIClient`

_ABCD is not a real username_

---

## 2018-12-02 10:55:18 - general channel

**Donkey**

I’m looking for some help please with the .bash_profile content.

Currently set with (fake username/api/pass this is just an example, I use the real ones on my server):

```export username="johnsmith"

export appKey="1234567890"

export password="abcdef"```



In the exampleone.py I have:

```# create trading instance

trading = betfairlightweight.APIClient('username', 'password', app_key='appKey')```



On execution I get however the following error:

```# python exampleone.py

Traceback (most recent call last):

  File "exampleone.py", line 10, in &lt;module&gt;

    trading.login()

  File "/usr/lib/python3.6/site-packages/betfairlightweight/endpoints/login.py", line 30, in __call__

    (response, elapsed_time) = self.request(self.url, session=session)

  File "/usr/lib/python3.6/site-packages/betfairlightweight/endpoints/login.py", line 52, in request

    self._error_handler(response_data)

  File "/usr/lib/python3.6/site-packages/betfairlightweight/endpoints/login.py", line 57, in _error_handler

    raise self._error(response)

betfairlightweight.exceptions.LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE```



But my actual password logs me in betfair account without any issues.



Thanks for the help.

---

## 2018-11-20 17:00:06 - general channel

**liam**

No problem, yes please do, the examples sometimes have bugs / could certainly be bulked out further 

---

## 2018-11-15 22:31:39 - general channel

**Unknown**

any ideas how to restart the streaming easily? I've been getting SocketErrors more frequently lately for some reason.

---

## 2018-11-03 13:19:38 - general channel

**Matt P**

thanks, been getting BET_ACTION_ERROR and suspected this was the reason

---

## 2018-10-19 18:51:38 - general channel

**liam**

If you set requests to debug I think you can see the requests

---

## 2018-10-09 11:44:57 - general channel

**bb**

I am getting the following error when trying to place a limit on close order, could anyone shed some light on what I am missing as have been staring at this for a while without much luck

---

## 2018-10-08 09:02:28 - general channel

**liam**

v1.8.0 released, minor bug fixes and 'LoginInteractive' endpoint added so a user can login without certs, note that this will fail if you have certs setup on your account  [https://github.com/liampauling/betfair/blob/master/HISTORY.rst](https://github.com/liampauling/betfair/blob/master/HISTORY.rst)

---

## 2018-09-23 15:03:43 - general channel

**cieria**

Hello! I am trying to parse some historical and output into a file, using the code in the example here [https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py](https://github.com/liampauling/betfair/blob/master/examples/examplestreaminghistorical.py). I have downloaded the historical data from betfair, an archive "data.tar". If unzipped, it yields a folder structure like C:/data/xds/historic/BASIC/ $many_folders$ /archives.bz2. In the example code, when initiating the historical stream I have tried giving the "directory" parameter as the the path to the BASIC dir, as well as the path to the actual bz2 files, but both cases fail with error "IsADirectoryError" or with "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xdf in position 12: invalid continuation byte" if I give the path to a bz2 archive

---

## 2018-09-21 10:03:29 - issues channel

**liam**

[@UCCF7JJVC](@UCCF7JJVC) are you using async? It’s recommended to create a new thread manually with as much exception handling as possible over the start function, been discussed a few times but here is an example

---

## 2018-09-20 15:00:38 - issues channel

**loken92**

Hi!

I am implementing the stream listener and experiencing some issues. For some reason the python script stops at random, without any error. I think it could be related to high latency. Any tips on what could be causing this and how to fix it? Thanks!

---

## 2018-09-20 10:45:19 - general channel

**George**

Liam, in case you are interested, I think I may have fixed it myself. I've submitted a pull request so you can see what I did.

---

## 2018-09-20 08:31:18 - general channel

**George**

Anyone know how to fix this issue?

---

## 2018-09-13 10:15:54 - general channel

**liam**

do a pull and you should get v0.5.3b and all should be fixed

---

## 2018-09-13 10:09:37 - general channel

**liam**

the retry line is catching that error

---

## 2018-09-13 10:04:21 - general channel

**liam**

can you set logging to DEBUG on line 15

---

## 2018-09-10 23:09:12 - random channel

**seaders**

was getting errors in my system that a market was likely incorrectly rapidly switching market_id (like on every "tick")

---

## 2018-09-04 06:24:50 - issues channel

**liam**

Hmm it must be windows, we had a bug a while ago where Betfair was closing the connection now and again by sending an empty string through the socket. The following line solved that but maybe it doesn’t work for windows.

---

## 2018-09-03 21:41:22 - issues channel

**Rob**

thanks - that must be a red herring. I've added some error handling to try to work out what's happening

---

## 2018-09-03 21:22:46 - issues channel

**Rob**

I guessed it'd be something like that - I'll add some more error handling

---

## 2018-09-03 08:33:57 - issues channel

**liam**

No, is that py3.5? I wouldn't recommend launching run in a thread without a lot of error catching anyway due to timeouts/connection issues

---

## 2018-09-03 07:49:42 - issues channel

**Rob**

Has anyone ran in to this issue before using streaming? It's occurring after the stream has been running for a while, seemingly at random:



```

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\threading.py", line 916, in _bootstrap_inner

    self.run()

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\threading.py", line 864, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 191, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 225, in _receive_all

    data += part.decode(self.__encoding)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd2 in position 1: invalid continuation byte



Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\threading.py", line 916, in _bootstrap_inner

    self.run()

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\threading.py", line 864, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 191, in _read_loop

    received_data_raw = self._receive_all()

  File "C:\Users\username\Anaconda3\envs\pythonBetfairDataGatherer\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 225, in _receive_all

    data += part.decode(self.__encoding)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 296: invalid start byte

```

---

## 2018-08-27 10:34:04 - issues channel

**favetelinguis**

[@UAXGAG15J](@UAXGAG15J) what is sort order good for/used for? Does it ever change during the lifetime of a market or is it fixed at the start of a market?

---

## 2018-08-24 12:48:15 - random channel

**seaders**

they give you that info in [https://pinnacleapi.github.io/linesapi#operation/Fixtures_V1_Get](https://pinnacleapi.github.io/linesapi#operation/Fixtures_V1_Get)

---

## 2018-08-21 20:43:44 - general channel

**Tom**

betfairlightweight.exceptions.StatusCodeError: Status code error: 503

---

## 2018-08-16 21:15:17 - general channel

**Tom**

The original code was

                m = next((x for x in markets if x.market_id == b.market_id) , None)

But I was getting the following error

AttributeError: 'dict' object has no attribute 'market_id'

---

## 2018-08-16 21:07:28 - general channel

**Tom**

Hi Liam, I have pycharm community but I'm calling this script from a django base command and django isn't supported in the community edition so debugging isn't doing me much help:(

---

## 2018-08-16 21:00:24 - general channel

**liam**

Recommend getting pycharm and debugging if you haven’t already 

---

## 2018-08-16 20:37:23 - general channel

**Tom**

Hi, I'm trying to modify this code to use lightweight in order to gather tennis data from betfair api on a cronjob and save to a model. I'm having an isssue with getting competition names from list.market.catalogue, I'm getting the following error AttributeError: 'tuple' object has no attribute 'competition' Can anyone help? Code and stacktrace posted below. Thanks

---

## 2018-08-12 18:41:19 - general channel

**Rob**

thanks [@U4H19D1D2](@U4H19D1D2) - I've got some code streaming the data now. Are there any obvious errors that I should definitely look out for?

---

## 2018-08-12 12:48:26 - general channel

**liam**

Just set conflation to desire update time, streaming is much nicer on CPU, cleaner and less code. Just make sure you catch errors 

---

## 2018-07-31 16:40:15 - issues channel

**man**

Hi! I'm trying to make use of the historicalstreaming.py but I keep getting this error:

File "/usr/local/lib/python3.5/dist-packages/betfairlightweight/streaming/betfairstream.py", line 290, in _read_loop

    for update in f:

  File "/usr/lib/python3.5/codecs.py", line 321, in decode

    (result, consumed) = self._buffer_decode(data, self.errors, final)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xfd in position 10: invalid start byte

---

## 2018-07-30 14:11:56 - general channel

**Ian**

(casbi) ian@KYOFBU C:\code\casbi\casbi

$ python casbi.py

Traceback (most recent call last):

  File "casbi.py", line 5, in &lt;module&gt;

    import betfairlightweight

  File "C:\Users\ian\Envs\casbi\lib\site-packages\betfairlightweight\__init__.py", line 3, in &lt;module&gt;

    from .apiclient import APIClient

  File "C:\Users\ian\Envs\casbi\lib\site-packages\betfairlightweight\apiclient.py", line 2, in &lt;module&gt;

    from . import endpoints

  File "C:\Users\ian\Envs\casbi\lib\site-packages\betfairlightweight\endpoints\__init__.py", line 4, in &lt;module&gt;

    from .betting import Betting

  File "C:\Users\ian\Envs\casbi\lib\site-packages\betfairlightweight\endpoints\betting.py", line 277

    customer_strategy_ref=None, async=None, session=None, lightweight=None):

                                    ^

SyntaxError: invalid syntax



(casbi) ian@KYOFBU C:\code\casbi\casbi

$

---

## 2018-07-30 14:11:35 - general channel

**Ian**

Hey all,  fresh box, trying to get dev env up and running. I receive the following error when I try and import bflw

---

## 2018-07-26 11:06:18 - general channel

**liam**

so to fix I added that if statement

---

## 2018-07-18 16:55:52 - general channel

**klozovin**

Yeah, as I've started it - name matching will be first class service, so that I can get logging and debugging, etc... it's just too important to be tucked away with no introspection

---

## 2018-07-18 16:54:34 - general channel

**seaders**

I've a few viewers for those things that both serve as an aggregate viewer for those "debug" things, but also for overround opportunities across platforms

---

## 2018-07-18 16:52:59 - general channel

**seaders**

bits, yeah.  you may have seen my whinge in [#C4H05KKMY|random](#C4H05KKMY|random) that BF has the "vanilla" /first round of fixtures up

---

## 2018-07-17 20:38:31 - random channel

**seaders**

but because Serie A and Ligue 1 haven't fricking released their fixtures yet, they're not on BF yet

---

## 2018-07-09 16:41:23 - general channel

**liam**

Im getting a lot streaming errors this afternoon, anyone else?

---

## 2018-07-05 17:06:39 - general channel

**klozovin**

It logs me in successfully even if supply gibberish keys, but the header is required... otherwise I get `INPUT_VALIDATION_ERROR`

---

## 2018-06-13 23:46:44 - general channel

**klozovin**

Docs for the `Runner` type say that the `adjustmentFactor` is required, but I'm getting responses without that field. 



Is it just a error in the docs, or is there more to it?

---

## 2018-06-07 20:00:09 - general channel

**liam**

Any errors? / code??

---

## 2018-06-06 20:53:50 - general channel

**Mihai**

Hello guys, I'm new to Python &amp; after trying the steps mentioned here: [https://underround.wordpress.com/2017/07/05/historical-data/](https://underround.wordpress.com/2017/07/05/historical-data/) 

-&gt; I got the following error: AttributeError: 'APIClient' object has no attribute 'historical'. I've adapted both codes using the code from examplestreaminghistorical.py &amp; 



-&gt; After running the first code (updated based on xamplestreaminghistorical.py) I only get: 

INFO:betfairlightweight.streaming.stream:[Stream: None]: "MarketStream" created

INFO:betfairlightweight.streaming.stream:[MarketStream: HISTORICAL] 1.136292168 added



-&gt; After running the second code I get the below error:

Traceback (most recent call last):

  File "historic_data_2.py", line 44, in &lt;module&gt;

    listener=listener

  File "C:\Users\jdoe\AppData\Local\laragon\bin\python\python-2.7.13\lib\site-packages\betfairlightweight\endpoints\streaming.py", line 58, in create_historical_stream

    listener.register_stream('HISTORICAL', 'marketSubscription')

  File "C:\Users\jdoe\AppData\Local\laragon\bin\python\python-2.7.13\lib\site-packages\betfairlightweight\streaming\listener.py", line 25, in register_stream

    self.stream = self._add_stream(unique_id, operation)

  File "historic_data_2.py", line 33, in _add_stream

    unique_id, self.output_queue, self.max_latency, self.lightweight

  File "historic_data_2.py", line 16, in __init__

    super(HistoricalStream, self).__init__(unique_id, output_queue, max_latency, lightweight)

TypeError: __init__() takes exactly 2 arguments (5 given)



Could you please help? I'm trying to get the files in a readable format.

---

## 2018-06-06 18:46:56 - issues channel

**liam**

Sure your not double calling stop? Really line 70 should error if it is None 

---

## 2018-06-06 18:01:51 - issues channel

**Ben**

Hi Liam, I get a weird error on a regular basis when i try to close a stream?

---

## 2018-06-02 13:37:11 - general channel

**Jonatan (skyw)**

Im going tro setup something with message queues later and spawn a thread that starts the stream in sync mode to catch those exceptions.

---

## 2018-06-02 13:36:00 - general channel

**Jonatan (skyw)**

I guess you are running in async mode then reguluary checking changes if change, stop stream and subscribe to new updated markets? If that is the case how do you catch exceptions from betfair thread?

---

## 2018-06-02 10:14:07 - issues channel

**liam**

1.6.3 now pushed to pypi, minor fix to handle ciso8601 update and setting specific versions for third party libs to prevent it happening again. I used in production last night with no issues (streaming). Thanks [@U9CP5N36K](@U9CP5N36K) as this would have screwed me over.

---

## 2018-05-30 23:10:08 - general channel

**Jonatan (skyw)**

I might be missing something but how do we catch exceptions from the stream thread?

---

## 2018-05-28 14:14:59 - general channel

**liam**

1.6.2 pushed, minor fixes, thanks [@U7QLCB7HA](@U7QLCB7HA)

---

## 2018-05-28 13:38:57 - general channel

**OT**

pushed to fix that stupid error on issue 168. good lesson that get() can be dangerous because it fails silently

---

## 2018-05-28 12:08:50 - general channel

**OT**

[@U4H19D1D2](@U4H19D1D2) ok thanks. I tried to fix it before but i was loathe to load it up with if statements or add more classes. i'll see what you think before I proceed

---

## 2018-05-06 07:27:28 - general channel

**favetelinguis**

wow that would be very nice, format is not an issue i can fix that as long as the data is there

---

## 2018-05-01 08:20:21 - issues channel

**liam**

I think I was getting some of those errors when making cleared orders requests last week 

---

## 2018-04-30 18:19:43 - issues channel

**jfo**

anyone have any idea what error code `ANGX-0003` is about?

---

## 2018-04-11 22:35:06 - issues channel

**OT**

python3.5/site-packages/betfairlightweight/resources/bettingresources.py", line 489, in __init__

    ) if kwargs.get('keyLineDescription') else None

TypeError: __init__() got an unexpected keyword argument 'kl'

---

## 2018-04-11 22:33:46 - issues channel

**OT**

just decided to update bfl and getting this: TypeError: __init__() got an unexpected keyword argument 'kl'

---

## 2018-04-11 17:33:54 - general channel

**OT**

of course not! just the ol' "we found an error and fixed it"

---

## 2018-04-11 10:39:24 - general channel

**OT**

betfair have fixed up the historical data api.. working great, now.

---

## 2018-04-03 19:08:25 - general channel

**liam**

v1.6.1 which fixes this but it doesn't output the value into the stream yet

---

## 2018-04-02 13:00:32 - general channel

**liam**

If you set logging to DEBUG what does the full message look like?

---

## 2018-04-01 21:35:15 - general channel

**seaders**

```  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py", line 60, in start

    self._read_loop()

  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py", line 198, in _read_loop

    self._data(received_data)

  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/streaming/betfairstream.py", line 231, in _data

    if self.listener.on_data(received_data) is False:

  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/streaming/listener.py", line 115, in on_data

    self._on_change_message(data, unique_id)

  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/streaming/listener.py", line 146, in _on_change_message

    self.stream.on_update(data)

  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/streaming/stream.py", line 55, in on_update

    self._process(data[self._lookup], publish_time)

  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/streaming/stream.py", line 154, in _process

    order_book_cache.update_cache(order_book, publish_time)

  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/resources/streamingresources.py", line 506, in update_cache

    runner.update_unmatched(order_changes['uo'])

  File "/home/ubuntu/virtualenvs/lbbsports/lib/python3.6/site-packages/betfairlightweight/resources/streamingresources.py", line 476, in update_unmatched

    self.unmatched_orders.append(UnmatchedOrder(**unmatched_order))

TypeError: __init__() got an unexpected keyword argument 'lsrc'```

---

## 2018-03-27 12:42:38 - general channel

**liam**

I agree with making it clean but then I don’t want to hide errors from the user 

---

## 2018-03-26 19:22:37 - general channel

**marco**

liam, I got the correct error now:  NOT_AUTHORIZED: AppKey is not configured for service

---

## 2018-03-26 19:18:38 - general channel

**liam**

I recommend running the example as you are probably not starting the stream quick enough (10s timeout between you running subscribe and start or it will error)

---

## 2018-03-26 19:14:36 - general channel

**liam**

although you should get a 'app key not authorised' error if used correctly

---

## 2018-03-26 19:11:27 - general channel

**liam**

Any other errors on the DEBUG logs? But I am fairly sure it won't work with the delayed key unless authorised

---

## 2018-03-26 19:10:33 - general channel

**marco**

I was trying to run the code regarding streaming in the github README. I get "betfairlightweight.exceptions.SocketError: Connection closed by server" on the last line. I wonder if this is supposed to work with a test app key which is what I have...

---

## 2018-03-23 14:48:22 - general channel

**Unknown**

[@U9UB05M3J](@U9UB05M3J) uploaded a file: [https://betfairlightweight.slack.com/files/U9UB05M3J/F9W4H2QR5/proposed_fix_for_stream_stop__.py|proposed fix for stream.stop()](https://betfairlightweight.slack.com/files/U9UB05M3J/F9W4H2QR5/proposed_fix_for_stream_stop__.py|proposed fix for stream.stop())

---

## 2018-03-23 14:46:12 - general channel

**istb**

yeah that fixes it

---

## 2018-03-23 14:31:10 - general channel

**istb**

If you kept track of all the threads in the class, and set ```self._running = False``` then call  t.join() for each t  where t is a thread, then close the socket, I think this would fix it?

---

## 2018-03-23 14:28:17 - general channel

**liam**

Hence why we decided to use an if running raise error

---

## 2018-03-23 14:26:59 - general channel

**liam**

Hi mate, I was going to have a look at this tonight, you mention stopping threads (you can’t do this in python) We has this issue before and I though it was fixed but should be able to mimic the following but then I am surprised closing the socket is returning empty rather than raising an error



 [https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py#L214](https://github.com/liampauling/betfair/blob/master/betfairlightweight/streaming/betfairstream.py#L214)

---

## 2018-03-23 14:23:38 - general channel

**istb**

First of all, thanks for making such an easy to use package :slightly_smiling_face:. Does anyone mind if I fix [https://github.com/liampauling/betfair/issues/165](https://github.com/liampauling/betfair/issues/165)?

---

## 2018-03-20 07:21:01 - general channel

**liam**

[@U8RT48D8X](@U8RT48D8X) when using the stream you can’t just thread it off and forgot about it, you need to handle any errors and resubscribe or subscribe again if required 

---

## 2018-03-19 16:14:07 - general channel

**mbk**

hey guys, I have been using the stream and am generally happy with it. I start the stream with async=True and then snap prices whenever necessary. However, sometimes there is a connection error and the underlying stream stops. From that moment on, the prices are all stale. What would you say is the best way to deal with situations like that?

---

## 2018-03-12 21:15:35 - general channel

**Tom**

[@U92CASP1B](@U92CASP1B)  yes I have. The error message is saying change my password. My password is fine. I'm logged in so I've no idea why the api is triggering that error

---

## 2018-03-12 21:10:56 - general channel

**Jonatan (skyw)**

Have you tried google your error message?

---

## 2018-03-12 20:57:48 - general channel

**Tom**

[@U4H19D1D2](@U4H19D1D2) I've got the login script you sent me working when I pass in my username and password directly to APIClient( 'myuser', 'mypass', app_key=None) If I add my username and password to .bash_profile  I get this error 

betfairlightweight.exceptions.LoginError: API login: ACCOUNT_PENDING_PASSWORD_CHANGE



What's really strange is I deleted the .bash_profile at the top level directory I set up in the project and at the home directory of my mac too and there's no reference to api_key, I've api_key set to none and I'm getting a session token.  if I try to add or filter markets I get an error then that my api key is invalid. I'd like to get the bash_profile working to keep the login system as is.

---

## 2018-03-10 22:10:24 - general channel

**Tom**

[@U4H19D1D2](@U4H19D1D2) thanks for your help so far. When I run that code it says that the "Exception: Certificate folder not found in /certs/ should there be another folder one deep?

---

## 2018-03-10 20:59:54 - general channel

**Unknown**

[@U4H19D1D2](@U4H19D1D2) I fixed the unittest imports but I'm still getting an an error     raise self._error(response)

betfairlightweight.exceptions.LoginError: API login: UNKNOWN



6.9e-05



do all the certs have to be in a list or tuple named cert_files? attaching screenshot of how I've set up the certs.

---

## 2018-03-10 13:25:48 - general channel

**Tom**

not sure what that belongs too. I deleted that folder and ran the code and still the same error. can someone check if test_login.py is working for them?

---

## 2018-03-07 18:23:48 - general channel

**Unknown**

[@U847PLYN6](@U847PLYN6) uploaded a file: [https://betfairlightweight.slack.com/files/U847PLYN6/F9L698K0S/traceback.py|traceback](https://betfairlightweight.slack.com/files/U847PLYN6/F9L698K0S/traceback.py|traceback)

---

## 2018-03-07 12:52:01 - general channel

**liam**

list_market_book is listMarketBook, have you had a look at the examples? Or use a debugger (recommend pycharm) and have a look at what is in that market book response 

---

## 2018-03-02 07:44:45 - general channel

**liam**

[@U6XQL6FJR](@U6XQL6FJR) what error are you getting? Only listRaceDetails works without your appKey being authorised, even then its limited to Tennis. Use the inplayservice endpoint which is what the website uses.

---

## 2018-02-22 12:29:01 - general channel

**Henry**

Then come with `requests.exceptions.ConnectionError: ('Connection aborted.', IsADirectoryError(21, 'Is a directory'))`

---

## 2018-02-22 12:19:31 - general channel

**Henry**

`Exception: Certificate folder not found in /certs/`

---

## 2018-02-21 21:20:18 - general channel

**richard_h**

Getting SocketErrors about once a week or so, you guys have any solutions to restart things when this happens?

---

## 2018-02-20 11:13:02 - issues channel

**hugo**

Betfair seem to not be sending an openDate on one of their market definitions causing the MarketDefinition resource init to crash. Making that field an optional arg seems to fix.

---

## 2018-02-17 17:23:19 - general channel

**seaders**

it's better to get all the info as well (logging in with both keys, and get the error messages as well)

---

## 2018-02-17 17:07:36 - general channel

**seaders**

If it happens again, it sends me an error email, then waits 5 minutes and connect again

---

## 2018-02-17 16:45:03 - general channel

**Ian**

I receive the following error when calling print(market_books)

---

## 2018-02-07 11:37:20 - issues channel

**liam**

It’s basically betfair telling you that something is wrong but the connection / filter / clk is still valid and open, data should then be sent if it is fixed 

---

## 2018-02-06 15:56:23 - issues channel

**seaders**

all sorted now, my PR has a test in that fails 100% of the time in python 3.x, but with your fix passes 100% of the time

---

## 2018-02-05 22:46:40 - issues channel

**seaders**

but will pass with your fix

---

## 2018-02-05 21:53:14 - issues channel

**seaders**

[https://betfairlightweight.slack.com/archives/C4H05ML2E/p1517855520000072](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1517855520000072)

just on this, make sure to read the whole error, cos it does explain, `dictionary changed size during iteration`

---

## 2018-02-05 21:47:12 - issues channel

**seaders**

in python 2, if you use `.itervalues()` instead of values, you get a generator, and you get the same error

---

## 2018-02-05 21:44:11 - issues channel

**seaders**

^^^ in Python 3, you get a Runtime error, dict changed

---

## 2018-02-05 18:32:00 - issues channel

**liam**

Just created a new issue #154, I believe my PR #155 will fix it but I am struggling to confirm that dict.values() returns a generator and this is what caused the RuntimeError, anyone know? [https://github.com/liampauling/betfair/pull/155](https://github.com/liampauling/betfair/pull/155)

---

## 2018-02-05 16:56:49 - general channel

**seaders**

The error happens in the library, but that's a horrible bug on Code's side, you should *never* be doing things like that

---

## 2018-02-05 16:54:50 - general channel

**seaders**

Unfortunately VS Code overrides this, in debug mode, and puts different stuff in locals

---

## 2018-02-05 16:51:57 - general channel

**NicolasW**

INFO:betfairlightweight.streaming.stream:[Stream: None]: "MarketStream" created

Traceback (most recent call last):

  File "C:\Users\Nicolas\source\repos\BF stream test\BF stream test\BF_stream_test.py", line 47, in &lt;module&gt;

    sys.exit(int(main() or 0))

  File "C:\Users\Nicolas\source\repos\BF stream test\BF stream test\BF_stream_test.py", line 32, in main

    streaming_unique_id = stream.subscribe_to_markets(market_filter=market_filter,market_data_filter=market_data_filter,conflate_ms=10000)

  File "C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 131, in subscribe_to_markets

    self._send(message)

  File "C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 245, in _send

    message_dumped = json.dumps(message) + self.__CRLF

OverflowError: Maximum recursion level reached

Press any key to continue . . .

---

## 2018-02-05 16:50:56 - general channel

**NicolasW**

Hi, I can see a thread on "maximum recursion level reached" which also happens to me when I test my app in debug mode. Is there a solution to still run my app in debug mode?

---

## 2018-01-25 10:11:15 - issues channel

**mbk**

ah I see this issue was fixed in the UAT branch, but not in master

---

## 2018-01-25 09:59:41 - issues channel

**mbk**

the weird thing is that the response has status 200 but the content says error

---

## 2018-01-25 09:50:13 - issues channel

**mbk**

```

'\r\n\r\n\r\n&lt;!DOCTYPE html&gt;\r\n\r\n&lt;html&gt;\r\n&lt;head&gt;\r\n    &lt;meta name="viewport" content="width=device-width" /&gt;\r\n    &lt;title&gt;ngErrorRedirect&lt;/title&gt;\r\n&lt;/head&gt;\r\n&lt;body&gt;\r\n    &lt;div&gt; \r\n        Error\r\n    &lt;/div&gt;\r\n    &lt;script&gt;\r\n        window.location("[https://historicdata.betfair.com/#/error](https://historicdata.betfair.com/#/error)");\r\n    &lt;/script&gt;\r\n&lt;/body&gt;\r\n&lt;/html&gt;\r\n'

```

---

## 2018-01-25 09:50:03 - issues channel

**mbk**

Using the example in your repo, I get the following response when calling `trading.historic.get_file_list` which raises an exception

---

## 2018-01-12 15:40:57 - issues channel

**mikey155**

Thanks that's a good lead. What gets me about Python is that things change so quickly e.g. I'm using Python 3.6 in PyCharm and the word async gives a syntax error. I was able to get round that for the historical data but it might be an issue when I move on to stream API for trading.

---

## 2018-01-12 15:33:24 - issues channel

**mikey155**

File "C:/Users/Jam/PycharmProjects/betfair/examples/examplestreaminghistorical.py", line 33, in on_process

    runner.selection_id, runner.name, runner.last_price_traded or ''

AttributeError: 'RunnerBook' object has no attribute 'name'

(this is all in PyCharm)

---

## 2018-01-12 15:32:50 - issues channel

**mikey155**

I get the following error:

---

## 2018-01-12 14:40:57 - issues channel

**Unknown**

You able to share the code / error?

---

## 2018-01-12 14:36:31 - issues channel

**mikey155**

I'm new to this site. I'm a python newbie, all of my existing apps written in Visual Basic. Following up the previous discussion on horses names, I'm now drilling into historical data, employing betfairlightweight. Your examplestreaminghistorical works as expected as is, but I'm finding errors (missing positional argument in RunnerBook) when I try to acquire horse names. I tried adding name to RunnerBook but get the same error. Probably a naive newbie error but I thought I'd try to get some insight here. Thanks in advance.

---

## 2018-01-12 13:38:19 - issues channel

**mikey155**

I'm new to this site. I'm a python newbie, all of my existing apps written in Visual Basic. Following up the previous discussion on horses names, I'm now drilling into historical data, employing betfairlightweight. Your examplestreaminghistorical works as expected as is, but I'm finding errors (missing positional argument in RunnerBook) when I try to acquire horse names. I tried adding name to RunnerBook but get the same error. Probably a naive newbie error but I thought I'd try to get some insight here. Thanks in advance.

---

## 2018-01-12 11:21:00 - general channel

**seaders**

in pycharm / eclipse, all their debugging stuff is done via pydevd

---

## 2018-01-12 11:18:46 - general channel

**Ian**

Given I’m new to python mo code/debug workflow will be quite frequent lol

---

## 2018-01-12 11:18:41 - general channel

**seaders**

they've 'debug' info available, and they obviously have their own "locals" variable

---

## 2018-01-12 11:18:20 - general channel

**seaders**

so what VSCode has done is, for their 'debug' windows,

---

## 2018-01-12 11:17:55 - general channel

**seaders**

`Debug -&gt; Start without debugging`, and it runs right

---

## 2018-01-12 11:17:35 - general channel

**seaders**

[@U7R5CEDAL](@U7R5CEDAL) it's only an issue when you're debugging

---

## 2018-01-12 07:08:29 - general channel

**Ian**

So, when I use PyCharm, it debugs without error so that must mean the issue is within VSCode?

---

## 2018-01-12 06:59:46 - general channel

**Ian**

I’ve added in try blocks to catch any exception. When I run this as python recorder.py, it runs seemingly without error. I will keep digging - apologies for clogging up the chat

---

## 2018-01-12 06:51:35 - general channel

**Ian**

I’ve looked into this a bit more - taken a clean install of ubuntu and installed anaconda3, then bflw lib. same as MacOs - rec error when debugging. However,also same as MacOS, if I run outwith the VSCode IDE, it seems to run, I get what looks to be the correct output?

---

## 2018-01-11 18:26:45 - general channel

**liam**

Looks like its some sort of recursive error in the market filter function, probably due to locals but I have no idea why

---

## 2018-01-11 18:07:22 - general channel

**liam**

got to be ujson causing the error

---

## 2018-01-11 18:03:58 - general channel

**Ian**

when I run this outwith the debugger, I receive the following

---

## 2018-01-11 17:39:37 - general channel

**Ian**

am i doing soemthing wrong - should I be error checking at this level?

---

## 2018-01-11 17:39:18 - general channel

**Ian**

OverflowError: Maximum recursion level reached  - i presume this is an exception raised in the library -

---

## 2018-01-10 16:24:58 - general channel

**mbk**

My plan is to empty the queue in a deque of fixed length 1 so that I only keep the latest from the output_queue

---

## 2017-12-31 19:17:33 - general channel

**Tom**

Hi, I'm trying to modify the baseresource.py file in resources folder. and I've noticed that all import statements that start with 

from .baseresource import BaseResource is throwing this error



ModuleNotFoundError: No module named '__main__.baseresource'; '__main__' is not a package



Is there a particular reason for this?

---

## 2017-12-31 11:09:53 - general channel

**OT**

Ok no errors on histrical download in the last hour. Definitely don't hit their api with more than one request at a time

---

## 2017-12-31 10:43:07 - general channel

**liam**

[@U7QLCB7HA](@U7QLCB7HA) / [@U5D4ZBEAG](@U5D4ZBEAG) made some big fixes, either of you able to check I haven't done anything stupid? Should close 3 open issues [https://github.com/liampauling/betfair/pull/147](https://github.com/liampauling/betfair/pull/147)

---

## 2017-12-31 10:09:28 - general channel

**liam**

Got an example? Im fixing bugs at the moment

---

## 2017-12-31 09:48:53 - general channel

**OT**

Does anybody else have problems downloading historical data from the API? sometimes the content of the market file is just "Error" .. Is this betfair rate-limiting me or something?

---

## 2017-12-30 20:55:58 - issues channel

**Lennart**

Thanks, Liam - I appreciate your help. That seems to have resolved  the first error but the second one still persists. The wording of the error message ("Certificate folder") seems to suggest that there should be more just the .crt file in the certs folder. I currently just have the .crt file in it - Might that be the issue?

---

## 2017-12-20 21:09:16 - issues channel

**OT**

Just wondering if this is correct behaviour.. before I start to debug further.

---

## 2017-12-20 08:14:14 - general channel

**liam**

If you are using pycharm use debug and have a look inside the MarketBook, there’s loads of data in there 

---

## 2017-12-19 23:19:26 - general channel

**Tom**

For example name  



   "status": "ACTIVE",

            "sortPriority": 1,

            "id": 8597476,

            "name": "Stan Wawrinka"

          },

          {

For example if I try "market_book.name" method

I get an error

 AttributeError: 'list' object has no attribute 'name'





Is there a list of definitions I can use in order to expand on the data I'm extracting?

---

## 2017-12-15 00:38:33 - general channel

**Unknown**

I'm going to save the headache and use the lightweight api to get the data. I am however having trouble generating an app key. I'm getting a http 404 error from the following link

404 error means server is unable to preform request? Is this service down at the moment?

---

## 2017-12-14 02:45:43 - general channel

**Tom**

I must check my packages I'm even getting an error running that tiny piece of code. "Expecting property name enclosed in double quotes:" I'll have come back to it in the evening. thanks for you help seaders:+1:

---

## 2017-12-14 02:30:29 - general channel

**Tom**

I added the .json manually once I got my first error

---

## 2017-12-14 01:44:30 - general channel

**Tom**

That's the first few lines. I formatted the json to make it easier to read. That part I posted seems fine. My IDE isn't crying. The below bit is giving me a json standard error

---

## 2017-12-14 01:41:34 - general channel

**seaders**

That error kinda seems like the file has content like "{...} {...}"

---

## 2017-12-14 01:37:31 - general channel

**Tom**

Hi Liam, This is where I downloaded the data from [https://historicdata.betfair.com](https://historicdata.betfair.com)  I'm trying to oswalk the data to pull out what I need but it seems the json isn't following json standard. Have you had issues parsing betfair json before?  "json standard only allow one top level value', Is the error, have you come across that error before?

---

## 2017-12-13 09:14:56 - general channel

**aag**

[@U4H19D1D2](@U4H19D1D2) ok I understand, network error in case of streams, in http yes it doesnt matter

---

## 2017-12-09 11:30:37 - random channel

**OT**

zlib.error: Error -3 while decompressing: invalid distance too far back

---

## 2017-12-09 11:30:35 - random channel

**OT**

Anybody seen this error when dealing with the historical data?

---

## 2017-12-03 13:30:53 - general channel

**liam**

need to add a break or continue somewhere to prevent line 222 executing which would error otherwise

---

## 2017-12-03 11:26:06 - general channel

**OT**

how about only raising the socket error when it's running, ie: ```if len(part) == 0 and self._running is True: ```

---

## 2017-12-02 14:51:30 - general channel

**seaders**

I havenae said anything because as you said, it doesn't do much damage, and it's a bit of a PITA to 100% fix

---

## 2017-12-02 13:51:05 - general channel

**OT**

doesn't seem to cause any damage, just makes my app shutdown a bit messy with some socket errors

---

## 2017-11-20 11:39:54 - general channel

**liam**

a nasty hack could be to raise a specific error at that level and then catch it at listener.on_data then break out of the read loop

---

## 2017-11-12 17:22:47 - general channel

**magiclevinho**

Hello Mates!

I m trying to get the live scores for a particular match, but I get connection error. What I use is:

trading.in_play_service.get_scores(event_ids=[event.event.id])

I can successfully get the events, but not the scores!

---

## 2017-11-02 18:08:47 - general channel

**seaders**

tests fixed

---

## 2017-11-02 17:45:04 - general channel

**liam**

I normally add some error catching and attempt a login() if it fails

---

## 2017-10-30 13:10:41 - general channel

**seaders**

some calls it will error out if you give it things it doesn't expect, some calls it won't

---

## 2017-10-30 13:10:22 - general channel

**seaders**

it's irritating that it doesn't error out there

---

## 2017-10-30 11:37:41 - general channel

**liam**

1.5.5 fixes the issue, [https://pypi.python.org/pypi/betfairlightweight/1.5.5](https://pypi.python.org/pypi/betfairlightweight/1.5.5)

---

## 2017-10-30 11:14:12 - general channel

**liam**

[!channel](!channel) market streaming is broken, fixing now [http://forum.bdp.betfair.com/showthread.php?t=1831&amp;page=11#106](http://forum.bdp.betfair.com/showthread.php?t=1831&amp;page=11#106)

---

## 2017-10-28 21:28:28 - general channel

**Unknown**

I followed the instructions for creating the cert for non interactive login. I think it did it correctly. When I try to upload as instructed, I get the above error. Has anyone seen that before? Cheers.

---

## 2017-10-26 20:46:05 - issues channel

**liam**

If you set logging to debug can you see runner data?

---

## 2017-10-16 20:11:53 - general channel

**liam**

Anyone got experience with serverless / pickling data via http? Currently have a backtesting library as a serverless function on AWS which I currently send market ids which are then downloaded from s3 and processed. However I want to be able to send ‘strategies’ which would be a list of classes. When I attempt to unpicked I get all sorts of errors about not being able to find the module. 

---

## 2017-09-19 11:54:41 - general channel

**seaders**

you already have "_error_handler" in there for the request

---

## 2017-09-19 09:25:58 - general channel

**liam**

[@U5D4ZBEAG](@U5D4ZBEAG) so you want to raise an error but catch the response from betfair? Seems reasonable for the main endpoints. For racecard and inplayservice I think dynamically creating the class is the only way as they are constantly changing, either using the old becket type class or one of the python serialisation / marshalling libraries. 

---

## 2017-09-15 10:34:29 - general channel

**seaders**

like, per BF's documentation, [http://docs.developer.betfair.com/docs/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Type+Definitions#BettingTypeDefinitions-RunnerCatalog](http://docs.developer.betfair.com/docs/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Type+Definitions#BettingTypeDefinitions-RunnerCatalog) what you have should work, but they were obviously not sending one of selectionId, runnerName, handicap or sortPriority, but ew don't see that because the response is swallowed &amp; lost with the exception

---

## 2017-09-15 10:32:13 - general channel

**seaders**

so that when it bubbles up, we could check a `BetFairLightweightError.invalid_response` to know exactly what's breaking the response processor

---

## 2017-09-15 10:31:15 - general channel

**seaders**

to wrap process_response in try/catch, and catch and raise any error there, but with a `invalid_response` field (or something like that) that preserves the unhandled response from BF?

---

## 2017-09-15 10:29:03 - general channel

**seaders**

```

   File "/home/ubuntu/Envs/bfstream/lib/python2.7/site-packages/betfairlightweight/endpoints/betting.py", line 158, in list_market_catalogue

    return self.process_response(response, resources.MarketCatalogue, elapsed_time, lightweight)

  File "/home/ubuntu/Envs/bfstream/lib/python2.7/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 100, in process_response

    return [resource(elapsed_time=elapsed_time, **x) for x in result]

  File "/home/ubuntu/Envs/bfstream/lib/python2.7/site-packages/betfairlightweight/resources/bettingresources.py", line 248, in __init__

    self.runners = [RunnerCatalogue(**i) for i in kwargs.get('runners', [])]

TypeError: __init__() takes at least 5 arguments (4 given)```

---

## 2017-09-14 08:14:02 - general channel

**liam**

 0.15.1 released which 'should' fix the 'connection closed by server' / empty recv error sometimes seen when running a socket for a while. [@U5D4ZBEAG](@U5D4ZBEAG) I also noticed that betfair have added more data to racecard responses (currently failing) I am thinking for these non public endpoints (racecard  and inplayservice) we either add kwargs or dynamically create the class to prevent having to update every time they make a change but welcome any thoughts / PR's

---

## 2017-09-13 21:00:26 - general channel

**liam**

I see, yeh because subscriptions aren't addictive I assume you just get an update. It's annoying that you dont get an error from betfair 

---

## 2017-09-13 20:47:28 - general channel

**seaders**

so the actual error happens in [https://github.com/liampauling/betfair/blob/b4e85fdc595a74610f85599eb15792411e3e108c/betfairlightweight/resources/streamingresources.py#L329](https://github.com/liampauling/betfair/blob/b4e85fdc595a74610f85599eb15792411e3e108c/betfairlightweight/resources/streamingresources.py#L329)

---

## 2017-09-13 20:31:24 - general channel

**liam**

Should probably try and catch this and raise an informative error...

---

## 2017-09-13 19:51:01 - general channel

**liam**

If its a 'new' market and you provide clk i assume it will just provide a delta and therefore error when the marketbook attempts to be created as there is no def 

---

## 2017-09-13 19:26:14 - general channel

**seaders**

I'm getting an error when it's going to that second market

---

## 2017-09-13 13:06:09 - general channel

**liam**

You can increase the timeout but because there should be a heartbeat, the library assumes that the connection is broken so stop() is called to tidy it up. You can then subscribe again or resubscribe using the clk / initial_clk. Aaron posted an example of how he deals with it which is similar to mine but async = true can hide these errors 

---

## 2017-09-11 16:36:05 - general channel

**liam**

[https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1497360179025752](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1497360179025752) [@U4H3EEV45](@U4H3EEV45) did you ever isolate this error? I think I am seeing the same thing at least once a week 

---

## 2017-09-11 02:42:45 - issues channel

**seaders**

main thing is running it, breaking it, debugging / logging it, until you're comfortable

---

## 2017-09-11 02:23:09 - issues channel

**seaders**

and, *at worst*, start up the api with a debugger

---

## 2017-09-11 01:39:40 - issues channel

**gerg**

I used forward slashes , not double back slashes.. But in the error its showing double forward slashes

---

## 2017-09-09 23:32:09 - issues channel

**gerg**

[@U4H19D1D2](@U4H19D1D2) Like you said I downloaded the file and gave the entire path to that file, 



# create historical stream, update directory to file location

stream = trading.historical.create_stream(

  directory='C:\\Users\Gerg\Downloads\data\Sites\bodw\api\8223dab0-db21-4435-af78-42d036c9ada0\BASIC-1.119219417',

  listener=listener

)



but I am getting following error. 





IOError                                   Traceback (most recent call last)

&lt;ipython-input-13-9b68443c839e&gt; in &lt;module&gt;()

35 

36 # start stream

---&gt; 37 stream.start(async=False)



C:\Users\Gerg\Anaconda2\lib\site-packages\betfairlightweight\endpoints\historical.pyc in start(self, async)

45             t.start()

46         else:

  ---&gt; 47             self._read_loop()

48 

49     def _read_loop(self):

  

  C:\Users\Gerg\Anaconda2\lib\site-packages\betfairlightweight\endpoints\historical.pyc in _read_loop(self)

48 

49     def _read_loop(self):

  ---&gt; 50         with open(self.directory, 'r') as f:

  51             for update in f:

  52                 self.listener.on_data(update)



IOError: [Errno 22] invalid mode ('r') or filename: 'C:\\Users\\Gerg\\Downloads\\data\\Sites\x08odw\x07pi\\8223dab0-db21-4435-af78-42d036c9ada0\\BASIC-1.119219417'

---

## 2017-09-09 21:44:13 - issues channel

**liam**

The error above just has your desktop 

---

## 2017-09-09 21:42:45 - issues channel

**gerg**

I am getting IO error in windows machine. Its failing here in examplehistorical.py



#######################

# create historical stream, update directory to file location

stream = trading.historical.create_stream(

    directory='C:\\Users\Gerg\Desktop',

    listener=listener

)

########################

---------------------------------------------------------------------------

IOError                                   Traceback (most recent call last)

&lt;ipython-input-27-5894684e70b4&gt; in &lt;module&gt;()

     35 

     36 # start stream

---&gt; 37 stream.start(async=False)



C:\Users\Gerg\Anaconda2\lib\site-packages\betfairlightweight\endpoints\historical.pyc in start(self, async)

     45             t.start()

     46         else:

---&gt; 47             self._read_loop()

     48 

     49     def _read_loop(self):



C:\Users\Gerg\Anaconda2\lib\site-packages\betfairlightweight\endpoints\historical.pyc in _read_loop(self)

     48 

     49     def _read_loop(self):

---&gt; 50         with open(self.directory, 'r') as f:

     51             for update in f:

     52                 self.listener.on_data(update)



IOError: [Errno 2] No such file or directory: 'C:\\Users\\Gerg\\Desktop'

---

## 2017-09-08 17:22:47 - general channel

**magiclevinho**

in time it takes 2 sec before the error appears.

---

## 2017-09-08 16:50:26 - general channel

**magiclevinho**

[@U4H19D1D2](@U4H19D1D2) No, it says Exception: ConnectionError. Idk if it is timeout or not?

---

## 2017-09-08 15:43:03 - general channel

**liam**

Is it a timeout error? 

---

## 2017-09-08 14:05:04 - general channel

**magiclevinho**

[@U4H19D1D2](@U4H19D1D2) Do You have any clue why do I get a lot of Connection Error while running my program? I can successfully ping [http://google.com|google.com](http://google.com|google.com) without loss. Is there some switch for retry on Connection Error? Now I use try except method in a while loop but if there are a lot of matches to query it barely can succeed.

---

## 2017-09-07 12:25:23 - general channel

**liam**

And for py3 you need to use: except BetfairError as e:

---

## 2017-09-07 12:23:25 - general channel

**liam**

That should print the error message 

---

## 2017-09-07 12:23:03 - general channel

**liam**

except BetfairError, e:

---

## 2017-09-07 11:16:02 - general channel

**magiclevinho**

I try to investigate betfairlightweight exception, but I don't know how to do it.

I have a try, except betfairlightweight.exceptions.APIError function implemented, and if I print "print(str(betfairlightweight.exceptions.APIError.message))" the error message, then I only get "&lt;attribute 'message' of 'exceptions.BaseException' objects&gt;" as response. How can I see what was the excetion cause?

---

## 2017-08-30 12:09:52 - general channel

**liam**

That would explain the errors 

---

## 2017-08-30 11:49:36 - general channel

**seaders**

I've put in a PR with the fix, [https://github.com/liampauling/betfair/pull/119](https://github.com/liampauling/betfair/pull/119)

---

## 2017-08-25 16:05:15 - general channel

**seaders**

hilarious, I'm just checking here.  stopped chatting with my mate at 12.25, last racecard error reported at 12.44

---

## 2017-08-25 15:54:00 - general channel

**seaders**

I was getting 100% 404 errors for the past I don't know how long

---

## 2017-08-25 15:25:11 - general channel

**liam**

I took it off the website, I can only assume it's a betfair error, you able to check the website to see if that is also error'ing 

---

## 2017-08-25 11:51:34 - general channel

**seaders**

I'm getting a crapton of 404 errors from it

---

## 2017-07-26 16:56:25 - general channel

**liam**

Random question but anyone getting socket timeout errors at around 06:03am UTC? Had it every day this week 

---

## 2017-07-26 16:12:49 - general channel

**liam**

Interesting, this is one of the reasons why I want to move to using the rest endpoint. The status code error catcher would then hopefully catch the error. [@U5Q3P94NT](@U5Q3P94NT) did you create the issue on GitHub? 

---

## 2017-07-26 10:31:36 - general channel

**liam**

What are the logs saying at the debug level? 

---

## 2017-07-26 05:15:29 - general channel

**magiclevinho**

Until now my program worked, now I'm getting JSON error during login:

Traceback (most recent call last):

  File "D:/01_PhD/Fogadas/BETFAIR0,5/main.py", line 39, in &lt;module&gt;

    trading.login()

  File "C:\Python27\lib\site-packages\betfairlightweight\endpoints\login.py", line 26, in __call__

    (response, elapsed_time) = self.request(self.url, session=session)

  File "C:\Python27\lib\site-packages\betfairlightweight\endpoints\login.py", line 41, in request

    response_data = response.json()

  File "C:\Python27\lib\site-packages\requests\models.py", line 894, in json

    return complexjson.loads(self.text, **kwargs)

  File "C:\Python27\lib\json\__init__.py", line 339, in loads

    return _default_decoder.decode(s)

  File "C:\Python27\lib\json\decoder.py", line 364, in decode

    obj, end = self.raw_decode(s, idx=_w(s, 0).end())

  File "C:\Python27\lib\json\decoder.py", line 382, in raw_decode

    raise ValueError("No JSON object could be decoded")

ValueError: No JSON object could be decoded

---

## 2017-07-22 16:30:49 - general channel

**jfo**

i’m getting a timeout error

---

## 2017-07-20 12:33:14 - general channel

**liam**

Thanks [@U5D4ZBEAG](@U5D4ZBEAG) is this breaking now or is it planned? I'm on holiday at the moment (typical) and haven't seen any major errors on my builds. However I can login on my phone and merge if required 

---

## 2017-07-02 11:00:28 - general channel

**agberk**

Will need to remind myself of specifics but I'm probably in favour of raising an error; will double check tomorrow and add comments to the issue

---

## 2017-07-02 10:55:50 - general channel

**agberk**

I think I might have seen the error again but with more info; I'll check the logs tomorrow when i go into work hopefully they havent been rotated

---

## 2017-06-30 11:55:39 - general channel

**liam**

[@U4H3EEV45](@U4H3EEV45) did you ever get a response regarding the EOF error?

---

## 2017-06-28 18:37:32 - general channel

**liam**

Will push a minor update tonight to fix the sp issue, any other patches to add?

---

## 2017-06-28 13:41:39 - general channel

**liam**

Pt is persistence type, yeh this needs to be fixed as well. Surprised no one else has encountered this but I guess sp isn't popular... 

---

## 2017-06-28 13:31:19 - general channel

**Evaldas**

Exception in thread Thread-2:

Traceback (most recent call last):

  File "/usr/lib/python3.4/threading.py", line 920, in _bootstrap_inner

    self.run()

  File "/usr/lib/python3.4/threading.py", line 868, in run

    self._target(*self._args, **self._kwargs)

  File "/home/daan/Python/GreyHoundBot_streaming/greyMain.py", line 104, in start_orders_socket

    self.betfair_orders_socket.start(async=False)

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/streaming/betfairstream.py", line 49, in start

    self._read_loop()

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/streaming/betfairstream.py", line 177, in _read_loop

    self._data(received_data)

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/streaming/betfairstream.py", line 204, in _data

    if self.listener.on_data(received_data) is False:

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/streaming/listener.py", line 84, in on_data

    self._on_change_message(data, unique_id)

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/streaming/listener.py", line 109, in _on_change_message

    self.stream.on_subscribe(data)

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/streaming/stream.py", line 40, in on_subscribe

    self._process(book_data, publish_time)

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/streaming/stream.py", line 134, in _process

    self._caches[market_id] = OrderBookCache(publish_time=publish_time, **order_book)

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/resources/streamingresources.py", line 494, in __init__

    self.runners = [OrderBookRunner(**i) for i in kwargs.get('orc', [])]

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/resources/streamingresources.py", line 494, in &lt;listcomp&gt;

    self.runners = [OrderBookRunner(**i) for i in kwargs.get('orc', [])]

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/resources/streamingresources.py", line 454, in __init__

    self.unmatched_orders = [UnmatchedOrder(**i) for i in uo] if uo else []

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/resources/streamingresources.py", line 454, in &lt;listcomp&gt;

    self.unmatched_orders = [UnmatchedOrder(**i) for i in uo] if uo else []

TypeError: __init__() missing 1 required positional argument: 'pt'

---

## 2017-06-28 12:49:27 - general channel

**liam**

Setting lightweight to False will hide the error 

---

## 2017-06-28 12:48:59 - general channel

**liam**

Yeh it can't handle the sp response betfair returns, need to fix this 

---

## 2017-06-28 12:46:16 - general channel

**Evaldas**

i get error:



place_order()

  File "/home/daan/Python/GreyHoundBot_streaming/bf_api_test.py", line 28, in place_order

    place_orders = trading.betting.place_orders(market_id=market_id, instructions=[instruction])  # list

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/endpoints/betting.py", line 299, in place_orders

    return self.process_response(response, resources.PlaceOrders, elapsed_time, lightweight)

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/endpoints/baseendpoint.py", line 102, in process_response



    return resource(elapsed_time=elapsed_time, **result)

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/resources/bettingresources.py", line 679, in __init__



    PlaceOrderInstructionReports(**i) for i in kwargs.get('instructionReports')

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/resources/bettingresources.py", line 679, in &lt;listcomp&gt;

    PlaceOrderInstructionReports(**i) for i in kwargs.get('instructionReports')

  File "/home/daan/Python/GreyHoundBot_streaming/bfmaster/betfairlightweight/resources/bettingresources.py", line 659, in __init__

    self.instruction = PlaceOrderInstruction(**instruction) if instruction else None

TypeError: __init__() got an unexpected keyword argument 'marketOnCloseOrder'

---

## 2017-06-28 12:33:24 - general channel

**Evaldas**

that was exception from betting.place_orders

---

## 2017-06-28 12:21:02 - general channel

**liam**

What file are you getting that error in? Is it in the response?

---

## 2017-06-28 10:15:31 - general channel

**liam**

Do you get an error? / what's the response?

---

## 2017-06-23 09:21:23 - general channel

**heedfull**

Hi, newbie question here, get this error when I’m trying to get some markets back. It say’s I’m missing a required field, but I can’t for life of me find it

```

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketCatalogue

Params: {'maxResults': 100, 'sort': 'FIRST_TO_START', 'filter': {'marketStartTime': {'to': None, 'from': '2017-06-23T09:08:57Z'}, 'eventTypeIds': '7', 'marketCountries': 'GB', 'marketTypeCodes': 'WIN'}, 'marketProjection': ['EVENT', 'MARKET_START_TIME']}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}

```

---

## 2017-06-13 14:43:23 - general channel

**liam**

Sometimes it's as though there are only a handful of people actually using the api. I'm still waiting on an answer about cancel requests not having an error code sometimes 

---

## 2017-06-13 14:39:07 - general channel

**agberk**

I don't quite understand the point of the flag - because if EOF means your connection is done and it's suppressing it... then is just the point of it to stop an exception being thrown? As in if it wasn't there, whenever the connection got closed while you were receiving you'd get an exception, but this way you'll just get a 0 length string and its down to the user to take some action if the return is a 0 length string because they should know that's what it means? And it stops them from having to catch an exception?

---

## 2017-06-13 14:35:06 - general channel

**liam**

If EOF means that betfair has closed the connection then hiding it will cause an issue no? Most likely a timeout error 

---

## 2017-06-13 14:32:42 - general channel

**agberk**

If that `suppress_ragged_eofs` flag is set to True then there wouldn't be an exception to catch unfortunately

---

## 2017-06-13 14:30:54 - general channel

**liam**

Hmm interesting, I don't think I have encounter this or maybe I have but my error catching is hiding it. Will be interesting to see what betfair say along with your test. Would an alternative of trying to catch all potential socket errors at .recv work?

---

## 2017-06-13 14:25:04 - general channel

**agberk**

If that is indeed the issue then the solution might be either to change that suppress_ragged_eofs flag, or maybe to take some different action like throwing an exception if part is empty - though I'm not too sure whether that happens a lot anyway? Or if that can only happen if a ragged EOF comes through

---

## 2017-06-13 14:22:59 - general channel

**agberk**

I'm also going to try setting the field on the socket `suppress_ragged_eofs` to False and run my code - if that's the issue then I should expect to see these exceptions get raised in my logs following by an automatic restart which my code takes care of

---

## 2017-06-13 14:21:34 - general channel

**agberk**

I've opened a ticket with BDP asking them to look at a specific connectionId where this has happened to see if they can tell me how it was closed and whether there was some error or whatever

---

## 2017-06-13 14:14:22 - general channel

**agberk**

[@U4H19D1D2](@U4H19D1D2) I mentioned a while ago about having issues with streaming connections that were stopping unexpectedly but weren't throwing an exception - may have found the issue

---

## 2017-06-10 19:16:20 - general channel

**Evaldas**

hey guys!

Im trying to fix my by bot here a bit, by putting all markets under one api stream, instead of creating new ones. And I cant figure out how do you "feed" stream to all threads? If I have running n market threads and one of them calls get() from stream queue.Queue() that object is gone, right? So how do I know which of the threads should call the queue to get latest MarketBook?

---

## 2017-06-09 17:12:10 - general channel

**liam**

Wrap the request in try / except with BetfairError and it will catch it 

---

## 2017-06-09 17:03:01 - general channel

**magiclevinho**

Traceback (most recent call last):

  File "C:\Program Files\JetBrains\PyCharm Community Edition 2017.1.3\helpers\pydev\pydevd.py", line 1585, in &lt;module&gt;

    globals = debugger.run(setup['file'], None, None, is_module)

  File "C:\Program Files\JetBrains\PyCharm Community Edition 2017.1.3\helpers\pydev\pydevd.py", line 1015, in run

    pydev_imports.execfile(file, globals, locals)  # execute the script

  File "C:/Users/john/Documents/Pythonprojects/betfair_00/main.py", line 27, in &lt;module&gt;

    in_play_only=True,

  File "C:\Python27\lib\site-packages\betfairlightweight\endpoints\betting.py", line 84, in list_events

    (response, elapsed_time) = self.request(method, params, session)

  File "C:\Python27\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 43, in request

    raise APIError(None, method, params, 'ConnectionError')

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listEvents 

Params: {'filter': {'eventTypeIds': [u'1'], 'inPlayOnly': True}} 

Exception: ConnectionError

---

## 2017-06-06 16:33:41 - general channel

**liam**

So the data is parsed into a Scores resource, use a debugger and investigate what's in there. Pycharm is good for this 

---

## 2017-06-05 14:46:31 - general channel

**liam**

Ok thanks will fix that, yeh Becket would set it as None if not present 

---

## 2017-06-05 13:54:26 - general channel

**agberk**

[@U4H19D1D2](@U4H19D1D2) - another error I've just run into with the latest version

```

Exception in thread Thread-1:

Traceback (most recent call last):

  File "/usr/lib/python2.7/threading.py", line 801, in __bootstrap_inner

    self.run()

  File "/usr/lib/python2.7/threading.py", line 754, in run

    self.__target(*self.__args, **self.__kwargs)

  File "/home/aaron/workspace/xxx/betfair_market_feed.py", line 42, in betfair_market_feed

    locale=config.get('markets', {}).get('locale')

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/endpoints/betting.py", line 158, in list_market_catalogue

    return self.process_response(response, resources.MarketCatalogue, elapsed_time, lightweight)

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/endpoints/baseendpoint.py", line 100, in process_response

    return [resource(elapsed_time=elapsed_time, **x) for x in result]

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/resources/bettingresources.py", line 229, in __init__

    self.runners = [RunnerCatalogue(**i) for i in kwargs.get('runners', [])]

TypeError: __init__() takes at least 5 arguments (4 given)

```

Now the docs do say there are 4 required attributes on a RunnerCatalogue: [http://docs.developer.betfair.com/docs/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Type+Definitions#BettingTypeDefinitions-RunnerCatalog](http://docs.developer.betfair.com/docs/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Type+Definitions#BettingTypeDefinitions-RunnerCatalog)

They've sent through a list of runners where one is missing the runnerName:

```

runners: [{u'handicap': 0.0, u'runnerName': u'Knowle/Zelenay', u'selectionId': 5717065, u'sortPriority': 1}, {u'handicap': 0.0, u'runnerName': u'Marrero/Paes.', u'selectionId': 8786145, u'sortPriority': 2}, {u'handicap': 0.0, u'sortPriority': 3, u'selectionId': 8781561}]

```

I know a lot has changed in terms of the resources - how come this sort of thing worked (or maybe silently failed is a better way of describing it? lol) before? Did the Beckett resource model just None anything that wasn't present?

---

## 2017-06-03 09:38:00 - general channel

**liam**

version 1.3 released, bug fixes and initial attempt at a Historical end point [https://github.com/liampauling/betfairlightweight#historical-data](https://github.com/liampauling/betfairlightweight#historical-data)

---

## 2017-06-02 18:43:19 - general channel

**liam**

Also wasn't even aware of exception hooks 

---

## 2017-06-02 15:27:23 - general channel

**agberk**

```

Traceback (most recent call last):

  File "/usr/lib/python2.7/threading.py", line 801, in __bootstrap_inner

    self.run()

  File "/usr/lib/python2.7/threading.py", line 754, in run

    self.__target(*self.__args, **self.__kwargs)

  File "/home/aaron/workspace/xxx/betfair_order_feed.py", line 94, in betfair_stream_run

    betfair_stream_socket.start()

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 49, in start

    self._read_loop()

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 177, in _read_loop

    self._data(received_data)

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 204, in _data

    if self.listener.on_data(received_data) is False:

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/streaming/listener.py", line 83, in on_data

    self._on_change_message(data, unique_id)

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/streaming/listener.py", line 108, in _on_change_message

    self.stream.on_subscribe(data)

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/streaming/stream.py", line 40, in on_subscribe

    self._process(book_data, publish_time)

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/streaming/stream.py", line 132, in _process

    self._caches[market_id] = OrderBookCache(publish_time=publish_time, **order_book)

  File "/home/aaron/tmp/venv/betfairlightweight/local/lib/python2.7/site-packages/betfairlightweight/resources/streamingresources.py", line 488, in __init__

    self.runners = [OrderBookRunner(**i) for i in kwargs.get('orc', [])]

TypeError: __init__() got an unexpected keyword argument 'hc'

```

---

## 2017-06-02 14:54:54 - general channel

**agberk**

Yeah it's in a thread but I've got an excepthook for logging uncaught exceptions and I'm aware of [https://bugs.python.org/issue1230540](https://bugs.python.org/issue1230540) and am using one of the workarounds in there

---

## 2017-06-02 14:52:23 - general channel

**liam**

Are you running that in a thread? Python has a habit of not showing an error if a thread dies due to a third party library like lightweight erroring 

---

## 2017-06-02 14:47:24 - general channel

**agberk**

I've got debug level logging switched on for betfairlightweight now so I'll be able to see what output there is if any when it happens again

---

## 2017-06-02 14:46:31 - general channel

**agberk**

So even if the _error_handler on the listener causes _data to call stop() it should loop again, create a fresh stream and subscribe on that new stream object

---

## 2017-06-02 14:44:36 - general channel

**agberk**

The main read loop is in my own thread

```

def betfair_stream_run(config, order_queue):

    betfair_api = betfairlightweight.APIClient(

        config['betfair_username'],

        config['betfair_password'],

        config['betfair_application_key'],

        config['betfair_certificate_dir'])



    while True:

        try:

            betfair_api.login()

            betfair_stream_socket = betfair_api.streaming.create_stream(

                unique_id=1,

                description=config['description'],

                listener=StreamListener(output_queue=order_queue)

            )

            betfair_stream_socket.subscribe_to_orders(

                unique_id=12345,

            )

            betfair_stream_socket.start()

        except betfairlightweight.exceptions.SocketError:

            logger.warning('SocketError in betfair stream thread.')

            time.sleep(5.0)

        except betfairlightweight.exceptions.APIError as e:

            logger.error(e, exc_info=True)

            time.sleep(5.0)

```

---

## 2017-06-02 14:44:05 - general channel

**agberk**

[@U4H19D1D2](@U4H19D1D2) am running into situations quite frequently today where the stream / socket stops receiving data but I'm not getting an exception or the read loop isn't exiting as I'm expecting; I know there was something recent discussion on subscribing multiple times on a socket, or perhaps creating multiple streams or something - I'm about to go look at the issues to refresh my memory - I'm still on v1.0.0 so it might be the problem is fixed just thought I'd check to see whether describing that behaviour made you think of anything obvious

---

## 2017-05-29 18:15:17 - general channel

**liam**

What is instruction? And what init is erroring?

---

## 2017-05-29 18:11:53 - general channel

**jfo**

Sorry. More daft questions but i’m seeing this error: `__init__() takes at least 3 arguments (5 given)` It says its coming from: 

```place_orders = self.client.betting.place_orders(

                            market_id=str(book.market_id),

                            instructions=[instruction]

                        )```

---

## 2017-05-29 13:02:16 - general channel

**liam**

i have never used a limit order with these options, probably needs to be fixed

---

## 2017-05-27 23:34:26 - general channel

**heedfull**

Hi folks getting this error when running `python setup.py test` 

```

ImportError: Failed to import test module: test_accountresources

Traceback (most recent call last):

  File "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/unittest/loader.py", line 153, in loadTestsFromName

    module = __import__(module_name)

  File "/betfairlightweight/tests/test_accountresources.py", line 8, in &lt;module&gt;

    from tests.tools import create_mock_json

  File "/betfairlightweight/tests/tools.py", line 1, in &lt;module&gt;

    from mock import Mock

ModuleNotFoundError: No module named 'mock'

```

---

## 2017-05-26 15:16:12 - general channel

**jfo**

got an exception i've not seen before: `Exception: Timeout value connect was (3.05, 16), but it must be an int or float.`

---

## 2017-05-24 18:17:30 - general channel

**liam**

Odd, the error is the size, needs to be above 2 for gbp or £10 liability 

---

## 2017-05-24 18:00:57 - general channel

**jfo**

```SportsAPING/v1.0/placeOrders

Params: {'instructions': [{'orderType': 'LIMIT', 'selectionId': 5687409, 'limitOrder': {'persistenceType': 'LAPSE', 'price': 1.02, 'size': 1}, 'side': 'LAY'}], 'marketId': '1.131837764'}

Exception: None

Error: {u'message': u'ANGX-0002', u'code': -32099, u'data': {u'exceptionname': u'APINGException', u'APINGException': {u'errorCode': u'INVALID_INPUT_DATA', u'requestUUID': u'prdang-2882bf-04180911-00ee30c51a', u'errorDetails': u'market id passed is invalid'}}}

Full Response: {u'jsonrpc': u'2.0', u'id': 1, u'error': {u'message': u'ANGX-0002', u'code': -32099, u'data': {u'exceptionname': u'APINGException', u'APINGException': {u'errorCode': u'INVALID_INPUT_DATA', u'requestUUID': u'prdang-2882bf-04180911-00ee30c51a', u'errorDetails': u'market id passed is invalid'}}}}```

---

## 2017-05-22 19:10:54 - general channel

**liam**

Looking through my error logs I can see that an order stream restarted twice because rac and rc (regulator auth code and regulator code) weren't provided, any ideas why an order wouldn't have this?

---

## 2017-05-21 23:30:52 - general channel

**richard**

On trying the trading.login() line I now get:APIError: None

Params: None

Exception: [('system library', 'fopen', 'No such process'), ('BIO routines', 'FILE_CTRL', 'system lib'), ('SSL routines', 'SSL_CTX_use_certificate_file', 'system lib')]

---

## 2017-05-19 15:13:12 - general channel

**richard**

The example part 1 errors "Certificate folder not found in /certs". I don't recall ever needing to make certificates to run my bots of old. Am I going to need to now to use this package?

---

## 2017-05-17 14:08:33 - general channel

**liam**

The client creates a new session on each request unless you supply a session object, as [http://requests.post|requests.post](http://requests.post|requests.post) will create a new session if not supplied. I use a session per thread as I was getting errors when trying to share

---

## 2017-05-01 13:53:06 - general channel

**jfo**

```INFO:betfairlightweight.streaming.listener:[Subscription: 2]: SUCCESS

ERROR:betfairlightweight.streaming.listener:[Subscription: 0] SUBSCRIPTION_LIMIT_EXCEEDED: trying to subscribe to 202 markets whereas max allowed number was: 200

INFO:betfairlightweight.streaming.listener:[Subscription: 0]: FAILURE```

---

## 2017-05-01 13:34:24 - general channel

**jfo**

```Exception in thread My Socket:

Traceback (most recent call last):

  File "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py", line 801, in __bootstrap_inner

    self.run()

  File "/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.py", line 754, in run

    self.__target(*self.__args, **self.__kwargs)

  File "/usr/local/lib/python2.7/site-packages/betfairlightweight/streaming/betfairstream.py", line 160, in _read_loop

    raise SocketError('[Connect: %s]: Socket %s' % (self.unique_id, e))

SocketError: [Connect: 2]: Socket ('The read operation timed out',)```

---

## 2017-05-01 13:19:41 - general channel

**jfo**

getting timeout errors on stream :thinking_face:

---

## 2017-04-14 20:07:59 - general channel

**favetelinguis**

TypeError: ObjectId(‘58f11d3c63b1476ade4ac24c’) is not JSON serializable

---

## 2017-04-14 20:07:57 - general channel

**favetelinguis**

[@U4H19D1D2](@U4H19D1D2) thanks works now but seems like market book is not json serializable using mb.jason() im getting the error

---

## 2017-04-06 20:24:59 - general channel

**liam**

or you can set blocking to False (get(False)) and then add error handling for an empty queue if you want your code non blocking

---

