# Random Knowledge Base

*Generated from Slack chat history - 2951 technical conversations*

---

## 2017-11-20

**liam** - *20:11:32*

Good question, I haven’t actually timed it but it’s certainly sub 1s, I will time it tomorrow 

*Tags: General Technical*

---

## 2017-12-09

**OT** - *11:30:35*

Anybody seen this error when dealing with the historical data?

*Tags: Data Quality, Errors Debugging*

---

**OT** - *11:30:37*

zlib.error: Error -3 while decompressing: invalid distance too far back

*Tags: Errors Debugging*

---

## 2018-03-24

**jfo** - *18:14:41*

:wave: i’ve mentioned this once before and haven’t done _much_ on it since I did the first push, but i’ve just updated a Swift library for betfair api to use Apple’s new NIO framework if anyone is interested: [https://github.com/foulkesjohn/BetSwift](https://github.com/foulkesjohn/BetSwift)

*Tags: General Technical*

---

## 2018-04-04

**liam** - *10:03:58*

Good question, I have been using c5 spot instances but looking at fargate to reduce costs. But like you not sure where to start with building my own... 

*Tags: General Technical*

---

## 2018-04-07

**liam** - *08:02:51*

Nope just the ability to process historical data through it

*Tags: Data Quality*

---

## 2018-04-18

**liam** - *19:42:36*

Data classes in 3.7 look cool and could make API wrapper resources much cleaner [https://blog.jetbrains.com/pycharm/2018/04/python-37-introducing-data-class/](https://blog.jetbrains.com/pycharm/2018/04/python-37-introducing-data-class/)

*Tags: General Technical*

---

## 2018-04-19

**hugo** - *14:39:24*

Heard good things about [https://github.com/python-attrs/attrs](https://github.com/python-attrs/attrs) as well

*Tags: General Technical*

---

## 2018-07-17

**Unknown** - *20:29:53*

[@U5D4ZBEAG](@U5D4ZBEAG) uploaded a file: [https://betfairlightweight.slack.com/files/U5D4ZBEAG/FBRL1AAKB/image.png|image.png](https://betfairlightweight.slack.com/files/U5D4ZBEAG/FBRL1AAKB/image.png|image.png)

*Tags: General Technical*

---

**seaders** - *20:38:31*

but because Serie A and Ligue 1 haven't fricking released their fixtures yet, they're not on BF yet

*Tags: Errors Debugging*

---

**Unknown** - *21:43:00*

[@U5D4ZBEAG](@U5D4ZBEAG) uploaded a file: [https://betfairlightweight.slack.com/files/U5D4ZBEAG/FBSCHR1BP/pasted_image_at_2018_07_17_09_42_pm.png|Pasted image at 2018-07-17, 9:42 PM](https://betfairlightweight.slack.com/files/U5D4ZBEAG/FBSCHR1BP/pasted_image_at_2018_07_17_09_42_pm.png|Pasted image at 2018-07-17, 9:42 PM)

*Tags: General Technical*

---

**Unknown** - *21:43:35*

[@U5D4ZBEAG](@U5D4ZBEAG) uploaded a file: [https://betfairlightweight.slack.com/files/U5D4ZBEAG/FBRMHGU3T/pasted_image_at_2018_07_17_09_43_pm.png|Pasted image at 2018-07-17, 9:43 PM](https://betfairlightweight.slack.com/files/U5D4ZBEAG/FBRMHGU3T/pasted_image_at_2018_07_17_09_43_pm.png|Pasted image at 2018-07-17, 9:43 PM)

*Tags: General Technical*

---

## 2018-07-26

**Anatoliy** - *16:15:36*

Hello; I have a question. I am looking for a way to get live data for tennis matches to be able to place live bets.

Currently I am using the following method:

betfairlightweight.APIcleint.in_play_service.get_scores

I am wondering; 

- is it possible to get live scores using a websocket?

- if a websocket is not an option, at what rate should I use "get_scores"? Is every 3 seconds too often?

*Tags: Deployment*

---

**liam** - *16:38:30*

[https://github.com/liampauling/betfair/blob/master/betfairlightweight/endpoints/scores.py#L32](https://github.com/liampauling/betfair/blob/master/betfairlightweight/endpoints/scores.py#L32)

*Tags: General Technical*

---

**Anatoliy** - *16:40:20*

Do you know whether a latency of 160ms for the complete operation, including roundtrip is fast enough, or way too slow?

*Tags: Performance*

---

## 2018-08-24

**seaders** - *12:44:28*

and I've run into problems with that, as well, especially when they randomly add in pitcher names to MLB games

*Tags: General Technical*

---

**seaders** - *12:48:15*

they give you that info in [https://pinnacleapi.github.io/linesapi#operation/Fixtures_V1_Get](https://pinnacleapi.github.io/linesapi#operation/Fixtures_V1_Get)

*Tags: Errors Debugging*

---

**seaders** - *12:50:16*

[https://github.com/pinnacleapi/pinnacleapi-documentation/blob/master/GettingStarted.md](https://github.com/pinnacleapi/pinnacleapi-documentation/blob/master/GettingStarted.md)

*Tags: General Technical*

---

**seaders** - *12:56:50*

[https://betfairlightweight.slack.com/archives/C4H05KKMY/p1535111716000100](https://betfairlightweight.slack.com/archives/C4H05KKMY/p1535111716000100)

I don't really.  I think I'm well past it at this point

*Tags: General Technical*

---

## 2018-09-10

**seaders** - *23:09:12*

was getting errors in my system that a market was likely incorrectly rapidly switching market_id (like on every "tick")

*Tags: Errors Debugging*

---

## 2018-10-10

**seaders** - *16:08:38*

how to get the race number from a place market you're interested in

*Tags: General Technical*

---

## 2018-10-13

**OT** - *09:37:58*

i save the race/event data to a database, then do a query on that event, sort by the start time, then you get the races in order. you can then commit the race number to the db to limit processing time

*Tags: General Technical*

---

**OT** - *10:55:40*

the documentation, I mean

*Tags: General Technical*

---

## 2018-10-25

**OT** - *14:32:56*

I'd prefer python but python and gui is a bit.. you know!

*Tags: General Technical*

---

**agberk** - *16:50:01*

I did come across this recently [https://github.com/dddomodossola/remi](https://github.com/dddomodossola/remi) haven't used it to build anything yet but would like to try it; a qt port for python was also released earlier this year [https://blog.qt.io/blog/2018/05/04/hello-qt-for-python/](https://blog.qt.io/blog/2018/05/04/hello-qt-for-python/)

*Tags: General Technical*

---

## 2018-10-26

**OT** - *10:04:39*

Interesting ideas, qt for python especially

*Tags: General Technical*

---

**OT** - *10:04:41*

I prefer python

*Tags: General Technical*

---

## 2018-10-29

**Daydreamer** - *19:44:10*

did anyone have the same problem?

*Tags: General Technical*

---

## 2018-12-11

**liam** - *20:06:34*

[!channel](!channel) Anyone looking for a new job? 



Exciting opportunity to work in Financial Crime Technology at KPMG (with me) Tech stack is mostly python but opportunity to work with AWS, ECS, terraform, vault, JavaScript (reactjs), Jenkins, docker... machine learning.. We are focussed on finding someone who is keen to learn so no requirement to have experience in all of the tech listed or Financial Crime. Feel free to send me a message to learn more!



[https://www.linkedin.com/feed/update/urn:li:activity:6478346553730875392](https://www.linkedin.com/feed/update/urn:li:activity:6478346553730875392)

*Tags: Deployment*

---

## 2019-02-26

**liam** - *15:38:57*

The betfair forum legend ‘ayerobot’ is free and will be making an appearance (he’s a bflw user)

*Tags: General Technical*

---

## 2019-03-07

**agberk** - *13:40:02*

they only reserve tables for food, but said that there should be no problem getting a table at 1830 - I'll probably get there a bit earlier anyway

*Tags: General Technical*

---

## 2019-03-10

**LK** - *11:46:31*

Is anyone aware of a free streaming service for soccer inplay (goals) updates? I'm looking at the websocket from futbol24: [wss://p.futbol24.com/f24/liveHtmlXml/ws/15](wss://p.futbol24.com/f24/liveHtmlXml/ws/15) I could try and reverse engineer it but if anyone has better ideas they are much appreciated. I don't want to make a ton of requests to the betfair inplay service. When this works well I want to switch a to commercial streaming service.

*Tags: Deployment*

---

## 2019-05-18

**liam** - *08:34:14*

Not sure what this guys problem is.... [https://github.com/liampauling/betfair/issues/210](https://github.com/liampauling/betfair/issues/210)

*Tags: General Technical*

---

## 2019-05-19

**liam** - *11:24:38*

I am just going to let him have the last word as it makes zero sense...



‘’’

It's an interface to an interface, betfair handles the heavy lifting and ssl the scurity, its a wrapper to presumably improve interacting with the underlying betfair api, you aren't building betfair from scratch.

‘’’

*Tags: General Technical*

---

## 2019-07-07

**OT** - *11:24:56*

I've written for 3 betting APIs and it's the worst one. It's the second time I've written for matchbook api though, the first time the strategy was not so sensitive to this

*Tags: Getting Started, Strategies*

---

## 2019-07-17

**William** - *12:53:37*

Are there any issues with this API and using EX_BEST_OFFERS_DISP, seem to be getting some errors when it is used in the filters

*Tags: Errors Debugging*

---

**Mo** - *12:53:58*

What errors?

*Tags: Errors Debugging*

---

**William** - *12:54:08*

Exception in thread BetfairSocket:

Traceback (most recent call last):

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\threading.py", line 917, in _bootstrap_inner

    self.run()

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\threading.py", line 865, in run

    self._target(*self._args, **self._kwargs)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 198, in _read_loop

    self._data(received_data)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 237, in _data

    if self.listener.on_data(received_data) is False:

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\listener.py", line 115, in on_data

    self._on_change_message(data, unique_id)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\listener.py", line 148, in _on_change_message

    self.stream.on_update(data)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\stream.py", line 55, in on_update

    self._process(data[self._lookup], publish_time)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\stream.py", line 130, in _process

    market_book_cache.update_cache(market_book, publish_time)

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 189, in update_cache

    runner.best_display_available_to_back.update(new_data['bdatb'])

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 61, in update

    self.sort()

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 40, in sort

    {'price': volume[self.deletion_select-1], 'size': volume[self.deletion_select]} for volume in self.prices

  File "C:\Users\PC one\AppData\Local\Programs\Python\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 40, in &lt;listcomp&gt;

    {'price': volume[self.deletion_select-1], 'size': volume[self.deletion_select]} for volume in self.prices

IndexError: list index out of range

*Tags: Errors Debugging*

---

## 2019-11-25

**PeterLe** - *15:17:16*

hi Mo, yes that looks fair as that date has the majority. I only travel down to London (from Manchester)  a couple of times a month, so ill try and make the next one. (I might even be able to better under the language a bit better then anyway, as I can imagine the Python discussion would sound like a foreign language to me currently :grinning: thanks for organising too

*Tags: General Technical*

---

## 2019-12-02

**Tom Poole** - *10:52:13*

Liam has given me permission to post an exciting new DevOps Lead Engineer opportunity in a high traffic data and streaming platform sports company, based in Central London.



As Lead DevOps Engineer you will report to the VP of Technology and will be tasked with shaping and executing the cloud and DevOps strategy. Given the seniority of the role, you should have a strong analytical mindset, be a natural problem-solver and enjoy working closely with Software Engineering teams to create a best in breed infrastructure ecosystem. You'll be responsible for shaping, building and monitoring a scalable cloud-based infrastructure (hybrid AWS / GCP… you decide!) and live operations environment. Given this is a new greenfield team you’ll have the opportunity to do this speed, scalability and security in mind. You’ll be given the autonomy to choose the best technologies and processes that will allows Engineers to consumer services effortlessly. The company has a great culture with lots of autonomy and empowerment to do things the right way.



As Lead DevOps Engineer you will need the following:

•	DevOps Engineer

•	Cloud experience AWS and/or GCP

•	Containerisation

•	CI / CD Pipelines

•	Strategy and execution

•	Docker and Kubernetes

•	Excellent communication skills

•	Advocate Agile working

•	Sports enthusiast



In return you will receive a generous salary package ranging from £90,000 - £110,000 plus bonus as well as some great benefits including free gym memberships, private medical/dental insurance and a competitive annual holiday plan.



If you are interested in learning more about the role, then please let me know when you’re next available, so I can update my diary. I look forward to hearing from you

*Tags: Performance, Deployment, Strategies*

---

## 2019-12-03

**Tom Poole** - *11:55:08*

Liam has given me permission to post a job that my Colleague is currently working. A super exciting greenfield project with the UKs #1 odds comparison site, owned by a major player in the gambling industry. He is looking for high caliber Java/Python/Go Developers to join the highly autonomous and creative team to work on their highly scalable and low latency core platform, moving into inplay streaming. Salary is incredibly competitive in addition to a bonus scheme of up to 25%! For more details please email James Full at [mailto:James@formularecruitment.co.uk|James@formularecruitment.co.uk](mailto:James@formularecruitment.co.uk|James@formularecruitment.co.uk) or give him a call on 020 3940 7464.

*Tags: Performance*

---

## 2019-12-20

**Tom** - *16:42:17*

Hi, I'm using the matchbook API wrapper that some people on here may use. I'm trying to do some optimisation I would like to be able to instead of poll data from the events endpoint by sport_id I'd prefer to pass a list of event_id's to the wrapper function that handles the request.  On matchbooks online documentation you can pass a list of evend_id's and only return data for those markets.  the below code using requests lib returns event's data for three events passed in the querystring.

Is it possible to do the same with  the matchbook wrapper here? [https://github.com/rozzac90/matchbook/blob/master/matchbook/endpoints/marketdata.py](https://github.com/rozzac90/matchbook/blob/master/matchbook/endpoints/marketdata.py)

When I try I get an error

```matchbook.exceptions.ApiError: ['Incorrect request param: id.']```

```    events = api.market_data.get_events(

                                        event_id='1148393114710116,1308951387620017',

                                        states=MarketStates.All,

                                                        per_page=200, offset=0,

                                                        include_event_participants=Boolean.T,

                                                        category_ids=None, price_depth=3,

                                                        side=Side.All, session=None)```







```import requests

url = "[https://api.matchbook.com/edge/rest/events](https://api.matchbook.com/edge/rest/events)"```

```querystring = {"offset":"0","per-page":"20","ids":"1305049710690017,1305058606890017, 1302073817190017","states":"open,suspended,closed,graded","exchange-type":"back-lay","odds-type":"DECIMAL","include-prices":"false","price-depth":"3","price-mode":"expanded","include-event-participants":"false"}```

```headers = {'user-agent': 'api-doc-test-client'}```

```response = requests.request("GET", url, headers=headers, params=querystring)```

```print(response.text)```

*Tags: Errors Debugging*

---

## 2019-12-29

**Mo** - *20:17:51*

This example shows you how to get a market catalogue and iterate through the runners, accessing the selection ID and runner name: [https://github.com/liampauling/betfair/blob/master/examples/exampleone.py](https://github.com/liampauling/betfair/blob/master/examples/exampleone.py)

*Tags: General Technical*

---

## 2019-12-31

**PeterLe** - *11:19:22*

[@UBS7QANF3](@UBS7QANF3) Hi Mo, thanks for adding more dates to the potential meetup; Im going to be at the other end UK in Edinburgh on business when the majority of you guys can make it, so Ill probably come to one of the future meetups. Just as an aside; if anyone is based in and around manchester I thought I may go to a local Python meetup that is being held 20th Jan In Manchester. Its not specific to Betfairlightweight, but Python in general. If so drop me a message. Its always good to meet like minded people. thanks (PS Happy New Year All !) :grinning:

*Tags: General Technical*

---

## 2020-01-24

**Tom Poole** - *17:15:19*

To Senior DevOps Engineers, perm or contractors looking for some security, who want a new and exciting opportunity within a sports and data streaming organisation, 3d immersive visualisation and gamification of sporting events is the plan. Tech stack - AWS/GCP, Docker, Jenkins, Terraform, Kubernetes and Ansible.  Location - Central London. Competitive salary, exceptional bonus and benefits. Let me know if you want to learn more, or know of anyone that may want a step in the right direction.

*Tags: Errors Debugging, Deployment*

---

## 2020-03-15

**Tom** - *22:34:33*

Has anyone got a smarkets wrapper written in Python? Or is anyone interested in making one?

*Tags: General Technical*

---

## 2020-03-30

**liam** - *09:40:08*

Anyone got experience in AWS Aurora? (specifically multi readers)

*Tags: Deployment*

---

## 2020-04-09

**Unknown** - *20:39:37*

[@U4H19D1D2](@U4H19D1D2) In this bit of code in streaming.cache, did you compare the performance against an implementation using an OrderedDict to store prices?

*Tags: Performance*

---

**Jonjonjon** - *21:25:47*

Do you think it's worth investigating? There is a chance it could improve performance. Though I have not done any detailed analysis, so I could be wrong.

*Tags: Performance*

---

## 2020-04-10

**liam** - *07:28:26*

Yeah always open to performance improvements

*Tags: Performance*

---

**Jonatan (skyw)** - *15:54:28*

I created a simple example showing order streaming using python SocketIO and ReactJS. Should be easy to use any "streaming" library such as zeroMQ, redis, betfairlightweight, raw sockets ...

[https://github.com/almenjonatan/betfair-gui](https://github.com/almenjonatan/betfair-gui)

It's basically react  tutorial, glued together with socket io tutorial, might be helpful for someone starting to build a gui.

*Tags: General Technical*

---

**liam** - *16:53:53*

Awesome I think betfair could use this example to get streaming rolled out on the site itself!

*Tags: General Technical*

---

## 2020-04-11

**Jonjonjon** - *09:48:36*

I read the docs for orderedict and realised it won't help. I could try a sorteddict ([http://www.grantjenks.com/docs/sortedcontainers/|http://www.grantjenks.com/docs/sortedcontainers/](http://www.grantjenks.com/docs/sortedcontainers/|http://www.grantjenks.com/docs/sortedcontainers/)), but that would add a dependency that we would need to add to requirements.txt. If I did that, would it be a problem?

*Tags: General Technical*

---

## 2020-04-12

**Dave** - *11:39:30*

* man who solved the markets (biography of Jim Simmons and RenTech (one of the most successful funds))

*Tags: General Technical*

---

**Mo** - *11:48:50*

Ed Thorpe is my role model

*Tags: Strategies*

---

**Unknown** - *12:03:18*

Too bad his ventures in financial markets are somewhat questionable ;) but everything else...pretty amazing indeed

*Tags: General Technical*

---

**Ruben** - *12:12:26*

Was there a betfair API meetup? that sounds great

*Tags: General Technical*

---

**Mo** - *12:13:45*

A betfairlightweight meetup. It was indeed great (although I organised it so possibly biased). I'm sure there will be more in the future

*Tags: General Technical*

---

## 2020-04-13

**Silver Drifter** - *19:44:02*

Hi team - I'm looking for some general advice: I've been a software developer for 30 years, always using the Microsoft stack (C#, VB, C++, SQL Server, etc).  I'm getting the feeling that Python may be better suited when it comes to the Betfair API specifically.  I'm probably going to teach myself the language.  Does anybody have any pointers as to the best place for me to start, given that I'm an experienced programmer and probably just need to learn the syntax, etc?

*Tags: Deployment*

---

**Amanda** - *19:53:38*

The Betfair API samples are in C# so why not use it?

*Tags: General Technical*

---

**Silver Drifter** - *19:57:33*

Thanks Josh.  Amanda, that's a good question.  I guess, the reason is that I can find very little in the way of online communities for the Betfair API using C#.  This community looks pretty good to me but of course, it's heavily focused on Python.  Not 100% sure yet, maybe I will stick with C#.  I've written a ton of code already for the API, which I'm quite happy with

*Tags: General Technical*

---

**James T** - *19:57:50*

Yeah, I use C# myself. I’m not sure there’s anything that makes Python specifically suited to the Betfair API. There are pros and cons of all the languages so it may be best you just choose what you’re comfortable with. Or else have a specific reason you want to use Python (eg. If you want to do stuff with machine learning). 

*Tags: General Technical*

---

**James T** - *20:00:29*

I’ve always started from the Betfair C# samples and gone from there. Never had any issues with the language. Even for ML work I’ve been doing recently I’ll do the R&amp;D in Python and then serialise the model and load it into C# for production use. 

*Tags: Deployment, Strategies*

---

**Silver Drifter** - *20:01:55*

James, I'm looking at the Azure stuff now for ML &amp; AI - I like your approach of using existing Python models and refactoring into c#, etc

*Tags: Strategies*

---

**James T** - *20:06:45*

I’ve been using Keras/Tensorflow in Python and saving models in .h5 format which can be converted to onnx models and loaded into [http://ML.Net|ML.Net](http://ML.Net|ML.Net) libraries to run predictions within C#, so actually no refactoring required. I haven’t looked into the Azure specific services though. 

*Tags: Strategies*

---

**Mo** - *20:18:49*

Yeah, we cover a lot of topics here. I’m sure we’ll be able to help out even if you stick with the Microsoft tech stack

*Tags: General Technical*

---

## 2020-04-14

**brightcake** - *17:08:12*

If any of you are looking for financial trading strategies this paper might be of help - [https://journals.sagepub.com/doi/pdf/10.1057/s41265-016-0034-2](https://journals.sagepub.com/doi/pdf/10.1057/s41265-016-0034-2)

*Tags: Strategies*

---

## 2020-04-17

**Amanda** - *16:26:04*

(Sharecast News) - Paddy Power Betfair owner Flutter Entertainment said revenue had been more resilient than expected despite the cancellation of many sports due to the coronavirus pandemic, bolstered by a continuation of US and Australian horse racing.

Total revenue rose 16% to ?547m for the three months to March 31. Racing in Ireland and the UK was suspended last month, leading to a 32% slump in revenue since the ban was imposed, Flutter said on Friday.



The company said last month it could take a hit of up to ?110m to earnings if sports fixing restrictions due to the coronavirus remain in place until the end of August. It generated about 78% of its revenues through bets placed on global sporting events.



Flutter last week said said its final dividend would be paid out in shares rather than cash as it sought to bolster its finances in the face of the pandemic. The company had planned to pay 133p a share.



Flutter has seen its share price slump by 25% as sports fixtures were cancelled and the government imposed a lockdown forcing the closure of non-essential shops.

*Tags: Errors Debugging*

---

## 2020-04-19

**Lee** - *17:51:14*

There was me wondering when you actually feel comfortable leaving an automated strategy. I’m only using small stakes and have a small amount in my account so not a big deal losing it.

I’ll think differently if i had a bigger account.

*Tags: Strategies*

---

**Dave** - *21:51:00*

[https://www.google.com/amp/s/www.bloomberg.com/amp/news/articles/2020-04-17/renaissance-says-quant-models-misfired-during-march-mayhem](https://www.google.com/amp/s/www.bloomberg.com/amp/news/articles/2020-04-17/renaissance-says-quant-models-misfired-during-march-mayhem)

*Tags: Strategies*

---

## 2020-04-20

**liam** - *06:03:33*

Interesting thanks for looking into it, the serialise function is the bottleneck in the streaming code anyway 

*Tags: General Technical*

---

## 2020-04-21

**mandelbot** - *13:38:19*

I think they do a lot of statistical arbitrage. They are pattern recognition mathematicians, so they were very early to the machine learning game in finance. A large portion of their trades they didn't know the reasoning, just their machine learning spewed it out. I imagine it finds all sorts of things, some things they understand, others they dont. From the book it seemed they weren't doing too well in crashes though.

*Tags: General Technical*

---

## 2020-04-22

**Newbie99** - *21:18:00*

I keep getting high latency warnings over night (they are genuine, I seem to have some weird processes running that I need to sort out), anyway, that aside, as a stopgap, a quick restart of the python script always seems to get things back on track. But is there a way I can look for a high latency warning and then automatically perform a restart somehow (well I presume I can work that bit out, its more a case of where do I need to be looking to determine programatically that I'm getting a high latency warning, then I can do something like pause for x seconds then restart)?

*Tags: Performance*

---

**Newbie99** - *21:46:32*

It basically occurs around 2am when some weird processes occur (nothing to do with BFLW), so I'm not too worried about my code, its just something else that I need to resolve, but as a stop gap, I find restarting the script once the process has stopped does the trick, so I just wanted to establish a high latency warning had occurred, then pause for x seconds until the process completes and then restart the script (for some reason once the warning appears the script never seems to recover)

*Tags: Performance*

---

**Jonatan (skyw)** - *23:11:48*

I would be kinda worried if the script does not recover when the issue goes away. One thing you could try is just ignoring processing the messages that are above a certain threshold and see if that helps.



For a really dumb and naive solution just put it in a while true loop in bash and exit the script when the process has stopped and the app restarts...

*Tags: General Technical*

---

**Jonatan (skyw)** - *23:32:55*

Yeah but it's ugly as hell :slightly_smiling_face:



Well it can be lots of different problem  with that description, just for curiosity, do you think some other process hogs all your available bandwidth or cpu?

*Tags: General Technical*

---

**Newbie99** - *23:36:41*

and somehow once the high latency warnings appear it just never seems to recover

*Tags: Performance*

---

## 2020-04-24

**Newbie99** - *08:10:09*

Just going back to the high latency warnings, I got some strange ones last night (which might just be a limitation of my machine, in which case so be it, but wanted to get the opinion of others):



`CRITICAL:streaming_errors:MarketStreaming run error`

`MemoryError`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "D:\Python37\lib\site-packages\betfairlightweight\resources\bettingresources.py", line 504, in __init__`

    `self.ex = RunnerBookEX(**ex) if ex else None`

  `File "D:\Python37\lib\site-packages\betfairlightweight\resources\bettingresources.py", line 377, in __init__`

    `self.available_to_lay = [PriceSize(**i) for i in availableToLay]`

`MemoryError`



`During handling of the above exception, another exception occurred:`



`Traceback (most recent call last):`

  `File "D:\Python37\webpages\streaming_errors.py", line 46, in run`

    `self.stream.start()`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 59, in start`

    `self._read_loop()`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 209, in _read_loop`

    `self._data(received_data)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\betfairstream.py", line 248, in _data`

    `if self.listener.on_data(received_data) is False:`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\listener.py", line 127, in on_data`

    `self._on_change_message(data, unique_id)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\listener.py", line 167, in _on_change_message`

    `self.stream.on_update(data)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\stream.py", line 59, in on_update`

    `self._process(data[self._lookup], publish_time)`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\stream.py", line 153, in _process`

    `self.unique_id, market_book, self._lightweight`

  `File "D:\Python37\lib\site-packages\betfairlightweight\streaming\cache.py", line 229, in create_resource`

  `File "D:\Python37\lib\site-packages\betfairlightweight\resources\bettingresources.py", line 585, in __init__`

    `self.runners = [RunnerBook(**i) for i in kwargs.get("runners")]`

`MemoryError`

*Tags: Errors Debugging, Performance, Strategies*

---

**Jonjonjon** - *09:48:14*

I had those errors a few weeks ago when my buggy code did not shutdown processes correctly.

*Tags: Errors Debugging*

---

**Unknown** - *10:11:20*

For your reference this is a flumine instance that has been up for 2 weeks recording 200-400 markets, memory is very flat. I have noticed that there might be a memory leak in the race_card.login() endpoint, are you using that?

*Tags: Performance*

---

**Jonatan (skyw)** - *10:34:20*

Not directly related to this but I think it would be nice to have some benchmarks of what the capabilities of bflw and flumine are. That could get people away from trying to implement distributed solutions when not necessary or other pre optimized paths.

*Tags: General Technical*

---

**liam** - *10:42:00*

Are you able to expand? bflw wont change, its always going to just be a wrapper for whatever is required to work with the api but is dynamic enough for a user to adapt/override methods if required.

flumine will be an equivalent framework with the ability to adapt, modify and build on top of, [@UBS7QANF3](@UBS7QANF3) may disagree but in my opinion distributed solutions aren't required for 99% of api users

*Tags: General Technical*

---

**Jonatan (skyw)** - *10:50:00*

I agree that for most the basic solution is more than sufficient.  Things that I think could be there are how fast can you process historical data, the rate of messages through market cache. the delay added.

*Tags: Data Quality*

---

## 2020-04-25

**Jonatan (skyw)** - *15:32:42*

Started to create benchmarks for the ones interested, might only be me though :joy:

[https://github.com/almenjonatan/benchmark/blob/master/betfairlightweight_benchmark.ipynb](https://github.com/almenjonatan/benchmark/blob/master/betfairlightweight_benchmark.ipynb)



Although I feel some of the numbers are on the low end. I might have ruined the library while patching it or something else.

*Tags: General Technical*

---

## 2020-04-27

**D C** - *11:18:33*

Morning all. Sorry to have to ask such a question irrelevant to botting/betting but desperate times call for desperate measures! Does anyone know anywhere currently recruiting C++ developers in the London or Cambridge areas????? Or at a push (former) mathematicians?

*Tags: Strategies*

---

**JazzMan** - *11:57:02*

Find a developer job first any langauge, could be C#, [http://VB.net|VB.net](http://VB.net|VB.net) or this Monty Python nonsense. Then learn the langauge. Developing software is the difficult part, the programming langauge is the easy part.

*Tags: General Technical*

---

**James T** - *12:01:47*

Hi DC, by coincidence I got an agent email looking for a C++ developer with low latency and or trading platform experience. Contract job, potentially long term though. DM me your email and I’ll forward to you. 

*Tags: Performance, Strategies*

---

## 2020-04-28

**Jonjonjon** - *09:13:35*

Random question, but does anyone use Tensorflow for sports betting purposes?

*Tags: Strategies*

---

**Mo** - *10:15:23*

Might take me a while, the Kelly criterion book is 850 pages...

*Tags: Strategies*

---

**Mo** - *18:31:47*

I think Shin's paper is immediately useful to almost every betting strategy. Here's my implementation: [https://github.com/mberk/shin](https://github.com/mberk/shin)

*Tags: Strategies*

---

**Jonatan (skyw)** - *19:24:49*

Very nice, will test it!



Thought about numpy implementation of it? it looks numpyish, (biased) :)

*Tags: General Technical*

---

**PeterLe** - *21:41:01*

In keeping with the above topic; This is an interesting article which draws comparisons between four methods (inc Shin)



[http://article.sciencepublishinggroup.com/pdf/10.11648.j.ajss.20170506.12.pdf](http://article.sciencepublishinggroup.com/pdf/10.11648.j.ajss.20170506.12.pdf)



Taken from : Stephen Clarke, Stephanie Kovalchik, Martin Ingram. Adjusting Bookmaker’s Odds to Allow for Overround. American Journal of Sports Science. Vol. 5, No. 6, 2017, pp. 45-49. doi: 10.11648/j.ajss.20170506.12

*Tags: Deployment*

---

**Mo** - *21:44:02*

No because I’m not a big numpy user but I’m definitely open it if other users would find it useful

*Tags: General Technical*

---

## 2020-04-29

**Mo** - *09:33:35*

I think of it like this: if you remove the overround by dividing by the booksum then you are assuming that bookmakers (or aggregate exchange participant behaviour) applies the overround for each selection proportionally to the odds. An alternative assumption is that Shin's theoretical framework is true and the odds arise from how bookmakers would set the odds to protect themselves from insider trading. Neither of these assumptions is going to be a perfect model of reality but you can judge them on their output - how accurate the inferred probabilities are.

*Tags: Strategies*

---

## 2020-05-01

**Mo** - *08:08:25*

I actually use IntelliJ which is JetBrains' Java IDE even though I mostly code in Python these days

*Tags: General Technical*

---

**PeterLe** - *09:13:38*

As a beginner I currently use pycharm community. Is it worth buying the professional version? I’m wondering whether it will help me learn quicker, and assist me greater or whether it’s overkill until I have more experience. Thanks 

*Tags: Getting Started*

---

**Jonjonjon** - *10:10:31*

[@UBS7QANF3](@UBS7QANF3) If it isn't secret info, what PC did you get? I am thinking of getting a new PC at some point this year. I'm wondering whether or not it's worth getting lots of cores if I'm going to be doing backtesting using Flumine.

*Tags: General Technical*

---

**Jonjonjon** - *10:26:55*

Nice. Thanks for sharing. Are you mainly going to be doing CPU (rather than GPU) intensive stuff? I currently have dual Xeon X575 chips in my setup. So they are almost 10 years old. I'm not sure how to work out how much faster a new setup will be. Having said that, I only managed to run historical data through Flumine last night, so it's early days to tell whether or not I need a crazy setup.

*Tags: Getting Started, Data Quality*

---

**Jonatan (skyw)** - *10:35:35*

[@UPMUFSGCR](@UPMUFSGCR) Are you running multiple instances of Flumine at the same time? if not I think that distributing it over multiple cores would help greatly.

*Tags: General Technical*

---

**Jonjonjon** - *10:40:45*

Last night, all I did was pump some historical data through the backtest example. It probably took over a minute just to loop over all the data in the file. Once I've worked out how to use it, I can test several different parameters/markets/strategies simultaneously using different cores. But as Mike Tyson says, everyone has a plan until they get punched in the mouth, so I don't want to buy new hardware until I really need it.

*Tags: Data Quality*

---

**Mo** - *10:40:56*

I don't use flumine but a lot of my data processing tasks are structured like this because they're embarrassingly parallel:



```with futures.ProcessPoolExecutor(max_workers=number_of_processes) as pool:

    all_futures = [

        pool.submit(

            backfill_market_catalogue,

            s3_key=record.key,

            betfair_market_id=record.betfair_market_id,

            get_market_catalogue_function=get_market_catalogue_function

        )

        for record in records

    ]

    for _ in tqdm([http://futures.as|futures.as](http://futures.as|futures.as)_completed(all_futures), total=len(all_futures)):

        pass```



*Tags: General Technical*

---

**Mo** - *18:11:46*

With the CPU? No, just stuff like [https://betfairlightweight.slack.com/archives/C4H05KKMY/p1588326056232000](https://betfairlightweight.slack.com/archives/C4H05KKMY/p1588326056232000)

*Tags: General Technical*

---

## 2020-05-02

**Jonjonjon** - *22:56:07*

Is anyone interested in, and is there any way, to benchmark and compare the performance of Flumine on our different machines? I've got a very old PC, and am just wondering how much faster a newer machine will be.

*Tags: Performance*

---

**Jonatan (skyw)** - *23:15:08*

[@UPMUFSGCR](@UPMUFSGCR) I created benchmarks for the bflw market cache above, that should give you an upper bound on how fast it can be.



I'm interested in performance in simulated execution.



If you want to benchmark just run the script using timeit I would say is the simplest.

*Tags: Performance*

---

**Lee** - *23:35:32*

The Ryzen CPUs cost/performance is tempting me to make the switch to linux.

*Tags: Performance*

---

## 2020-05-03

**liam** - *08:53:05*

With flumine the target is making a simple framework which is going to come at a cost of performance. 

However eventually we can add the ability to use lightweight mode and handle the raw json, this will rapidly speed up backtesting, not worth it for the 99% when live trading unless speed is a priority or you are processing lots of markets. 



Very keen on benchmarking, with my own framework it’s about a minute for each racing market or sub 10s when using lightweight mode. I use a variation of threads, processes and AWS lambda for overnight backtesting. 

*Tags: Performance, Deployment, Strategies*

---

**Lee** - *09:00:07*

I tried backtesting with flumine and pypy recently, went from 49 seconds down to 27 seconds.

*Tags: General Technical*

---

**Jonjonjon** - *20:46:27*

[@U92CASP1B](@U92CASP1B) I notice that you are using a data from Dec 2019 to do your benchmarking. Are you able to share that (without getting in trouble), so that I can test against the same file? If not, could we try to use a common file from the recent free historical data that Betfair has provided? For example, I am now running it against 29639024, an AU horse racing data from 1st April 2020. The pro data is free for April.

*Tags: Data Quality*

---

**Unknown** - *22:06:06*

Is there a problem with this bit of code?

*Tags: General Technical*

---

**Jonatan (skyw)** - *22:31:22*

[@UPMUFSGCR](@UPMUFSGCR),  Yeah, of course, could you send it to me? I do not have access to historical data from Sweden.

*Tags: Data Quality*

---

**Jonatan (skyw)** - *22:46:42*

Yeah I hardcoded the "seconds", did not bother to lookup how to get the stats into variables.



You have to do you own calculations  based on your time. and size of your data. I should fix that ...

*Tags: Errors Debugging*

---

**Unknown** - *23:07:46*

This is my exciting bedtime reading. I'm hoping it helps me write faster bots. If not it will help me pass stupid interview questions.

*Tags: General Technical*

---

## 2020-05-05

**Julio** - *09:04:55*

Hello all, sorry if this has already been asked before. Is there a way to filter the streaming of data on date/time? I can see in filter.py that there is a time_range object, but i cant see it as argument of streaming market filter. If not I'll request through the REST api and then pass the list i want to stream to the streaming engine.

I am trying to trade on the greyhound, but i only want to stream the one immediately coming. When i try all the markets the message latenty high get higher and higher.

*Tags: General Technical*

---

**liam** - *09:06:26*

No you can't, out of interest how many markets are you subscribed to? As you really shouldn't have latency issues with greyhounds as the data/updates are minimal

*Tags: Performance*

---

**liam** - *09:09:46*

do the latency logs increase or is it stable? It might be your clock as 70 markets is nothing

*Tags: Performance*

---

**Tobias Pankrath** - *09:15:29*

Yesterday I've got an illegal response in listMarketCatalogue, one without 'description.marketType'. Could not find anything about this on the offical forums. Do you have the same problem sometimes?

*Tags: General Technical*

---

**Mo** - *09:16:07*

Not that specific problem but sometimes expected fields are missing, yes

*Tags: General Technical*

---

## 2020-05-06

**AP** - *01:41:57*

Hi Mo, have the issues with Linux and Ryzen been solved?

*Tags: General Technical*

---

**Mo** - *08:17:03*

Haven’t had any problems like that. There’s a problem with sound on the TRX40 chipset which means my rear microphone jack doesn’t work nor my sound front panel but it sounds like it’ll be fixed in kernel 5.7 :crossed_fingers:

*Tags: Errors Debugging*

---

**liam** - *08:23:51*

Tasty commit in flumine which improves processing streaming data by 3 times (96s-&gt;28s) with minimal impact on usability, more info in the commit message :sunglasses: I feel more can be done here but wary of pre optimisation, note that initial logic for simulated matching added as well but not fully hooked up yet [https://github.com/liampauling/flumine/pull/156/commits/64ae76f0cb5571a040ce9904febf35df733931c4](https://github.com/liampauling/flumine/pull/156/commits/64ae76f0cb5571a040ce9904febf35df733931c4)

*Tags: General Technical*

---

**Mo** - *14:42:59*

[@U012NE8QN15](@U012NE8QN15) I'm interested because I'm trying to understand what it would take to sort out your problems and whether I (or anyone else) could do that

*Tags: General Technical*

---

**footysystems** - *14:44:42*

Thanks [@UBS7QANF3](@UBS7QANF3) the problem is getting an API that uses 365 stats without having to re code the site but even just a webpage with stats on would do the job I am quite willing to share everything on this chat tbh all the work I have done

*Tags: General Technical*

---

**footysystems** - *14:50:56*

The site own used to fix it but it's been out for 5 weeks and no sign of coming back no contact with owner or anything

*Tags: Errors Debugging*

---

**Fab** - *17:08:05*

Having said that, at the start of March they had major problems with their API for a few days, which prompted me to also implement the Betsapi API in my code.

*Tags: General Technical*

---

**Fab** - *17:12:24*

With regards to Betsapi, please bear in mind that it’s a completely different proposition to integrate their API in your software. With Totalcorner, you get all matches/stats in one API request, with Betsapi you need to hit each individual endpoint, which can be problematic with 200+ matches at the same time on Sat afternoons. You can use multithreading though, although it will never be as good as Totalcorner.

*Tags: General Technical*

---

**Fab** - *17:15:50*

There’s no flashplayer anymore, it’s all done by 365 streaming data from them directly to the browser.

*Tags: General Technical*

---

**Fab** - *17:19:01*

BTW I believe we spoke before on the Betangel forum, you helped me get a refund for a double payment on [http://Inplayking.com|Inplayking.com](http://Inplayking.com|Inplayking.com)’s predecessor

*Tags: General Technical*

---

## 2020-05-07

**footysystems** - *12:02:52*

That's interesting wonder why ? Not making any money I guess it's a very niche market surprised really but had the same problem with inplayking no or very little interest.

*Tags: General Technical*

---

## 2020-05-08

**MacrcoPolo** - *15:55:02*

It's not secret sauce - it's a well known approach to markets. The secret sauce would be in the implementation, as it's a fairly obvious idea for a strategy. Doing well at xmarket arb requires a lot of attention on the details. Essentially you have an execution problem - how do I get the positions I want?

*Tags: Strategies*

---

**Mo** - *16:01:08*

I think for a lot of newbies it is secret sauce. Most people seem to want to start by either building a machine learning model to predict horses and end using features everyone else is already incorporating or some kind of generic time series analysis model to predict price movements as if that’s not driven by fundamental factors. 

*Tags: Feature Engineering, Strategies*

---

## 2020-05-09

**Dave Simonds** - *14:18:41*

Thank you Mo…. I joined this group hoping for some helpful pointers like this… hopefully this will get me going in the right direction. Cheers

*Tags: General Technical*

---

## 2020-05-10

**Unknown** - *19:25:37*

The program is alsorts of inplay match data from total corners API I have created my own inplay rating ipk I have saved over 20k matches and found a sweet spot when a goal will come. This helps me trade the goals markets.

*Tags: General Technical*

---

## 2020-05-12

**Mo** - *20:56:53*

Doesn’t it use streaming? As in, you don’t need to rescan, new markets get picked up automatically given the filter?

*Tags: General Technical*

---

**liam** - *20:59:04*

Yeah it uses streaming, single containers handled by my own api/framework and then portainer when I want to manually check stuff 

*Tags: General Technical*

---

**Jonjonjon** - *23:28:27*

What's the difference between the E and M File Types from Betfair's Historical Data?

*Tags: Data Quality*

---

## 2020-05-13

**Tom** - *04:06:26*

Is anyone on this forum good at scraping data delivered through websockets? There's a stocks app I use that delivers data within a section of their page through this protool. I have scraped every visible node onsite but can't get the websocket part which is delivered through websocket. Using the pythons libs suchs as Scrapy/splash/lua, BS4 and requests-html... Seems the libs don't have the ability. Slightly worried if datasources start to adopt this approach of websocket delivery. Current scraping frameworks are miles behind in terms of documentation for websocket scraping solutions.

*Tags: Deployment*

---

**Lee** - *15:18:21*

Not sure how to phrase the question better but hopefully it makes a bit of sense

*Tags: General Technical*

---

**Lee** - *15:20:22*

So a profitable strategy eventually loses it's edge over time and needs optimizations

*Tags: Performance, Strategies*

---

**Unknown** - *15:34:24*

I think it can depend on what the strategy is doing and it works both ways, here is something I haven't touched since I created it (very simple)

*Tags: Strategies*

---

## 2020-05-14

**Mo** - *12:51:47*

Generally if a game will run under proton then performance will be as good if not better than under windows. Use [http://protondb.com|protondb.com](http://protondb.com|protondb.com) to check compatibility of your games. 

*Tags: Performance*

---

**Lee** - *17:46:23*

I can't seem to find any documentation for it

*Tags: General Technical*

---

## 2020-05-18

**Remi** - *12:10:16*

I wonder if you could build any kind of edge in this market if it were traded. An edge could exist because the host may influence outcomes to create interesting matches or developments in the sport. Or maybe marble surface/density affects performance.

*Tags: Performance*

---

**PeterLe** - *21:35:16*

Evening Folks,

I mentioned on this channel a few weeks ago that a new book was due out called Flash Crash by Liam Vaughan. It tells the story of Navinder Singh Sarao, a UK based day trader who traded the stock market from a standing start (from his bedroom) to amass a fortune of ~£70m!..and then supposedly loose it...

Enjoyed reading it, although a large proportion of the book is centred on the regulatory side of things.

Some soundbites I took: 



- Nav was sell taught

- His strategy was a simple scalping technique, by placing orders out of the money (on what we class as the back side), to skew the weight of money to give the appearance that sellers were in the market. Ie to push the price down. Tactics that are used on Betfair every day (probably by a few of us on here :-)

- He ended up using a standard platform “Trading Technologies” (TT) and had some additional features programmed in by a software engineer at TT. He subsequently had a guy from Edge Technologies to further enhance those features and add a couple more (to take on the HFT’s)

- He wasn’t 100% on auto. Rather, he traded manually with these extra “weapons” as he describes it

- He didn’t write any of his own code

- At his peak he was making upto £900K/Day

- He never spent anything! (Think he treated himself to a new bike and the odd McDonalds:-)

- He attributed his success to his pattern recognition and fast reactions, the numbers dont lie, so can you doubt it?



If anything I think the book tried to paint a picture of his character, that I didn’t quite like. A bit of a dis service to him IMO. He is obviously a clever guy and its not always possible to determine intelligence or judge someone on how they come across that is perhaps different to the norm.

I dont think this will lend itself to a film/movie (Unlike The Big Short), However, it does make a good story and especially to us on here as a glimpse of the art of the possible!!

*Tags: Feature Engineering, Strategies*

---

## 2020-05-21

**Newbie99** - *12:36:56*

I have a couple of questions on SP bets (by which I mean bets with a persistence of 'MARKET_ON_CLOSE'), around how Betfair view the £10 minimum liability:



1. If have a lay bet that is partially matched, so say £9.90 gets matched initially (i.e. in live pre-market trading, before the SP is reconciled), is the expected behaviour that this additional 10p gets matched or cancelled?

*Tags: Deployment, Strategies*

---

## 2020-05-22

**Mo** - *19:48:34*

Some thoughts (spoilers ahead):



1) I found the story about taking advantage of the rogue trader very interesting from two angles: 1) considering whether there are malfunctioning algos on Betfair to exploit and 2) the idea that being lucky to be presented with an easy money making opportunity provided him with a bankroll that he could use to bootstrap his success. I wonder how differently things may have turned out if he hadn’t been in the right place at the right time to take advantage

2) As I said, I don’t think he deserves prison time in the US for what he did but I feel even worse for the developer being charged. I think that is a very dangerous precedent that if you write software that could be misused then you’re liable

3) I’m pretty sure I did some work on the Iconic Worldwide Gaming platform. I had no idea of the connection until the product was described - betting on financial price movements using a casino style interface

4) I loled at the description of him drinking coffee with a tea spoon

*Tags: Strategies*

---

## 2020-06-01

**Lee** - *07:58:24*

i am, i got the all product pack but was a lot cheaper when i did it so i'm stuck on a lower pricing model (not as low as i first thought, was looking at organisation pricing)

*Tags: Strategies*

---

**Lee** - *07:59:31*

i never really realise what extra features you get until you try to help someone using community edition

*Tags: Feature Engineering*

---

**Mo** - *08:26:39*

My situation is that I actually use IntelliJ because historically I worked on some Java projects so that was my IDE when I got into Python and I just used the Python plugin



I'm thinking of buying a license because of SQL and Jupyter Notebook support (and because I've used it pretty much every day for 4 or 5 years)



But I'm not sure whether to:



1. Buy a license for PyCharm - it's cheaper than IntelliJ, I'm much more Python focused than when I started using IntelliJ and if I need to work on Java projects in the future I can use IntelliJ CE just for that

2. Buy a license for IntelliJ - from what I understand, with the Python plugin the functionality is equivalent to PyCharm Ultimate

3. Buy the all products pack - I didn't know this existed; on the one hand this doesn't seem necessary because of the official language plugins for IntelliJ but on the other hand I have an interest in e.g. CLion because I do occasional C development and that's an example of a language where there isn't a plugin for IntelliJ

*Tags: General Technical*

---

**Troy Edwards** - *09:37:24*

This sounds right SrFabio

1. I place a high odds (or low odds) bet 

2. I then reduce this size calling the CancelBetfairOrder. In Australia min is $5 bet so I can cancel $4 of it to place a $1 bet

3. Then I change the odds such that the bet is matched using RepaceBetfairOrder

I have been doing this for a while (2 months - 200 bets a day) and have not got in trouble as [@UBS7QANF3](@UBS7QANF3) mentioned.  Maybe its ok in Oz :wink:



    '##################################################################################################

    '### PLACE LOW VALUE BETFAIR ORDER - IF SUCCESSFUL RETURNS BET ID                               ###

    '###    IF BET IS UNDER $5 LETS SAY $1                                                          ###

    '###        WE NEED TO SEND AN UNMATCHED LAY BET AT ODDS 1.01 FOR $5                            ###

    '###        WE THEN CALL CANCEL-ORDER AND REDUCE THIS LAY BET TO $1                             ###

    '###        WE THEN CALL REPLACE ORDER WITH OUR ORIGINAL ODDS                                   ###

    '##################################################################################################

    Public Function PlaceLowBetSizeBetfairOrder(sMarketID As String, sSelectionID As String, dBetOdds As Double, dBetSize As Double, BetSide As Side, BetPersistence As PersistenceType, Optional customerStrategyRef As String = Nothing) As ReplaceExecutionReport

        PlaceLowBetSizeBetfairOrder = Nothing

        Try

            Dim BetfairMinBet As Integer = 5

            Dim placeBet As PlaceExecutionReport = Nothing

            Select Case BetSide

                Case Side.BACK

                    'PLACE $5 BET AT HIGH ODDS WHICH WE BE UNMATCHED, SO $5 @ 1.01

                    placeBet = PlaceBetfairOrder(sMarketID, sSelectionID, "500", BetfairMinBet, BetSide, BetPersistence, customerStrategyRef)



                Case Side.LAY

                    'PLACE $5 BET AT LOW ODDS WHICH SO THAT IT WILL BE UNMATCHED, SO $5 @ 1.01

                    placeBet = PlaceBetfairOrder(sMarketID, sSelectionID, "1.01", BetfairMinBet, BetSide, BetPersistence, customerStrategyRef)

            End Select



            If placeBet.Status = ExecutionReportStatus.SUCCESS Then

                'NOW REDUCE THE BET FROM $5 @ 500 TO &lt;dBetSize&gt; @ 500 - THIS WILL KEEP THE SAME BET ID

                Dim myReduceSizeBet As CancelExecutionReport = THREAD_CancelBetfairOrder(sMarketID, placeBet.InstructionReports(0).BetId, BetfairMinBet - dBetSize)



                If myReduceSizeBet.Status = ExecutionReportStatus.SUCCESS Then

                    'NOW INCREASE THE ODDS BACK TO WHAT WAS ORIGINALLY REQUESTED SO &lt;dPriceOdds&gt; @ 500 TO &lt;dBetSize&gt; @ &lt;dPriceOdds&gt;



                    'NOTE WE WILL NOW GET A NEW BET ID AS WE ARE CHANGING THE QUEUE POSITION

                    Dim myReplaceBet As ReplaceExecutionReport = THREAD_ReplaceBetfairOrderChangeOdds(sMarketID, myReduceSizeBet.InstructionReports(0).Instruction.BetId, Math.Round(dBetOdds, 2))

                    PlaceLowBetSizeBetfairOrder = myReplaceBet

                End If

            End If



        Catch ex As System.Exception

            Debug.Print("PlaceLowBetSizeBetfairOrder " &amp; ex.Message)

            THREAD_BF.InUse = False

        End Try

    End Function

*Tags: Errors Debugging, Strategies*

---

**SrFabio** - *09:50:45*

Hey guys, has anyone implemented an hedging algorithm that works well when all selections of a market have orders? The algorithm I'm using basically hedges each traded selection but I'm having a problem where some of the orders won't get matched as the market moves on the opposite direction, which completely obliterates the hedge itself

*Tags: General Technical*

---

**Stefan** - *10:26:39*

VS Code is really lightweight IDE, actually it is javascript app hosted in electron, therefor you can find web version of it on cloud services, like:



[https://visualstudio.microsoft.com/services/visual-studio-codespaces/](https://visualstudio.microsoft.com/services/visual-studio-codespaces/)



and so on.



I cannot afford to buy professional version of visual studio, so I use community one, and of course VS Code which supports all kinds of languages, and I experimented with python, R, julia, my favorite F# and so on. Just open VS Code Extensions and type whatever programming language you know and you will find there some extension. Python extension has 20.6 millions of installs, so seems to be quite popular.

*Tags: Getting Started*

---

**JonJonJon** - *11:14:22*

Regarding your hedging question, I often end up with positions where my risk per runner is often unbalanced. I haven't found a way to hedge perfectly. I just accept it as additional variance. Sometimes, when placing limit orders, I might set the price to be a few ticks into the depth. This means that I might get a worse price, but means that I'm more likely to end up getting matched.

*Tags: General Technical*

---

**SrFabio** - *11:26:00*

Can't find documentation on this, that would be perfect really...but I'm not sure if it's doable on the context of a mobile app to be distributed freely to users

*Tags: General Technical*

---

**SrFabio** - *11:29:17*

the big problem is that this type of operation is incredibly hard to test with delay API key, and can be costly to test with live key

*Tags: Deployment*

---

**liam** - *12:02:19*

Thats my problem, I am so used to pycharm but I have forced myself to use vscode more as I do a lot of react/javascript work where pycharm is crap

*Tags: General Technical*

---

**Jonatan (skyw)** - *12:11:09*

[@UBS7QANF3](@UBS7QANF3) I've used vs code for python, I did not like the experience. For me everything is just not as good.

• Visuals, easier to navigate project explorer, notice errors in code

• Easier to refactor code

• Less buggy, Microsoft Language  Server just felt buggy and slow overall

• A lot better auto imports

*Tags: Errors Debugging, Performance, Deployment*

---

**Lee** - *12:14:41*

haha yeah, when helping colleagues that use vs code the project explorer i'm literally lost, exactly the same as you. No idea where i am in the project

*Tags: General Technical*

---

## 2020-06-02

**JonJonJon** - *16:48:03*

How much does it cost to run an instance of AWS per month, running a bflw horse trading bot 24x7?

*Tags: Deployment, Strategies*

---

**jfo** - *16:49:19*

AWS lightsail isn’t cheap, might even be cheaper than that now

*Tags: Deployment*

---

**PeterLe** - *16:52:17*

If you havent used AWS before there is a free tier available that should run BFLW

*Tags: Deployment*

---

**brightcake** - *16:54:21*

if you're looking at ec2 you could probably do it with a micro machine

*Tags: Deployment*

---

**Mo** - *16:58:22*

Roughly speaking if you’re running it 24/7 it’ll be cheaper to get a dedicated server. But AWS gives discounts for paying for eg 12 months in advance which makes the price about the same

*Tags: Deployment*

---

**liam** - *17:20:43*

[@UBS7QANF3](@UBS7QANF3) not sure if I have asked you this before but are you 100% AWS?

*Tags: Deployment*

---

**James McKenzie** - *21:41:24*

Is that £20pm including your database costs?

*Tags: General Technical*

---

**PeterLe** - *23:04:08*

I appreciate that all traffic is routed before arriving at betfair, but Just wondered if anyone had a view on which service had the fastest connection overall. I did some simple tests and found that my home PC was as fast as AWS.

*Tags: Deployment*

---

**Dave** - *23:15:11*

Yes forgot to mention I run a mysql server on it too. It's 20 USD (DO charge USD so it happens to be under £20). I could probably do with just a dual core machine (rather than quad) which is 10 USD I think, but needed the extra RAM that comes with the quad core to train various models.

*Tags: Deployment, Strategies*

---

**Dave** - *23:20:45*

If useful, ping roundtrip is 18ms from the London DO datacentre. I think Mo mentioned the path is asymmetric though, I've never really tried to measure the outbound latency.

*Tags: Performance*

---

**PeterLe** - *23:25:23*

About the same on AWS. I tested by running the same program (and bet criteria) on two of my accounts. One on AWS, one on my home PC.  I then compared the Betids from each account at the end of the day. There was literally nothing in it.

*Tags: Deployment*

---

## 2020-06-03

**JonM** - *11:09:31*

I use Lightsail - as far as I can tell it's just a lighter weight skin on AWS.  Simpler website/interface etc.  I'm only using a single VM and MySQL instance, so it suits me.  If you had a more complex infrastructure the limited functionality would get pretty annoying pretty quickly.

*Tags: Deployment*

---

**SrFabio** - *15:12:02*

I'm yet to run some more tests on the scenario I mentioned, which is basically:

1. Back under 2.5 

2. Back over 2.5 (after this bet we have a green on each selection, just not even)

3. Hedging bet - &gt; At the moment my cashout mechanism is trying to hedge each selection, so this means two bets to hedge the market, but I think this can be optimised to a single bet (on the selection with the highest profit). My problem with a bet on each selection is that the bet going to the "worst" selection (i.e, odds moving quick on opposite direction) is unlikely to get matched, and if only one of the bets gets matched it means the market won't be on a "all green" situation anymore

*Tags: General Technical*

---

## 2020-06-04

**Mo** - *11:52:45*

Someone recommended this site to me: [https://www.betconnect.com/](https://www.betconnect.com/). Seems like an interesting new take on the exchange model. Anyone used it?

*Tags: Strategies*

---

**James T** - *13:14:55*

Seems like a pretty unique and refreshing idea actually. Essentially it’s letting (or aiming to let) professionals back at bookie odds, and aiming to get punters to lay those odds, but with the hope that there are enough matched bettors who will hedge that lay by backing at the bookies with equivalent odds (which the pros couldn’t do themselves because they’re already limited). 



Now the question is whether there is enough lay money from punters, but also whether pros can still win backing at bookie odds but also paying a commission. 



Also I’m not sure what’s stopping a pro from signing up as a punter to lay bets at 0% comm instead. Alternatively as a punter you’d just follow the best pros backs by copying at the bookies and forget laying on Betconnect. (I guess you’d get limited like the pro eventually)



Disclaimer: I haven’t read all the FAQs yet. That’s just my initial take. 



What’s your take on it [@UBS7QANF3](@UBS7QANF3) ?

*Tags: General Technical*

---

**JonJonJon** - *15:46:17*

I can't see an API for Betconnect, so it probably isn't a worthwhile use of time, when bflw can place thousands of bets for us every day

*Tags: General Technical*

---

## 2020-06-06

**Sandy Caskie** - *11:40:26*

When placing a starting price bet I place my order by specifying the liability, this as done as such:

``` string = '{"jsonrpc": "2.0", "method": "SportsAPING/v1.0/placeOrders", "params": {"marketId":"' + marketId + '","instructions":[{"selectionId":"' + j + '","handicap":"0","side":"'+ z + '","orderType":"MARKET_ON_CLOSE","marketOnCloseOrder":{"liability":"' + i + '","persistenceType":"LAPSE"}}],"customerRef":"' + ref + '"},"id": 1}'



               ```

Using pandas in python j, z and ref are stored separately and are passed to the above code. Is it possible to specify the size instead of the liability? I checked the documentation and it only shows examples where liability is specified. I would just place an order myself but I have removed all my funds from my account as testing some stuff therefore if any of you could help without me having to potentially throw money away that would be great. Cheers.

*Tags: Feature Engineering*

---

**liam** - *11:50:30*

For back bets the liability is technically the size but for lays you can only select the liability. This is to prevent you setting a size of x and the BSP being calculated at 1000 or similar (due to error / slow start from the suspend guy) you would therefore have a massive exposure (something betfair couldn’t calculate before BSP is reconciled)

*Tags: Errors Debugging, Performance*

---

**liam** - *11:50:46*

How come you are not using bflw anyway :pensive:

*Tags: General Technical*

---

**liam** - *11:51:47*

:grin:this problem was solved in 2016 

*Tags: General Technical*

---

**Mo** - *12:29:29*

It's jarring to see that code here because anyone who uses bflw wouldn't do that:



1. Why hard code some of these things? What if you want to place a LIMIT_ORDER? What if you don't want to use a customerRef?

2. It's unecessarily verbose, how many places in your code base do you have "jsonrpc": "2.0"?

3. JSON has a well defined key:value format so why are you generating the string yourself from data? Just use json.dumps on a dict

Obviously bflw solves all of that for you.



I'm just explaining why I think it's gross. I think legacy constraints are an understandable reason for you to do it that way and I totally understand that it would have been a valuable learning experience. I'm someone who has written multiple trading platforms and Betfair wrappers over his career so I too came to bflw with my own codebase and I'd wholeheartedly recommend you make the switch. Don't waste your time developing/maintaining your own Betfair API implementation. Reserve that time for developing actual strategies.

*Tags: Strategies*

---

**Sandy Caskie** - *13:07:28*

Ye fair points.



1. This is hardcoded as I want to implement the strategy in a rigid way. Also do you not always need a unique customer ref if you place a certain number of orders over a specific period? I remember something along those lines when developing this.

2. JSON is specified once as it is passed directly to make an order.

3. Ye that is the format though when I was developing it I specified this way and don't see why I should change it as I am implementing my code in with these inputs every time the code is executed with variability around z and i.

This all said the next project I will be using bflw.



Why is f-strings better, I've always used + operator never really thought why should change that though I am more than happy to if it is much better. Though how much benefit can you gain from concatenate strings differently in the whole scheme of things.



I also thought to place this question in random as it not directly related to bflw.



Thanks for your comments and assistance :slightly_smiling_face:

*Tags: Strategies*

---

**Sandy Caskie** - *13:09:47*

Also, can you get near price and far on bflw?

*Tags: General Technical*

---

**Mo** - *13:15:10*

If you had just said it’s for legacy reasons and you’ll use bflw in your next project I’d have said fair enough and left it and that :joy:

*Tags: General Technical*

---

**Jonatan (skyw)** - *14:49:13*

Ill add to this slow saturday discussion, I do not think point 3 is the real benefit, the real benefit comes from readability and that it makes it easier to type check arguments as well doing validation.



Something that bflw actually missing a.t.m. : )

*Tags: Performance*

---

**Jonatan (skyw)** - *16:11:22*

yeah : ) this is what I was thinking about, [https://www.python.org/dev/peps/pep-0561/](https://www.python.org/dev/peps/pep-0561/).

*Tags: General Technical*

---

**liam** - *16:16:34*

Bflw already has type hints using annotations, do you mean for the responses? 

*Tags: General Technical*

---

**Jonatan (skyw)** - *16:18:09*

If I install bflw, and then run mypy on my code which depends on bflw I will get an error that missing stubs or something like that.

*Tags: Getting Started, Errors Debugging*

---

## 2020-06-07

**Newbie99** - *11:38:29*

Is there a simple way to retrospectively check if a market_id is was for a WIN or PLACE market (essentially I've processed a load of data, I recorded with flumine...all good, expect I stupidly didn't include a market_type column). Rather than process every market again, I just wondered if there's a quick way to tell (for UK/US I can probably get the racecard info, but for AU markets I haven't come up with a plan yet)?

*Tags: General Technical*

---

**John Sheppard** - *11:50:54*

dang, i thought I could be helpful for once...maybe next time :slightly_smiling_face:

*Tags: General Technical*

---

**Unknown** - *20:24:59*

That approach worked Mo...however slightly embarrassingly I appear to have deleted a huge chunk of raw data (I have the data itself in my DB, but not the flumine extract, so I can't reprocess these markets). I don't suppose anyone happens to have market_type for the attached (the file says horses, but it does include greyhound markets too).

*Tags: General Technical*

---

## 2020-06-10

**liam** - *20:34:38*

I think it’s the simulated.size_matched that sits under, but then you fixed that, have you profiled / if so can you share the breakdown?

*Tags: Errors Debugging*

---

**JonJonJon** - *20:51:58*

I don't think it's the bit I fixed. This comes after. I think it's because it gets called so many times.



My profiler is not providing any details worth sharing.



As a baseline, after my prior changes, it takes 32s for the backtest, cumtime 4.5s for size_matched.



If I change the code to the below, then it becomes 28 seconds for the backtest, cumtime 1.1s for size_matched ( I know the numbers don't quite add up, but I'm also using my PC to play some music off youtube which might affect things)

```@property

def size_matched(self) -&gt; float:

    return self.simulated.size_matched or 0.0```

So it could be because the original size_matched calls current_order, which has the "if" statement to return self.simulated:



```    @property

    def current_order(self) -&gt; Union[CurrentOrder, Simulated]:

        if self.simulated:

            return self.simulated

        elif self.responses.current_order:

            return self.responses.current_order

        elif self.responses.place_response:

            return self.responses.place_response```

Perhaps the use of the @property is slow?



But the repeated test of "if self.simulated" is unnecessary, especially when it essentially comes down to a test of whether or not config.simulated is True or False.

*Tags: Errors Debugging, Performance*

---

**liam** - *21:01:48*

Yes that bit is unnecessary once initialised but only for backtesting, a question of reducing readability for performance 

*Tags: Performance*

---

**JonJonJon** - *23:16:16*

Did the RAM work OK when you built your PC? I see some forum posts saying it Corsair Vengeance RAM had issues with Ryzen chips in April 2019. But I'm hoping that problem has gone away, as the company I want to build a PC for me only seems to stock that.

*Tags: General Technical*

---

## 2020-06-11

**liam** - *06:34:17*

Are you able to share an example strategy which exhibits similar times? Interested to know how many times it’s being called and if we can reduce that instead.



Considering this is just a lookup I am very surprised it’s taking that much time :thinking_face:

*Tags: Strategies*

---

**Mo** - *07:42:11*

Yeah the RAM is fine. The only problem I had was that the BIOS defaulted to much lower clock speed and timings than it was rated for. I only discovered this when I started to dig into my Monero mining hashrate :wink:

*Tags: Performance*

---

**JonJonJon** - *20:50:18*

Hi Liam. This probably isn't a very realistic example, but it illustrates the problem:



[https://github.com/liampauling/flumine/compare/master...jsphon:size_matched_example?expand=1](https://github.com/liampauling/flumine/compare/master...jsphon:size_matched_example?expand=1)

*Tags: General Technical*

---

**JonJonJon** - *21:46:27*

When setting items in blotter, such as here, we use order.id to index it:

```def place_order(self, order, execute: bool = True) -&gt; None:

    order.place(self.market_book.publish_time)

    if order.id not in self.blotter:

        self.blotter[order.id] = order

        self.flumine.log_control(events.TradeEvent(order.trade))  # todo dupes?```

But in the set item code, it is called customer_order_ref



```def __setitem__(self, customer_order_ref: str, order) -&gt; None:

    self._orders[customer_order_ref] = order



def __getitem__(self, customer_order_ref: str):

    return self._orders[customer_order_ref]```

Could we rename that customer_order_ref to id (or id_ or _id, seeing as id is a builtin function)? It will save confusion.

*Tags: General Technical*

---

## 2020-06-12

**liam** - *09:06:28*

yeah haven't tacked that yet... [@U92CASP1B](@U92CASP1B) it does a check on the status but without offloading any complete not really a way around it, I see more than 1k orders in a market to be an edge case / you are always going to have problems in backtesting

*Tags: General Technical*

---

**Mo** - *09:10:26*

Not sure how comfortable you are with C but I'm happy to help out with that

*Tags: General Technical*

---

**liam** - *12:37:33*

my question will be 'how do you get your fast pics'

*Tags: General Technical*

---

**Mo** - *16:58:43*

I've been working with some larger data frames that are approximately ~5 GB when written to CSV. Pandas takes ages to write them to CSV but seconds to write them to h5 format. But then you lose the ease of readabiltiy e.g. being about to use `head`, `less`, `cat` and other UNIX command line tools. Was wondering if anyone else has experience of dealing with this

*Tags: Feature Engineering*

---

**Dave** - *17:04:23*

One possible solution might be to write a CSV in memory and compress it (gzip) prior to writing to disc (and you can use `zcat` to access the data via the terminal). I think numpy even has a function that can save the array directly as a zipped file but not sure if it transforms it to some prop format before zipping it (rather than -&gt; CSV &gt; zip).

*Tags: Performance*

---

**Dave** - *17:26:33*

Yeah unfortunately I don't think a "hdf5cat" exists, probably because you typically store multiple arrays of n dimensions (rather than a 2D CSV). Might be worth whipping up a quick utility in python for your use case. :white_frowning_face:

*Tags: General Technical*

---

**James T** - *17:32:56*

In a way, us replying to threads on a “strategy” channel is effectively “training” competitors. I’m sure there’s info on there people would have paid for. We choose not to charge for it, but I don’t think whether we do or don’t reflects on whether we are really profitable or not. Maybe we’re just more generous? :stuck_out_tongue_winking_eye: But again, maybe he does have a legitimate reason. 



Anyway, I stay open minded about what people can do in sports betting. I wouldn’t have believed myself if I told myself 10 years ago what I’d be able to do now. 

*Tags: Strategies*

---

**D** - *17:44:26*

Have you considered parquet format? I went from zipped csv to parquet - compressed but can be saved loaded directly from Pandas.

*Tags: Feature Engineering*

---

**MacrcoPolo** - *19:25:28*

I've moved from hdf5 to parquet in other parts of my life as it's more modern and implicitly reads files using multiple cores, so the reads are nice and quick in an age where loading data is often cpu bound on the decompression +conversion to pandas obj end

*Tags: Feature Engineering*

---

**Mo** - *19:56:46*

Thanks for the input guys. I agree, I don’t think there’s much to like about HDF5 aside from the fact pandas seems to output it incredibly quickly. I’ll check out parquet although probably I will just stick to compressed CSV

*Tags: Feature Engineering*

---

**JonJonJon** - *20:06:21*

I've been experimenting with tracking completed trades in my personal strategy code, and therefore being able to quickly find executable trades.

*Tags: Strategies*

---

**JonJonJon** - *20:15:27*

Perhaps if there was a way to stop the code iterating over all orders on every market book update, that would help a lot

*Tags: General Technical*

---

**JonJonJon** - *20:21:53*

It's related to how Python works. Under the hood, doing a set difference is probably doing some C-level fast code.



If we do something like [x for x in blotter where x.status=='EXECUTABLE'], it has to go through slow Python code every time it looks at x.status.

*Tags: Performance*

---

**JonJonJon** - *21:10:37*

Hi Liam, I don't know whether or not I'm identifying complete orders correctly, but what do you think of this?



[https://github.com/jsphon/flumine/commit/7606619a01f2b677547c3f4e36c7bb63acb611df](https://github.com/jsphon/flumine/commit/7606619a01f2b677547c3f4e36c7bb63acb611df)

*Tags: General Technical*

---

**James T** - *21:38:54*

I agree with everything you say and at the same time I’m sort of consciously hypocritical about it. 



I think I’m slightly biased though, because I fall into that small category of people who have been successful having been inspired by other people, whether they were/are real or not. If I weren’t inspired them I don’t think I’d have got into sports betting and won as much as I have. 



I also personally feel that what I/we do as winning professionals is a bit of a grey area in itself. We essentially win money from people stupid enough to bet against us. Perhaps they gain some entertainment value, but essentially they are sold the idea of winning, but they won’t in the long run. At the same time I continue to do it for a living. So even though I feel that I want to cast judgement on others doing possibly questionable things like selling courses, I personally don’t feel like I’m in a position to do so. 

*Tags: Strategies*

---

## 2020-06-13

**mandelbot** - *07:42:57*

is the AWS free tier only available in us regions? No option to choose UK it seems.

*Tags: Deployment*

---

**liam** - *08:32:30*

I use 1c but that is just because what I started with and have never bothered to move, I think London is more expensive but some have said the latency is now better but I would worry to start off with 

*Tags: Performance*

---

## 2020-06-14

**Michael** - *17:25:24*

I completely share your ambivalence about the whole thing and yes I can see that I'm in a weak position to throw stones. Some of the people I met at BF events (VIPs) really haunt me - they obviously have a huge problem and they're being exploited by a system that I'm part of. On the other hand we all have freedom of choice and I don't think they would be losing any less money if I wasn't playing, it would just go to BF instead of to me. I remain troubled by it, but evidently not enough to stop.

*Tags: General Technical*

---

**Michael** - *17:43:10*

The nearest I've come to resolving the dilemma is to speak plainly about it to people who ask, tell them the truth and avoid euphemisms like all the _'investment'_ terminology, you know: _'trading'_ all of that. We know that the great majority of those who try this game will fail and that includes people reading these groups. I'd like them to fail as gently as possible and not to get sucked in to a world of self delusion.  I worry that it might be easier for people to be blind to a gambling problem if the stuff that surrounds it looks less like the stereotype image of a gambler. Graphs, machine learning, code - all sensible stuff for clever people, it can blind you to the reality that you're wasting your money and your time.

*Tags: Strategies*

---

## 2020-06-15

**mandelbot** - *09:10:56*

Does anyone know of a database of horse name changes?

*Tags: General Technical*

---

**D** - *09:41:56*

Just for info, the AWS availability zones a,b,c are assigned randomly to each account, I.e. your zone 1a could be somebody else’s 1c. This is to stop everyone piling into the same zone. 

*Tags: Deployment*

---

**D** - *09:50:51*

[https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html|https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html|https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html)

Glad I could contribute something!

*Tags: Deployment*

---

**Chris** - *14:25:11*

A naive question as I'm only really dipping in and out of using bflw when needed, and not really a developer, but I've got a setup where I'm basically only ever grabbing prices from BFEX, and storing/comparing them with input i am providing from scraping other sites or manually, right now I generate a list of markets, and store the current available back/lay price, I'm only ever really interested in that price, currently that runs over a series of (now fairly slow) loops for the events and markets i'm interested in, I'd like to be able to expand that list of markets/events but this then makes some of the data at the beginning of my loops quite old by the time it's gone through the rest of the markets i'm interested and stored those (in a MySQL database), I think the right answer is to use Flumine, but I just wanted to see if anyone else does similar and how they handle it, in terms of getting the data back out for "current price", as I'd always been storing it in a db that was easy but i'm not sure if it's feasible with the rate that the data comes into flumine whether to then store that in a db to be able to use with my comparisons, hope that makes sense

*Tags: Getting Started, Performance*

---

**liam** - *14:26:06*

Use streaming, ignore the queue and instead [https://liampauling.github.io/betfair/streaming/#snap|snap](https://liampauling.github.io/betfair/streaming/#snap|snap) the listener when you want a price, super quick and super lightweight

*Tags: General Technical*

---

**Chris** - *14:38:49*

Thanks [@U4H19D1D2](@U4H19D1D2) just looking at that now, so I'd still need to store the list of markets and all the associated metadata that I'm streaming somewhere in my database, and then just grab them directly from the stream, how does that actually work in practice though, do i have it sitting as a daemon and can query that, or just run it essentially ad-hoc when i want to update the prices as I pretty much do now with bflw but in a big loop

*Tags: General Technical*

---

**liam** - *14:42:43*

it would be a daemon similar to this [https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|example](https://github.com/liampauling/betfair/blob/master/examples/examplestreamingerrhandling.py|example) but set the queue to None as you don't need it (leaving it would cause a memory leak in your use case as it would fill)

*Tags: Performance*

---

**Chris** - *14:48:00*

Ok, I think I understand, so the logic of running that and then connecting to it from another script is built into bflw? And I think I've seen mentioned before that there's a limit to the number of markets you can have streaming in a single stream? For instance I'd quite happily just have every football match and market for the next 7 days but I guess that isn't realistic

*Tags: General Technical*

---

**Chris** - *14:54:50*

Thanks for your help, I'll give it a go

*Tags: General Technical*

---

**Aaron** - *15:02:50*

Hi guys, new here, just saying hi. Great gratitude to liam and whoever has contributed to betfairlightweight, working my way through the github reading now!

*Tags: General Technical*

---

**JonJonJon** - *19:41:22*

Does anyone know whether an Intel 10900k CPU would be better than the Ryzen 3900x for running Python/Flumine with multiprocessing?



Ryzen 3900x has a much better passmark score:

[https://www.cpubenchmark.net/cpu.php?cpu=Intel+Core+i9-10900K+%40+3.70GHz&amp;id=3730](https://www.cpubenchmark.net/cpu.php?cpu=Intel+Core+i9-10900K+%40+3.70GHz&amp;id=3730)



[https://www.cpubenchmark.net/cpu.php?cpu=AMD+Ryzen+9+3900X&amp;id=3493](https://www.cpubenchmark.net/cpu.php?cpu=AMD+Ryzen+9+3900X&amp;id=3493)



However, reading reviews of the 2 doesn't seem very conclusive, such as [https://www.tomshardware.com/reviews/intel-core-i9-10900k-cpu-review/4|this](https://www.tomshardware.com/reviews/intel-core-i9-10900k-cpu-review/4|this).

*Tags: General Technical*

---

**JonJonJon** - *20:28:44*

The backtest is run on the example I added to flumine. So it is just a modified version of your LowestLayer strategy, but runs PE, and therefore has a lot of cancelled orders in the blotter. Such a profile would be realistic for someone quoting/changing lots of prices. Such as someone who quoted limit orders at the bollinger bands

*Tags: Strategies*

---

**JonJonJon** - *20:42:20*

A user would typically receive orders when backtest.py calls strategy.process_orders here:



```for strategy in self.strategies:

    strategy_orders = blotter.strategy_orders(strategy)

    strategy.process_orders(market, strategy_orders)```

My code change does not effect the contents of strategy_orders.



It just changes what gets sent to process.process_current_order:



```for bet_id in potentially_incomplete_order_ids:

    process.process_current_order(blotter[bet_id])```

From my understanding of the code, the orders that it omits won't get affected by process_current_order. However, I am not 100% sure.

*Tags: Strategies*

---

**liam** - *21:05:52*

No problem, looking at it I would move the logic into the blotter itself 

*Tags: General Technical*

---

## 2020-06-16

**liam** - *09:10:48*

Are you able to have a look/test of [https://github.com/liampauling/flumine/pull/219|this](https://github.com/liampauling/flumine/pull/219|this)? Basically taking your idea but placing it inside the blotter, ended up cleaning up quite a few things, I am seeing a dramatic improvement :thumbsup:

*Tags: General Technical*

---

**JonJonJon** - *21:29:01*

2 questions...



Could this code be moved into blotter, and called something like "process_live_orders"?



```for order in blotter.live_orders:

    process.process_current_order(order)

    if order.trade.status.value == "Complete":

        blotter.complete_order(order)```



*Tags: Deployment*

---

## 2020-06-17

**SrFabio** - *08:34:17*

Current AMD cpus are far better especially when it comes to price/performance

*Tags: Performance*

---

**JonJonJon** - *15:29:15*

Another random question... What made you choose the 3200Mhz ram, vs 3600Mhz ram? I can't find conclusive data on which is better.

*Tags: General Technical*

---

**Mo** - *15:30:55*

In most applications the RAM speed is not that important, I think latency is an equally important consideration

*Tags: Performance*

---

**liam** - *20:35:52*

In flumine? 

*Tags: General Technical*

---

**mandelbot** - *20:55:12*

I am learning to build models so I figure it might come in handy in the future. Would be nice to have a nice cache. I already have this data for a few years back.

*Tags: Strategies*

---

**JonJonJon** - *21:26:11*

I've had a doodle with it. Hard to say if it improves performance or not directly, as we can't change live orders to a set, and leave it as that. We have to hack this bit too:



```# process current orders

blotter = market.blotter

completed = set()

for order in blotter.live_orders:

    process.process_current_order(order)

    if order.trade.status.value == "Complete":

        #blotter.complete_order(order)

        completed.add(order)

blotter._live_orders = blotter._live_orders - completed```

The above change is obviously not suitable for production as we are modifying the private variable. But I just did it as a quick hack to make things work for testing.



Given variable run times. It might or might not shave 0.2-0.4 seconds off my backtest which, takes around 12.5 seconds to run. But there is variability, so it is impossible to say for sure.



However, using sets expresses the intent of the code clearer, as there should be no duplicates in "live orders", and they should be unordered.



Perhaps we should just leave this for now, but be aware of it anyone reports bottlenecks in this part of the code. I think using sets is more likely to be better if a user has hundreds of live orders at once. I think that is unlikely. But I could be wrong!

*Tags: Performance, Deployment*

---

## 2020-06-24

**Mo** - *10:10:56*

Noob horse racing question... do horses get renamed? Looks like they get renamed if they're imported to HK? [https://racing.hkjc.com/racing/information/English/Horse/HorseFormerName.aspx](https://racing.hkjc.com/racing/information/English/Horse/HorseFormerName.aspx). Any other circumstances?

*Tags: General Technical*

---

## 2020-07-05

**Newbie99** - *17:47:43*

Another cashout question....



```import requests as rq

import json



def cash_out(session_token, market_id, min_return, ai.acckey):



    url = ('[https://cashout-service.betfair.com/cashout-service/transactional/v1.0/cashout?_ak=](https://cashout-service.betfair.com/cashout-service/transactional/v1.0/cashout?_ak=)' + str(ai.acckey)

                          + '&amp;alt=json&amp;currencyCode=GBP&amp;marketId=' + str(market_id) + '&amp;quotePercentage=100&amp;quoteValue=' + str(min_return))

    header = {'X-Application': ai.acckey, 'X-Authentication': session_token, 'content-type': 'application/json'}

    response = [http://rq.post|rq.post](http://rq.post|rq.post)(url, headers=header)

    if response.status_code == 200:

        return json.loads(response.content.decode('utf-8'))

    else:

        return None```

The above works, however whatever I put in as min_return it just cashes out regardless, so can anyone spot where the error lies (this is just tweaking the example posted here the other day btw, so I am assuming the endpoint is the preferred one for the UK exchange)?



ai.acckey = appkey for the avoidance of doubt

*Tags: Errors Debugging*

---

**SrFabio** - *18:33:18*

I don't see any error there. Does it cashout for less than  the min return? I've not used this endpoint before (but I'm extremely tempted to!)

*Tags: Errors Debugging*

---

**SrFabio** - *18:38:23*

does it not like quoteValue being a string? I'd be extremely surprised if that was the issue but I think we all seen things on the Betfair API that don't look amazing

*Tags: General Technical*

---

## 2020-07-06

**Lee** - *21:17:35*

Maybe a bit of a newbie question but in a recent horse race the website says BSP 5.41 but in the stream I got BSP 6.82. What causes this difference?

```{"adjustmentFactor": 11.628, "status": "ACTIVE", "sortPriority": 4, "bsp": 6.818947736265255, "id": 12660148}```

*Tags: General Technical*

---

## 2020-07-20

**D C** - *14:13:57*

Can anyone recommend a standard laptop that will have no problems installing linux onto (mint specifically)? I am talking about something that I can roll up to PC world and purchase and have linux installed within a couple of hours without worry about hardware issues etc.  I usually use older machines for this purpose but my dev box needs a serious upgrade now.

*Tags: Getting Started*

---

**D C** - *14:16:56*

No problems overwriting the Windows install with fresh ubuntu? SSD no issue? Its been a long time since I did a fresh install - before SSDs were commonplace

*Tags: Getting Started*

---

**Chris** - *14:17:01*

Lenovo Ideapad's have been no problem for me to run Linux on with minimal fuss/problems, and they're widely available

*Tags: General Technical*

---

**Lee** - *14:18:19*

Nope, no problems. The only thing downsides i would say is the battery life was pretty average and the camera was in the bottom of the screen so everyone ends up looking up your nose

*Tags: General Technical*

---

**Newbie99** - *14:18:41*

Just be a bit careful with this year's model, I had to send 2 back because of defective trackpad's and looking at you tube and other reviews it seems to be an issue with the 2020 XPS 15 (not sure if the whole line up uses the same trackpad). So personally based on that, I wouldn't get a 2020 XPS until they announce they've fixed that issue.

*Tags: Errors Debugging, Strategies*

---

**Jono** - *14:34:49*

Just a general question about bet placement, if an order is requested at odds outside of betfairs tick brackets how are these bets handled? do they immediately fail and give an error response or are they rounded at betfairs end?

*Tags: Errors Debugging*

---

**Newbie99** - *14:37:22*

You get an error and they fail

*Tags: Errors Debugging*

---

**Jono** - *14:43:58*

thanks thats good to know. is there a "fit to appropriate bracket" function in the bflw repo? I wrote my own for a previous script to do this but have fallen prey to using my own untested functions before

*Tags: General Technical*

---

**liam** - *14:44:39*

there is in flumine [https://github.com/liampauling/flumine/blob/master/flumine/utils.py#L77](https://github.com/liampauling/flumine/blob/master/flumine/utils.py#L77)

*Tags: General Technical*

---

## 2020-07-27

**Frankz** - *19:17:54*

hi, im new here. after building a crypto arbitrage bot back in 2016 I started shifting towards sports betting. how about you? who else is betfairlight streaming the games tonite?? :slightly_smiling_face:

*Tags: Strategies*

---

## 2020-08-01

**Mo** - *09:13:10*

Need some help from any PyCharm professional owners...



I have a problem with the documentation popup window feature when typing in the Python console. I start typing a function and the documentation appears. Great. Now I open brackets to start specifying arguments and the documentation disappears - the documentation window says "No documentation found.". At exactly the time when I want to see it so I know what the arguments are and what they do. There are various settings involved such as the delay before the popup appears, whether to show the documentation on mouse move, whether to auto-update from source etc.



Does anyone have any idea what I'm talking about and how to fix it?!

*Tags: Errors Debugging, Feature Engineering*

---

**Disco** - *09:43:06*

I have this version too, will check it later. Since updating, I've been having problems with color scheme applying very slowly, and real time code check/suggestions being slow too (while cpu load is normal. Didn't have it in preview versions, seems like a bug)

*Tags: Errors Debugging, Performance*

---

**Lee** - *19:07:44*

This works fine for me, but doesn’t update if i go back to an existing function with the params already filled out, will only update when i delete a param. Happy to share any settings if that may help.

But I have had quite a few other bugs over the last month of two.  The main one now being moving code around messes up the indentation.

*Tags: Errors Debugging*

---

## 2020-08-05

**birchy** - *20:29:51*

I believe it's unlimited as it's basically a simplified version of EC2.

*Tags: Deployment*

---

**liam** - *20:33:23*

Surely your site would have to become huge for transfer costs to be a problem 

*Tags: General Technical*

---

## 2020-08-14

**Newbie99** - *15:57:38*

Just playing around with Flumine and I was testing placing live orders, but I can't seem to place multiple orders against the same runner, is that by design, or is there a parameter I'm missing?



```import time

import logging

import betfairlightweight

from betfairlightweight.filters import streaming_market_filter

from pythonjsonlogger import jsonlogger



from flumine import Flumine, clients, BaseStrategy

from flumine.order.trade import Trade

from flumine.order.ordertype import LimitOrder

from flumine.order.order import OrderStatus

import account_info as ai



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))





class ExampleStrategy(BaseStrategy):

    def start(self):

        # subscribe to streams

        print("starting strategy 'ExampleStrategy'")



    def check_market_book(self, market, market_book):

        # process_market_book only executed if this returns True

        if market_book.status != "CLOSED":

            return True



    def process_market_book(self, market, market_book):

        # process marketBook object

        for runner in market_book.runners:

            if (

                runner.status == "ACTIVE"

                #and runner.last_price_traded

                and runner.selection_id == 5512138

            ):

                trade = Trade(

                    market_id=market_book.market_id,

                    selection_id=runner.selection_id,

                    handicap=runner.handicap,

                    strategy=self,

                )

                order = trade.create_order(

                    side="BACK", order_type=LimitOrder(price=1000, size=2.00)

                )

                # self.offset_orders= []

                # self.customer_order_ref='t'

                self.place_order(market, order)

        print(market_book.publish_time)



    def process_orders(self, market, orders):

        for order in orders:

            if order.status == OrderStatus.EXECUTABLE:

                # if order.elapsed_seconds and order.elapsed_seconds &gt; 2:

                #     self.cancel_order(market, order)

                # if order.elapsed_seconds and order.elapsed_seconds &gt; 5:

                #     # print(order.bet_id, order.average_price_matched, order.size_matched)

                #     if order.size_remaining == 2.00:

                #         self.cancel_order(market, order, size_reduction=0.01)

                # self.update_order(market, order, "PERSIST")

                # if order.order_type.price == 1.01 and order.size_remaining == 0.49:

                #     self.replace_order(market, order, 1.02)

                # if order.order_type.price == 1.02:

                #     self.replace_order(market, order, 1.03)

                # if order.order_type.price == 1.03:

                #     self.replace_order(market, order, 1.05)

                pass





trading = betfairlightweight.APIClient(ai.accname, ai.accpass, ai.acckey, certs=ai.path)

client = clients.BetfairClient(trading)



framework = Flumine(client=client)



strategy = ExampleStrategy(

    market_filter=streaming_market_filter(market_ids=["1.172039988"]),

    streaming_timeout=2,

    # max_selection_exposure=5000,

    # max_order_exposure=2000

)

framework.add_strategy(strategy)

framework.run()```

I can place, cancel, update etc successfully, but I assumed the above would try to fire off multiple orders, but it only ever seems to place one (obviously there's not a real world use for this script, I was just trying to play around to place multiple orders). Have I missed something, or is this intended behaviour?

*Tags: Deployment, Strategies*

---

**liam** - *16:42:34*

By default it will look to see if the runner already has live/pending orders for that strategy aka [https://github.com/liampauling/flumine/blob/master/flumine/strategy/strategy.py#L121|invested](https://github.com/liampauling/flumine/blob/master/flumine/strategy/strategy.py#L121|invested), if you want to prevent this logic just override the `def validate_order` function to return True.



Strongly recommend testing this via the backtester or paper trading as it will fire in a lot of orders very quickly!

*Tags: Deployment, Strategies*

---

**Lee** - *17:11:59*

```from flumine import BaseStrategy

from flumine.order.ordertype import LimitOrder

from flumine.order.trade import Trade





class ExampleMultipleOrders(BaseStrategy):

    def check_market_book(self, market, market_book):

        if market_book.status != "CLOSED":

            return True



    def process_market_book(self, market, market_book):

        for runner in market_book.runners:

            if runner.status == "ACTIVE" and runner.selection_id == 35527773:

                trade = Trade(

                    market_id=market_book.market_id,

                    selection_id=runner.selection_id,

                    handicap=runner.handicap,

                    strategy=self,

                )

                order = trade.create_order(

                    side="BACK", order_type=LimitOrder(price=1000, size=2.00)

                )

                self.place_order(market, order)```

*Tags: Strategies*

---

## 2020-08-18

**Jonjonjon** - *10:40:10*

For anyone with a 3950x chip, what sort of CPU temps and clockspeeds do you get when running Flumine with the multiprocessing module?



I'm getting CPU temps of around 61C this morning, and clockspeeds of just over 3.8GHz.

*Tags: Performance*

---

**Unknown** - *11:50:59*

That's how I've done my fans. I'm not sure if the rear/roof exhaust fan is helping much. But the guys who built it tied the lower/front 120mm's power cables with a load of other stuff, and I'm scared of breaking something if I cut the cable tie.

*Tags: General Technical*

---

**Twatter** - *11:52:16*

[@UBS7QANF3](@UBS7QANF3) Just run a hoover over those filters - it'll help a bit.. no need to turn it off...

*Tags: General Technical*

---

**Twatter** - *12:01:36*

[@UBS7QANF3](@UBS7QANF3) Static discharge - haven't had a problem with stuff like that... I suppose if you're wearing a balloon suit and rolling around on the carpet for an hour or so whilst vacuuming then might be an issue... but for shoving a cleaner over a vent I would have said it be fine for a few seconds...

*Tags: General Technical*

---

**Newbie99** - *20:08:14*

Using flumine (live), when an order goes into a pending state and then the "message": "1 order packages created" appears in the next line as expected. Sometimes the orders never actually make it onto the order book. Given the orders weren't in any violation of the controls and there don't appear to be any API issues, does this mean there is some kind of latency logic built in (i.e. if the order book receives the order x seconds after it was sent it automatically fails or something along those lines)?

*Tags: Performance, Deployment*

---

**Newbie99** - *20:10:53*

```{"asctime": "2020-08-18 18:54:33,224", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.172181073", "selection_id": 26836902, "handicap": 0, "id": "138170696732214253", "customer_order_ref": "27cfde50caeb3-138170696732214253", "bet_id": null, "trade": {"id": "411783ec-e184-11ea-8bfc-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138170696732214253"], "notes": "1.172181073,2020-08-18 18:56:00,2020-08-18 18:53:46.472000,OPEN,False,26836902,4. Energize Bingo,0,2.94,2.88,2.94,2.86,2.96,3693.63,355.2099999999996,2.757220771341723,2.7819444254664205,0.008706128457104802,0.012755260522776427,-0.5531056874468805,1.0469958809755968,-1.5485176472436966,-2.423454304332246,0,0,0.03303360044899266,2.54,2.74,True", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 2.88, "size": 5.21, "persistence_type": "MARKET_ON_CLOSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}

{"asctime": "2020-08-18 18:54:33,230", "levelname": "INFO", "message": "1 order packages created", "order_packages": [{"id": "4118e32b-e184-11ea-aace-2016d8944b85", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x000001B04D3CFDF0&gt;", "market_id": "1.172181073", "orders": ["138170696732214243", "138170696732214245", "138170696732214247", "138170696732214249", "138170696732214251", "138170696732214253"], "package_type": "Place", "customer_strategy_ref": "BlueOcean", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}]}```

*Tags: Deployment, Strategies*

---

**liam** - *20:14:11*

I think there is an error in the thread pool that isn’t being caught [https://github.com/liampauling/flumine/issues/256|https://github.com/liampauling/flumine/issues/256](https://github.com/liampauling/flumine/issues/256|https://github.com/liampauling/flumine/issues/256)

*Tags: Errors Debugging*

---

**liam** - *20:25:28*

Remove the use of the thread pool in execution.baseexecution.py and call the function directly, you should get an error

*Tags: Errors Debugging*

---

**Newbie99** - *20:33:56*

```{"asctime": "2020-08-18 19:33:11,458", "levelname": "INFO", "message": "New requests.Session created", "sessions_created": 1}

{"asctime": "2020-08-18 19:33:11,459", "levelname": "INFO", "message": "Stopped OrderStream 1001"}

{"asctime": "2020-08-18 19:33:11,510", "levelname": "INFO", "message": "Stopped output_thread (OrderStream 1001)"}

{"asctime": "2020-08-18 19:33:11,511", "levelname": "INFO", "message": "Shutting down Execution (SimulatedExecution)"}

Traceback (most recent call last):

{"asctime": "2020-08-18 19:33:11,512", "levelname": "INFO", "message": "Stopped MarketStream 2001"}

  File "D:\Python38\lib\site-packages\flumine\flumine.py", line 35, in run

    self._process_order_package(event)

  File "D:\Python38\lib\site-packages\flumine\baseflumine.py", line 155, in _process_order_package

    order_package.client.execution.handler(order_package)

  File "D:\Python38\lib\site-packages\flumine\execution\baseexecution.py", line 42, in handler

    self._thread_pool.submit(func, order_package, http_session)

AttributeError: 'BetfairExecution' object has no attribute '_thread_pool'



During handling of the above exception, another exception occurred:



Traceback (most recent call last):

  File "D:/Python37/webpages/flumine_examples/example.py", line 285, in &lt;module&gt;

    framework.run()

  File "D:\Python38\lib\site-packages\flumine\flumine.py", line 53, in run

    logger.error("Unknown item in handler_queue: %s" % str(event))

  File "D:\Python38\lib\site-packages\flumine\baseflumine.py", line 348, in __exit__

    self.simulated_execution.shutdown()

  File "D:\Python38\lib\site-packages\flumine\execution\baseexecution.py", line 117, in shutdown

    self._thread_pool.shutdown(wait=True)

AttributeError: 'SimulatedExecution' object has no attribute '_thread_pool'```

*Tags: Errors Debugging*

---

**liam** - *20:34:59*

Change this line [https://github.com/liampauling/flumine/blob/69d68904b4ae0c8ba3c0d60991c3a6a38066040d/flumine/execution/baseexecution.py#L44|https://github.com/liampauling/flumine/blob/69d68904b4ae0c8ba3c0d60991c3a6a38066040d/flumine/execution/baseexecution.py#L44](https://github.com/liampauling/flumine/blob/69d68904b4ae0c8ba3c0d60991c3a6a38066040d/flumine/execution/baseexecution.py#L44|https://github.com/liampauling/flumine/blob/69d68904b4ae0c8ba3c0d60991c3a6a38066040d/flumine/execution/baseexecution.py#L44)

*Tags: General Technical*

---

**Newbie99** - *20:43:12*

hmm....no error interestingly, I get the pending logs then...nothing else (I have publish time ticking along so can see its still going)

*Tags: Errors Debugging*

---

## 2020-08-19

**liam** - *08:19:08*

```{"asctime": "2020-08-19 07:16:22,242", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.172171556", "selection_id": 8329902, "handicap": 0, "id": "138171141822420430", "customer_order_ref": "27cfde50caeb3-138171141822420430", "bet_id": null, "trade": {"id": "e28912a4-e1eb-11ea-86ee-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138171141822420430"], "notes": "", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 10, "size": 2, "persistence_type": "MARKET_ON_CLOSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}

{"asctime": "2020-08-19 07:16:22,242", "levelname": "INFO", "message": "1 order packages created", "order_packages": [{"id": "e28930c2-e1eb-11ea-86ee-a0999b054753", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x104826b20&gt;", "market_id": "1.172171556", "orders": ["138171141822420430"], "package_type": "Place", "customer_strategy_ref": "Liams-MBP", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}]}

{"asctime": "2020-08-19 07:16:22,243", "levelname": "INFO", "message": "New requests.Session created", "sessions_created": 1, "session": "&lt;requests.sessions.Session object at 0x10485e850&gt;", "session_time_created": 1597821382.243398, "session_time_returned": 1597821382.2433999}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "execute_place", "trading_function": "place", "elapsed_time": 0.24187803268432617, "response": {"customerRef": "e28930c2e1eb11ea86eea0999b054753", "status": "SUCCESS", "marketId": "1.172171556", "instructionReports": [{"status": "SUCCESS", "instruction": {"selectionId": 8329902, "handicap": 0.0, "limitOrder": {"size": 2.0, "price": 10.0, "persistenceType": "MARKET_ON_CLOSE"}, "customerOrderRef": "27cfde50caeb3-138171141822420430", "orderType": "LIMIT", "side": "BACK"}, "betId": "208759879486", "placedDate": "2020-08-19T07:16:22.000Z", "averagePriceMatched": 0.0, "sizeMatched": 0.0, "orderStatus": "EXECUTABLE"}]}, "order_package": {"id": "e28930c2-e1eb-11ea-86ee-a0999b054753", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x104826b20&gt;", "market_id": "1.172171556", "orders": ["138171141822420430"], "package_type": "Place", "customer_strategy_ref": "Liams-MBP", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "Trade status update: Pending", "id": "e28912a4-e1eb-11ea-86ee-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.PENDING", "orders": ["138171141822420430"], "notes": "", "market_notes": "3.05,3.15,3.1"}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "Order Place: SUCCESS", "bet_id": null, "order_id": "138171141822420430", "status": "SUCCESS", "error_code": null}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "Order status update: Executable", "market_id": "1.172171556", "selection_id": 8329902, "handicap": 0, "id": "138171141822420430", "customer_order_ref": "27cfde50caeb3-138171141822420430", "bet_id": "208759879486", "trade": {"id": "e28912a4-e1eb-11ea-86ee-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.PENDING", "orders": ["138171141822420430"], "notes": "", "market_notes": "3.05,3.15,3.1"}, "order_type": {"order_type": "Limit", "price": 10, "size": 2, "persistence_type": "MARKET_ON_CLOSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Executable", "status_log": "Pending, Executable"}

{"asctime": "2020-08-19 07:16:22,488", "levelname": "INFO", "message": "Trade status update: Live", "id": "e28912a4-e1eb-11ea-86ee-a0999b054753", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138171141822420430"], "notes": "", "market_notes": "3.05,3.15,3.1"}```

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2020-08-20

**Mo** - *14:28:23*

Most of the time (but not always!) the Weatherbys ID is the same as the Timeform ID if that helps

*Tags: General Technical*

---

## 2020-08-24

**Newbie99** - *16:25:35*

[@U4H19D1D2](@U4H19D1D2), I haven't been able to replicate the issue with pending orders from the other day, but came across this today and wanted to check the correct way it's intended to be handled:



```{"asctime": "2020-08-24 15:11:49,150", "levelname": "INFO", "message": "Order status update: Violation", "market_id": "1.172319685", "selection_id": 26578374, "handicap": 0, "id": "138175747090349752", "customer_order_ref": "27cfde50caeb3-138175747090349752", "bet_id": null, "trade": {"id": "21e4feb7-e61c-11ea-8071-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138175747090349752"], "notes": "1.172319685,2020-08-24 15:15:00,2020-08-24 15:11:48.783000,OPEN,False,26578374,Phoenix Strike,0,32,32,34,30,36,1116.3899999999999,4.0,34.20734773394412,34.20734773394412,-0.00017030046190238602,-0.015229531148119538,0,-0.34410707742395563,-1.0,-0.9994686305661997,-1.0,-0.9994686305661997,0.04510370240413563,32,36,32", "market_notes": "32,34,32"}, "order_type": {"order_type": "Limit", "price": 32, "size": 2, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Violation", "status_log": "Pending, Violation"}

{"asctime": "2020-08-24 15:11:49,151", "levelname": "WARNING", "message": "Order has violated STRATEGY_EXPOSURE and will not be placed", "control": "STRATEGY_EXPOSURE", "error": "Order exposure (62) is greater than strategy.max_order_strategy (20)", "order": {"market_id": "1.172319685", "selection_id": 26578374, "handicap": 0, "id": "138175747090349752", "customer_order_ref": "27cfde50caeb3-138175747090349752", "bet_id": null, "trade": {"id": "21e4feb7-e61c-11ea-8071-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138175747090349752"], "notes": "1.172319685,2020-08-24 15:15:00,2020-08-24 15:11:48.783000,OPEN,False,26578374,Phoenix Strike,0,32,32,34,30,36,1116.3899999999999,4.0,34.20734773394412,34.20734773394412,-0.00017030046190238602,-0.015229531148119538,0,-0.34410707742395563,-1.0,-0.9994686305661997,-1.0,-0.9994686305661997,0.04510370240413563,32,36,32", "market_notes": "32,34,32"}, "order_type": {"order_type": "Limit", "price": 32, "size": 2, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Violation", "status_log": "Pending, Violation"}}```

So that order failed validation, which makes sense, all looks correct...however,

```runner_data = strategy.get_runner_context(market_id=market_book.market_id,

    selection_id=runner['selection_id'],

            handicap=runner['handicap'])

live_trade_count = runner_data.live_trade_count```

live_trade_count returned 1 until the close.



If an order fails validation, does the live_trade_count need to be manually adjusted and is that intentional?

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *16:35:43*

can you put the debugger here [https://github.com/liampauling/flumine/blob/master/flumine/order/process.py#L69](https://github.com/liampauling/flumine/blob/master/flumine/order/process.py#L69)

*Tags: Errors Debugging*

---

**Newbie99** - *20:34:19*

```{"asctime": "2020-08-24 19:29:22,513", "levelname": "WARNING", "message": "Order has violated ORDER_VALIDATION and will not be placed", "control": "ORDER_VALIDATION", "error": "Order size is less than min bet size (2) or payout (10) for currency", "order": {"market_id": "1.172363533", "selection_id": 19763676, "handicap": 0, "id": "138175901625116463", "customer_order_ref": "27cfde50caeb3-138175901625116463", "bet_id": null, "trade": {"id": "1ce2672e-e640-11ea-9229-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138175901625116463"], "notes": "1.172363533,2020-08-24 19:30:00,2020-08-24 19:29:22.551000,OPEN,False,19763676,Hush Buffy,0,2.88,2.88,2.9,2.84,2.92,384.1600000000001,39.120000000000005,2.9232699537837674,2.9232699537837674,-0.00016599506431987516,-0.0018108429044144984,0,-0.43546624108134707,-1.0,-1.020314057737078,-1.0,-1.020314057737078,0.012721252976427583,2.82,2.9,2.82", "market_notes": "2.88,2.9,2.88"}, "order_type": {"order_type": "Limit", "price": 2.9, "size": 0.73, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Violation", "status_log": "Pending, Violation"}}

{"asctime": "2020-08-24 19:29:22,515", "levelname": "WARNING", "message": "Empty package, not executing", "id": "1ce28e3d-e640-11ea-905c-2016d8944b85", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x000001BC1E36D100&gt;", "market_id": "1.172363533", "orders": ["138175901625116463"], "package_type": "Place", "customer_strategy_ref": "BlueOcean", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}```

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *20:37:42*

Can you share what the code looks like for the order / trade in the strategy? Without revealing the secret sauce :wink:

*Tags: Strategies*

---

## 2020-08-25

**Newbie99** - *10:50:29*

```def process_market_book(self, market, market_book):

                total_live_trade_count = 0

                for runner in runner_list:

                    runner_data = strategy.get_runner_context(market_id=market_book.market_id,

                        selection_id=runner['selection_id'],

                                handicap=runner['handicap'])

                    live_trade_count = runner_data.live_trade_count

                    print({'selection_id': runner['selection_id'], 'runner_name': runner['runner_name'], 'live_trade_count': live_trade_count})

                    total_live_trade_count = total_live_trade_count + live_trade_count



                if total_live_trade_count == 0:

                    for runner in runner_list:

                        if 'price' not in runner.keys():

                            pass



                        else:

                            price = runner['price']

                            if price &gt; absolute_min_price and price &lt; absolute_max_price:

                                stake = 2



                                trade = Trade(

                                    market_id=market_book.market_id,

                                    selection_id=runner['selection_id'],

                                    handicap=runner['handicap'],

                                    strategy=strategy,

                                    notes=runner

                                )

                                order = trade.create_order(

                                    side="LAY", order_type=LimitOrder(price=price, size=stake, persistence_type=persistence_type)

                                )

                                self.place_order(market, order)```

*Tags: Deployment, Strategies*

---

**Newbie99** - *10:51:34*

The indents came out a bit weird there, but that's essentially it for now, its a super simple script, just familiarising myself with Flumine at the mo (runner_list is just a list of dicts with runner info)

*Tags: General Technical*

---

**Newbie99** - *10:52:16*

The replace logic I was testing (which is where I'm theorising the problems occur is very similar to the example code):

*Tags: General Technical*

---

**liam** - *10:57:19*

where is `strategy` coming from?

*Tags: Strategies*

---

**PeterLe** - *12:12:44*



Afternoon all, quick question please; we’re the TPD GPS feed present at the first race today? Thanks

*Tags: General Technical*

---

**liam** - *12:37:15*

`Yes, its due to the use of "Bangor-on-Dee" instead of "Bangor" and is causing mapping failures at our side.



The change was made to the venue name to fix a different feed related issue but we don't yet have dual mapping (for both Bangor &amp; Bangor-on-Dee) on the GPS API from our side so the data won't be coming through for todays Bangor meeting.  This will be addressed as part of the current ongoing GPS API v2 work and I expect this to be in place in time for the next Bangor-on-Dee meeting on the 30th September.`

*Tags: Errors Debugging*

---

**birchy** - *22:53:58*

All this talk of gps issues makes me wonder if it's actually reliable enough to be used for triggering bets? In particular, this is concerning:



`How accurate is the live data?

Accuracy is recorded as the difference between the official finish time and the GPS derived finish time, 

the BHA defined conversion between time and length varies by ground and code between 4 and 6 

lengths per second, taking speed = 5.5ls-1 and L=2.4m, and a standard deviation of a sample of the 

data measured as 100ms, then 95% of the live data is within 2.59m of the true position.`



...considering that there are often multiple runners within a 2.59m section. I would imagine GPS could easily be reporting positions in the wrong order? And that's only 95% of the time. The other 5% must be a monumental fuckup, particularly where all the runners are tightly bunched?

*Tags: Performance, Deployment*

---

**birchy** - *23:48:25*

It's peaked my interest...is there any timestamped historical data available, i.e. where I could compare gps feed vs exchange prices?

*Tags: Data Quality*

---

## 2020-08-26

**Mo** - *05:50:24*

TPD provide historic data BUT it's not a reproduction of what you would have received live as they apply some transformations after the fact to try to make the positions more accurate. As a result I've found it largely useless for backtesting and this seems to be a barrier to entry that protects the guys who have been doing it since the beginning and have collected their own data... on the flip side, they would have had zero historic data having started from the beginning and have done very well for themselves

*Tags: Deployment*

---

**Mo** - *07:34:22*

Sort of... the aim of their historic feed is not to provide an accurate recording of the live data but to provide the most accurate positions possible. This still has value from e.g. more accurate sectional timing. TPD is aware that there is demand for the kind of historic data we'd need for backtesting and have made noises that they are working on it but I'm not expecting it any time soon

*Tags: Deployment*

---

**liam** - *08:19:31*

Yep since March 2018, I believe it helps but its been mentioned in the premium newsletter a few times, not sure on the current license situation

*Tags: General Technical*

---

**liam** - *09:56:42*

[@U016TGY3676](@U016TGY3676) in regards to treatment its very much a two way street, have you ever spoken to anyone on the premium team? Obviously being a PC payer helps but they really do prioritise us auto guys as they always want more liquidity

*Tags: General Technical*

---

**birchy** - *10:44:00*

[@U4H19D1D2](@U4H19D1D2) I've never spoken to anyone other than Neil for bug fixes/clarification, etc regarding the API. I know it's a 2 way street, but I couldn't ask for something I didn't know existed (ie the premium team) and tbh, I would have thought the onus is on THEM to be initiating those kind of conversations. My lifetime account is in the black, but probably not significantly enough to be noticed.

*Tags: Errors Debugging*

---

**Newbie99** - *13:56:37*

[@U4H19D1D2](@U4H19D1D2), I've created another script to demo the violation issue (i.e. that the trade still counts as a live trade), this strips out everything, so hopefully makes it clearer where (I think) the problem lies (or alternatively it may be clearer where I'm wrong if that's the case)!



All it does is try to lay the lowest price runner (I just adapted the example script) @ 1.2, with a size of 2, but the max_order_exposure is set to 0.1, so it should violate.



This occurs as expected and it states the trade is complete, however it appears to remain in the live trade count (which I assume is not intended behaviour). So nothing to do with replaces as I incorrectly said yesterday, but I assumed when the violated trade is completed, the live trade count should drop to 0.





*Tags: Deployment*

---

**Newbie99** - *13:56:37*

```from flumine import BaseStrategy, clients, Flumine

from flumine.order.trade import Trade

from flumine.order.order import OrderStatus

from flumine.order.ordertype import LimitOrder

from flumine.utils import get_price

import account_info as ai

import betfairlightweight

from betfairlightweight.filters import streaming_market_filter

import logging

from pythonjsonlogger import jsonlogger

import time



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



time_to_open_execution_in_seconds = 900

time_to_close_execution_in_seconds = 0



class test_violation(BaseStrategy):



    def check_market_book(self, market, market_book):

        if market_book.status not in ["CLOSED", "SUSPENDED"]:

            return True



    def process_market_book(self, market, market_book):



        if market.market_catalogue is not None and \

                market.seconds_to_start &lt;= time_to_open_execution_in_seconds and \

                market.seconds_to_start &gt;= time_to_close_execution_in_seconds:

            print('Open for orders')



            prices = [

                (r.selection_id, r.last_price_traded)

                for r in market_book.runners

                if r.status == "ACTIVE"

            ]

            prices.sort(key=lambda tup: tup[1])

            selection_id = prices[0][0]



            for runner in market_book.runners:

                if runner.selection_id == selection_id:

                    # lay at current best lay price

                    lay = 1.2

                    trade = Trade(

                        market_book.market_id, runner.selection_id, runner.handicap, self,

                    )

                    order = trade.create_order(

                        side="LAY", order_type=LimitOrder(lay, 2),

                    )

                    self.place_order(market, order)



                    runner_data = self.get_runner_context(market_id=market_book.market_id,

                                                              selection_id=runner.selection_id,

                                                              handicap=runner.handicap)

                    live_trade_count = runner_data.live_trade_count

                    trade_count = runner_data.trade_count

                    print({'selection_id': runner.selection_id,

                           'live_trade_count': live_trade_count, 'trade_count': trade_count})



    def process_orders(self, market, orders):

        if market.market_book.status not in ['CLOSED', 'SUSPENDED']:

            for order in orders:

                print({'selection_id': order.selection_id, 'customer_order_ref': order.customer_order_ref,

                       'trade_complete': order.trade.complete, 'trade_status': order.status})



trading = betfairlightweight.APIClient(ai.accname, ai.accpass, ai.acckey, certs=ai.path)

client = clients.BetfairClient(trading)



framework = Flumine(client=client)





strategy = test_violation(

    market_filter=streaming_market_filter(

        event_type_ids=[7],

        country_codes=['GB'],

        market_types=['WIN'],

    ),

    streaming_timeout=2,

    # max_selection_exposure=50,

    max_order_exposure=0.1

)



framework.add_strategy(strategy)

framework.run()```



*Tags: Deployment, Strategies*

---

**liam** - *15:52:18*

I see the problem, not quite sure how to fix it at the moment

*Tags: Errors Debugging*

---

**Unknown** - *15:55:02*

This fixes it, the issue is caused by the fact there are no orders live in the market so `_process_current_orders` is never executed and the trade never completed, adding the following fixes it just not sure if that is the way I want to fix it

*Tags: Errors Debugging, Deployment*

---

**liam** - *16:02:01*

So the above will fix it, just tempted to rewrite `process.py` so its not an issue (never liked it)

*Tags: Errors Debugging*

---

**liam** - *18:49:18*

[@UFTBRB3F1](@UFTBRB3F1) gone for a minor refactor to move the logic which I think makes things simpler [https://github.com/liampauling/flumine/pull/262/files](https://github.com/liampauling/flumine/pull/262/files)

*Tags: General Technical*

---

**mlpanda** - *20:42:58*

Hey [@U4H19D1D2](@U4H19D1D2), I have a couple of questions on using Flumine for tennis:



1. Is there an easy way to get all country_codes to get all matches rather than me passing a wikipedia list of all I can find?

2. Is there any functionality which makes it easy to fetch scores data? I'm aware that you have implemented two scores endpoints (thanks for highlighting this [@UBS7QANF3](@UBS7QANF3)): [https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1597749400063800](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1597749400063800) 

       My current thought on implementation is to find the `eventid` the first time a given market enters `process_market_book()` and then afterwards try both endpoints to get scores, but would of course be happy if I didn't have to reinvent this myself :wink:

  3.  Is it possible to determine whether it's a match involving men or women from the scores endpoints?

*Tags: Getting Started*

---

**Mo** - *21:00:39*

Take a look at some of these methods [@U016535QCJ2](@U016535QCJ2) mentioned here: [https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1596104343458200|https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1596104343458200](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1596104343458200|https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1596104343458200). Not all of them are implemented in bflw but for example you might find the method for getting the in play events helpful 

*Tags: General Technical*

---

## 2020-08-27

**liam** - *09:35:24*

[@UF3AYKZMW](@UF3AYKZMW) just pushed a tennis [https://github.com/liampauling/flumine/pull/264/files|example](https://github.com/liampauling/flumine/pull/264/files|example), the design of flumine is to use workers and callbacks to continually poll the scores endpoint out of the main loop and make available for all markets that sit in that event using the `market.context`

*Tags: General Technical*

---

**birchy** - *10:32:36*

[@U4H19D1D2](@U4H19D1D2) Excellent work! Will the updates be picked up by `pip` `install` `Flumine --upgrade`, or is it better to git pull the source?

*Tags: Getting Started*

---

**Lee** - *10:33:20*

[@U016TGY3676](@U016TGY3676) i'd recommend to always use the version number e.g. `flumine==1.11.1`

*Tags: General Technical*

---

**liam** - *10:33:55*

not released yet as it will be in `1.11.2` waiting for a fix from Lee but I can't remember what it was

*Tags: Errors Debugging*

---

**Newbie99** - *15:59:27*

[@U4H19D1D2](@U4H19D1D2) I seem to have been able to replicate that issue where a pending order never appears:



```{"asctime": "2020-08-27 14:56:02,323", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.172406553", "selection_id": 22583996, "handicap": 0, "id": "138178329623238566", "customer_order_ref": "27cfde50caeb3-138178329623238566", "bet_id": null, "trade": {"id": "6cd997a5-e875-11ea-8295-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138178329623238566"], "notes": "1.172406553,2020-08-27 15:00:00,2020-08-27 14:53:16.392000,OPEN,False,22583996,Go Hard Or Go Home,0,3.7,3.7,3.75,3.65,3.8,24071.260000000002,44.0,3.640561751239103,3.6228700238460068,0.0027530273204042087,0.0028067051365076334,0.5678797216934938,0.502030814968028,-0.7126908839976814,-1.4514553590612573,-0.7126908839976814,-1.4514553590612573,0.013439251525677598,3.65,3.75,3.65", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 3.65, "size": 5.66, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}

{"asctime": "2020-08-27 14:56:02,323", "levelname": "INFO", "message": "1 order packages created", "order_packages": [{"id": "6cd997a7-e875-11ea-a46f-2016d8944b85", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x000001E40D033970&gt;", "market_id": "1.172406553", "orders": ["138178329623238566"], "package_type": "Place", "customer_strategy_ref": "BlueOcean", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}]}```

That was (and still is as I write) the last message to appear

*Tags: Deployment, Strategies*

---

**liam** - *17:19:23*

my assumption is that the issue is to do with the later orders (if there is still a problem), and that `def validate_order` is blocking

*Tags: General Technical*

---

**Newbie99** - *17:20:30*

It seems random, but I've had markets where it hasn't placed a single order (but I can see them going into pending). Is there any timing issue, where it could somehow kick them out without warning if the latency got to high?

*Tags: Performance*

---

**Newbie99** - *17:22:45*

(and latency could explain why its only happening to me, perhaps a connection / machine issue...although I've tried on AWS and have replicated so I guess its not that).



Okay cool, will try that and report back...

*Tags: Performance, Deployment*

---

**mlpanda** - *18:10:53*

Hey [@U4H19D1D2](@U4H19D1D2), in the tennis example you provided ([https://github.com/liampauling/flumine/pull/264/files|example](https://github.com/liampauling/flumine/pull/264/files|example)) you hardcoded the market_id. When I try to treat it similarly to horse racing, i.e. automatically obtain all markets, Flumine doesn't seem to be able to find any tennis markets. I tried with country_codes=["IT"] first since there is an Italian challenger match, but also tried including a bunch like below:



```strategy = TestStrategy(

    market_filter=streaming_market_filter(

        event_type_ids=["2"],

        country_codes=['AX', 'AL', 'DZ', 'AS', 'AD', 'AO', 'AI', 'AQ', 'AG', 'AR', 'AM', 'AW', 'AU', 'AT', 'AZ', 'BS', 'BH', 'BD', 'BB', 'BY', 'BE', 'BZ', 'BJ', 'BM', 'BT', 'BO', 'BQ', 'BA', 'BW', 'BV', 'BR', 'IO', 'BN', 'BG', 'BF', 'BI', 'CV', 'KH', 'CM', 'CA', 'KY', 'CF', 'TD', 'CL', 'CN', 'CX', 'CC', 'CO', 'KM', 'CG', 'CD', 'CK', 'CR', 'CI', 'HR', 'CU', 'CW', 'CY', 'CZ', 'DK', 'DJ', 'DM', 'DO', 'EC', 'EG', 'SV', 'GQ', 'ER', 'EE', 'SZ', 'ET', 'FK', 'FO', 'FJ', 'FI', 'FR', 'GF', 'PF', 'TF', 'GA', 'GM', 'GE', 'DE', 'GH', 'GI', 'GR', 'GL', 'GD', 'GP', 'GU', 'GT', 'GG', 'GN', 'GW', 'GY', 'HT', 'HM', 'VA', 'HN', 'HK', 'HU', 'IS', 'IN', 'ID', 'IR', 'IQ', 'IE', 'IM', 'IL', 'IT', 'JM', 'JP', 'JE', 'JO', 'KZ', 'KE', 'KI', 'KP', 'KR', 'KW', 'KG', 'LA', 'LV', 'LB', 'LS', 'LR', 'LY', 'LI', 'LT', 'LU', 'MO', 'MG', 'MW', 'MY', 'MV', 'ML', 'MT', 'MH', 'MQ', 'MR', 'MU', 'YT', 'MX', 'FM', 'MD', 'MC', 'MN', 'ME', 'MS', 'MA', 'MZ', 'MM', 'NR', 'NP', 'NL', 'NC', 'NZ', 'NI', 'NE', 'NG', 'NU', 'NF', 'MK', 'MP', 'NO', 'OM', 'PK', 'PW', 'PS', 'PA', 'PG', 'PY', 'PE', 'PH', 'PN', 'PL', 'PT', 'PR', 'QA', 'RE', 'RO', 'RU', 'RW', 'BL', 'SH', 'KN', 'LC', 'MF', 'PM', 'VC', 'WS', 'SM', 'ST', 'SA', 'SN', 'RS', 'SC', 'SL', 'SG', 'SX', 'SK', 'SI', 'SB', 'SO', 'ZA', 'GS', 'SS', 'ES', 'LK', 'SD', 'SR', 'SJ', 'SE', 'CH', 'SY', 'TW', 'TJ', 'TZ', 'TH', 'TL', 'TG', 'TK', 'TO', 'TT', 'TN', 'TR', 'TM', 'TC', 'TV', 'UG', 'UA', 'AE', 'GB', 'US', 'UM', 'UY', 'UZ', 'VU', 'VE', 'VN', 'VG', 'VI', 'WF', 'EH', 'YE', 'ZM', 'ZW'],

        market_types=["WIN"],

    ),

    market_data_filter=streaming_market_data_filter(fields=["EX_LTP", "EX_ALL_OFFERS", "EX_MARKET_DEF", "EX_TRADED"]),

    max_order_exposure=10000,

    max_selection_exposure=105,

    context={"stake": 100},

)```

When I run this, `framework.markets._markets` is empty. Might be a stupid mistake on my side, but if I change the event_type_id to "7" then I do get a bunch of markets. Any idea why this is happening?



I haven't included your scores fixes in the example above as I don't see it helping given that it finds the event_id from the market_id - and if the market_id is never present it wouldn't matter.

*Tags: Errors Debugging, Strategies*

---

**Newbie99** - *18:38:56*

`{"asctime": "2020-08-27 17:28:52,375", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.172407748", "selection_id": 24110964, "handicap": 0, "id": "138178421323748982", "customer_order_ref": "27cfde50caeb3-138178421323748982", "bet_id": null, "trade": {"id": "c6a05675-e88a-11ea-8728-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138178421323748982"], "notes": "1.172407748,2020-08-27 17:30:00,2020-08-27 17:26:42.946000,OPEN,False,24110964,Walk It Talk It,0,7.6,7.4,7.6,7.2,7.8,15228.77,54.539999999997235,7.3562828939581335,7.3548410230981025,7.51219521213161e-05,0.0005672825912416327,-0.485228770809155,-1.6962085742376443,-1.1856819494519342,1.5158875740819253,-1.1856819494519342,402.8352149156427,0.009164996444333584,7.6,8", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 8, "size": 2.14, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}`

`{"asctime": "2020-08-27 17:28:52,521", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.172407748", "selection_id": 11562443, "handicap": 0, "id": "138178421325218981", "customer_order_ref": "27cfde50caeb3-138178421325218981", "bet_id": null, "trade": {"id": "c6b6c4a4-e88a-11ea-a5ec-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138178421325218981"], "notes": "1.172407748,2020-08-27 17:30:00,2020-08-27 17:26:42.946000,OPEN,False,11562443,Bailarico,0,26,25,26,24,27,5153.51,32.36000000000058,28.535445913411476,28.548128733377446,-0.0001627451517698249,-0.02293902095003263,-0.6511582668772105,10.045226723497908,-0.1199440789187813,-41.791918890313944,-0.1199440789187813,-41.791918890313944,0.0078068834946611,29,32,29", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 32, "size": 0.43, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}`

`{"asctime": "2020-08-27 17:28:52,581", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.172407748", "selection_id": 24420530, "handicap": 0, "id": "138178421325818936", "customer_order_ref": "27cfde50caeb3-138178421325818936", "bet_id": null, "trade": {"id": "c6bfec37-e88a-11ea-a189-2016d8944b85", "strategy": "ExampleStrategy", "status": "TradeStatus.LIVE", "orders": ["138178421325818936"], "notes": "1.172407748,2020-08-27 17:30:00,2020-08-27 17:26:42.946000,OPEN,False,24420530,Selsey Sizzler,0,11.5,11,11.5,10.5,12,8648.15,12.989999999999782,11.418560202853765,11.419067823979393,-1.4023312049340216e-05,-8.680345957619678e-05,-0.49187450420717704,-0.9872627534678625,-0.5703850484523233,-1.0597854728689005,-0.5703850484523233,-1.0597854728689005,0.03665404088008629,12.5,13.5,12.5", "market_notes": null}, "order_type": {"order_type": "Limit", "price": 13.5, "size": 1.1, "persistence_type": "PERSIST", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "BACK", "size_matched": 0.0, "size_remaining": 0.0, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "status": "Pending", "status_log": "Pending"}`

`{"asctime": "2020-08-27 17:28:52,721", "levelname": "INFO", "message": "1 order packages created", "order_packages": [{"id": "c6d54903-e88a-11ea-b947-2016d8944b85", "client": "&lt;flumine.clients.betfairclient.BetfairClient object at 0x0000014904B43670&gt;", "market_id": "1.172407748", "orders": ["138178421323748982", "138178421325218981", "138178421325818936"], "package_type": "Place", "customer_strategy_ref": "BlueOcean", "bet_delay": 0, "market_version": null, "retry": true, "retry_count": 0}]}`

*Tags: Deployment, Strategies*

---

**Newbie99** - *18:40:01*

Just after this I got a high latency warning btw, maybe unrelated of course

*Tags: Performance*

---

## 2020-08-28

**liam** - *08:41:30*

really not sure on this, if you can try changing logging to debug there might be some more info (you will get a lot of logs!)

*Tags: Errors Debugging*

---

**Unknown** - *16:52:54*

[@U4H19D1D2](@U4H19D1D2), with regards to the pending orders that disappear saga, I've attached a log from the 16:40 today (Curragh- WIN market), now interestingly when the market suspends at the end the pending orders (placed approx 2 mins before the scheduled start) all fail (which looks to be correct as the market is suspended)....but the bigger question is, why did they sit in pending for the entire race, I can't work it out from the logs tbh, but hopefully you might spot something I've missed which may shed some light on it (I didn't receive any high latency warnings, but then given the timeframe, I don't think it can be a pure latency issue anyway)?

*Tags: Performance*

---

**birchy** - *21:48:46*

[@U4H19D1D2](@U4H19D1D2) just read your comment above regarding "slow" code... what's the recommended way to implement strategies that do a lot of number crunching/processing? The problem I can foresee is that by the time the calculation process is completed, the market may have updated several times, thus making any calculation results obsolete.

*Tags: Performance*

---

**Chris** - *22:33:32*

Would be interested in Liam's perspective here as well. Particularly w/r/t any architectural or Python-specific implementation details but I think in general the guideline is to ensure you have efficient one-pass (O(1)) implementations for any stats / math / decision making that you are doing on each market update

*Tags: General Technical*

---

## 2020-08-29

**liam** - *06:43:14*

Yep agree with all of that however you can adjust the streaming `conflate` to reduce the amount of updates if required 

*Tags: General Technical*

---

**Remi** - *09:40:14*

I have chosen to not play the speed game at all (for now). I am coming at it more from a math/machine learning angle. Volume is a big problem for me but when I get matched it is very reliably profitable. I have tried updating orders faster but I find that it can quickly turn into a race to the centre of the spread.

*Tags: Performance*

---

**Misha** - *09:50:17*

[@UU1URJ8L8](@UU1URJ8L8) - speed isn't really helpful to "beat" others. The randomness of delays from the Betfair exchange server and across the stream (which needs only to be milliseconds) means that trying to be the fastest is useless. Good performance is more about the ability to process all updates in real time. I am moving into in-play tennis where there is a 3 or 5 second delay to actually place orders, and all the money disappears during the point so you need to wait for a few seconds after a point anyway for the volume to "arrive"

*Tags: Performance, Deployment*

---

**Newbie99** - *11:19:43*

Just going back to your earlier point about the priority order queue, thinking about it, I think it does make sense then with regards to this masking issues such as above (i.e. slow code), what if there was another flag (like the high latency warning), that lets you know local processes aren't processing quickly enough?

*Tags: Performance*

---

**liam** - *14:47:40*

Assuming you are streaming you have `market_book.streaming_update`

*Tags: General Technical*

---

## 2020-09-01

**PeterLe** - *13:09:08*

Just a reminder; the new transaction conditions kick in today : _What are the changes?_

_•            5,000 Transactions per hour – the first 5,000 transactions within any given hour will be free of charge._  

_ _

_•            £0.002 cost per transaction – each transaction that exceeds the 5,000 transactions per hour threshold will incur a cost of £0.002._

_ _

_•            Commission Generated Offset – we will offset any fee against any commission generated (Commission Paid + Implied Commission)/2._

_ _

_•            Transaction = Bet Placed or Failed Transaction._

_ _

_A placed bet consists of any bet that is matched, cancelled or lapsed._

_Failed transaction is an action that results in a bet not being placed on the Betfair Exchange. Full descriptions of each failed transaction type can be found in the link below:_

_[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-ExecutionReportErrorCode](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Betting+Enums#BettingEnums-ExecutionReportErrorCode)_

*Tags: Errors Debugging, Strategies*

---

## 2020-09-09

**Remi** - *10:02:07*

BTW, that last race was a wonderful test for my model/strategy. Even with the total chaos I came out ahead nicely :slightly_smiling_face:

*Tags: Strategies*

---

## 2020-09-12

**damon.p.hill** - *04:41:56*

[@UU1URJ8L8](@UU1URJ8L8) I’d love to chat with you offline about your F1 strategy. I love motorsport and would like to learn more about strategy logic from you if your open to it?

*Tags: Strategies*

---

## 2020-09-13

**Newbie99** - *20:17:57*

By chance does anyone have the race result (in the format from the racecard end point) for the 18:45 from Musselburgh yesterday ('1.172950042').



For some reason I can get every other race, but that one throws up an error (I'm guessing Betfair did something at their end) and purely for OCD purposes it would be handy to have it if anyone has it to hand?



```Traceback (most recent call last):

  File "D:/Python37/webpages/bingo.py", line 41, in &lt;module&gt;

    race_cards = trading.race_card.get_race_result(market_ids=['1.172950042'])

  File "D:\Python38\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 94, in get_race_result

    (response, response_json, elapsed_time) = self.request(

  File "D:\Python38\lib\site-packages\betfairlightweight\endpoints\racecard.py", line 113, in request

    check_status_code(response)

  File "D:\Python38\lib\site-packages\betfairlightweight\utils.py", line 31, in check_status_code

    raise StatusCodeError(response.status_code)

betfairlightweight.exceptions.StatusCodeError: Status code error: 500```

*Tags: Errors Debugging, Strategies*

---

## 2020-09-14

**Peter** - *07:01:21*

[@UFTBRB3F1](@UFTBRB3F1) I think you're going to be out of luck. This for the 18:15 works, `race_cards = trading.race_card.get_race_result(market_ids=['1.172974372'])` but stick '1.172950042' in there instead and it's still throwing an http 500 (server error) response. So def. a problem at the Betfair end and one likely to affect everybody.

*Tags: Errors Debugging, Deployment, Strategies*

---

## 2020-09-15

**liam** - *20:16:08*

Hmm the data will be from an aws db so maybe I should just use ec2 but just seems such a waste to have it on all be time 

*Tags: Deployment*

---

**Alex B** - *22:41:23*

you could just turn off an EC2 instance when you’re not using it, then you’d only be paying for the associated EBS volume(s)

*Tags: Deployment*

---

## 2020-09-16

**liam** - *06:25:05*

Yeah I could but going to use it as my strategy analysis box so want it available whenever, if I have to turn it on first I won’t use it 

*Tags: Strategies*

---

**Misha** - *23:52:57*

[@U0160E9HS2G](@U0160E9HS2G) - I can't vouch for the official scores endpoint, but the website scores don't have it. You need access to the navigation part of the Betfair API to check, but sometimes you can discern by the name of the tournament. A combination of keeping your own tournament lookups in conjunction with checking the ATP/WTA/ATP Challenger/ITF Mens/ITF Womens calendars will give you the data

*Tags: General Technical*

---

## 2020-09-17

**agberk** - *14:08:04*

[@U4H19D1D2](@U4H19D1D2) RE: home server - I've got a pi (not sure what version) that I was planning to use as a home media server and had loftier goals of maybe self hosting email and other services; I forget the exact nature of the problem but it turned out it wasn't powerful enough and the architecture didn't support certain libraries. Haven't done anything since but the conclusion I came to was I would just get a full on PC in a small form factor - maybe something like this [https://www.scan.co.uk/shop/computer-hardware/desktops-home-office/barebone-intel-nucs](https://www.scan.co.uk/shop/computer-hardware/desktops-home-office/barebone-intel-nucs) - of course there's some benefits that cloud brings but no substitution for being fully in control :smile:

*Tags: Deployment*

---

**Peter** - *15:48:55*

Similar here. Used to run build development machines for my web development agency. We wanted fast processors and lots of RAM, but didn't need high end graphics and the manufacturers didn't really offer machines like that (as well as charging premium prices for decent processors). So I'd buy cheap motherboards and small form factor cases, install high end processors and RAM and mix in Ubuntu. At the time it made for really-cost effective and powerful development machines. So fast forward to today and I still have a few around which have now been repurposed to run python scripts processing or analysing sports data (often for days at a time) served to them by a shared fast 4TB disk drive onto which data stored at S3 is periodically downloaded. Next step is to convert some of those scripts to Flumine.

*Tags: Getting Started*

---

**Jonjonjon** - *22:10:52*

[@U9JHLMZB4](@U9JHLMZB4)  Did any of your machines have overheating problems? I was told that mixing high end processors with cheap motherboards causes heating problems.

*Tags: General Technical*

---

## 2020-09-18

**Peter** - *06:37:40*

They do generate a fair bit of heat. But it's never risen to the level of a problem (except on very hot days when the wife instructs me to close them down to avoid overheating the office).

*Tags: General Technical*

---

**Jorge** - *09:04:21*

Does anyone have a recommendation on any technical podcast about strategy's execution? I'm looking more into the developing tasks rather than the Math/backtesting

*Tags: Strategies*

---

## 2020-09-22

**Chris** - *03:24:42*

Hey all - is a t3.nano (2 vCPU @ 2.5ghz, 0.5 gb ram) a reasonable choice for running a simple strategy on ~50 liquid markets with 0 conflation?

*Tags: Strategies*

---

**Chris** - *03:30:39*

Second - for storage I have no idea what to get. AWS seems to define speed in IOPS, which I am researching now but haven't seen before. If I am recording all ticks + basic logging is 1k IOPS enough? (common consumer SSDs have ~50 to 100k). Is the default of 100 enough (similar to what a common HD has)?

*Tags: Performance, Deployment*

---

**Chris** - *03:33:51*

I realize I need to log + trial and error here but I am hoping to avoid the bulk of the churn by getting a second set of eyes on this guesstimate

*Tags: Errors Debugging*

---

## 2020-09-24

**Newbie99** - *10:48:15*

[@U4H19D1D2](@U4H19D1D2), that violation issue (appears) to have resurfaced (i.e. once a violation occurs no further orders are placed on that strategy via Flumine). Am wondering if they are picked up here:



```market.blotter.strategy_orders```

and being shown as executable, even though they never actually made it to Betfair (as my check looks at strategy orders and if 0 places new ones, but if I've had a violation it doesn't)?

*Tags: Strategies*

---

**Newbie99** - *12:59:35*

Haven't been able to replicate yet, so it may be the case there was actually no problem after all...however I came across something else that (I think) is worth a thought.



When an order is replaced, obviously it cancels, then places a new order, sometimes (possibly every time I guess, but I've only noticed it on occasions) this results in 0 live orders being reported, even though in reality (I would argue) it should remain at 1 throughout the process.



I use live orders as a trigger (i.e. when all done, send the next lot down), so its easy enough to workaround, but (just thinking out loud), should the logic be tweaked show that order as live throughout the entire replace process, rather than the current logic?

*Tags: Deployment*

---

## 2020-09-27

**Dave** - *16:23:01*

Ahh efinancialcareers, perhaps _the_ worst "journalism" in the finance industry. I recall licensing is silly expensive, and their free licenses used to have some restrictions (time limit and performance-based I think?). Not sure if the latter is still the case. Also, that article is total BS :joy:

*Tags: Performance*

---

**Jonjonjon** - *19:40:30*

Is redis suitable for storing/querying Betfair streaming files?

*Tags: General Technical*

---

**Oliver Varney** - *19:41:57*

as [@U4H19D1D2](@U4H19D1D2) said, if your doing basic stuff why not just use flumine / betfairlightweight

*Tags: General Technical*

---

**Jonjonjon** - *19:43:45*

I'm currently using bflw/flumine. But was wondering if something like redis would help with analysis.



For example, if I wanted to query the average trading range of prices, the prior day before a race, would Redis be better than just pumping the files through BFLW and getting the results using plain Python code?

*Tags: Strategies*

---

**Jonjonjon** - *19:47:12*

But perhaps any overhead in learning/implementing redis would be more costly than the benefits of using it. It's good to have all your code in one place. If I have separate analytical code, it could double up my chances of errors.

*Tags: Errors Debugging*

---

**Oliver Varney** - *19:48:28*

I thinks its secondary, you have a requirement first then if you need a feature that is suited to an in memory database /key-value store you use it.

*Tags: Feature Engineering, Performance*

---

## 2020-09-28

**river_shah** - *13:14:59*

not sure about pycharm, but certainly for clion + python plugin have managed to get all include directories and python paths to work seamlessly together. all autocomplete and reference look ups work for a mixed code project.

*Tags: General Technical*

---

**liam** - *13:42:18*

I thought you have to create them yourself when not python

*Tags: General Technical*

---

**river_shah** - *16:10:17*

how do I get strategy’s runner limit orders please inside `process_market_book` ? `runner.orders` seems to not be populated despite outstanding limit orders

*Tags: Strategies*

---

**liam** - *16:11:07*

flumine uses streaming so the marketBook does not contain orders as per the docs

*Tags: General Technical*

---

## 2020-09-30

**Misha** - *11:37:04*

My view would be that market making with Betfair and various sports is very specific, and you would probably do best by studying the particular markets and poring through the data. I can tell you that there is basically nothing in common between making markets for pre-play horse racing (have done that) and the market making employed for in-play tennis (have studied that in detail). Background info is always good, but nothing beats detailed experience. So would help (of course) but probably not to any great extent

*Tags: General Technical*

---

## 2020-10-02

**liam** - *07:58:37*

I know but 



`If any candidate withdraws for any reason, including death, all bets on the market will stand and be settled as per the defined rules (Updated - 20/06/2020)`

*Tags: Deployment*

---

**Misha** - *11:50:54*

But the latest developments throw everything "up in the air" anyway. Hard to see how today's news is good for Trump though

*Tags: General Technical*

---

**azevedo** - *12:45:50*

I like that philosophy [@UBS7QANF3](@UBS7QANF3) , agree :+1:



I definitely noticed people market making markets like correct score in football (pre-match) in less liquid games; where they would quote decent sizes at widish spreads without much actually matched on that market or even Match Odds for that event. But in those cases they must be relying on their own model quite heavily? (or possibly wider market/bookies)



what’s your view on models (or perhaps importance of models) in market making?

*Tags: Strategies*

---

**Mo** - *14:36:58*

I don't know who is making those correct score markets. I agree that there doesn't seem to be much action but with the wide spreads you are going to be getting good value on any bets you book. So it's probably about scalability so that you're market making as many matches as possible and picking up the odd bet here and there on each one.



Importance of model probably depends how dynamic the markets are; if you're talking pre-event football then it's probably more important that you have a good market feed that's plugged into Asia and you're not posting prices when the lineups are announced - i.e. you're looking for times when there is no price trend and you can just profit from volatility. In some markets maybe it's enough to assume the true price is the middle of the spread, or adjusted for the weight of money on either side, but in a trending market you'll probably get killed without your own opinion of what the true price. Of course, the ideal situation is a good model where you're happy to take a position.

*Tags: Strategies*

---

## 2020-10-05

**D C** - *09:53:56*

Even better a full list of them. Google is not proving to be at all helpful in this regard.

*Tags: General Technical*

---

**Mo** - *09:55:00*

No problem :+1:

*Tags: General Technical*

---

**Newbie99** - *20:00:24*

Sorry, I meant when streaming

*Tags: General Technical*

---

## 2020-10-06

**Remi** - *11:02:28*

[https://docs.python.org/release/3.9.0/whatsnew/3.9.html](https://docs.python.org/release/3.9.0/whatsnew/3.9.html)

*Tags: General Technical*

---

**Remi** - *11:04:32*

For my phone etc I always dread updating to the new version but I feel with python it always improves :slightly_smiling_face:

*Tags: General Technical*

---

**liam** - *20:36:47*

[@UU1URJ8L8](@UU1URJ8L8) it’s great if you are using it for your own software but as soon as you make something open source you are very limited by the oldest version, it will be years until we can clear up type hints / use the new features in bflw :sob:

*Tags: Feature Engineering*

---

**Jonjonjon** - *21:31:00*

[@U4H19D1D2](@U4H19D1D2) Would it be possible to change



```def customer_order_ref(self) -&gt; str:

    return "{0}-{1}".format(self.trade.strategy.name_hash, self.id)```

to:



```def customer_order_ref(self) -&gt; str:

    return "{0}{1}{2}".format(self.trade.strategy.name_hash, self.sep, self.id)```

, where self.sep defaults to '-'



?

*Tags: Strategies*

---

## 2020-10-07

**Remi** - *08:50:57*

Obviously old bflw could still be available to them

*Tags: General Technical*

---

**Jonjonjon** - *09:44:32*

Within my own code, I plan on changing it to help identify entry/exit trades. Hopefully it could be useful for other people, and it won't increase the risk of collisions so it will be safe.

*Tags: General Technical*

---

**Jonjonjon** - *10:41:04*

[@U4H19D1D2](@U4H19D1D2) I like your comment here:



[https://github.com/liampauling/flumine/issues/267](https://github.com/liampauling/flumine/issues/267)



_*Stop Loss*_

_Basically Hedge used by those who want to lose money quickly.._

*Tags: General Technical*

---

**liam** - *10:46:28*

Not sure if I like the idea of the framework making offset orders anymore and pushing to maybe have the strategy itself handle any offsetting/hedging etc.

*Tags: Strategies*

---

**Mo** - *10:59:02*

People don’t have infinite bankrolls. The ability to remain solvent and be able to place future bets is important for maximising long term wealth

*Tags: General Technical*

---

**liam** - *11:08:39*

Bankroll is crucial, my understanding is that traders look around the 1-3% ROI mark with the focus on turnover to get the profit up. When I started I was the worst at getting value and then hedging but when you look at the results it just doesn't make any sense.



[@UBS7QANF3](@UBS7QANF3) I am surprised you don't agree, finding value is the hard part, why give it away?

*Tags: General Technical*

---

**Newbie99** - *11:11:35*

[@UUE6E1LA1](@UUE6E1LA1) thats actually how I arrived at my first strategy, ha! I intended for it to be trading and based on that logic realised that it didn't make sense to close out the trades!

*Tags: Strategies*

---

**liam** - *11:30:45*

kelly stakes (sort of)

*Tags: Strategies*

---

**Oliver Varney** - *11:31:47*

my point is this, with at strike rate of 70% you can easily run a trading strategy with 50 points, and that is conservative. So at the early stage you can virtually compound stakes every day

*Tags: Strategies*

---

**Twatter** - *11:36:14*

[@UFTBRB3F1](@UFTBRB3F1) I agree with you. Although I'm a newbie to the science and maths of it, Value betting for me is very different to Trading/scalping. I could manually trade 4 or 5 horses pre race and make a profit based on odds movement that I might be able to in theory create an automated strategy out of it. But why would I want to simply back those 4 or 5 horses to win and let the bet ride?

*Tags: Strategies*

---

**Newbie99** - *13:42:11*

I would argue that question can not be answered without knowing timescale

*Tags: General Technical*

---

**Twatter** - *13:42:42*

I can't help but translate this into the Stock market world. If an investor took a position on a stock/company, then the best positions are made when the price is lower than perceived value of the company. But that might not eb true forever...

*Tags: General Technical*

---

**Newbie99** - *13:46:45*

No problem at all, its not personal and I'm not claiming I can do so, I'm merely engaging in the debate :slightly_smiling_face:

*Tags: General Technical*

---

**Twatter** - *13:47:14*

Whether the value is squandered or not - isn't it a case that someone may want to squander larger profits by hedging and overall drawdowns and variance? i.e. Value sacrificed for variance as per a strategy

*Tags: Strategies*

---

**Michael** - *13:53:54*

That's their problem. The maths is the same.

*Tags: General Technical*

---

**Jonjonjon** - *13:57:57*

I almost wish I hadn't asked the original question.

:older_man:

*Tags: General Technical*

---

**Twatter** - *14:00:24*

Hahaha - to be honest I'd be pleased if I could reach a mediocre profitable strategy! I'm way off at the moment...

*Tags: Strategies*

---

**Newbie99** - *14:10:19*

Anyway we digressed there slightly....I think the original point was about whether offsetting orders should be included in flumine, in a roundabout way I was saying I thought for some they might be useful (even if not optimal)!!! :zipper_mouth_face:

*Tags: General Technical*

---

**liam** - *14:11:26*

[https://github.com/liampauling/flumine/issues/267#issuecomment-687744021](https://github.com/liampauling/flumine/issues/267#issuecomment-687744021)

*Tags: General Technical*

---

**Jonjonjon** - *14:14:46*

In my personal (using BFLW, not Flumine) code, I have code that does automatic offsets.



So I try to enter with a fill or kill. If that gets filled, it places the offset order. This is a limit. Not a stop. I don't use stops. I scale my bets such that I am willing to ride out any potential loss on an individual trades.



However, if I did not use a fill or kill, the logic could be complicated. As what should the code do if there is only a partial fill? What if it is partially filled, and the appropriate hedge size is not a valid bet size?



What if it is partially filled in really small clips? A bot that hedged every small clip could run afoul of transaction limits/costs.



What if the user wants to cancel the original, partially filled trade, and the hedging state is left in a mess due to reasons stated above?

*Tags: General Technical*

---

**Newbie99** - *14:21:49*

one other idea...perhaps a quick win, maybe introduce a new parameter, so that when flumine (by default) checks to see if an existing order is in place, that can be over ridden easily (I know of course people can tweak the code, but its neater if its done at source), so it allows one back and one lay or even x of each (as opposed to just 1 live order at any given time), that would allow people that search for value on boht sides to leave at least 1 back and 1 lay simultaneously and if anyone was inclined to trade, it would also allow that.



Does that make sense and sound vaguely sensible?

*Tags: Deployment*

---

**liam** - *14:27:37*

just override `validate_order` in the strategy, I think [@ULDAVFDRP](@ULDAVFDRP) does this

*Tags: Strategies*

---

**Michael** - *15:05:00*

[@U01B8031PM1](@U01B8031PM1) I'm not sure about Star Lizard specifically, but the world of big stakes betting is very interesting and unknown to most people. There are networks of agents connecting people to counter-parties, foreign skins on Betfair with amplified liquidity and much more besides. Much of it is quite murky. I had a little insight into it when I helped out a footie syndicate and it was totally fascinating.

*Tags: Strategies*

---

**Dave** - *15:12:38*

I wrote a long thread on it on the betangel forums a while ago...that "auto offset bet" feature has probably helped make everyone money but the user :sweat_smile:

*Tags: Feature Engineering*

---

**Dave** - *15:14:58*

It's nothing groundbreaking or different to what the guys are saying here really, but sure

```A strategy only has positive expected value if each bet that you take is a value bet (e.g. you think there's an 80% chance of something happening, market thinks there's only a 50% chance, so you back it).



Assuming your opening trades *do* take value then you should not trade out of it _unless_ your closing trade is ALSO a value trade. If you close 100% of your opening trades by default without considering value then your closing trades are going to have negative value over time (due to fees and spread), and you'll lose money through them.



Ideally, forget the idea of "closing" a trade. Just run two strategies independently, a backing strategy and laying strategy. Ensure each of them only takes a position when there's value, and that'll make sure they have positive EV in long term. Sure, there'll be cases when you back something cus you think there's value, and 10 mins lay it because you think there's value given new stuff that's happened in the game. It looks like you closed your original back, but really you just took two value bets.



Unless you take the same approach with scalping, you're just taking an uneducated guess and over time will lose money. To apply the same principle to scalping, you ought to think: my prediction of no goal over next 5 mins is X% and the market says Y%. If X% &gt; Y% then open your scalping position as this is value. Then when the 5 mins is over, revaluate your forecast. If X% &gt; Y% then there's no reason to close your scalp. If X% &lt; Y%, then you will close your scalp with a value bet.





Of course this assumes that your detection of value is actually somewhat sensible.```

*Tags: Strategies*

---

**Michael** - *15:54:41*

Then you know that you're going to get a +EV bet and a -EV bet and that the +EV one will out-weigh the -EV so overall you'll be matching +EV bets. We're all making individual -EV bets all the time because we can't avoid it, that's fine. It's knowingly matching -EV bets that's the problem and when you 'trade out' that's what you're doing. EDIT: You might also be getting 2 +EV bets because the 0EV price was mid-spread.

*Tags: General Technical*

---

**Michael** - *15:59:16*

I don't have a dog in the Flumine fight because I don't use it, but I can see why Liam doesn't want to institute a feature that is guaranteed to lose money and I just have a little demon in me that won't stand by when people say you can win without getting value.

*Tags: Feature Engineering*

---

**Oliver Varney** - *16:13:53*

Michael I agree 100% with what your saying, but would you say there are strategy combined with bankrolls that can outperform even by giving up value on the hedge?

*Tags: Strategies*

---

**Oliver Varney** - *16:15:00*

when I say give up I mean lets say you have a strategy that has 20% ROI on bet to win vs 18% ROI on hedging out

*Tags: Strategies*

---

**PeterLe** - *19:20:00*

Enjoyed reading the posts this afternoon. Just to throw my hat into the ring, although there are always exceptions to the rule, there are many very successful long term traders who have used nothing more complicated that GCSE maths (probably not even that), myself included. Ive said it before that if I were to sell my strategy on Ebay, people would probably want their money back when I disclosed it! :grinning: Simplicity is often overlooked IMHO

*Tags: Errors Debugging, Strategies*

---

**Michael** - *21:32:23*

I'm going to expand on why 'closing' bets are inherently loss making because it illustrates a fundamental feature of profitable betting that is terribly important but isn't generally well understood and it might help some people.

*Tags: Feature Engineering, Strategies*

---

**Michael** - *21:34:57*

Our example gives us 3 points that we can put on the graph to help us plot the line. A bet with a very negative EV (that's your back bet at 1.01) would be virtually certain to match, so you have a point on your graph at the top left hand corner. A bet with a very positive EV (your back at 1000) would be extraordinarily unlikely to match – so that's a point in the bottom right corner. Your 0EV bet (backing at 2) goes in the middle of the X axis, and it was likely but not certain to match so it's almost at the top of the Y. Now that you've got three points you can guess the shape of the curve that connects them, for these purposes it doesn't matter exactly what shape you draw, all that matters is that you can see that the right hand half of the line (where the +EV bets are) slopes down from a probability a little bit below 1 (slightly less than certain) to almost 0 (virtually impossible).

*Tags: General Technical*

---

**Newbie99** - *21:43:42*

That was nicely articulated, you've made it very easily to visualise there, much appreciated...although I do have one question if I may...



If you have 2 strategies for value betting, 1 only ever backs, 1 only ever lays (but independent) and execution is only if value is there (i.e. you never close out simply because you have a position), are you eroding value there? I'm sort of confusing myself thinking 1 has to be -EV, but also if the price moves, could they not both be +EV at the point of execution?

*Tags: Strategies*

---

**Michael** - *22:08:14*

Here's where this problem comes from: A bunch of software vendors have a vested interest in getting people to 'trade' on their platforms, and Betfair are into that too. And the vendors and betfair want to target people who wouldn't be caught dead spunking a hundred quid on backing a dog because that's gambling and gambling is for mugs. So they make up a load of shit about how placing bets somehow isn't betting even though you're doing it on a site called BETfair and they say that the maths of gambling (which is really pretty simple) doesn't apply because  somehow it's not gambling even though it's regulated by the gambling commission who's only job is to regulate gambling (there is no 'trading commission') . Then for years on end they pump out their crap to people who want to hear it and those people repeat it and other people somehow start to think it's true even though when you step back from it it's obviously just horse shit and anyone who can do basic maths (like adding and subtracting) can prove it with a pencil. It honestly makes me furious.

*Tags: Strategies*

---

**Michael** - *22:26:56*

Sorry I mis-read your question - Probabilities do change in time so it's rational to place different bets at different times. In the scenario you mention it was first rational to place your initial back bet at 2.01 (or whatever better than 1.5) and later it might be rational to place a lay bet anywhere better than 2 because the situation has changed, but those two bets have no relationship to each other, they are two separate +EV bets. The fact that they're both in your account rather than being struck by two different people is of no significance.

*Tags: General Technical*

---

**Misha** - *22:48:02*

On the "hedging issue. One thing I have learnt is that if you have a successful model, you never hedge (learnt that by working for big clients). Why minimise profits if the model is successful overall?

*Tags: Strategies*

---

**D C** - *23:23:05*

[@U016535QCJ2](@U016535QCJ2) "Why minimise profits if the model is successful overall?" - this is a key point though. How many recreational users on Betfair have the skills to gather a dataset and generate a statistical model and then validate it to the extent that you are confident enough in your estimates that you would "know" the size of your edge? It might even be argued that to get a REALLY successful model you need access to bespoke data that hardly anyone else has access to. Yes, with a good model you can "know" how +EV a particular bet is going to be and even optimise profit with Kelly staking, but the key is knowing what the true 0EV price actually is (or at least a tight confidence interval around it). Understanding the concept of value IS just basic probability but that may well be beyond a lot of users of the exchanges - but almost everyone would see the merits of piling onto a steamer and (hoping) that they can get off before it reverses so it is completely understandable why many people hedge. I am currently hedging +EV positions and I acknowledge that what I am doing is foolish but I do so purely to help counter the variance. As [@UGV299K6H](@UGV299K6H) says, this can be alleviated by appropriate staking and I am working to correct this element of my strategy and long term I will stop doing so (assuming the edge disappears).

*Tags: Strategies*

---

## 2020-10-08

**Mo** - *10:31:11*

`Why hedging at negative EV is optimal - a rebuttal`

_Including math for [@UGV299K6H](@UGV299K6H)’s delectation_



Imagine the following scenario:



• You have backed a selection pre-event at odds of 2.0

• Your model gave the fair probability as 52% (and it's right)

• You calculate the Kelly fraction to be 4% of your bankroll

• But you're sensible and are using half Kelly so you actually bet 2% of your bankroll

The match goes in-play:



• Unfortunately, your selection performs poorly and the odds move against you

• The best lay on your selection is now 3.0

• Your model gives the fair probability as 33.5% (and it's right)

• This means laying the selection has an EV of -0.5%

• The optimal Kelly stake given your existing position is approximately 1% of your bankroll!

• Kelly is telling you to hedge at negative EV! :scream:

• Again, you're sensible so you actually bet the half Kelly stake of 0.5%

Application of Bayes theorem gives us the probability that your selection hits odds of 3 as 0.72180 (5 d.p.) so we can work out that your selection wins without ever hitting odds of 3 as 0.27820.



Now let's simulate this, generating 10,000 runs of 10,000 successive bets each. We'll do this for both hedging and no hedging:



```no_hedge_bets = np.random.choice([1.02, 0.98], size=(10000, 10000), p=[0.52, 0.48])

hedge_bets = np.random.choice([1.02, 1.01, 0.985], size=(10000, 10000), p=[0.278195489, 0.241804511, 0.48])



no_hedge_cumulative_bank = np.cumprod(no_hedge_bets, axis=0)

hedge_cumulative_bank = np.cumprod(hedge_bets, axis=0)



print(np.median(no_hedge_cumulative_bank[9999,:]))

print(np.median(hedge_cumulative_bank[9999,:]))```

```403.69789599466213

739.0367526793249```

The _median_ terminal bank of the hedging strategy is 83% larger than no hedging.

*Tags: Strategies*

---

**Misha** - *10:39:40*

Alas, no model gets EV correct - the better the model, the closer you get on average. But no individual bet is ever guaranteed to be correct, or even close

*Tags: Strategies*

---

**Mo** - *10:41:55*

[@U016535QCJ2](@U016535QCJ2) if you have a winning model you are going to achieve some positive ROI over the long term. Using half Kelly is an excellent way to protect yourself against model inaccuracies. Using a smaller fraction is even more protection. I like to use 1/6th. Adapting the example to a different fraction is left as an exercise to the reader

*Tags: Strategies*

---

**liam** - *12:10:09*

Your maths is wrong, when you treat the two bets separately the second will show negative EV (as expected). I believe the problem lies in the combing the two probabilities at the different times, once the selection drifts to 3 its chance of winning changes and thus the initial probabilities can no longer be used.



I don't think its mathematically possible to accurately predict win, win with drift and lose as you have with 0.27, 0.24 and 0.48 because the last two are related. What you can say is that the the selection drifts to 3.0 72% of the time which means 72% of the time we place the negative EV bet.

*Tags: General Technical*

---

**Jonjonjon** - *12:59:25*

We seem to have diverged quite a lot from the original point of the question.



Could/should we implement offset orders within Flumine framework? Or should users who wish to use them implement their own solutions?

*Tags: General Technical*

---

**Michael** - *13:08:36*

[@UBS7QANF3](@UBS7QANF3) thanks that's a nice reply. I can't get into this much right now because I'm doing something else but quickly: I've got two point to make. 1: Your example closes selectively and I think that's not fair - IE you're not accounting for the other scenarios where the market goes in your favour and you close out for a loss anyway. You've answered the general case with a specific case. The 'open, wait close' strategy is decided before the opening bet is placed, you don't get to wait and see how your event goes. The 'open' bet is triggered by a signal of value but the 'close' bet is just triggered by the 'open' bet matching. 2: You haven't refuted any of my points or the structure  of my argument.

*Tags: Strategies*

---

**Remi** - *13:45:06*

Suppose that you are betting on something which you know is a fair coin. We are pre-play, coin is not in the air yet. You are 95% sure that the market will be stable where you can back at 2.1 and lay at 2.06. What do you do?



You might see the positive EV, perhaps do the kelly thingy, and back 3.62% of your bank at odds 2.1. Great, you made a positive EV bet. Congrats.



You could also back 10% of you bank, then hedge at 2.06 (insert nEgAtIvE eV spongebob meme) and go for another course of the same. You estimate that there is enough volume and stability to do this round trip many times on average. Okay, so you can make your initial bet bigger than kelly because you expect to be able to get out and you get to round trip this a few more times.



You end up with more money by making negative EV bets.

*Tags: Strategies*

---

**D C** - *13:53:04*

You need to know your expected loss in the 5% of cases where you don't get things fall your way (and anyway what is the CI around that 95%??). If such info were available you could make an informed decision on your expected returns based on strategy X but without them who knows?

*Tags: Strategies*

---

**D C** - *13:59:39*

Yes but what you are modelling here is price movement direction. I mean you could add strategy 3 into this - back at 2.1 and take the value, then in your 5% of cases where the price drifts out more, back again at even more positive EV.

*Tags: Strategies*

---

**Remi** - *14:00:37*

No you can’t, then you would bet more than kelly suggest.

*Tags: Strategies*

---

**D C** - *14:02:59*

You don't need to use kelly if you can get 2.1 on a coin toss every time. Maybe you should but its not compulsory. I mean in your scenario, every price mentioned is +EV so you can't fail to make money anyway unless you have very poor stake management!! I would be happy taking that 2.06 as a fire and forget and count my money at the end of the year (barring some extreme variance that killed my bankroll)

*Tags: Strategies*

---

**Misha** - *14:04:02*

I think you are getting into circular arguments making assumptions using accuracy that isn't possible. Any modelling you do on any market is so variable that you can't guarantee anything close to a set percentage. Real EV plots can be pretty much all over the place, and if your returns increase with EV then you are doing well

*Tags: Strategies*

---

**Misha** - *14:07:19*

My view is that if your model is good you just bet as much as you can within the variance that you can expect. That's how all the really big players run - they trust the model implicitly and just let it go

*Tags: Strategies*

---

**Remi** - *14:28:20*

This is much like a vanilla short-volatility strategy on the stock exchange, e.g. short-VIX

*Tags: Strategies*

---

**Mo** - *14:46:12*

This is not intended to address the question of stop losses specifically although I think it might be possible to reframe it without much effort. I am only showing that there are situations where not only is it good to place a negative EV bet but it is in fact optimal. 

*Tags: General Technical*

---

**Michael** - *16:50:41*

Yeah I don't have any problem with that and you're much better qualified on the Bayesian stuff than I am so I'm not even going to go there. My purpose in the discussion above was to address really basic subjects like the idea that it might be wise to decide to trade out of a bet whatever happens before you've even placed it, that trading 'isn't betting' and the basic concept that your bets have to be +EV or you can't win and I don't think you'd disagree with me on any of those things?

*Tags: Strategies*

---

**Michael** - *16:56:15*

Your example above is very specific, quite theoretical and omits a few home truths (for example assuming that it's possible to scale stakes according to Kelly without sacrificing value). That doesn't make it wrong, but it limits its application to the general case - I think you've shown that in a few special cases there might be a reason to make a -EV bet, but for practical application for the 99.99% I think 'always bet with +EV' is the rule to go with.

*Tags: Strategies*

---

**Mo** - *17:10:00*

For illustration purposes it has to be specific. I agree there are shortcomings, such as not taking account of commission, that the bank cannot scale infinitely (but the flip side is that practically speaking once the bank reaches a small enough size you are wiped out), and that the mean of the unhedged final return is greater than the mean of the hedged. However, I don’t believe that any of these things affect the conclusion and with an 83% better median return there is a lot of wriggle room for the conclusion to be the same, just not as large a disparity. Personally I think that you saying for almost all cases always bet with +EV is _exactly_ the problem. This is simply not true and rules like this persist the misinformation. Everyone can benefit from negative EV hedges to grow their bankroll faster and larger. 

*Tags: General Technical*

---

**Michael** - *18:09:31*

I could sign up to this without problem if the title was different. 'Why hedging at -EV is optimal' implies it's always or usually optimal - which in fairness is not what I think you mean.

*Tags: General Technical*

---

**Mo** - *18:13:12*

I don’t disagree with you but I did have that in mind with odds that are not extreme, a medium size edge on the initial bet and the idea of a pre-event bet followed by a hedge in-running. I think that football or tennis markets could easily support the kind of sizes we’re talking about with a six figure bankroll

*Tags: General Technical*

---

**Michael** - *19:19:04*

1: All profitable betting that is sustained over a large number of bets is dependant on those bets having positive expected value at the time of placement on aggregate and there is no exception to this.

*Tags: Errors Debugging, Strategies*

---

**Michael** - *19:19:19*

2: After placing a bet any decision about placing further bets on the same selection must be contextual if it is to increase profits or optimise growth of bankroll. Making a decision to place a 'closing' bet before placing an 'opening' bet (as in the classic 'trading' scenario) is a bad proposition.

*Tags: Strategies*

---

**Michael** - *19:20:52*

3: As [@UBS7QANF3](@UBS7QANF3) has illustrated: in situations where a market will support escalating stakes some well judged -EV hedging can facilitate better growth of bank roll. Whether this is workable in practice depends on the specific character of markets in question. In markets that won't support escalating stakes Mo's illustration is not applicable.

*Tags: General Technical*

---

**Remi** - *19:25:34*

&gt;  Making a decision to place a ‘closing’ bet before placing an ‘opening’ bet (as in the classic ‘trading’ scenario) is a bad proposition.

That is actually exactly what I suggested in the example I gave. You could even (in theory) back 10x your bankroll and hedge it all away at negative EV. But you need to place a closing bet first because otherwise you can’t reach that volume.

*Tags: Strategies*

---

**river_shah** - *19:44:38*

[@UU1URJ8L8](@UU1URJ8L8) the problem setup you have would better be seen as a multivariate markowitz portfolio optimisation problem. if leverage is allowed and there is guaranteed payoffs then both multivariate kelly or markowitz would say to invest to max of allowed leverage to get the risk on. regarding doing negative ev trades, for bets or assets with known covariance matrix, it is very much permissible (infact recommended) to do negative ev trades to maximize risk reward. please notice in equations on page 4 and 5 that there is absolutely no requirement to clamp weights to 0 or negative for assets where asset return is negative ([https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/lecture-notes/MIT18_S096F13_lecnote14.pdf](https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/lecture-notes/MIT18_S096F13_lecnote14.pdf))

*Tags: Getting Started, Strategies*

---

**river_shah** - *19:47:13*

the thing with gambling unlike equity portfolio trading is that we are talking of unit dim covariance matrix, hence kelly and markowitz both result in the same answer and you really should not be doing -ev bets / trades

*Tags: Strategies*

---

**river_shah** - *19:52:03*

no, in the case of arbitrage you max out to your bankroll + leverage. i am speaking here theoretically. lots of things go bump in arbs.

*Tags: General Technical*

---

**river_shah** - *19:54:06*

in the idealised setting, you’d invest 100% of the bankroll.

*Tags: General Technical*

---

**Newbie99** - *19:54:24*

I read point 3 as covering [@UU1URJ8L8](@UU1URJ8L8)'s point (I think). What I believe [@UGV299K6H](@UGV299K6H) is saying there is that in specific markets you could have a unique scenario (and this only works if bankroll is limited), where (very simplistically) the following could occur.



Lets say you only have £10 in your account, nothing more, you do the following:



fair value = 3 (or higher, doesn't matter so long as its above 2.9)

trade 1: back £10 @ 3

trade 2: lay £10 @ 2.9

trade 3: lay £10 @ 2.9



You now have a +EV bet, with the same risk going in-play, but your return is higher, than had you initially taken the +EV bet and layed £10 @ 2.9 initially.



At least I think that's (simplistically) the point (obviously if not bankroll limited you could just lay in larger size).

*Tags: General Technical*

---

**liam** - *20:23:04*

All bets are independent regardless of the underlying market, just because you placed that first bet doesn’t make the second different in terms of its eventual ev. 



I don’t agree with your probabilities surrounding your hedged scenario and I don’t understand how this proves you can increase your wealth based on a fixed bank because your backtest uses a new bankroll on each execution.

*Tags: Errors Debugging*

---

**birchy** - *21:29:56*

Minimising losses is just as important as maximising profits, so taking the "optimal" path will rarely have a negative impact on the bottom line. Anyone who has ever played Heads Up poker will have heard of Nash equilibrium and that is basically a -EV strategy that becomes +EV if the other player plays sub-optimally. As with all things related to gambling, profits are made from others making mistakes...

*Tags: Strategies*

---

## 2020-10-09

**Mo** - *07:10:37*

I didn’t say anything about a fixed bankroll. The entire point is to compound the winnings. 

*Tags: Errors Debugging*

---

**Jonjonjon** - *20:46:16*

When I run the flumine integration tests for the first time after starting Pycharm, I need to change the working directory from:



`/home/jon/PycharmProjects/flumine/`



to



`/home/jon/PycharmProjects/flumine/tests`



How can I top having to do this serveral times per day?

*Tags: Getting Started, Deployment*

---

## 2020-10-15

**D C** - *09:33:41*

A laptop is just a laptop yes. I assumed it would be clear but what I mean is a laptop that comes pre-installed with linux on it and in which all hardware is chosen such that it will run without issue on linux. Not many places seem to do this, hence the question.

*Tags: Getting Started*

---

**Twatter** - *09:43:57*

(actually - the only drivers I've ever had problems with on Linux are Blu ray drivers/drives, but these days most laptops don't come with them anyhow...)

*Tags: General Technical*

---

**Chris** - *09:44:14*

Yeah, would also agree, unless you've got some specific pieces of hardware you're looking to utilize with the laptop the last 2-3 I've purchased with Windows installed I've had no problems with installing Ubuntu/Fedora on them and no problems with any hardware working on it, bluetooth/wifi etc. assume are the biggest concerns

*Tags: Getting Started*

---

**Jonjonjon** - *10:19:33*

Random question... But is the RTX 2060 a gaming graphics card? If so, would it be useful on Linux?

*Tags: General Technical*

---

**agberk** - *13:26:53*

I put together a new desktop a few months ago; there was no way I was moving to Win10 so it was time to make the switch to Linux only for me. I came across Entroware and made an enquiry with them since I wanted a bit of customisation from the desktops they offered.



On their About Us page they literally say "No challenge is too big." I asked to use a different case and they wouldn't accommodate. They also didn't list the exact motherboard model (was considering doing some horrible GPU passthru for a Windows VM for gaming and mobos need supporting virtualisation features) and they wouldn't tell me what it was because I might mess around with it and void the warranty? I appreciate getting a laptop is slightly different but it still completely put me off them.



As an aside, gaming on Linux has been surprisingly painless. Lots of games run natively and most that don't run in Steam's Linux runtime or Proton (just an option to select in Steam). The only remaining annoyance is that most anti-cheat software doesn't run on Linux so you can't play certain online games without getting banned. I haven't tried it yet but my plan for those types of games (and anything which isn't compatible) is to go for one of these cloud gaming services like GeForce NOW.

*Tags: Feature Engineering, Strategies*

---

**Jonjonjon** - *13:29:21*

From Ubuntu, do I just log into steam, and then click the button to install it? Do I need to worry about security? This PC is my work machine for BFLW. I don't want to break it.

*Tags: Getting Started*

---

**D C** - *13:30:23*

Thanks [@U4H3EEV45](@U4H3EEV45) that is very helpful indeed.

*Tags: General Technical*

---

**D C** - *13:56:14*

So Dell customer services tell me that the XPS 13 range can be purchased with Ubuntu 20.04 pre-installed. Looks mighty thin and have no idea what this thunderbolt port 3 hardware is but I guess I will need a hub of some kind for peripherals. Nice to know that they still do linux builds though so I think I will go down this route. Thanks to all for helpful suggestions.

*Tags: Getting Started*

---

**Newbie99** - *14:01:42*

Not sure if the issues with the trackpads have been fixed, or whether the XPS 13 uses the same as the 15, but they are awful (there are a few reviews around on youtube etc that talk about this so its a known issue)

*Tags: Errors Debugging*

---

**birchy** - *18:23:37*

Taking this chat on a slight detour...what flavour of Linux do you AWS people use? I've always been a Debian/xfce fan on my own machines but have more recently started using Mint as it works out if the box, whereas Debian is a bit more "hardcore" and sometimes requires tinkering to get certain hardware drivers working correctly. As I've only recently started using AWS, I opted for Ubuntu on my one and only instance, but am wondering how Amazon Linux performs? Also, I've read that CentOS runs faster than most other distros?

*Tags: Deployment*

---

**Alessio** - *18:43:22*

not an aws, rather digitalocean, but yeah, ubuntu

*Tags: Deployment*

---

## 2020-10-16

**Chris** - *08:13:27*

Amazon Linux is built off of Redhat/CentOS I believe, so performance very similar there

*Tags: Performance*

---

**D C** - *10:15:04*

I think on the Betfair side things are not helped by the fact that there are multiple place markets sometimes. Particularly in larger fields.

*Tags: General Technical*

---

**Twatter** - *10:16:53*

Not used to Aus racing - are there a fixed number of runners?

*Tags: Errors Debugging*

---

**Misha** - *10:19:37*

All the fixed odds bookmakers have 2 places up to 7 runners, and 3 for larger fields

*Tags: Errors Debugging*

---

**river_shah** - *11:58:41*

This is a very interesting feature / dependence. [https://betgps.com/betting-library/Gibson-etal-The-Best-Probability-Model-for-Exacta.pdf](https://betgps.com/betting-library/Gibson-etal-The-Best-Probability-Model-for-Exacta.pdf) must break pricing hard if one naively projected win probs to place

*Tags: Feature Engineering, Strategies*

---

**Mo** - *13:48:30*

Maybe a dumb question maybe not but have you compressed them?

*Tags: General Technical*

---

**Alessio** - *13:50:25*

(btw, to upload you can start from boto3 python pkg)

*Tags: General Technical*

---

## 2020-10-19

**JC** - *16:33:30*

[@U4H19D1D2](@U4H19D1D2) very late to the party on this one... I remember you saying that 95% of your strategies don't use modelling per se, but are just a series of if statements. And here you are arguing for only taking positions with +EV with respect to the outcome of the event. Without getting at your secret sauce, how do you calculate value using only if statements?

*Tags: Strategies*

---

## 2020-10-20

**Jonjonjon** - *14:24:23*

Suppose , within a `FlumineBacktest`, I add numerous strategies.



When a market book update is received, is it safe to assume that `process_market_book` of each strategy, will be called in the same order that the strategies were added to the `FlumineBacktest` instance?

*Tags: Strategies*

---

**liam** - *14:26:06*

Yes because it's a [https://github.com/liampauling/flumine/blob/master/flumine/strategy/strategy.py#L216|list](https://github.com/liampauling/flumine/blob/master/flumine/strategy/strategy.py#L216|list), however you shouldn't count on it

*Tags: Strategies*

---

## 2020-10-27

**Twatter** - *10:05:20*

Does a neat little job of downloading a ton of football stats history data from football-data and organise it for analysis easier. Certainly helping me understand a bit on stats and modeling...

*Tags: Strategies*

---

## 2020-11-01

**D C** - *14:09:49*

Has anyone had to regenerate their SSL cert and key files? I upgraded my linux install recently and my nodejs stuff no longer works unless I roll back to an old nodejs version. The issue is inside openssl I think and the error is "*ca md too weak*". Some research suggests that this is because my cert and key files were generated with too old a version of SSL and this now causes issues with later versions of openssl. Is this something that you guys have had to do from time to time? For now it is not an issue overall, but I dont want to be running old versions of node for too long just to keep things going.

*Tags: Getting Started, Errors Debugging*

---

**liam** - *15:27:04*

Yeah I have had this, work fine with python and rejected by GO with a cryptic error message, took me a full day before I tried creating a new key and it started working :man-facepalming: 

*Tags: Errors Debugging*

---

**Twatter** - *15:29:06*

Random question on Betfair website - Does anyone know if it's possible to find a list of cancelled bets after the event from your account page? e.g. Unmatched bets that have been set to Cancel when an event goes in-play?

*Tags: General Technical*

---

**D C** - *15:57:05*

So there is no problem generating new certificates? Can you have multiple certs or are existing ones invalidated once you attach a new one. I am not very informed on the finer aspects of SSL really. It is that long ago that I cannot remember how you create them but I know the API documentation describes this. I had some similar issues with openssl 1.1.1 and some framework issues because linux distros won't upgrade to 1.1.1 . I am sure there are good reasons for that but it is all rather distracting when all you want to to is refine strategies rather than deal with the SSL nuts and bolts.

*Tags: General Technical*

---

## 2020-11-03

**AP** - *20:12:58*

I think betting his model last time would've made you a healthy Trump profit

*Tags: Strategies*

---

**Alex A** - *20:17:30*

It was just straight up gambling though, no models or anything.

*Tags: Strategies*

---

**Misha** - *20:47:02*

There is another site that looks at all the different models. Of the 16 different models they had, Biden won in all 16

*Tags: Strategies*

---

## 2020-11-04

**Jonjonjon** - *16:49:40*

Would there be much difference between hosting a docker image on AWS or Dockerhub?

*Tags: Deployment*

---

**Jonjonjon** - *16:59:31*

If I have an image with BFLW, Flumine, and a bit of my own code, how large is it likely to be? And what will it likely cost to host on AWS?

*Tags: Deployment*

---

**river_shah** - *17:00:16*

[@U4H19D1D2](@U4H19D1D2) you just run your own private registry in AWS?

*Tags: Deployment*

---

**birchy** - *22:24:31*

Once running, bots are left untouched for months, so I'm intrigued at what point automated deployment is necessary?

*Tags: Deployment*

---

**Misha** - *22:40:18*

I also run from one server, which has a suite of other applications, a database, runs a web server, etc. I take snapshots of the server as backup and if I need another one

*Tags: Deployment*

---

## 2020-11-05

**liam** - *08:02:24*

I follow gitops, merge to master, test, build, push to ECR and then some lambdas to deploy to servers based on a json config file. The beauty of this is that I can spend 5 minutes fixing a bug and merge to master and that’s it, CI/CD is then automated with a few slack notifications on success / error.



I deploy about 3/4 times a week due to framework updates, strategy adjustments or new strategies for testing. I have about 15 instances running during the day at the moment each running 1/2 instances of my framework. 



RDS for my API and data lake with API Gateway used for a small django app.

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *08:13:20*

I have a suite of integration tests that run through all strategies through a handful of markets and check the profit/order count is the same. Found this to be very helpful and helps me sleep at night 

*Tags: General Technical*

---

**Misha** - *08:13:48*

Obviously vastly different approaches depending on your starting point. I'm testing a single model/strategy/idea that if works will next be updated in 2022 (tennis probabilities based on historical data). Also looking at a more specific model that would need a fair bit more fine-tuning than that, but that's in development. I think the different approaches reflect the different target markets

*Tags: Data Quality, Strategies*

---

**Alessio** - *08:13:59*

and the fact that i want to integrate external souces, which makes deployment on a dfferent machine complicated

*Tags: Deployment*

---

**Alessio** - *08:23:13*

because it's a live subscribed API, where you first list events, then subscribe to some, then get updates in a streaming way. but it's in JS, so for now i'm zeromq-ing the updates in, but it's a bit hard to mock into testing without making things super-ugly with IF TEST everywhere

*Tags: Deployment*

---

**D C** - *09:02:00*

You guys make me feel like a dinosaur. Everyone will have different approaches and that will depend on their skill set and the scale they are working at. I only do horses right now and I just use single C++ applications that run acccording to rules in config files so I can run multiple instances. It is not ideal but for the scale I am working at this is sufficient (don't get me wrong, it is not trivial stuff, but it is all self-contained). Coming from a desktop development background, hearing how others are working really makes me feel like I am working in the dark ages (WTF is django and why so many APIs ?). Would love to see a presentation one day (suitable for old-school dunces like me) from one of the larger scale guys like [@U4H19D1D2](@U4H19D1D2) or [@UBS7QANF3](@UBS7QANF3) or anyone else about their setup and WHY they work that way. Might help drag me out of my neo-luddite bubble.

*Tags: Getting Started*

---

**Misha** - *09:08:27*

Depends what you mean by scale. If it's a set of complex intertwined strategies, then you probably need a complex system. If you are referring to profit, I have seen a system that was making 8 figures per year profit from a single application that looked like a DOS application. The model behind it was incredibly complex, but the actual execution engine was pretty simple

*Tags: Strategies*

---

**D C** - *09:18:37*

OK I thought by "scale" it would be pretty obvious but I was specifically referring to market/data level scale - thousands of markets a day placing tens of thousands of bets across many different event types. Yes you could have an incredibly complicated strategy / analysis engine processing the it but if you were only dealing cricket for example, there are not many markets per day and you could probably get away with a single stream connection in term of the input data feed side. You could be placing 1 bet per event or 20000 bets per event and depending on which one you would probably expect a different designs. I realise there is not a precise line in the sand at which one approach becomes unworkable and more complicated or more distrubuted system becomes a requirement

*Tags: Strategies*

---

**D C** - *09:28:30*

[@UN1497LJC](@UN1497LJC) Well I have the hairline of someone in their early 90s which doesn't help....

*Tags: General Technical*

---

**Jonjonjon** - *09:39:45*

Well, a lot of us are locking ourselves into bflw/flumine. But fortuntely it is open source

*Tags: General Technical*

---

**Alessio** - *09:41:11*

AWS will not go into a price war soon

*Tags: Deployment*

---

**D C** - *09:44:40*

Perl CAN be written in a legible manner. The problem you can achieve the same things with ugly hard to read code. It is probably a lot better now. Not touched it for years but I would probably still use it now for some quick and easy text file manipulations.

*Tags: General Technical*

---

**Alessio** - *09:56:00*

instead of having to think defensively all the time (like you need to do in python, where you hunt that seldom None) you get into a different paradigm

*Tags: General Technical*

---

**Alex A** - *10:16:11*

Random question, but all these 1000 odds available to back on Betfair in the US Election, are people really tying up millions in capital by making £11749 at odds of 1000 available to back on Tim Kaine?

*Tags: General Technical*

---

**Alex A** - *10:37:08*

But with lawsuits and recounts, it could be weeks before this is resolved.

*Tags: Deployment*

---

## 2020-11-06

**RichL** - *02:31:45*

Hey DC - interested in why you are both using C++, and in a python env forum? It’s a genuine question: my background has been in both high frequency and mid frequency trading for the last 10 years, and cannot justify to myself the overhead of C++ for a market that ‘clears’ once every 200ms. I’d happily share my trading env with you, but it’s entirely a WIP. I can share my thoughts on what I’m looking to build though if that would be of interest, perhaps as a soul familiar with host-on-premises C++ and my own experience of moving to cloudy python.

*Tags: Strategies*

---

## 2020-11-08

**stephencornelius** - *02:53:55*

Ive played around with the Betfair API for sometime, since their previous REST API. Im now looking into developing a full app with strategies etc. using the streaming API and I'm conscious ill need market data in order to backtest / validate them. I recall reading about the REST API that if you requested price data but were not placing bets that you would be disconnected.



With the streaming API is it possible to subscribe to price data without any repercussions? E.g. The first thing I was planning to create was an automated method of subscribing to all prices for all markets for a given event from each market creation until market closure with a result in order to build as much data as quickly as possible while I develop the rest of my app.



Firstly, is this allowed? If so can you use the Live API key or is only the delayed key allowed?

If not allowed can anyone advise the best way to get as much data as possible for backtesting (Would rather not use the historical data as I dont think its either live or complete / rich enough for me). Feel free to point me to answers if this has already been asked but I was unable to locate.



Thanks in advance

*Tags: Data Quality, Deployment*

---

**liam** - *07:30:13*

They seem to base it on API requests of which streaming isn’t included 

*Tags: General Technical*

---

**stephencornelius** - *08:31:39*

Are you talking about their original REST API (they refer to it as API-NG) such as this code refers to? [https://github.com/betfair/API-NG-sample-code](https://github.com/betfair/API-NG-sample-code)





Or their streaming API which this code refers to? [https://github.com/betfair/stream-api-sample-code](https://github.com/betfair/stream-api-sample-code)





The BetfairLightweight Client allows you to access both API's.





The fact you refer to scraping leads me to believe youre talking about their API-NG as with the streaming API you dont make requests to endpoints, you subscribe to what you want once and then the data gets pushed to you in real time. Therefore if operating correctly you wont miss any data which you can always do when making api requests. Which is why I say the historic might not be representative enough of the data im actually receiving.

*Tags: General Technical*

---

**Mo** - *10:33:52*

I am referring to streaming. There is no point in using the REST API to request prices, for scraping purposes or otherwise

*Tags: General Technical*

---

**Mo** - *10:46:47*

It sounds like you don't understand what the historic data is, which is a reproduction of what you would have received live while streaming. Whether you record the stream yourself (scraping) or download the corresponding historic data, the result should be (essentially) the same

*Tags: Deployment*

---

## 2020-11-09

**Jonjonjon** - *15:50:04*

Do you think econometric timeseries models are worth testing?

*Tags: Strategies*

---

**Mo** - *15:52:03*

What time series would you be modelling?

*Tags: Strategies*

---

**Jonjonjon** - *15:52:59*

Good question [@UBS7QANF3](@UBS7QANF3). Given it wouldn't really be possible to model the last traded price, I was thinking of looking at the high/low prices.

*Tags: Strategies*

---

**JC** - *19:23:43*

I would agree that it seems financial indicators may be inappropriate to translate to betting. Not least because there are fundamental factors and external information (such as TPD feed for in running horses) driving price. However I have also seen some of the big in play guys in this group state that access to GPS data is not essential... implying that the fundamental method they are using is possible with only access to price data/market books. Maybe I have misunderstood but it seems the key that noobs like me need to grasp is how to define a value criteria, perhaps one more simple than would be expected?

*Tags: Strategies*

---

## 2020-11-10

**liam** - *08:57:16*

Having instant notifications when things go to shit helps me not work :grin:

*Tags: General Technical*

---

**Misha** - *09:17:01*

I reckon tennis results are a bit all over the shop due to Covid-19. So having a model based on past results is not likely to be as good, if you are straight betting based on your own probabilities (or maybe you pick specific matches, in which case you may be thriving). US Open women's runner-up going out in the second round of the French Open. World #1 Djokovic having his worst ever career loss, a lot of the top players not even competing, etc

*Tags: Strategies*

---

**Alessio** - *09:18:14*

if they don't compete, it really doesn't matter for modelling, right?

*Tags: Strategies*

---

**Alessio** - *09:18:48*

(and yes, you need a soccer model that takes the lineup in account :wink:

*Tags: Strategies*

---

**liam** - *09:32:50*

Interesting how it work, looks to pull in the historic streaming data and then cycle through, however the matching process is a load of crap :laughing:

*Tags: General Technical*

---

**Newbie99** - *11:30:45*

in the rules:



If there is any material change to the established role or any ambiguity as to who occupies the position, then Betfair may determine, using its reasonable discretion, how to settle the market based on all the information available to it at the relevant time. Betfair reserves the right to wait for further official announcements before the market is settled.

*Tags: General Technical*

---

## 2020-11-13

**AP** - *19:05:29*

For the AWS users here, what is the most efficient CI/CD pipeline for lambda? I've noticed it doesn't support Docker images

*Tags: Deployment*

---

## 2020-11-16

**AP** - *04:36:44*

Hi Liam, I have managed to deploy my lambda function but there seems to be a permissions error when trying to download my certs from s3. I have fiddled around with adding permissions but yet to have any success, did you have any issues here?

*Tags: Errors Debugging, Deployment*

---

**AP** - *10:59:02*

Are you referring to the AWS credentials file on my computer?

*Tags: Deployment*

---

**liam** - *11:01:18*

the provider section of the yml, one of mine looks like this

```provider:

  name: aws

  runtime: python3.6

  stage: prod

  region: eu-west-1

  vpc:

    securityGroupIds:

      - sg-rty

  iamRoleStatements:

    - Effect: "Allow"

      Action:

        - "s3:GetObject"

        - "s3:PutObject"

        - "s3:DeleteObject"

      Resource: "arn:aws:s3:::*"



    - Effect: "Allow"

      Action:

        - "ec2:CreateNetworkInterface"

        - "ec2:DescribeNetworkInterfaces"

        - "ec2:DeleteNetworkInterface"

      Resource: "*"

  environment:

    DATABASE_HOST: ${env:aurora_writer_endpoint}

    DATABASE_RO_HOST: ${env:aurora_reader_endpoint}

    DATABASE_PASSWORD: ${env:aurora_password}```

*Tags: Deployment*

---

**Mo** - *13:39:56*

Yeah I use loads and have never had a problem

*Tags: General Technical*

---

**Oliver Varney** - *13:40:00*

I ran into a too many login error the other day and got a temp ban :joy: more likely linked to some buggy code

*Tags: Errors Debugging*

---

## 2020-11-18

**Michael** - *09:11:48*

The Indian BF clones/partners/whatever they are have been known to welch on bets without much justification, for example alleging market manipulation on very thin grounds. I helped provide evidence for one syndicate which had been done out of several hundred thousand with no real reason (horse racing). That whole world is very murky and best approached with caution.

*Tags: General Technical*

---

**Mo** - *09:31:34*

I don't think you personally should care about that but I was asking these questions becaues I was wondering what the requirements would be for my operation to take your bets

*Tags: General Technical*

---

**Andrey Yunoshev** - *19:02:14*

ok, already a little less than just interested. is the zero strategy worth something? let's say 200 bets on average per day on greyhounds, tested at 2 euro bets on live for ~30 days, approximately the same result at rates up to 20  euro bets (possible more) via backtesting

*Tags: Deployment, Strategies*

---

**Alessio** - *19:10:13*

what's zero strategy for you?

*Tags: Strategies*

---

**Andrey Yunoshev** - *19:20:34*

Obviously, I'm just wondering if I can get any profit from such a strategy. for example generate a lot of commission and reduce it for yourself but to do this in a reasonable time frame, you need to bet much more than 2 per bet, and then the question of bankroll but not the point, it's not a question of what to do with it, but whether it is worth something by itself

*Tags: Strategies*

---

**Mo** - *19:22:31*

In principle a break even strategy should be very appealing to anyone who pays premium charge. It depends how scalable it is though

*Tags: Strategies*

---

**Michael** - *19:33:10*

A break even strategy is a great place to start if it's real bets. Take your results, work on them and hopefully you can turn it into a profitable strategy. That's how you get going.

*Tags: Strategies*

---

**Andrey Yunoshev** - *19:50:30*

&gt;In principle a break even strategy should be very appealing to anyone who pays premium charge. It depends how scalable it is though



on the backtest I checked up to 20 euros per bet, I can check and even more 100 for example -

but in my opinion it will not show anything, such amounts bets are not indicative for backtesting



run live with more bet size = more volatility, not sure what I can and want

even if everything fits together by the results of the month,

*Tags: Deployment, Strategies*

---

## 2020-11-20

**Mo** - *13:39:01*

1. Bookmakers have extremely good models for customer profiling. They will be able to detect patterns of bad bets trying to disguise good ones

2. Arbs are so blatant I don't think you can hide them at all

*Tags: Strategies*

---

**Mo** - *13:39:36*

Their customer profiling models are almost certainly better than their pricing models (in most cases)

*Tags: Strategies*

---

**Michael** - *13:47:59*

Betfair is awesome for winning players, fully legit, almost unlimited scale and they help you. I honestly don't see why small/new players would bother looking elsewhere - except maybe to skim off a bunch of sign up offers to get going (although that's not nearly what it used to be).

*Tags: General Technical*

---

**Artur Gräfenstein** - *14:28:58*

I’m glad I can access betfair api directly.

*Tags: General Technical*

---

**Oliver Varney** - *21:07:26*

question for the layers, but does anyone lay at bsp, and if so specifically on long prices is there a metric that you look out for to confirm that your model is performing inline with backtesting.

*Tags: Strategies*

---

**Oliver Varney** - *21:08:27*

just thinking in terms of actual performance may take hundreds to thousands bets (depending on exsactly how long) to play out

*Tags: Performance*

---

**Jonjonjon** - *21:27:19*

I lay at BSP when my exit orders don't get filled before the race starts, using PERSIST_ON_CLOSE order type. It's stupid, but it helps other people on here to buy Ferraris.

*Tags: General Technical*

---

**Oliver Varney** - *21:30:38*

Im more wondering about how to judge how your model performing. if your lay high odds, its very easy to hit long winning streaks, which could give a false idea of performance.

*Tags: Performance, Strategies*

---

**Jonjonjon** - *21:31:52*

Something from information theory might help. I'm no expert. It's what someone told me

*Tags: General Technical*

---

**Oliver Varney** - *21:31:52*

then 3 horses win and your actually on a losing strategy if you get my drift. obviously benchmarking vs bsp is normal for pre off but if your laying at bsp this metric isnt available

*Tags: Strategies*

---

**Jonjonjon** - *21:32:35*

I wouldn't want to trade a strategy that was based on laying long shots like that.

*Tags: Strategies*

---

**Oliver Varney** - *21:37:19*

depends whether you trust your model

*Tags: Strategies*

---

**Oliver Varney** - *21:40:27*

I think its safe to say I trust my own model I built seeing as what its provided

*Tags: Strategies*

---

**Oliver Varney** - *21:44:01*

Yer might be able to devise something from there, could lead to a new feature for the model

*Tags: Feature Engineering, Strategies*

---

**Oliver Varney** - *21:47:33*

but with most of my model I like a metric for live to understand / identify any issue / how its performing

*Tags: Deployment, Strategies*

---

**Oliver Varney** - *21:47:53*

i.e. beating bsp consistently is a good measure for most of my models

*Tags: Strategies*

---

**V** - *21:49:35*

I guess it depends on how often you bet in a given week. If it’s like 10 or something then the above will be useless, but if it’s it’s like 50+ then the above could still help... if a week isn’t too slow to notice something up that is

*Tags: Performance*

---

**V** - *21:59:56*

Also, another idea is that since you have years worth of backtest results, then you can get an ideas as to the characteristics of the strategy. The max draw down, the typical return you can expect etc etc you can compare your results to various metrics in the backtest to see how out of line you are at a given moment  

*Tags: Strategies*

---

## 2020-11-21

**liam** - *02:27:07*

[@ULDAVFDRP](@ULDAVFDRP) as you are aware market impact will be your problem

*Tags: General Technical*

---

**liam** - *02:27:37*

I replied a while ago on [https://www.betangel.com/forum/viewtopic.php?t=21823|BA](https://www.betangel.com/forum/viewtopic.php?t=21823|BA) about the problem 

*Tags: General Technical*

---

## 2020-11-23

**Dave** - *22:30:18*

[https://www.kaggle.com/c/jane-street-market-prediction/overview](https://www.kaggle.com/c/jane-street-market-prediction/overview) for the modelling enthusiasts out there

*Tags: Strategies*

---

**qwerty.nat** - *23:00:27*

Indeed, i'm not even allowed to do volunteer work without sign off. I do work for a HFT but doing ultra low latency trading, and i disagree with Misha that sports is a lot more consistent. There are lots of times where we know the price will change with 100% certainty, so if you are fast enough you can scalp a tick here and there. Free money basically. However to get to that point you need massive investments in technology / market structure research etc.

*Tags: Performance, Strategies*

---

## 2020-11-25

**Oliver Varney** - *09:39:12*

Is there any reason why creating many flumine instances using the multiprocess.Process wouldnt work. Not sure if ive missed something out as when I call flumine.run() its seems like the MarketStream and Orderstreams are added and the workers are started but I cant see any market_book events come through. the rough idea was to split strategies onto a few separate accounts (mainly keeping LAY and BACKs seperate) then launch an instance for each account from one service process

*Tags: General Technical*

---

**Lee** - *09:42:28*

I personally wouldn’t use multiprocessing to start multiple live/production instances. I think two separate services would be better.

I use docker so would have two separate docker containers running.

*Tags: Deployment*

---

## 2020-11-26

**Artur Gräfenstein** - *14:18:18*

Or do your models still work the same way?

*Tags: Strategies*

---

**thambie1** - *15:27:31*

[@U01EYDA8345](@U01EYDA8345) In backtesting, I have noticed changes in the performance in soccer pre vs post corona.

*Tags: Performance*

---

**Lee** - *16:37:06*

random question, what is the `with self` doing in this context [https://github.com/liampauling/flumine/blob/master/flumine/backtest/backtest.py#L34](https://github.com/liampauling/flumine/blob/master/flumine/backtest/backtest.py#L34)?

*Tags: General Technical*

---

**MacrcoPolo** - *16:39:33*

Calls _enter_ and _exit_ methods when entering or exiting the block. See `___exit___`  on `BaseFlumine`

*Tags: General Technical*

---

**thambie1** - *17:18:55*

Depends on the strategy.

*Tags: Strategies*

---

## 2020-11-27

**PeterLe** - *10:12:50*

Morning Folks, I was thinking of building a very simple Python program that I can run on my iphone that can access my master account; obtain the balance on each sub account and provide an overall tally for the day

I just wonder if any of you do this already and the best way to do it ?

Ive never run python on my iPhone before so not sure the best app (Pythonista ?)

No doubt some of you have elaborate dash boards etc I dont need anything fancy, Im just in interested in the single number for the day

Thanks in advance for any guidance

*Tags: General Technical*

---

**Mo** - *10:13:50*

I like Pythonista but have never used it for something as complex as that. Sounds like this would be better conceived as a web app you can access using the browser on your phone

*Tags: General Technical*

---

**Mo** - *10:38:41*

On the flip side, I find that seeing some of the summary statistics I look at like bet count or total staked per match can help to reveal subtle issues that aren't caught by error reporting

*Tags: Errors Debugging*

---

**Misha** - *10:45:27*

I also have 3 web pages to check: one for errors, one for alerts, and one for all applications that have been running over the past week

*Tags: Errors Debugging*

---

**Oliver Varney** - *11:42:25*

question for the techies, I am just running cprofilev suggested by liam to find slow parts of code. I have already found some simple enhancements. one thing that is throwing me of is, that if I sort by tottime when looking at the report  {method 'acquire' of '_thread.lock' objects} comes out massively at the top. Is this expected?

*Tags: Performance*

---

## 2020-11-29

**Newbie99** - *17:30:46*

I've been getting this all day and I can't figure it out, as it appears to occur when _process_close_market runs (which I haven't changed from the pip install of flumine)?



```  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/flumine.py", line 44, in run

    self._process_close_market(event)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/baseflumine.py", line 264, in _process_close_market

    market.blotter.process_closed_market(event.event)

  File "/home/ec2-user/trading/env/lib64/python3.7/site-packages/flumine/markets/blotter.py", line 86, in process_closed_market

    for runner in market_book.runners:

AttributeError: 'dict' object has no attribute 'runners'```

*Tags: Getting Started, Errors Debugging, Deployment, Strategies*

---

**liam** - *17:42:51*

You running bflw in lightweight mode?

*Tags: General Technical*

---

**liam** - *17:43:24*

If not can you debug or print what market_book is on that line?

*Tags: Errors Debugging*

---

**Newbie99** - *17:46:05*

that was via flumine, wasn't in lightweight mode.



Will try and replicate and report back...

*Tags: General Technical*

---

**liam** - *18:02:40*

No idea tbh, get a debugger in it to confirm that it is a dictionary MarketBook and not something else 

*Tags: Errors Debugging*

---

## 2020-11-30

**Artur Gräfenstein** - *08:09:53*

Hi everyone, does anyone know how tolerant Betfair is with read-only live keys? I can’t really finish my development with a 2 minute delay. So I have to adjust the details with the live key without betting.

*Tags: Deployment, Strategies*

---

**Artur Gräfenstein** - *08:30:21*

Without a strategy, isn’t the risk always the same?

*Tags: Strategies*

---

**Misha** - *08:31:49*

You can actually make a profit on the win market like this on tennis with one other piece of information (tested on all matches since streaming started in 2015) :wink:

*Tags: General Technical*

---

**Misha** - *08:36:48*

I kept my account clocking over before running a strategy doing this - it cost me about $5 per $1K turnover on average

*Tags: Strategies*

---

**Michael** - *09:03:29*

Assuming you have some idea how you intend to bet your best approach might be to code up some version of your likely strategy (however quick and dirty) and just go live at £2 stakes. That way you're generating useful data and not costing yourself much. Data from real bets placed is far more valuable than back-test data. Rather than trying to bet the absolute minimum without getting banned I would suggest you get a little money down in a lot of markets. If you have no strategy in mind then just put bets on in a good number of market as offers to backers - so you're laying at or slightly shorter than the best available to back price. Maybe have some check that the book is well made up to avoid very low liquidity markets.

*Tags: Deployment, Strategies*

---

## 2020-12-02

**Jonjonjon** - *10:03:03*

To be honest, I had a very low fill rate (under 1%) when I started and it wasn't a problem. Betdaq didn't like it too much though and sent me an angry email

*Tags: General Technical*

---

**Jonjonjon** - *10:09:29*

I don't work with them. But I'm a customer of both. I don't use Betdaq anymore though as I could not work out how to make money on it

*Tags: General Technical*

---

**Artur Gräfenstein** - *10:10:55*

What was the problem? big commissions?

*Tags: General Technical*

---

## 2020-12-03

**Artur Gräfenstein** - *08:24:58*

You can’t say it’s not JSON. Transit is on top of JSON.

```Transit is designed to be implemented as an encoding on top of formats for which high performance processors already exist, specifically JSON and MessagePack. ```

*Tags: Performance*

---

**PeterLe** - *13:20:31*

Just noticed that Salesforce has agreed to buy Slack for $27bn :astonished:, I bet some of the collectives minds on here could build something similar :grinning:…makes you wonder how much BetfairlightWeight is worth now Liam :grinning:

*Tags: General Technical*

---

**Artur Gräfenstein** - *15:01:57*

It would also be interesting how high the turnover through bflw is. Betfair may want to charge you a super premium commission for providing  Bflw. :grinning:

*Tags: General Technical*

---

**birchy** - *15:52:10*

[@U4H19D1D2](@U4H19D1D2) within expectations. It's a strategy I ran about 8 years ago. Difficult to backtest properly when offering prices due to match rates.

*Tags: Strategies*

---

**PeterLe** - *15:55:21*

[@U016TGY3676](@U016TGY3676) well helps with commission :+1:

*Tags: General Technical*

---

**birchy** - *17:12:18*

[@UQL0QDEKA](@UQL0QDEKA) already on the 2% basic package, but even if it turns out to be a break even strategy (which is why I pulled it ~6 years ago), it does at least help towards data recording and PC reduction.

*Tags: Strategies*

---

**Misha** - *21:20:51*

[@U919M37DL](@U919M37DL) - not really. The odd match is probably fixed, and that would usually be at a lower level. But there are almost 20,000 matches per year to bet on, and the dodgy ones might be a handful

*Tags: Errors Debugging*

---

## 2020-12-04

**Mo** - *11:34:46*

Streaming is cheap so seems like premature optimisation

*Tags: General Technical*

---

**Misha** - *11:36:29*

My software copes with it because the historical streaming data has the full ladder

*Tags: General Technical*

---

## 2020-12-06

**Oliver Varney** - *09:13:15*

so I guess what I want to design or improve is a data quality / checking service. I run models that use data from many sources + I further aggregate and build out more features. also I would like to build some kind of unit test that tests the built out aggregate features in SQL Server. With a large number of sources + features it can be easy to let a inner join slip through the net instead of being a left join and it might not be fully noticeable straight away.

*Tags: Data Quality, Feature Engineering, Deployment, Strategies*

---

**Alessio** - *15:10:57*

What you are looking for is an integration test in a sense.. so basically you'll probably want some golden data apart, a second database in sqlserver and some golden expectations?

*Tags: Deployment*

---

## 2020-12-07

**Oliver Varney** - *16:30:00*

yes essentially I use sql server as a long term datastore, with python services that request / add data, call further internal procs that populate tables and build out further features. Just wondered if there was something similar to unittest / pytest within sql server. Or is it a case of using python to pull data out then do the test cases that way

*Tags: Feature Engineering, Deployment*

---

**Oliver Varney** - *16:32:20*

typically access tables via pandas, and upsert using procs

*Tags: Feature Engineering*

---

## 2020-12-11

**Lee** - *16:07:04*

Bit of a broad question for the full timers in the uk - how do you give yourself an "income" to get finance on things like a mortgage on an investment property?

*Tags: General Technical*

---

**Lee** - *16:28:58*

So in the short term some sort of diversified fund (depending on which) is probably the best way to invest and excess winnings? Or are there potential problems with that too?

*Tags: General Technical*

---

**mandelbot** - *17:42:42*

If you need any help with the painting let me know :art:

*Tags: General Technical*

---

**James T** - *19:02:36*

Yep, I went with a broker in the past for a mortgage and they were very helpful. (I used John Charcol). Just be very honest about your situation. They know exactly what checks and information each bank needs so they can advise on the best choice. 



Re: bank accounts, I’d advise withdrawing winnings into an established bank account so it has less chance of raising alarms. I’ve heard that banks are getting stricter with money laundering checks, and my accountant says having somewhere to withdraw money to is becoming a bigger problem for big winners than actually winning the money is. It may actually be better to create a new account to receive your work income for 3-6 months for the mortgage application than to switch where you’re transferring winnings. 



Some mortgage lenders will want to see statements from all your bank accounts and some just your current account where you receive your work income. The brokers will know. 

*Tags: General Technical*

---

**D C** - *19:04:20*

Thanks chaps that is all very helpful stuff.

*Tags: General Technical*

---

**Amanda** - *19:06:44*

I’m guessing you guys aren’t making much money from the Betfair API if you have to apply for a mortgage? I just pay cash.

*Tags: General Technical*

---

**James T** - *23:33:06*

For me (and most other individual gamblers), nothing special, just peace of mind if HMRC were to audit me I know I have someone with experience to respond for me. For big syndicates, a good accountant is probably very important to build the right company structure to avoid taxes and so on. 



I imagine receiving lots of money from gambling on a consistent basis would raise question marks from many people (including some banks) who don’t understand the industry. 



Part of me wonders whether my bank just doesn’t know it’s gambling related. My Betfair withdrawals appear as “sporting exch client” rather than “Betfair” on my statement. I think that’s because larger withdrawals go through a different pipeline to smaller withdrawals. So maybe the name doesn’t get flagged up? :man-shrugging:

*Tags: General Technical*

---

**Michael** - *23:44:01*

I've done exactly the same as James and established a few bank accounts just in case. My feeling is that the shortest possible audit trail would be best if questions were ever raised so I've never done any kind of laundering.

*Tags: General Technical*

---

## 2020-12-13

**Alessio** - *15:18:49*

It depends a lot on the country. IANAL, but the main problem is not the legal requirement or not, but the fact that you never want to be on the other side of an AML check, they are pretty..invasive (and they tend to freeze all your assets if they have some doubt, *then* ask questions -- at least that's what i hear from some of the bank compliance friends).

*Tags: General Technical*

---

**AP** - *17:23:38*

I worked for someone in Australia who used Citibet extensively. I can’t speak for the laws in the UK but in Australia it was illegal for an offshore gambling entity to offer gambling services to Australians, but not illegal for Australians to use them. 

*Tags: Deployment*

---

## 2020-12-14

**Michael** - *00:48:30*

That's not his situation. He's putting in money. Even if he wasn't; if you know that the law is being broken and you participate in it then you're part of the enterprise and in this case there would really be no ambiguity about that. That's why a getaway driver is held responsible for a robbery whilst an unwitting taxi-driver wouldn't be even though they might provide an identical service. Like I said, I don't think he needs to worry because in real life the chances of anyone coming after him are negligible, but he wants to know where he stands and it's quite clear that he would be part of the enterprise and answerable for his role in any law breaking. Whether there is any illegality is another question, I don't know what the law is on the Isle of Mann.

*Tags: General Technical*

---

**Mo** - *05:48:34*

My question is still this: what law is being broken by the person using an unlicensed exchange? I understand that an unlicensed exchange or bookmaker is breaking the law by offering betting services to UK customers. But I cannot find anything that says it is illegal for a UK citizen to use them. I am not saying this is the case but I am looking for some concrete evidence either way.

*Tags: Strategies*

---

## 2020-12-15

**Mo** - *12:23:37*

Does anyone here participate in Kaggle competitions?



I used to do a bit but I've always struggled with the idea because it feels like time better spent on developing my betting strategies as the processes are pretty similar (analyse some data and build a model). On the other hand, I think it can be good to expose yourself to other types of data and techniques as you may find crossover opportunities

*Tags: Strategies*

---

**river_shah** - *12:50:07*

I have done so. For example there was one on halo / dark matter detection in synthetic large field galaxy pictures. the idea was that the presence of a black hole slightly bends light coming from distant  sources which allows one to pinpoint the presence of a black hole through indirect means. the signals were very faint which I found to have direct analogs for our domain (finance, betting, quasi efficient markets) I also ended up mastering some linear algebra and data compression techniques which ended up helping with the day job

*Tags: Strategies*

---

**Alessio** - *13:21:09*

Side question though, how do you guys keep all your data around for joining and building models? If you get ~100K markets to train on + all the side data coming from other sources, the risk of data going stale/out-of-sync or mess-ups increase. Just SQL and some extra checks on top? Processing queues on top?

*Tags: Strategies*

---

**Oliver Varney** - *13:22:18*

and it can be quite easy to muck it up when the number of source increase and the complexity of the model increases

*Tags: Strategies*

---

**river_shah** - *15:25:53*

plus watch the videos, cute girl who knows machine learning. win / win

*Tags: General Technical*

---

**Oliver Varney** - *17:23:21*

I use sql server, and I think they have something similar. I think it came down to performance in the end. I purely only use it for training models, basically pushes the historical files into it

*Tags: Performance, Deployment, Strategies*

---

## 2020-12-16

**Charlie 303** - *00:47:23*

+1 for using Postgres if SQL is involved for holding historical data. As Mo mentioned, the JSON handling is convenient and somewhat easy to optimize.  Using PG for historical + NeDB (in-mem mongo basically) essentially as a cache

*Tags: Data Quality*

---

## 2020-12-17

**MacrcoPolo** - *13:12:38*

random idea... is it possible to have a channel consisting of just curated 'best threads'? Not sure if slack allows copying that easily, but figured it might save answering the same questions over and over

*Tags: General Technical*

---

## 2020-12-18

**Oliver Varney** - *12:35:45*

interesting in the 12.07, didnt watch the race but assume it was a tight finish. Was trading around 1.1 for about 10 mins then just before the result came in it shot out to 1.2. The lowest traded one was given the win but I find it interesting that 5 seconds before the actual close the price shot out. I was expecting a dead heat or something to be called by the trading activity in that last few seconds. Is it a viable strategy that people have a faster feed of the result data then betfair? I know there is an issue around non runner.

*Tags: Strategies*

---

**Oliver Varney** - *12:37:07*

ah okay, I guess the question still stands about the strange trading in the last few seconds

*Tags: Strategies*

---

**bb** - *14:10:35*

Just watched the replay and the winner jumping left severely hampered the progress of the second place horse at the final flight. My guess is people would be trading expecting it to go to stewards and the result be overturned, but given it was horse error rather than jockey error causing the interference it couldn't be protested and the market settled

*Tags: Errors Debugging, Strategies*

---

**John A** - *21:45:36*

Would be interested to know from the fellow full timers out there the answer to, this question. What do you tell people when they ask “What do you do for a living?” These days I just say I’m a Software Developer. Would love to say I’m a gambler but it’s not really gambling. Also, trying to explain what an automated betting exchange is beyond my communication skills.

*Tags: Strategies*

---

## 2020-12-19

**D C** - *10:28:23*

[@ULDAVFDRP](@ULDAVFDRP) The link in terminology I understand and I have even seen people use the logic that using an exchange is a "trade" of opinions but I see it simply as placing a bet where the party accepting the risk is not necessarily a bookie. A lot of people (particularly on social media) like to distance themselves from the term "gambling" and not always because they are trying to sell tips or some useless ebook on how to "trade betfair". I understand there are times when you may want or need to distance yourself from the term (for example, I recently asked some questions about mortgage providers and gambling transactions) but I am instantly distrusful of people who try and label what we do as anything other than what it actually is. It is not really OUR problem (well, SHOULD not be our problem) that a lot of people in society (usually those who have never set foot in a bookmaker) seem to regard this game as murky or undesirable.

*Tags: General Technical*

---

**Misha** - *10:48:35*

I have a mate who started a hedge fund. The way he built his fund is no different to what I do in sports betting. Both of us have Pure Maths degrees. Both models use data analysis and automated trading. There is no difference

*Tags: Strategies*

---

**D C** - *10:52:36*

OK call it what you will. Even if you have the best model in the world and you have huge +EV long term what we do is still gambling. I just guess its one of those things we will never agree on.

*Tags: Strategies*

---

**D C** - *11:36:43*

[@U016535QCJ2](@U016535QCJ2) I don't really understand the question - my job description is "data scientist" if that is what you are asking. In terms of sophistication, I speak with a chap who makes shitloads of money on football basically by getting team/match status news way ahead of other people. There is no "sophistication" in that approach so to speak but he makes lots of profit. What I have is way more computer/algorithm based but I would swap my bank balance with him if offered the chance. He is a professional gambler - would you say that was a fair desrciption? I am sorry but I just cannot see how someone who uses algorithms/analysis should be viewed any differently to someone who reads the racing post and places their bets manually over the counter at the bookies.

*Tags: General Technical*

---

**Misha** - *12:06:27*

Mathematical modelling

*Tags: Strategies*

---

**Mo** - *12:11:02*

Now I think you are just arguing for the sake of it. You think when he plays Keno to make money he is not professional gambling but mathematical modelling?

*Tags: Strategies*

---

**Misha** - *12:26:56*

I think we will just have to agree to disagree. The original thread was about "what do you do" in response to a question from others. My views are how I approach that question as I have been asked a lot of times. Based on the arguments here, I respond somewhat differently to others

*Tags: General Technical*

---

**Mo** - *12:41:50*

You are of course welcome to answer that question however you want



But you said that you have never gambled which is utterly false (unless I have misunderstood your own venture and you personally do not place any bets)



You might have your own incorrect definition of what gambling means but standardised definitions exist for very good reasons, such to facilitate the exchange of ideas. This is not about agreeing to disagree

*Tags: General Technical*

---

**Misha** - *12:59:59*

Note the above: I have conceded that under the definition, what I do constitutes gambling. But you need to look at the original source of the argument, which is how do you describe what you do to others (to which you said you are a gambler). So you win the argument, but that is a moot point in the context of how one might answer the question to others

*Tags: General Technical*

---

**Misha** - *13:03:49*

Given that pretty much everyone knows my maths and software development background I say developing automated sports betting systems based on mathematical models

*Tags: Strategies*

---

**Michael** - *13:21:36*

There will be exceptions but on the whole winners tend to quite comfortable with the term 'gambling'. They don't need to justify their choices because the money does that. The various euphemisms are usually more popular with losers as they support denial.

*Tags: Errors Debugging*

---

**Michael** - *13:38:37*

Just to be clear I haven't read through all the discussion above, that wasn't directed at any individual and like I said 'there will be exceptions'. Just my observation after having met more than my share of winning and losing gamblers.

*Tags: Errors Debugging*

---

**Michael** - *14:04:25*

looks like his problem stemmed from cash transactions rather than it being betting winnings. There have been several test cases involving various bodies going after gamblers and the gambler always wins.

*Tags: Strategies*

---

**Mo** - *14:43:45*

I think that is exactly the problem [@UFTBRB3F1](@UFTBRB3F1) which I am trying to address

*Tags: General Technical*

---

**Michael** - *15:28:18*

[@UQL0QDEKA](@UQL0QDEKA) - Yes - I think this can be a real problem. Part of my distaste for the euphemisms is that they enable people to pretend that they're not problem gamblers. Gambling is dangerous and can ruin your life. I think it's important that we keep sight of that and don't sugar coat it.

*Tags: General Technical*

---

## 2020-12-20

**Misha** - *05:41:53*

We have a very significant issue with problem gamblers in Australia. But that's across slot machines (the worst), sports betting, and to a lesser extent, casinos. Of those with problems, less than 0.01% (if that) would be people who do some sort of computer analysis and then use that to bet. We just aren't the problem group. Those pretending they are not problem gamblers aren't using euphemisms, they are denying an addiction

*Tags: Strategies*

---

**Alessio** - *09:24:00*

This whole world  of betting is evil. It's designed to extract money from you and barely help you when you are addicted. You should be proud that you are extracting money for yourself and fighting the system! :wink:

*Tags: Strategies*

---

**Lee** - *16:32:15*

For those who use lambdas, do you have a separate repo for each function to make CI and deployment simpler? I use github actions to deploy

*Tags: Deployment*

---

**V** - *17:42:17*

This may be one of those “those that know won’t say” questions :smirk:

*Tags: General Technical*

---

## 2020-12-22

**liam** - *13:21:00*

Am I correct in thinking no fixtures till the 26th after today?

*Tags: Errors Debugging*

---

**Oliver Varney** - *13:23:20*

although the calender view doesnt even have todays races. actually think its updated here [https://www.britishhorseracing.com/racing/fixtures/upcoming/](https://www.britishhorseracing.com/racing/fixtures/upcoming/)

*Tags: Errors Debugging*

---

**PeterLe** - *13:33:51*

Yes i was watching the prices and they seemed all over the place. there were two under 1.06 in the last too  :astonished: maybe someone is trying  new strategy !

*Tags: Strategies*

---

**Jonjonjon** - *16:04:51*

Isn't that dependent on strategy? I had an opposite experience to you this year.

*Tags: Strategies*

---

**mandelbot** - *18:03:30*

Perhaps it's a good time for [@UBS7QANF3](@UBS7QANF3) to give a presentation on sports modeling  :nerd_face:

*Tags: Strategies*

---

## 2020-12-23

**Jonjonjon** - *22:23:54*

Are there any Spyder experts here? I'm trying to shift from the IPython console to the edit, using CTRL+Shift+e. But it just prints e in the console. I can go from the editor to the console using CTRL+SHIFT+I

*Tags: General Technical*

---

## 2020-12-24

**Artur Gräfenstein** - *09:37:25*

No existing API, but I keep running into the problem that I want to use information from different platforms but have no easy way to link the events.

*Tags: General Technical*

---

**Mo** - *09:38:02*

It's a hard problem. Being able to deal with it is a technological edge

*Tags: General Technical*

---

**Artur Gräfenstein** - *09:39:29*

So I thought, probably other developers have the same problem and I could start to make the information already gained publicly available through an API.

*Tags: General Technical*

---

**Misha** - *09:41:46*

Even for tennis. my area, it is fiendishly difficult to get right. And I have spent a lot of time refining how to do this

*Tags: General Technical*

---

**Misha** - *09:44:07*

Good question - a lot of effort I exepct

*Tags: General Technical*

---

**Artur Gräfenstein** - *10:19:38*

For tennis we can use your knowledge to help other developers. :smile:

*Tags: General Technical*

---

**Misha** - *13:21:59*

Yes - historical may not be that problematic. I have already done this as a one-off and get about 95% of the matches on Betfair mapped (from 2015)

*Tags: General Technical*

---

**Mo** - *13:49:31*

[@U01EYDA8345](@U01EYDA8345) the more I think about it, the more I think this is a good idea and I would be happy to contribute if it helps

*Tags: General Technical*

---

**Mo** - *13:54:39*

[@U016535QCJ2](@U016535QCJ2) I think you should be careful about being too precious about things. What you think is secret sauce is probably already known by many people. I don't think [@U4H19D1D2](@U4H19D1D2) has done himself any damage by making bflw and flumine open source and has gained many valuable contributions from the community

*Tags: General Technical*

---

**Misha** - *14:15:12*

[@UPMUFSGCR](@UPMUFSGCR) - you don't have access to Liam's modelling :joy: The framework is just a tool

*Tags: Strategies*

---

**Oliver Varney** - *14:47:42*

Hey chaps, techy question, currently I use SQL Server as my database software (locally). I am starting some work that will basically give me a chance to remodel all my database work going forward. I run everything locally atm but there is scope for this side project to be run on AWS / cloud and my stuff also down the line. Am I right in thinking there is high license fees for SQL server on AWS? If so what opensource/free SQL databases would people recommend

*Tags: Deployment, Strategies*

---

**John A** - *14:54:14*

I use SQL Server development version which is free. SQL licenses are expensive but if you’re the only user there’s no reason to buy one. Been using the developer version for years with no problems. If you’re running windows server on AWS I can’t see any problems.

*Tags: Deployment*

---

**Oliver Varney** - *14:58:05*

okay so am I right in thinking that I can run SQL server dev in AWS like I do locally without any costs? just wondering what the pros and cons of SQL Server, whether I can use it for free and whether I should ditch it now I have an opportunity

*Tags: Deployment*

---

**JazzMan** - *15:24:21*

I run SQL server 2019 on 2 local Windows 10 pc’s and on 2 Windows Server Azure servers without any problems. I don’t see why AWS would make any difference. I should be buying a license I suppose but be

*Tags: Deployment*

---

**Dave** - *21:12:57*

Just use a proxy list that refreshes daily and rotate proxies on each request (if you don't care about extra latency in the order of few hundred ms)

*Tags: Performance*

---

## 2020-12-26

**liam** - *17:55:21*

Anyone got any exciting 2021 plans/intentions/goals when it comes to betting? 



Personally I am looking to get flumine in a solid state as I am half way to migrating all my strategies to it. Also looking to roll my own container orchestration / auto scaling cluster / API so I can better monitor / spin up strategies and backtest pipelines  

*Tags: Strategies*

---

**Oliver Varney** - *17:58:02*

[@U4H19D1D2](@U4H19D1D2) thanks alot for flumine, I had started something similar but your expertise and superior coding made flumine a must have :+1: Multiple beers coming your way next time we cross paths :beer:

*Tags: General Technical*

---

**D C** - *17:59:56*

Scale up IP stuff and start trying to model pre-off horse SP / closing prices. Not sure how far I will get fitting that in around the day job but have to at least get it started.

*Tags: Strategies*

---

**Oliver Varney** - *18:00:41*

not sure it will happen next year but a reinforcement learning inplay model

*Tags: Strategies*

---

**Artur Gräfenstein** - *18:02:26*

1) Create an open API to connect different data providers.

2) Develop a mobile app that shows your betting earnings and some statistics (can be used by anyone).

3) Develop a new profitable strategy

*Tags: Strategies*

---

**Mo** - *18:05:22*

Having another bflw meet-up 

*Tags: General Technical*

---

**Lee** - *18:08:52*

+1 for flumine. Liam will definitely not be short of beers when we’re allowed to meet. Cheers Liam

*Tags: General Technical*

---

**AP** - *19:09:50*

+1 again, Flumine made it so easy to get strategies up and running quickly and it is extremely reliable. Thanks Liam!

*Tags: General Technical*

---

**Alessio** - *20:43:57*

Get my first profitable strategy :wink: And tbh, if i can contribute to something to basic things for others more than happy to. Flumine has really been a saver into understanding where my ideas would break

*Tags: Strategies*

---

**Alessio** - *20:45:26*

[@UBS7QANF3](@UBS7QANF3) before mentoring, i think maybe getting to some sport modelling for real would be good. happy to find something to contribute (if I can) to make sure it doesn't look like there's a bunch of newbies leeching from the more experienced people.

*Tags: Strategies*

---

**Alessio** - *20:45:56*

I mean, in soccer, there are only a bunch of papers most of which get you worse results than Nate Silver's model :stuck_out_tongue_winking_eye:

*Tags: Strategies*

---

**thambie1** - *20:47:03*

Congrats Alessio! Curious, what approach are you taking? Generating models from historical football data, statistical arbitrage, etc?

*Tags: Strategies*

---

**Alessio** - *20:49:37*

For now, i am looking at two things: low liqudity markets where betfair goes out of sync with reality and historical data prediction to see when a "sure bet" will generate during certain markets

*Tags: Data Quality*

---

**Misha** - *21:05:22*

Started here when we had problems in April/May. No way could I work with everyone stuck at home

*Tags: General Technical*

---

**JC** - *22:55:08*

My aim is also to turn profitable in 2021! And to keep learning and improving my knowledge, skills and strategies. Hopefully I will be able to help others in this community as well, as it has been an essential resource for me as well as a source of inspiration. Thanks to the guys who made it and to everyone for the debates and long may your automated profits continue :grin:

*Tags: General Technical*

---

## 2020-12-27

**Alessio** - *13:15:21*

[@UBS7QANF3](@UBS7QANF3) I was pointing out to your 'offer' that mandelbot reposted the other day about sport modelling.. on my side the only thing i can contriute is what i read and what i understood :stuck_out_tongue:

*Tags: Strategies*

---

**Mo** - *13:51:09*

Yeah that offer was related to the idea of a general betfairlightweight/automated betting knowledge base. Still waiting for [@U4H19D1D2](@U4H19D1D2) to organise it :wink:

*Tags: Strategies*

---

**Mo** - *13:54:28*

Probably explanations of specific models for different sports

*Tags: Strategies*

---

## 2020-12-30

**Jonjonjon** - *09:11:01*

This is more random then usual, but has anyone here had problems getting their coinbase accounts verified?

*Tags: General Technical*

---

**Oliver Varney** - *11:47:39*

not to sure how to phase this question, but maybe describing the situation will help. Yesterday there was a horse (matties mountain,limerick 3:25) which all my algos piled in to and built up some big positions. Looking at the off the price had doubled (5-&gt;11), typically an awful sign right. looking at its form to see if the algos had gone awol it had won last run ( i know this doesnt mean much in isolation, but it was not like it had been pulled up 3 times running). The horse won with a bit in hand. I do have some straegies that catch drifters, but I guess at what point do you stop continuing to build up a larger and larger position when you algo says it was good value. Furthermore, because its a rare case was I right and the market just completely wrong, or was it luck that it won. Do people evaluate this somehow?

*Tags: General Technical*

---

**Oliver Varney** - *11:47:48*

hopefully that somewhat makes sense as a question

*Tags: General Technical*

---

**Misha** - *11:51:52*

Can't speak for horse racing but the model I currently have for tennis in-play (still working on it, nowhere near mature), often piles onto a player that, when you watch the match, looks to be throwing money down the toilet. And sometimes it does. Yet when I ran the numbers on the matches where I bet very one-sided, I have roughly the same POT% as other matches. So I just let the numbers be a guide

*Tags: Strategies*

---

**Oliver Varney** - *12:00:22*

there is a limit per strategy runner based on prediction strength / odds. This is preoff horses, even before the race has started. I guess im wondering how I could measure / quantify this scenario. To have the combination of me betting on something + the price increasing + the horse winning leaves me with a very small samples size as [@U4H19D1D2](@U4H19D1D2) has just said

*Tags: Strategies*

---

**Oliver Varney** - *12:22:20*

nope, only if, but in this case (and thinking generally) the combination of the strength of all my separate models (operating on slightly different features + times), plus the doubling of price, raises the question of how to evaluate these situations. All typical metrics suggest that pre off it was a bad bet. Probably just falls under the category of not worth the time looking into.

*Tags: Feature Engineering, Strategies*

---

**Oliver Varney** - *12:36:51*

Cool cheers chaps I think ive answered the question looking back at the backtesting. thanks for the input :+1:

*Tags: General Technical*

---

## 2020-12-31

**Oliver Varney** - *08:03:46*

Cant remember exactly what the standard version has vs it but it has stuff like viewing pandas data frames , coverage for testing, threading debugging and performance stuff. Maybe not worth it for a developer of my skill but yes, the debugging tools are much better. Im surprised you dont have it. I think its only a few quid a month. They have monthly rolling options so id recommend trying it for a month and then binning it if you dont think its worth it

*Tags: Errors Debugging, Feature Engineering, Performance*

---

**Mo** - *08:04:17*

I like the database tools

*Tags: General Technical*

---

**Oliver Varney** - *08:05:51*

yer they can definitely improve it, but was decent vs trying to view stuff in the standard debugger

*Tags: Errors Debugging*

---

**liam** - *08:34:11*

I only know how to use PyCharm and nano 

*Tags: General Technical*

---

**Alessio** - *09:59:14*

(but i know how to exit it)

*Tags: General Technical*

---

**Sam Asin** - *10:09:14*

only messing with python a bit to try out your package tbh :smile:

*Tags: General Technical*

---

**Alessio** - *10:11:41*

written by statisticians, with no real documentation

*Tags: General Technical*

---

**Sam Asin** - *10:14:46*

I think pandas is a lot more verbose [@U01C12ZEADQ](@U01C12ZEADQ), but also i'm used to thinking in R ways.

*Tags: Feature Engineering*

---

**Alessio** - *10:19:15*

i''m not familiar with data.table, though. my main complaint about R is the lack of any meaningful documentation. There's documentation, but it explains ZERO of any gotchas that there may be. It looks like i'm trying to work in perl

*Tags: General Technical*

---

**Alessio** - *10:19:44*

Pandas is more verbose, but indeed the verboseness gives you a better understanding of what to expect.

*Tags: Feature Engineering*

---

**river_shah** - *10:26:03*

pycharm fixed their god awful jupyter integration. it really is now the best single ide for development and data exploration (that I am have used)

*Tags: Errors Debugging*

---

**Alessio** - *10:49:41*

Not everybody relies on the well thought out stuff like flumine :slightly_smiling_face:

*Tags: General Technical*

---

**Alex B** - *10:51:19*

Even without flumine, this is pretty basic stuff to get right :man-facepalming:

*Tags: General Technical*

---

**Oliver Varney** - *11:03:16*

also when flumine restarts the hourlys restart also

*Tags: General Technical*

---

**MacrcoPolo** - *13:14:31*

It's great for general stats work and cutting edge stats (since the standard is still to write your new inference technique in R I believe) but I too find it slightly vile. I also find that the IDEs for python are just better... . R always felt not-quite-turing complete to me

*Tags: General Technical*

---

**Michael** - *17:05:00*

Might be worth noting that I haven't had this warning email, I don't think [@UBS7QANF3](@UBS7QANF3) or [@U4H19D1D2](@U4H19D1D2)  mentioned receiving it either, which might suggest that there is at least some targeting going on and it could be worth those who got it taking a look at their transactions. Quite apart from transaction charges posting a lot of transactions without getting them matched is rather pointless and not really indicative of a well optimised strategy.

*Tags: Strategies*

---

**Oliver Varney** - *21:42:35*

Yup ive had issues cancelling orders in an incorrect state, I haven't found my bug yet, so I just added further code on top of flumine to prevent my inability to be half decent at coding and not making mistakes :man-facepalming:

*Tags: Errors Debugging*

---

**Sam Asin** - *23:53:35*

[@U01C12ZEADQ](@U01C12ZEADQ) sorry i passed out it was like 4:30 am my time and I stayed up too late playing FTL. Yeah, data.table is pretty much it's own thing so it's borderline unrelated. That said, i had done some base R before, and hadn't had any problems with gotchas or anything. There are often more examples online for pandas, though.



For data.table, at least, I feel like its less verbose but that hasn't come with gotchas to me. Sometimes I just have to learn weird little tricks that are in there to help do what I want, but ultimately it's always doing what it seems like it should. I will def stan for it and think it's genius, but I'm no real programmer.



The basic gist is, compared to pandas, it generally assumes you're working inside the scope of the data.frame you're dealing with, and is really into powerful group bys with whatever statement. Everything is always df[subset stuff, stuff to do, group by stuff] and you can accomplish a ton with it.



So now, in pandas, I find myself writing:



newdf= df_name[['colname_tosum']].groupby(df_name['colname1'], df_name['colname2']).loc[df_name['colname3'] &gt; 4].sum()



or something like that, where in data.table in R it would be.



newdf = df_name[colname3 &gt; 4 , sum(colname_tosum), groupby = list(colname1, colname2)]



or just (the groupby is optional):



newdf = df_name[colname3 &gt; 4 , sum(colname_tosum),  list(colname1, colname2)]



or could just calculate that new column in the same data.frame:



df_name[colname3 &gt; 4 , newcol := sum(colname_tosum), list(colname1, colname2)]



it's probably a bit of what you're used to, and in this case the pandas line isn't that long, but it takes me forever to read that pandas line and figure out what's going on. On the other hand, I think if you are practiced in pandas, you don't default to group by etc. so much to solve your problems the way I do. Also, you might use way shorter df_names, i'm in the habit of writing long descriptive names because i usually in data.table write 'em just once per line. Anyhoo, that's my shpeal.

*Tags: Feature Engineering*

---

## 2021-01-01

**Mo** - *08:45:54*

Like you say, it's what you're used to, but I prefer the pipeline syntax of pandas to remembering what operations go in which position inside the square brackets

*Tags: Feature Engineering*

---

**Alessio** - *10:36:21*

And as we always say, as long as the tools are comparable in power, whether you use pandas or R it's more your problem and the community you cater to.

*Tags: Feature Engineering*

---

**Sam Asin** - *17:45:20*

and anyways, we're all using pandas with thsi package so it's sort of moot.

*Tags: Feature Engineering*

---

**Sam Asin** - *17:46:31*

I mostly need to figure out how to do more of my stuff by using, like, lists of data.frames maybe? And other sorts of structures. I'm imagining you guys aren't writing groupby all the time?

*Tags: General Technical*

---

## 2021-01-03

**Chris** - *20:36:57*

Not particularly betfair related more general betting, wonder if anyone can help. When calculating EV for a bet if I have a “true price” obviously the calc is fairly simple but I’ve some markets where dead heats are common. If I know how often that a dead heat would occur (from my calculations) how could I calculate the EV to account for that. Or should that be included in my original estimates price and factored in there?

*Tags: Strategies*

---

## 2021-01-04

**Misha** - *04:16:22*

If your model is really good you just ratchet it up until you can't put any more money on without eating into your profits

*Tags: Strategies*

---

## 2021-01-05

**Oliver Varney** - *09:10:36*

morning chaps, just a general question on staking for those that use kelly style staking, but in the scenario where you have one bet that settle in like 1 hour lets say, then a second new bet comes along which settles in a few minutes, what % of bankroll are you basing the second bet on? Are you basing the bet on the bankroll what you have available at the time of bet or do you attribute some value to the initial bet?

*Tags: Strategies*

---

**river_shah** - *09:11:34*

Clearly paying what they pay, I assume staff turnover is going to be fairly high. How does IP get controlled in such situations? Mono repo’s out of the question and keep everything very siloed / locked down?

*Tags: General Technical*

---

**river_shah** - *09:19:36*

I will just make a heuristic argument (although there is an exact answer and I need to look up the paper)

Typically in real world situations the kelly size bet is usually a small fraction (i.e one third or half kelly) as is the edge for any given bet. Considering the bets are independent, I would just bet with same bank roll assumption

*Tags: Strategies*

---

**river_shah** - *09:23:39*

hmmm, maybe look up multi period mean variance optimization papers. [https://opus4.kobv.de/opus4-zib/files/418/SC-99-30.pdf](https://opus4.kobv.de/opus4-zib/files/418/SC-99-30.pdf)

*Tags: Performance, Strategies*

---

**river_shah** - *09:25:34*

re 50 bets, if bets are independent and your mean edge and variance computations are reasonable I’d still treat bank roll as the same. on expectation your bankroll grows proportionally to mean edge.

*Tags: General Technical*

---

**river_shah** - *09:27:07*

If you truly want to avoid heuristics then my suggestion is to look at markowitz multi period mean variance optimization (this is the generalisation of kelly to multiple bet scenarios with no assumptions of independence either)

*Tags: Performance, Strategies*

---

**Mo** - *09:35:29*

If you really do base it on some global bankroll then you should really take account all of the existing bets or simultaneous bets to be placed

*Tags: General Technical*

---

**Oliver Varney** - *09:36:56*

each strategy has its own bankroll, but within the strategy itself there are many bets that may have not settled before a new bet opportunity becomes available

*Tags: Strategies*

---

**Oliver Varney** - *09:39:02*

am I thinking about bankroll wrong / naively

*Tags: General Technical*

---

**Mo** - *09:39:27*

I think it's a perfectly legitimate way to think about bankroll

*Tags: General Technical*

---

**Mo** - *09:39:45*

When I used to use Kelly I would have a bankroll per match

*Tags: Strategies*

---

**Mo** - *09:40:37*

Nowadays I would prefer the concept of an overall bankroll or a per strategy bankroll

*Tags: Strategies*

---

**Mo** - *09:46:52*

Kelly is just maximising the geometric growth rate or equivalently expected log return. You can fairly easily calculate the expected log return by integrating over all possibilities for simultaneous bets or some existing unsettled bets plus new bets. Then maximise using your favourite optimiser (although you can work it out analytically as well)

*Tags: Strategies*

---

**Michael** - *15:38:01*

[@UBS7QANF3](@UBS7QANF3) are you still using Kelly?

*Tags: Strategies*

---

**Sam Asin** - *22:23:34*

hoooooooooooooooolllllllllllllllllllllllllyyyyyyyyyy crap. I realize this isn't the place for python tech support, but since there are a lot of python/pandas/data people  here

*Tags: Feature Engineering*

---

**Sam Asin** - *22:28:04*

[https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas](https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas)

*Tags: Feature Engineering*

---

**Sam Asin** - *23:08:39*

but now i know where to look to try to fix this

*Tags: Errors Debugging*

---

## 2021-01-06

**Sam Asin** - *00:33:07*

Yeah I'm gonna assess a bit more what I can do differently now that I know what's going on. Gotta think through how to change it. Gonna work on it myself for a while and I can ask again if I have problems, but best way to learn I find is to muddle a bit.

*Tags: General Technical*

---

**Sam Asin** - *07:11:42*

thanks [@UBS7QANF3](@UBS7QANF3) this is all really helpful

*Tags: General Technical*

---

**Sam Asin** - *07:12:32*

i'll keep working my way through and ask questions as they come up!

*Tags: General Technical*

---

**bb** - *08:17:27*

[@U01J98RDHRN](@U01J98RDHRN) This is a great talk about how pandas works behind the scenes which should help to explain the indexing issue you were facing and get better understanding of it all



[https://www.youtube.com/watch?v=CowlcrtSyME](https://www.youtube.com/watch?v=CowlcrtSyME)

*Tags: Feature Engineering*

---

## 2021-01-07

**Lee** - *14:05:05*

Does anyone see any issues running flumine using ECS with ec2?

*Tags: Deployment*

---

**Lee** - *14:09:38*

I should probably rephrase my question. Currently I use dokku on digital ocean but am migrating everything to aws so considering using ECS

*Tags: Deployment*

---

**Jonjonjon** - *16:04:15*

Does anyone use Sympy to help them hack through betting equations?

*Tags: Strategies*

---

## 2021-01-08

**Oliver Varney** - *06:35:59*

Those using models it may be worth checking your data providers for Lingfield and Newcastle today. Some strange race types / variables

*Tags: Strategies*

---

**bb** - *08:07:05*

I personally give these races a miss for all but the true bumpers at the beginning of the cards. Trying to accurately assess the chances of a horse stepping back from a 3 mile chase to a 2 mile bumper is not something I think my models are well suited for.

*Tags: Strategies*

---

**Michael** - *08:08:12*

How do you treat normal bumpers? Don't they present the much the same problem?

*Tags: General Technical*

---

**bb** - *08:09:49*

I have a seperate set of models for juvenile races with a much heavier weighting on pedigree and aptitude for the distance

*Tags: Strategies*

---

**Michael** - *08:23:18*

It's certainly true that there aren't usually that many of these races so I can see why you might sit them out. That said; you can end up classifying quite a lot of races as 'unusual' for one reason or another, for example the longest races in either NH or Flat racing can have very little associated form and there are always mountains of confounding variables. If you were to over-stretch that approach you'd miss out on quite a lot of markets. A lot of our money comes from being calm and consistent when others are over rating the significance of one variable or another, it's often less about our amazing predictions and more about our not getting carried away. There's a balance to strike between checking the validity of your model and just letting your variability shake out over as many markets as possible.

*Tags: Strategies*

---

**Oliver Varney** - *08:28:02*

in my opinion is all very reliant on your models + techniques + how the data is used in training used which is very individual. Im guessing most AI models will struggle as the sample size is small and a large number of expected inputs are missing. My models are built to generalise, but I think if I built more an anomaly detection algorithm that would hold up better.

*Tags: Strategies*

---

**bb** - *08:32:19*

One of my colleagues who knows more about racing than I could ever hope to, but nothing about modelling, loves betting in these markets and experience has shown that the markets he loves are where my models tend to fall over

*Tags: Strategies*

---

**Michael** - *08:32:59*

Could you construct some kind of 'poor data' races model? We do get this problem every year for one reason or another. Thinking back we've had floods, snow, drought, equine flu, foot and mouth.... there's always something.

*Tags: Strategies*

---

## 2021-01-14

**Mick** - *17:00:57*

No, I'm just getting HTTP ERROR 403

*Tags: Errors Debugging*

---

**James T** - *23:42:02*

Just in case people aren’t aware, there’s a Gambling Commission public consultation on gambling harm and interventions going on. Here’s a link in case anyone wants to make their own comments (you don’t have to answer all questions, but you may find page 7 or 11 relevant for example):



[https://consult.gamblingcommission.gov.uk/author/remote-customer-interaction-consultation-and-call|https://consult.gamblingcommission.gov.uk/author/remote-customer-interaction-consultation-and-call](https://consult.gamblingcommission.gov.uk/author/remote-customer-interaction-consultation-and-call|https://consult.gamblingcommission.gov.uk/author/remote-customer-interaction-consultation-and-call)

*Tags: General Technical*

---

## 2021-01-15

**D C** - *09:37:31*

Is anyone else quite worried about the potential impact that this review might have on the exchange model? Social media is a cesspit for sure, but I have seen talk from people who "work in the industry" of monthly loss limits and means tested deposit limits. I don't want to see people having problems from gambling, but there must be better ways to deal with that than blanket limits and restrictions.

*Tags: Strategies*

---

**D C** - *10:35:24*

Totally agree. I think the exchange model would be trashed completely if loss limits were forced on users and that would be game over for me. It does make me angry that such things are even discussed as an option - can you imagine the uproar if people were only allowed to consume 5 units of alcohol per week or 10 cigarettes per week. I can piss my life savings up a wall and nobody is concerned but if I want to gamble with the same money its a problem. Really hope common sense prevails, but given recent events I have very little faith in decision makers right now.

*Tags: Strategies*

---

**D C** - *11:03:07*

At the end of the day, if people are genuinely addicted to gambling they will find a way to do it. Be it some dodgy bitcoin casino or worse. Encouraging people to seek help and getting bookies to flag problem accounts and act on it has to be better. After all, they already KNOW about most of these problem accounts but are clearly allowed to get away with doing nothing about it (other than target them with free bet offers and other stuff that fuels addiction).

*Tags: General Technical*

---

**James T** - *11:09:55*

Yeah, that’s talked about a bit in the “unintended consequences” section - that people might just move to black markets for example. I think anything related to addictions is a tricky problem to solve. 

*Tags: General Technical*

---

**D C** - *11:34:36*

You just feel that bookies know full well who the problem gamblers are but are currently allowed to pretend that they don't and let it slide. Ultimately though, only a problem gambler themself can make that decision to seek help.

*Tags: General Technical*

---

**bb** - *11:58:04*

One potential thing to be aware of for modelling with RPRs is they are not set in stone and are sometimes adjusted retrospectively. This is not a frequent thing but is enough to be a potential source of data leakage and throw off a model in production

*Tags: Deployment, Strategies*

---

**Newbie99** - *18:30:54*

I'm sure this has been asked before, but I couldn't see anything in the search...



Does  `order.elapsed_seconds` start when an order is placed in Flumine, or when an order is executable (in short I'm just trying to clarify whether when order.elapsed = 1 for in-play does that mean the order has been placed, post delay and has been live for 1 second, or does that mean it has been pending and is now turning active)?

*Tags: Deployment*

---

**liam** - *18:35:43*

[https://github.com/liampauling/flumine/blob/2adcd24379e07dfc1a017ffcc7895d99102814ee/flumine/order/order.py#L223|https://github.com/liampauling/flumine/blob/2adcd24379e07dfc1a017ffcc7895d99102814ee/flumine/order/order.py#L223](https://github.com/liampauling/flumine/blob/2adcd24379e07dfc1a017ffcc7895d99102814ee/flumine/order/order.py#L223|https://github.com/liampauling/flumine/blob/2adcd24379e07dfc1a017ffcc7895d99102814ee/flumine/order/order.py#L223)

*Tags: General Technical*

---

## 2021-01-16

**Ruben** - *08:03:42*

Good morning gents, do you know of an API that can be used to retreive prices from the global befair exchange (i.e. [http://betfair.com|betfair.com](http://betfair.com|betfair.com)). I can't bet on the global exchange so I don't have access to the official global API, but I think my model would perform a lot better if the odds used as input came from the global exchange vs my local exchange, which has less volume

*Tags: Strategies*

---

**Michael** - *13:38:17*

You're probably doing exactly the right thing. If you're investing relatively modest sums then a couple of Index funds is ideal because it limits your transaction costs. That's what I did to start with. When the amounts get bigger I think it makes more sense to buy a broad portfolio of individual shares with a leaning towards value as index funds always slightly under-perform the index because of costs and fees whereas shares held directly give you all the performance of those shares. Although I have done well from investing I've always made much more money from betting so I never found it all that exciting. This is likely to be true of any investment. However you probably already know that in real life betting profits don't compound like they do in the movies so you have to put the money somewhere....

*Tags: Performance, Strategies*

---

## 2021-01-18

**Oliver Varney** - *13:58:27*

yes, highly likely its just the subset of runners my models been picking and a very very small sample size.

*Tags: Strategies*

---

## 2021-01-19

**Jonjonjon** - *09:19:11*

My models are very crude, and I need the skew to work in my favour. So if I have an IT issue I still have the chance of winning big, rather than losing lots

*Tags: Strategies*

---

## 2021-01-20

**Jonjonjon** - *15:15:29*

Has anyone had problems with overheating hard drives?



I have a Samsung Evo 970 plus NVME. And 3950X cpu. I'm using it to backtest with Flumine on 32 cores.



So when that happens, my machine is looping through 32 files at the same time. And the NVME gets to over 70C.



I'm wondering if it could be better to load the full files to RAM, and then iterate over them from RAM. This will obviously use more RAM, but the files are smaller anyway. Perhaps the user could specify which method they want to use?



What do you think [@U4H19D1D2](@U4H19D1D2)?



This is the bit that I'm thinking of refactoring: [https://github.com/liampauling/betfair/blob/10b268673923dcfaf3847b28ddcd963f775661c5/betfairlightweight/streaming/betfairstream.py#L331-L356](https://github.com/liampauling/betfair/blob/10b268673923dcfaf3847b28ddcd963f775661c5/betfairlightweight/streaming/betfairstream.py#L331-L356)

*Tags: General Technical*

---

**Jonjonjon** - *16:43:43*

I've done some performance tests. There doesn't seem to be any speed difference if I load the files into ram first, and then iterate over that. It seems to reduce the SSD temperature by 10-20C. Hard to test this well, as if I run the test twice in a row on the same data set, it doesn't heat up on the 2nd run.

*Tags: Performance*

---

**Jonjonjon** - *16:54:52*

[@U4H19D1D2](@U4H19D1D2) By patch, do you mean doing something on my side instead of making a change to the bflw codebase? Something like this?

[https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1608035327035400?thread_ts=1608012009.025500&amp;cid=C4HL6EZTQ](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1608035327035400?thread_ts=1608012009.025500&amp;cid=C4HL6EZTQ)

*Tags: General Technical*

---

**V** - *18:04:56*

I mean actually pricing the underlying probs and trading deviations to their models 

*Tags: Strategies*

---

**V** - *18:05:41*

Modelling the actual sports

*Tags: Strategies*

---

**bb** - *18:41:55*

*So you’re conflating two numbers here. Pre race what you are seeing is a projected RPR that the horse will run too. This is is a projection generated pre-race by the in house handicappers for the Racing Post. As you say these numbers are no longer accessible after a race has been run.* 



*What you see post race is a performance metric for the ability the horse showed on the day. This is set by the handicappers taking into account a number of factors including the weight carried by the horse, distance beaten/ahead of the other horses in the race any trouble in running etc. This number is generally set but is also the one I was warning about potentially being adjusted according to subsequent information (e.g. the race turning out to be a strong form race).*

*Tags: Performance*

---

**Mo** - *18:51:16*

Don’t get too excited I’m not sure it will solve your point by point data problems 

*Tags: General Technical*

---

**Mo** - *18:52:50*

From memory, the point by point data is not part of the database but is pulled in on demand when you click a button for a given match in the application. I’m not sure if that still holds and how hard it would be to reverse engineer where it’s getting it from

*Tags: Performance*

---

## 2021-01-21

**Misha** - *00:25:52*

OnCourt is our base for stats. Over 1.4 million matches. I automate updates (every 12 hours) from the .mdb file into my own database structures in SQL Server

*Tags: Deployment*

---

**Misha** - *23:27:20*

To get it right I parsed the lot, over and over again, putting the data in a database checking, updating, then doing it again

*Tags: General Technical*

---

## 2021-01-24

**Ruben** - *15:40:26*

good evening all, system design question: let's say I'm pulling data from an API, and I would like several script running in a server to be able to access that data, without each of them having to re-query the API. What's the best way to query the API once, and republish data so different scripts can access it?

*Tags: Deployment*

---

## 2021-01-27

**Jonjonjon** - *16:44:22*

It could be answer to the question of what to do with Betfair winnings.

*Tags: General Technical*

---

**MacrcoPolo** - *19:38:14*

First tip if you go down this route is to get hold of some intraday data, even a daily model should try and avoid using the closing prices - they're not executable, they're marked from a closing auction which isn't a price you can be certain to get

*Tags: Strategies*

---

**Newbie99** - *19:45:57*

IG Index have an API too (streaming for Indices &amp; commodities + equities on request) and REST for everything else.



The tax implications are probably more relevant for financial markets, plus of course leverage (i.e. do you self declare as a professional and get greater leverage but lose guaranteed stop loss protection, for example).

*Tags: General Technical*

---

**river_shah** - *19:48:46*

Re asset class for retail quant, I would recommend to steer clear of CME and EUREX futures trading. They are extremely deterministic and dominated by &lt; 5 players for delta one strats. If you know about options, then your space opens up significantly as options trading (especially delta neutral strats) are more about modelling than execution speed. Look at more niche sectors, for example agricultural products, Chinese products, LME metals. I am not sure about market access for those at the retail level though.

*Tags: Performance, Strategies*

---

**Newbie99** - *19:55:42*

Have you had problems with IG out of curiosity, or is it just the offering?

*Tags: General Technical*

---

**Unknown** - *19:59:18*

if it helps:

*Tags: General Technical*

---

**MacrcoPolo** - *19:59:35*

same question about their natural gas

*Tags: General Technical*

---

**Alex A** - *20:52:21*

You can do some pretty simple maths to work out roughly what an options price should be, and I’m sure this applies to other assets too, but a load of exchanges have “speed bumps” so you can put up prices, and then if the underlying moves against you the aggressive orders face a 250 ms (or whatever) delay, so even though you’re up against people who are colocated running FPGAs, you can still get out of the way running a simple python bot over the internet.

*Tags: Performance*

---

## 2021-02-01

**Lee** - *09:33:19*

Has anyone used zappa and if so what's your thoughts on it in relation to maintenance/monitoring? (compared to a docker image)

I'm also curious about any potential drawbacks of using zappa schedule over an independent lambda. I quite like the idea of being able to reuse django models.

*Tags: Strategies*

---

**Lee** - *09:35:39*

nice, i'll give it a go. It's the schedule that's really sold me. Being able to create tasks quickly and interact using the same django models

*Tags: Strategies*

---

**liam** - *09:37:23*

i use it due to the scaling, because the load on my API varies a lot! I would either have to have an oversized EC2 or mess around with ASG instead I just let the gateway and lambda handle it

*Tags: Deployment*

---

## 2021-02-03

**Alessio** - *08:35:57*

Yes that's very distilled experience. The book is a bit "arrogant" i'd say, i.e. it sounds like "these are the problems you will find, here is THE MIGHTY SOLUTION"

*Tags: General Technical*

---

**Newbie99** - *09:59:57*

[https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1610917619044400](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1610917619044400)

*Tags: General Technical*

---

**liam** - *12:34:20*

I see [https://apply.workable.com/longshot-systems-ltd/j/DC5582D1E0/|longshot systems](https://apply.workable.com/longshot-systems-ltd/j/DC5582D1E0/|longshot systems) are hiring, not sure if anyone on here works for them? / I wonder if they use bflw?

*Tags: General Technical*

---

**Robert** - *13:12:55*

as a more general point: lets say I want to get hold of a dataset for UK horse racing (e.g historical sectional data) and its not easily accessible online.  But I suspect someone out there may have collected this data.  Does anyone have any tips or contacts who might be able to help with this?

*Tags: General Technical*

---

**MacrcoPolo** - *14:17:12*

Welcome to horse race modelling (missing data...). Do I recall you work at seemlessML?

*Tags: Strategies*

---

## 2021-02-04

**Misha** - *00:39:35*

My modelling suggests (and actual betting suggests) that they just aren't a big proportion of losses (and sometimes we win from then as well)

*Tags: Strategies*

---

**Misha** - *00:41:02*

So to answer the questions directly:

*Tags: General Technical*

---

**Misha** - *00:42:01*

1. The Betfair API does have information about injuries (but no WTA at the moment, and I don't think it covers the Australian season)

*Tags: General Technical*

---

**Misha** - *00:46:58*

Last thing from my point of view: it seems my model is most profitable when the market prices are WAY out from what would be expected. For big price swings the market gets it wrong more often than right (and that surprised me). But to be profitable you need to hold your nerve, because it makes for some truly awful losses

*Tags: Strategies*

---

**Mo** - *07:24:01*

Detecting strange market prices also has value for detecting match fixes but you do need to be careful as [@U016535QCJ2](@U016535QCJ2) says because to find value you need to disagree with the market

*Tags: Errors Debugging*

---

**V** - *23:50:14*

Interesting read for those into this kind of stuff: [https://www.eurex.com/resource/blob/48918/74e70365580415639ea4628ec25a6b72/data/presentation_insights-into-trading-system-dynamics_en.pdf|https://www.eurex.com/resource/blob/48918/74e70365580415639ea4628ec25a6b72/data/presentation_insights-into-trading-system-dynamics_en.pdf](https://www.eurex.com/resource/blob/48918/74e70365580415639ea4628ec25a6b72/data/presentation_insights-into-trading-system-dynamics_en.pdf|https://www.eurex.com/resource/blob/48918/74e70365580415639ea4628ec25a6b72/data/presentation_insights-into-trading-system-dynamics_en.pdf)

*Tags: Deployment, Strategies*

---

## 2021-02-05

**liam** - *15:02:26*

Pretty cool:



```The Eurex exchange experienced an increasing amount of "speculative triggered" packets during 2019 and 2020. These

packets are sent by Trading Participants based on receiving the first bytes of market data in anticipation of potential trading

opportunities.

During processing of further bytes of these market data packets the data of the requests can still be modified to non-trading

requests in case the incoming market data turns out not to show a trading opportunity. This is possible if the respective fields

of the requests have not yet been written to the underlying physical ethernet layer.

Various adjustments of the Excessive System Usage (ESU) Fees mitigated the problem only for a limited timeframe and the

amount of speculative requests became a load issue and an increasing amount of orders went into the orderbook.

The graph shows this development by means of the ratio of sent versus executed IOC orders for Eurex benchmark products```

*Tags: Strategies*

---

**Oliver Varney** - *16:42:22*

kind of on topic, just out of curiosity, do people generally watch races or not? If so, is it just the odd one or two per day, or is there any rationale for doing so, i.e. strategy ideas / order checking

*Tags: Strategies*

---

**Oliver Varney** - *17:13:28*

ive just wonder whether its distracting or whether there is value in it. It can highlight issues / questions like why hasnt the strategy bet, or even give new ideas, but also its easy to lose the whole day watching races.

*Tags: Strategies*

---

## 2021-02-07

**D C** - *14:59:22*

I've been told that my problem with Wolves is "not uncommon".

*Tags: General Technical*

---

**MacrcoPolo** - *23:00:20*

I know someone who moved over just after Christmas with help from their company - it's not impossible

*Tags: General Technical*

---

## 2021-02-08

**D C** - *12:06:14*

DOGE is shit everyone knows that. But this is part of the problem - you place a bet and your winnings could be eroded or augmented based on market sentiment.

*Tags: General Technical*

---

**D C** - *12:09:41*

Don't get me wrong, I keep a close eye on Augur platform. How is the market outcome resolved on Wager platform??

*Tags: General Technical*

---

**Jonjonjon** - *12:16:18*

Could we set up our own Oracle and fix the results?

*Tags: Errors Debugging*

---

## 2021-02-10

**Misha** - *22:14:50*

Australia does have a fixed upper limit of 24, so per country it might be OK

*Tags: Errors Debugging*

---

## 2021-02-15

**river_shah** - *14:30:13*

does anyone have some tv / streaming viewership numbers for horse racing events please? curious to see what the general viewers like to watch. matched volume is obviously a proxy for viewer interest but I am sure things get skewed by horse traders.

*Tags: General Technical*

---

## 2021-02-16

**PeterLe** - *16:46:02*

Sorry I was about to add...(I know we have kelly or partial kelly, but wouldnt the above work in the same manner?)

*Tags: Strategies*

---

**Aaron Smith** - *17:07:24*

so the percentage (here 1%) is of what ever you made with the strategy so far?

*Tags: Strategies*

---

**Aaron Smith** - *17:11:04*

the only fix point this could ever have (a point where stakes remain the same) is when (total) earnings remain the same

*Tags: Errors Debugging*

---

**Aaron Smith** - *17:17:05*

like, always have it decide after 1 week (or what ever time period) decide if it should increase given its performance or decrease

*Tags: Performance*

---

**birchy** - *18:42:18*

[@UQL0QDEKA](@UQL0QDEKA) have you not heard of Martingale? :rolling_on_the_floor_laughing:

Seriously though, fractional Kelly is the way forward. Rather than using the _actual_ bank for calculating, I would use a fixed bank size and update daily/weekly/every 1000 bets/whatever.

*Tags: Errors Debugging, Strategies*

---

**liam** - *18:44:57*

Kelly is for optimising your bankroll whereas you will hit market capacity issues (is this inplay?) As you know it won’t take much for your pnl to fall very fast in which case you won’t optimise your profit but just oscillate between profit and loss as it tries to stabilise but this should be simple to model 

*Tags: Strategies*

---

## 2021-02-18

**tobsve** - *10:13:34*

```logging.basicConfig(level=logging.DEBUG)```

What if you sett to above?

*Tags: Errors Debugging*

---

**Jonjonjon** - *10:27:42*

So if I update my code to the following, it prints out 2 lines:



```import logging

from pythonjsonlogger import jsonlogger

import time



new_logger = logging.getLogger(__name__)



# This should only get run once

new_logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



# formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")



custom_format = "%(asctime) %(levelname) %(message)"

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime



stream_handler = logging.StreamHandler()

stream_handler.setFormatter(formatter)

new_logger.addHandler(stream_handler)



[http://new_logger.info|new_logger.info](http://new_logger.info|new_logger.info)('hello')```

output:



`{"asctime": "2021-02-18 10:26:36,642", "levelname": "INFO", "message": "hello"}`

`INFO:__main__:hello`



How can I update that to input print out 1 line?

*Tags: General Technical*

---

**Aaron Smith** - *10:38:44*

i m far from being a coding expert, but does your IDE effect your output? Its still python generating the output? :thinking_face:

*Tags: General Technical*

---

**Aaron Smith** - *11:42:13*

my last OS update made a big chaos aswell. My VS is no longer showing syntax-mistakes live (have to safe for it to show any errors) and even then, it seems like it misses 90% of errors. Also no more auto-complete. My terminal lost all its colours and no longer tells me which git branch i m in. I read some stack-overflow, but couldnt find the root cause and basically decided to postpone fixing that (has been a month now :smile: ) and now i m just very careful while writing code :smile:

*Tags: Errors Debugging, Deployment*

---

**Aaron Smith** - *11:42:42*

Should probs have fixed it long ago, but i hate doing that kinda stuff :smile:

*Tags: Errors Debugging*

---

## 2021-02-19

**river_shah** - *14:36:52*

I feel gambling on horses is making me a superstitious person. anytime model backs big on long shots and I watch the race, they never win. A watched pot never boils. Now I just let the model bet and sit with eyes shut tight.

*Tags: Strategies*

---

**MacrcoPolo** - *14:39:00*

in fairness long shots don't win often regardless of your model

*Tags: Strategies*

---

## 2021-02-20

**James T** - *11:56:57*

To check turnover charge races I used to have a fixed venue list but that always had mistakes and even Betfair seemed inconsistent when asked. Now I just check the market description rules for the string “this is a racing nsw turnover charge market”. 

*Tags: Errors Debugging*

---

**Misha** - *11:58:57*

Fixed, Tote, and Betfair

*Tags: Errors Debugging*

---

**James T** - *11:59:12*

I wasn’t aware that there was a separate AUS only liquidity pool. I thought it’s always been global since the start. Used to be hosted in the AUS (and therefore had more latency from UK), but is now hosted in UK or IRE or whatever. 

*Tags: Performance*

---

**Misha** - *12:05:53*

Not sure how a general strategy would work

*Tags: Strategies*

---

**Jonjonjon** - *13:10:24*

Does anyone know how to use Python to do transactions on the Cake crypto currency?

*Tags: General Technical*

---

## 2021-02-28

**Alessio** - *15:52:16*

hey mate.. I started hitting this one today as well.. exactly identical.. did you manage to figure out where the problem was?

*Tags: General Technical*

---

## 2021-03-01

**Dave** - *09:49:09*

Maybe there is a fixed initial cost for alarms and any additional alarms are negligible in cost. I'll dig

*Tags: Errors Debugging*

---

**Dave** - *09:50:32*

Oddly when I breakdown by API, it groups my CloudWatch costs as MetricStorage:AWS/S3. So perhaps CW is storing results of the monitoring in S3 indefinitely or something

*Tags: Deployment*

---

## 2021-03-04

**Jonjonjon** - *20:37:53*

Does anyone create command line interfaces with Python?



I want to display a table of prices on the command line, with the numbers changing as prices update. I don't want to keep printing new tables.

*Tags: General Technical*

---

## 2021-03-08

**Newbie99** - *14:03:13*

This is possibly more of a maths question, than a Python one and hopefully quite a simple one, but my brain appears to be malfunctioning.



All I am trying to do, is create a function that returns the win probability for a and b (be they runners or teams) for a series n length (for now not allowing draws) on the assumption the series ends after one a or b reaches the target number of games (e.g. 3 out of 5, 4 out of 7 etc) and therefore  when calculating for a, a always has to win the final game (and vice versa).



This is what I've come up with, however what's bugging me is that the summed probabilities keeps increasing the higher number of games in the series, so I'm trying to get my head round whether I've made a coding mistake or if there is a mathematical reason for this that I've missed?



```from math import ceil, pow, comb



def calc_win_probability(n, p_a, p_b=False):



    if p_b is False:

        p_b = 1-p_a



    g = ceil(n/2)

    prob_list = []

    for i in range(g,n+1):

        a = (comb(i,g-1) * pow(p_a,g-1) * pow(p_b,(i - (g-1)))) * p_a

        b = (comb(i,g-1) * pow(p_b,g-1) * pow(p_a,(i - (g-1)))) * p_b

        prob_list.append({'games': i, 'prob_a_win': a, 'prob_b_win': b, 'combined_prob': a+b})



    return {'overall_prob': sum([p['combined_prob'] for p in prob_list]) ,'prob_list': prob_list}



t = calc_win_probability(7,2/3,1/3)



for x in t['prob_list']:

    print(x,'\n','----------------------------------------------------------')

print({'total_prob': t['overall_prob']})```

*Tags: Errors Debugging, Deployment*

---

**Newbie99** - *14:24:35*

I am making the assumption for say cricket where a series carries on regardless (and draws have to be factored in) the approach would require more work, so was ignoring that for now

*Tags: Deployment*

---

**Aaron Smith** - *14:25:33*

i dont know exactly how it works in cricket, but draws should be no problem really

*Tags: Deployment*

---

**Newbie99** - *15:37:02*

Sorry, was sidetracked.



Yes, thats why I was ignoring cricket for now, I want to determine the probability of A to win, bearing in mind that:



The series ends once A reaches x out of n (e.g. 4/7)

There can be no draws

It is know prior to the start the probability each team has of winning an individual game



So what I'm struggling to get my head round is why is it not important to discount the unplayed games and factor in that A has to win the final game (or B when in reverse)?

*Tags: Deployment*

---

**D C** - *15:48:31*

I agree with you here but if using binomial then we are assuming probabilities of each time winning are identical for each game. I can't help but feel that Binomial distribution is not quite right for this problem though. I mean take a MLB were the choice of starting pitcher has a massive effect on price. Is it not more accurate to just enumerate all possible outcomes using the respective probabilities for each distinct pair of probabilities. I feel that this question should have a simpler answer than what I am trying to make of it though.

*Tags: General Technical*

---

**Aaron Smith** - *22:03:08*

yeah, in a real world situation this will probably be over simplified, i was just aiming to solve the math questions asked. I dont know anything about cricket really :smile:

*Tags: General Technical*

---

## 2021-03-09

**Newbie99** - *15:00:51*

That makes sense, however the reason I wanted to go down this approach is to then try to work out after x games of the series, what is the probability then?



So I thought trying to understand this might help me get my way around the next step, as say we're 3 games in then, the probability will have changed (potentially dramatically) depending on the first 3 results.



In essence, my thought process was as follows:



1. Get starting price (modelled or market doesn't matter for now as its hypothetical)

2. Derive probability of winning each game from starting price (assumes scoreline is 0-0 at the start). I was going to attempt o reverse engineer this somehow once I understood the concept a bit better.

3. Once probability per game is known, then attempt to create live probability based on games won so far / remaining.

Is that approach logical (I appreciate its overly simplistic, its more conceptual than anything else at the mo)?

*Tags: Deployment, Strategies*

---

**river_shah** - *20:19:06*

beginning to look at in-play football a bit more. orders adds are N second delayed and take N seconds to reflect in the stream. order cancels are network / matching engine latency instantaneous and reflect in the stream straight away? If guys with better pictures and more manual attention are cancelling a side, do my algos see that behaviour quickly enough to take defensive measures themselves?

*Tags: Performance*

---

**MacrcoPolo** - *20:29:40*

it's a common question - I believe the situation is that you can't cancel an order without an order id, so you can't cancel an order until you have a reply after N seconds.

*Tags: General Technical*

---

## 2021-03-10

**river_shah** - *10:05:09*

what is the best way to achieve async, long running function evaluation that is compute heavy without blocking the main thread in python? want to fire off a function with some parameters, main thread keeps running, and then get called back when it is done with the results provided. function orchestration can take time (so process pool pickling etc is acceptable delay as long as main thread not blocked for too long). don’t think asyncio is what I am looking for. Don’t want to introduce zmq pub sub complexity.

*Tags: General Technical*

---

**river_shah** - *10:06:42*

function params and return objects are smallish numpy arrays. can use pre allocated shared mem buffers but that will be a small optimisation

*Tags: General Technical*

---

**Michael** - *10:28:21*

On a related topic - can I add to [@U01B8031PM1](@U01B8031PM1)'s question and ask if it makes sense to re-write complex functions in C and what the threshold is for when that might become worthwhile?

*Tags: General Technical*

---

**liam** - *10:30:20*

You can make python pretty fast (hopefully proved that with bflw/flumine), C comes at a cost in terms of time/maintenance, happy to look at code if you want?

*Tags: General Technical*

---

**Mo** - *10:31:37*

IMVHO, yes. The threshold would be if you can’t otherwise generate predictions for the strategy in time to act on them...

*Tags: Strategies*

---

**river_shah** - *11:06:42*

[@U4H19D1D2](@U4H19D1D2) was hoping for something like this: [https://github.com/taskflow/taskflow](https://github.com/taskflow/taskflow) (see the section on launch async tasks) but for python. ok, looks like with python I will need to embrace zmq for these kind of function calls. totally happy with python speeds, however the gil does get in the way of these async function / task evals

*Tags: Performance*

---

**river_shah** - *11:28:45*

sorry if this is more stack overflow question

*Tags: General Technical*

---

## 2021-03-11

**river_shah** - *11:58:29*

I guess I am going with 80 /20. I am not at the limit to squeezing everything I can re horses but the models are decent enough (and run fairly autonomously) so gives me time to look at other things too. Next steps for horses are sizing up more but for that I need market feedback (acquired over months).

*Tags: Strategies*

---

**liam** - *11:59:50*

Rapid, how have you been able to develop/deploy so quick? (ignoring flumine)

*Tags: Deployment*

---

**river_shah** - *12:00:08*

well, lets not discount flumine and bflw. amazing libraries!!

*Tags: General Technical*

---

**river_shah** - *12:12:24*

the single biggest factor in modelling bets well I find is options trading background

*Tags: Strategies*

---

**Beeblebrox** - *12:13:33*

I'd second that. I was using my own library/bot for running strategies, but bflw/flumine make developing/testing/deploying strats way simpler and quicker, so thanks [@U4H19D1D2](@U4H19D1D2)

*Tags: Deployment*

---

**river_shah** - *12:19:06*

so obviously there is only so much I can share here but price action trumps fundamentals most of the time (again; my biases not true for everyone and strategy dependent)

*Tags: Strategies*

---

**Dave** - *15:52:51*

For racing I have generally found price action far more useful than fundamentals. Maybe because my skills for modelling from fundamentals suck, but one thing that sticks out to me is that paragraph from that article about Bill Benter where incorporation of market data massively proved his pnl.

*Tags: Strategies*

---

**Dave** - *15:53:36*

But i've found much more room for modelling from fundamentals in footie...

*Tags: Strategies*

---

**river_shah** - *18:02:52*

modern exchanges are radically different from betfair and a surprisingly huge amount of volume and opportunity is derived from latency races. none of that applies here. that being said, constantly thinking about bets, expectations, risk management, those skills are transferrable

*Tags: Performance*

---

**river_shah** - *18:36:02*

fixed it

*Tags: Errors Debugging*

---

**MacrcoPolo** - *21:32:19*

I think that's mostly it... I think it helps to just remember that in both markets people have different goals. Investing in stocks may be generally +ve EV, but if that was the end of the story then market makers would lose money. I think the goal of most in gambling market is to get a bet on and have some fun. In the stock market these participants exist too, it's just that the proportion of folk looking for speculative fun from a bet is higher in betting markets. If the point is that gambling achieves very little economic benefit, then I whole-heartedly agree.

*Tags: Strategies*

---

**Misha** - *22:12:13*

There is also a difference if you model on the results of the sports rather than market movements. There is no equivalent in financial trading, and there is no equivalence to the stability of returns with a good model based on sporting results. I know of two very large organisations in sports betting and financial trading. The sports betting organisation checks returns every few weeks, The financial trading organisation checks positions every few hours

*Tags: Strategies*

---

**Misha** - *22:52:06*

There are no such thing as market results based on the fixed rules of a game. It's an area where if you do this, sports betting has no financial equivalent

*Tags: Errors Debugging, Strategies*

---

## 2021-03-12

**Mo** - *08:33:39*

I suppose the newer dividends based on match performance that were time limited were an attempt to encourage more trading activity

*Tags: Performance, Strategies*

---

**Jonjonjon** - *08:36:30*

Poor guy. That is the problem with that sort of investmet. Your capital is always at risk.

*Tags: General Technical*

---

**Paul** - *19:50:06*

On the Football Index story: I encountered one of their senior people at a dinner for people in senior positions in London tech firms (for those who understand such things: back then I was a CTO of a scrappy healthcare startup, these days I'm just a lowly SDM in a FAANG), and he was talking about how tough he was finding it. Digging a bit I discovered he had moral questions about how some in the business behaved and wanted advice. The moment I mentioned I was knowledgable about exchanges and trading on sports markets and that I was mates with some of the data guys at City Football Group, he clammed up. Seems like there was more going on there than even I realised, perhaps.

*Tags: Strategies*

---

**Paul** - *19:54:51*

That was back in 2019 I think. I don't think I marked it as possible ponzi in my head, but I decided to keep my money away because _any_ moral behaviour questions at that level (even if it's being an arse to subordinates), is enough to make me worry about integrity

*Tags: General Technical*

---

## 2021-03-13

**Aaron Smith** - *14:27:25*

Correctly configuring field filters can help by:

• Reducing the size (and time) of initial images

*Tags: General Technical*

---

## 2021-03-14

**IndikaE** - *08:10:15*

Thanks. It does seem like a good idea to use ips. But as a complete beginner I don’t even know how to get historic data for IPS. Is that even available? My fundamental problem is that I am relying on a data feed that doesn’t provide timestamps, but only times of events relative to the beginning of each half. And I need to sync that up with betfair market data Using ips seems very reasonable, but I don’t know how to get ips historic data for backtesting. Is that possible?

*Tags: Getting Started*

---

**Misha** - *08:13:24*

As a veteran of scraping live data, it's always a good idea to come in on the URL's used by a manual user

*Tags: Deployment*

---

**Mo** - *08:22:43*

Alignment of data feeds with Betfair price data is a big problem. The best solution is collect both yourself in real time. In the absence of that, you will have to do the best you can, for example:



1. Restrict yourself to backtesting only the first half, assuming here that the start of the match is more accurately capture by the inPlay flag than the second half

2. The trigger described above

3. Time when first half markets close + X minutes

4. Identify when OU goals markets odds start decaying again

5. Use some combination of these methods to narrow down the window in which the first half must have started

*Tags: General Technical*

---

**IndikaE** - *08:39:16*

This is valuable information to me. I will consider starting scraping the IPS. I really only need a rough estimate of second half time stamp, so I think I will will rely on a combination of the proposed heuristics- including the bet delay. Already doing point 1. , btw! My strategy does not need very exact timing - for backtesting I just need to know that I am not using future events to predict the past (of course I don’t want preds to be wildly dated - but when backtesting I prefer to err on the side of caution ). And thanks for pointing me in the direction of IPS - I might try it for better syncing in production. You guys are great :pray:This was one of the last unsolved problems blocking me from deploying my first strategy - now I am pretty excited!

*Tags: Deployment, Strategies*

---

**D C** - *21:39:50*

Its a fair point. But I think it likely that most people here in the money do so via automation. Some of the stuff listed on the course sounds a lot like the sort of questions people ask here (how to calculate my EV etc) so that is why I posted it. Clearly it won't be for everyone.

*Tags: General Technical*

---

## 2021-03-15

**Paul** - *11:47:54*

There is plenty of free and cheap materials out there that will do wonders - I noticed [@UBS7QANF3](@UBS7QANF3) put up a list of books last week which I owned half of, the other half are now in my wishlist - and I think getting diverse thinking can only help you, but a little Bayesian thinking can help weight inputs. People posting perfect trading positions on twitter and asking for thousands for training and academics who know the theory but don't seem to be interested in the practice tend to go towards one end of the spectrum compared to books and papers written by people with proven tracks records, to my mind

*Tags: Strategies*

---

**Paul** - *11:50:28*

For example, if you are interested in a fundamentals approach, and you haven't read the (freely available) Benter paper - even though it might not be very helpful today - and thought about it, can you quantify exactly what it is you are hoping an academic is going to help you with before you spend your money that could be part of your bankroll?

*Tags: General Technical*

---

**Paul** - *12:19:38*

"I have an excellent trading strategy that makes me $100k a MONTH! And I'm prepared to absolutely destroy it by letting you in on my HOT SECRETS for just $3k! Discounted to $1k for 24 hours!"

*Tags: Strategies*

---

**Michael** - *12:21:46*

I suppose that's a question of reasonable marketing an how the course is described. There are certainly some on the wrong side of that line.

*Tags: General Technical*

---

**D C** - *14:19:16*

I agree if we are talking about some shithouser like "The Badger" who "trades" allsorts but focuses on teaching IP horse racing traders how to "race read" using video streams delayed by who-knows-how-many-seconds. Now as an inplay botter I recognise that I benefit greatly from scum like him duping newbies with some pisspot e-book and making them think they can make money manually trading inplay against video lag/drones/GPS/tracksiders, but it does not sit comfortably with me at all from a moral perspective.



But now compare the other side of the "courses" coin. Imagine someone teaching a course on multinomial logistic regression to an audience who want to model probabilities of horses in a race using historical data/form etc. Or basic poisson regression so you could implement dixon-coles or some ML technique - specifics don't really matter provided it is an actual subject that the tutor has expertise in. The application area (making money from sports betting) is the selling point but paying to learn the methodology from a quality teacher is by no means "dodgy" even if afterwards the technique does not yield profit. After all you can have the right tools but they might not be good enough unless you have the right data (be that bespoke data or fast stream stuff etc). I think I know the types you are referring to though [@U016TGY3676](@U016TGY3676) and I agree with you for the most part. Nobody with an edge is going to sell it on unless they at stage 3 in your list - and after that point that edge will likely evaporate quickly the more people start to utilise it.

*Tags: Data Quality, Strategies*

---

**MacrcoPolo** - *15:23:12*

Liam when is the next bflw meetup once the pubs open?

*Tags: General Technical*

---

## 2021-03-16

**river_shah** - *15:06:58*

Don’t think my models are calibrated for races that match £5M+. Still making money but nowhere around what the raw matched volumes would indicate.

*Tags: Strategies*

---

**Alessio** - *21:38:21*

hey man, random question, where did you find this one? I was looking at my browser around the site and realized I don't see where (and how often) they call that endpoint :slightly_smiling_face:

*Tags: General Technical*

---

## 2021-03-17

**river_shah** - *09:18:25*

Imagine implied commission is 0, you have an uber model that never loses in any market. You paid £X in commission for the week. Betfair still divides X by 2 for the PC offset?

*Tags: Strategies*

---

**Mo** - *09:33:29*

Not something I've thought about before [@U01B8031PM1](@U01B8031PM1). It is worth thinking about what the commission generated rate of your strategy is [@U01A8EKD545](@U01A8EKD545) because it determines what rate of PC you pay

*Tags: Strategies*

---

**James T** - *09:39:29*

Yeah, a strategy that is volatile in its returns pays less PC than one which wins consistently even if they have the same absolute return. 



That’s because a win generates 1% implied comm, and a loss generates 1.5% comm. So in the case you win £100 and lose £100, you’ve generated £2.5 comm for PC, but only paid a physical £2 (from the winning bet). So breakeven strategies actually make you money from a PC perspective if you are on 2% comm. 

*Tags: Strategies*

---

**Chris C** - *11:14:17*

Thanks guys, really interesting. I guess I have really underestimated how the implied commission can help.

*Tags: General Technical*

---

**D C** - *13:06:11*

Well that just leads to the question at what point do you get an account manager??

*Tags: General Technical*

---

**Paul** - *21:40:46*

Random podcast recommendation: [https://twitter.com/halfkelly](https://twitter.com/halfkelly) - if you follow spanky and Captain Jack carefully there won't be much new here, but a nice 2-part audio documentary

*Tags: Strategies*

---

## 2021-03-18

**Oliver Varney** - *08:51:16*

morning, apologies if this is a basic question, im trying to get my head around how to improve my version control with SQL. I am wondering how people structure this with something like git. What does the workflow look like? How do you apply changes through environments. what should I track and what shouldnt I (i.e. everything including small data fixes?)

*Tags: Errors Debugging*

---

**Mo** - *08:52:00*

A problem I've never solved

*Tags: General Technical*

---

**Oliver Varney** - *08:53:51*

conceptually I would like to be able to just track all the objects in my database over time and better test for regressions

*Tags: General Technical*

---

**Misha** - *08:58:44*

As a solo developer I don't bother trying as the difficulties outweigh the benefits. I just take regular database backups so I can recover

*Tags: General Technical*

---

**Oliver Varney** - *09:04:01*

hmm yer seems like a nightmare, the thing I would like to be able to do (and maybe it exsists) is to be able to right click in SSMS / Azure data studio / SQL editor, alter proc make some changes commit and push then apply to the database

*Tags: General Technical*

---

**Oliver Varney** - *09:09:02*

but the only way I can see this working maybe im missing something is to have a seperate tracked folder with all the scripts basically replicating the current database objects, apply changes to those files, then run into to sql server but that seems very messy to me and I can see it being very easy for the files to go out of sync with the database objects

*Tags: Deployment*

---

**Misha** - *09:20:02*

You can - but to do this you really need some database design software that generated DDL update queries

*Tags: General Technical*

---

**Misha** - *09:20:39*

So the version control is part of the database design software, which automates the updates (generates the necessary SQL)

*Tags: General Technical*

---

**Misha** - *09:21:07*

But you need to design the database first, not update it manually

*Tags: General Technical*

---

**Jonjonjon** - *20:58:02*

What's the preferred way to look at all logs, generated by Flumine, for a particular market and strategy? I've found that my backtest result (using data that I recorded) for a market hasn't matched what actually happened, and I'm trying to find out why.

*Tags: Strategies*

---

## 2021-03-19

**Mo** - *12:28:48*

Can anyone recommend some resources for drawing things in Python which aren’t plots? For example, infographics, rendering tables, maps etc ?

*Tags: General Technical*

---

**Dave** - *12:30:12*

Used plotly for maps before. Pandas has decent styling options for rendering tables using HTML (and am sure the output can easily be converted to PDF/PNG etc)

*Tags: Feature Engineering*

---

**Alessio** - *12:37:18*

Tbh, I think Python straight is not necessarily a good one. A very common infographic backend is d3 (javascript).

*Tags: General Technical*

---

**river_shah** - *14:04:28*

My model is very simple now. `if horse == Irish: self.place_order("MATCH_ME", side="BACK")`

*Tags: Strategies*

---

**Peter C** - *16:37:32*

Does anyone here run their flumine stuff on digitalocean? I'm using them simply because it's what I'm used to - thinking about resizing my droplet/moving to aws and I'd be curious to know what size droplet anyone else who uses digitalocean gets by on.

*Tags: Deployment*

---

**Dave** - *17:27:59*

Yup. No need to bang out the big guns until you start seeing latency issues

*Tags: Performance*

---

**Peter** - *18:50:24*

A while back Liam posted how much processing he was able to push through a tiny AWS instance and some of us, i.e. me, were stunned. Streaming + BFLW/Flumine is unbelievably efficient.

*Tags: Deployment*

---

**Lee** - *18:56:49*

Adding to what Peter said, since the latest optimisations to bflw + flumine, my cpu usuage in prod has pretty much halved

*Tags: General Technical*

---

**Paul** - *19:46:51*

Also, it might be interesting to see how things perform on Graviton2. The price/performance is pretty :ok_hand:  if you can get the things you need compiled

*Tags: Performance*

---

**Paul** - *19:51:20*

Disclosure: I work for Amazon and therefore it can be argued I have a vested interest - literally - in everyone spending more money on AWS, even if I’m in Retail and nothing to do with AWS. I still would give this advice even if I didn’t though, I am not shilling.

*Tags: Deployment*

---

**Paul** - *19:55:18*

It depends on what you’re trying to optimise for. If you’re trying to hold a lot of data in RAM, you’d go in a different direction to if you have an ML model. If you’re just doing a simple strategy that works on a small instance, use that, absolutely

*Tags: Strategies*

---

**Paul** - *19:56:32*

This is a good tool for exploration if you’re completely new to it all: [https://aws.amazon.com/ec2/instance-explorer/|https://aws.amazon.com/ec2/instance-explorer/](https://aws.amazon.com/ec2/instance-explorer/|https://aws.amazon.com/ec2/instance-explorer/)

*Tags: Getting Started, Deployment*

---

**Paul** - *19:57:53*

You can’t remove them, but some AWS customers detect them and ditch instances when they think they have them

*Tags: Deployment*

---

**Paul** - *20:05:37*

As a general point: the AWS business model is built around shared resources and contention of those resources. If your application is particularly sensitive to contention, perhaps it’s not the optimal environment for that application.

*Tags: Deployment, Strategies*

---

**Paul** - *20:06:15*

But you can reduce the problem by throwing more money at it, and that takes a few clicks and you’re done, so :shrug: 

*Tags: General Technical*

---

**Oliver Varney** - *21:43:48*

My main problem is its not an exchange, they just want a platform where they trade their own money

*Tags: General Technical*

---

**V** - *21:44:28*

The problem is that Jason himself doesn’t know what he wants 

*Tags: General Technical*

---

## 2021-03-20

**Dave** - *15:38:47*

[https://quant.stackexchange.com/questions/7826/how-does-hansons-market-maker-lmsr-work](https://quant.stackexchange.com/questions/7826/how-does-hansons-market-maker-lmsr-work) oh so this must be referring to the same Hanson :slightly_smiling_face:

*Tags: General Technical*

---

**Jonjonjon** - *20:31:18*

My account is littered with them. And Godaddy support aren't good at answering questions on that sort of stuff

*Tags: General Technical*

---

## 2021-03-21

**Unknown** - *14:45:57*

Thanks to everyone who made suggestions for Python visualisation packages. The reason I was asking is because I am working on this: [https://github.com/mberk/betfairviz](https://github.com/mberk/betfairviz). Sometimes I find myself wanting to quickly get a sense of a MarketBook object and the dict representation is hard to parse visually

*Tags: General Technical*

---

**Mo** - *15:45:09*

Good question... I’d need to have a think about that

*Tags: General Technical*

---

## 2021-03-22

**Paul** - *20:58:34*

The fact it “failed” does not mean it failed. It would not take much to back all those selections on the exchange, scatter around the impression of a gamble, watch the price move in, lay off on the exchanges and pocket the change. Wouldn’t surprise me if we don’t see more of this if people have figured out how to spook bookies...

*Tags: Errors Debugging*

---

## 2021-03-26

**river_shah** - *12:58:33*

my model systematically bets hard against heavy favourites….not sure what made it go fairly ballistic in backing 1.15s….

*Tags: Strategies*

---

**Oliver Varney** - *12:59:11*

my model also had it as value at 1.21

*Tags: Strategies*

---

**Aaron Smith** - *16:31:45*

Inplay is still somewhat a mystery to me. Modelling a price obviously isnt the way to go and price movement cant be trusted with the delay. I suppose i need some extra information about horse position/velocity (combined with historical info of the horse still i guess) to make it work?

*Tags: Strategies*

---

**Mo** - *16:32:26*

What do you mean modelling a price obvious isn't the way to go?

*Tags: Strategies*

---

**Aaron Smith** - *16:33:24*

well, that can be used aswell, but no matter how perfectly i model my price, if i just put that in there as a passive limit order i ll be broke in a day :smile:

*Tags: Strategies*

---

**Mo** - *16:37:25*

Direct from the source: [http://www.totalperformancedata.com/](http://www.totalperformancedata.com/). Betfair have a number of licenses they give out, speak to your account manager

*Tags: Performance*

---

**Aaron Smith** - *16:44:09*

mh, then i feel like i m missing the point there. How would i know when to switch away from my modeled price? I suppose then its only based on price movement, but thats 1 seconds old. I suppose cancels are instant so i can try and derive enough info from that

*Tags: Strategies*

---

**liam** - *16:46:23*

Your modelled price needs to be updated on every update (new information) that you get 

*Tags: Strategies*

---

**Mo** - *16:46:28*

Your terminology is confusing, you keep referring to a model price as if one only has one before the race starts

*Tags: Strategies*

---

**Aaron Smith** - *16:51:25*

I can model again with the new info, but the new info is price movement, so i kinda have to guess how accurate that is. That is basically already processed info. If i had the situation on track i may be able to model a new pirce, but if i only get price movement i dont see how that works, as i dont know how accurate that is.

*Tags: Strategies*

---

**liam** - *16:53:02*

What is this model? To give you some context, I don’t use SP, for me it’s useless once things are inplay 

*Tags: Strategies*

---

**Aaron Smith** - *16:57:07*

Well, the thing i cant get my head around is this: For pre event, i get a bunch of historical info, i can process that in some way and come up with a price. If i did a good job, i ll be making money. Now inplay, i may still have my modelled price, but now i need to adjust it (or even completly forget about it). So now all i have is: someone says the horse should be priced 3.4. Now i need some extra information that tells me its not actually 3.4, otherwise i m not matching anything.

*Tags: Strategies*

---

**Oliver Varney** - *17:06:44*

do you fall into a low strike rate high odds bracket generally [@U4H19D1D2](@U4H19D1D2), or does it depend by strategy?

*Tags: Strategies*

---

**liam** - *17:19:45*

No info? You have historic data, both for the current race (very important) and other races (important to be able to model the former)

*Tags: Strategies*

---

**liam** - *17:20:49*

[@ULDAVFDRP](@ULDAVFDRP) I do everything, 1.01 to 1000, low/high strike rate, depends on the strategy and market 

*Tags: Strategies*

---

**liam** - *17:28:08*

Your problem is getting matched, not the delay 

*Tags: General Technical*

---

**Oliver Varney** - *17:29:00*

[@U4H19D1D2](@U4H19D1D2) Not that ive had a chance to look at IP yet, but I think you have got a lightbulb going about how to approach :+1:

*Tags: General Technical*

---

**Michael** - *20:20:23*

Nice for a new player to get a bit of reassurance, and you have less impact on the market which is helpful too.

*Tags: General Technical*

---

**Oliver Varney** - *20:26:55*

but as an alternative learning objective probably would lead to +ev strategy

*Tags: Strategies*

---

**liam** - *20:27:12*

It is certainly quicker to see if a strategy is profitable compared to pre play, I am sure there is an eloquent way to describe this but I can’t 

*Tags: Strategies*

---

**Oliver Varney** - *20:29:27*

i dont know if this statement is true but there must be a point where at if you can predict a price movement/directionality  x% of time between updates you have a +ev strategy

*Tags: Strategies*

---

**liam** - *20:31:16*

Tbh neither do I really but in comparison to modelling based off form inplay has a lot more opportunities / unique events 

*Tags: Strategies*

---

## 2021-03-27

**Oliver Varney** - *08:37:19*

[@U4H19D1D2](@U4H19D1D2)is it worth rate limiting this logger.warning / does anyone do this? Or do people get value having at every market book update? [https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/baseflumine.py#L123](https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/baseflumine.py#L123)

*Tags: General Technical*

---

**Oliver Varney** - *08:41:25*

Is it worth adding a dict at the class level with keys = market ids then, with latency for last updates stored etc

*Tags: Performance*

---

**river_shah** - *14:16:56*

Hey Mo, curious what your thoughts are for turning off best price execution when trading “fundamental” models. For football I am focused much more on proper modelling of the game and odds are inherently noisy. I would not want my bets to lapse if odds do improve during the inplay delay.

*Tags: Strategies*

---

## 2021-03-28

**Ruben** - *18:23:59*

is pinging [http://betfair.com|betfair.com](http://betfair.com|betfair.com) a reliable way to measure latency? In other words, will a lower ping latency translate into less latency when receiving streaming data from betfair?

*Tags: Performance*

---

**Mo** - *18:31:05*

If what you care about is receiving the streaming data as quickly as possible you probably want to be in Dublin AWS

*Tags: Deployment*

---

**Ruben** - *18:33:02*

Thanks a lot Mo; I'm asking mainly because I'm seeing that I'm receiving a price update that my strategy thinks is value, but I am always late to the party :man-facepalming: someone else takes the price before I can do it, so I'm trying to find possible leaks

*Tags: Strategies*

---

**thambie1** - *20:36:57*

[@U011VL3CA2Y](@U011VL3CA2Y) When I started trading football pre, I didn't notice any latency competition, despite taking some really obvious trades. Which makes me wonder if if the competition you're talking about is me. If you want to send me one or two of the trades you missed out on, I'll let you know if I took them.

*Tags: Performance, Strategies*

---

**Mo** - *20:40:22*

Probably depends on the strategy. I had a lot of competition when I was doing pre-event football

*Tags: Strategies*

---

**thambie1** - *20:46:40*

Hmm, weird. I'm also doing 100% taking for the time being. Surprised in such a similar space we would see such different latency considerations

*Tags: Performance*

---

## 2021-03-29

**Dave** - *00:20:14*

my biggest focus is football, IP though. All execution via the REST api...never really had a concern for latency for this :sweat_smile:

*Tags: Performance*

---

**Dave** - *00:20:49*

i suppose if one is reacting to changes in the book then latency is more of a concern.

*Tags: Performance*

---

## 2021-03-31

**Oliver Varney** - *08:41:13*

Just out of interest, anyone using models,  when the exchange is down for an extended period and some features are impacted as a result, do people continue as normal or sit on the bench

*Tags: Feature Engineering, Strategies*

---

**Jonjonjon** - *08:44:23*

I just sit here and hope my models don't go crazy.

*Tags: Strategies*

---

**Dave** - *08:51:48*

My models just 0 out signals when features are detected to be rubbish or market volume is too low for when the data for features was collected

*Tags: Feature Engineering, Strategies*

---

## 2021-04-03

**Lee** - *17:55:39*

is there believed to be much fixing in racing?

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:53:36*

Suppose I backtest 2 strategies with a single `framework.run`. e.g.



```client = clients.BacktestClient()

framework = FlumineBacktest(client=client)



...



framework.add_strategy(strategy1)

framework.add_strategy(strategy2)



...

    

framework.run()```

Would the results for `strategy1` and `strategy2` be different if I'd run them with separate `framework.run`'s

*Tags: Strategies*

---

## 2021-04-04

**liam** - *06:59:16*

There is a [https://github.com/liampauling/flumine/pull/406/commits/b956086b177fbcbfef68d805d77798a6e249cd9c|bug](https://github.com/liampauling/flumine/pull/406/commits/b956086b177fbcbfef68d805d77798a6e249cd9c|bug) which I found last week which means there is a chance they won’t be if two identical strategies are executed in the same framework, should be releasing 1.18.0 soon with a fix 

*Tags: Errors Debugging*

---

**Mo** - *08:54:41*

Very much a random question but can anyone recommend a good mouse? I've bought this one: [https://www.amazon.co.uk/Wireless-Patuoxun-Computer-Cordless-Adjustment/dp/B01ESZJSUK](https://www.amazon.co.uk/Wireless-Patuoxun-Computer-Cordless-Adjustment/dp/B01ESZJSUK) a couple of times but the mouse wheel starts slipping after about 6 months or less of usage which is super annoying. I'm a bit overwhelmed by all of these gaming mouse options all of which seem to have terrible software you need to use if you want to customise LED colours or DPI or whatever and probably aren't supported by Linux. All I care about is something that is built to last and comfortable to use

*Tags: General Technical*

---

**James T** - *12:32:40*

I’m not a massive germaphobe but I do use a simple fully washable mouse and keyboard. I’m sure basically everyone snacks at their computer but it happens to be one of the least hygienic places. Also when I wash them every month or so it’s like I’ve got a brand new device again! It also solves the problem of choice paralysis because there’s basically zero choice out there. Both are fine for regular use and gaming, but it would be nice to have a few more advanced ones available. My mouse is just a wired two button and scroll wheel thing, and the keyboard is basic too, but at least has a num-pad! I think my brand is Seal Shield. They last for years too. 

*Tags: General Technical*

---

**charlie_v** - *14:58:47*

I use tea if that helps. Very useful while trading

*Tags: Strategies*

---

**Jonjonjon** - *21:09:49*

Is the performance for WSL as good as running Linux natively? I do a lot of flumine backtesting

*Tags: Performance*

---

**MacrcoPolo** - *21:14:08*

"Under some applications WSL was delivering slightly better performance over WSL2, but in general the WSL/WSL2 performance was very close to that of bare metal Ubuntu 20.04."

*Tags: Performance, Deployment*

---

**Jonjonjon** - *21:15:51*

Interesting. A shame they don't do Python benchmarking!

*Tags: General Technical*

---

**Mo** - *21:15:52*

Were you playing through Steam? Did you look it up on protondb and apply any recommended fixes?

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:16:45*

[@UBS7QANF3](@UBS7QANF3). Yes. Via steam. And I tried a load of different suggested fixes from Protondb. In the end I decided I should spend more time gambling on horses instead.

*Tags: Errors Debugging*

---

## 2021-04-05

**liam** - *12:00:20*

Where is the value in your strategy? If it’s back at x because of y and then lay at x-20 then the lay isn’t going to be value and there needs to be some sort of value logic for y or you are just going to lose money 

*Tags: Strategies*

---

## 2021-04-06

**James T** - *16:40:42*

I think it’s a different skill though - betting track side. There must be a bit of race reading involved. GPS vs drone vs trackside must be pretty similar in terms of latency now. In-running has been doing particularly well since there were zero crowds (hence drones attempting to replace trackside), so it’ll be interesting to see how our strategies do once crowds do return. Has GPS completely wiped out trackside potential? I doubt it. 

*Tags: Performance, Strategies*

---

**Jonjonjon** - *21:48:36*

Could this line also cause similar issues?



[https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/order/process.py#L116](https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/order/process.py#L116)

*Tags: General Technical*

---

## 2021-04-07

**Dave** - *21:20:01*

Yeah never had much success modelling dogs from past results tbh.

*Tags: Strategies*

---

## 2021-04-08

**Mo** - *06:49:44*

Some matches have insane volume but not that many matches in total per year (around 2000). In play seems like a tough nut to crack because of the importance of latency and hard to model considerations like the impact of weather

*Tags: Performance, Strategies*

---

**Crofty** - *08:37:50*

There are some weather radar apps and if it was possible to download historical data ie at  x time on y date, the weather at Lords was cloudy you could factor that in. But then there is other factors like the standard of the bowler versus the standard of the batsman; a strong batsman facing a weaker bowler would have more impact on the prices.

*Tags: Data Quality*

---

**Mo** - *11:24:51*

Some more thoughts. Similar to tennis, it is well suited to modelling because of the highly structured scoring system and continual flow of information. (This also means there are hundreds of betting opportunities per match). On the other hand, as [@U01HQ97J5HA](@U01HQ97J5HA) says, there are complex interactions between the batsman and the bowler plus the state of the pitch

*Tags: Strategies*

---

**Jonjonjon** - *13:00:32*

I just place exit orders at "fair value" after entries get filled. But I don't adjust the exit orders as fair value changes. At some point I need to do some flumine backtesting to test whether or not adjusting the exit orders will be good or not

*Tags: General Technical*

---

**Unknown** - *13:18:05*

That's certainly something that I've found. This is a plot of cumulative profit v time to get filled for a live strategy I'm testing, that's bet on ~500 markets so far.

*Tags: Deployment, Strategies*

---

## 2021-04-11

**MacrcoPolo** - *22:53:40*

Frustrating problem I'm dealing with. Does anyone see duplicate publish times in their data? I.e a message with a specific pt, then followed up with another message with a diff clk, but the same publishtime?

*Tags: General Technical*

---

## 2021-04-12

**Benito Pagnotto** - *10:49:46*

Hi, I’m am intermedie python dev, solid foundation in math. I have very little knowledge about betting and stock exchange neither about betting exchange (I know only how they works but I haven’t any operative experience). I would like to explore a bit of this worlds. Could you redirect me to some place where should I start? Is it better to download Liam’s libraries and start playing with them or get more knowledge about strategy in the betting exchange market? Any books or sites?



Thank you

*Tags: Strategies*

---

**Aaron Smith** - *11:08:04*

[@U01TWECSFLH](@U01TWECSFLH)  probably plenty of diffrent ways to get there. My qualifications match yours pretty well and i just played around with liams library and some ideas i had and i m at least making enough to live off of it by now. Havent read any book yet, however i m sure that can help aswell. I ll probs end up checking some books out eventually, but for starters i felt like it may limit my horizon to the stuff discussed in the books. Not sure if that makes any sense, but i can always catch up on reading books :smile:

*Tags: Deployment*

---

## 2021-04-14

**James T** - *10:15:59*

Yeah, I doubt front line support will be any help. I expect if it affects enough people then they’ll notice and someone will fix it. Odd issue though. 

*Tags: Errors Debugging*

---

**Mo** - *11:17:04*

Best just to email Neil if it's a technical problem IMO

*Tags: General Technical*

---

**James T** - *11:19:24*

Haha, good question. I would class them as second line support as they should know more than basic customer service and phone support. Still haven’t been the most help in the past though. 

*Tags: General Technical*

---

**Lee** - *12:04:04*

Had a reply from Neil:

This issue was raised with our dev team yesterday. I'll let you know as soon as this has been resolved. Sorry for the inconvenience caused in the meantime.

*Tags: General Technical*

---

## 2021-04-15

**Mo** - *09:11:15*

Good question, hadn’t actually considered it! Probably too much of a conflict of interest...

*Tags: General Technical*

---

**Dave** - *09:28:28*

This is cool. Question about "must use publicly available data" - where does "realtime data scraped from public sources and persisted" fall with respect to this constraint?

*Tags: General Technical*

---

**Mo** - *09:31:31*

Another good question that we haven’t considered. I would say that the persisted data would need to be hosted somewhere public

*Tags: General Technical*

---

**Mo** - *12:26:52*

A couple of comments:



1. There are examples of data which are publicly available, such as on sites such as [http://WhoScored.com|WhoScored.com](http://WhoScored.com|WhoScored.com), which are both highly detailed and not really usable without extensive scraping and data transformation. You don't have to make such scraping code publicly available (although you would need to include it as part of your submission so the judging panel can - in principle - run it themselves to reproduce your predictions exactly) so you can still gain a significant edge over other entrants even with the public availability requirement

2. I've included a link to StatsBomb free data ([https://github.com/statsbomb/open-data](https://github.com/statsbomb/open-data)) in the README which is highly detailed, ball-by-ball data. For developing a betting strategy this free data is probably not very useful as you would need access to data going forward but the free data includes the last World Cup which is highly relevant to the competition. In other words, data which is of relatively low value generally can actually be of high value for the purposes of this competition

*Tags: Strategies*

---

## 2021-04-17

**river_shah** - *20:58:07*

I want to become better informed about the ethical issues around jump racing and use of whips in horse racing. If I go to animal abuse prevention sites, it is extremely one sided and and there is a similar myopia when I go to the racing industry websites. Sports conservatives don’t particularly feel there is a problem or want change. Seems like both sides are talking their own books. Are there any forums or websites you can recommend that will help me understand the issues in a balanced way around these aspects of horse racing? Any BHA white papers / fact findings or other resources will be welcome.

*Tags: General Technical*

---

## 2021-04-19

**Jonjonjon** - *13:46:51*

Is there anything special about today's dog racing? My models are performing better than usual.

*Tags: Strategies*

---

## 2021-04-26

**D C** - *10:35:05*

Can anyone recommend (from actual experience) a model and brand of new laptop that will allow an installation of ubuntu 20.04 (or linux mint equivalent) without any issues with hardware/drivers etc? Dell have crapped out on linux completely and I don't want to run the risk of excessive customs fees on a high end model from system76 in USA. And advice appreciated.

*Tags: Getting Started, Strategies*

---

**D C** - *10:37:40*

Yeah just spoke with a rep. They have 2 models of laptop geared at heavy high end data science use but they are in excess of 3.5K

*Tags: Strategies*

---

**D C** - *10:40:01*

no longer doing the XPS unbuntu preinstalled models.

*Tags: Getting Started, Strategies*

---

**Newbie99** - *17:42:49*

Possibly a bit of a longshot, but is anyone else running Nord VPN (locally) on Windows 10?



I'm running Nord VPN on my laptop and wanted to write a script to start an EC2 instance using boto3 etc, that all works fine. However when I try to create an SSH tunnel it seems to be blocked (which is logical), but I can't work out how to bypass this.



In the Nord VPN for windows client I have SSH setup under split tunnelling, so it works fine if I just try to SSH manually.



Additionally if I turn off the Nord VPN client this script works fine.



Here is my script, is anyone aware of a smart way to get something like this working without having to manually switch off the Nord VPN client (the fetch public IP function grabs the public IP of the EC instance)?



```def ssh_tunnel():



    EC2_URL = fetch_public_ip()

    username = "ec2-user"

    pem_file = '~/betfair.pem'



    # Create the tunnel

    server = SSHTunnelForwarder(

        (EC2_URL, 22),

        ssh_username=username,

        ssh_pkey=pem_file,

        remote_bind_address=(EC2_URL, 27017),

        local_bind_address=('127.0.0.1', 27017)

    )

    # Starts the tunnel

    server.start()



    # Prints the local bind port

    print(server.local_bind_port)  

    

    # Closes the tunnel

    server.stop()```

*Tags: Getting Started, Deployment*

---

**Newbie99** - *20:12:08*

Essentially it is something like that...the problem is unlike linux the only way I can see to config anything is via the client GUI

*Tags: General Technical*

---

## 2021-04-29

**KG** - *07:10:13*

[@US72QTH33](@US72QTH33) we don't have a bookmaker arm to the business in Aus, pure Exchange model :ok_hand:

*Tags: Strategies*

---

**Oliver Varney** - *14:45:07*

problem is you get picked off if your offering

*Tags: General Technical*

---

## 2021-04-30

**KG** - *06:18:14*

we're really interested in seeing the impact on different customer groups [@ULDAVFDRP](@ULDAVFDRP) and hopefully we can use the learnings to help develop the idea further

*Tags: General Technical*

---

**Newbie99** - *09:26:08*

Yeah, the problem is, in windows there's no way to unblock a particular port (in linux you can whitelist)!

*Tags: General Technical*

---

## 2021-05-01

**John A** - *00:21:21*

Never purchased Historical data, do my own recording of streaming data. 

*Tags: Data Quality*

---

**birchy** - *19:00:36*

Are occasional ANGX-0006 "UNEXPECTED ERROR" API messages anything to be concerned about? I've always assumed these were just an acceptable error due to the nature of Betfairs slight flakiness?

*Tags: Errors Debugging*

---

## 2021-05-02

**birchy** - *11:17:04*

{"asctime": "2021-05-01 01:05:59,816", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/flumine/worker.py\", line 232, in _get_cleared_market\n    group_by=\"MARKET\",\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182752035'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-04190756-002ab3f9ad', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-04190756-002ab3f9ad', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182752035'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-04190756-002ab3f9ad', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang07b-prd-04190756-002ab3f9ad', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}

{"asctime": "2021-05-01 09:13:50,608", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/flumine/worker.py\", line 232, in _get_cleared_market\n    group_by=\"MARKET\",\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182736400'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang26b-prd-04190756-002b4d66d5', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang26b-prd-04190756-002b4d66d5', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182736400'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang26b-prd-04190756-002b4d66d5', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie1-ang26b-prd-04190756-002b4d66d5', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}

{"asctime": "2021-05-01 10:42:17,013", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/flumine/worker.py\", line 232, in _get_cleared_market\n    group_by=\"MARKET\",\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/betting.py\", line 432, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 55, in request\n    self._error_handler(response_json, method, params)\n  File \"/home/ubuntu/.local/lib/python3.6/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 81, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182736390'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang28a-prd-04270851-0008c9b97e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang28a-prd-04270851-0008c9b97e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'groupBy': 'MARKET', 'settledDateRange': {'to': None, 'from': None}, 'customerStrategyRefs': ['ip-172-26-33-16'], 'marketIds': ['1.182736390'], 'betStatus': 'SETTLED'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang28a-prd-04270851-0008c9b97e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0006', 'data': {'APINGException': {'requestUUID': 'ie2-ang28a-prd-04270851-0008c9b97e', 'errorCode': 'UNEXPECTED_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}

*Tags: Errors Debugging, Strategies*

---

**PeterLe** - *23:49:24*

Over recent months there has been a number of people who have their accounts suspended due to them extracting data and not putting enough bets through.

My question please is; What constitutes ‘enough’

If you had a single account and the choice of two systems to deploy whilst collecting data, the systems would be as follows:-



Sys A, places say 500 bets an hour £2 bets (liability) ie £1000

Sys B places 50 bets an hour, £20 (liability) ie £1000



Are Betfair interested in the amount of bets or the value of the combined bets?

Anyone have a view?



Thanks in advance

*Tags: Deployment*

---

## 2021-05-04

**Jonjonjon** - *08:28:20*

This is unrelated to Sports, but what do people think is the fastest way to learn Solidity for an experience Python developer? A book? A video course?

*Tags: General Technical*

---

**Peter** - *10:26:25*

Don't think that's an answerable question :wink: It depends on the learner's preferred learning style, the quality of the materials available in different media, and the learner's objectives e.g. being bang up to date v grasping the fundamentals.

*Tags: General Technical*

---

## 2021-05-06

**D C** - *14:31:07*

On paper laying the field at 1.01 is profitable - if you can get front of the queue. This is where the "strategy" falls apart for cases where not a lot is matched there on a losing runner

*Tags: Strategies*

---

**Oliver Varney** - *14:34:10*

hmm i guess what im struggling to understand is who is the fool in this situation and why are they running a loss making strategy, or is it just joe bloggs with betangel and a trigger finger putting his mortgage on

*Tags: Strategies*

---

**liam** - *14:37:57*

there seems to be an endless supply of 'joe bloggs' on there and as you have probably seen the question of how do i create automation to back at 1.01 gets asked daily on BA

*Tags: General Technical*

---

**Oliver Varney** - *14:40:25*

haha so actually my 19/1218 is an underestimate most likely, hmm interesting. Was only looking because I have been massively on the wrong side of them recently and thought id do some digging not that it would change anything (nothing for strategy thinking ill leave that to the IP guys)

*Tags: Strategies*

---

**Oliver Varney** - *14:45:43*

Yer wont be happening anytime soon I can guarantee that, although the +12k profit lost alone from 1.01 positions in april would of helped

*Tags: General Technical*

---

## 2021-05-07

**Oliver Varney** - *14:25:51*

[@U01B8031PM1](@U01B8031PM1) trying to set some bait out for a bflw poker night where he can take all our money :joy:

*Tags: General Technical*

---

## 2021-05-11

**Jonjonjon** - *10:17:24*

How hard would it be to refactor BFLW, so that it returns the price/sizes as lists ornumpy arrays? I see that the data comes from the market cache. When profiling my backtests, they spend a lot of time converting "price/size lists of dicts" into numpy arrays. I feed these into my numba-compiled pricing functions, which is why they need the conversion. So I guess I'm wondering whether or not it's common for people to feed the market data into numerical pricing functions, and whether or not enough people would like the data in array-format, for this to be worth doing.

*Tags: General Technical*

---

**liam** - *10:38:56*

just patch it, in flumine we [https://github.com/liampauling/flumine/blob/master/flumine/patching.py|patch](https://github.com/liampauling/flumine/blob/master/flumine/patching.py|patch) the price size by not converting to py objects so you could just do the same to numpy arrays

*Tags: General Technical*

---

**Jonjonjon** - *11:07:02*

Thanks for the tip [@U4H19D1D2](@U4H19D1D2). I might also try patching the market cache to keep everything in numpy arrays. Insertions and deletions could be slower, but if it saves my code from creating new numpy arrays at every time step, perhaps it will be faster anyway.



[https://github.com/liampauling/betfair/blob/ee4488ddb4f4bee775450f7497c08ea0fb470e9b/betfairlightweight/streaming/cache.py#L45-L72](https://github.com/liampauling/betfair/blob/ee4488ddb4f4bee775450f7497c08ea0fb470e9b/betfairlightweight/streaming/cache.py#L45-L72)

*Tags: Performance*

---

## 2021-05-13

**Misha** - *09:01:55*

I have stuffed up one rollout. System for processing cheques and applications for the first Telstra float/IPO (like British Telecom) in 1997 (I think). We (me and one other guy) were developing the software to link all the document imaging, cheque scanning, application entry to process $20B of applications in 4 weeks. Naturally, the client requested changes while we were live. One change that I implemented managed to zero out all application amounts for batches post my rollout. Imagine my surprise/horror when one of the data entry operators showed me a screen that had applications worth $0. And then another. And another. Managed to rollback, find the batches affected, and fix it. Not the most relaxing day of my career :joy:

*Tags: Errors Debugging, Deployment*

---

**Mo** - *19:07:08*

Last call to get your vote in for the date of the meetup before I start looking for a venue. This is obviously dependent on everything opening up on 21st June as planned which last I heard has been called into question

*Tags: General Technical*

---

**Mo** - *19:12:06*

It's helpful for me if you vote even if you're happy with how it's looking (23rd or 24th) so I can get a better idea of numbers

*Tags: General Technical*

---

## 2021-05-14

**Jonjonjon** - *16:44:30*

Does he use BFLW?

*Tags: General Technical*

---

## 2021-05-15

**liam** - *18:22:25*

Yep seamless use bflw 

*Tags: General Technical*

---

## 2021-05-17

**D C** - *11:03:49*

Not to demean education it but a Phd can be very overrated and I think if people really knew what it takes to get one and some of the internal "tricks" that supervisors use to get their students over the finish line, they would be both shocked and appalled. I am sure its not the case at top instutitions but places lower down the foodchain dodgy things certainly happen. I've personally found my Phd to be way more of a hindrance to me than a help in this game but that could be down to subject area and it could be due to my own shortcomings and incompetence. Others may disagree here but I wasted literally years trying fancy stuff that never worked based on knowledge I had acquired that I thought could be applied - again though, lack of success could be down to my own shortcomings. I did a masters degree in statistics and that has been WAY more useful.

*Tags: General Technical*

---

**liam** - *11:12:29*

[@UBS7QANF3](@UBS7QANF3) I think you mentioned something before about syndicates and minimum profit/roi being required for a marketType/strategy to even be considered. I see that as an advantage for me, a team of 15 might sound scary but thats 15 pay checks each month :wink:

*Tags: Strategies*

---

**D C** - *11:26:28*

I suppose it opens up an interesting question. Given 15 employees with a Phd do they all work together on one thing under someone managing a project, or would they be off as solo players trying to develop their own profitable strategies to cover more surface area in the markets? If the former, must be a tough taks from a management perspective.

*Tags: General Technical*

---

**Oliver Varney** - *11:28:10*

I guess one question I had which maybe I missed is, how do you scale up and bring people in without giving away your model. How do you incentivize and prevent them from leaving and doing it themselves?

*Tags: Strategies*

---

**Oliver Varney** - *11:31:40*

Does that play out in the real world well? If they have 15 guess doing modelling then what if one guy discovers something that could pay way more then his salary and they are not getting profit share

*Tags: Strategies*

---

**Mo** - *11:34:15*

I think it works for SmartOdds and Star Lizard. Obviously it is strategy dependent but often having the model is only half the battle. If you don't have the Asian bookmaker connections required to execute the bets and if you don't have the bankroll or the risk tolerance required to go down that route...

*Tags: Strategies*

---

**D C** - *11:40:10*

I guess it depends. Most academic types I have encountered do what they do for love of the subject alone. That said I most of those worked in a uni and I have never met anyone with Phd working in a finance/gambling related field. A "typical" uni academic type would have no problem working on an isolated project without any thought about if it would make them money or not.

*Tags: General Technical*

---

**MacrcoPolo** - *14:34:23*

God I know. I also asked them the million dollar question (which everyones been discussing) which was: "How on earth are you going to scale this?"

*Tags: General Technical*

---

## 2021-05-18

**ShaunW** - *01:55:21*

Syndicates reduce the per head fixed costs like curating data sources, and splits the ancilliary dev like monitoring and reporting. So it's not just a case of setting up in your back bedroom when you see their model because the cost of running it on your own might well outstrip what it earns, even if you have the time do all it involves. Being a one-man-band at any job is tougher than having a team, especially balancing doing the work and looking for the next work, probably where syndicates excel. We'd all like someone else to do the stats and the coding so we can muse all day, Voila! A business is born, but it's sports betting so let's call it a syndicate.

*Tags: Errors Debugging, Strategies*

---

**Crofty** - *17:47:02*

Good point. I've been self-employed since 2003 (non gambling) and prefer the simplicity of working alone. Without a doubt, I could earn a lot more if I had a team but I know from helping someone run their company, that finding good people is the toughest part.

*Tags: General Technical*

---

## 2021-05-19

**KG** - *00:37:32*

Anyone who's keen to start their day with insights into modelling football you're welcome to join us online tomorrow morning  :soccer: [http://bfhub.co/SoccerEdition|bfhub.co/SoccerEdition](http://bfhub.co/SoccerEdition|bfhub.co/SoccerEdition)

*Tags: Strategies*

---

**Jonjonjon** - *09:17:59*

Some people might be more suited to this sort of work. I'd have no idea how to run a service or retail company

*Tags: General Technical*

---

**Jonjonjon** - *09:30:06*

Startup costs for Betfair trading are very cheap. It only cost me £2.5k to get started. I could have started with less on my bread and butter strategy. But I did not have it at the time.

*Tags: Strategies*

---

**Jonjonjon** - *09:48:29*

I think I'm about 0.01-0.1% of the horse markets I trade. So there can't be that many people running the same strategy as me.

*Tags: Strategies*

---

**Mo** - *09:58:41*

I’m sure I’ve had one of the most successful betting _careers_ out of everyone on here but I’m certain that [@UGV299K6H](@UGV299K6H) beats me for lifetime profits, I suspect [@U4H19D1D2](@U4H19D1D2) does as well (and I think it's fair to say that none of us are close to the likes of Benter, Bloom or Benham). I think that’s probably down to having always done my betting activities as part of a team rather than getting the whole pie to myself but on the flip side there are advantages to working as part of a team and it’s given me a breadth of industry knowledge that is probably close to unparalleled. Having had some of my profits stolen by the IRS also doesn’t help. I certainly don't feel well off in the London property market...



For example, I'm pretty sure if 11 years ago I went to work for a hedge fund instead of a new betting syndicate I would have more money today.

*Tags: Strategies*

---

**Mo** - *11:24:04*

[http://www.totalperformancedata.com/](http://www.totalperformancedata.com/)

*Tags: Performance*

---

**D C** - *11:56:49*

Be aware though that TPD directly requires (required) you to be running off a static IP. That might have changed now and its not a problem for everyone but something to bear in mind. Must easier if you can get it from Betfair.

*Tags: General Technical*

---

## 2021-05-20

**liam** - *09:24:10*

I don't doubt its possible, it seems these guys have learnt to see trading flow, however I would rather have an automated strategy that earns 50% less if it means I can do other things...

*Tags: Strategies*

---

**Dave** - *09:39:49*

Not sure how one forecasts price from order flow without having a model really. $20 per race is pretty good tbh, pretty sure that works out to mean London wage lol.

*Tags: Strategies*

---

**Greg** - *09:46:20*

yeah-the manual stuff bores me to tears and finding value there does appear to be a mugs game..unless you are part of an exclusive club ( it seems). 'Should have started on python years ago..better late and all that:grin:

*Tags: General Technical*

---

**Dave** - *09:50:10*

Agreed the manual stuff is super dull. I am happy with my low volatility, high sharpe autonomous money printer, even if it's a tiny printer :joy: (for avoidance of doubt, I do mean my bflw powered strategies, not an actual printer)

*Tags: General Technical*

---

**D C** - *11:50:02*

I hear what you are saying there and obviously the market seldom moves smoothly (one team dominates etc.) but it just scares because of the suspensions. Unless of course you are simply looking at taking value bets at various points inplay which is a very different thing to "trading". I don't know I am not looking down on it but I just think that the word "trading" gets overused in this area. If you are taking value it doesn't matter if the market suspends as you will just get your order cancelled. If you are looking to enter at event X then exit at event Y you just can't guarantee that you will be able to do it because of how the suspensions are handled. And this is exactly the kind of strategy I see called trading by many online.

*Tags: Strategies*

---

## 2021-05-23

**James T** - *23:56:10*

I think that’s a really good / interesting question. I’ve wondered a few times about how I can keep my strategies (essentially passive income) running for my family should I die suddenly.



I’ve had an intention to properly document all my systems, setup, theory, etc... but never get round to it. Even then no one in my family would have the computer knowledge to maintain any of it, so they’d still need help. 



For now I just hope I don’t die suddenly!



Perhaps buying life insurance for an amount roughly equal to what I think my systems are worth would be another option...

*Tags: Getting Started*

---

## 2021-05-24

**liam** - *06:59:45*

Theoretically as long as my aws bill is paid, no breaking api changes / someone keeps bflw up to date my code would run indefinitely 

*Tags: Deployment*

---

**PeterLe** - *08:18:12*

Im right in the process now of setting up my will; LPA’s and trusts. There is nothing more certain that we are all going to die one day.

Ive documented how to access my account and given those instructions to my daughter/sons.

10 years or go my best friend died early and I helped his wife maintain her Betfair account for many years, withdrawing 5 figs each Christmas. It helped his son through University. 



In terms of passing it on to someone, I can imagine that (and taking James T /Liam as an example), the information would be useless unless it was passed to someone who had the knowledge how to use [http://it.In|it.In](http://it.In|it.In) that case you could pass it to someone on the understand(or gentlemens agreement) that a percentage of the profits that seemed from that IP was passed to their loved ones. I think that would be a fair agreement.

*Tags: General Technical*

---

**Jonjonjon** - *11:26:31*

I went to the Bognor Butlins with my family 2 years ago. It was awesome, and I wrote some pretty awesome pricing models while I was there.

*Tags: Strategies*

---

**Jonjonjon** - *16:16:55*

What if you wanted to help out your cousin? Would they suddenly become a higher rate payer?

*Tags: General Technical*

---

**Mo** - *16:21:48*

If you run the same strategy on their account then yes

*Tags: Strategies*

---

**Oliver Varney** - *16:27:58*

what constitutes the same strategy. A model can have different inputs and come up with the same output ?

*Tags: Strategies*

---

**Mo** - *16:37:59*

Yes strategies can be doing similar things but I think their fingerprints are a lot more unique than you might think. Your predictions might be similar but maybe your staking is totally different. Maybe you run your strategy on AWS, someone else runs their strategy on Azure. You use bflw, someone else uses C# (this will show up in the HTTP user-agent strings). Maybe you make keepAlive requests for your session tokens at different frequencies. Maybe you scrape settled orders once an hour, someone else does it every 15 minutes etc. etc.

*Tags: Deployment, Strategies*

---

**Jonjonjon** - *16:38:36*

YOu are right [@ULDAVFDRP](@ULDAVFDRP). The way things stand, I'm working totally solo, and terrified of giving a helping hand to anyone I know, incase it subsequently gets me in trouble for PC avoidance.

*Tags: General Technical*

---

**PeterLe** - *19:39:22*

My wife was using a very similar strategy to me years ago. I emailed betfair and told them of my intentions and that we would essentially be trading from the same IP Address with different usernames. She did a KYC and betfair confirmed that there was no problems. that was the end of it.

I think as long as you are upfront and you are genuinely not trying to circumnavigate the rules, you will be OK.

[@UBS7QANF3](@UBS7QANF3) why do you feel you’re treated so badly?

*Tags: Strategies*

---

## 2021-05-25

**Mo** - *07:24:26*

Here are three examples of why it doesn't feel like Betfair is my "partner".



Firstly, I think Betfair should be doing a lot more to protect customers from match fixing. There have been some blatant tennis match fixes recently which hurt us. I reported them to my account manager who has passed them on to the "integrity team" but nothing ever comes of this. Their policy is not to void markets based on allegations alone which I think is dangerous and may ultimately cost them as by keeping the market open they are facilitating the match fixing:



&gt; Ultimately we don’t suspend betting as customers use the product with the expectations that they will be able to manage their positions. Market suspension would be detrimental to this, especially in the cases where the volume is substantial.

The volume is substantial because you have organised crime syndicates using your product!



&gt; The difference between this and the sportsbook is that we choose not to offer bets on the Sportsbook if we suspect a problem, whereas on the Exchange it’s up to customers to make that judgement for themselves. It may be obvious in some cases, but obvious isn’t enough to go by until it has been proven after investigation by the governing body. 

This seems like madness to me. It's not hard to notice that every other bookmaker has stopped taking bets on a match and to suspend and void the market in these situations. I think it's far better to err on the side of caution rather than risk supporting organised crime.



There is the particular case of Teymuraz Gabashvili, a player who is so bent that Betfair has not offered markets on his matches for years. Recently, they had markets on one of his matches, it was a fix and it cost us 5 figures. Well, they are back to not offering markets on his matches but did they void the market and refund our loss? No. My suspicion is that someone in market ops fucked up in creating that market in the first place. I didn't think it was necessary to have our own filter to prevent trading his matches because it's been Betfair policy for YEARS not to offer his matches. Was there any communication they would change that policy? No.



Secondly, we've had so many problems recently with Betfair being late to create tennis markets, sometimes missing matches completely, other times only creating them once they've turned in play which inevitably means they end up having poor liquidity. It seems to me that it essentially boils down to:



1. Poor integration with data feed providers. These have been WTA matches and the provider for these changed this year. Something with the integration is preventing these markets from being automatically created

2. Lack of coverage from the market ops team. The problems normally happen on a Saturday morning; Saturdays tend to be days with lots of qualfiiers being played for the upcoming tournaments for the week. The schedule for the day typically gets published in the early hours of Saturday but if there are any issues with the automatic creation of markets it's not until around the middle of the day that these actually get resolved by which time some matches will have been missed. Seems like it's driven by whenever the guys working on Saturday get into the office

3. Some weird regulatory issue where only the Australian team can create Australian markets. But the Australian team doesn't have 24/7 coverage so when they've failed to create the markets but it's the middle of the night for them all we can do is twiddle our thumbs

My point here (aside from concerns about their technical capabilities re: integration) is that I have no problems making sure our systems are working at 7 am on a Saturday so I bloody well expect Betfair to be doing the same. Yeah, I get it, not everyone has the same work life balance as me but for an organisation the size of Flutter it's well within their capabilities to provide 24/7 coverage on these teams. There's always sport being played somewhere.



Thirdly, site outages. We've all been hurt by these. Betfair can have a meltdown over multiple days but you can be damn sure they won't have any problems taking your premium charge.



In summary, if this was something resembling a true partnership I would expect:



1. Betfair to care more about protecting its (premium) customers. They don't care (enough) if you get hurt for 5 figures in a match fix because they still get their juicy commission/PC on the increased volume

2. Betfair to pursue the same technical excellence that I aspire to. They don't care (enough) if I miss out on trading a few tennis markets because what could be hundreds of pounds in EV for me is a drop in the ocean for them

3. Betfair technical teams to provide 24/7 coverage

4. Some compensation when their services fail

*Tags: Errors Debugging, Strategies*

---

**Jonjonjon** - *08:03:49*

Thanks for sharing [@UBS7QANF3](@UBS7QANF3). How can you tell if a match is a fix? I don't watch any sports, so apologies if it's a dumb question.

*Tags: Errors Debugging*

---

**Oliver Varney** - *08:06:38*

might be another stupid question but, you know they say PC money goes to get new customers onto the platform (advertising etc), but after all that cost is said and done, are PC customers more worthwhile to betfair in terms of profit then our counterparts who we take money off.

*Tags: General Technical*

---

**Mo** - *11:54:41*

A couple more points on the match fixing issue:



1. Saying you won’t void a market for suspected match fixing, only definite match fixing is essentially saying you won’t ever void a market for match fixing. Anything definitive will only come as the result of an investigation by the authorities and probably subject to an appeals process. By the time you have a definitive answer, the money will be long gone. This is why I think they should be voiding markets before they are settled

2. The more I think about it, the worse the optics look of keeping the exchange market open when all other mainstream bookmakers have stopped taking bets. How do you possibly justify that to the authorities? I don’t think you can abdicate the responsibility for preventing your platform being used by organised crime by saying it’s down to users to detect when this is likely to be happening

*Tags: Errors Debugging*

---

**Jonjonjon** - *12:21:30*

I don't see how users can be expected to detect match fixing. If I'd seen that video of Stefano out of context, I'd have just thought he was a really bad player.

*Tags: Errors Debugging*

---

**Jonjonjon** - *12:21:56*

Could users ever be punished for making money from fixed markets?

*Tags: Errors Debugging*

---

**Oliver Varney** - *12:25:52*

isnt it just a sad fact of gambling (edit: and anything where large sums of money are involved)? our model are build on historical data where it most likely occurred in a handful of matches and is already built in to our expected return? not that legitimises it at all

*Tags: Data Quality, Strategies*

---

**Jonjonjon** - *12:32:39*

Would match fixing show up in the data?

*Tags: Errors Debugging*

---

**liam** - *12:34:34*

Recent betfair QA, crap answers and crap questions [https://community.betfair.com/service/go/thread/view/94166/31708679/betfair-forum-open-evening-get-your-questions-in-live|https://community.betfair.com/service/go/thread/view/94166/31708679/betfair-forum-open-evening-get-your-questions-in-live](https://community.betfair.com/service/go/thread/view/94166/31708679/betfair-forum-open-evening-get-your-questions-in-live|https://community.betfair.com/service/go/thread/view/94166/31708679/betfair-forum-open-evening-get-your-questions-in-live)

*Tags: Deployment*

---

**Oliver Varney** - *12:46:55*

The answers seem to be typical management response that either answer a separate question or provide no real detail. A fair few questions about IP liquidity for horses

*Tags: General Technical*

---

**Mo** - *12:50:00*

My point is that bookmakers have a tool they can deploy in this situation which is that they can choose to remove the match and void bets placed on it. As exchange users, we cannot do this even if we strongly believe match fixing is taking place. I think Betfair should be more proactive in the most egregious cases to protect their customers in the same way that bookmakers are protected - and to protect themselves!!

*Tags: Errors Debugging, Deployment*

---

**D C** - *12:52:54*

Is it not troublesome from a legal perspective though if they declare the reason for voiding as suspected match fixing? That way if players ever got wind of it they might have grounds to sue etc? And Betfair would have to declare the reason for voiding otherwise they would be accused of dodgy antics themselves. For what it's worth [@UBS7QANF3](@UBS7QANF3) I completely agree with your sentiment buy I can see the difficulty their end.

*Tags: Errors Debugging*

---

**Mo** - *12:59:39*

A flag in the market book is troublesome because often the damage will already have been done (you want existing bets voided, not future bets avoided). It also might encourage _more_ betting as people try to get the right side of the fix

*Tags: Errors Debugging, Strategies*

---

**Mo** - *13:21:19*

Apologies to anyone here with a genuine gambling problem

*Tags: General Technical*

---

## 2021-05-27

**Jonjonjon** - *11:29:29*

Where is their public performance?

*Tags: Performance*

---

**Dave** - *11:33:27*

[@UPMUFSGCR](@UPMUFSGCR) [https://priomha.com/documentation/](https://priomha.com/documentation/) found it after one of their guys (founder maybe) was on the business of betting podcast

*Tags: Strategies*

---

**Jonjonjon** - *11:51:13*

Thanks @dave. I'm not keen on performance being reported as a single monthly figure. It doesn't mean much. Equity curves tell a lot more.

*Tags: Performance*

---

**MacrcoPolo** - *13:06:52*

I do overall find sports more interesting, but it's far more time consuming (betfair api is pretty shit) compared to working with crypto exchanges

*Tags: General Technical*

---

**MacrcoPolo** - *13:13:23*

Problem is the holdings look like utter trash

*Tags: General Technical*

---

**Michael** - *15:31:56*

Haha, no I agree. You're really planning for the general case rather than the exceptions so you're apt to get caught out by something like this (although it doesn't look like I was in this case). For my part I incorporate a lot of market signals in my GPS operation so I expect that mitigates things to an extent.

*Tags: Errors Debugging*

---

## 2021-05-28

**Oliver Varney** - *19:25:11*

they should of put the bflw drinks meetup in there :wink:

*Tags: General Technical*

---

**thambie1** - *22:44:17*

I pay PC, I have occasionally deposited. I don't like keeping much more than I need to on my account. So if I have a significant downswing, scale up trading, launch a capital intensive strategy, etc; I will need to deposit.

*Tags: Strategies*

---

**thambie1** - *23:07:12*

To be clear the amount of money I have on my account is less than my total winnings. If anything I'm being the coward by not keeping more on there, haha. It's a combination of trusting my bank more than Betfair, and wanting to minimize risk should my bot go haywire and blow my bankroll.

*Tags: General Technical*

---

## 2021-05-29

**Oliver Varney** - *06:17:24*

maybe a naive question, but do people withdraw often as they trust the bank more as [@U01DCR5PXDY](@U01DCR5PXDY) has said or for other reasons such as having other investments they want to service? Or are they happy to run it up and re-pump the money into new strategies?

*Tags: General Technical*

---

**Mo** - *07:31:15*

I would imagine that most strategies have relatively modest bankroll requirements and it doesn't make sense to have a lot of money sitting in your Betfair account. Surely it's better to have it in products that are covered by the FSCS guarantee? My question is whether anyone has experienced any problems with their bank when making large withdrawals from Betfair?

*Tags: General Technical*

---

**Michael** - *08:00:34*

I withdraw weekly, like [@UBS7QANF3](@UBS7QANF3) Says you don't need much float. In the past I've let it run up and made large withdrawals without problems except that they get held up on BF end.

*Tags: General Technical*

---

**river_shah** - *09:20:14*

I've had both BF and my bank block transactions at the start, had to talk to humans on both ends to explain to them the reason for transfers. Haven't been a problem for a couple of months. 

*Tags: General Technical*

---

**liam** - *09:43:25*

I use paypal as a layer to prevent questions (had issues before when trying to get a mortgage) the issues is that its limited per week (cost to betfair)

*Tags: General Technical*

---

**Mo** - *09:44:40*

[@U4H19D1D2](@U4H19D1D2) that implies they are mainly if not exclusively looking at who the transaction is coming from as otherwise surely they would still question why you are receiving large sums of money through PayPal?

*Tags: General Technical*

---

**liam** - *09:46:43*

yeah any large amounts going in/out are going to be questioned but a lot of the checks are automated and from experience anything with the word 'bet' in gets red alerted :face_palm: As [@U01B8031PM1](@U01B8031PM1) the TM checks work off normal vs abnormal behaviour so if you are consistent you can fly under the radar

*Tags: General Technical*

---

**Jonjonjon** - *10:42:35*

Mine says Betfair Refunds too. HSBC haven't questioned why I get so many refunds

..

*Tags: General Technical*

---

## 2021-06-01

**Jonjonjon** - *10:27:19*

I saw that on LinkedIn. Is the salary for a senior quant modeller really that low?

*Tags: Strategies*

---

**Crofty** - *18:00:21*

When companies like Star Lizard talk about placing client bets into the market, how do people become clients of Star Lizard - is it people who are high net worth individuals for example? I hope that isnt a silly question!

*Tags: General Technical*

---

## 2021-06-04

**Newbie99** - *15:29:34*

[@UEA14GBRR](@UEA14GBRR) it was just a reference to a conversation on here the other day about how Betfair aren't consistent with their approach on this topic, I suspect everyone on here accepts to some degree, so long as something can be bet on, some people will try to fix events, as you say, its just the way it is.

*Tags: Errors Debugging*

---

**Newbie99** - *18:19:33*

[@U4H19D1D2](@U4H19D1D2), I've found out what is happening with regards to these replaced orders, although I haven't had a chance yet to have a full look at the logic.



Using the middleware example, I thought I'd just check a hunch that the replaced order is removing the original one from the blotter, including any matched portion of it and it seems that is what is happening, so by doing the following:



```count = 0

        for current_order in resp.orders:

            [http://logger.info|logger.info](http://logger.info|logger.info)(

                "OrdersMiddleware: Processing order {0}".format(current_order.bet_id),

                extra={

                    "bet_id": current_order.bet_id,

                    "market_id": current_order.market_id,

                    "customer_strategy_ref": current_order.customer_strategy_ref,

                    "customer_order_ref": current_order.customer_order_ref,

                },

            )

            order = self._create_order_from_current(current_order, market)

            if order:

                order.update_current_order(current_order)

                order.execution_complete()

                print(count, [o for o in market.blotter])

                count +=1```

It produces:



```9 [Order 234495806779: Execution complete, Order 234495806780: Execution complete, Order 234496199746: Execution complete, Order 234519003980: Execution complete, Order 234519007090: Execution complete, Order 234561895209: Execution complete, Order 234596897945: Execution complete, Order 234606983431: Execution complete, Order 234835647854: Execution complete, Order 234837496317: Execution complete]

10 [Order 234495806779: Execution complete, Order 234495806780: Execution complete, Order 234496199746: Execution complete, Order 234519003980: Execution complete, Order 234519007090: Execution complete, Order 234561895209: Execution complete, Order 234841458352: Execution complete, Order 234606983431: Execution complete, Order 234835647854: Execution complete, Order 234837496317: Execution complete]```

Order 234596897945 is the original one (which had £2.87 matched out of £3.00), however additionally later on the remaining 13p was replaced with Order 234841458352, this then matched later on (both prior to shutdown of course).



As you can see from the above, when the second order appears in the blotter the first one is removed and the already matched portion is taken out too.



This appears to be something very specific to orders where a portion has later been replaced and I'm guessing is to do with the way the orders are linked, but I haven't had a chance to look at that yet.



Hopefully that is helpful, but I'll keep on digging away too!

*Tags: Strategies*

---

## 2021-06-05

**Oliver Varney** - *14:12:47*

9 meets all in a short period of time cant help also

*Tags: General Technical*

---

**Mo** - *14:42:24*

You know there is a distinction between these place markets in the market type? (PLACE vs OTHER_PLACE). It makes it very easy for API users to focus on the main Place market. My guess is the problem here is not the number of markets but the general problem of how to attract liquidity to a sport/market type that people aren’t really interested in

*Tags: General Technical*

---

**Newbie99** - *15:00:43*

It was the order_id!



The replacement order has the same order_id as the initial order, so when this gets added to the blotter, the first bet_id is removed.



My short term fix is just order_id = current_order.bet_id (just for the orders picked up by middleware).



Not sure if there is a better approach than that (could generate a new hash or something, not really sure what the correct/best way is).

*Tags: Errors Debugging*

---

## 2021-06-09

**Steve Roach** - *02:46:34*

Digging into some of the documentation and a couple of random questions occurred to me:

• API-NG: what does the NG stand for?

• What is the difference between bflw &amp; flumine? Is there overlap in functionality?

*Tags: General Technical*

---

**thambie1** - *03:05:08*

NG is the api version, though I'm not sure what the actual letters stand for. Bflw is a simple tool to access the Betfair API using python. Flumine is a full framework for trading, which notably includes backtesting. Flumine uses blfw.

*Tags: Strategies*

---

**Steve Roach** - *07:02:23*

Thanks for that. So, I’m going to build 2 main systems - one for analysis, the other for managing bets. Is there a preference for bflw or flumine for either of these. Of course, the analysis engine is mainly concerned in collecting and structuring data, largely from betfair but I could imagine other feeds down the track. The bet management system would interact with live markets using strategies invented on the former. Or is this just a personal preference?

*Tags: Deployment*

---

**Mo** - *07:08:41*

If you’re starting from scratch then use flumine. You can use it to collect Betfair price data and do backtesting and any strategy you develop using it can be trivially switched from backtest to live

*Tags: Deployment, Strategies*

---

**Lee** - *12:06:55*

i used to use it at my previous two companies, might be able to help with some basic config

*Tags: General Technical*

---

## 2021-06-10

**Sam Asin** - *18:16:45*

Not sure if any of you guys read Matt Levine, but he mentioned this article and it seems pretty funny/applicable to your models

*Tags: Strategies*

---

**Sam Asin** - *18:19:17*

"A simple trading strategy of betting against all horses classified as fast-sounding yields a return of approximately 2.9% before the commission but a negative return of −1.6% after deducting the standard commission of 5% from Betfair. This finding could be bracketed under the “limits of arbitrage” argument of Gromb and Vayanos (2010) because the mispricing is not large enough to overcome the transaction costs; thus, potentially misleading or false information is not fully eliminated from prices."

*Tags: Strategies*

---

**Mo** - *18:29:10*

Yeah sounds like a great strategy to me

*Tags: Strategies*

---

**Oliver Varney** - *18:33:12*

The guys who solved poker, I'm sure they published their paper straight away ....

*Tags: General Technical*

---

**thambie1** - *18:33:29*

The ones who solved limit poker sure did

*Tags: General Technical*

---

**Sam Asin** - *18:36:19*

haha maybe i'm too trusting but not gonna lie, if I were interested in trading horses I'd at the very least be testing whether or not to include it in my model, and/or reading the details of the paper to see if it's messed something up badly.

*Tags: Strategies*

---

**Sam Asin** - *18:39:28*

Not sure if Mo is being sarcastic or not but yeah I think it'd be hilarious if this could add even a little value to an already profitable strategy. Some situation where you have a profitable strategy, but you can up your belief about your edge slightly when betting against a fast sounding horse, and lower it slightly when betting against a slow sounding horse, and improve your bet sizing or something.

*Tags: Performance, Strategies*

---

**Unknown** - *23:21:52*

As the commission is mentioned here, I can see a strategy on AU horse races I have been doing for the past 12 months is profitable (mostly a straight line), IF the commission is 0-1% (unfortunately), but you know the often 6% (sometime 10%) commission completely destroys any profit. I was wondering if you [@UBS7QANF3](@UBS7QANF3) or anyone have any advices on how to deal with it (get some profit out of it), if possible at all. Thanks in advance!

*Tags: Strategies*

---

## 2021-06-13

**Oliver Varney** - *10:25:21*

no mention of bflw or flumine, youve missed a trick there [@U4H19D1D2](@U4H19D1D2) :joy:

*Tags: General Technical*

---

**D C** - *11:20:24*

[@UBS7QANF3](@UBS7QANF3) you are right there but he only did that off the back of cricket trader Mark Iverson asking legit questions about the credibility of it many many months prior. Him and his toxic mate "GeeksToy" were mainly looking for clicks and likes there.

*Tags: General Technical*

---

## 2021-06-17

**Paul** - *21:45:28*

It’s an interesting strategy. If you were to do this on BF you overcome the weak middle of laying to liability and the third or fourth in the market landing and laying to payout across the book where you flatten returns but you end up needing to match £1k a runner to make £10 profit

*Tags: Strategies*

---

**AndyL** - *23:24:13*

[@U4H19D1D2](@U4H19D1D2) ha, hadn't seen this, quite ironic given my question in [#CTPL3R3FU|strategies](#CTPL3R3FU|strategies)

*Tags: General Technical*

---

## 2021-06-18

**Unknown** - *10:57:37*

My son and myself were behind this one some time ago; think the guy owns a company that sells applications, hence the plate :grinning:  Think you need one with Flumine Liam :grinning:

*Tags: General Technical*

---

## 2021-06-20

**Newbie99** - *20:44:43*

For live, I use the sep parameter to insert a code (i.e. order type a, b, c etc.), however I noticed in paper trading, it appears to ignore the sep parameter and just appears to have the 2 hashes joined together without a separator. Is there a way to replicate the live functionality here, so I can insert my order code without messing around with flumine source code (or if that is the only option, which bit should I be looking at, as I couldn't work it out)?



All I'm doing is this:



```order = trade.create_order(

        side=order_direction, order_type=LimitOrder(price=price, size=stake, persistence_type=persistence_type), sep=sep

    )```

*Tags: Deployment, Strategies*

---

## 2021-06-21

**Newbie99** - *12:02:44*

[https://github.com/liampauling/flumine/issues/453#issue-926097024](https://github.com/liampauling/flumine/issues/453#issue-926097024)

*Tags: General Technical*

---

## 2021-06-23

**PeterLe** - *11:32:31*

Sorry very basic question..Ive got the marketrecorder running just fine and its set up on an account that Im using my own program on. That program places plenty of bets during the day. (So no issues with recording and not placing bets...)

My question is: Given that Im using my ownprogram during the day on that account, I only want Flumine to record and not place any bets. Am I correct in thinking that Flumine doesnt automatically include any strategy (such as Lowest Later etc)?

Im fairly sure it doesnt but just want to double check . many thanks and sorry for basic question

*Tags: Strategies*

---

**PeterLe** - *11:41:26*

Thanks [@UUCD6P13J](@UUCD6P13J) So as a way forward, as Im still learning Python, would a good way forward be :

Record Data

Create Strategies

Test Those Strategies as a BackTest against recorded data before going live (On limited funds :grinning:)

*Tags: Deployment*

---

**Peter** - *11:48:29*

[@UQL0QDEKA](@UQL0QDEKA) You can run multiple instances of Flumine. Each instance will only run the strategies that you explicit add to it. So it's possible to run one instance that just does data collection and a different one to execute your strategies. Though backtesting would be done locally against your recorded data and wouldn't involve any real money.

*Tags: General Technical*

---

**PeterLe** - *11:48:37*

Yea thanks Lee, I had a strategy that [@U016TGY3676](@U016TGY3676) kindly coded up for me and Ive been going through that line by line. Its a pity we dont have more examples to go off. I know people wont want to post up their strategies but its easy to disguise the real 'secret sauce'

Just enjoying learning it to be honest

*Tags: Strategies*

---

**Dave** - *13:31:55*

Can I have a strategy that backs the runner with the largest price (cus bigger the price, bigger the win), and then greens up for a guaranteed profit at SP???? and don't enter the market if it isn't guaranteed

*Tags: Strategies*

---

**Aaron Smith** - *14:55:25*

yea, greening (so laying) obviously makes no sense in this strategy (cus bigger the price, bigger the loss)

*Tags: Strategies*

---

## 2021-06-25

**Mo** - *08:25:32*

Samantha Murray Sharan vs Marta Kostyuk is the match in question

*Tags: General Technical*

---

**azevedo** - *10:04:27*

[@UBS7QANF3](@UBS7QANF3) another match fix?

*Tags: Errors Debugging*

---

**PeterLe** - *16:02:36*

Folks quick question please: Im running a backtest on some recent recorded data and all is well (but I only have 229 Markets) , yet when I also try to run it some old recorded markets (I have more data from this period - around July 2019) I get an error such as this:

 raise JSONDecodeError("Extra data", s, end)

json.decoder.JSONDecodeError: Extra data: line 2 column 1 (char 1508)



Im just wondering has the structure changed somehow or is it an error in my code?  Ie has the data that Flumine records changed in any way?) Thanks in advance

*Tags: Errors Debugging*

---

**Mo** - *16:04:18*

Do you know exactly which of the markets is broken? I suspect the raw file has a problem 

*Tags: General Technical*

---

**PeterLe** - *16:11:12*

Im not sure [@UBS7QANF3](@UBS7QANF3) It doesnt provide enough detail in the error message. Should files recorded in that period (july 2019) work ok with the latest version of Flumine, if so, Ill work through it. Thanks

*Tags: Errors Debugging*

---

**Mo** - *16:12:50*

I don’t use flumine but I can’t think of a reason why the format would have changed. I am thinking you had a connection issue or something that caused a partial json object to be output or some such. If you could work out the file (just put a print statement somewhere indicating which file is being processed) then you could examine the file for obvious errors like these

*Tags: Errors Debugging*

---

## 2021-06-26

**Adrian** - *07:37:29*

Can I ask the opinion of you more seasoned python warriors... I have a script cycling through the markets created by marketrecorder monitoring the start time so that at the correct time i can execute a strategy. I need to know my choices with regards to calling that strategy. My first inclination is call a separate script through os, because I may have to run multiple strategies at once if markets overlap. The second way is probably the correct way and a bit over my head, that would be to run multiple strategies from within that same monitoring script without using os and without calling other scripts. Any pointers?

*Tags: Strategies*

---

**Mo** - *07:43:44*

Good question, I don't know. [@UQ379K087](@UQ379K087)?

*Tags: General Technical*

---

**Peter** - *07:47:24*

My gut says option 2, but I'm not entirely clear what you're trying to do here.



Are you trying to work out when specific events go in-play, or using a population of markets to try to build a model to predict start times, that you would then use to initiate actions.



Either way, Flumine is rather good at running multiple strategies from a single script (and therefore limiting the number of connections needed) and the each strategy's `check_market_book` method allows you to control which are active at any point in time.

*Tags: Strategies*

---

**Adrian** - *07:51:48*

Thanks [@U9JHLMZB4](@U9JHLMZB4). It's simply monitoring when an event is within, say 5 minutes of starting and if it is then turn on the automation for that market. If I am looping through the markets checking the times, how would it be possible to run a strategy from within that loop without interrupting the loop, so that it can continue to monitor the other markets.

*Tags: Strategies*

---

**Mo** - *07:52:28*

Are you using flumine?

*Tags: General Technical*

---

**Oliver Varney** - *07:54:32*

[https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/flumine/markets/market.py#L126](https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/flumine/markets/market.py#L126)

*Tags: General Technical*

---

**Oliver Varney** - *08:10:30*

[https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/flumine/baseflumine.py#L120](https://github.com/liampauling/flumine/blob/6d7ed2eed5a1a111949d0feb4ffe11f9be28efec/flumine/baseflumine.py#L120)

*Tags: General Technical*

---

**Oliver Varney** - *08:17:01*

worth checking out this function. It may be abit obscure if your new to python but in plain English ignoring most of it, basically a market_book update will come through and need to be processed. To save processing time, a function was created strategy.check_market_book (it looks like in newer versions of flumine it gets called via strategy.check_market  ) to throw away any updates that are not required. If the function strategy.check_market_book return True then strategy.process_market_book will be called. If strategy.check_market_book return False it will not be called.

*Tags: Getting Started, Strategies*

---

**Dave** - *09:19:07*

Flumine is a bit magical in this sense. The code you need to write can be from the perspective of trading a single market, however this logic is executed on every market, seamlessly, that you allow via the return value from `check_market_book`

*Tags: Strategies*

---

**Mo** - *10:48:34*

[@U01S1VB9X9P](@U01S1VB9X9P) think about it like this. What you are trying to do - run multiple strategies on multiple markets which operate some X seconds before an event starts - is very common. If it's common, flumine can handle it

*Tags: General Technical*

---

## 2021-06-28

**Matthieu Labour** - *12:33:22*

I came across this BBC podcast about Tennis Fixing. [https://www.bbc.co.uk/sounds/play/p03g25cn](https://www.bbc.co.uk/sounds/play/p03g25cn).

*Tags: Errors Debugging*

---

**PeterLe** - *21:50:48*

Just watching the France Switzerland game, how do you football traders model that!:open_mouth:

*Tags: Strategies*

---

## 2021-06-29

**LK** - *07:32:02*

I've never seen anything other than 0 for handicap. Cannot think of a reason why it would be needed for horses or dogs. The term handicap means something different for horses and dogs compared to team sports. To answer your question: handicap for dogs and horses always zero.

*Tags: General Technical*

---

**Ke** - *08:10:30*

Anyone knows how to access pinnacle from UK?

*Tags: General Technical*

---

**D C** - *20:33:59*

yeah. I was getting lags of 15 seconds at times for a short period but could be a problem with my setup.

*Tags: Getting Started*

---

**Newbie99** - *20:48:43*

(I'm using AWS EC2, eu-west-2c region, are you the same by chance?)

*Tags: Deployment*

---

**D C** - *20:49:40*

no I'm testing something new out from home - thats why I have a strong suspicion it could be a problem my end but I thought I would ask the question just in case.

*Tags: General Technical*

---

## 2021-06-30

**birchy** - *20:05:29*

Yeah, you've probably already got something in mind? Correct me if I'm wrong, but weren't you working on some sort of market re-player using historical data?

*Tags: Data Quality*

---

**Dave** - *20:38:18*

Don't care about the historical data. Just want the merch. I am in.

*Tags: Data Quality*

---

## 2021-07-01

**Javier Martín Pérez** - *15:10:26*

I am giving my first steps with a greyhound strategy built on top of betfairlightweight. I can place bets but not sure how to check if the bets have been matched?  Do you have to actively check it all the time or do you receive some sort of notification on the stream? Can´t find anything if it's not matched straight away.

*Tags: Strategies*

---

**river_shah** - *15:19:44*

Anyone use poetry for python dependency management? I have a mix of private package repos and pypi. Wondering what the best practices circa 2021 are. raw pip and requirements.txt seems rife for dependency confusion attacks among many other issues.

*Tags: General Technical*

---

**river_shah** - *15:22:36*

potery seems promising: [https://python-poetry.org/](https://python-poetry.org/)

*Tags: General Technical*

---

**river_shah** - *18:34:58*

nice things like:

```$ poetry show --tree

requests-toolbelt 0.8.0 A utility belt for advanced users...

└── requests &lt;3.0.0,&gt;=2.0.1

    ├── certifi &gt;=2017.4.17

    ├── chardet &gt;=3.0.2,&lt;3.1.0

    ├── idna &gt;=2.5,&lt;2.7

    └── urllib3 &lt;1.23,&gt;=1.21.1



$ poetry show --latest

pendulum 2.0.4   1.4.5 Python datetimes made easy.

django   1.11.11 2.0.3 A high-level Python Web framework ...

requests 2.18.4  2.18.4 Python HTTP for Humans.```

My stack nearly got into some operational trouble due to dependency confusion..poetry just helps tighten the package supply side of things. it is not much of a cognitive overload if you just want to replicate pip behaviour and wait for more advanced feature usage

*Tags: Feature Engineering*

---

## 2021-07-05

**Newbie99** - *22:39:50*

Is there a way to delay Middleware adding a market until the market catalogue has been updated?



This (as always) is very niche...but some markets (e.g. [https://www.betfair.com/exchange/plus/politics/market/1.160740937|1.160740937](https://www.betfair.com/exchange/plus/politics/market/1.160740937|1.160740937)) runners can be settled, whilst the market remains active. The middleware appears to be pulling in some orders on a runner that has been settled in the Betfair GUI, so the exposure is showing incorrectly.



I tried to filter out orders for runners where runner.status != 'ACTIVE' and this appeared to work, but then I noticed it quite often errored as the market_book hasn't always loaded into the market.



I thought it would be a simple sleep(x) but that doesn't appear to work as presumably all it does is stop the Framework kicking off in the first place for x seconds.



So, is this possible and I'm missing the obvious way to delay it, or is it simply not doable?

*Tags: Errors Debugging*

---

## 2021-07-06

**Newbie99** - *09:50:35*

Haha I agree, but I have no idea how to detect whether a market can have runners settled before the end (other than simply knowing its that type of market) and otherwise it means running for all markets.

*Tags: General Technical*

---

**Newbie99** - *10:07:34*

Very true about the debt!



In this case, the order status doesn't help, this is the order:



`{'bet_id': '223920989477', 'average_price_matched': 17.0, 'bsp_liability': 0.0, 'handicap': 0.0, 'market_id': '1.160740937', 'matched_date': datetime.datetime(2021, 2, 12, 23, 10, 17), 'order_type': 'LIMIT', 'persistence_type': 'LAPSE', 'placed_date': datetime.datetime(2021, 2, 8, 23, 32, 3), 'regulator_auth_code': None, 'regulator_code': 'GIBRALTAR REGULATOR', 'selection_id': 25205104, 'side': 'LAY', 'size_cancelled': 0.0, 'size_lapsed': 0.0, 'size_matched': 2.0, 'size_remaining': 0.0, 'size_voided': 0.0, 'status': 'EXECUTION_COMPLETE', 'customer_strategy_ref': None, 'customer_order_ref': None, 'price_size': &lt;betfairlightweight.resources.bettingresources.PriceSize object at 0x00000229D309F880&gt;, 'lapsed_date': None, 'lapse_status_reason_code': None, 'cancelled_date': None}`

*Tags: Strategies*

---

**Newbie99** - *10:08:30*

and unless I'm being dumb (which is quite possible) I can't figure out a smart way to filter it out



In the end, I used this approach you suggested, which appears to do the job:



```        if market.market_book is None:

            market_book = self.flumine.client.betting_client.betting.list_market_book(market_ids=[market.market_id])[0]

        else:

            market_book = market.market_book



        runner_list = [(str(runner.selection_id), str(runner.handicap)) for runner in market_book.runners if runner.status == 'ACTIVE']



        for current_order in resp.orders:

            if (str(current_order.selection_id), str(current_order.handicap)) in runner_list:```

*Tags: Strategies*

---

**Jonjonjon** - *11:02:55*

Do people use execution algos such as TWAP to help them execute more size?

*Tags: General Technical*

---

## 2021-07-07

**Peter** - *07:54:20*

Your code as written should be returning a "TypeError: fetch() got an unexpected keyword argument 'date_gte'" message. Query style search criteria need to be wrapped in an AND, OR or NOT function. This works for me



```from imap_tools import AND

...

for msg in mailbox.fetch(AND(date_gte=datetime.date(2021, 6, 1))):```

*Tags: Errors Debugging*

---

**James** - *11:18:50*

Thanks Peter. I'm beginning to think there's an issue with yahoo as this throws an error.

*Tags: Errors Debugging*

---

**liam** - *14:36:39*

big question is do you trust that data

*Tags: General Technical*

---

**liam** - *14:37:04*

2016/17 is when they stopped supplying the old historic data and moved to the current streaming format

*Tags: General Technical*

---

**Unknown** - *14:53:31*

I don't have back to 2017 but here's volumes (summed) for the last 12 months from recorded data. Might be helpful comparison.

*Tags: General Technical*

---

**Oliver Varney** - *14:57:58*

or streaming

*Tags: General Technical*

---

**Oliver Varney** - *16:01:17*

15 mins was enough to confirm everything we already knew about Jason, shame the questions were weak and didnt go further to challenge his responses

*Tags: General Technical*

---

## 2021-07-08

**D C** - *19:39:33*

Maybe a bot error submitting lots of bets at 2.0 in quick succession with failure to check that they were already placed? Seems to have fat fingered the entire ladder and then kept on going.

*Tags: Errors Debugging*

---

## 2021-07-09

**Oliver Varney** - *08:26:34*

silver lining as that was the final straw and pushed me to go full auto with my own stuff and kindly [@U4H19D1D2](@U4H19D1D2) was just releasing flumine at that point

*Tags: General Technical*

---

**PeterLe** - *08:43:52*

Just out of interest, you mentioned that you saw your position in betangel yesterday…do you use flumine exclusively to place your bets and betangel to provide you with visuals ?

*Tags: General Technical*

---

**Peter C** - *11:23:18*

Just checked - that's it I think. Sorry, stupid question, should have thought about it.

*Tags: General Technical*

---

**liam** - *17:09:59*

Deadline today for the hackathon [https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1625155535217600|https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1625155535217600](https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1625155535217600|https://betfairlightweight.slack.com/archives/C4HL6EZTQ/p1625155535217600)

*Tags: General Technical*

---

## 2021-07-10

**Scott** - *07:33:00*

Morning all, if one of the football guys wouldn’t mind could they run a calc on how many games go over 1.5 goals but fail to go over 2.5? Ideally in top 5 leagues and CL. Not for a strategy of my own. Just intrigued at some o1.5 prices in relation to o2.5

*Tags: Strategies*

---

**thambie1** - *08:21:26*

[@U0223J9067R](@U0223J9067R) You'd be able to answer questions like that better and more easily with a dataset like this ([https://www.kaggle.com/hugomathien/soccer](https://www.kaggle.com/hugomathien/soccer)), than with the one I'm using. For me to answer a question like that I'd have to write a custom backtest, and spend hundreds of cpu hours running it. Perhaps others on here have their data in more suitable formats

*Tags: General Technical*

---

**Scott** - *08:40:13*

Thanks [@U01DCR5PXDY](@U01DCR5PXDY) I’ll take a look. Wasn’t sure if anyone had a simple results database from the past few years they could query total goals = 2

*Tags: General Technical*

---

## 2021-07-13

**Newbie99** - *17:14:12*

[https://nypost.com/2021/07/13/wimbledon-being-investigated-for-alleged-match-fixing/?utm_medium=SocialFlow&amp;utm_source=NYPTwitter&amp;utm_campaign=SocialFlow|https://nypost.com/2021/07/13/wimbledon-being-investigated-for-alleged-match-fixin[…]medium=SocialFlow&amp;utm_source=NYPTwitter&amp;utm_campaign=SocialFlow](https://nypost.com/2021/07/13/wimbledon-being-investigated-for-alleged-match-fixing/?utm_medium=SocialFlow&amp;utm_source=NYPTwitter&amp;utm_campaign=SocialFlow|https://nypost.com/2021/07/13/wimbledon-being-investigated-for-alleged-match-fixin[…]medium=SocialFlow&amp;utm_source=NYPTwitter&amp;utm_campaign=SocialFlow)

*Tags: Errors Debugging*

---

## 2021-07-16

**Oliver Varney** - *09:20:44*

I think what would be nice if slack had a way of doing an anonymous chart style response (not sure if this is a thing). Id be interested in this question but as a scatter with years experience on the y axis and stake/ traded volume on the y axis. Getting the buckets correct with a poll is quite hard without knowing roughly the distribution of responses.

*Tags: General Technical*

---

**Jonjonjon** - *09:26:45*

Would we expect stake/traded volume to go up much with years of experience? It could easily decline at some point, if a user's strategy stopped working. :disappointed:

*Tags: Strategies*

---

**river_shah** - *09:29:52*

I really don't think this is a good metric at all. It is super dependent on strategy and market. Better metrics are value at risk or variance adjusted stakes. A better question could be what is user mean / variance profile per month.

*Tags: Strategies*

---

## 2021-07-20

**Adrian** - *23:08:48*

I'm curious how you guys use flumine, whether you have a lot of your own custom code in there or if you use the libraries extensively. I ask because I got tons of my own code, classes and functions to get it up and running how I need it, but only because I am a laymen when it comes to understanding how flumine works and don't really know how to utilise its potential.

*Tags: General Technical*

---

**Andy B** - *23:26:25*

I'll second that notion Adrian.  At this stage I am still far more comfortable with my own code, although I have finally implemented somethign with betfairlightweight.

*Tags: General Technical*

---

**Adrian** - *23:36:45*

Thanks Andy. Have you tried flumine? I think it's amazing but I know i'm only scratching the surface

*Tags: General Technical*

---

## 2021-07-21

**Peter** - *03:33:06*

[@U01S1VB9X9P](@U01S1VB9X9P) for me it's a point of principle not to load Flumine strategies up with a ton of my own code. I view my strategies as infinite loops executing the same code over and over, so want that code to be as lightweight as possible. Whenever Flumine has a helper that does what I need, I use it in preference to writing my own as they often deal with edge cases that I might not have thought of, and moreover, it makes the code more maintainable for when future me comes back to it later needing to make adjustments. That doesn't mean I don't have some quite complex processing, but when it starts to get too complex, that's often a sign that I'm overthinking the strategy itself.

*Tags: Strategies*

---

**liam** - *10:05:05*

cool, I think this place can be a bit daunting to a newbie but it seems the best discussions have come about the simple questions

*Tags: General Technical*

---

**Adrian** - *10:09:16*

i think some kind of manual or flow chart would help for those getting started. i would like to create something visual to help me learn flumine. if anyone else is interested i might make a kind of mind map or something

*Tags: Getting Started*

---

**liam** - *10:31:35*

Yep, certainly a need for this and agreed on it being visual, can probably start with a just a simple diagram and description on bflw/flumine and how they interact at a high level before dropping down to the different threads and queues etc

*Tags: General Technical*

---

**Jonjonjon** - *10:41:05*

It was kind of Bruno to share his knowledge, but the talk didn't really convince me that advanced modelling/quant work is the way forward.

*Tags: Strategies*

---

**Jonjonjon** - *12:24:32*

The modelling channel?

*Tags: Strategies*

---

## 2021-07-22

**Oliver Varney** - *15:33:36*

is it possible for someone to pull the funds from their betfair account before an incorrect settlement is fixed ?

*Tags: Errors Debugging*

---

**D C** - *16:47:28*

Bit cheeky of them to give people grief when it is their incorrect settlement that has caused the problem!

*Tags: General Technical*

---

## 2021-07-23

**Mo** - *15:20:46*

This model has 100% accuracy

*Tags: Strategies*

---

## 2021-07-24

**Jonjonjon** - *21:18:00*

Are there any plans to update the flumine backtester so that simulated orders remove liquidity from the exchange?

*Tags: General Technical*

---

## 2021-07-29

**Dirk** - *09:51:08*

I'm not entirely sure what this slack group actually is about, but in fact, I was trying to login to Betfair using python using betfairlightweight but couldn't manage. I've set up the certificates and found my (delayed) app key. Upon following the tutorial on [https://betfair-datascientists.github.io/api/apiPythontutorial/](https://betfair-datascientists.github.io/api/apiPythontutorial/) I got stuck at the moment of actual login. Is there anyone keen on helping a newbie out? You can send me a private message

*Tags: General Technical*

---

**Mo** - *11:03:41*

What do you mean “stuck”? What’s the error message?

*Tags: Errors Debugging*

---

## 2021-08-03

**Oliver Varney** - *08:47:29*

bit of a random question, but trying to understand a best practice. I am wondering if your get data from a source that is a dict with many levels deep and your are converting it into classes, if one of the attributes of a class sometimes gets a data attribute which itself may have a few levels, when its not included in the dict from the data provider, would you initialise that variable to None, or would you propagate that down to the lowest level and set the variables to none in each of the classes (sorry if this doesnt make hard to explain).

*Tags: General Technical*

---

**Peter** - *09:40:51*

My philosophy on this sort of thing is that your objects are models of something happening in real-life, and so should broadly follow the real-life structure. Thus if you discover that an object or attribute of an object doesn't exist, mark it as None at that level, rather than constructing lower levels reflecting what would be there if it existed. This has the advantage of potentially saving some CPU cycles by catching no-existence higher up the tree.

*Tags: Strategies*

---

**Oliver Varney** - *09:43:55*

The rationale for maybe populating the lower levels is that the user doesnt have to constantly check whether each level is None or not  and im not sure whats preferable. i.e. if you have a horse object that has a attribute flat_statistics which include like number of runs, percentage of wins etc, if for some horses its provided and other its not you would have to constantly check whether it exsists and that just for one level. Performance would not be a concern as its just a regular get request with unlikely need to constantly poll.

*Tags: Performance*

---

**liam** - *09:46:30*

But doesn't that then make error handling harder? As I assume its easy to send a null value through to a model but if the entire class is null you would have to handle?

*Tags: Errors Debugging, Strategies*

---

**Oliver Varney** - *09:46:57*

the entire class would obviously have to have default values, but typically I would have to add these into the database anyways.

*Tags: General Technical*

---

**Oliver Varney** - *09:50:39*

in the example of a horse stat, when its null it just means it hasnt run, so in a model a default value for runs = 0. I can also see other cases where maybe it doesnt make sense though

*Tags: Strategies*

---

**Michael** - *11:29:55*

Quick python question if that's ok:



Are sets always ordered? When I google it says 'no' but if I make a set - like set([1, 3, 4, 4, 2, 5]) and print it it always seems to come out in order. What's going on there?

*Tags: General Technical*

---

**liam** - *11:36:19*

oh so tiny size, just use Mo's code, but to answer your question sets aren't ordered

*Tags: General Technical*

---

**thambie1** - *11:36:40*

No tree sets in python?

*Tags: General Technical*

---

**Mo** - *12:27:33*

bflw inside joke :muscle:

*Tags: General Technical*

---

**Oliver Varney** - *13:12:40*

is order stream recording supported like market stream in flumine [@U4H19D1D2](@U4H19D1D2)?

*Tags: General Technical*

---

**liam** - *13:13:42*

thinking about how we can plug betfairviz straight into flumine and use it as a backtester visualiser

*Tags: General Technical*

---

**Mo** - *20:01:39*

Yeah but I'm kicking myself for not working out how to make evince full screen ahead of time

*Tags: General Technical*

---

## 2021-08-05

**PeterLe** - *11:39:58*

Morning; Quick question please re this var...max_selection_exposure: float = 500,

if you had two selections A&amp;B and you had a £2 lay bet matched on each (lets say at 2), would the selection exposure be -£2 for each or would it be 0? Thanks

*Tags: General Technical*

---

**liam** - *11:50:37*

logic [https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/controls/tradingcontrols.py#L168|here](https://github.com/liampauling/flumine/blob/4f6fa1b9a2ab4c70f6bcec5888a012c17d47a3c0/flumine/controls/tradingcontrols.py#L168|here), quick lookup using this function:



```current_exposures = market.blotter.get_exposures(

    strategy, lookup=(market_id, selection_id, handicap), exclusion=exclusion

)```

*Tags: Strategies*

---

**Jonjonjon** - *15:12:43*

Could be useful for models based on trading prices just before the race starts.

*Tags: Strategies*

---

## 2021-08-06

**liam** - *15:52:15*

Yeah I do a fair amount of frontend stuff, normally for POC or fixing other peoples shit :wink:

*Tags: Errors Debugging*

---

## 2021-08-07

**Mo** - *10:38:36*

You don't need to go through any kind of formal setup procedure. The biggest question is how are you going to distribute profits? Will you have one account doing the betting or will each member have their own account?

*Tags: Getting Started, Strategies*

---

**Thomas JAMET** - *10:40:12*

Yes, this is part of the question. Ideally, we want to have a single account and then share from that account, i.e. pooling the bankroll (and the PnL).

*Tags: General Technical*

---

**Thomas JAMET** - *10:40:56*

But how to justify the cash flows if we are not legally setup?

*Tags: Getting Started*

---

**Mo** - *10:46:50*

There's no official way to set up a syndicate. You'll need to create a syndicate agreement. Up to you whether you want this checked over by a solicitor. That will be your justification for your banking activity but if the bank starts to question your transfers they will run a mile even with the syndicate agreement

*Tags: General Technical*

---

**Mo** - *10:59:29*

Some advice regarding the banking situation:



1. If you can organise your betting activity such that each individual has their own betting account and earns their own betting profits this greatly simplifies matters. To distribute profits you can rotate the account being used or use all accounts simultaneously. There are bound to be some imbalances in individual profit earned but hopefully these will even out over time and require much more modest balancing payments at the end of the year

2. You _may_ have more success using an e-money provider (e.g. Revolut) rather than an actual bank (with a banking license)

3. If you do use a bank, probably better to distribute by withdrawing cash but the individuals may have problems with their own banks when depositing

*Tags: Strategies*

---

**Mo** - *11:06:52*

I think it's a question of being able to get (a lot) more down at a similar price (for some markets)

*Tags: General Technical*

---

**Oliver Varney** - *11:38:46*

kinda off topic of the original thread, but could someone explain pinnacles business model? Ive herd people say they can bet very large amounts without getting banned or limited, but is this true in reality?

*Tags: Strategies*

---

**Oliver Varney** - *11:44:52*

interesting, I can see why they dont do horses with this model (assuming its not regulatory)

*Tags: Strategies*

---

**Mo** - *11:44:52*

From listening to Marco Blume speak they probably also have good models so they're close to that true price to begin with

*Tags: Strategies*

---

**Oliver Varney** - *11:48:01*

They sound like a pretty good pricing model for other bookies to copy (adding in a higher margin)

*Tags: Strategies*

---

**Thomas JAMET** - *11:52:22*

Definitely off topic of the original thread but is there a library similar to the BFLW library that uses the Pinnacle API and integrates with Flumine?

*Tags: General Technical*

---

**azevedo** - *11:56:24*

To add to Mo’s on Pinnacle topic, you have the behaviour where Pinnacle shows you a maximum amount for a single bet at any given time, and if you take that max you would move their lines. And Pinnacle are very good at setting those limits and margins depending on time to event/activity/their models etc. For example, from Marco Blume’s description, they would be open to take much larger bets in the middle of a baseball season as they more confident with their models vs earlier in the season. So I’d imagine there is a combination of all these factors that they optimise and set appropriate limits and margins throughout the event lifecycle.

*Tags: Strategies*

---

**Jonjonjon** - *15:04:28*

If 3 different accounts run the same strategy, would Betfair notice, and subsequently put them on the higher PC rate after they've made £250k each, or as a group?

*Tags: Strategies*

---

**Jonjonjon** - *15:12:16*

Any idea what would happen if a strategy was sold to a syndicate, in terms of PC? The strategy would be turned off on the original account and turned on, from another account?

*Tags: Strategies*

---

## 2021-08-09

**liam** - *12:08:47*

Thoughts on [https://www.youtube.com/watch?v=1u3sSGuPhWg|this](https://www.youtube.com/watch?v=1u3sSGuPhWg|this)? Personally I think he has completely missed the point, first of all he isn't going to get the prices manually and secondly the reason he isn't getting the prices is because HT is good, the tips are free so whats the problem :confused:

*Tags: General Technical*

---

**Oliver Varney** - *12:12:51*

[@U4H19D1D2](@U4H19D1D2) getting his Monday Caan fix :joy:

*Tags: Errors Debugging*

---

**Jonjonjon** - *16:11:37*

This may be a dumb question, but do any UK bookies offer API access?

*Tags: General Technical*

---

**S G** - *16:13:16*

Hi guys, is there any java implementation libraries similar to betfairlightweight?

*Tags: General Technical*

---

## 2021-08-10

**Unknown** - *12:28:22*

A bit of fun..:grinning:, 1st live Flumine strat (week) hangin on by a thread (thanks to [@UUCD6P13J](@UUCD6P13J) lee for building the bare bones and then me making it look like a Frankenstein version, and not a pretty one at that!), thumbs up if you think it will  turn out well, thumbs down if you think no chance :grinning: rocket if it will let me put an offer in for [@UPMUFSGCR](@UPMUFSGCR) yacht early next year...and Ill report back in a month :grinning: (PS my main stuff had an under par week too, so lets see)

*Tags: Deployment*

---

**liam** - *12:40:38*

I really miss the excitement of getting something working with python for the first time :sob:

*Tags: Getting Started*

---

**birchy** - *13:50:28*

Hopefully be ok and not what I call a "WM" strategy. :grinning:

*Tags: Strategies*

---

**PeterLe** - *15:53:44*

yea in-play [@U0128E7BEHW](@U0128E7BEHW) , just testing the waters with Flumine, very cautious for now. the objective really was just a bit of fun and to show that someone with a tiny knowledge of Python (ie such as me) can cobble something together.

*Tags: General Technical*

---

**birchy** - *16:06:25*

If you need me to verify the strategy code, please send it over [@UQL0QDEKA](@UQL0QDEKA). :smiling_face_with_3_hearts: :rolling_on_the_floor_laughing:

*Tags: Strategies*

---

## 2021-08-11

**Oliver Varney** - *12:16:20*

Boring question incoming for the python typing nerds, is there a correct way to say the input should be any type of BaseResource or anything that extends that? is Type[BaseResource] correct?

*Tags: General Technical*

---

**Oliver Varney** - *12:20:56*

yup I was more questioning the correct typing convention to use, i.e. the Type[] part

*Tags: General Technical*

---

**Oliver Varney** - *12:24:16*

sorry I havent explained this well, and thanks for the above, the request is getting called from a baseendpoint class which makes a request to an external service and returns a type of baseresource. Ive just checked bflw and it also uses the Type[BaseResource] convention.

*Tags: General Technical*

---

**MacrcoPolo** - *12:25:08*

But plz someone who knows more plz fix me

*Tags: Errors Debugging*

---

## 2021-08-12

**Mo** - *06:30:52*

Not exactly because I don't consider my profits small and I don't think liquidity or competition are big problems for me but the existential threat of being completely dependent on Betfair does keep me up at night

*Tags: General Technical*

---

**Beeblebrox** - *07:46:24*

That's a question only you can answer surely, but if I wasn't enjoying something or I wasn't gaining anything from doing it, either financially or through learning new things, then I'd definitely stop and do something else. Life's too short.

*Tags: General Technical*

---

**Laybot McBackbot** - *07:53:27*

One thing I learned from losing a lot -- if a couple of mistakes (regardless of the sources) could significantly ruin your P/L -- then it's probably not a good system.  These days I am spending most of my time backtesting and compiling all the worst possible outcome that I came across in my testing/live and whatever strat I come up with must be able to survive those.



Of course,  past data is no indicator of future performance but how could one say a system is working if it could not even do well when backtested? :sweat_smile:

*Tags: Performance, Deployment*

---

**PeterLe** - *11:27:09*

I honestly said that if I were to ever start losing money, i would stop immediately. I only put £2k into my account in 2007 and never added to it and Ive done very well on it overall.

I was very lucky really that I got off to a flyer and made a fair bit of money and i have a sense of ‘using betfair money’ so im not too worried if I have a losing day. (nor am I reliant on it as an income)

I think it would be a completely different scenario if I had never made any money and i had a coupe of children to support and a big mortgage though.

The only thing id say [@U01S1VB9X9P](@U01S1VB9X9P) is dont give up too soon though. If you have a well thought out strategy, and offering to the market, you wont lose too much even betting at random in my experience.

*Tags: Strategies*

---

**Oliver Varney** - *14:42:37*

Im probably missing the obvious but, im trying to answer the questions, what was the adjusted price I requested, what was the adjusted price I matched at ( I can grab this either from the order or cleared orders) and the relation. Im not sure about the adjusted request price part

*Tags: General Technical*

---

## 2021-08-13

**Adrian** - *06:40:45*

[@UGV299K6H](@UGV299K6H) thanks for the reality check. This is my conscience on one hand, telling me there are greener pastures. My problem is, I think, quitting too often and not following through. Which is why I haven't given up on this thing.



[@UQL0QDEKA](@UQL0QDEKA) thank you for the word of encouragement. 2007 sure is ahead of my time. I heard the profits were pretty easy to find back then. My strategy is well thought out. I think it's cutting edge, but it's like a solution looking for the right problem.



[@UPMUFSGCR](@UPMUFSGCR) I enjoy learning new things and trying what others won't, so yeah better than World of Warcraft, which embarrassingly was what I was doing before this :joy: I think I started with the manual trading around 18 months ago. With python 6 months. Given the length of time others have been around I guess that means I'm still new so I should lower my expectations.



Thanks everyone, I feel better about what I'm doing. I've noticed this tendency of mine to have a moan right at the pivotal moment when a breakthrough is imminent. Had a good night and today is looking good too. I might have turned things around :crossed_fingers:

*Tags: Strategies*

---

**Adrian** - *06:47:06*

Thanks. That's something I should be focusing more on. My problem is I've started with a system that can't be backtested (easily). So maybe that's the way forward

*Tags: General Technical*

---

**Oliver Varney** - *19:41:02*

Not sure if this is a stupid question, but if you took the IP mid odds at lets say 1f out across all races, how accurate are they on average at the percentage chance of winning?

*Tags: General Technical*

---

**Michael** - *19:59:46*

...and totally not a stupid question by the way.

*Tags: General Technical*

---

**Laybot McBackbot** - *20:05:42*

Question: How many of you bet/trade all AU + US + GB/IRE races and doing well at all of them?  I don't have problem being profitable at GB/IRE races but for months I have not been able to crack AU markets and all the $$$ I made from former I lost them trying to crack the latter. I also get mixed results for the US markets, but that's probably due to both the markets liquidity and volatility.

*Tags: General Technical*

---

**Michael** - *20:19:28*

....I'm thinking of a whole other strategy where you use your pre-off model to predict the value of in-running prices, nothing to do with your existing positions.

*Tags: Strategies*

---

**Gazuty** - *22:27:31*

Cracked aus racing from the getgo. Took me almost 10 years to figure out uk/ire racing :flushed: - for me different strategy than aus racing. Cracked aus and uk dogs about 5 years ago. Used to do US racing but the market moved on the edge that I had. 

*Tags: Strategies*

---

## 2021-08-14

**Laybot McBackbot** - *08:52:39*

Thanks, all! Very happy to hear that some people have cracked them all. Now I just need to figure out how to do it myself.

*Tags: General Technical*

---

**Laybot McBackbot** - *12:12:23*

[@UGV299K6H](@UGV299K6H) I would define that consistently profitable with a strategy that a couple of losing bets wouldn't wipe the entire or large amount of the profit made. In other words, if you can confidently do this as your only source of income -- then you've probably cracked it.

*Tags: Strategies*

---

**Michael** - *12:39:41*

I can't agree with that [@UEA14GBRR](@UEA14GBRR) - I think the markets are quite different, just look at the volumes if nothing else. Regarding what you mean by 'cracked' what I'm really getting at is that it probably doesn't make sense to move on from (say) UK racing just because you're making a few quid per market. There's far more capacity in UK racing, if your profits from Aus are the same as UK then maybe you're not exploiting the UK to the fullest - in which case have you really 'cracked' it? If you're thinking about how to get the best return on your time just expanding into new markets isn't the only option. UK racing has room to give more income than anyone could spend - might your time be better spent getting more out of that?

*Tags: General Technical*

---

**Laybot McBackbot** - *14:13:43*

Thanks guys. I agree with both of you. I guess it's just my OCD, one is not enough -- I want to beat of all them, and that's not helping me. I guess I really need to focus on fully exploiting the market that I already know how to be profitable.

*Tags: General Technical*

---

**Michael** - *14:34:47*

Yeah [@UEA14GBRR](@UEA14GBRR) I'm also not interested in the sport - what I really meant was that AUS and UK markets aren't the same in the same way that a horse market isn't the same as a greyhound market. Yes you can treat them the same and if your strategy is generic enough you might win on both but you're not making the most of either. You're doing better on thin markets right? So that shows you that thin markets aren't just scaled down liquid markets. I guess you're working to understand why you're finding that?

*Tags: Strategies*

---

**ShaunW** - *17:03:53*

[@UGV299K6H](@UGV299K6H) I realise I'm probably too far towards the similarities. I'd do well to spend more time looking at asset species. :slightly_smiling_face:  I do try to break things down of course to see what's working it just seems with my little strategy I can't make the differences pay. I've been in maintenance mode too long really, enjoying the small fruits, it's time for some new thinking or ideally rehashing other people's thinking.

*Tags: Strategies*

---

**Michael** - *21:35:10*

You might be in a better position than you think [@UEA14GBRR](@UEA14GBRR), if you've been running a relatively low margin strategy without many changes on a lot of markets you should have a great data set. You'll have a good mix of -EV to +EV bets to work with and not too many strategy changes to confound your analysis. I'm a big believer in working with your bets and refining/developing what you have - you'll have a potential treasure trove of new ideas hidden in the learning you can take from your betting history.



You've got routes in too - let's say you know that you do better in AUS markets (for example) well why? Ok you might say it's thinner volume but that's not really the answer - why exactly does that make a difference? There must be some market characteristic that is more common in those AUS markets that's making the difference. Is it wider spreads? Is it that more of your bets match as offers? Something to do with differential match rates at different odds? Something else? What is it? If you can identify that you'll understand your betting much better and you're sure to be able to develop new approaches from what you find. For an easy start you could find the niches in UK racing that share that critical characteristic and you could cut out all the junk bets where those circumstances don't pertain. Ditching your bad bets is always the lowest fruit.



Quite often people who've had small scale success* either don't understand WHY their strategies make money or they think they understand but they're wrong. That's the key to greater success - (well one of the possible keys). If you can unlock the mechanisms that have returned your profit the the doors really open.



*I don't know you so please forgive me if I'm miss-describing you, I'm just going by my sense from your posts and I mean no dis-respect, small success is far more than the vast majority achieve.

*Tags: Strategies*

---

## 2021-08-17

**Newbie99** - *12:50:25*

Looking at logging controls, particularly this example (which I have up and running fine):



[https://github.com/liampauling/flumine/blob/master/examples/controls/backtestloggingcontrol.py](https://github.com/liampauling/flumine/blob/master/examples/controls/backtestloggingcontrol.py)



Am I correct in saying that currently the best way to capture net profit (i.e. market level grouping of cleared orders, including com) at the same time would be to make a seperate call to list_cleared_orders (with market grouping) when the ClearedOrdersMetaEvent event comes through (currently I just make 2 calls periodically for market and order level, but the logging control approach seems a bit neater than my current approach)?



Appreciate its probably the obvious answer (I've had a look through baseflumine and I think my assumption is correct, but just wanted to check), I'm just always paranoid about making too many API calls!

*Tags: General Technical*

---

**Lee** - *12:54:40*

There's already a worker that does this for you [https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/flumine/worker.py#L226|here](https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/flumine/worker.py#L226|here) and be able to process [https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/controls/loggingcontrols.py#L68|here](https://github.com/liampauling/flumine/blob/62b40ad11988ecab039b3b822bc70779aed64bca/flumine/controls/loggingcontrols.py#L68|here)

*Tags: General Technical*

---

**Newbie99** - *13:36:23*

Apologies, I'm probably being dense, but in order to use that approach, do I not need to tweak the source code (which I was hoping to avoid), I'm perhaps missing the obvious in how I can get that into a custom class (e.g. that backtest logging control example), without adjusting some of the source (of course if that is the only way so be it, not a problem, was just hoping to avoid it if pos)?

*Tags: General Technical*

---

**Lee** - *13:43:42*

The one caveat to that is the cleared market call will only group orders from that flumine instance but you could easily create your own worker that does similar

*Tags: General Technical*

---

**Newbie99** - *14:49:19*

Still can't get this working, I can see the control is added to the framework here:



```framework.add_logging_control(MyLoggingControl())```

and I can see from the logs that it is definitely added.



The meta event I can see is sent here and if I try to capture that it works fine:



[https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/flumine/baseflumine.py#L314](https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/flumine/baseflumine.py#L314)).



So I'm missing a step I think, I can see the ClearMarketsEvent is being sent here, but the control never seems to receive this event:



[https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/flumine/worker.py#L252](https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/flumine/worker.py#L252)



I presume its something blindingly obvious, but I'm missing it!

*Tags: General Technical*

---

## 2021-08-18

**liam** - *08:43:45*

On your test do you have orders on the market? [https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/flumine/worker.py#L250](https://github.com/liampauling/flumine/blob/720eb8168a18bbea62042d3fd0a67a0550b19e9e/flumine/worker.py#L250)

*Tags: General Technical*

---

**Jonjonjon** - *09:42:15*

Tom's got good knowledge. Yet another person telling me not to look at fundamental models.

*Tags: Strategies*

---

**Jonjonjon** - *10:00:03*

The chunking idea is probably good. I usually just apply a model to everything in the dataset.

*Tags: Strategies*

---

**Newbie99** - *13:39:42*

Orders appear to be clearing correctly and I'm just simply trying to verify the event is coming through correctly at the mo, not even trying to do anything clever yet.



Here are the logs:



```INFO:flumine.markets.market:Market 1.186458391 closed

{"asctime": "2021-08-18 12:01:04,265", "levelname": "INFO", "message": "Market 1.186458391 closed", "market_id": "1.186458391", "event_id": "30801039", "event_type_id": "7", "event_name": "Ballarat (AUS) 18th Aug", "market_type": "WIN", "market_start_datetime": "2021-08-18 11:57:00", "country_code": "AU", "venue": "Ballarat", "race_type": "Flat", "orders_cleared": false, "market_cleared": false, "closed": true}

INFO:flumine.baseflumine:Market cleared

{"asctime": "2021-08-18 12:01:04,266", "levelname": "INFO", "message": "Market cleared", "market_id": "1.186458391", "order_count": 31, "client": {"id": "78382e88", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 4, "transaction_count_total": 31, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x0000028CAC6449A0&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": true}, "markets": {"market_count": 249, "open_market_count": 240}, "streams": ["&lt;SimulatedOrderStream(SimulatedOrderStream, started daemon 20980)&gt;", "&lt;MarketStream(MarketStream, started daemon 1276)&gt;"], "logging_controls": ["&lt;ClosedMarketLogging(CLOSED_MARKET_LOGGING_CONTROL, started daemon 26460)&gt;"], "threads": ["&lt;_MainThread(MainThread, started 24220)&gt;", "&lt;Thread(Thread-1, started 24048)&gt;", "&lt;BackgroundWorker(get_live_orders, started daemon 12544)&gt;", "&lt;BackgroundWorker(get_price_change, started daemon 22728)&gt;", "&lt;BackgroundWorker(terminate, started daemon 26972)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 24260)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 8088)&gt;", "&lt;BackgroundWorker(poll_account_balance, started daemon 24856)&gt;", "&lt;BackgroundWorker(poll_market_closure, started daemon 25208)&gt;", "&lt;ClosedMarketLogging(CLOSED_MARKET_LOGGING_CONTROL, started daemon 26460)&gt;", "&lt;SimulatedOrderStream(SimulatedOrderStream, started daemon 20980)&gt;", "&lt;MarketStream(MarketStream, started daemon 1276)&gt;", "&lt;Thread(MarketStream_output_thread, started daemon 19184)&gt;", "&lt;Thread(ThreadPoolExecutor-0_0, started daemon 9736)&gt;", "&lt;Thread(ThreadPoolExecutor-0_1, started daemon 11932)&gt;", "&lt;Thread(ThreadPoolExecutor-0_2, started daemon 20068)&gt;", "&lt;Thread(ThreadPoolExecutor-0_3, started daemon 18468)&gt;", "&lt;Thread(ThreadPoolExecutor-0_4, started daemon 27360)&gt;"]}

INFO:flumine.baseflumine:Market closed

{"asctime": "2021-08-18 12:01:04,267", "levelname": "INFO", "message": "Market closed", "market_id": "1.186458391", "client": {"id": "78382e88", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 4, "transaction_count_total": 31, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x0000028CAC6449A0&gt;"], "order_stream": true, "best_price_execution": true, "paper_trade": true}, "markets": {"market_count": 249, "open_market_count": 240}, "streams": ["&lt;SimulatedOrderStream(SimulatedOrderStream, started daemon 20980)&gt;", "&lt;MarketStream(MarketStream, started daemon 1276)&gt;"], "logging_controls": ["&lt;ClosedMarketLogging(CLOSED_MARKET_LOGGING_CONTROL, started daemon 26460)&gt;"], "threads": ["&lt;_MainThread(MainThread, started 24220)&gt;", "&lt;Thread(Thread-1, started 24048)&gt;", "&lt;BackgroundWorker(get_live_orders, started daemon 12544)&gt;", "&lt;BackgroundWorker(get_price_change, started daemon 22728)&gt;", "&lt;BackgroundWorker(terminate, started daemon 26972)&gt;", "&lt;BackgroundWorker(keep_alive, started daemon 24260)&gt;", "&lt;BackgroundWorker(poll_market_catalogue, started daemon 8088)&gt;", "&lt;BackgroundWorker(poll_account_balance, started daemon 24856)&gt;", "&lt;BackgroundWorker(poll_market_closure, started daemon 25208)&gt;", "&lt;ClosedMarketLogging(CLOSED_MARKET_LOGGING_CONTROL, started daemon 26460)&gt;", "&lt;SimulatedOrderStream(SimulatedOrderStream, started daemon 20980)&gt;", "&lt;MarketStream(MarketStream, started daemon 1276)&gt;", "&lt;Thread(MarketStream_output_thread, started daemon 19184)&gt;", "&lt;Thread(ThreadPoolExecutor-0_0, started daemon 9736)&gt;", "&lt;Thread(ThreadPoolExecutor-0_1, started daemon 11932)&gt;", "&lt;Thread(ThreadPoolExecutor-0_2, started daemon 20068)&gt;", "&lt;Thread(ThreadPoolExecutor-0_3, started daemon 18468)&gt;", "&lt;Thread(ThreadPoolExecutor-0_4, started daemon 27360)&gt;"]}```

Here is the code:



```import logging

from flumine.controls.loggingcontrols import LoggingControl

from flumine.events import events



logger = logging.getLogger(__name__)



class ClosedMarketLogging(LoggingControl):

    NAME = "CLOSED_MARKET_LOGGING_CONTROL"



    def __init__(self, *args, **kwargs):

        super(ClosedMarketLogging, self).__init__(*args, **kwargs)



    def _process_cleared_markets(self, event: events.ClearedMarketsEvent):

        [http://logging.info|logging.info](http://logging.info|logging.info)(event)

        for cleared_market in event.event.orders:

            [http://logging.info|logging.info](http://logging.info|logging.info)(cleared_market.profit, cleared_market.commission)```

I'm really hoping I'm unintentionally just doing something weird (which lets face it is normally the case)!!!

*Tags: Deployment, Strategies*

---

**Newbie99** - *15:04:05*

Actually I say that, this is the message in the above:



```INFO:flumine.baseflumine:Market cleared```

not market _level_ cleared, is the above expected?

*Tags: General Technical*

---

**Lee** - *15:05:00*

The one with level is the one you're looking for, which is the `_process_cleared_markets` method called from baseflumine and your one should be just after this

*Tags: General Technical*

---

**Lee** - *15:06:50*

I've just noticed in your logs you're running with paper_trade=True, that will be the problem as you won't have any orders

*Tags: General Technical*

---

**Lee** - *15:16:51*

yep [https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/flumine/worker.py#L228](https://github.com/liampauling/flumine/blob/1213faebdb8176268ee663a80d48854edacb6872/flumine/worker.py#L228)

*Tags: General Technical*

---

## 2021-08-20

**Jeff Waters** - *08:52:03*

Interesting discussion on match fixing with an ex mafia boss: [https://www.youtube.com/watch?v=9uGfeivlVFo](https://www.youtube.com/watch?v=9uGfeivlVFo)

*Tags: Errors Debugging*

---

## 2021-08-22

**Lee** - *12:59:43*

I've not really had any of the frustrations that they talk about. I do get his points but think Caan's probably over hyped/exaggerated some of his problems.

*Tags: General Technical*

---

**Oliver Varney** - *13:03:42*

I thought Richard conducted himself well / very professionally, but questions are normally answered with high level answers with no push back.

*Tags: General Technical*

---

**Mo** - *13:18:25*

Anyone on the fixed rate PC?

*Tags: Errors Debugging*

---

**thambie1** - *13:42:25*

What exactly is fixed PC? Just a higher commission rate?

*Tags: Errors Debugging*

---

## 2021-08-23

**Mo** - *11:02:55*

Here you go:



[https://www.amazon.co.uk/Logic-Sports-Betting-Ed-Miller/dp/1096805723](https://www.amazon.co.uk/Logic-Sports-Betting-Ed-Miller/dp/1096805723)

[https://www.amazon.co.uk/Trading-Bases-Fortune-Betting-Baseball/dp/0451415175](https://www.amazon.co.uk/Trading-Bases-Fortune-Betting-Baseball/dp/0451415175)

[https://www.amazon.co.uk/Statistical-Sports-Models-Excel-Andrew/dp/1079013458](https://www.amazon.co.uk/Statistical-Sports-Models-Excel-Andrew/dp/1079013458)

[https://www.amazon.co.uk/Precision-Statistical-Mathematical-Methods-Racing/dp/1432768522](https://www.amazon.co.uk/Precision-Statistical-Mathematical-Methods-Racing/dp/1432768522)

[https://www.amazon.co.uk/Efficiency-Racetrack-Scientific-Financial-Economics/dp/981320351X](https://www.amazon.co.uk/Efficiency-Racetrack-Scientific-Financial-Economics/dp/981320351X)

[https://www.amazon.co.uk/Kelly-Capital-Growth-Investment-Criterion/dp/9814383139](https://www.amazon.co.uk/Kelly-Capital-Growth-Investment-Criterion/dp/9814383139)

[https://www.amazon.co.uk/Man-All-Markets-Beating-Street/dp/1786071975](https://www.amazon.co.uk/Man-All-Markets-Beating-Street/dp/1786071975)

*Tags: Strategies*

---

## 2021-08-24

**Pierino S** - *16:58:45*

Don't think he was gunning for Hugh, but he has posted recently about these tipping people with affiliate links and they get revenues irrespective if the punter wins or loses, think that's more Caan message than the Tipster per se. Because punters may not how these models work and there's a lot of punters you can see who do follow these tipsters, so if they see a winning historical record, but they can never get that price, good someone told them.

*Tags: Strategies*

---

**Michael** - *22:28:15*

Anyone work for a bookmaker making models for prices and or risk management? Whats the work like and what type of background do most have?

*Tags: Strategies*

---

**thambie1** - *22:54:45*

I'd expect StarLizard has some internal models that they are only exposing the results of to traders, making it difficult for them to leave and replicate their success

*Tags: Strategies*

---

## 2021-08-25

**Van** - *01:15:04*

Still doesn’t explain why an modeller couldn’t go and place bets.. bet placing doesn’t sound like a particularly niche job.

*Tags: Strategies*

---

**Peter** - *07:44:12*

Also, it's unlikely that there's "a modeller" who has access to the whole process. I suspect that there will be a team who manage a significant data pipeilne covering a wide spectrum of data, with all the standardisation and cleansing that goes with it. So the modeller may have insight into the features being used, but not how the data arrives to him (or her). Moreover, if there's deep neural network at the core of this, it may be a black box anyway (though in the ad earlier in this thread, there was clearly a need for solid domain knowledge).

*Tags: Feature Engineering, Strategies*

---

**Jonjonjon** - *08:32:15*

I read an article about Star Lizard a few weeks ago. In the early days, lots of employees placed their own bets, but it caused issues. I think there's now an internal syndicate that they can all join if they want to bet on the company's strategy (I might be wrong, it might be a different syndicate!).



Anyway, a lot of modelers wouldn't have the risk appetite to bet their own accounts, otherwise they would be already.

*Tags: Strategies*

---

**Dave** - *09:28:13*

This reminds me of a story about a caretaker who worked for a prestigious high-school with very competitive places. He'd offer to 'help' get your kid in if you paid him, and if your kid didn't get accepted then you got your money back. Genius.

*Tags: General Technical*

---

**Jeff Waters** - *13:50:04*

I'm not sure that you necessarily need a degree in maths. If you can self-teach, and be able to demonstrate that you know your stuff through programs you've written and your answers to interview questions, I think that would be sufficient. It might even be an advantage, as it would show initiative and a passion for the subject. However, you may find that, by the time you get to that stage, you know enough to profit from your knowledge independently (and don't need to work for someone else).

*Tags: General Technical*

---

**Crofty** - *21:46:42*

You did a fine job. Helped even more by the fact it wasn't on YouTube and you weren't saying "For more videos like this, smash that subscribe button"

*Tags: General Technical*

---

## 2021-08-26

**Jonjonjon** - *14:33:57*

Has anyone ever had problems with giving away strategies to friends to manage? I've got a very baseline strategy that I don't have time to research/manage and was thinking of giving to a novice friend to manage and explore. But unsure if the powers at Betfair would take a dim view of it in relation to premium charges

*Tags: Strategies*

---

**Michael** - *14:49:19*

If it's really vanilla (the sort of thing loads of people try) then I'd say go for it. Worst case you get caught and have to cough up some PC but really that's quite unlikely if it's a generic sort of strategy.

*Tags: Strategies*

---

## 2021-09-01

**liam** - *17:19:55*

If so I have helped pay for it :man-facepalming:

*Tags: General Technical*

---

## 2021-09-02

**Peter** - *11:21:51*

Their T&amp;Cs include the ability to gub you or close your account, however that's no indication as to how quickly they apply those actions. For me the real problem with bookmakers is the execrable odds offered for the dogs.

*Tags: General Technical*

---

**Jonjonjon** - *20:37:06*

I was getting an insurance quote from Aviva, and one of the questions asked if I was a professional footballer, entertainer, gambler or student. Why would being a professional gambler affect the premium?

*Tags: General Technical*

---

## 2021-09-03

**Mo** - *15:36:41*

I guess the problem is the number of combinations (runners). Not sure whether it's both a problem in the backend (API) and how to display it on the frontend or whether it's just a display issue that could be solved with a better user interface

*Tags: General Technical*

---

## 2021-09-05

**Dave** - *10:38:56*

Came across this which I am sure some of you guys are already acquainted with: [https://www.airtonrisk.com/](https://www.airtonrisk.com/) - pretty cool, helping sports teams/firms hedge their exposure to performance-based risks (e.g. bonus payouts etc)

*Tags: Performance*

---

**Mo** - *11:03:27*

Examples of what we worked on:



• Insurance for a William Hill promotion where you had to predict the exact final Premier League table one season

• Hedging Andy Murray's sponsors' exposure to his on court performance

• Hedging Bundesliga teams' risk of demotion

*Tags: Performance*

---

**Mo** - *11:20:56*

You have to be careful because the financial incentives can make match fixing much more attractive

*Tags: Errors Debugging*

---

**liam** - *11:34:31*

Do the company’s get paid a fixed amount / did you ever take a position? 

*Tags: Errors Debugging*

---

**Mo** - *11:39:18*

Yeah I can't think of a case where it wasn't a fixed amount. You're basically placing a bet at incredible value. For these season long positions it's pretty difficult to get on in size either on Betfair or with bookmakers so hard to hedge on that basis even if you want to. We tended to work out the potential impact of individual match results on the position and hedge in those markets

*Tags: Errors Debugging*

---

**Jonjonjon** - *23:59:50*

I'm using `systemctl` to run some of my Flumine scripts. it ends up logging a LOT to syslog, such as:



```Sep  5 22:52:38 flumineclient env[1249xxx]: WARNING:flumine.order.process:Strategy not available to create order 138501748xxxx

Sep  5 22:52:43 flumineclient env[1249xxx]: WARNING:flumine.order.process:Order 2433387xxxx not present in blotter```

What's the best way to suppress these sort of messages?

*Tags: Strategies*

---

## 2021-09-06

**Jonjonjon** - *09:07:38*

Looking through the sourcecode for flumine, I think `config.hostname` is only used for retrieving orders based on the `customer_strategy_ref`.



Would it be cleaner to rename it to `config.customer_strategy_ref`, to make this behaviour more explicit?

*Tags: Strategies*

---

**Jonjonjon** - *22:12:16*

[https://github.com/liampauling/flumine/pull/488](https://github.com/liampauling/flumine/pull/488)

*Tags: General Technical*

---

## 2021-09-07

**D C** - *08:54:17*

Yes its a fair point. I just find the whole thing a bit hypocritical to be honest. In my experience alcohol abuse and smoking cause far more harm but people can be "trusted" to make decisions for themselves in this regard. I say all this as someone who until recently had lost a lot of money gambling over the years and at times been close to developing a problem. Point is that had these restrictions been in place during some of my more problematic spells, I would simply have placed bets manually or asked others to place them on my behalf. I genuinely think it solves nothing.

*Tags: General Technical*

---

**Oliver Varney** - *09:31:39*

Yes probably why it was one of his best! Nothing like a good rant vs some professional person not answering the question you ask  Realistically we should be somewhat greatfull for him bringing in less competitive money onto the exchange through the people who watch his videos.

*Tags: General Technical*

---

**Jonjonjon** - *09:38:38*

His video's don't actually contain any info on how to bet. He just has click-bait titles, and then really vague content

*Tags: General Technical*

---

**Oliver Varney** - *09:49:20*

[@U4H19D1D2](@U4H19D1D2) developer series, from basics to advanced betting with flumine and betfairlightwight :joy:

*Tags: Strategies*

---

**Jonjonjon** - *09:50:35*

Haha. I don't think there are any actual strategy tips here. But the general tips on analysis and technology are of course invaluable.

*Tags: Strategies*

---

**Mo** - *13:14:57*

Cheers. I certainly want to get content out there, the question is what is the best way to do it. I've talked before about doing a book and doing mentoring

*Tags: General Technical*

---

## 2021-09-08

**Oliver Varney** - *15:02:30*

I have a couple of corsair k70s that are decent (I think :joy:) but they are not the cheapest. Not Bluetooth though but im sure they have a Bluetooth model

*Tags: Strategies*

---

**Jack** - *15:51:05*

Got £200 for keyboard and mouse from work so just figuring out how to use it :drooling_face:

*Tags: General Technical*

---

## 2021-09-09

**Jonjonjon** - *09:44:27*

I finally implemented it. It fixed my disk space issue. Thanks Liam!

*Tags: Errors Debugging*

---

## 2021-09-10

**Unknown** - *15:36:31*

Question for tennis traders.



Emma Raducanu is currently odds on to win the US Open.



A lot of money was previously traded on her at very high prices. Was it the case that the market was accurate when she was trading at around 100, given what was known at the time, or did the data suggest that her chances were far better than the market had thought?

*Tags: Strategies*

---

**Tosin** - *22:56:13*

Inspired by flumine, but wanting to go for a low latency approach. I developed(still developing) this: [https://github.com/tosinalagbe/hedg](https://github.com/tosinalagbe/hedg) . If anyone is interested in this approach and knows a bit of C++ , please do chack it out. Would love to see

it tested by anyone other than me. [https://github.com/tosinalagbe/hedg](https://github.com/tosinalagbe/hedg)

*Tags: Performance*

---

**thambie1** - *23:01:17*

What magnitude of latency are you aiming for?

*Tags: Performance*

---

## 2021-09-11

**Aaron Smith** - *10:41:10*

yesterday when changing the market filter from market_filter to streaming_market_filter, somehow the AUS markets managed to find their way in. For all of the ppl on AUS greyhounds, your welcome for that easy cash, i hope you pay me back some time :smile:

*Tags: General Technical*

---

**Aaron Smith** - *10:41:37*

on that note, whats wrong with:

```filter=betfairlightweight.filters.streaming_market_filter(

    event_type_ids=[4339, ],

    country_codes=['GB', 'IE'],

),```

?

*Tags: General Technical*

---

**Aaron Smith** - *10:47:07*

oh okay, however it managed to only grab the greyhounds at least, so i should probably fix it, but its unlikely to be the solution to how AUS made it through that filter

*Tags: Errors Debugging*

---

**thambie1** - *12:57:10*

Sounds like rapid json is pretty slow. Single digit microsecond is definitely possible, just a question of if it's worth the effort

*Tags: Performance*

---

**Tosin** - *13:37:02*

I went with the simdjson library and  rough timing shows single digit micro-second latency on average except for occasional jitter that can go to 3 digits

*Tags: Performance*

---

**thambie1** - *17:28:57*

I got an ERROR_IN_MATCHER error for the first time, other than that, not seeing anything

*Tags: Getting Started, Errors Debugging*

---

**thambie1** - *17:36:09*

Possibly. I shudder to think how bad things must be if their matching engine is throwing errors

*Tags: Errors Debugging*

---

**Mo** - *17:53:20*

Tenacity. The Python package not the character trait

*Tags: General Technical*

---

**birchy** - *21:49:35*

I recently started a new strategy that revolves around how I perceive something might happen within the matching engine. I better check my logs. :flushed:

*Tags: Strategies*

---

## 2021-09-12

**Jonjonjon** - *23:25:23*

What is the recommended way to stop a flumine application? In particular if I want to pull all orders before allowing the process to terminate?

*Tags: General Technical*

---

## 2021-09-13

**liam** - *06:35:37*

Poison pill [https://github.com/liampauling/flumine/blob/master/examples/workers/terminate.py|https://github.com/liampauling/flumine/blob/master/examples/workers/terminate.py](https://github.com/liampauling/flumine/blob/master/examples/workers/terminate.py|https://github.com/liampauling/flumine/blob/master/examples/workers/terminate.py)

*Tags: General Technical*

---

**Mo** - *07:45:33*

We declined to get involved because:



1. Going to be hard to beat courtsiders

2. Modelling the impact of weather is a nightmare

*Tags: Strategies*

---

**Mo** - *07:46:14*

However the volumes (for T20) are very compelling and modelling it is certainly intellectual stimulating

*Tags: Strategies*

---

**D C** - *10:17:26*

I love cricket and use to play it a lot but T20 doesn't hold my interest as a spectacle but I see the appeal of it from trading perspectives. I used to bet a lot on test matches but based on knowledge, not analytics. For me I would not know where to start modelling it properly as it is essentially more about bowler versus batsman matchups and that in itself holds a lot of variation. It is something I would love to get into though but you have to be wary of the match fixing element - you see some terrible examples at times but I suppose no worse than in tennis.

*Tags: Errors Debugging, Strategies*

---

**D C** - *10:20:30*

As for pitch conditions [@U01LD279D16](@U01LD279D16) that is quite a subjective thing and does it really factor that much in a game that lasts 3 hours? Genuine question as I don't enjoy/watch T20 but in a test match pitch condition is crucial for the first day but you even see some of the former professional players have varying opinions on these things.

*Tags: General Technical*

---

**liam** - *10:44:27*

The low latency feed betfair are looking to supply is an estimated 3s delay so not quite 'low latency', my understanding is that a lot of the feeds come from guys on the ground via phone (similar to racing with facetime)

*Tags: Performance*

---

**M F** - *11:20:07*

[@ULDAVFDRP](@ULDAVFDRP) i am a cricket person. i trade on cricket (specifically t20s) for a living. i have never traded any other sport but just to let you know t20 markets are very tough to crack (compared to test matches and ODIs anyway) but it can be worth your time.

as for models you can scrape data online and create a base model (which doesn't include pitch information but this is unlikely to do well). pitch conditions - even in the shortest format have a huge impact on the outcome. i have been gathering pitch data by hand over the last 5 years so i have enough data to model the pitch conditions. but i dont think you can easily obtain this info anywhere.

my 2 cents - its probably worth it but it will require a lot of work. test matches are significantly easier than t20s. happy to chat more about this if youd like

*Tags: Strategies*

---

**Van** - *14:10:45*

How did people’s models go for Djoko / Medvedev?

*Tags: Strategies*

---

**Van** - *14:14:00*

I would like to see you scale this model

*Tags: Strategies*

---

## 2021-09-14

**Jonjonjon** - *22:08:33*

Are you much of a Poker player? I keep dabbling with rules-based approaches, with dice to help mix things up. I've yet to become successful.

*Tags: General Technical*

---

## 2021-09-17

**Oliver Varney** - *13:07:48*

are we doing a pre xmas bflw meetup this year? Just thinking if people are keen then maybe best to get the word out super early this time.

*Tags: General Technical*

---

## 2021-09-21

**Oliver Varney** - *08:34:19*

Well the tricky part is trust right, but im sure there are many people on here who could stake someone if there model was half decent and they didnt have the same PC restrictions

*Tags: Strategies*

---

**Oliver Varney** - *08:36:38*

im not fully aware of the ins and outs, I was more thinking about is there a world whereby you could stake / help new starters with tiny banks and get a cut as a return

*Tags: General Technical*

---

**charlie_v** - *09:38:23*

On the footie facebook group I'm an admin on have a poor bloke just posted who has been limited to £100 a month deposit, he made some losses last few months but is a matchbetter, how frustrating, I am sure it will get resolved but must be so frustrating.

*Tags: General Technical*

---

## 2021-09-23

**Oliver Varney** - *12:11:21*

cool interesting, I guess at that point python mirrors the syntax of statically typed languages

*Tags: General Technical*

---

**Dave** - *22:16:19*

typing is also helpful if you like to compile your functions with numba for example

*Tags: General Technical*

---

## 2021-09-27

**Michael** - *13:18:22*

Obviously how you feel about it depends on what your overall position is in terms of finances, family and so on but if you're being sensible and putting money aside so that you could cover a gap without income then I think you can dial your worrying right down because the reality is that you will always get through. It might take longer to get a job or you might have to do something you don't love for a bit whilst you re-establish yourself but you'll get through. None of us is  watching the Taliban tighten the noose or trying to cross the channel on a lilo.



When I occasionally expressed anxiety about this sort of thing to my friends in the past they used to laugh at me because from where they were sitting it was obvious that I'd be fine. It's always obvious that other people will be fine it just never feels that way.



I don't know if it's really a good idea for you to quit your job if I'm honest - just because your record of making profits is relatively short. However you do decide to do that you could explain to your employer that you just don't need a job, offer a very long notice period, help your successor with the transition and maybe even provide a little help after you've left so that you're on the best possible terms should you need to go back.

*Tags: General Technical*

---

**Oliver Varney** - *13:24:09*

[@UGV299K6H](@UGV299K6H) I feel its a hard conversation to get away from especially with friends, kinda feel like im constantly repeating myself and boring them to death (as well as myself at the same time) yet they still keep asking questions.

*Tags: General Technical*

---

## 2021-09-28

**liam** - *11:46:00*

I have kept a job going from a risk point of view, having an income stops the questions coming from HMRC / student loan / cv gap etc, as Jon has mentioned you can funnel it into a pension, get the perks (healthcare etc) and remove the headache of mortgages

*Tags: General Technical*

---

**liam** - *12:28:06*

For context this was actually before I wrote bflw

*Tags: General Technical*

---

**liam** - *12:29:29*

The team I currently work for is crying out for some real world experience in python / sql / analytics as opposed to tutorial newbies  

*Tags: General Technical*

---

## 2021-09-29

**Jonjonjon** - *22:49:42*

What process did you use for the selection? I'm unsure of how to choose a fund, but am considering something from here: [https://www.wealthclub.co.uk/seis-investments/](https://www.wealthclub.co.uk/seis-investments/)

*Tags: General Technical*

---

## 2021-10-03

**Oliver Varney** - *09:36:14*

ah crap didnt realise you have been covering it, in my head for some reason I just thought as there was enough of us it was just to let them know to reserve space.  Certainly happy to help put some monies towards this time ( and buy you beer all night for the previous times)

*Tags: General Technical*

---

## 2021-10-04

**Alex A** - *05:29:51*

I don’t use flumine, but I always use the timestamp on the most recent message I received from BetFair as the current time, so all my logic around comparing times should be the same in a backtest as it is live.

*Tags: Deployment*

---

**liam** - *13:53:36*

I can help with layering income to prevent questions on deposits but haven't heard of anyone recently getting a mortgage from income

*Tags: General Technical*

---

## 2021-10-10

**Aaron Smith** - *17:15:31*

is this more for a mathematical question or practical use?

*Tags: General Technical*

---

**Jonjonjon** - *17:37:56*

I was looking at genetic algos but can't seem to find a well maintained Python library for it.

*Tags: General Technical*

---

**Jonjonjon** - *20:31:17*

In essence,  have a dataframe of 3 columns:



• forecasted return

• actual return

• market variable (e.g. time, volume, volatiliy etc...)

My strategy enters a trade if the forecasted return is greater than some threshold.



That threshold is a function of the market variable.



I'm trying to fit a piecewise linear function to the threshold.



So the dimensions are the knots on the piecewise linear function.

*Tags: Feature Engineering, Strategies*

---

## 2021-10-11

**Disco** - *09:17:04*

Hello. Have a question, unrelated to bf, as there are people experoenced in IT industry: is it common for for non-uk/non-eu citizens to work for uk/irish companies remotely as a developer/QA on permanent/long contract basis? I've been working in data warehousing and etl/elt for the past 3 years (1 year fully remote) and wondering if there is any demand as pandemic made employers switch a lot of workers to remote/wfh, but maybe it's not an option for foreigners.

*Tags: General Technical*

---

**Jonjonjon** - *09:53:40*

[@U01PQ9SR9MJ](@U01PQ9SR9MJ)  thanks for the suggestion but I am too old to try new software. And I don't have a Windows machine. I'd prefer to stick to Python.

*Tags: General Technical*

---

**Finn** - *09:58:01*

[@UPMUFSGCR](@UPMUFSGCR) have you looked into this? [https://github.com/fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization) I used to use it to tune hyperparameters, not sure if its a good fit for your purpose.

*Tags: Performance, Strategies*

---

**Peter** - *11:26:03*

[@UPMUFSGCR](@UPMUFSGCR) As the approach recommended by [@U01PQ9SR9MJ](@U01PQ9SR9MJ) doesn't appeal ("Windows", "defunct", "30d trial") you may be interested to know that you can do the same in python using scipy. There's a particularly good [https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python|stackoverflow post](https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python|stackoverflow post).

*Tags: General Technical*

---

## 2021-10-14

**Paul** - *20:26:52*

I know my employer (which is a FAANG), will pay to relocate the right people and happily put them through visa sponsorship, but the problem with out-of-country remote is tax and legal (specifically intellectual property) stuff. That seems common to all the FAANGs. Smaller companies might be more flexible, and [http://remoteok.io|remoteok.io](http://remoteok.io|remoteok.io) has worked for me in the past when I wanted to WFH back in 2018.

*Tags: General Technical*

---

## 2021-10-15

**Van** - *06:14:52*

Well, I’m thinking solo project.. not even a trading bot but any solo project..

*Tags: Strategies*

---

**Paul** - *06:18:27*

Yeah, some people find it's really helpful, others less so. I can be lazy but if I get the one major task done then I can feel I've got something important done and slack off a bit if I want/need. I know others would prefer to have a strong design doc and backlog, and then push through. I do that for my day job, but at the weekend? When I'm not quite sure what is possible and I'm learning? Not for me.

*Tags: General Technical*

---

**Jack B** - *10:35:50*

How have people setup their network security when running on AWS? Public/Private subnets, ssh tunnels etc?

*Tags: Getting Started, Deployment*

---

**Jack B** - *12:58:41*

Security Group - [https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html)

*Tags: Deployment*

---

## 2021-10-16

**Paul** - *08:05:40*

For example, you might start with “identify a profitable trading strategy for horse racing markets 2 minutes before official start time” (which is tough enough already). To do that you will need to:

• Download historical data

• Understand it, perhaps do some cleaning and so on

• Get it into a format that you can use for your strategy building

• Run some tests

• Visualise the test results

…

*Tags: Data Quality, Strategies*

---

## 2021-10-17

**Oliver Varney** - *08:49:50*

Morning, im looking for some advice on hosting platforms, mainly AWS vs the rest. I am just about to start re-writing some of my services and was just wondering what peoples thoughts are on the best way to go. From what I understand if I go with AWS (rather then something like linode) im getting a large product/ feature set but in return paying higher costs and potentially slightly slower performance (from what ive read thus far). Is there any specific things around AWS and Betfair/betting that are also advantages of using it. From my understanding betfair are hosted on AWS? im pritty clueless when it comes to this stuff so would be interested in the techy guys thoughts.

*Tags: Feature Engineering, Performance, Deployment, Strategies*

---

**Mo** - *09:36:28*

Betfair aren’t in AWS

*Tags: Deployment*

---

**Mo** - *09:37:59*

AWS Dublin is close to the Betfair servers but it doesn’t help with the way their infrastructure is currently set up 

*Tags: Deployment*

---

**Mo** - *09:48:03*

AWS maybe has an advantage in the number of users we have here that have experience with it. I’m sure there are more cost effective options out there but personally I’m too invested in AWS already and I don’t think they have the same track record (a few days ago there was a global Azure outage). Cheaper and better drop in replacements for AWS services would be ideal. Someone mentioned Cloudflare R2 recently which is supposed to do this for AWS S3

*Tags: Deployment*

---

**liam** - *11:52:56*

AWS isn’t the cheapest compared to some other providers but it has everything 

*Tags: Deployment*

---

**Paul** - *13:24:38*

Disclaimer: I work for AWS, but do not speak for them here in an official capacity. Customers tend to think it's expensive but reserved instances, spot instance if you're able to use them, moving to Lambda if you can (so not paying for idle), can all cut costs.

*Tags: Deployment*

---

## 2021-10-18

**Oliver Varney** - *06:20:07*

cool cheers mo Ill take a look. Secondly and kind of on the same note but has anyone attempted to represent the Available class in the cache as a numpy array (1, len(number_of_ticks) with size being represent at an predefined index?

*Tags: General Technical*

---

**Mo** - *06:28:28*

What do you do for AWS if you don't mind sharing?

*Tags: Deployment*

---

## 2021-10-19

**liam** - *10:47:15*

Are you not seeing the fact the suspensions is based on the feeds rather than the latency? The edge is in the angle when it comes to the drones

*Tags: Performance*

---

**Oliver Varney** - *11:00:27*

Imo, There would have to be a latency advantage over TPD (maybe fairly large as well) as processing images into a useful representation will take some time assuming you can correct for visual effects. I guess we will never know without getting the feed. Maybe betfair can add it into their available feeds :grinning:

*Tags: Performance*

---

## 2021-10-25

**Unknown** - *10:58:12*

[@ULDAVFDRP](@ULDAVFDRP) No I dont think TPD are at Wexford - [https://betfairlightweight.slack.com/files/UQL0QDEKA/F019FC7CUSE/tpd_faqs.pdf](https://betfairlightweight.slack.com/files/UQL0QDEKA/F019FC7CUSE/tpd_faqs.pdf)

Ive just re played that race and you can see in image 1 (a couple of seconds before) and image 2 the point Filon touched 1.01

I layed the wrong one in that race :grinning:

*Tags: General Technical*

---

**Oliver Varney** - *11:02:22*

Is that a database that is visualising that or something else?

*Tags: General Technical*

---

**PeterLe** - *11:03:58*

No its my own stuff Oliver,I use Flumine too

*Tags: Deployment*

---

## 2021-10-26

**Paul** - *13:15:56*

“Yes minister, the French have done this, but look at all the progress on problem gambling that would be reversed if we did the same”. End of discussion for a decade. IMO, natch.

*Tags: General Technical*

---

## 2021-10-27

**Oliver Varney** - *13:20:20*

I guess one question in my mind is that are you just going to give too much information away for little volume that might signal your making moves in the WIN market also

*Tags: General Technical*

---

## 2021-10-28

**Amanda** - *10:23:10*

Bookmakers want you to lose, they’re conmen, they’re coming along to find out how to get more money for their company. 

*Tags: General Technical*

---

**Daniel** - *15:53:58*

Thanks [@UFTBRB3F1](@UFTBRB3F1). The site has had a few major changes in the last few months and one of these was the addition of the API. The front end back side now looks more like a sportsbook but with exchange functionality. The API documentation is available if you wanted to review.

*Tags: General Technical*

---

**Paul** - *23:26:58*

Very much enjoyed this evening. Big thanks to [@UBS7QANF3](@UBS7QANF3) for organising, lots of thoughts pinging in my head. Also, enjoyed my chats with Betconnect and Betfair people present - found that I didn't want to spray them with holy water or drive a stake in their hearts as they were mostly interested in how to make our lives easier. Great stuff.

*Tags: Deployment*

---

## 2021-11-01

**Mick** - *12:43:06*

Roughly you could say that most horse races are run at a comfortable pace with all the horses clustered together, then when they reach the last couple of furlongs they will sprint for the line and only then do the gaps between horses open up. Occasionally however, races are run where one or two horses will apply pressure much earlier on and the race will become strung out and the final gaps between horses will end up much larger than would normally be the case. What I want to do is be able to determine how strung out a race was early on, from historical data. I dare say it may be revealed by sectional times but they are only available for a few racecourses. So is there some other clue in data I could download/scrape/purchase? Perhaps in-running odds at the half way point?

*Tags: Data Quality*

---

**Mick** - *13:36:01*

I am wanting this early pace measure to help determine how much significance to place on the gaps between the horses at the finish. So a win by X lengths in a normal jog-then-sprint race should be seen as more impressive than a win by X lengths in a fast-all-the-way race.

*Tags: General Technical*

---

**Michael** - *13:36:48*

Are you looking to use this in some kind of fundamentals pre-off model?

*Tags: Strategies*

---

**Oliver Varney** - *13:47:10*

A performance on a given day probably cant be boiled down to one attribute. Youve got weight carried, going + actual going, jockeys, weight allowances, interference all sorts really. I think you will end up creating a feature that is way too specific and wont generalise. Furthermore if a horse cant place the jockey will walk the horse over the line and distances then can be misleading. What I will say is in-play odds can be used to determine how well a horse has run, even if it hasnt won.

*Tags: Feature Engineering, Performance*

---

**Oliver Varney** - *13:59:03*

I just think its way to complex to model and get anything trustworthy out of. As I suggested in the second message, using the odds relative to a benchmark / entry point probably the route to go.

*Tags: Strategies*

---

## 2021-11-07

**D C** - *19:30:35*

yeah. I believe that the clocks change in US today (yesterday) too which may be related. Clutching at straws but I had issues with the feed last night for US too

*Tags: Deployment*

---

## 2021-11-08

**river_shah** - *07:16:24*

anyone ever use [https://numba.pydata.org/|numba](https://numba.pydata.org/|numba) for the kind of model building we would use? I have always had julia envy. seems like numba is a good middle round

*Tags: Strategies*

---

## 2021-11-09

**Paul** - *07:37:59*

I'm looking for a derivative of kelly that takes into account multiple existing bets and price movement. All I can find are linear programming solutions, or "wind everything back to all green/red and start again". Anything I should be looking at/reading?

*Tags: Strategies*

---

## 2021-11-15

**liam** - *12:53:55*

Yeah I can’t see a manual edge here, it very much suits automation / modelling 

*Tags: Strategies*

---

**Mo** - *16:58:45*

I don't know but did you see this thread? [https://betfairlightweight.slack.com/archives/C02J4CBA0H5/p1634896059330300](https://betfairlightweight.slack.com/archives/C02J4CBA0H5/p1634896059330300)

*Tags: General Technical*

---

**D C** - *22:05:02*

Thanks Mo. Going forward it is not a problem for me but for quite a while I was polling listCurrentOrders before finally implementing order stream - hence the question to try and slightly improve the accuracy of the timestamps I have historically.

*Tags: General Technical*

---

## 2021-11-16

**Jonjonjon** - *09:51:11*

Will BFLW ever use the asyncio library? Or will  the simplicity of single threaded execution be preferred?

*Tags: General Technical*

---

**Jonjonjon** - *14:23:15*

Only th Bitfinex python api at the moment. Have not looked at it in 6 months though. Too focused on Betfair!:grinning:

*Tags: General Technical*

---

## 2021-11-17

**Mick** - *10:59:14*

I have been working on a website [http://sprintratings.com|sprintratings.com](http://sprintratings.com|sprintratings.com) which displays my horse ratings. The ratings are significantly more accurate (i.e. correlate better with finishing position) than the Racing Post ratings (RPR). The site also displays the history of each horse's past performance in a rather unique way which I hope people will find useful. This site is not open to the general public yet but it is running with updates every day so I can give the automated systems a good workout. The site has a simple username and password of "horse"/"123". I am looking for general feedback both on the website and the individual ratings themselves. If you prefer to give feedback directly to me, please email [mailto:michael@sprintintelligence.com|michael@sprintintelligence.com](mailto:michael@sprintintelligence.com|michael@sprintintelligence.com)

*Tags: Performance*

---

**Peter C** - *11:22:53*

I had a look, found the site easy enough to use and navigate, and thought you had the basis of quite a professional presentation. However I found the disparity between the rating given to a horse and the odds you display confusing. What does the rating actually mean, and where are you getting the odds, or are these your calculated odds? The other immediate question I had is if the ratings are so good why aren't you using them for your own betting? I'm sure I'm not your target audience; I don't frequent horse rating websites (in fact yours is the first I've ever visited) so perhaps the questions/feelings I have won't be universal, and I just don't understand the jist of these websites. Thanks for sharing though - you're braver than me putting yourself out there like that.

*Tags: Strategies*

---

## 2021-11-19

**D C** - *10:28:35*

The content is OK but his conclusions are off. Basically if you are profitable its just survivorship bias seems to be his opinion. I found a few useful things in one of his books when I needed to acquaint myself with some elements of the bookie industry though. I have this new one on my amazon wishlist but this is mainly just because there are so few books about gambling and sports modelling in general so I will give most things a try.

*Tags: Strategies*

---

## 2021-11-21

**Unknown** - *20:17:22*

Has anything changed with GB Greyhounds in the last few days? A formerly consisten strategy has fallen off a cliff.

*Tags: Strategies*

---

**Jonjonjon** - *20:21:17*

Sorry to hear that? How are you planning on adjusting? I'm going to scale back my stuff massively. The problem is that I have lots of legacy bots that I leave running in the background (this is one of them), and I can't remember a lot of stuff about it.

*Tags: General Technical*

---

**Jonjonjon** - *20:32:05*

I haven't touched the code on that in several months. And don't really have the tools to answer the rest of the questions... :disappointed:

*Tags: General Technical*

---

**bb** - *20:53:14*

Yeah no changes my end to the code, matching rates have dropped a fair amount but all modelling metrics have stayed within expected bounds 

*Tags: Strategies*

---

## 2021-11-24

**Jonjonjon** - *10:37:16*

I'm trying to understand the Flumine codebase better... What the benefits of wrapping the orders into the Transaction objects?

*Tags: General Technical*

---

**Jonjonjon** - *10:39:10*

[@UEA14GBRR](@UEA14GBRR) do you have a similar chart for US racing? My strategy died for that too. For some reason it might have been OK for higher prices runners. I'm a bit confused why short prices should have thrown it off so badly.

*Tags: Strategies*

---

**liam** - *10:42:11*

you read the [https://github.com/liampauling/flumine/blob/6216bcc233326cf07852fca9c7d39a18cee265ad/flumine/execution/transaction.py#L12|code](https://github.com/liampauling/flumine/blob/6216bcc233326cf07852fca9c7d39a18cee265ad/flumine/execution/transaction.py#L12|code) comments?

*Tags: General Technical*

---

## 2021-11-26

**Mo** - *11:23:32*

I've been having that error for months if not years but haven't investigated

*Tags: Errors Debugging*

---

## 2021-11-30

**Jonjonjon** - *22:52:06*

I'm not sure it would be that economical.



I paid about £600 for a Dell T7500 with dual X5675 Xeons a few years ago. That's 12 physical cores.



A year ago, I paid £1,600 for a PC with an AMD 3950X CPU. That's 16 physical cores.



Using [https://www.cpubenchmark.net/cpu.php?cpu=Intel+Xeon+X5675+@+3.07GHz&amp;id=1309&amp;cpuCount=2|passmark](https://www.cpubenchmark.net/cpu.php?cpu=Intel+Xeon+X5675+@+3.07GHz&amp;id=1309&amp;cpuCount=2|passmark) as a crude measure.... The X5675 has 11,616



The 3950x has 39,170.



So I paid 19.36 per passmark on the old Dell.

24.48 per passmark on the more modern machine. Passmark is a crude benchmark. But in terms of running Flumine backtesting on multiple cores, the modern machine is 2.5-3 times faster. So both machines had comparable bang per buck.



However, the older Dell runs into heating issues and I can't run it for a long time before it thermal throttles. It's a tangle of cables in there, so I'm not confident of repasting the CPU.

*Tags: General Technical*

---

**Jonjonjon** - *23:03:01*

Yes. Please also be aware that if you have more cores, you need the RAM to use them. And performance gains don't scale linearly with number of cores (they scale less), due to shared hard drive and memory bandwidth.

*Tags: Performance*

---

## 2021-12-01

**Michael** - *08:14:51*

I'd have to say that my experience with HP workstations has been quite different. One of the reasons that I like them is that they're so well put together and I've never had problems with cooling even if I max them out for hours at a time, the quality of the cases is way beyond normal consumer equipment and I've never had a problem with a power supply, fan or anything like that. I should stress that I'm talking about high end used hardware though, the sort of things that come out of professional video studios or labs, so they're made to be reliable.

*Tags: General Technical*

---

**D C** - *09:52:51*

I've been routinely using the API to obtain all my bet records on the horses since April this year. Before that just have monthly per market stuff. Not sure what the time interval on these things is but I can still query results at a market level (not bet level) per strategy reference going back a year (not tried beyond that).

*Tags: Strategies*

---

**D C** - *09:56:13*

I don't use bflw but I assume that it has support for listClearedOrders (what I use). If not and if it would be useful to you I can give you the script

*Tags: General Technical*

---

**birchy** - *13:13:40*

With ref to the earlier chat about getting bet histories, I seem to have some distant memory that `listClearedOrders` can retrieve bets way beyond the 90 days that the documentation suggests? And IIRC, it's about 2 or 3 years?? Can anyone confirm?

*Tags: Performance*

---

**Newbie99** - *16:28:39*

Sort of on this subject, there are some scenarios that come up and I'm curious how other people go about this:



1. Orders don't appear to settle properly at market level. So this appears to result in the orders settling correctly at bet level when the market closes, but when calling listClearedOrders at the market level it doesn't exist (this normally appears to get fixed after a couple of days, but it occasionally does drag on longer).

2. A market gets settled, all appears to be correct, but then Betfair re-settle at a later date.

Both are fairly uncommon, but do occur occasionally, I'm just wondering if there is any way to detect if a market is re-settled, or is it simply a case of calling listClearedOrders periodically and doing a lookback (and presumably taking settled bets with the most recently settled time if a bet with the same id already exists in my DB)?



I'm guessing it is the latter, but just wanted to be sure.

*Tags: Errors Debugging*

---

## 2021-12-03

**liam** - *11:55:16*

agreed but I would hire someone who has some real work experience in data/programming/problem solving when compared to a tutorial zombie regardless of the domain, finding the former is very difficult

*Tags: General Technical*

---

## 2021-12-04

**Mo** - *15:33:03*

I find participating in their hackathons to be an effective strategy

*Tags: Strategies*

---

## 2021-12-05

**Aaron Smith** - *15:48:45*

Hi ppl, today i ll hit you with some (potentially dumb) tech-noob questions.

Suppose i have 2 vCPUs. Am i right in the assumption that this is somewhat simular to having 2 cores? If so, does that mean python would only use one vCPU? If i had 2 different instances of flumine running, would it automatically allocate those to the 2 different vCPUs?

*Tags: General Technical*

---

**Aaron Smith** - *15:54:48*

from "sort of" can i deduce that i dont have to worry about it? would it make any difference if i had for example 1 flumine instance running 4 strategies or 2 flumine instances running 2 strategies each in terms of how efficient the cpu is used?

*Tags: General Technical*

---

**Mo** - *15:56:52*

Essentially there is a good deal of randomisation. Yes you'll get the benefit of both processes running in parallel but they won't be fixed to a particular vCPU (unless you configure it that way yourself) and the CPUs will be shared with everything else running on the machine

*Tags: Errors Debugging*

---

**Mo** - *15:58:01*

I can't speak too much to the design of flumine but as I understand it you'll need to run two instances to get the benefit of the two vCPUs, it's not enough to run two strategies in one instance

*Tags: General Technical*

---

**KG** - *22:50:31*

I can help in Aus, not so much UK sorry gang! :confused: gotta love merch though :ok_hand:

*Tags: General Technical*

---

## 2021-12-06

**Atho55** - *14:29:03*

[@UBS7QANF3](@UBS7QANF3) The book looks to refer to the same model type I used in your footy comp without the MC element I bolted on

*Tags: Strategies*

---

**C0rnyFlak3s** - *21:00:52*

I was wondering which approach you guys use, to extract goal scored information from the market streams. Do you check how to correct score market reacts or do you extract the information from the over/under markets?

*Tags: General Technical*

---

**James T** - *21:31:09*

There's an unofficial API which provides scores for the Betfair website. Can't remember the url off the top of my head. I recall that there is an example in the bflw library. 



For backtesting I just use the same code as I would in live. Decipher the score from correct score, O/U and score API. 

*Tags: Deployment*

---

**Aaron Smith** - *21:51:07*

[@USYQKE5HN](@USYQKE5HN) using flumine and it stopped you from placing more bets over transaction limit?

*Tags: General Technical*

---

**James T** - *21:52:08*

I don't actually use flumine myself. I have my own platform written in C#. 

*Tags: General Technical*

---

**James T** - *21:52:41*

If I were on Python I probably would be using flumine though!

*Tags: General Technical*

---

## 2021-12-11

**birchy** - *14:37:52*

Must confess that I'm not an Apple fan either (unless used for making cider, which I used to do, but that's a whole different story), but am tempted to treat myself to an M1. But at ~£1K, I can't help wondering if a Dell XPS or something else with an i7 cpu would offer better VFM. Obviously I'd be installing Linux rather than Windows.

*Tags: Getting Started*

---

**Oliver Varney** - *14:46:09*

Problem with the Intel cpus is efficiency. Apple is one generation ahead in terms of processing node. Kinda feed up of doing simple tasks and battery being at zero too fast

*Tags: General Technical*

---

**Oliver Varney** - *15:00:20*

Very high memory requirements in terms of models here unfortunately

*Tags: Performance, Strategies*

---

**birchy** - *16:17:04*

Anyone here ever been locked out of an AWS VPS instance? In my case, it's a Lightsail instance, which is basically an idiot's version of EC2. Can't login via SSH from any of my machines OR from the AWS management web page/console. Tried to reboot from AWS console but it failed. Ended up having to "stop" the instance from AWS but that also hung for a good 10+ minutes. Have been using this server for 6+ months and not had anything like it happen before.

*Tags: Errors Debugging, Deployment*

---

**Aaron Smith** - *16:27:39*

[@U016TGY3676](@U016TGY3676) few days ago my ec2 instance would only pass 1/2 status checks and i was unable to do anything with it. Probably there is some smart solution i didnt find, i ended up terminating and remaking it :smile:

*Tags: Deployment*

---

**Beeblebrox** - *20:00:16*

[@U016TGY3676](@U016TGY3676) I had something similar today, in my case it was because I was maxing out the cpu.  It had been fine for months, but I started running an extra flumine instance with a new strategy a couple of days ago and it couldn't cope.



My Lightsail instance was Windows (yes, yes I know! I just used that as I'm more used to Windows), but I'm going to try setting up some Unix EC2 instances instead.  As a novice Unix user has anyone got a guide on things like which flavour of Unix to use, which instance types to use (I'm thinking t3.micro), how to install Python, Git, etc, and any other tips?  I'm sure I can work it out myself, but any guidance would be appreciated.

*Tags: Getting Started, Deployment, Strategies*

---

**Mo** - *20:36:58*

Recommend Ubuntu. Should come with Python, Git etc already installed. 

*Tags: Getting Started*

---

**birchy** - *21:59:18*

Or you can just open multiple terminals on your client/local machine and SSH into the AWS instance from each.

*Tags: Deployment*

---

## 2021-12-12

**Peter** - *07:15:07*

How did you manage that without getting a subscription limit exceeded error?

*Tags: Errors Debugging*

---

**Mo** - *13:42:09*

Thanks for sharing, this was great. First time listening to this podcast. I like the format where the host is providing commentary interleaved with the guests' answers.



My top take aways:



1. There was an interesting discussion about Betfair's price ladder and how it proved an advantage over Flutter in the early days which is highly relevant to a question I posed in the Betfair AMA ([https://betfairlightweight.slack.com/archives/C02J4CBA0H5/p1635194249356600](https://betfairlightweight.slack.com/archives/C02J4CBA0H5/p1635194249356600))

2. The host mentioned the importance of being bored for coming up with creative ideas. I tend to do my best to avoid being bored but maybe this is something to try

*Tags: Getting Started*

---

## 2021-12-15

**Oliver Varney** - *09:45:27*

Anyone know of better options office options on linux then libreoffice (calc) to tinker with formulas (other then python stuff like pandas)? Man it crashes constantly ..

*Tags: Feature Engineering*

---

**D C** - *11:49:35*

On the topic of AWS or other cloud approaches, what do people consider the main benefits? What does it give you over a good old fashioned server hire other than (presumably) lower cost. I've been working on dockerising my stuff ready for AWS deployment and reading about various types. There is a bewildering array of options but cost aside, the only reason I will be going down this route is more reliable internet connectivity but I could get that getting a dedicated server hire (although admittedly more expensive). I must be missing something because I can't see the allure of AWS other than improved connection reliability. Can someone educate me?

*Tags: Deployment*

---

**Paul** - *11:58:30*

The high-level benefits (beyond reliability), are briefly touched on here: [https://aws.amazon.com/what-is-aws/|https://aws.amazon.com/what-is-aws/](https://aws.amazon.com/what-is-aws/|https://aws.amazon.com/what-is-aws/)

*Tags: Deployment*

---

**liam** - *11:59:12*

For me its about having everything in one place and a nice simple terraform file, ec2/ecs/rds/s3/cloudwatch

*Tags: Deployment*

---

**Mo** - *13:10:39*

Yes. Need an extra server? You can have one in seconds, no contract to sign, no need to wait for your hosting provider to provision it or - God forbid - order the hardware. And there are all kinds of niche configurations available e.g. GPU or FPGA instances. If you want to relocate your infrastructure half way around the world, you can do it in seconds. You can scale down just as easily as scaling up. You're not tied into a contract or stuck with last gen hardware. And these are the benefits of just the EC2 product

*Tags: Deployment*

---

**birchy** - *13:14:51*

I'm a bit of a simpleton and simply use S3 for storage and Lightsail for deployment, which is nothing beyond `python3 launchbots.py &amp;` :man-shrugging:

*Tags: Deployment*

---

**John** - *22:18:48*

Yeah, this is a brilliant podcast! Got me interested in cyber warfair. And I ended up with this one lately [https://www.amazon.co.uk/This-They-Tell-World-Ends/dp/B08WBSNV1R/ref=sr_1_1?crid=1O49TOE6LGL7N&amp;keywords=this+is+how+they+tell+me+the+world+ends&amp;qid=1639606533&amp;sprefix=this+is+how%2Caps%2C732&amp;sr=8-1|https://www.amazon.co.uk/This-They-Tell-World-Ends/dp/B08WBSNV1R/ref=sr_1_1?crid=1O49[…]d+ends&amp;qid=1639606533&amp;sprefix=this+is+how%2Caps%2C732&amp;sr=8-1](https://www.amazon.co.uk/This-They-Tell-World-Ends/dp/B08WBSNV1R/ref=sr_1_1?crid=1O49TOE6LGL7N&amp;keywords=this+is+how+they+tell+me+the+world+ends&amp;qid=1639606533&amp;sprefix=this+is+how%2Caps%2C732&amp;sr=8-1|https://www.amazon.co.uk/This-They-Tell-World-Ends/dp/B08WBSNV1R/ref=sr_1_1?crid=1O49[…]d+ends&amp;qid=1639606533&amp;sprefix=this+is+how%2Caps%2C732&amp;sr=8-1)

*Tags: Errors Debugging*

---

## 2021-12-17

**Mo** - *09:15:03*

Or that have a lot of Bitcoin on the books like MicroStrategy (MSTR)

*Tags: Strategies*

---

## 2021-12-19

**Ruben** - *10:23:14*

I'm thinking about using cloudwatch to start monitoring logs as opposed to logging into my EC2 instance and using grep like a maniac. Anyone here using it? What do you guys use to monitor logs?

*Tags: Deployment*

---

**Ruben** - *10:31:46*

cool, thanks liam. Ideally I'd be able to point it to the log file that flumine generates and use that to monitor types of errors and stuff. will look into it

*Tags: Errors Debugging*

---

## 2021-12-20

**charlie_v** - *11:47:06*

Can't this be the one exception...

*Tags: Errors Debugging*

---

## 2021-12-22

**birchy** - *18:47:23*

For those of you running Flumine backtests on Apple M1 devices, what's a rough ballpark time to run 5k markets? Currently have an old probook and it's ~15 minutes with multiprocessing on 2 cores (4 threads).

*Tags: General Technical*

---

**mandelbot** - *19:48:17*

The air and pro? It's pretty much identical to the 13 inch pro model except for some extra battery life it seems. The 14" and 16" have more cores and ram etc

*Tags: Strategies*

---

**Jonjonjon** - *23:04:14*

[@U4H19D1D2](@U4H19D1D2) I'm looking at transactions again, using something like:



`with market.transaction() as t:`

    `t.place_order(order1)`

    `t.place_order(order2)`



Is there a way to get the full transaction to fail if either `order1` or `order 2` fails to validate? From what I know, Betfair will fail both orders if either of them is invalid (please correct me if I'm wrong!). However (and perhaps I'm not using it properly), I am seeing one of the orders being matched (in a backtest) if the other fails.



As a hack, I am using this code but it feels like a bit of an abomination:



```                        with market.transaction() as t:

                            all_valid = all(

                                t._validate_controls(order, OrderPackageType.PLACE)

                                for order in entry_trade.orders

                            )

                            if all_valid:

                                if runner_context.live_trade_count+len(entry_trade.orders)&lt;self.max_live_trade_count:

                                    for order in entry_trade.orders:

                                        t.place_order(order)

                                else:

                                    logger.error('This would invalidate the max trade count')```

*Tags: Errors Debugging, Deployment*

---

**Beeblebrox** - *23:09:36*

There's a seconds_to_start flag you can use as well. [https://liampauling.github.io/flumine/performance/|https://liampauling.github.io/flumine/performance/](https://liampauling.github.io/flumine/performance/|https://liampauling.github.io/flumine/performance/)

*Tags: Performance*

---

## 2021-12-24

**liam** - *10:18:59*

There was a question in the AMA on this 

*Tags: General Technical*

---

## 2021-12-25

**Jonjonjon** - *19:26:53*

Happy Christmas. Thanks to everyone for making BFLW and Flumine so great.

*Tags: General Technical*

---

## 2021-12-26

**Jonjonjon** - *13:59:34*

Betfair keep sending me free bets  (6 on the last month) and my bot performance has been lackluster. Am I at risk of being classified as the wrong sort of VIP?

*Tags: Performance*

---

**Jonjonjon** - *17:11:37*

Yes. But it depends on your strategy. For what I do, 8% is best as my returns are relatively consistent. But if your strategy is less consistent a lower % could be better. [@UGV299K6H](@UGV299K6H) shared a useful spreadsheet for doing the calculations a long time ago.

*Tags: Strategies*

---

**Oliver Varney** - *17:39:01*

yup gonna use that for market book differences for sure. I want to batch run some code against like 85k price files, which looks like it will take a fair few hours. Just wondering if the more technical python chaps can find optimisations in the above code to reduce timings

*Tags: General Technical*

---

## 2021-12-28

**Michael** - *09:01:38*

I recall the discussion - did I really post a spreadsheet? Anyway for anyone who's wondering the take-away is that the lowest percentage is almost always best because otherwise you don't benefit as much from your implied comm. The main exception is if your total charges ratio (or whatever they call it) puts you right on the boundary between the upper PC brackets (40/50/60%) in which case the higher rates might make sense. If you are extremely consistent then your comm rate won't make much difference either way.



There's a separate but related discussion about the degree to which you should value returns now against generating comm to offset future winnings. I'm very much in the _"take the money now"_ camp but a case can be made the other way.

*Tags: Errors Debugging*

---

**PeterLe** - *20:31:01*

Merry Christmas!

Someone asked me a question today and although I had an inkling as to the answer I wasn’t sure..

The question was..how would you measure the performance of an inplay manual ‘trader' over time.

Assuming the stakes would increase over time as the trader got better



Would you use ROI (Profit/Total Stakes) or even MC as indicators as you would with automation? Then do a comparison between periods (by Month Quarter etc)

Thanks

*Tags: Performance*

---

**Michael** - *21:14:12*

That's a very small sample..... presumably not even 250 markets...? Do you have in place some procedure for analysing the performance of your analysis?

*Tags: Performance*

---

**PeterLe** - *21:21:05*

Yes only a tiny sample. No to the second question.

The idea behind this by the way was a POC to generate ideas for a new automation. Ive seen something in the markets thats hard to understand (for me anyway :grinning:) and I wanted to test it manually to frame it etc

I have some free time in January so will work on it, Cheers gents

*Tags: General Technical*

---

## 2021-12-29

**D C** - *13:18:45*

Got it for Christmas but not started yet. Hoping there is something useful in there but you do need to detatch from his conclusions about profitability. Needs to move his attention to other areas as he focuses only on stuff for which analytics are capable of generating pretty accurate prices. I would sit up and pay more attention if he widened his focus but I suppose sticking to these sports (Football and US sports) helps with his own confirmation bias.

*Tags: General Technical*

---

**Mo** - *13:56:41*

[https://betfairlightweight.slack.com/archives/C4H05KKMY/p1638797982452500](https://betfairlightweight.slack.com/archives/C4H05KKMY/p1638797982452500)

*Tags: General Technical*

---

**Mo** - *13:57:59*

Also the conversation starting here: [https://betfairlightweight.slack.com/archives/C4H05KKMY/p1637273019237600](https://betfairlightweight.slack.com/archives/C4H05KKMY/p1637273019237600)

*Tags: General Technical*

---

## 2021-12-30

**Oliver Varney** - *11:46:57*

which looks something like this:

```def patch_open(file_name, read_write):

    if len(file_name) &gt; 4:

        if file_name[-4:] == ".zip":

            archive = zipfile.ZipFile(file_name, read_write)

            name_list = archive.namelist()

            return archive.open(name_list[0], read_write)

        elif file_name[-4:] == ".bz2":

            return smart_open.open(file_name, read_write)

        elif file_name[-3:] == ".gz":

            return smart_open.open(file_name, read_write)

    else:

        raise Exception("Unrecognised file {}".format(file_name))```



*Tags: Errors Debugging*

---

**Mo** - *12:19:59*

I'd like to reassure everyone that the bflw meetup will NOT be postponed. Poll coming in the next few days

*Tags: General Technical*

---

**Oliver Varney** - *15:40:56*

I guess the question is assuming the sandp goes up another 30% next year (which I personally doubt although im clueless), do people expect to increase their bankroll more then that?

*Tags: General Technical*

---

**Michael** - *18:43:12*

I agree that trackers are a great product for most people, it's what I get family and friends to buy but if you're putting quite a lot aside then I don't think it's the only game in town. The internal costs in tracker funds are not negligible and the resulting tracking errors do become significant. If you're putting away enough that your transaction costs aren't a big deal then just buying a well diversified portfolio of individual shares gets you the full return on your holdings and spares you the risk associated with some of the synthetic tracking.

*Tags: Errors Debugging*

---

**James T** - *18:44:13*

I think it can make sense to have a regional bias to where you live though. I believe the UK Vanguard LifeStrategy 100% equity fund is global equities, but has a higher weighting towards the UK for example. 

*Tags: Deployment, Strategies*

---

**James T** - *18:55:01*

I personally still worry whether the global stock market will continue to grow as it has done like in the hundreds of years in the past. I think one major driving factor of the past has just been population growth, which leads to consumption growth, which leads to economic growth - but I think we're beginning to see a slow down in population growth now. So who knows. 



I expect for hundreds of years people have always questioned whether stocks can just go up forever or not, and so far it has! So maybe this is just the same. There's too much incentive for people to want that to happen. Then again, perhaps times are changing…

*Tags: Performance*

---

**mandelbot** - *19:07:18*

Problem with it is you can't offload your share in an artwork unless you live in the US and have a buyer. You'd have to wait till the fund sells the artwork. So it's a long term commitment

*Tags: Deployment*

---

**PeterLe** - *19:34:06*

I'm in the Vanguard Lifestrategy 60% equity JonJon for the last 4 or 5 years, served me well

*Tags: Strategies*

---

**Michael** - *20:01:20*

One thing that's happened to me and I'm sure others is that I've started to worry about different sorts of investment risks than I used to. I'm over stressing about market fluctuations, now I think about how to protect myself from global conflict, climate change chaos or runaway inflation.

*Tags: General Technical*

---

**Mo** - *20:02:23*

To be clear, masterworks is not a fund. You buy shares of individual pieces of art. 



They focus on art created since the Second World War as this has historically performed the strongest. 



If you sign up you get access to a database of art sales they have compiled so you can do independent analysis on whether you think the pieces on offer represent a good buy or not. 

*Tags: General Technical*

---

**Michael** - *21:08:39*

Haha - yeah fully agree [@USYQKE5HN](@USYQKE5HN) except that I don't think I (we?) have more at stake, less so really. At one time I couldn't pay my rent so the roof over my head was at stake. It's not now.



I think it's the opposite really, you don't have space to think about economic melt down when you can't pay the gas bill. Basically I've transitioned from just trying to get by to defending/entrenching my privilege. The latter condition is way less stressful.



Whilst I do think about financial risks I don't want to over state it because I'm basically quite care free. Trying to set your life up such that you never have to work come what may is one of a few first world problems that I think I can endure.

*Tags: General Technical*

---

**James T** - *21:54:11*

Yeah, higher absolute monetary stakes, but lower real life stakes like you say. Definitely a first world problem!

*Tags: General Technical*

---

## 2021-12-31

**Jonjonjon** - *09:51:23*

I just had warning from my cloud provider that my CPU utilisation has been 90% for the last 2 hours. What sort of utilisation do others have for their Flumine machines? I just have a single vcpu and should be able to easily upgrade to 2 vcpus. It will cost around $20 a month.

*Tags: General Technical*

---

**liam** - *11:30:03*

Unless you are running multiple instances of flumine? 

*Tags: General Technical*

---

**liam** - *13:07:24*

I try and keep one instance per core, strategy dependant but another CPU will help or condense / profile 

*Tags: Strategies*

---

**mandelbot** - *22:04:50*

check out this thread [https://betfairlightweight.slack.com/archives/C4H05ML2E/p1640699979363700](https://betfairlightweight.slack.com/archives/C4H05ML2E/p1640699979363700)



tl;dr there was a nonrunner and all bets are voided when there's a nonrunner for greyhounds, your lay bets must've been placed after the scratch

*Tags: General Technical*

---

**Jonjonjon** - *22:36:20*

I'm not sure about writing stuff to hedge once bets are voided. It's a rare circumstance. Will Flumine catch voided bets?

*Tags: General Technical*

---

## 2022-01-01

**Peter** - *09:57:39*

Although greyhounds are withdrawn on the day of the race, it's fairly rare for them to be withdrawn in the few minutes before the race when the market is active. That usually only happens if there's a problem that couldn't be spotted earlier in the day when they were caged waiting for their run time.

*Tags: General Technical*

---

**liam** - *11:41:15*

Happy New Year everyone! Thanks for making this such an awesome group :grinning:



Happy with my first goal as flumine has certainly become more stable, failed on the second.



This year looking to make this more of a programming/betting group rather than just python/bflw so maybe a rename and moving some libraries to an organisation. Personally I want to keep things ticking over and look to future proof certain areas. 

*Tags: Errors Debugging, Strategies*

---

**river_shah** - *12:12:26*

Happy New Year everyone! Thanks for all the contributors on this slack. Really invaluable.



I started betting in good size in Feb ’21. Not that I had any priors, but been a decent first year and my goals for ’22 are to continue using sports betting as a test bed for ideas for statistical modelling / simulation / optimal scaling. While the sports betting market is small relative to traditional financial markets, the rapid feedback that sports markets provide is particularly useful for my use case.



My stretch goal for sports betting for this year would be to reliably crack football markets.

*Tags: Strategies*

---

**VT** - *14:59:27*

Happy New Year everyone!



I plan to increase my profits in soccer manual trading by adding some tools that I can program in Python, I hope this will give me an advantage (even if small) over the other manual traders.

*Tags: Strategies*

---

**mandelbot** - *18:41:30*

Anyone know of a bflw/flumine for crypto? :smile:

*Tags: General Technical*

---

## 2022-01-02

**Peter** - *14:54:04*

I'm not understanding why this is a question. They're integers, so unless they are going to be so big as to require big ints, why does the number of digits matter?

*Tags: General Technical*

---

## 2022-01-03

**Ruben** - *22:48:04*

works like a charm, helped me track a bug

*Tags: Errors Debugging*

---

## 2022-01-05

**Paul** - *01:05:07*

Indeed first time [@U4H19D1D2](@U4H19D1D2) - dropped them a note to ask for more detailed info as it's not actually obvious how that happened. Frustrating, but sometimes learning how to buy money can be expensive :shrug: 

*Tags: Getting Started*

---

## 2022-01-07

**Jonjonjon** - *13:40:53*

Suppose you didn't have access to a local machine with several CPU cores and wanted to run a Flumine backtest using python multiprocessing. Is it practical to launch an aws instance to run the cpu-intensive task. Then stop it and analyse the results. Then rinse and repeat several times? Is there much overhead in starting/stopping an aws?

*Tags: Deployment*

---

**Jonjonjon** - *14:27:28*

Can my Python code automatically create and shutdown the spot instance?

*Tags: General Technical*

---

**Jonjonjon** - *14:52:07*

Has anyone here used ray?[https://www.ray.io/|https://www.ray.io/](https://www.ray.io/|https://www.ray.io/)



I'm wondering if that's what I need to do my backtesting on AWS. Though I'm not yet sure how to get all my Betfair historical files up there...

*Tags: Deployment*

---

## 2022-01-09

**Mo** - *14:48:06*

It's a good question. My guess is no as the official scores provider is different to either the main ATP or WTA tours

*Tags: General Technical*

---

**Jonjonjon** - *16:53:20*

Suppose I wanted to place 10 orders in quick succession. With each subsequent order placed after the prior has been received by Flumine. Assume I have a fast connection. How long would that take?

*Tags: General Technical*

---

**ShaunW** - *18:02:48*

I'm non-flumine [@UPMUFSGCR](@UPMUFSGCR) but you could do as I do and have a generic performance checking prog that for the sake of minimum maintenance is attached to a long term market, maybe next President, which checks things like you're looking at. 10 individual placements, 10 placements with confirmations between, 10 cancellations etc which is scheduled to run a few times a day. No reason you couldn't use one on an in-play market too if you want to look at delays.  Basically the best answer to your question is just to find out because your specific situation will be whatever it is.

*Tags: Performance*

---

**Dave** - *18:52:08*

Question RE benchmarking performance. How do you guys quantify how much better off / worse off you are by allocating your money to your gambling activity rather than some index fund? Especially as on Betfair your money is turned over many times, and also the concept of a "bank" doesn't make much sense given recurring withdrawals etc

*Tags: Performance*

---

**Mo** - *20:20:09*

What's wrong with the benchmark being investing your starting bankroll in the index?

*Tags: General Technical*

---

**Dave** - *20:25:38*

Seems inappropriate as you turnover your bankroll many times. But maybe that is the way to do it and pnl being many multiples of your bankroll shouldn't sound stupid compared to say "measly" 30% via the sp500!

*Tags: General Technical*

---

**Michael** - *22:10:44*

Is this theoretical or does it really arise as a practical question? In my experience there is no comparison between betting returns and investment returns. You bet everything the market will take, Investment is just what you do with your profits.

*Tags: Strategies*

---

**Dave** - *23:29:54*

Cheers guys. Was just reviewing performance over the past 12 months and wanted to compute some benchmarks in other asset classes, hence the q.

*Tags: Performance*

---

## 2022-01-10

**Stefan** - *15:12:38*

[@UPMUFSGCR](@UPMUFSGCR) My connection latency to betfair servers is around 120ms. I wrote my test code for 4 combination using rest api or streaming api, and placing 10 bets in one api call, or bet by bet in succession checking whether rest or order streaming api updated market bets.  Results are following:



                            | RestApiInOneApiCall -&gt; 0.504 seconds

                            | RestApiBetByBet -&gt; 3.134 s

                            | StreamingApiInOneApiCall -&gt; 0.332 s

                            | StreamingApiBetByBet -&gt; 2.308 s



[https://github.com/StefanBelo/Bfexplorer-BOT-SDK/blob/master/TestBetPlacementSuccession/Program.fs](https://github.com/StefanBelo/Bfexplorer-BOT-SDK/blob/master/TestBetPlacementSuccession/Program.fs)

*Tags: Performance, Deployment*

---

**D C** - *18:51:28*

It does go beyond 90 days for market level P&amp;L just not at the bet level. I can get stuff by strategy reference per market as far back as 2020. Depends on how specific you need the info.

*Tags: Strategies*

---

**Jonjonjon** - *21:46:18*

Does one instance of Flumine use 2 connections? I keep hitting the 20 MAX connection limits. I'm wondering if I have a stale processs somewhere as I'm only running 6 instances of Flumine.

*Tags: General Technical*

---

**Jonjonjon** - *22:07:59*

Is there a way to check how many streaming connections each of my servers is using?

*Tags: Deployment*

---

**Jonjonjon** - *22:27:18*

Running `netstat -np | grep python | grep ESTABLISHED` gives me 18 lines of output. I've blanked out the IP addresses as I'm not sure if they are safe to share or not. BUt the process numbers are my flumine instances on one machine:



`netstat -np | grep python | grep ESTABLISHED`

`(Not all processes could be identified, non-owned process info`

`will not be shown, you would have to be root to see it all.)`

`tcp 0 0 YYY:46208 XXX ESTABLISHED 21053/python3`

`tcp 0 0 YYY:41776 XXX ESTABLISHED 2144/python3`

`tcp 0 0 YYY:46202 XXX ESTABLISHED 539/python3`

`tcp 0 0 YYY:56134 XXX ESTABLISHED 21053/python3`

`tcp 0 0 YYY:41990 XXX ESTABLISHED 2144/python3`

`tcp 0 0 YYY:45264 XXX ESTABLISHED 546/python3`

`tcp 0 0 YYY:46204 XXX ESTABLISHED 21053/python3`

`tcp 0 0 YYY:58348 XXX ESTABLISHED 2144/python3`

`tcp 0 0 YYY:46206 XXX ESTABLISHED 2144/python3`

`tcp 0 0 YYY:54580 XXX ESTABLISHED 546/python3`

`tcp 0 0 YYY:45262 XXX ESTABLISHED 539/python3`

`tcp 0 0 YYY:46190 XXX ESTABLISHED 2144/python3`

`tcp 0 0 YYY:46188 XXX ESTABLISHED 2144/python3`

`tcp 0 0 YYY:46212 XXX ESTABLISHED 21053/python3`

`tcp 0 0 YYY:58346 XXX ESTABLISHED 21053/python3`

`tcp 0 0 YYY:58350 XXX ESTABLISHED 21053/python3`

`tcp 0 0 YYY:54572 XXX ESTABLISHED 539/python3`

`tcp 0 0 YYY:45268 XXX ESTABLISHED 539/python3`

*Tags: General Technical*

---

## 2022-01-11

**Jonjonjon** - *08:10:29*

Suppose I want to run separate WIN and PLACE strategies under one Flumine instance and one market filter. How would you recommend I manage the price filtering? My naive initial thought is to use 'check_market_book'. But is there a cleaner way?

*Tags: General Technical*

---

## 2022-01-15

**Newbie99** - *09:30:23*

Apologies as this is a bit open ended, but I'm not understanding what went wrong here, last night around 1 am, out of (seemingly) no-where it looks like I suddenly got latency warnings and then eventually the process killed:



```{"asctime": "2022-01-15 01:00:05,664", "levelname": "INFO", "message": "Placing new LAY order for runner ('Jaime Jamel', 35971913, 0), runner exposure is: {'selection_id': 35971913, 'handicap': 0, 'if_win': 0.539, 'runner_matched_stake': 0.0, 'runner_matched_exposure': 0.0, 'min_market_exposure': -18.509999999999998} and limit is: 0.3."}

{"asctime": "2022-01-15 01:00:05,664", "levelname": "INFO", "message": "Order status update: Pending", "market_id": "1.193372878", "selection_id": 35971913, "handicap": 0, "id": "138615012056645370", "customer_order_ref": "7c44d7544ce40O138615012056645370", "bet_id": null, "date_time_created": "2022-01-15 01:00:05.664573", "publish_time": "2022-01-15 01:00:05.647000", "market_version": null, "async": false, "trade": {"id": "7a2c3bee-759e-11ec-b096-02054918c7c6", "strategy": "betting_market_lay", "place_reset_seconds": 0.0, "reset_seconds": 0.0, "orders": ["138615012056645370"], "offset_orders": [], "notes": "R3 5f Allw,2022-01-15 01:02:00,WIN,Flat,US,Charles Town,False,False,None,False,Jaime Jamel,2.64,2479.75,8,1,False,None,0,Charles Town (US) 14th Jan,31175177,7,{'strategy_name': 'betting_market_lay', 'selection_id': 35971913, 'handicap': 0, 'price_percentage': 0.768, 'min_valid_external_value': 0.8, 'current_back_price': 48, 'current_mid_price': 56.5, 'current_lay_price': 65, 'previous_back_price': 50, 'previous_mid_price': 62.5, 'previous_lay_price': 75},1", "market_notes": null, "status": "Live", "status_log": ""}, "order_type": {"order_type": "Limit", "price": 50.0, "size": 0.31, "persistence_type": "LAPSE", "time_in_force": null, "min_fill_size": null, "bet_target_type": null, "bet_target_size": null}, "info": {"side": "LAY", "size_matched": 0.0, "size_remaining": 0.31, "size_cancelled": 0.0, "size_lapsed": 0.0, "size_voided": 0.0, "average_price_matched": 0.0}, "responses": {"date_time_placed": null, "elapsed_seconds_executable": null}, "runner_status": null, "status": "Pending", "status_log": "Pending", "violation_msg": null, "simulated": {"profit": 0.0, "piq": 0.0, "matched": []}, "notes": "R3 5f Allw,2022-01-15 01:02:00,WIN,Flat,US,Charles Town,False,False,None,False,Jaime Jamel,2.64,2479.75,8,1,False,None,0,Charles Town (US) 14th Jan,31175177,7,{'strategy_name': 'betting_market_lay', 'selection_id': 35971913, 'handicap': 0, 'price_percentage': 0.768, 'min_valid_external_value': 0.8, 'current_back_price': 48, 'current_mid_price': 56.5, 'current_lay_price': 65, 'previous_back_price': 50, 'previous_mid_price': 62.5, 'previous_lay_price': 75},1", "market_notes": null}

{"asctime": "2022-01-15 01:00:30,284", "levelname": "INFO", "message": "1.193373059: 0 cleared orders found, more available: False"}

{"asctime": "2022-01-15 01:01:13,244", "levelname": "WARNING", "message": "[FlumineStream: 4002]: Latency high: 0.9758524894714355"}

{"asctime": "2022-01-15 01:01:13,245", "levelname": "WARNING", "message": "[MarketStream: 3001]: Latency high: 0.9100987911224365"}

{"asctime": "2022-01-15 01:01:13,245", "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 0.8022336959838867"}

{"asctime": "2022-01-15 01:12:41,802", "levelname": "INFO", "message": "Deleting requests.Session", "sessions_created": 36, "session": "&lt;requests.sessions.Session object at 0x7f2c6a5195d0&gt;", "session_time_created": 1642208309.3769233, "session_time_returned": 1642208405.607362, "live_sessions_count": 1, "err": true}

{"asctime": "2022-01-15 01:12:41,813", "levelname": "WARNING", "message": "[MarketStream: 3001]: Latency high: 689.2287058830261"}

{"asctime": "2022-01-15 01:12:41,814", "levelname": "WARNING", "message": "[FlumineStream: 4002]: Latency high: 689.5181279182434"}

{"asctime": "2022-01-15 01:12:41,814", "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 689.121832370758"}```

The only change I've made (and so at this stage I'm assuming is the culprit) is to run the market recorder on my live instance, as opposed to my local test instance (previously I recorded locally and kept my live stuff separate), so I added this just before framework.run() on my live code in AWS:



```recorder = MarketRecorder(

            name="MR_horse_greyhounds",

            market_filter=streaming_market_filter(

                    event_type_ids=[7],

                    country_codes=['GB','IE','US','FR', 'AU'],

                    market_types=['WIN', 'PLACE', 'EACH_WAY'],

                ),

            stream_class=DataStream,

            context={

                "local_dir": ai.unprocessed_data,

                "bucket": "fluminetest",

                "force_update": False,

                "remove_file": True,

            },

        )



        framework.add_strategy(recorder)```

Am I potentially trying to record too much in one go and/or from the error am I somehow creating too many sessions (and if so how might I stop this)?



Again apologies for the open ended nature, I'm clearly not understanding something about sessions I feel!

*Tags: Data Quality, Errors Debugging, Performance, Deployment, Strategies*

---

**Mo** - *10:40:10*

Given the process got killed, presumably by the OOM Killer, seems like memory would have to have been the problem

*Tags: Performance*

---

**Newbie99** - *11:03:33*

yes, thats correct, so 1 instance which effectively does:



```framework.add_strategy(strategy)



recorder = MarketRecorder(

            name="MR_horse_greyhounds",

            market_filter=streaming_market_filter(

                    event_type_ids=[7],

                    country_codes=['GB','IE','US','FR', 'AU'],

                    market_types=['WIN', 'PLACE', 'EACH_WAY'],

                ),

            stream_class=DataStream,

            context={

                "local_dir": ai.unprocessed_data,

                "bucket": "fluminetest",

                "force_update": False,

                "remove_file": True,

            },

        )

framework.add_strategy(recorder)



framework.run()```

Is that not a sensible approach (previously I did have it on a separate instance, but I thought people on here suggested they had everyone on one and it might be simpler)?

*Tags: Strategies*

---

**Peter** - *11:36:37*

Last conversation I remember here o this topic said the opposite, i.e. keep data collection separate from strategy execution. However it's very possible to combine the execution of multiple strategies on a single server and this is generally what people advise.

*Tags: Deployment, Strategies*

---

**Newbie99** - *11:42:26*

I guess the problem then is you might run out of connections (as presumably if you are collecting data using the same filters as a live strategy flumine shouldn't open up a new connection). But if that is the best approach then I can revert back to that, in a sense its easier to record locally as it saves transferring everything and then can test on the same machine!

*Tags: Deployment, Strategies*

---

**liam** - *11:52:28*

Market recorders actually use different stream types so no benefit when sharing an instance, hence recommendation to use separate 

*Tags: Data Quality*

---

**Jonjonjon** - *21:18:22*

When doing A/B testing, what do people use to check whether to choose A or B?



So I have a strategy, and given a market_id, I want to always choose the same A or B, but at random.



I currently have the following code, but it is the slowest part of my program and is causing performance issues:



```def rand_int_from_market_id(

        market_id: str,

        low: int=0,

        high: int = 2

):

    """

    Deterministic way to generate a random int from a market id.

    The purpose of this is to help us do A/B testing

    Parameters

    ----------

    market_id



    Returns

    -------



    """

    seed = int(market_id.replace('.', ''[-6:]))

    state = np.random.RandomState(seed)

    return state.randint(low, high)```

Would it be safe to just choose odd market ids for A, and even numbers for B? Or could something like this be safer:



```(((market_id % 7) % 5) % 3) % 2```



*Tags: Performance, Strategies*

---

## 2022-01-16

**Mo** - *10:39:32*

The question of how to randomly assign market IDs to 2 groups but in a repeatable way is super interesting. I'd like to put a function for this in betfairutil. My first thought was a quasi-RNG like Halton sequence but it's not fast to calculate the n-th element of the sequence (I would use the market ID as n). I found this blog post on low discrepancy sequences: [http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences/](http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences/) which proposes a new method:



```g = 1.6180339887498948482

a1 = 1.0/g

x[n] = (0.5+a1*n) %1```

*Tags: General Technical*

---

**Oliver Varney** - *10:41:26*

dont know if this can be leveraged (maybe off topic to the specific use case here) [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)

*Tags: Strategies*

---

**Mo** - *10:58:58*

Sounds very similar to [@UPMUFSGCR](@UPMUFSGCR)’s approach above which seems to have performance issues

*Tags: Performance*

---

**Aaron Smith** - *13:52:07*

this discussion goes a little over my head i feel. What would be the problem with something like adding digits and taking it modulo 2 ?

*Tags: General Technical*

---

**Mo** - *14:06:00*

Depending on your requirements, nothing. The questions are:



1. What is the computational cost?

2. Does it actually assign a market ID to each group with probability 50%?

*Tags: General Technical*

---

**birchy** - *21:08:45*

Maybe I'm misunderstanding the A/B problem here, but why not loop through the market IDs and do something simple like this?

`if random`.`choice(True, False):

    groupA.append(market_id)

else:

    groupB.append(market_id)`



*Tags: General Technical*

---

**Aaron Smith** - *23:45:47*

[@U016TGY3676](@U016TGY3676) surely it wont be truly random, but as long as its deciding factors are independent of anything related to how betfair assigns market_ids, it its effectively random in the eyes of the betfair market_id generator. For example if i take my grandmas birthday and choose to pick all market_ids that have the last 2 digits of her birth year in it, that will have nothing to do with how betfair assigns market_ids (at least so i would hope). However, this would probs not give a 50/50 distribution. Odd/even is not random in the eyes of the betfair market_id generator, as place_market_id = win_market_id + 1 (this may not be a problem really, but its also not perfect). 1's &gt; 0's wouldnt work as mostly market_ids are counting upwards, so you ll have long streaks where there is more 0's and long streaks where there is more 1's. You can throw in sqrt or whatever, but a complication like that doesnt necessarily result in a 50/50. A simple system that is proven to be pseudo-random and guarantees a 50/50 result would surely be nicer.

*Tags: General Technical*

---

## 2022-01-17

**Mo** - *07:10:44*

[@U016TGY3676](@U016TGY3676), it's very common to want to have a random sequence that can be reproduced. For example, this might help with debugging or ensuring some backtest results are comparable. Typically this is done by setting the random seed and if that was combined with your use of `random.choice` then that can be considered a complete solution to the problem at hand. The method I posted has a couple of advantages that I can see:



1. No need to _remember_ to set the seed or what seed you should use

2. Will produce the same results for everyone

Coming back to my point about debugging, 2. is very useful. If someone comes on here with a bug in their program that ran on a random assignment of market IDs then, provided this canonical method for that assignment existed and was used, I could run the code and generate the same bug without needing to know anything about the state of their random number generator. And coming back to 1., if they didn't use this method and they weren't aware of this nuance they might not have set the seed and no one would ever know what random number generator state produced the bug.

*Tags: Errors Debugging*

---

**Oliver Varney** - *13:34:04*

everyone else having a few account errors come through ?

*Tags: Errors Debugging*

---

## 2022-01-20

**liam** - *09:53:10*

assuming you have a trigger or model, to increase volatility I would just need to move my trigger further away from its optimum, sometimes this will increase profit but at a cost of volatility and potential scaling so not sure why you would?

*Tags: Strategies*

---

**Oliver Varney** - *13:32:43*

someone must have a great strategy catching out people to slow to cancel orders

*Tags: Performance, Strategies*

---

**Oliver Varney** - *13:33:30*

sounds like one of [@UBS7QANF3](@UBS7QANF3) latency sensitive ones

*Tags: Performance*

---

**Lee** - *18:34:58*

Very verbose, large diffs, if using a non typed language like Python for the api then it can be tricky to get the right structure in the swagger def, takes a bit of trial and error.

All that aside, personally I'd say the benefits outweighs the negatives. Especially when working in a team or have a fair amount or endpoints.

*Tags: Errors Debugging*

---

**Oliver Varney** - *18:43:15*

unless im generating it wrong, basically works backwards from how bflw does it

*Tags: General Technical*

---

**Lee** - *20:20:40*

I've only really used it from a django / sprint boot backend and used on a react frontend. It is a clunky, but it's a compromise of easy api calls and documentation. 

*Tags: General Technical*

---

## 2022-01-22

**Jorge** - *11:13:19*

Hey guys, I finally moved from my crappy server provider to AWS but I am having trouble configuring an Alarm for Disk Space and RAM usage. Anyone knows a simple way to do this?

*Tags: Deployment*

---

**gbettle** - *12:48:23*

In rear, raced wide early, midfield after 1f, pushed along when up the centre over 2f out, headway but edged left from over 1f out, soon close up, ridden when challenging inside final furlong, kept on to lead final 110yds (trainer said, on the improvement in form, the mare was freshened up for the return from a 44 day break and felt that this, along with a good break from the stalls had helped to bring about the apparent improvement) (op 5/1 tchd 11/2)

*Tags: General Technical*

---

**gbettle** - *13:20:04*

No problem

*Tags: General Technical*

---

**Mick** - *14:30:48*

"The Stewards requested a report from Shane Crawley, trainer, as to the apparent improvement in form of Kalmira, placed first, as compared with its most recent form. The trainer reported that his charge had disappointed on its previous run when running in very quick succession. He said that his charge was freshened up for tonight's run which was off the back of a 44 day break and felt that this, along with a good break from the stalls had helped to bring about the apparent improvement in form. Having considered the evidence, the Stewards noted the content of the report."

*Tags: General Technical*

---

## 2022-01-23

**Ruben** - *08:34:04*

I created an alert for when my estimated billing costs went above a threshold using cloudwatch, following this tutorial: [https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/monitor_estimated_charges_with_cloudwatch.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/monitor_estimated_charges_with_cloudwatch.html) I imagine creating alerts for other metrics would be very similar

*Tags: Deployment*

---

**Jorge** - *10:00:53*

Thanks, I created a Disk and RAM alarms with CloudWatch following this tutorial: [https://kumargaurav1247.medium.com/aws-cloudwatch-agent-installation-for-memory-metric-integrate-with-grafana-365404154](https://kumargaurav1247.medium.com/aws-cloudwatch-agent-installation-for-memory-metric-integrate-with-grafana-365404154)

*Tags: Getting Started, Performance, Deployment*

---

**Jorge** - *10:01:35*

I'd have expected AWS to include a button to do this in the Website, though

*Tags: Deployment*

---

**Peter** - *11:36:44*

I think that AWS's philosophy is to give you the tools to produce alerts to your specific requirements. If they offered buttons for this stuff, people would come up with 1001 different use cases and their admin pages would be an unintelligible mess of buttons.

*Tags: Deployment*

---

## 2022-01-24

**Jonjonjon** - *22:14:47*

Suppose I want to store some information relating to a particular runner. This information will be different for every different strategy instance. The information is generated on-the-fly (i.e. it's a particular indicator that I'm using). Should I be storing this is `BaseStrategy.context`?

*Tags: Strategies*

---

**Jonjonjon** - *22:17:55*

I've been looking at market.context too. But the data is specific to each strategy/market combination. So I'm not sure about it.

*Tags: Strategies*

---

**Aaron Smith** - *23:09:38*

I make a key for each strategy in market.context

*Tags: Strategies*

---

## 2022-01-25

**James T** - *20:39:25*

They also have a prop trading team who trades against customers on their own exchange (obviously without charges and probably at lower latency). And they can see whose bets are whose. I don't think that's a fair market. 



Last time I looked a couple years ago, they make far more money from betting against customers than they do on exchange revenue. 

*Tags: Performance, Strategies*

---

## 2022-01-28

**liam** - *09:32:36*

Morning, I have been thinking about this for a while but looking to have a name change / rebrand for bflw to open the doors to everyone who is involved in betting but keeping the API/model/programming link.



Nothing would change other than the name of this group and the creation of a GitHub organisation to hold any relevant libraries (wrappers/flumine etc) I have signed a few of you up to this already but if anyone else wants to be a member of the org please let me know :slightly_smiling_face:



The only blocker is the name, anyone got any ideas?

*Tags: Strategies*

---

**Unknown** - *09:33:17*

betfairlightweight rename..

*Tags: General Technical*

---

**Joel Beasley** - *12:07:07*

Are there likely to be languages other than Python in the future [@U4H19D1D2](@U4H19D1D2)?

*Tags: General Technical*

---

**liam** - *12:37:25*

potentially however python is fast becoming the goto for everything, `PyBet` wouldn't stop others being included though

*Tags: General Technical*

---

**Atho55** - *13:27:54*

PyBet makes it sound like a Python only site IMHO

*Tags: General Technical*

---

**James T** - *14:47:30*

I'm sort of with the others. I'm not sure a rebrand will make that much difference? So of the existing options I voted for betlightweight since it's more an evolution of the current name. Completely losing the link to bflw seems a shame. 

*Tags: General Technical*

---

**liam** - *14:49:54*

I guess the question is would you have joined earlier and/or contributed more if the name didn't have betfair in it or was linked to the python library?

*Tags: General Technical*

---

**Aaron Smith** - *14:56:10*

whats the common ground for all ppl in the group? betting or automated betting or betting with python? I guess its automated betting? PyBet does sound nice tho :smile:

*Tags: Strategies*

---

**Unknown** - *14:56:20*

Was looking for a spin on Flumine and found this

*Tags: General Technical*

---

**James T** - *15:00:41*

I don't think I would have contributed anything more / less if it had Py in the name actually. I might have joined earlier though if it didn't have Py in the name. I'd probably contribute to C# code if there was a starting base already, but there's probably no demand for a C# base to start with. 



Betfair in the name draws me in because that is my primary platform. I guess maybe the question is do people choose Betfair and then look for a library / community, or does someone want to learn how to bet professionally and then look for a library to see what it provides and how others do it?

*Tags: Deployment*

---

**D C** - *15:34:45*

I might not have joined at all if it had Py in the name because I don't use Python. Probably not many of us in here that don't actually use the BFLW code base, but I feel that if I had not joined this group by just because of that "Py" prefix I would have missed out on an incredible resource.

*Tags: Errors Debugging*

---

**river_shah** - *15:49:12*

could the org be called `flumine` / rename this channel to it as well / refactor underlying repos, maybe `bflw` becomes a module in `flumine`

*Tags: General Technical*

---

**birchy** - *21:12:55*

It's always difficult deciding whether to rename/refactor something. The main implications I can see are that there are already a lot of followers using bflw/Flumine and also tutorials on betfair, etc recommending it, so it's potentially breaking. Unless, of course, the intention is to create a resource that includes bflw and Flumine, plus whatever other libraries get added in the future?

*Tags: General Technical*

---

**liam** - *21:58:28*

That reminded me of my favourite betfairlightweight issue [https://github.com/liampauling/betfair/issues/210|https://github.com/liampauling/betfair/issues/210](https://github.com/liampauling/betfair/issues/210|https://github.com/liampauling/betfair/issues/210)

*Tags: General Technical*

---

## 2022-01-29

**Dave** - *09:32:53*

Personally I think the name should be semantic and not try to be some flashy brand. bflw did achieve that the first time round. Wannabe sport bettors and retail traders in finance love the flashy crap like "NinjaTrader" etc. I think we are all here to take a systematic and scientific approach to capitalise on market in efficiencies, and the name should reflect that. Flumine is nice as it relates to flow of liquid(ity) and I think we all appreciate the link to markets there. PyBet IMO is too generic. Something related to quantitative/systematic/non-discretionary betting would be good. Some of the flashy "brand names" here would put me off tbh, and also cater a lot to the same audience from whom you make your money off.

*Tags: Getting Started, Strategies*

---

**Newbie99** - *10:11:38*

I think it really comes down to the new audience you're trying to attract.



Is it a case of trying to get people on-board who are already using their own code for automated betting on other sides?

Is it people who are currently manually betting on betfair without the API?

The same as above but manually betting via the betfair API?

What about people who see themselves as 'sports traders' would that bring in a new audience?



And so on...



Once the target has been selected the name probably is easier to derive.

*Tags: Strategies*

---

**river_shah** - *13:30:02*

out curiosity, what was the origin of the name `flumine`?

*Tags: General Technical*

---

**PeterLe** - *13:30:36*

there was a company called betcode Limited registered in the UK although it looks like the company has since been dissolved

*Tags: General Technical*

---

**Jonjonjon** - *14:32:58*

Do many people fiddle with the latency setting of the backtester?

*Tags: Performance*

---

**thambie1** - *14:54:10*

I do it once in a blue moon, to check how latency sensitive my strategies are

*Tags: Performance*

---

**Jonjonjon** - *22:22:53*

I've found that changing the my backtest latency up to 0.3 seconds can have a big impact.:disappointed:

*Tags: Performance*

---

## 2022-01-30

**Alessio** - *15:23:52*

[@U4H19D1D2](@U4H19D1D2) very late to the convo as usual, but I see how the 'api/automation/modelling' full circle looks like a key point. I landed here because flumine looked like a full integrated thing, so I'd suggest stuff like BetStudio or BetDeveloper or BetCharm. Or NeverGreen, possibly with an altered version of Never Gonna Green You Up :wink:

*Tags: Strategies*

---

**river_shah** - *16:01:40*

I really think `flumine` is a fantastic name (a play on streams and evocative of steampunk) and we already have a community around it who understand that it is an integrated quant betting system. Sorry to repeat but my strong vote would be to promote `flumine` as the org name / all other packages / repos under this umbrella.



Users can still pick and choose sub packages or install the whole of `flumine` and get all the `flumine` eco-system dependencies sorted for them.

*Tags: Getting Started, Strategies*

---

**MacrcoPolo** - *18:12:42*

PyBetCore/PyBetMore for bflw/flumine respectively (I just like things that rhyme...)

*Tags: General Technical*

---

**D C** - *21:28:33*

Hi chaps. I have a generic question about open source licenses. Basically I am in the process of making my manual ladder trader code into an open source project (mainly because I have zero interest in manual trading now and no time to work on it) but not sure about what license to apply. It is build using an open source licence version of Qt creator which I believe is LGPL3. I want to use MIT license as I believe that means that anyone can do whatever they like with it. I want it to be used by anyone for any purpose and I believe MIT is the best here. I am hoping that some here might know more about open source license stuff as I have zero interest in this kind of thing and don't really know much about it.

*Tags: Strategies*

---

## 2022-01-31

**Jonjonjon** - *14:11:31*

In Betfair streaming files, will the first message always be a marketDefinition?

*Tags: General Technical*

---

## 2022-02-01

**Paul** - *09:27:47*

Sounds like it. Most importantly you haven't made the novice error of trying to write your own :ok_hand: 

*Tags: Errors Debugging*

---

**Unknown** - *12:31:27*

Hey guys, here's something I'm working on for the next release of betfairviz: defining "points of interest" to use with the dashboard



These points of interest could be market related - in this example I've defined them as any matching cycle where at least £10k was matched - or they could be exogenous like goals/cards/corners in football. They let you quickly navigate the market through time and explore the market dynamics around these points



Next step is to display these points of interest on the book percentage graph with flexible styling chosen by the user



Code for the example is:



```import pandas as pd



import betfairutil

import betfairviz



market_books = betfairutil.read_prices_file('../betfair-hackathon-2021/1.176457983.bz2')



volumes_traded = pd.Series(betfairutil.calculate_total_matched(mb) for mb in market_books).diff()



points_of_interest = [

    betfairviz.PointOfInterest(

        text=f"£{round(volumes_traded[i], 2)} matched at {betfairutil.publish_time_to_datetime(market_books[i]['publishTime'])}",

        timestamp=betfairutil.publish_time_to_datetime(market_books[i]['publishTime']))

    for i in volumes_traded.index[volumes_traded &gt; 10000]

]



betfairviz.create_dashboard(market_books, points_of_interest=points_of_interest)```

It requires the latest (0.1.1) version of betfairutil, installable from GitHub a la



```pip install git+[https://github.com/mberk/betfairutil.git@master#egg=betfairutil[files]](https://github.com/mberk/betfairutil.git@master#egg=betfairutil[files])```

and the points-of-interest branch of betfairviz:



```pip install git+[https://github.com/mberk/betfairviz.git@points-of-interest#egg=betfairviz](https://github.com/mberk/betfairviz.git@points-of-interest#egg=betfairviz)```



*Tags: Getting Started, Feature Engineering*

---

## 2022-02-02

**Peter C** - *09:11:34*

Hi [@UBS7QANF3](@UBS7QANF3), I'm having a play with this this morning, but I'm having problems loading my self recorded data. I get the following error, please would you help me debug? I get the same error importing various files with a variety of the betfairutil functions. I installed betfairutil/viz as above



```~\anaconda3\lib\site-packages\betfairutil\__init__.py in read_prices_file(path_to_prices_file, lightweight)

    792     stream = trading.streaming.create_historical_generator_stream(

    793         file_path=path_to_prices_file,

--&gt; 794         listener=StreamListener(

    795             max_latency=None, lightweight=lightweight, debug=False, update_clk=False

    796         ),



TypeError: __init__() got an unexpected keyword argument 'debug'```

*Tags: Getting Started, Errors Debugging, Performance, Strategies*

---

**charlie_v** - *10:04:57*

As we all know we are in a lonely job, and a lot of stuff we cannot share, so a question, do any of you talk to yourself (similar to bouncing ideas of others) to work out a few answers, or am I simply going mad :slightly_smiling_face:

*Tags: General Technical*

---

**Lee** - *10:05:52*

[https://en.wikipedia.org/wiki/Rubber_duck_debugging](https://en.wikipedia.org/wiki/Rubber_duck_debugging)

*Tags: Errors Debugging*

---

**liam** - *10:07:14*

that error is due to debug being removed as a variable for the Listener

*Tags: Errors Debugging*

---

**Mo** - *10:27:02*

[@U4H19D1D2](@U4H19D1D2) yeah was fixed 2 versions ago in betfairutil so must have been a stale install that was fixed when restarting his IDE

*Tags: Getting Started, Errors Debugging*

---

## 2022-02-03

**Mo** - *08:55:18*

If it's one match I wouldn't describe it as a change which implies permanence, sounds more like a mistake. My guess would be Betfair had connection problems with their data provider

*Tags: General Technical*

---

## 2022-02-04

**Unknown** - *09:44:26*

Thanks to everyone for coming to the meetup last night, especially @river_shah for being a massive alpha leak. If I'm honest, the level of attendance was disappointing. If you can answer the following poll it will help plan more events in the future

*Tags: General Technical*

---

**Oliver Varney** - *13:46:07*

just was getting that debug issue then double checked

*Tags: Errors Debugging*

---

## 2022-02-05

**Oliver Varney** - *07:28:19*

[@U4H19D1D2](@U4H19D1D2) , random one , MarketCatalogueDescription.keyLineDefinition / key_line_definition is never set in bflw betting resources?

*Tags: Strategies*

---

**Oliver Varney** - *10:20:10*

[https://github.com/liampauling/betfair/blob/b202fe192b2a46c4d19ab50cf60e380f2a38cb4e/betfairlightweight/resources/bettingresources.py#L216](https://github.com/liampauling/betfair/blob/b202fe192b2a46c4d19ab50cf60e380f2a38cb4e/betfairlightweight/resources/bettingresources.py#L216)

*Tags: Strategies*

---

**Oliver Varney** - *11:09:20*

Another random one, Is .get() vs [''] used in all places for resources and isnt specifically used to return None when missing. Im just looking into to doing some work around dataclass/pydantic models.

*Tags: Strategies*

---

## 2022-02-06

**Dave** - *18:59:52*

Has anyone tried running their same strategies on smaller exchanges? E.g. maybe using the same pricing model but just executing on betdaq instead? If so, do you find that your margins are higher (i.e. profit / volume traded)?

*Tags: Strategies*

---

## 2022-02-07

**Mo** - *07:19:34*

[@U4H19D1D2](@U4H19D1D2) what's the bflw version requirement? 2.13.1?

*Tags: General Technical*

---

**Oliver Varney** - *07:32:41*

are certain file types associated with different PRO/ADVANCED? Is that what you mean. [@U4H19D1D2](@U4H19D1D2) gave me a helper function that can determine the file type

*Tags: General Technical*

---

**Oliver Varney** - *11:38:47*

inplay chaps, stupid question incoming (probably overthinking this), is there any logic in the market book that can be used to determine the last market book that can account for both false starts and after market reopenings for close calls? i.e. is there a variable that changes for the point where they close the market when the front horses cross the line.

*Tags: General Technical*

---

## 2022-02-08

**Oliver Varney** - *05:18:50*

is that a flumine field [@UGV299K6H](@UGV299K6H)?

*Tags: General Technical*

---

**Michael** - *08:19:47*

Up at 5 [@ULDAVFDRP](@ULDAVFDRP)? Or should that be "still up at 5"? Anyway; I don't use Flumine, I just record the time that the market first turns in play and count as a false start any suspension within 30 seconds. I just go with the obvious market signals for a close/photo finish.

*Tags: General Technical*

---

## 2022-02-09

**Jonjonjon** - *12:23:40*

Recently, [@U4H19D1D2](@U4H19D1D2) posted a screenshot of his CPU utilisation on AWS. I can't find it. Does anyone have a link to it?

*Tags: Deployment*

---

**Unknown** - *12:39:21*

last 3 days of EC2

*Tags: Deployment*

---

**Oliver Varney** - *19:39:54*

basic question which I should of probably rethought about ages ago, but do people use certs or interactive login. If I understand correctly,  interactive login doesnt require certs and is just password and username. Ive always just used the certs as thats how I originally did it. docs suggest using certs but I couldnt remember if liam or someone said they dont use that approach any more.

*Tags: General Technical*

---

## 2022-02-10

**Unknown** - *13:14:15*

According to the premium accounts newsletter ([https://betfairlightweight.slack.com/files/UQL0QDEKA/F031J38E0FK/premium_newletter_january_2022.pdf|https://betfairlightweight.slack.com/files/UQL0QDEKA/F031J38E0FK/premium_newletter_january_2022.pdf](https://betfairlightweight.slack.com/files/UQL0QDEKA/F031J38E0FK/premium_newletter_january_2022.pdf|https://betfairlightweight.slack.com/files/UQL0QDEKA/F031J38E0FK/premium_newletter_january_2022.pdf)), if you want access then ask your AM if you have one or BDP otherwise

*Tags: General Technical*

---

**D C** - *19:34:53*

I'm looking for a bit of advice in regards to streaming. In trying to move my bots to a "permanent" (instead of run daily) I've started to use coarse filters instead of market ID list with the view to detect "new" markets on the stream, store the initial image then call listMarketCat on it later to fill in the gaps. Trouble is that I have had a couple of new markets come in where the first detection message is not a market image. I assumed that the initial image would have to be the first message. Any ideas of what I can do to get around this? If I have missed the image, I need to do a full resub presumably but I really don't want to do that. How do others get around this issue?

*Tags: General Technical*

---

**D C** - *19:40:23*

I have a "market" class. This used to be initialised from a marketInfo from the listMarketCat. Moving to the stream now, I instead initialise from the initial stream image, then later call listMarketCat. When new markets are added, I pick it up off the stream and call listMarketCat later. Couple of times today though I've had exceptions fire because the initial stream message was NOT an image. I didn't think this was possible. It's happened twice over about 1500 markets now. I can't even think of an explanation and your response suggests that it simply should not happen

*Tags: Errors Debugging*

---

**D C** - *19:50:28*

I know some of you run bots continuously so if you have never had this problem then it must be some junk code in my implementation

*Tags: General Technical*

---

**liam** - *19:54:04*

bflw creates a new market cache if img is True or if it doesn’t exist, doesn’t assume img has to be True. Docs aren’t clear 

*Tags: General Technical*

---

## 2022-02-11

**liam** - *08:53:38*

Along the lines of this Mo is there an easy way to add another box with a value, for example LTP or a model calculation etc?

*Tags: Strategies*

---

**Oliver Varney** - *10:09:57*

With the market recorder do people recorder all horse racing with one process? what do poeple market_filter look like? is it too heavy to do it all in one or not really anything to worry about?

*Tags: Data Quality*

---

**Stefan** - *16:07:25*

[@UUE6E1LA1](@UUE6E1LA1) any streaming api response has market id, so you can reload market data at any moment of processing streaming api message.  You can take inspiration from my code:



[https://github.com/StefanBelo/Betfair-Tutorials](https://github.com/StefanBelo/Betfair-Tutorials)



When running the code you will get following, and anytime a new football market is added, new market name is reported. When market is in-play it reports current score on football matches. The code is just simple example of using streaming api.



[https://youtu.be/R-TygYsjpxo](https://youtu.be/R-TygYsjpxo)

*Tags: General Technical*

---

## 2022-02-12

**Mo** - *07:53:14*

+1 for database table indexing S3 files

*Tags: General Technical*

---

## 2022-02-14

**Mo** - *10:08:28*

Can't see how to do it without touching IAM...

*Tags: General Technical*

---

**Fab** - *11:55:57*

I roughly follow these steps to create a dedicated IAM with programmatic access to a bucket (replace `new_user` with your friend name):



• Log into AWS using your root account.

• Top right, a dropdown has an option called My Security Credentials, click on it.

• On the left menu, go to Access Management &gt; Users.

• Create a new user (e.g. `new_user`) with Programmatic Access.

• Do not add it to a group nor assign any permissions for now.

• Towards the end of the creation steps, it shows you the user’s KEY/SECRET. Write it down.

• After creation, in the user list, click on the user and note down his ARN, it looks like:

*arn:aws:iam::168242217730:user/new_user*

• On the top menu, go to Services &gt; S3, then get into the desired bucket.

• Go to Permissions &gt; Bucket Policy.

• Enter a policy similar to the json below, you need to replace the user ARN (inside AWS) and the bucket name (inside Resource).

```{

    "Version": "2012-10-17",

    "Statement": [

        {

            "Sid": "AllowAccessToNewUser",

            "Effect": "Allow",

            "Principal": {

                "AWS": "arn:aws:iam::168242217730:user/new_user"

            },

            "Action": "s3:*",

            "Resource": [

                "arn:aws:s3:::thebucket",

                "arn:aws:s3:::thebucket/*"

            ]

        }

    ]

}```

*Tags: Deployment*

---

## 2022-02-15

**Oliver Varney** - *11:00:26*

as a benchmark, how long should it take to stream a pricing file using bflw, full updates with all performance settings (although with recalcs of traded_volumes)?

*Tags: Performance*

---

**Unknown** - *11:04:00*

Am I right in thinking debug got recently removed?

*Tags: Errors Debugging*

---

**Oliver Varney** - *11:07:59*

Is the structure of the market book identical in this library? I have to run a full batch of files through a process and grab some basic data, so im just looking to cut down time where possible. Im along way off 6 markets a second with bflw even with traded volume recalced turned off. Although im using betfairutils package directly

*Tags: Data Quality*

---

**Oliver Varney** - *11:35:12*

ah gotcha, unfortunately I need bflw. Ill play around, not sure how the benchmark is doing 45k message with bflw a second although it is an aussy file.

*Tags: General Technical*

---

**Oliver Varney** - *11:41:25*

```def read_prices_file(

    path_to_prices_file: str, lightweight: bool = True, **kwargs

) -&gt; Union[List[MarketBook], List[Dict[str, Any]]]:

    import smart_open

    from unittest.mock import patch



    trading = APIClient(username="", password="", app_key="")

    stream = trading.streaming.create_historical_generator_stream(

        file_path=path_to_prices_file,

        listener=StreamListener(

            max_latency=None, lightweight=lightweight, update_clk=False, **kwargs

        ),

    )



    with patch("builtins.open", smart_open.open):

        g = stream.get_generator()

        return list(mbs[0] for mbs in g())```



*Tags: Performance, Strategies*

---

## 2022-02-16

**Chris H** - *11:42:43*

Is it worth keeping track of `initialClk` and `Clk` to deal with streaming disconnections? Surely it's fine/ not that much work to just reconnect and received a fresh image? or is there something I am missing

*Tags: General Technical*

---

**liam** - *12:28:25*

the listener keeps track of it for you so you can do [https://github.com/liampauling/betfair/blob/0dd9c151d58ef1cfa065fa12dccd69e52104bc74/examples/examplestreamingerrhandling.py#L60|this](https://github.com/liampauling/betfair/blob/0dd9c151d58ef1cfa065fa12dccd69e52104bc74/examples/examplestreamingerrhandling.py#L60|this)

*Tags: General Technical*

---

**Chris H** - *12:32:21*

sure- my question was more that it seems like betfair providing this clk/ reconnect feature is pointless as you can just reconnect and received fresh image which will return your book to the correct state.



From the user perspective I'm not sure what using clk/initialclk adds other than some minor complication

*Tags: Feature Engineering*

---

**liam** - *14:07:53*

in the docs



```Performance tips



A single market subscription &amp; a subscription to all markets have an identical latency:

Cost is identical as the two subscriptions above would evaluate in sequence and thus with the same average latency.

Initial image is more costly to send than extra updates.

Limiting data with appropriate filters reduces initial image time

Segmented data will always out perform non-segmented data:

You will be processing a buffer while another is in-flight and another is being prepared to send

Writes to your connection are directly effected by how quickly you consume data &amp; clear your socket's buffer

Consuming data slowly is effectively identical to setting conflation.

If you receive con=true flag on a market - then you are consuming data slower than the rate of delivery.```

*Tags: Performance, Deployment*

---

**liam** - *14:08:12*

[https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-PerformanceConsiderations](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Exchange+Stream+API#ExchangeStreamAPI-PerformanceConsiderations)

*Tags: Performance*

---

**Jonjonjon** - *14:32:24*

Suppose I ran a script locally and it had no problems, but running it on AWS caused memory issues. How would you try to debug it? I have checked that I am running the same version of the script.

*Tags: Errors Debugging, Performance, Deployment*

---

## 2022-02-18

**bb** - *07:58:19*

I assume you are running it on EC2. One thing I have found is that the default swap is a lot lower than on my laptop and any memory spike above the limit caused crashes. 

*Tags: Performance, Deployment*

---

**D C** - *10:40:11*

For those of us who use TPD stuff, has anyone ever tried to create a model like the one that TPD sell to bookies (or at least what I imagine that model/product is)? Essentially a model that updates prices from start to finish ?

*Tags: Strategies*

---

**liam** - *10:51:15*

there isn't really, first 50% of a race there tends not to be too much value (as you know) so even having a decent model isn't much to take advantage

*Tags: Strategies*

---

## 2022-02-20

**D C** - *13:15:44*

Question for the python gurus: Just started using python properly for data analysis and stuff so really feeling my way so far - is there a utility for 3d surface plots over an irregular mesh? Assuming not (most likely) is there something for surface over regular mesh or failing that a heatmap utility? Failing that (although it is essentially the same thing), an x,y,x bar chart over regular mesh?

*Tags: General Technical*

---

## 2022-02-21

**D C** - *09:31:08*

Do people use multiple github accounts for extra security on their code base for their production level code? Or is it generally accepted that a private github repo is sufficient for the task?

*Tags: Deployment*

---

**Mark** - *10:18:36*

May be worth looking at Plotly to see if it suits your needs. It has a number of 3D graphs and it looks like it's fairly easy to pick up quickly. [https://plotly.com/python/3d-surface-plots/](https://plotly.com/python/3d-surface-plots/)

*Tags: General Technical*

---

## 2022-02-22

**Jonjonjon** - *22:54:04*

I'm trying to understand the `market_exposure` function here: [https://github.com/liampauling/flumine/blob/bc4d18a941778f41087b055c5c8d3f00ccd63201/flumine/markets/blotter.py#L137-L154](https://github.com/liampauling/flumine/blob/bc4d18a941778f41087b055c5c8d3f00ccd63201/flumine/markets/blotter.py#L137-L154)



Does anyone have a dummies explanation for why it results in the worst possible loss?

*Tags: General Technical*

---

## 2022-02-23

**D C** - *07:41:49*

I have a similar function in my setup so I can turn off the bet placement tap if it gets hit so I can have a max loss per market to save the bankroll

*Tags: Getting Started*

---

**Jonjonjon** - *21:19:16*

[@U4H19D1D2](@U4H19D1D2) Would you be happy if I added a trading control to limit the max exposure of a strategy?

*Tags: Strategies*

---

**Jonjonjon** - *21:36:42*

I think I might have worded my question incorrectly.:flushed:

I was referring to the `market_exposure` I can't find a control that uses it.

*Tags: General Technical*

---

## 2022-02-24

**liam** - *12:08:46*

Currently refactoring flumine for multi clients (likely to be a v2 bump due to the number of changes and renames), any feedback on this [https://github.com/liampauling/flumine/blob/8fe3329734b3a24aa425caf25d979b56a3cb8fce/docs/clients.md|API](https://github.com/liampauling/flumine/blob/8fe3329734b3a24aa425caf25d979b56a3cb8fce/docs/clients.md|API) welcomed.



Initial release would be the limited in use but future work would allow orders/execution via the framework and the addition of further ExchangeTypes (betdaq etc)

*Tags: Multi Client*

---

## 2022-03-02

**liam** - *13:23:26*

[https://www.totalperformancedata.com/news-all/2022/3/2/total-performance-data-signs-landmark-multi-year-deal-with-jockey-club-of-saudi-arabia|:eyes:](https://www.totalperformancedata.com/news-all/2022/3/2/total-performance-data-signs-landmark-multi-year-deal-with-jockey-club-of-saudi-arabia|:eyes:)

*Tags: Performance*

---

## 2022-03-11

**liam** - *16:38:39*

Anyone see any issues with this? Takes a list of dictionaries and returns a random one based on the marketId, ie a list of `strategy.context`



```def _get_rand_context(market_id: str, context: list[dict]) -&gt; dict:

    id_ = int(market_id[2:])

    r = (0.5 + _INVERSE_GOLDEN_RATIO * id_) % 1

    count = len(context)

    x = [(i * (1 / count)) for i in range(1, count + 1)]

    for i, y in enumerate(x):

        if r &lt; y:

            return context[i].copy()

    return context[-1].copy()



context = _get_rand_context("1.23", [{"a": 1}, {"a": 2}, {"a": 3}])```

*Tags: Strategies*

---

## 2022-03-12

**Jonjonjon** - *10:18:42*

Has anyone tried using an apple m1 ultra with Flumine?

*Tags: General Technical*

---

**Unknown** - *10:41:05*

It doesnt release for a few more days. But it has the same cpu cores as the m1Pro/m1Max so you can expect basically equivalent performance. (maybe a little higher if they clock it higher as theres not battery/power draw concerns)

*Tags: Performance*

---

**Jonjonjon** - *11:33:52*

I read that it's geekbench score is as good as the top threadripper. But don't know how that will compare when using Flumine. Also not sure if it will be good value. How many days/weeks profit are people willing to spend on a new PC?

*Tags: General Technical*

---

**Alex Alex** - *12:32:06*

Provided that flumine is python I would be surprised if you see a huge performance boost by buying a m1 ultra over something with less cores unless you have lots of code that releases the GIL.

*Tags: Performance*

---

**Oliver Varney** - *12:59:17*

Also if you don't mind, and I'm only asking all these questions as I'm a noob in this area, but what does that cost looks like. Many small instances or fewer larger compute instances ?

*Tags: General Technical*

---

**Mo** - *13:14:38*

Very roughly I would say that's split 3 ways between database, storage and servers

*Tags: Deployment*

---

**D** - *13:22:01*

My costs are about 10% of Mo's - spread mainly across a single ec2 server, S3/Athena data storage, sagemaker usage. I aspire to Mo's level of expenditure though.

*Tags: Deployment*

---

**Oliver Varney** - *13:41:32*

I guess another interesting question is whether people are using swarm or kubernetes ?

*Tags: General Technical*

---

**liam** - *17:15:02*

About 10 ec2 instances micro/small, RDS aurora (master/replica) I think it's two mediums, few £ on s3, cloudwatch and lambda 

*Tags: Deployment*

---

**thambie1** - *18:10:02*

I spend ~$100 a month on a single 8 core dedicated  machine for production. And maybe an avg of ~$1k a month on analysis computations done in the cloud

*Tags: Deployment*

---

**Oliver Varney** - *18:19:29*

Again maybe a silly question but do people run multiple envs, I.e. dev,stag,prod etc?

*Tags: General Technical*

---

**Oliver Varney** - *18:24:59*

I guess it depends on complexity, and proper gabion of errors.

*Tags: Errors Debugging*

---

**Mo** - *19:13:36*

Have production and test servers both running live trading code. New features get live tested before going into production

*Tags: Feature Engineering, Deployment, Strategies*

---

**VT** - *20:22:41*

Betfair with a lot of problems in the football api today, markets were open after the goal, games were finished before it ended. It's a mess.

*Tags: General Technical*

---

**VT** - *22:57:37*

Yes, this game also had a problem, the market was open in the extra time.

*Tags: General Technical*

---

## 2022-03-13

**Dave** - *13:01:19*

Premium charge should be reduced by a Betfair error factor :)

*Tags: Errors Debugging*

---

## 2022-03-14

**liam** - *09:13:45*

Just in case anyone finds this useful, this is working well in a flumine strategy:



```def get_context(self, market_id: str = None) -&gt; dict:

    if "AB" in self.context:

        _context = self.context["AB"]

        ab_context = self._get_rand_context(market_id, _context)

        context = {}

        for k, v in self.context.items():

            if k == "AB":

                continue

            if k in ab_context:

                context[k] = ab_context.pop(k)

            else:

                context[k] = v

        for k, v in ab_context.items():

            context[k] = v

        return context

    else:

        return self.context



@staticmethod

def _get_rand_context(market_id: str, context: List[Dict]) -&gt; dict:

    id_ = int(market_id[2:])

    r = (0.5 + _INVERSE_GOLDEN_RATIO * id_) % 1

    return context[int(r // (1 / len(context)))].copy()```

```Strategy(

    context={

        "AB": [

            {"bankroll": 1},

            {"bankroll": 1.3},

            {"bankroll": 1.5},

        ],

        "var_one": "LAY",

        "var_two": True,

    }

)```

*Tags: Strategies*

---

**D C** - *14:00:38*

I've been starting to use Python to perform logistic regression but struggling to find a way to model interaction effects. In R this is easy. I've tried sklearn and statsmodels but so far can't see an easy way to do this as both make use of the dataframe columns you provide. I am brand new to this in a python setting so may have missed something obvious but is there a simple way to do this or am I better off (from speed point of view) sticking with R ?

*Tags: Getting Started, Feature Engineering, Performance, Strategies*

---

**Oliver Varney** - *14:03:18*

although interaction effects im not sure about that tbh though, isnt that more stats based models?

*Tags: Strategies*

---

**Mo** - *14:04:24*

I've trod the same path as you and haven't found anything in Python as good as R. Luckily I'm not doing as much stats as I used to

*Tags: General Technical*

---

**D C** - *14:06:18*

OK cheers Mo. I guess I will stick with R. I've been getting a bit fed up with my setup as I have various bits and pieces in JS/C++/Python and was hoping to get a more uniform setup together. Was hoping that I would easily be able to just switch from R to Python but I guess not.

*Tags: Getting Started*

---

**Mo** - *14:08:33*

Depends what you are doing, `statsmodels` is decent just not as good as base R. You can always use `rpy2` to call R code from Python if that helps

*Tags: Strategies*

---

**D C** - *14:10:13*

Yeah I definitely prefer the statsmodels so far as at least you can get p-vals and parameter CI. Never even heard of rpy2 but that sounds like a great solution.

*Tags: Strategies*

---

**Alex Alex** - *15:34:23*

Did you have a look at `sklearn.preprocessing.PolynomialFeatures` ([https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)) I’m not sure how the R implementation differs from the PolynomialFeatures. Generally I occasionally use sklearn for this purpose and never found it too bad. You can neatly package this into a pipeline with whatever model you want to run afterwards.

*Tags: Feature Engineering, Strategies*

---

**D C** - *15:49:52*

I basically just want to be able to model using GLMs in a similar manner to that of R so that I can do model validation, residual checks and all the other stuff. This PolynomialFeatures looks to be more useful for pure approximation problems rather than inference. I am clearly going to have to get used to changes in terminology over the last 20 years. What seems now to be called a "feature" we used to call an explanatory or dependent variable. Similarly design matrix (or observation matrix) now seems to be called feature matrix. I guess this is ML based terminology superceding the stats/approximation theory lingo now. I'll stick with R for now as I don't want to be creating extra columns myself to try to model interaction effects.

*Tags: Feature Engineering, Strategies*

---

**Peter** - *16:09:06*

LOL [@UUE6E1LA1](@UUE6E1LA1). You had it easy. I was pumped to find that my Masters dissertation (based on the results of models and data coded on punch cards  loaded and run overnight on a mainframe) still had value. But then had 40 years of catching up to do.

*Tags: Strategies*

---

**D C** - *16:27:40*

If you are modelling a sport, do you ever "split" the modelling in the sense of using separate models across (fairly) homegeneous groupings? I am thinking along the lines of football - would you have many per-league models, or have the league as a cateregorical variable within a single more generic model? What about in the cases of differing environments? For example, if you were modelling snooker, you would not expect there to be much difference between venues. But for something like modelling total score in a baseball game, there are clear outliers (it was or still is the case that average runs per game at colorado games was higher due to the altitude above sea level) - would you model this venue seperately or place venue as a categorical variable within a broader model? These are not the best examples but the best I could think of but I am really interested in people's approaches or if there is a theoretically sound best practice for this kind of modelling?

*Tags: Strategies*

---

**Peter** - *18:01:40*

I try both ways. It's a balance between having a bigger dataset to model with versus and the potential of increased precision when targeting different models to different circumstances. There's not one answer. You have to suck and see which generates the best results for the specific sport.

*Tags: Strategies*

---

**Peter** - *18:02:40*

My starting point is to use a categorical variable in statsmodel and look at the coefficients and the p-test results to see whether the feature on which I might split has the variability and significance to justify a split.

*Tags: Feature Engineering, Strategies*

---

**D C** - *18:38:06*

Yeah I can see the sense in that. Parameter selection is usually about balance anyway. I suppose I was thinking about things untuitively or where there is an obvious bias. For example I don't know for certain but I would imagine that total points in NBA is consistent on a per venue basis as all basketball courts have the same dimensions so I would probably not even look at it. But the baseball venue altitude is a "known" thing. I suppose there though you are getting close to the edge of fundamentals based modelling as stuff like weather and humidity come into play. Was really just trying to get a feel for the general opinion on these types of problem.

*Tags: Strategies*

---

## 2022-03-20

**D C** - *11:04:20*

Does python/numpy have options for elementwise multiplication of matrices of same dimensions? Specifically I am looking for the python equivalent to matlab or octave  `A ./ B`  if it exists?

*Tags: General Technical*

---

**Josh** - *18:34:09*

You don't need to use the named functions in most cases as `a * b`  (where `a` and `b` are numpy arrays) and other operators are element-wise. See the note at the bottom of the docs for [https://numpy.org/doc/stable/reference/generated/numpy.multiply.html|np.multiply](https://numpy.org/doc/stable/reference/generated/numpy.multiply.html|np.multiply) and others. You can also perform all of the basic element-wise operations on arrays with different dimensions as long as the dimensions are compatible according to [https://numpy.org/doc/stable/user/basics.broadcasting.html|broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html|broadcasting rules).

*Tags: General Technical*

---

## 2022-03-22

**Unknown** - *08:21:02*

Interesting meetup on the AUS slack about AFL modelling from Michael Lean, given me a few ideas on other sports..

*Tags: Strategies*

---

**LM** - *09:21:09*

awesome thanks for your help

*Tags: General Technical*

---

**LM** - *09:31:06*

Something like this (reference for anyone wondering):

```def process_orders(self, market, orders):

    for order in orders:

        # kill order if unmatched in market for greater than 5 seconds

        if order.status == OrderStatus.EXECUTABLE and order.side == 'BACK':

            if order.elapsed_seconds and order.elapsed_seconds &gt; 5:

                market.cancel_order(order)



        # create lay order if back order was matched  

        if order.status == OrderStatus.EXECUTION_COMPLETE and order.size_matched &gt; 0:

            

            market_id, selection_id, handicap = order.lookup

            

            trade = Trade(

                market_id=market_id,

                selection_id=selection_id,

                handicap=handicap,

                strategy=self,

            )

            # create order

            order = trade.create_order(

                side="LAY",

                order_type=LimitOrder(lay_price, order.size_matched),

            )

            # place order for execution

            market.place_order(order)```

*Tags: Strategies*

---

**LM** - *09:39:32*

This should handly it pretty easily?

```            # create lay order if back order was matched  

            if order.status == OrderStatus.EXECUTION_COMPLETE and order.size_matched &gt; 0:

                

                market_id, selection_id, handicap = order.lookup

                

                runner_context = self.get_runner_context(

                        market_id, selection_id

                    )

                if runner_context.trade_count == 1:

                

                    trade = Trade(

                        market_id=market_id,

                        selection_id=selection_id,

                        handicap=handicap,

                        strategy=self,

                    )

                    # create order

                    order = trade.create_order(

                        side="LAY",

                        order_type=LimitOrder(lay_price, order.size_matched),

                    )

                    # place order for execution

                    market.place_order(order)```

*Tags: Strategies*

---

**LM** - *09:43:55*

Thanks heaps for your help!

*Tags: General Technical*

---

**LM** - *09:46:48*

One other question... If check_market_book returns false I know that process_market_book isn't executed. But I'm assuming process_orders is still run?

*Tags: General Technical*

---

**Jonjonjon** - *22:03:02*

What sort of POT figures to people consider respectable, and why is it important? I've just calculated the statistic for a model I'm calibrating. Just considering the back side, the POT is 0.6%.

*Tags: Strategies*

---

**James T** - *22:31:18*

For pre-play I would generally want more than 1% profit on stakes. 0.6% is a little low, since you're likely to loose a little to slippage / moving the market if you are taking volume once you go live. Or if you are offering then you'll have unmodelled adverse selection. 0.6% is just a bit too low on margin for it to be realistic and scalable. Might depend on when you are trading though, and how much you are trading (combining backs and lays) vs taking large outright bets.

*Tags: Deployment, Strategies*

---

**James T** - *22:37:59*

If you're taking, you can always simulate sensitivity to latency (slippage), but you won't be able to simulate how much you might move the market. Also I don't know how flumine simulates taking volume (e.g. does it simulate removing it from the book so you can't take it twice?)

*Tags: Performance*

---

**Jonjonjon** - *22:52:31*

At the moment, I don't think it simulates taking volume. By default it has 0.15 seconds of latency, but I increased it to 0.5 seconds for safety.

*Tags: Performance*

---

## 2022-03-23

**James T** - *00:14:45*

I'd test with more data, and see whether you have a decent edge betting outright or not (no hedge). But that's a riskier route. You'd want a few months of data.



If your strategy is purely price action based then you're never going to get a massive margin when taking volume anyway. Offering may be better, but that's harder to test.



I'd recommend just trying it live with small stakes and see whether you can realise that 0.6% or not. If your backtest says you should be getting 95% positive days when hedging out, but the first day you try you lose money, then you can quickly just say it's back to the drawing board.



You're probably not far off having something though.

*Tags: Deployment, Strategies*

---

**Peter** - *08:27:32*

I agree with [@USYQKE5HN](@USYQKE5HN). It's imperative that you test with more data. Two weeks isn't very long for the dogs. Although you get a lot of races, the narrowness of the grading bands means there's also a lot of unpredictability in the race results and the type of strategy you're testing, i.e. dependant on a few big wins will be very sensitive to the number of wins you manage to pick.

*Tags: Strategies*

---

**Peter** - *12:16:14*

Over the years I've found all the sources to provide very similar data, even down to the same errors. The two that I find it easiest to extract data from are the Greyhound Board of Great Britain and Sporting Life.

*Tags: Errors Debugging*

---

## 2022-03-24

**D C** - *16:29:25*

Does anyone here write their own betdaq bot? I have just started writing one for someone else but the documentation is painful (not to mention it being a SOAP API). Doesn't seem to be many github projects either and none that are recent. Trying to use nodejs for this currently but thinking of using one of these ancient githun python projects - has anyone else used these before with any success?

*Tags: General Technical*

---

**Peter** - *16:46:14*

I've looked a few times but been put off by both the SOAP aspect and the documentation. However, that their documentation actually lauds the SOAP approach suggests that it's very long in the tooth and that those old wrappers may therefore still be fit for purpose.

*Tags: General Technical*

---

**liam** - *16:53:22*

Last time I looked at their website it was using a much a nicer REST API with some sort of socket/streaming however when I asked they had no plans to make it 'public'

*Tags: General Technical*

---

**D C** - *16:55:44*

I'd heard that Ladbrokes sold it back to the original owner so was hoping that might be a return to a true exchange focused business model. I suppose even if that were true it would take time to change things around and modernise it. SOAP just feels dirty to me in this day and age.

*Tags: Strategies*

---

## 2022-03-27

**Mo** - *12:21:55*

Because the reason it exists in the first place is a regulatory requirement and regulations vary between jurisdictions. It's a reasonable question

*Tags: General Technical*

---

**Dave** - *12:27:31*

fascinating, it was a genuine question btw - so BPE is enforced on orders from ireland? :face_with_monocle:

*Tags: General Technical*

---

**mandelbot** - *12:31:28*

I'm only asking because I believe I have it toggled off yet my account details shows

```{"asctime": "2022-03-27 10:59:58,616", "levelname": "INFO", "message": "Client update account details", "username": "username", "exchange": "Betfair", "betting_client": "APIClient", "current_transaction_count_total": 0, "transaction_count_total": 0, "trading_controls": ["&lt;flumine.controls.clientcontrols.MaxTransactionCount object at 0x0000023775B21D00&gt;"], "order_stream": false, "best_price_execution": true, "paper_trade": false}```

`"best_price_execution": true`

*Tags: Strategies*

---

**Mo** - *12:32:52*

Isn't that just a flumine setting for simulation?

*Tags: General Technical*

---

**Mo** - *17:39:58*

Depends on the strategy

*Tags: Strategies*

---

**Mo** - *22:10:45*

Can anyone advise how to profile a Python extension written in Rust using PyO3?

*Tags: General Technical*

---

**Jonjonjon** - *23:39:09*

When using Flumine to run live trading on cloud servers, do people tend to to for shared or dedicated CPUs?

*Tags: Deployment, Strategies*

---

## 2022-03-28

**Mo** - *05:04:58*

Not a flumine user so speaking more generally here but shared. Dedicated is quite expensive 

*Tags: General Technical*

---

**Mo** - *06:30:27*

Answering my own question: [https://github.com/benfred/py-spy](https://github.com/benfred/py-spy)

*Tags: General Technical*

---

**PeterLe** - *08:08:12*

just to add; i did some test many years ago on Virtual V Dedicated, using similar specs and the exact same strategy, and then comparing the betids, I found the dedicated to be marginally slower (and more expensive as Mo has stated)

*Tags: Performance, Strategies*

---

**Mo** - *08:09:19*

I doubt you will notice a difference unless you are extremely latency sensitive

*Tags: Performance*

---

**Jonjonjon** - *08:31:59*

Also, I'm running around 4 Flumine instances on the 2vcpu machine that I am running the problematic script on. So perhaps I should just move it onto it's own machine. Whether that's a 1vcpu or 2vcpu machine, I'm not sure yet.

*Tags: General Technical*

---

**Jorge** - *09:33:28*

I use a AWS Instance with Tenancy=Default, I haven't had any problem with it. Tenancy=Dedicated is more expensive

*Tags: Deployment*

---

**VT** - *17:42:37*

After this perfect explanation the problem is solved.

*Tags: General Technical*

---

## 2022-03-29

**Oliver Varney** - *05:15:00*

whilst he should be,  im not too sure the situation has changed. No one has performed well enough to take over. he should of been out ages ago. Strange for someone who plays cricket their whole life, not to have that cricketing sense of game management /  how to manufacturer wickets etc. Hes not been dealt the best hand though

*Tags: General Technical*

---

## 2022-03-30

**Aaron Smith** - *19:46:09*

can someone explain `conflate_ms`  from flumine BaseStrategy to me? I see this will determine how often i get a market_book update, but how exaclty does it work? Is it still receiving all market_books and every conflate_ms millis it sends the newest one through? Also what are reason to set this to any specific value? Could i miss the the market_book update where the market closes (and would trigger process_closed_market) if i set it to a higher value? Pretty sure last one wont be the case, but i want to rule it out :smile:

*Tags: Strategies*

---

## 2022-04-03

**Ruben** - *10:05:05*

good morning, does anyone know of a way to print progress while backtesting with flumine? Something like "90 out of 1000 markets done"

*Tags: General Technical*

---

**Ruben** - *11:27:22*

to use this I should make my own backtest from the FlumineBacktest class; or do you suggest running an instance of FlumineBacktest for every market, in a loop?

*Tags: General Technical*

---

**liam** - *11:39:20*

Nah, chunk into 8 markets (prevents memory leaks) some code that might help



```chunk = 8

total = len(all_markets) / chunk

for markets in tqdm(chunks(all_markets, chunk), total=int(total)):

    run_process(markets)```



*Tags: Performance*

---

**D C** - *20:15:21*

Is it ever possible to get a virtual price that is worse than a non-virtual price? It seems a stupid question I am sure, but I just want to check because I am debugging something that is showing me a lower non-virtual LAY price than the virtual price. Seems to happen only for prices in the high 3 digit ranges. Just want a sanity check really before digging deeper

*Tags: Errors Debugging*

---

## 2022-04-06

**D** - *16:03:29*

I tend to use the aws wrangler library from aws. Not sure if it's the fastest but is very convenient.

*Tags: Deployment*

---

**Oliver Varney** - *17:19:15*

ended up going with aws cli which seems to be faster then boto3 threading but as youve said I think network is the main issue

*Tags: Deployment*

---

**Mo** - *17:27:54*

I remember AWS had a service where you could mail them a hard drive. Unfortunately it no longer seems to exist

*Tags: Deployment*

---

**Alessio** - *17:33:41*

[https://aws.amazon.com/snowball/pricing/](https://aws.amazon.com/snowball/pricing/)

*Tags: Deployment*

---

## 2022-04-13

**Nacho Uve** - *09:14:42*

I'm trying to use betfairviz.create_dashboard.



The module is imported correctly and MarketBooks are rendered as expected in jupyter notebook.



But when I call ``betfairviz.create_dashboard(prices)`, being `prices` a dict obtained with `betfairutil.read_prices_file` nothing happens. No error neither visualization of the widget.



Any clue to what I'm doing wrong?

*Tags: Errors Debugging*

---

**Nacho Uve** - *09:16:32*

Solved.

It looks that `plotly` was not properly installed. After reinstall and restart jupyter notebook it works.

*Tags: Getting Started*

---

**Aaron Smith** - *09:50:25*

had this happen to me aswell when placing a high number of bets in a short amount of time and i ve seen others encounter this too. For me the solution was to chunk bets together into 1 transaction.

check [https://github.com/liampauling/flumine/blob/master/flumine/execution/transaction.py](https://github.com/liampauling/flumine/blob/master/flumine/execution/transaction.py)

Obviously only possible when you actually place a bunch of orders on the same market_book update

*Tags: General Technical*

---

**D C** - *09:53:03*

I don't use flumine/bflw but I batch multiple orders per strategy (but have about 14 strategies run concurrently) so even placing large numbers of bets at once it is already going to be split over fewer than 10 calls to placeOrders.

*Tags: Strategies*

---

**D C** - *09:54:24*

I think the problem is coming from too many calls and I possibly need to add some kind of throttle or minimum delay between successive calls to see if it improves things. 12 second delay between transmission of request and receipt of response in a live horse race is ridiculous

*Tags: Deployment*

---

**Mo** - *14:36:52*

Yes, something like this:



```import pandas as pd



import betfairutil

import betfairviz



market_books = betfairutil.read_prices_file('../betfair-hackathon-2021/1.176457983.bz2')



volumes_traded = pd.Series(betfairutil.calculate_total_matched(mb) for mb in market_books).diff()



points_of_interest = [

    betfairviz.PointOfInterest(

        text='Market suspension at ' + betfairutil.publish_time_to_datetime(mb['publishTime']).strftime('%Y-%m-%d %H:%M:%S.%f'),

        timestamp=betfairutil.publish_time_to_datetime(mb['publishTime'])

    )

    for prev_mb, mb in zip(market_books, market_books[1:]) if mb['status'] == 'SUSPENDED' and prev_mb['status'] != 'SUSPENDED'

]



betfairviz.create_dashboard(market_books, points_of_interest=points_of_interest)```

*Tags: Feature Engineering*

---

**D C** - *16:33:16*

I was running another strategy on another box and didnt have the same issues.

*Tags: Strategies*

---

**Paul** - *23:34:02*

There's a service where you can get a lorry full of hard drives. Snowball edge is the more common variant though: [https://aws.amazon.com/snowball/|https://aws.amazon.com/snowball/](https://aws.amazon.com/snowball/|https://aws.amazon.com/snowball/)

*Tags: Deployment*

---

## 2022-04-17

**D C** - *11:34:14*

If you place a bet using the async flag on the API placeOrders operation, can you get a FAILURE state in the response? Docs are somewhat unclear here. For example, if I have a bug and I am trying to place something with async flag at an INVALID price will I still get a PENDING status or does the server filter out my error immediately?

*Tags: Errors Debugging, Deployment*

---

## 2022-04-18

**ShaunW** - *21:19:29*

Nice of you to ask [@UBS7QANF3](@UBS7QANF3) but after all that.... Err no. So don't do anything special on my behalf. :blush:   I quite like a trip into town tbh but last couple of times it seems like too much agro...(I'm not a python guy so limitted appeal anyway). But I know there's plenty of people north of Watford so was curious to see if there was a big vote for anywhere else.

*Tags: General Technical*

---

## 2022-04-20

**Troy Edwards** - *10:02:20*

Hey guys - I have been storing data in a BINARY file because I had structures within structures.  Today I ran out of memory and I know its time to go to SQL.  So I added a local MDF local database to my Visual Studio, created a table and tested access but I can't get it to work ?



Dim myDataReader As SqlDataReader

Dim myConnection As SqlConnection

Dim myCommand As SqlCommand

Dim strSQL As String



myConnection = New SqlConnection("Data Source=(LocalDB)\MSSQLLocalDB; Initial Catalog=C:\CODE\BETFAIR ARB\PREVIOUS DATA\PreviousRaceData.mdf")

myConnection.Open()



strSQL = "SELECT ID FROM dbo.tblCompletedRaces"

myCommand = New SqlCommand(strSQL, myConnection)



myDataReader = myCommand.ExecuteReader()



If myDataReader.Read() Then

            Debug.Print(myDataReader.Item("Runnername"))

        Else

            MsgBox("Didn't work...")

        End If

Any ideas :disappointed:

*Tags: Errors Debugging, Performance*

---

**liam** - *10:14:15*

quick fix is use a db such as postgres or MySQL

*Tags: Errors Debugging*

---

**liam** - *10:14:44*

but any error message on this?

*Tags: Errors Debugging*

---

**Troy Edwards** - *10:33:38*

Ta Liam it errors at

        myDataReader = myCommand.ExecuteReader()



and the message is Invalid Object name???

*Tags: Errors Debugging*

---

**Troy Edwards** - *11:01:50*

Hmmm when I entered that SQL statement there was no error at myDataReader = myCommand.ExecuteReader()

*Tags: Errors Debugging*

---

**liam** - *11:23:19*

I am not sure tbh, but I would focus on getting a simple query to work to check your connection/access as that looks to be the problem

*Tags: General Technical*

---

## 2022-04-21

**liam** - *09:04:51*

Maybe, personally thinking TA was a thing severely stunted my advances in strategy development

*Tags: Strategies*

---

**Jonjonjon** - *11:19:52*

i thought most people here used price action as the primary input of their models?

*Tags: Strategies*

---

**Unknown** - *20:33:53*

This is a real P&amp;L from a pure TA strategy. Implemented 100% in Flumine. It doesn't make a lot, but the result is definitely consistent.

*Tags: Strategies*

---

## 2022-04-22

**liam** - *14:54:57*

His satellite helps 

*Tags: General Technical*

---

**ShaunW** - *15:22:58*

TA isn't just using numbers, like price or volume, it's a term to describe looking for patterns in market data to identify trends, and seeing as there's almost no similarity between a sports market and any other type of market it's very unlikely there's much crossover.  But, TA will always get mentioned because sports gambling has never been shy of trying to borrow credibility from established forms of trading whether it's helpful or not.

*Tags: Strategies*

---

**Aaron Smith** - *17:48:13*

Its kinda sad considering all the effort put into programming and maths, but my most successful day was when i had a few beers and put 200bucks on a horse that i thought looked nice. Despite its good results, i decided to not further investigate that strategy.

*Tags: Strategies*

---

## 2022-04-23

**Newbie99** - *18:13:37*

Prior to the recent breaking changes to Flumine, I used to call list_current_orders as follows, from Middleware to avoid logging in separately via BFLW:



```self.flumine.client.betting_client.betting.list_current_orders(PARAMS)```

I haven't so far, been able to work out the new syntax, to be able to do the same, presuming it's still possible, could anyone point out what I need to change, I can't seem to figure it out from the docs?

*Tags: Strategies*

---

**Lee** - *18:21:49*

Try something like

```client = self.flumine.clients.get_betfair_default()

client.betting_client.betting.list_current_orders(PARAMS)```

*Tags: Strategies*

---

## 2022-04-24

**Newbie99** - *13:46:26*

I'm sure this has been asked before, but just wanted to double check as I couldn't find it.



This message simply means the publish time is x seconds ago and that could be because its a slow market (in this case tournament outright winner, which genuinely can go for some time without updates), but doesn't indicate a problem:



```WARNING:flumine.baseflumine:High latency between current time and MarketBook publish time

{"asctime": "2022-04-24 12:41:12,737", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.182979902", "latency": 61.23844265937805, "pt": "2022-04-24T12:40:11.499000"}```

Whereas this, suggests latency due to code / connection (or some other factor) and could indicate a problem:



```WARNING:betfairlightweight.streaming.stream:[MarketStream: 2001]: Latency high: 0.5573089122772217

{"asctime": "2022-04-24 12:41:50,796", "levelname": "WARNING", "message": "[MarketStream: 2001]: Latency high: 0.5573089122772217"}```

*Tags: Performance*

---

## 2022-04-25

**Newbie99** - *09:29:40*

```import logging

from flumine import config

from flumine.utils import STRATEGY_NAME_HASH_LENGTH

from flumine.markets.middleware import Middleware

from flumine.order.trade import Trade

from misc_functions import get_utc_time

from datetime import datetime

import pytz



logger = logging.getLogger(__name__)





class OrdersMiddleware(Middleware):

    """

    Middleware to add execution complete orders

    to the blotter. This is required on a restart

    as the order stream does not include

    EXECUTION_COMPLETE orders

    """



    def __init__(self, flumine):

        self.flumine = flumine



    def add_market(self, market) -&gt; None:

        ''' This checks each market, subject to the below filters (if the check is True then it will call list_current_orders) '''



        ''' Checks to see if the market is politics (2378961) or if it is due to start within the next 20 mins for others...hardcoded, may need to change.'''

        if market.seconds_to_start &lt;= 1200 or str(market.event_type_id) == str(2378961):



            ''' Calls list_current_orders and loops through if there are more than 1000 '''

            current_order_list = get_current_orders_flumine(self, 'ALL', market=market, all_market_orders=True)



            ''' If the output of current_order_list is non zero then checks the market_book to get runner info to use later...if the market_book hasn't loaded makes

             a call to the API to get the latest market_book'''

            if len(current_order_list) &gt; 0:

                if market.market_book is None:

                    market_book = self.flumine.clients.get_betfair_default().betting_client.betting.list_market_book(market_ids=[market.market_id])[0]

                    # market_book = self.flumine.client.betting_client.betting.list_market_book(market_ids=[market.market_id])[0]

                else:

                    market_book = market.market_book



                ''' Creates a list of Active runners (so that non-active runners are not included later when orders are created) '''

                runner_list = [(str(runner.selection_id), str(float(runner.handicap))) for runner in market_book.runners if runner.status == 'ACTIVE']

                for current_order in current_order_list:

                    if (str(current_order.selection_id), str(float(current_order.handicap))) in runner_list:

                        if current_order.customer_strategy_ref != config.hostname or current_order.status not in ['EXECUTABLE']:

                            if str(current_order.bet_id) not in [str(o.bet_id) for o in market.blotter]:

                                [http://logger.info|logger.info](http://logger.info|logger.info)(

                                    "OrdersMiddleware: Processing order {0}".format(current_order.bet_id),

                                    extra={

                                        "bet_id": current_order.bet_id,

                                        "market_id": current_order.market_id,

                                        "customer_strategy_ref": current_order.customer_strategy_ref,

                                        "customer_order_ref": current_order.customer_order_ref,

                                    },

                                )

                                order = self._create_order_from_current(current_order, market)

                                if order:

                                    order.update_current_order(current_order)

                                    if current_order.status == "EXECUTION_COMPLETE":

                                        order.execution_complete()

                                    else:

                                        # if order.bet_id not in [o.bet_id for o in market.blotter]:

                                        order.executable()

                                    # order.execution_complete()



        ''' Adds flag to market.context, so market is not processed until all orders added '''

        if 'order_startup_process_time' in market.context.keys():

            market.context.update({'order_startup_process_time': get_utc_time()})

        else:

            market.context['order_startup_process_time'] = get_utc_time()



    def _create_order_from_current(self, current_order, market):

        ''' Some legacy Politics markets had manual orders, this assigns a strategy to them '''

        legacy_market_id_list = ['1.160740937',

                                 '1.129176457',

                                 '1.160683973',

                                 '1.160843673',

                                 '1.176878927',

                                 '1.166577732',

                                 '1.160663234',

                                 '1.167249009'

                                 ]

        # strategy_name_hash = current_order.customer_order_ref[

        #     :STRATEGY_NAME_HASH_LENGTH

        # ]

        # order_id = current_order.customer_order_ref[STRATEGY_NAME_HASH_LENGTH + 1 :]

        if current_order.market_id in legacy_market_id_list:

            if current_order.side == 'BACK':

                strategy_name_hash = 'd0df7e7076e65'

            else:

                strategy_name_hash = '3203239236f2d'

            order_id = current_order.bet_id

        else:

            strategy_name_hash = current_order.customer_order_ref[

                                 :STRATEGY_NAME_HASH_LENGTH

                                 ]



            order_id = current_order.customer_order_ref[STRATEGY_NAME_HASH_LENGTH + 1:]

            # Had to put this in, so that replace orders were picked up correctly (otherwise it thinks they are already in the blotter and doesn't add the latest)

            # order_id = current_order.bet_id

        # get strategy

        strategy = self.flumine.strategies.hashes.get(strategy_name_hash)

        if strategy is None:

            logger.warning(

                "OrdersMiddleware: Strategy not available to create order {0}".format(

                    order_id

                ),

                extra={

                    "bet_id": current_order.bet_id,

                    "market_id": current_order.market_id,

                    "customer_strategy_ref": current_order.customer_strategy_ref,

                    "customer_order_ref": current_order.customer_order_ref,

                    "strategy_name": str(strategy),

                },

            )

            return

        # add trade/order

        trade = Trade(

            market.market_id,

            current_order.selection_id,

            current_order.handicap,

            strategy,

        )



        order = trade.create_order_from_current(client=self.flumine.clients.get_betfair_default(), current_order=current_order, order_id=order_id)

        market.blotter[order.id] = order

        runner_context = strategy.get_runner_context(*order.lookup)

        runner_context.place(trade.id)

        [http://logger.info|logger.info](http://logger.info|logger.info)(

            "OrdersMiddleware: New order trade created",

            extra={

                "bet_id": current_order.bet_id,

                "market_id": current_order.market_id,

                "customer_strategy_ref": current_order.customer_strategy_ref,

                "customer_order_ref": current_order.customer_order_ref,

                "strategy_name": str(strategy),

            },

        )

        return order



def get_current_orders_flumine(self, order_status, market=False, all_market_orders=True):

    start_record = 0

    complete_order_list = []

    if market is not False:

        market_ids = [market.market_id]

    else:

        market_ids = None



    if all_market_orders is True:

        strategy_ref = None

    else:

        strategy_ref = [config.hostname]



    while True:

        # market_orders = self.flumine.client.betting_client.betting.list_current_orders(

        market_orders = self.flumine.clients.get_betfair_default().betting_client.betting.list_current_orders(

            market_ids=market_ids,

            customer_strategy_refs=strategy_ref,

            order_projection=order_status,

            from_record=start_record)

        complete_order_list.extend(market_orders.orders)

        start_record +=1000

        if not market_orders.more_available is True:

            break

    return complete_order_list```

*Tags: Strategies*

---

**Newbie99** - *09:30:15*

I have modified it (trying to remember why now), I think it is because for some legacy markets I have orders that were non Flumine created and I want to capture those too

*Tags: General Technical*

---

**Newbie99** - *11:07:25*

In terms of orders, it can be &gt;1000, however that doesn't seem to be the issue as for 1.182979902 I only have a handful and the latency warnings start almost straight away.

*Tags: Performance*

---

**Newbie99** - *12:14:36*

```53265807 function calls (53250311 primitive calls) in 151.446 seconds



   Ordered by: cumulative time



   ncalls  tottime  percall  cumtime  percall filename:lineno(function)

     5682    0.076    0.000  124.859    0.022 D:\Python37\webpages\place_order_functions.py:192(place_or_cancel)

      738    0.068    0.000  124.829    0.169 D:\Python37\webpages\market_making.py:19(place_passive_order)

      341    0.007    0.000  116.552    0.342 D:\Python38\lib\site-packages\flumine\baseflumine.py:254(_process_current_orders)

      681    0.001    0.000  115.210    0.169 D:\Python38\lib\site-packages\flumine\utils.py:259(call_process_orders_error_handling)

      681    0.003    0.000  115.209    0.169 D:\Python37\webpages\betting_strategy.py:32(process_orders)

     5697   21.047    0.004   80.373    0.014 D:\Python37\webpages\risk_functions.py:18(get_runner_exposure)

     4997    0.022    0.000   43.979    0.009 D:\Python37\webpages\place_order_functions.py:188(cancel_orders_by_price)

     4997    0.014    0.000   42.767    0.009 D:\Python37\webpages\place_order_functions.py:180(get_orders)

     4997    0.541    0.000   42.754    0.009 D:\Python37\webpages\place_order_functions.py:185(&lt;listcomp&gt;)

    77775    0.790    0.000   42.540    0.001 D:\Python37\webpages\place_order_functions.py:132(construct_price)

    73587    0.095    0.000   39.810    0.001 D:\Python37\webpages\place_order_functions.py:489(adjust_price_for_self_matching)

    73587    0.390    0.000   39.715    0.001 D:\Python37\webpages\validation_functions.py:425(validate_order_self_matching)

   147174    0.484    0.000   39.253    0.000 D:\Python37\webpages\validation_functions.py:465(get_order_list)

   147174   37.736    0.000   37.736    0.000 D:\Python37\webpages\validation_functions.py:474(&lt;listcomp&gt;)

  1056788   23.509    0.000   23.509    0.000 D:\Python37\webpages\risk_functions.py:33(&lt;listcomp&gt;)

      108    0.001    0.000   21.532    0.199 D:\Python38\lib\threading.py:270(wait)

      997   21.530    0.022   21.530    0.022 {method 'acquire' of '_thread.lock' objects}

      464    0.004    0.000   21.454    0.046 D:\Python38\lib\queue.py:153(get)

     5697    0.030    0.000   19.673    0.003 D:\Python37\webpages\risk_functions.py:78(check_combined_strategy)

     5697    3.140    0.001   19.598    0.003 D:\Python37\webpages\risk_functions.py:86(&lt;listcomp&gt;)

       50    0.002    0.000    9.686    0.194 D:\Python38\lib\site-packages\flumine\baseflumine.py:134(_process_market_books)

      625    0.001    0.000    9.638    0.015 D:\Python38\lib\site-packages\flumine\utils.py:222(call_strategy_error_handling)

       57    0.000    0.000    9.624    0.169 D:\Python37\webpages\betting_strategy.py:22(process_market_book)

  2113432    4.618    0.000    9.271    0.000 D:\Python38\lib\site-packages\flumine\utils.py:80(create_cheap_hash)

  8518043    4.560    0.000    8.305    0.000 D:\Python38\lib\site-packages\flumine\order\order.py:426(size_matched)

  2113059    2.288    0.000    7.743    0.000 D:\Python37\webpages\risk_functions.py:11(get_order_matched_exposure)

  4291494    2.451    0.000    7.361    0.000 D:\Python37\webpages\risk_functions.py:4(get_order_matched_stake)

  2113821    3.039    0.000    5.130    0.000 D:\Python38\lib\site-packages\flumine\order\order.py:259(customer_order_ref)

 10643310    4.577    0.000    4.577    0.000 D:\Python38\lib\site-packages\flumine\order\order.py:188(current_order)

     5696    0.775    0.000    4.467    0.001 D:\Python37\webpages\risk_functions.py:39(&lt;listcomp&gt;)

   1391/2    0.018    0.000    3.269    1.635 {built-in method builtins.exec}

        1    0.000    0.000    3.269    3.269 startup.py:1(&lt;module&gt;)

  1045/16    0.014    0.000    3.082    0.193 &lt;frozen importlib._bootstrap&gt;:986(_find_and_load)

  1044/16    0.007    0.000    3.081    0.193 &lt;frozen importlib._bootstrap&gt;:956(_find_and_load_unlocked)

  1002/16    0.007    0.000    3.066    0.192 &lt;frozen importlib._bootstrap&gt;:650(_load_unlocked)

   890/16    0.005    0.000    3.065    0.192 &lt;frozen importlib._bootstrap_external&gt;:777(exec_module)

  1348/16    0.002    0.000    3.053    0.191 &lt;frozen importlib._bootstrap&gt;:211(_call_with_frames_removed)

  2113432    2.341    0.000    2.341    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}

  2113469    1.233    0.000    2.061    0.000 D:\Python38\lib\site-packages\flumine\order\order.py:419(average_price_matched)

      341    0.013    0.000    1.827    0.005 D:\Python38\lib\site-packages\flumine\order\process.py:33(process_current_orders)

  563/115    0.003    0.000    1.797    0.016 {built-in method builtins.__import__}

       46    0.001    0.000    1.721    0.037 D:\Python38\lib\site-packages\flumine\order\process.py:93(create_order_from_current)

        7    0.000    0.000    1.603    0.229 D:\Python38\lib\site-packages\flumine\baseflumine.py:197(_add_market)

        7    0.008    0.001    1.596    0.228 D:\Python37\webpages\middleware_example.py:24(add_market)

2117384/2117380    1.525    0.000    1.525    0.000 {method 'format' of 'str' objects}

 1227/677    0.003    0.000    1.475    0.002 &lt;frozen importlib._bootstrap&gt;:1017(_handle_fromlist)

     1586    0.005    0.000    1.400    0.001 D:\Python38\lib\logging\__init__.py:1553(_log)

        1    0.000    0.000    1.335    1.335 D:\Python37\webpages\orders_worker.py:1(&lt;module&gt;)

        1    0.000    0.000    1.332    1.332 D:\Python37\webpages\racing_functions.py:1(&lt;module&gt;)

  2113432    1.331    0.000    1.331    0.000 {built-in method _hashlib.openssl_sha1}

        1    0.000    0.000    1.325    1.325 D:\Python37\webpages\import_historic_horse_data.py:1(&lt;module&gt;)

     1586    0.002    0.000    1.308    0.001 D:\Python38\lib\logging\__init__.py:1579(handle)

     1586    0.012    0.000    1.305    0.001 D:\Python38\lib\logging\__init__.py:1633(callHandlers)

     4758    0.011    0.000    1.293    0.000 D:\Python38\lib\logging\__init__.py:937(handle)

    77775    0.183    0.000    1.271    0.000 D:\Python37\webpages\place_order_functions.py:222(get_base_price_source)

     4758    0.019    0.000    1.265    0.000 D:\Python38\lib\logging\__init__.py:1069(emit)

     1505    0.007    0.000    1.249    0.001 D:\Python38\lib\logging\__init__.py:1424(info)

        6    0.000    0.000    1.222    0.204 D:\Python38\lib\site-packages\requests\api.py:16(request)

        6    0.000    0.000    1.199    0.200 D:\Python38\lib\site-packages\requests\sessions.py:470(request)

     4997    0.018    0.000    1.189    0.000 D:\Python37\webpages\cancel_and_replace.py:33(cancel_orders)

        6    0.000    0.000    1.111    0.185 D:\Python38\lib\site-packages\requests\sessions.py:626(send)

        6    0.000    0.000    1.105    0.184 D:\Python38\lib\site-packages\requests\adapters.py:394(send)

   153222    1.010    0.000    1.078    0.000 D:\Python38\lib\site-packages\flumine\markets\blotter.py:268(__iter__)

        6    0.000    0.000    1.062    0.177 D:\Python38\lib\site-packages\urllib3\connectionpool.py:518(urlopen)

        6    0.000    0.000    1.058    0.176 D:\Python38\lib\site-packages\urllib3\connectionpool.py:357(_make_request)

        5    0.000    0.000    1.056    0.211 D:\Python38\lib\site-packages\requests\api.py:107(post)

        1    0.000    0.000    1.056    1.056 D:\Python38\lib\site-packages\pandas\__init__.py:3(&lt;module&gt;)```

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

**liam** - *12:27:22*

fix line 33 and it will be a good start

*Tags: Errors Debugging*

---

**Newbie99** - *12:29:15*

Okay cool, I think I see what the issue is. This is where I'm checking all orders in the market (regardless of strategy) to avoid self matching...



Will have a re-write

*Tags: Strategies*

---

## 2022-04-26

**Newbie99** - *08:23:35*

A significant improvement...unsurprisingly perhaps it was mostly due to inefficient looping, but I re-wrote a few other bits too.



One thing that is confusing me however, is that occasionally I do get a:



```"status": "Violation", "status_log": "Violation", "violation_msg": "Order has violated: STRATEGY_EXPOSURE Error: strategy.validate_order failed: live_trade_count (1) &gt;= max_live_trade_count (1)"```

But I perform this check before trying to place an order:



```live_trades = market.blotter.strategy_selection_orders(self, runner.selection_id, runner.handicap, order_status=[OrderStatus.EXECUTABLE])



    if len(live_trades) == 0:```

*Tags: Errors Debugging, Deployment, Strategies*

---

**liam** - *08:28:35*

chance its a race condition due to the latency issues

*Tags: Performance*

---

**Newbie99** - *08:39:58*

I can now just use:



```market.blotter.strategy_selection_orders(self, runner.selection_id, runner.handicap, order_status=[OrderStatus.EXECUTABLE])```

*Tags: Strategies*

---

**Dave** - *14:56:52*

Strange choice of game to move money around tbh. Fix?

*Tags: Errors Debugging*

---

**Robert** - *15:11:02*

very odd,  was it a fix, or a bit of washing going on...

*Tags: Errors Debugging*

---

## 2022-04-27

**Robert** - *11:51:13*

[@U0382CCLV08](@U0382CCLV08) It seems to be that this is just moving money around rather than fixing, or someone who knows something. I think the  + result of backing the draw is just coincidental. As Liam said, the chances of being matched  randomly at those sizes on these games is almost zero, hence they are using these games to move money. I am surprised you have seen it happen 81 times and it's not been identified on the exchange as suspicious :thinking_face:

*Tags: Errors Debugging*

---

## 2022-04-28

**James T** - *14:19:34*

For me it does that when I create a subfolder as a "python package" rather than just choosing "directory".

*Tags: General Technical*

---

**Oliver Varney** - *14:21:34*

yer the problem is not the _init_ within side that folder, but ones further up

*Tags: General Technical*

---

**Oliver Varney** - *14:23:13*

I think its pycharm trying to be smart and help me out, but I dont want that file :joy:

*Tags: General Technical*

---

## 2022-04-29

**Leo** - *09:28:36*

I use more fundamental pre race models, but I’ve also seen a drop off since about November 2021, trying to figure out what has changed  

*Tags: Strategies*

---

**James T** - *09:36:31*

I used to turnover quite a lot at low margin, especially in 2018/19, but I guess because of higher adverse selection I now have to lower my stakes and aim for more accurate models with higher margin, but overall less profit than back then. 

*Tags: Strategies*

---

**Michael** - *09:38:34*

I do feel for newer players. Albeit maybe they're the 'problem' and for them these are the good times.

*Tags: General Technical*

---

**Michael** - *09:43:59*

For me the question is more about whether I want to.

*Tags: General Technical*

---

**charlie_v** - *10:00:50*

[@UUE6E1LA1](@UUE6E1LA1) did some C++ last yes, talk about painful, was coding in .net and the debugger is so darn slow,. code was twice as fast as my C# but they really do not make it easy.

*Tags: Errors Debugging, Performance*

---

**D C** - *10:05:54*

It is the "modern" C++ that I don't like. All this heavy reliance on templating makes code close to unreadable at times. Last place I worked as a C++ dev, there were coders who preferred to use 50 classes with functions that had a single line of code rather than a a few functions with 10ish lines of code. To me that is plain stupid but it seems a popular way of thinking now. I presume it is so that they can unit test code to death but I would rather take a career change than do that for a living. All my stuff is pretty much restricted to C++11 which for me is fine, but when trying to get a job again that is going to be a problem. I also have the problem that I had to endure C# and Windows in my last job at a betting firm so my CV looks a bit wobbly right now.

*Tags: Strategies*

---

**D C** - *10:07:45*

I guess it is you that took all my money then [@UQL0QDEKA](@UQL0QDEKA) April has  been savage for me. I am lucky that I took the good advice that [@UGV299K6H](@UGV299K6H) gave me a while ago and imcrease my base bankroll amount - otherwise I would have been cooked.

*Tags: General Technical*

---

**Aaron Smith** - *10:23:52*

That sounds like a surviving strategy as you basically put yourself higher up the hierarchy. If no new players are introduced, i dont think this would solve anything in the long run though.

*Tags: Strategies*

---

**Michael** - *10:33:10*

Yes [@U01335QG2G3](@U01335QG2G3) Q1 last year was quite an anomaly for me too. Really exceptional. Generally Q1 is the worst time though. That's another thing to bear in mind right now.

*Tags: Errors Debugging*

---

**liam** - *11:05:54*

fairly sure I have shot myself in the foot releasing flumine

*Tags: General Technical*

---

**Michael** - *11:06:51*

I might never have made it into the streaming era without it!

*Tags: General Technical*

---

**Alessio** - *11:27:26*

I guess the next step is to build a company that sells "features" for the models that people want to do this stuff ... that way you are an intermediary, no matter their performance.

*Tags: Feature Engineering, Performance, Strategies*

---

**liam** - *11:31:18*

In addition to improving (speed/features/abstractions) flumine the only thing I would do is to abstract the way its used further with a quantopian style web frontend for simulating strategies

*Tags: Feature Engineering, Performance*

---

**liam** - *12:39:52*

without meeting those who I have met from bflw there is no way I would be making what I make now, I doubt even 10%

*Tags: General Technical*

---

**river_shah** - *12:50:17*

gross revenue higher for ’22 but higher rate PC this year so net flat to last year. having to deploy increasingly sophisticated research infra to capture edge but it is also clearly apparent that total scale is very constrained (for what I am doing). the biggest disappointment I have faced is lack of major scalability. i have been unable to crack football consistently (but trying). time management issues at play as well, baby on the way. [@U4H19D1D2](@U4H19D1D2) please make `flumine` for crypto.

*Tags: Deployment*

---

**D C** - *13:41:38*

Last time I received race state changes but not runner state changes I think that called it a "mapping problem" and the UK stuff was down but the US stuff worked. Could be anything though so I guess we just wait and see

*Tags: General Technical*

---

**liam** - *17:33:27*

Messaged George and it looks like its fixed

*Tags: Errors Debugging*

---

**Jonjonjon** - *20:54:21*

It's been fairly mediocre for me this year. I've really tuned up my strategies, but the performance is probably slightly less than where I was by this time last year.

*Tags: Performance*

---

## 2022-04-30

**Dave** - *09:27:52*

While flumine took people like river_shah to higher PC within 18 months (which is insane BTW), I doubt  the user-base has a different distribution of winners Vs losers. If anything probably increased the possible revenue pool - don't think it was any foot-shooting :)

*Tags: General Technical*

---

**Dave** - *09:29:48*

Turnover for me is much higher, lower margin though as I kicked out some volatile strategies in favour of higher-sharpe. Finding it hard to make fundamental improvements to models though, a handful of new features which looked decent on paper but not sure it has changed pnl trajectory much.

*Tags: Feature Engineering, Strategies*

---

**Jonjonjon** - *09:31:16*

Seems like a lot of us are in the same boat. I wonder if we have the same strategy?

*Tags: Strategies*

---

## 2022-05-01

**Jonjonjon** - *14:01:56*

If I used an Amazon EC2 micro instance to run a single instance of Flumine that trades around 100bets per week across all horse and dog markets, would I expect to pay any data charges? When using EC2, is there a risk of unexpected high data charges, or are fees predictable?

*Tags: Deployment*

---

**Mo** - *14:02:44*

Use the race card: [https://github.com/betcode-org/betfair/blob/master/betfairlightweight/endpoints/racecard.py|https://github.com/betcode-org/betfair/blob/master/betfairlightweight/endpoints/racecard.py](https://github.com/betcode-org/betfair/blob/master/betfairlightweight/endpoints/racecard.py|https://github.com/betcode-org/betfair/blob/master/betfairlightweight/endpoints/racecard.py)

*Tags: General Technical*

---

**LM** - *21:19:39*

[@UBS7QANF3](@UBS7QANF3) do you know if this data comes through with flumine stream data anywhere?

*Tags: General Technical*

---

**Mo** - *21:26:25*

I'm not a flumine user but my understanding is you'd have to implement fetching them yourself using Middleware

*Tags: General Technical*

---

**LM** - *23:11:24*

Does anyone know if data from the racecard endpoint is only provided for a limited period. I'm trying to get historical data for Jan this year and I'm not getting anything returned?

*Tags: Data Quality*

---

## 2022-05-02

**charlie_v** - *09:22:21*

[https://twitter.com/SimonNott/status/1520763898793766912](https://twitter.com/SimonNott/status/1520763898793766912)



To cheat or not to cheat that is the question

*Tags: General Technical*

---

**Jonjonjon** - *10:27:56*

I wish I knew how to cheat.

*Tags: General Technical*

---

**charlie_v** - *12:30:40*

You could have a beer with the trainers and jockeys while saying the 'mate' a lot might help.

*Tags: General Technical*

---

## 2022-05-03

**Unknown** - *11:48:03*

[@UN1497LJC](@UN1497LJC) You asked about EC2 Micro instances recently…I was just in my AWS console and noticed that there are some free cheap as chips Lightsail instances avail free, check it out (This is for windows by the way, linux avail too)

*Tags: Deployment*

---

## 2022-05-04

**VT** - *17:11:23*

Has anyone noticed differences in latency in the last 2 days? Here in Brazil it is high.



Latency: 2.8783345222473145

*Tags: Performance*

---

## 2022-05-06

**Oliver Varney** - *12:13:52*

Am I correct in thinking process_orders in flumine is called with all orders for a strategy rather than the ones that have received an update via the stream?

*Tags: Strategies*

---

**Oliver Varney** - *12:22:36*

Is there any optimisation just to get those that have been updated? i.e. just those trades that have had updates? I guess why isnt strategy_orders called with LIVE_STATUS ?

*Tags: Deployment, Strategies*

---

**liam** - *16:10:38*

You can update the order stream to use a [https://github.com/betcode-org/betfair/blob/9126dcec91a1941f03cc58e4fd75818f36de9013/betfairlightweight/streaming/listener.py#L100|listener](https://github.com/betcode-org/betfair/blob/9126dcec91a1941f03cc58e4fd75818f36de9013/betfairlightweight/streaming/listener.py#L100|listener) with `order_updates_only` set to True

*Tags: General Technical*

---

**Oliver Varney** - *17:13:15*

Probably missing something and its a stupid question, but If orders are stored in the blotter, is there a need to re serialise all of them each time theres an order update

*Tags: General Technical*

---

## 2022-05-07

**liam** - *09:09:38*

Yeah I see, maybe we should add a flag to the order object `order.streaming_updated` or similar

*Tags: General Technical*

---

**Newbie99** - *09:30:40*

I think that would be very useful! I've been working on developing strategies that place a far larger amount of orders than my previous stuff and my cancels are based on not just time, but also price. This is where I've found bottlenecks as with markets that stay open for a while (e.g. tournament outright winner types), as the order quantities build my inefficient code gets shown up more!



I'm working on refinements my end, but if flumine was enhanced as you suggest I would definitely find it helpful.

*Tags: General Technical*

---

**liam** - *09:59:12*

Have a look at the simulation middleware to see how flumine does it 

*Tags: General Technical*

---

## 2022-05-10

**Mo** - *08:10:37*

Not sure that separating the orders out helps you. Is using fill or kill essential?

*Tags: General Technical*

---

**Oliver Varney** - *08:14:23*

[@U4H19D1D2](@U4H19D1D2) is the flumine representation of best price execution an internal concept or something that is actually sent upto betfair?

*Tags: General Technical*

---

**Aaron Smith** - *15:59:49*

does anyone have an efficient approach to extract final back/lay prices from a streaming_data_file ?

*Tags: General Technical*

---

**Mo** - *16:13:17*

```stream = trading.streaming.create_historical_generator_stream(

    file_path=path_to_prices_file,

    listener=StreamListener(

        max_latency=None, lightweight=lightweight, update_clk=False, **kwargs

    ),

)

with patch("builtins.open", smart_open.open):

    g = stream.get_generator()

    for market_book in g():

        pass```



*Tags: Performance, Strategies*

---

## 2022-05-11

**liam** - *06:31:17*

No that is expecting a bool, try out this [https://github.com/betcode-org/flumine/pull/583|branch](https://github.com/betcode-org/flumine/pull/583|branch) 

*Tags: General Technical*

---

**Lee** - *13:04:44*

[https://github.com/betcode-org/flumine/blob/9307dd5a0084c3583207921a521a1c39e430220f/flumine/order/order.py#L76](https://github.com/betcode-org/flumine/blob/9307dd5a0084c3583207921a521a1c39e430220f/flumine/order/order.py#L76)

*Tags: General Technical*

---

**Oliver Varney** - *14:28:57*

Just out of interest / for my knowledge, the process_market_book and check_market_book calls are wrapped with exception handling, with the config.raise_errors used to control this from what i can see. It looks like Flumine exceptions continue, im guessing these are due to streaming issues / recoverable issues? Is there any reason why config.raise_errors is defaulted to False for all other execeptions?

*Tags: Errors Debugging*

---

**liam** - *14:31:43*

defaulted to False because I imagine the last thing a user wants is the python process to end, its configurable for debugging purposes only really

*Tags: Errors Debugging*

---

**liam** - *14:34:42*

ah I see what you are saying, yes it probably makes sense to put the if/raise in the flumine exception as well

*Tags: Errors Debugging*

---

**Oliver Varney** - *14:35:39*

I dont mind the flumine exceptions but if ive written crappy code which is likely :joy: id rather personally have the code terminate rather then cause more destruction, maybe just me

*Tags: Errors Debugging*

---

**liam** - *14:40:36*

I always have logging set to ERROR when simulating so if I have any logs then I know something has gone wrong, maybe we update config to True for simulating? Just don't like flumine overriding things it shouldn't

*Tags: Errors Debugging*

---

## 2022-05-14

**Michael** - *17:02:36*

I'm sure there's still some money there if you know how to cook it right. Not much though, that w/o market is only small.

*Tags: General Technical*

---

## 2022-05-15

**Mick** - *11:55:01*

Does anyone have any python code that will grab a page form [http://oddschecker.com|oddschecker.com](http://oddschecker.com|oddschecker.com) - I don't mean parse it in any way, I mean simply grab the entire contents of any page. I have both python and C code that can grab pages from many other sites and the code used to work on [http://oddchecker.com|oddchecker.com](http://oddchecker.com|oddchecker.com) previously but somehow oddschecker has become more prickly and is detecting something its doesn't like. FYI I can access oddschecker from any browser - so it must be possible to do somehow.

*Tags: General Technical*

---

## 2022-05-16

**Paul** - *12:43:50*

In all seriousness if there was appetite for something in Manchester (my home town), I'd try and find time for helping get that sorted.

*Tags: General Technical*

---

**Mick** - *13:47:34*

[@U01EZ613ZCZ](@U01EZ613ZCZ): I tried some hacked together C code and some simple python involving urllib - both work fine of a ton of other sites

*Tags: General Technical*

---

**liam** - *18:07:52*

Anyone else getting lots errors from AWS? Looks like it might be APIGateway related 

*Tags: Errors Debugging, Deployment*

---

**liam** - *18:19:41*

Ah great [https://health.aws.amazon.com/phd/status|https://health.aws.amazon.com/phd/status](https://health.aws.amazon.com/phd/status|https://health.aws.amazon.com/phd/status)

*Tags: Deployment*

---

## 2022-05-17

**Oliver Varney** - *12:11:07*

the problem you will find is that, if they stick to their word initially about no limiting and large stake sizes, then everyone who has fairly okay pre off models will go after them

*Tags: Strategies*

---

**Mo** - *12:12:30*

You're not familiar with the Pinnacle business model?

*Tags: Strategies*

---

## 2022-05-18

**D C** - *14:52:12*

If anyone here has betdaq automation, I would be very very grateful for a post of a raw xml dump (minus username of course) of the request packet for ListTopLevelEvents. I am trying to write a nodejs betdaq tool and am banging my head against a wall. A valid XML request will indicate if it is my brain or the package I am using that is the problem. Not had code rage like this since cross compiling for embedded stuff. Betdaq documentation is appalling.

*Tags: General Technical*

---

**Michael** - *17:52:42*

What is the Pinnacle business model [@UBS7QANF3](@UBS7QANF3)? How does it differ from any other book?

*Tags: Strategies*

---

## 2022-05-19

**Mo** - *14:08:43*

No, just thought the product might help with coming up with strategy ideas and improvements

*Tags: Strategies*

---

**charlie_v** - *17:37:06*

This will help with your trading



[https://www.amazon.co.uk/music/player/albums/B0087F7VLQ](https://www.amazon.co.uk/music/player/albums/B0087F7VLQ)

*Tags: Strategies*

---

## 2022-05-20

**Alex Alex** - *10:36:08*

I have tried it recently. I have to say it is a bit of a mixed bag. Yes, it saves a ton of time with boilerplate code and some of the stuff it writes is really amazing. But then other times it writes code that looks ok but doesn’t quite do what I intended it to do, so I end up fixing the code which tends to end up slower than just writing it correctly in the first place. It’s still super amazing to see it work and it is 1000x more useful than I first thought it was.

*Tags: Errors Debugging, Performance*

---

## 2022-05-21

**Kai** - *14:29:05*

I guess some agents are good enough to trust them with some money to prove a winning strategy before you set up an office in Malta. But you have to do  research on your own because it is a shady business and I don't know if the (good) agents take UK customers.

[https://www.sportsbookreview.com/forum/sportsbooks-industry/](https://www.sportsbookreview.com/forum/sportsbooks-industry/)

has countless stories about bookies and agents, some of them can be entertaining to read.

*Tags: Strategies*

---

## 2022-05-23

**D C** - *13:32:24*

Any one have a problem with Somedayonedaynever in the first at Wolves? For some reason my bot didn't treat it as an NR ? Anyone know what time it was pulled?

*Tags: General Technical*

---

## 2022-05-24

**Mo** - *18:54:19*

I've never had problems _but_ I am conservative with the frequency I make requests and I do it all using Selenium (ChromeDriver)

*Tags: General Technical*

---

## 2022-05-26

**thambie1** - *07:59:37*

Alternatively perhaps they intend to solve the problem for you, but not everyone. Hence return your stake, but don't change things for the person you matched against or anyone else.

*Tags: General Technical*

---

## 2022-05-28

**Gooat** - *01:01:24*

Isn't someone always a courtsider...quicker data, better model, more experience

*Tags: Strategies*

---

## 2022-05-31

**liam** - *15:52:08*

[https://www.totalperformancedata.com/blog/2022/5/31/a-day-in-the-life-of-a-tpd-operator|A day in the life of a TPD operator](https://www.totalperformancedata.com/blog/2022/5/31/a-day-in-the-life-of-a-tpd-operator|A day in the life of a TPD operator) 

*Tags: Performance*

---

**Newbie99** - *18:57:29*

[@UUX1L88MC](@UUX1L88MC) I was playing around with your Betfair Data library and I just wanted to check whether it can be used in conjunction with Flumine for backtesting?



I ask as I noted you can output BFLW objects, but I can't seem to get it to work for this purpose, so I'm wondering if this isn't a valid use case?



As an example, I would normally do something like this with a standard file (uncompressed from a .gz file):



```markets = ["Y:/betcode/unzipped_recorder_files/1.199726796"]





strategy = example_strategy(market_filter={"markets": markets},

        market_data_filter=streaming_market_data_filter(

            fields=[

                "EX_ALL_OFFERS",

                "EX_TRADED",

                "EX_TRADED_VOL",

                "EX_LTP",

                "EX_MARKET_DEF",

                "SP_TRADED",

                "SP_PROJECTED",

            ]

            ),

            name='dummy_strategy_name',

            )



framework.add_strategy(strategy)```

So I assumed I could do something like this:



```markets = bfd.Files(["Y:/betcode/unzipped_recorder_files/1.199726796.gz"])





strategy = example_strategy(market_filter={"markets": markets},

        market_data_filter=streaming_market_data_filter(

            fields=[

                "EX_ALL_OFFERS",

                "EX_TRADED",

                "EX_TRADED_VOL",

                "EX_LTP",

                "EX_MARKET_DEF",

                "SP_TRADED",

                "SP_PROJECTED",

            ]

            ),

            name='dummy_strategy_name',

            )



framework.add_strategy(strategy)```

But then I get the following:



```  File "D:\Python38\lib\site-packages\flumine\baseflumine.py", line 101, in add_strategy

    self.streams(strategy)  # create required streams

  File "D:\Python38\lib\site-packages\flumine\streams\streams.py", line 44, in __call__

    markets.sort()

AttributeError: 'builtins.Files' object has no attribute 'sort'```

So I essentially wanted to check whether I'm doing something wrong in terms of my approach, or whether this isn't what it is designed to do?

*Tags: Errors Debugging, Strategies*

---

## 2022-06-01

**Peter** - *17:34:19*

[https://github.com/betcode-org/flumine/pull/577](https://github.com/betcode-org/flumine/pull/577)



It's still a pull request, so not yet integrated into the master branch of flumine. So not appropriate for inclusion in the docs, but you could install the last commit in the PR to try it out.

*Tags: Getting Started*

---

## 2022-06-02

**Unknown** - *07:36:07*

raises an interesting question, but for the inplay boys that bet down to 1.01, how do you protect against horses getting disqualified for weird reasons? Is it just as simple as having a max market exposure and just taking your medicine?

*Tags: General Technical*

---

## 2022-06-05

**LM** - *07:09:47*

what approaches do people take to schedule flumine jobs so if becomes as hands off as possible? currently i'm killing of old process and restarting manually daily... Is there a way that flumine can add new markets as they are made available based on the filter provided (it could be setup to do this already, I'm just using it wrong....)?

*Tags: Getting Started*

---

**liam** - *07:20:14*

Uses streaming so yeah you are using it wrong

*Tags: General Technical*

---

**LM** - *07:51:11*

So using the below will continually give me all markets from the filter continuously? At the moment I'm passing market_ids to the filter which is why it stops at the end of the day. I needed to use the second approach to begin with as I was getting errors associated with connecting to too many streams (may be wrong terminology).

```    market_filter=streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["AU"],

        market_types=["WIN"],

        race_types=["Flat"],

        turn_in_play_enabled=True

    )```

*Tags: Errors Debugging*

---

## 2022-06-07

**liam** - *07:53:57*

I think gbp is default / only option for streaming, have a look at the docs

*Tags: General Technical*

---

**Newbie99** - *11:24:26*

I'm hoping this is a dumb question and I'm missing the blindingly obvious answer....



When backtesting how would I go about looking back x seconds on an in-play market?



In live of course I can simply compare the publish time to now, but when back testing of course that won't work.



(I appreciate I can look back y price updates as an alternative, but just wondered if this approach was possible)?

*Tags: Deployment*

---

**Newbie99** - *13:26:42*

A while back did someone post a multiproc code sample for Flumine backtesting? I can't seem to see it, but I didn't think it was that long ago so odd it didn't come up on the search (or did I just imagine it)?

*Tags: General Technical*

---

**liam** - *13:27:21*

[https://betcode-org.github.io/flumine/performance/#multiprocessing](https://betcode-org.github.io/flumine/performance/#multiprocessing)

*Tags: Performance*

---

## 2022-06-08

**Rudeger Jamison** - *01:10:14*

Hey - I am trying to do this within flumine and make the currency request process every 24 hours as a CustomStream.



I am trying to access the bflw object in order to make a request.



tried *`self.clients.get_betfair_default().betting_client.account.list_currency_rates("AU")`*



*but get an error* 

```Full Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'AANGX-0002', 'data': {'exceptionname': 'AccountAPINGException', 'AccountAPINGException': {'requestUUID': 'null', 'errorCode': 'INVALID_SESSION_INFORMATION', 'errorDetails': ''}}}, 'id': 1}```

*Tags: Errors Debugging, Strategies*

---

**liam** - *08:24:06*

[https://github.com/betcode-org/flumine/blob/master/flumine/worker.py](https://github.com/betcode-org/flumine/blob/master/flumine/worker.py)

*Tags: General Technical*

---

## 2022-06-09

**Ruben** - *10:55:45*

The storage of my aws ec2 instance seems to be filling up for no apparent reason, any ideas why that might happen? For context, I'm running a flumine instance, a redis instance, and also have anaconda with 1 environment that I use

*Tags: Deployment*

---

## 2022-06-11

**D C** - *16:03:58*

The TPD status page yesterday was showing Lone Star Park was active but I have not received any GPS from this track (via BF) for quite a while now. Anyone else getting this or is it a problem at my end?

*Tags: General Technical*

---

## 2022-06-14

**Steve** - *22:58:17*

Hey all! :slightly_smiling_face: I’m brand new here and I’m trying to figure out how much more I need to study before I should put together my first betting angle/model using statistics and data analysis. What exact prerequisite knowledge should I have before even attempting to do so? I’m specifically interested in doing Horseracing if that helps.



I’ve got a background in Math (studied Civil Engineering at uni) and I’ve studied Python for a few months now (was playing around with Selenium in Pycharm to automate work things) but not too confident on what I should be learning exactly from all the Python content out there. I’m just wondering what the next steps for myself are. I’ve watched a few tutorials on the Betfair Youtube channel and have had a look through a few resources.



I'm just trying to put together a learning curriculum for myself to give myself a realistic timeline and tangible goal to work towards, and I feel like there’s more to it than just what I’ve found as I don’t know what I don’t know, so does anyone have any suggestions? Also let me know if this question has been asked already as I couldn’t find a similar thread anywhere.

*Tags: Strategies*

---

**Jonjonjon** - *23:04:52*

A good place to start will be the Flumine examples. Watching Youtube tutorials about Betfair trading might reduce, rather than increase, your chances of success.

*Tags: Strategies*

---

## 2022-06-15

**D C** - *08:19:52*

Might be worth thinking about whether you want to base something off fundamentals or market data.  If the former, you will need to buy/find/scrape data but there is a school of thought that you won't find anything useful in public domain / free data. If the latter, start recording betfair market prices for markets of interest (probably a good idea to do that ASAP anyway). I don't use it myself but I believe that flumine does this so that might be a good place to start. Depending on your knowledge of betting, it might be useful to read some basic books on the subject - [@UBS7QANF3](@UBS7QANF3) used to have a link to a list of good reads in this area so you might be able to find that on one of the channels. Ultimately it depends on what you want to achieve but be warned you can waste literally hundreds/thousands of hours (I certainly have and I am definitely not alone) pursuing things that don't work so be very aware that success really is not guaranteed if being successful is equlvalent to being profitable.

*Tags: Strategies*

---

**Mo** - *08:23:47*

[https://www.amazon.co.uk/Logic-Sports-Betting-Ed-Miller/dp/1096805723](https://www.amazon.co.uk/Logic-Sports-Betting-Ed-Miller/dp/1096805723)

[https://www.amazon.co.uk/Trading-Bases-Fortune-Betting-Baseball/dp/0451415175](https://www.amazon.co.uk/Trading-Bases-Fortune-Betting-Baseball/dp/0451415175)

[https://www.amazon.co.uk/Statistical-Sports-Models-Excel-Andrew/dp/1079013458](https://www.amazon.co.uk/Statistical-Sports-Models-Excel-Andrew/dp/1079013458)

[https://www.amazon.co.uk/Precision-Statistical-Mathematical-Methods-Racing/dp/1432768522](https://www.amazon.co.uk/Precision-Statistical-Mathematical-Methods-Racing/dp/1432768522)

[https://www.amazon.co.uk/Efficiency-Racetrack-Scientific-Financial-Economics/dp/981320351X](https://www.amazon.co.uk/Efficiency-Racetrack-Scientific-Financial-Economics/dp/981320351X)

[https://www.amazon.co.uk/Kelly-Capital-Growth-Investment-Criterion/dp/9814383139](https://www.amazon.co.uk/Kelly-Capital-Growth-Investment-Criterion/dp/9814383139)

[https://www.amazon.co.uk/Man-All-Markets-Beating-Street/dp/1786071975](https://www.amazon.co.uk/Man-All-Markets-Beating-Street/dp/1786071975)

*Tags: Strategies*

---

**LM** - *11:52:19*

I am passing the name parameter to a strategy but the customer_strategy_ref I am getting when hitting the list_cleared_orders API are the IP address of the machine running the strategy. What am I doing stupidly?

*Tags: Strategies*

---

**liam** - *12:26:51*

You can change it per running instance using `config.customer_strategy_ref` however best practise is to use `loggingcontrol` for all order recording

*Tags: Strategies*

---

## 2022-06-16

**liam** - *16:02:37*

Reminds me of the legendary inplay [https://community.betfair.com/horse_racing/go/thread/view/94102/28802591/tony-calvin-it-is-an-obvious-error?liveView=0&amp;pg=5|error](https://community.betfair.com/horse_racing/go/thread/view/94102/28802591/tony-calvin-it-is-an-obvious-error?liveView=0&amp;pg=5|error) 

*Tags: Errors Debugging, Deployment*

---

## 2022-06-21

**thambie1** - *07:48:09*

Betfair's down, I would ignore that error for now

*Tags: Errors Debugging*

---

**Mr West** - *17:20:35*

PC page fixed now

*Tags: Errors Debugging*

---

**Jonjonjon** - *17:45:52*

It's telling me I need to pay £x&gt;0. I'd consider it fixed when I need to pay £0.

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:49:56*

Is there a recommended upper limit on the number of strategies that people run per Flumine instance?

*Tags: General Technical*

---

**birchy** - *21:56:40*

However many it takes to get to the CPU running at 99%? :grinning: 

Serious answer...depends on how much computing each strategy uses. I don't think there's a limit in flumine other than CPU limitations, particularly on AWS. I guess latency would be the key metric?

*Tags: Performance, Deployment, Strategies*

---

**Unknown** - *22:01:30*

Hmmm... I hadn't considered latency. My CPU% on a dual core machine looks like this, running 5 Flumine instances, one of which is at close to 100 strategies. I don't have much time to monitor this so am not too keen spinning up another machine if I can avoid it.

*Tags: Performance*

---

**liam** - *22:02:44*

Yeah I keep an eye on CPU, book processing time and place/cancel latency 

*Tags: Performance*

---

## 2022-06-22

**Mo** - *09:09:53*

Depends on the strategy

*Tags: Strategies*

---

## 2022-06-23

**mandelbot** - *15:06:04*

Linux question; how do you clear your nohup log files that your scripts create?

`echo -n &gt;nohup.out` , `true &gt; nohup2.out`  and `cat /dev/null &gt; nohup2.out` for me are a bit wonky, ie the log file returns after a while at the same size with the added annoyance that it takes much longer to load when trying to access. Curiously this happens one log file but not the other

*Tags: General Technical*

---

## 2022-06-24

**D C** - *10:09:24*

That is an interesting question [@UPMUFSGCR](@UPMUFSGCR) - I've always suspected this when looking at how my bets match but never heard anything about it nor any evidence to support it.

*Tags: General Technical*

---

## 2022-06-26

**birchy** - *22:43:02*

+1 for JuiceSSH. I also use AndFTP (using SSH key auth) and BucketAnywhere for up/downloading files to/from AWS Lightsail and S3. Great tools for maintenance jobs while on your lunch break.

*Tags: Deployment*

---

## 2022-06-27

**Newbie99** - *10:16:50*

Is there a neater way of removing latency warnings when using the market recorder than changing the MAX_LATENCY value in the basestream.py file (for Flumine)?

*Tags: Data Quality, Performance*

---

## 2022-07-01

**Unknown** - *18:57:44*

Hi all, had a funny settlement for the BJ exit dates market as in the screenshot. I thought the settlement mistake is pretty obvious in the calculation of market subtotal in the screenshot here. how come £ -30.49 + 48.00 = -57? Think my P&amp;L should be +£17.51 (before commission), right? The betfair twitter help investigated and told me that "Hi there apologies for the wait. Traders have reviewed this and have confirmed that they are happy with the settlement of this market. Apologies for any inconvenience this may have caused you." Do I miss anything ... ? Thanks

*Tags: General Technical*

---

**John** - *23:10:24*

Thanks. I am chasing Betfair help desk again. Hope they can clarify a bit.

*Tags: General Technical*

---

## 2022-07-02

**river_shah** - *11:20:04*

Checking if of interest to anyone in the community: I am looking for a developer to help setup some core infra / data collection / middleware / simulation systems. I am too occupied on other projects and have not done this work properly even after 18+ months of betting.



Will pay competitive day rates for the initial build phase and any ongoing support needed. Familiarity with `flumine` and `bflw` a must. Please direct message me if of interest and we can walk through more details.

*Tags: Getting Started, Strategies*

---

## 2022-07-06

**EJono** - *10:51:05*

Looking into different sources for football scores outside of bfs inplay service. Does anyone have any experience using "betsapi" ? it looks as if they offer a varied selection of endpoints with aggreagated data from several providers. Im interested in live football scores and the pricing seems quite a bit cheaper than previously suggested feeds from sites such as "thesports" and "sportsmonk" but havent heard much chat about it hear nor much published online. Any experience, good or bad, would be helpful before i dive in cheers.

*Tags: Deployment*

---

**EJono** - *15:55:50*

Thank you for the insight and use case. Its good to know what youve been able to get out of the service. The documentation is slightly unclear what endpoint should be used for live football scores, for instance the "Events API" has an inplay endpoint but its not clear if this data is made available after the match is terminated ie is historical data at that point. Which ebdpoint do you utilise for inplay live scores on football?

*Tags: Data Quality, Deployment*

---

## 2022-07-08

**Mo** - *15:38:04*

The absolute pinnacle is [https://twitter.com/halfkelly|Risk of Ruin](https://twitter.com/halfkelly|Risk of Ruin). It's described as "Audio documentaries about gambling" and that sums it up perfectly. If I'm nitpicking, the focus can be a bit too heavily on casino advantage play but I've enjoyed every episode nonetheless. Top pick of episode would be "A Seemingly Obvious Idea" featuring Andew Black, one of the co-founders of Betfair



Also fascinating but sadly no longer in production is Matthew Trenhaile's [https://podcast.app/inside-betting-p536238/|Inside Betting](https://podcast.app/inside-betting-p536238/|Inside Betting). I could happily listen to Matthew speak about gambling all day long. Everyone who has ever complained about Betfair Premium Charge should start by listening to Episode 14 "Betting Exchange Premium Charges"



One of the original podcasts is the [https://podcasts.apple.com/gb/podcast/business-of-betting-with-jason-trost/id1223927895|Business of Betting](https://podcasts.apple.com/gb/podcast/business-of-betting-with-jason-trost/id1223927895|Business of Betting). A big word of warning is that it has recently been taken over by Jason Trost, CEO of Smarkets who - in my very humble opinion - is a complete nob. However, don't let that put you off exploring the excellent back catalogue. There are probably too many must listen episodes to mention but to name a few: both episodes (26 and 127) with Marco Blume, director of trading at Pinnacle, episode 107 with Will Duff Gordon, the CEO of TPD - very relevant to anyone doing in-running horse racing - episode 119 with Andrew Mack, author of Statistical Sports Models in Excel volumes 1 and 2, episode 116 with Lloyd Danzig if you're interested in the US market, episode 96 with Matthew Davidow and Ed Miller, authors of The Logic of Sports Betting, episode 29 with William Ziemba who has published some standout papers on statistical modelling of horse racing, episode 28 with Dan Weston if tennis is your sport



Betting adjacent, I like [https://chatwithtraders.com/|Chat With Traders](https://chatwithtraders.com/|Chat With Traders). The host, Aaron Fifield seems quite naive but there's no doubting the quality of talent he gets on the show. Top pick would be Episode 109 with Ed Thorp who is a legend in both gambling and investing. Of some controversy on here is episode 215 featuring William Beauchamp of Seamless Capital. If you search the episodes you can pick out plenty of bettors that have made the jump to financial markets but the pure finance guys can certainly be worth listening to as well



There are quite a few US-centric podcasts like [https://podcasts.apple.com/gb/podcast/bet-the-process/id1291010585|Bet The Process](https://podcasts.apple.com/gb/podcast/bet-the-process/id1291010585|Bet The Process), [https://podcasts.apple.com/gb/podcast/be-better-bettors/id1493902736|Be Better Bettors](https://podcasts.apple.com/gb/podcast/be-better-bettors/id1493902736|Be Better Bettors) and [https://podcasts.apple.com/us/podcast/gambling-with-an-edge/id459476611|Gambling With An Edge](https://podcasts.apple.com/us/podcast/gambling-with-an-edge/id459476611|Gambling With An Edge) but personally I don't much care for them as it can seem like they're speaking a different language. It's not just the obvious focus on US sports, you're also got the increased focus on line betting, the impossible to understand odds system, the obsession with "off shore" bookmakers and Vegas, etc. etc.

*Tags: Deployment, Strategies*

---

**Fab** - *15:59:32*

But if you have any tips (or actual code) on how to scrape effectively, I'd gladly take a look :wink:

*Tags: General Technical*

---

**Ralegh** - *16:04:51*

Ah brilliant thanks for writing those out, time to sit out in the sun and listen to a couple. I don't have much to give in exchange but I've been heavily recommended [https://open.spotify.com/show/1IXldCXztfTaZeHbtcDRQI|Flirting with models](https://open.spotify.com/show/1IXldCXztfTaZeHbtcDRQI|Flirting with models) by the algotrading crowd (lots of quants plus a couple stories of gambling antics).

*Tags: Strategies*

---

**Mo** - *16:05:37*

Haha I was going to mention Flirting with Models as well but I thought I'd written enough :sweat_smile:

*Tags: Strategies*

---

**Jonjonjon** - *20:35:54*

[@UBS7QANF3](@UBS7QANF3) What's so great about Chat With Traders? I used to listen to it, but most of the interviewees were the delusional types who think that a positive mental attitude will make you a winning trader. I don't see how my mindset affects the performance of Python betting scripts?



The worst was a guy who thought that any strategy would win with the correct mindset. Suppose you ran the same Python script as me. Suppose you think it's great and I think it's nonsense. Would that make the script perform better for you?

*Tags: Performance, Strategies*

---

**LM** - *23:30:50*

Hey [@UBS7QANF3](@UBS7QANF3). Thanks for the great list of podcasts. I've just listened to the TPD episode you mentioned. Do you know whether betfair provides live TPD data?

Alternatively do you know if historical TPD data can be sourced to model before buying a subscription?

*Tags: Deployment, Strategies*

---

## 2022-07-13

**Newbie99** - *00:21:17*

A question for the football traders on here (well its probably generic in all honesty)....



Presumably I just need to maintain a many to one relationship for whatever randomness Betfair decide to come up with to map to whichever 3rd party data provider, or are situations like the one below likely to be errors, rather than duplicates (i.e. rather than keeping both with a many to one mapping, should I just keep the one that comes up more often and ignore any one offs)?



```'betfair_runner_name': 'Paris St-G', 'betfair_selection_id': 489720

'betfair_runner_name': 'PSG', 'betfair_selection_id': 65323,```



*Tags: Errors Debugging*

---

**LM** - *03:25:39*

Any examples anywhere of using the prices in the win market in a place market strategy (or what is the best way to get the last traded price of each runner in the win market for the corresponding races place market)?

*Tags: Strategies*

---

**liam** - *07:26:01*

Are you a flumine user? 

*Tags: General Technical*

---

**LM** - *08:54:15*

is the self referring to the instance of the BaseStrategy class?

*Tags: Strategies*

---

**liam** - *10:07:06*

regarding pricing there was some discussion in the betfair-quants slack group that you 'might' find helpful

*Tags: General Technical*

---

**Leo** - *11:49:11*

Yeah it's a tricky one really. I use fundamental models and my general assessment is that the chances of a horse improving significantly over a new distance or first time in handicaps etc is usually overestimated in the market in comparison to its previous form. But there are definitely exceptions 

*Tags: Getting Started, Errors Debugging, Strategies*

---

**Unknown** - *16:39:28*

I'm not actually much of a betcode user so forgive my ignorance...



I want to extract some data from the free (one minute interval) betfair historical data and write it out as csv so I can process it with my C code. The data I want is something like a snapshot of everything contained in the image below (for all races in a date range) at a certain time of day – or perhaps a certain number of minutes before the start of a race. So my question is, what would be the least painful way to do this? Does betcode (or flumine?) have this kind of functionality built in already? Or has someone made some other kind of utility to do this?

*Tags: Data Quality*

---

**liam** - *16:42:05*

yeah, behind the scenes its just betfairlightweight so if you can code use betfairlightweight

*Tags: General Technical*

---

## 2022-07-14

**Newbie99** - *09:28:52*

I use the market catalogue middleware example when backtesting and it all works fine:



[https://github.com/betcode-org/flumine/blob/master/examples/middleware/marketcatalogue.py](https://github.com/betcode-org/flumine/blob/master/examples/middleware/marketcatalogue.py)



However, when self recording, the market catalogues are saved as a .json.gz, so if I run the following in a standalone script:



```mc_path = '/1.200396929.json.gz'



with open(mc_path, "rb") as r:

    data = gzip.GzipFile(fileobj=r).read()

    catalogue_json_data = json.loads(data)

    print(catalogue_json_data)```

As expected it returns:



```{'marketId': '1.200396929', 'marketName': 'Over/Under 2.5 Goals', 'marketStartTime': '2022-06-22T16:00:00.000Z', 'description': {'persistenceEnabled': True, 'bspMarket': False, 'marketTime': '2022-06-22T16:00:00.000Z', 'suspendTime': '2022-06-22T16:00:00.000Z', 'bettingType': 'ODDS', 'turnInPlayEnabled': True, 'marketType': 'OVER_UNDER_25', 'regulator': 'GIBRALTAR REGULATOR', 'marketBaseRate': 2.0, 'discountAllowed': False, 'wallet': 'UK wallet', 'rules': '&lt;!--Football - Over/Unders --&gt;&lt;br&gt;How many goals will be scored in this match.&lt;br&gt; All bets apply to Full Time according to the match officials, plus any stoppage time. Extra-time/penalty shoot-outs are not included.&lt;br&gt;&lt;br&gt;&lt;/b&gt;For further information please see &lt;a href=[http://content.betfair.com/aboutus/content.asp?sWhichKey=Rules%20and%20Regulations#undefined.do](http://content.betfair.com/aboutus/content.asp?sWhichKey=Rules%20and%20Regulations#undefined.do) style=color:0163ad; text-decoration: underline; target=_blank&gt;Rules &amp; Regs&lt;br&gt;&lt;br&gt;\n', 'rulesHasDate': True, 'priceLadderDescription': {'type': 'CLASSIC'}}, 'totalMatched': 35.4, 'runners': [{'selectionId': 47972, 'runnerName': 'Under 2.5 Goals', 'handicap': 0.0, 'sortPriority': 1, 'metadata': {'runnerId': '47972'}}, {'selectionId': 47973, 'runnerName': 'Over 2.5 Goals', 'handicap': 0.0, 'sortPriority': 2, 'metadata': {'runnerId': '47973'}}], 'eventType': {'id': '1', 'name': 'Soccer'}, 'competition': {'id': '4051', 'name': 'Norwegian Cup'}, 'event': {'id': '31543907', 'name': 'Strindheim v Kristiansund', 'countryCode': 'NO', 'timezone': 'GMT', 'openDate': '2022-06-22T16:00:00.000Z'}}```

However, if I try to adapt the middleware code as follows:



```class MarketCatalogueMiddleware(Middleware):

    def add_market(self, market) -&gt; None:

        try:

            zipped_catalogue_file_path = str(get_mc_folder(market, zipped_folder_path))

            catalogue_file_path = os.path.join(MARKET_CATALOGUE_PATH, market.market_id + '_market_catalogue.json')

            if zipped_catalogue_file_path is not False:

                if os.path.exists(zipped_catalogue_file_path):

                    with open(zipped_catalogue_file_path, "rb") as r:

                        data = gzip.GzipFile(fileobj=r).read()

                        catalogue_json_data = json.loads(data)

                        print(catalogue_json_data)```

Then I just get the following error:



```Exception 'int' object has no attribute 'startswith' occured on market 1.200522372```

If I use a different approach, as follows:



```class MarketCatalogueMiddleware(Middleware):

    def add_market(self, market) -&gt; None:

        try:

            zipped_catalogue_file_path = str(get_mc_folder(market, zipped_folder_path))

            catalogue_file_path = os.path.join(MARKET_CATALOGUE_PATH, market.market_id + '_market_catalogue.json')

            if zipped_catalogue_file_path is not False:

                if os.path.exists(zipped_catalogue_file_path):

                    with gzip.open(zipped_catalogue_file_path, 'rb') as fin:

                        catalogue_json_data = json.loads(fin.read().decode('utf-8'))

                        market.market_catalogue = MarketCatalogue(**catalogue_json_data)```

Then I get the following error:



```Exception Not a gzipped file (b'{"') occured on market 1.199593125```

Now of course, I can get around this by unzipping the files first, but I feel I must be missing something obvious here, why can I unzip into memory from a static script, but not via middleware, I presume there is a logical reason and whilst it doesn't matter as there is an obvious alternative approach, I would like to understand why this doesn't work if possible?

*Tags: Errors Debugging, Performance, Strategies*

---

**Newbie99** - *09:54:41*

I effectively just copied this:



[https://betcode-org.github.io/flumine/performance/#multiprocessing](https://betcode-org.github.io/flumine/performance/#multiprocessing)



and this:



[https://github.com/betcode-org/flumine/tree/master/examples/middleware](https://github.com/betcode-org/flumine/tree/master/examples/middleware)



In terms of approach I don't think I've changed anything (other than the odd bit of formatting etc.)

*Tags: Performance*

---

**liam** - *09:56:01*

fairly sure that will be the problem, won't smart-open do the hard work, can you run the example as is without your code?

*Tags: General Technical*

---

**PeterLe** - *12:15:29*

Afternoon,

If you set environmental variables (so you don't hard code your details) for use in cloud

Are these instructions credible:



[https://able.bio/rhett/how-to-set-and-get-environment-variables-in-python--274rgt5](https://able.bio/rhett/how-to-set-and-get-environment-variables-in-python--274rgt5)



Also is a .env file secure or do you need to encrypt it somehow?

In addition, how you you append the 2FA onto your password? (or do you input just once and leave it running?)



I currently do it like this:



twofa = str(input("Please enter Pass and 2FA for Sub4: "))

trading = betfairlightweight.APIClient("Removed", twofa, app_key="Removed", certs=r"C:\certs")

sorry for the noddy questions. Thanks in advance

*Tags: Strategies*

---

**Mo** - *12:32:46*

1. At a glance the instructions seem reasonable

2. The file is not secure in the sense that if someone could log into your account they could read the file in plain text on disk. This is going to apply to pretty much every solution

3. I've only ever used 2FA on my master so can't comment

Some additional comments:



1. Do you not already have a configuration file for your strategy? If you do then you might as well just add the credentials to that rather than using environment variables

2. I use [https://github.com/fugue/credstash|credstash](https://github.com/fugue/credstash|credstash) for managing secrets in AWS

*Tags: Deployment, Strategies*

---

**PeterLe** - *12:47:57*

Thanks Mo

1. :+1:

2. :+1:

3. Just curious why only the MSA? Maybe you keep minimum funds the he sub accounts?

1a. I need to check (Ive only used the basic examples and then modified them). Think Wright brothers aviation and thats where Im at with Python (Strings; wire and sellotape)

1b. Need to read up on this :grinning:



Thanks for the reply

*Tags: General Technical*

---

## 2022-07-15

**Newbie99** - *13:55:28*

Can the latest version of Flumine distinguish between types of simulation mode (by which I mean backtesting via historic data vs paper trading)?



The problem I'm trying to solve, is when in simulation (backtesting) use historic score data, but of course when in simulation (paper) use live score data.



I can check whether its in simulation mode, but is it possible to distinguish between the two, or do I need to create something myself?

*Tags: Deployment, Strategies*

---

**liam** - *13:57:12*

this gets tricky, we need the simulation engine for paper trading but its on a per client basis, there is a flag in the `clients` class which might help?

*Tags: Strategies*

---

**AP** - *18:43:01*

Is anyone here using or has used the Proform racing software? Just looking to see whether people have found it useful for fundamental modelling purposes

*Tags: Strategies*

---

## 2022-07-16

**AP** - *14:50:54*

Yeah I found that too, but when I query directly on the database using SQL it seems fine and much faster than using the software

*Tags: General Technical*

---

**PeterLe** - *17:15:30*

Afternoon all, hope its warm enough for you :hot_face:

When running strategies/flumine in the cloud for weeks at a time unattended (thinking of being on holiday etc)

Are there any maintenance tasks that need to be carried out periodically eg clearing cache files; log files etc or has Liam made us lazy and factored that in. Thanks

*Tags: General Technical*

---

**birchy** - *17:24:08*

There's no maintenance required. I have Flumine strategies that have been running for 6+ months unattended.

*Tags: General Technical*

---

**PeterLe** - *17:31:29*

By the way; Im on LightSail too. Cheaper than EC2. Do you find any downside using it rather EC2? Seems good enough to me

*Tags: Deployment*

---

**birchy** - *20:32:03*

I chose it because EC2 is/was confusing with (IMO) far too many options. Lightsail works for a simpleton like me. :grinning:

Lightsail is basically a preconfigured, ready to use version of EC2.

*Tags: Deployment*

---

## 2022-07-17

**PeterLe** - *10:55:13*

Ive had bigger instances in the past, but at the moment I have a windows 2gb 1cpu and a ubuntu 2gb 1cpu Just learning linux)

Even on he windows version, Python hardly impacts the CPU utilisation

*Tags: General Technical*

---

**birchy** - *10:56:58*

Personally, I use a $10 instance for a small handful of strategies and a market recorder. CPU runs around 10%, so plenty more capacity.

 A $5 would probably suffice for my stuff.

*Tags: Data Quality*

---

**birchy** - *11:18:48*

Plus you get much improved latency, which will likely increase increase profit/loss.

*Tags: Performance*

---

**mandelbot** - *12:29:24*

Improved vs ec2?

*Tags: Deployment*

---

**birchy** - *12:30:11*

Same as EC2. Lightsail IS an EC2 instance.

*Tags: Deployment*

---

**Mo** - *14:30:20*

Not sure how to get to this through the interface rather than manually constructing the URL with the relevant commit hashes

*Tags: General Technical*

---

## 2022-07-18

**PeterLe** - *15:14:31*

Good Afternoon, Wow its cracking the flags in Manchester today! :hot_face:



Although I have the market recorder running fine in windows, Im trying to get it running in Ubuntu and I can see it is failing due to the certs reference below.



import time

import logging

import betfairlightweight

from pythonjsonlogger import jsonlogger



from flumine import Flumine, clients

from flumine.streams.datastream import DataStream

from marketrecorder import MarketRecorder

# from flumine import MarketRecorder



logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



myacc = str(input("please enter account name: "))

app_key = str(input("Please enter key: "))

mypass = str(input("Please enter Password and 2FA: "))

trading = betfairlightweight.APIClient(myacc,mypass, app_key, certs=r"C:\certs")



# client = clients.BetfairClient(trading) //Changed 21st July

client = clients.BetfairClient(trading, order_stream=False)



framework = Flumine(client=client)



strategy = MarketRecorder(

    name="WIN",

    market_filter=betfairlightweight.filters.streaming_market_filter(

        event_type_ids=["7"],

        country_codes=["GB", "IE"],

        market_types=["WIN"],

    ),

    stream_class=DataStream,

    context={

        "local_dir": "/home/ubuntu/flumine",

        "force_update": False,

        "remove_file": True,

    },

)



framework.add_strategy(strategy)



framework.run()



Question Please: Can i copy over the certs I have in my windows systems and then reference them something like : -

trading = betfairlightweight.APIClient(myacc,mypass, app_key, certs=r"/home/ubuntu/certs") I assume they are just a digital file and not specific to an OS?

Or, more likely, am I going about this the wrong way. Thanks in advance

(PS I will set the environment settings soon :grinning:)

*Tags: Data Quality, Strategies*

---

**PeterLe** - *16:51:15*

Ive used it to pull down flumine/Betfairlightweight but no not using it as such (Scared of cocking something up!) Why?

*Tags: General Technical*

---

**Newbie99** - *19:01:08*

With the Closed Market Logging control, should the following always produce an output, even if there are no settled orders (e.g. orders were placed, but 100% of orders were cancelled and market profit = 0)?



```def _process_cleared_markets(self, event):

        cleared_markets = event.event

        for cleared_market in cleared_markets.orders:

            [http://logger.info|logger.info](http://logger.info|logger.info)(

                "Cleared market",

                extra={

                    "market_id": cleared_market.market_id,

                    "bet_count": cleared_market.bet_count,

                    "profit": cleared_market.profit,

                    "commission": cleared_market.commission,

                },

            )```

Or does the above only return an output when there are 1 or more settled orders (I assumed it was the former, but I don't seem to get any output if I only have cancelled orders and I'm not sure if that's because I'm doing something weird or if its expected behaviour)?



I'm guessing I'm doing something weird as I output to a JSON and despite no error, I suspect something is going on there, but just wanted to check...

*Tags: Errors Debugging*

---

## 2022-07-19

**liam** - *11:22:31*

if you have a read of this [https://github.com/betcode-org/flumine/blob/802e71bde5753da806384fde371b885a4ce8853e/flumine/worker.py#L227|code](https://github.com/betcode-org/flumine/blob/802e71bde5753da806384fde371b885a4ce8853e/flumine/worker.py#L227|code) you can see when it gets called, tbh without testing I am not sure if you get a result on cleared orders with no 'matched' orders

*Tags: General Technical*

---

## 2022-07-23

**foxwood** - *10:36:19*

Didn't have any problems that I can remember. Was running daily updates during the licence period and also exploring the database using ssms. When I contacted them regarding a few odd issues in the database they gave a terse reply that direct access was not supported lol. Has your licence expired - that would stop their software working I expect ?

*Tags: General Technical*

---

**Peter** - *13:40:11*

I can see how this would be useful to market makers. If they're already paying enough commission to cover the transaction costs, then having large numbers of open (and implicitly diversified) positions across many markets would tie up capital, especially at longer odds and while markets are forming, with only moderate risks. So TCA would help them to spread their reach and, from Betfair's perspective, improve market liquidity. Betfair doesn't need to provide any capital, just allow the prices to be offered. So a bit of a win-win when working with the right customers.

*Tags: General Technical*

---

## 2022-07-24

**PeterLe** - *12:48:47*

[@U010GM77S4W](@U010GM77S4W) recently explained how to add more than one strategy to a single instance (thanks madelbot) using this :

import logging

import betfairlightweight

from pythonjsonlogger import jsonlogger



from flumine import Flumine, clients

from flumine.streams.datastream import DataStream

from Strategy1 import Strategy1

from Strategy2 import Strategy2





logger = logging.getLogger()



custom_format = "%(asctime) %(levelname) %(message)"

log_handler = logging.StreamHandler()

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = time.gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))



trading = betfairlightweight.APIClient('username', 'password', app_key='app_key',

					certs='/path/to/certs')

trading.login()



client = clients.BetfairClient(trading)



framework = Flumine(client=client)



markets1 = betfairlightweight.filters.streaming_market_filter(

           event_type_ids=["7"],

           country_codes=["GB", "IE"],

           market_types=["WIN"]

)



markets2 = betfairlightweight.filters.streaming_market_filter(

           event_type_ids=["4339"],

           country_codes=["GB"],

           market_types=["WIN"]

)





strategy1 = Strategy1(

    name="Strategy1",

    market_filter=markets1,

    max_order_exposure=50000000,

    max_selection_exposure=6000000,

    max_trade_count=200,

    max_live_trade_count=1,

    context={"stake": 2},

)



strategy2 = Strategy2(

    name="Strategy2",

    market_filter=markets2,

    max_order_exposure=50000000,

    max_selection_exposure=6000000,

    max_trade_count=2000,

    max_live_trade_count=2,

    context={"stake": 2},

)



framework.add_strategy(strategy)

framework.add_strategy(strategy2)



framework.run()



I assume you can use the same principle using the market recorder to record more than one sport/category?

If so, Ill probably just add one more sport category for now, but is it good practice to add multiple sports. Does it start to slow the system down too much if you add multiple? Would it be reasonable to assume it could handle 3 or 4 categories easily? (Im using ubuntu on AWS 4gb ram, 2 CPU's)

(Can someone remind me of the subscription limit too please?) Thanks in advance

*Tags: Data Quality, Performance, Deployment, Strategies*

---

**mandelbot** - *12:51:51*

You can add more sports to the marketrecorder by adjusting the filter. IE adding more `event_type_ids`/`country_codes` or `market_types`



```markets = betfairlightweight.filters.streaming_market_filter(

           event_type_ids=["7"],

           country_codes=["GB", "IE"],

           market_types=["WIN"]

)```

*Tags: General Technical*

---

**PeterLe** - *13:03:05*

Thanks Mandelbot. Sorry i didnt explain myself fully. I understand the code you posted above (filter). I could use a separate account and do it the way you suggested, but i though that if did it by adding a separate strategy I could set the context up correctly so that it recorded the additional sport to a different directory. ie multiple sports using a single instance, each recording to named directories

*Tags: Strategies*

---

**PeterLe** - *13:09:38*

Ah I see. OK in that case Ill keep it simple and use a separate account. Thanks for your help :+1:

*Tags: General Technical*

---

## 2022-07-28

**Mick** - *15:54:58*

I am trying to read the nearprice but can't seem to find any example code that includes it so I'm a bit lost. Can anyone give me some clues or a code snippit?



I feel it might be related to this line below...

betfairlightweight.filters.price_projection(price_data=['EX_ALL_OFFERS'])

*Tags: General Technical*

---

**Mick** - *17:05:56*

I have the following code...



```	price_filter = betfairlightweight.filters.price_projection(price_data=['EX_ALL_OFFERS', 'SP_PROJECTED'])

	print(f"mk_id={mk_id}")

	print(f"price_filter={price_filter}")

	market_books = trading.betting.list_market_book(market_ids=[mk_id],price_projection=price_filter)```

Which produces the following output



```mk_id=1.201434570

price_filter={'priceData': ['EX_ALL_OFFERS', 'SP_PROJECTED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}

Traceback (most recent call last):

  File "c:\Users\mick\Predictor\bfapi\bfex.py", line 2556, in &lt;module&gt;

    display_odds_for_this_race( course,stime,None,race_fp,            True,        "WIN")

  File "c:\Users\mick\Predictor\bfapi\bfex.py", line 1065, in display_odds_for_this_race

    market_books = trading.betting.list_market_book(market_ids=[mk_id],price_projection=price_filter)

  File "c:\users\mick\appdata\local\programs\python\python310\lib\site-packages\betfairlightweight\endpoints\betting.py", line 283, in list_market_book

    (response, response_json, elapsed_time) = self.request(method, params, session)

  File "c:\users\mick\appdata\local\programs\python\python310\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 55, in request

    self._error_handler(response_json, method, params)

  File "c:\users\mick\appdata\local\programs\python\python310\lib\site-packages\betfairlightweight\endpoints\baseendpoint.py", line 81, in _error_handler

    raise self._error(response, method, params)

betfairlightweight.exceptions.APIError: SportsAPING/v1.0/listMarketBook

Params: {'marketIds': ['1.201434570'], 'priceProjection': {'priceData': ['EX_ALL_OFFERS', 'SP_PROJECTED'], 'exBestOffersOverrides': {}, 'virtualise': True, 'rolloverStakes': False}}

Exception: None

Error: {'code': -32602, 'message': 'DSC-0018'}

Full Response: {'jsonrpc': '2.0', 'error': {'code': -32602, 'message': 'DSC-0018'}, 'id': 1}```

BTW, if instead I just had this at the start:

```	price_filter = betfairlightweight.filters.price_projection(price_data=['EX_ALL_OFFERS']) ```

then there is no error.

*Tags: Errors Debugging, Strategies*

---

**Mo** - *17:17:57*

Oh I thought you were streaming

*Tags: General Technical*

---

**Mick** - *17:23:17*

Not streaming - I don't think I need the high speed stuff. I'm betting hours before the off.

*Tags: Performance, Strategies*

---

**Newbie99** - *17:46:29*

SP_AVAILABLE is what you need if non-streaming

*Tags: General Technical*

---

## 2022-07-29

**LM** - *13:31:30*

Any examples of hedging/greening in flumine based on current strategy market exposure (or matched exposure for each runner)?

*Tags: Strategies*

---

**Peter** - *14:58:35*

Blotter class has a selection_exposure() method which gives you the net exposure of a runner for a given strategy.

*Tags: Strategies*

---

**PeterLe** - *16:09:10*

Could someone comment on how I may do this please.

I know BFLW uses the non virtualised prices as deafualt ( eg ex.available_to_back etc)

i tend to use  these prices in live  strategies, but Id like to be able to run some back tests for a particular use case using the virtualised prices.



I can see that there is a parameter set to true for virtualise in the filters, but I think that when this is true it merely receives the virtualise pices too:



```def price_projection(

    price_data: list = None,

    ex_best_offers_overrides: dict = None,

    virtualise: bool = True,

    rollover_stakes: bool = False,```

is there an easy way for me to choose whether to use virtualised or non virtualised prices in my backtesting/simulation?

Thanks in advance

*Tags: Deployment*

---

## 2022-08-01

**Michael** - *21:11:03*

This may be my ignorance, but how does framework.run() work. If I have functions defined within the strategy, how are they run?

*Tags: Strategies*

---

## 2022-08-02

**Mick** - *16:52:01*

Am I right in thinking that the betfair API employs UTC (Coordinated Universal Time) everywhere?

*Tags: General Technical*

---

## 2022-08-03

**Wayne** - *14:00:22*

I know of cases like this going back to 2017 - was originally worded as "credit" until it was clear offering loans would be problematic in terms of licensing and regulations. It was re-named trading capital then. Back then I think it was viewed as an incentive for profitable guys to scale up new/other ideas quicker

*Tags: Strategies*

---

**birchy** - *14:39:15*

This is a general programming question for the python gurus. I have a library of boilerplate stuff that I install via:



`python3 -m pip install -e [git+ssh://github/|git+ssh://github/](git+ssh://github/|git+ssh://github/)...`



Inside the `__init__.py` of that library, I have:



`import logging

logging.getLogger(__name__).addHandler(logging.NullHandler())`



...and inside each module of my library I have:



`import logging

logger = logging.getLogger(__name__)`



As far as I understand it, that's a conventional setup for libraries and logging handlers should be setup by the end user. When I import and use the library, I setup a root logger like this:



`import logging

from time import gmtime

from pythonjsonlogger import jsonlogger

from logging.handlers import RotatingFileHandler`



`logger = logging.getLogger()

custom_format = "%(asctime) %(levelname) %(message)"

os.makedirs('logs', exist_ok=True)

log_handler = RotatingFileHandler('logs/flumine_log.txt', maxBytes=int(1e6), backupCount=10)

formatter = jsonlogger.JsonFormatter(custom_format)

formatter.converter = gmtime

log_handler.setFormatter(formatter)

logger.addHandler(log_handler)

logger.setLevel([http://logging.INFO|logging.INFO](http://logging.INFO|logging.INFO))`



When running my code, none of the library logging messages are saved or outputted. I'm clearly missing something obvious. Any suggestions?

*Tags: Getting Started*

---

**birchy** - *17:35:11*

Fixed it! It was clearly an inheritance issue and then I realised that I wasn't explicitly importing my library, i.e. I was doing:

`from mylibrary` `import...`

But didn't have:

`import mylibrary`

*Tags: Errors Debugging*

---

## 2022-08-06

**Mick** - *21:43:55*

I'd like to get the BETDAQ API but have just seen they have an intimidating looking questionnaire ([https://api.betdaq.com/v2.0/Docs/default.aspx](https://api.betdaq.com/v2.0/Docs/default.aspx)) I'm nervous of being rejected. Any tips on what they're looking for? And one more thing - I haven't bet anything with them for many years except for a few bets yesterday - any idea how much regular betting they're expecting to see?

*Tags: Strategies*

---

## 2022-08-07

**Joel Beasley** - *22:09:57*

Yes I'd say I know enough to help on this :slightly_smiling_face: 



Expanding on what foxwood said, there are various obvious red flags for IR35 in a contract like having a set amount of hours per week, a named individual, then various secondary factors like having someone who tells you what to do on a daily basis, an email address on the client side etc - it's all about factors that indicate you are operating like a permanent employee rather than a more arms length service provider :slightly_smiling_face: 



The terms of the contract decide this, there are contract review services like Qdos, insurance can be taken based on what they say.



However, we're probably missing the main point in that the recent legal change was that the emphasis now falls on the client rather than the provider to determine IR35 status - as if later found to be 'inside' after all then the client has to pay all the income tax and national insurance, it was the other way around for the previous 20 odd years that IR35 has existed, i.e. the service provider was the one at risk

*Tags: General Technical*

---

## 2022-08-08

**Jorge** - *16:26:02*

Hi, I'm starting with the Binance Python API. Is there any group similar to this Slack for Binance trading? The API docs are really bad [https://python-binance.readthedocs.io/en/latest/overview.html](https://python-binance.readthedocs.io/en/latest/overview.html)

*Tags: Strategies*

---

**Mo** - *17:04:43*

Have you looked at this documentation? [https://binance-docs.github.io/apidocs/spot/en/#introduction](https://binance-docs.github.io/apidocs/spot/en/#introduction)

*Tags: General Technical*

---

## 2022-08-09

**Mo** - *09:16:50*

Yeah that's the one I've always used and found it pretty good so was a bit surprised by your comments but I guess you were looking at the Python package specific docs

*Tags: General Technical*

---

## 2022-08-11

**Mick** - *18:02:29*

Anyone here using the BETDAQ API? Is it easy enough to access via python? I came across this - &gt; [https://github.com/rozzac90/betdaq](https://github.com/rozzac90/betdaq) but it looks like it hasn't been touched for three years so either it's so rock solid it needs no alterations or it's so flaky that it's been abandoned!

*Tags: General Technical*

---

**D C** - *18:26:29*

I attempted a nodejs bot for Betdaq API with no luck. I came across this very project and it appeared to work (a few others here and I think the project author mentioned this was the case too) for market queries. I didn't persist as python is not one of my major skills and I had no joy getting nodejs SOAP packages to work with the Betdaq API. It was eating up lots of time trying and became very annoying so I basically gave up on betdaq until I come across a better SOAP package for nodejs then might have a look again. From what I remember several people said that this github project worked so if you are looking for a base probably be as well to start for that if python is your thing

*Tags: General Technical*

---

**D C** - *18:31:55*

I am not sure if it works to your requirements but I was certainly able to get available markets and things like that. Never got to the bet placement level stuff. If I was better with python I would have definitely used it as my start point

*Tags: General Technical*

---

## 2022-08-15

**Mo** - *18:05:22*

Depends what the client wants help with

*Tags: General Technical*

---

## 2022-08-17

**D C** - *11:29:21*

I think in general this group is pretty friendly - look at [@U01PJ5YMFBJ](@U01PJ5YMFBJ) - he asked loads and loads of questions and people were very helpful to him. For me, that aspect should determine how user friendly a community is.

*Tags: General Technical*

---

**Michael** - *11:40:35*

It's really interesting to see different people's attitudes to how to use the community and what their strategy is to get the best from it.

*Tags: Strategies*

---

**AndyL** - *11:49:50*

Ive gained hugely from the help here and the contacts made. Tips from [@UBS7QANF3](@UBS7QANF3) [@UGV299K6H](@UGV299K6H) [@U4H19D1D2](@U4H19D1D2) and [@UEA14GBRR](@UEA14GBRR) have all been key to becoming profitable, I'm currently +£6k for the year. But it's darn hard work! Im sure i spout utter rubbish half the time still, but at least it's not all the time like it was a year ago!!

*Tags: General Technical*

---

**river_shah** - *11:57:16*

For long running tasks such as market recorders, do you guys ever experience outages or does AWS /cloud platform of choice handle live migration gracefully and flumine keeps running?

*Tags: Data Quality, Deployment*

---

**liam** - *12:15:48*

I don't have problems with AWS EC2

*Tags: Deployment*

---

**river_shah** - *12:32:09*

Let’s say one refactors market recorder and need to update containers, what is the best way to terminate old instances and bring up new ones without causing any blips in data recording?

this is typically very stable code but still curious how 100% uptime can be achieved

*Tags: Data Quality*

---

**user34** - *14:04:24*

I recently received an email from AWS about one of my EC2s failing, so I had to manually stop and restart it. Apparently if I'd had Auto Recovery or Auto Scaling this would have been handled automatically, but I guess the current data might still have been lost.

*Tags: Deployment*

---

**Peter** - *15:12:32*

[@U012XEYK2FJ](@U012XEYK2FJ) I had a similar message too, though it turned out to be a networking issue interrupting external access EC2 instance that they resolved without them or me having to touch the affected server, and there was no interruption to my data collection.

*Tags: Deployment*

---

## 2022-08-18

**liam** - *09:06:24*

This is one of the negatives of flumines simplicity, in a more complex trading system you would separate the different components to allow strategy/framework/execution/price code to be updated without downtime.



My understanding is that [@UBS7QANF3](@UBS7QANF3) system allows this but it obviously comes at a complication/setup cost

*Tags: Getting Started, Strategies*

---

**Mo** - *09:18:36*

Easier to update individual components yeah but I still use the market recorder to scrape the price stream so I face this problem too



I agree with [@U016TGY3676](@U016TGY3676) if it was essential you had no gaps then I think the only solution is you run 2 instances and stagger the deployment of updates



I sort of follow the policy of buying the historic data for the sports I trade so the scraped data acts as something available for immediate analysis while the historic data is - I hope - a cleaner and more comprehensive data set when that is needed. However, as I'm sure you can guess or know the historic data is far from perfect



Given that there's huge overlap in what we're all scraping I think the ideal would be some kind of data sharing but that's a very gray area

*Tags: Data Quality, Deployment*

---

**birchy** - *11:07:32*

Given that most of us are running market recorders and collecting the same data sets, it would make sense if we amalgamated the data from a handful of instances but as [@UBS7QANF3](@UBS7QANF3) states, it's a grey area regarding Betfair licencing &amp; selling. Probably better to just team up with a couple of trustworthy colleagues and share data privately.

*Tags: Data Quality*

---

## 2022-08-19

**mandelbot** - *08:58:25*

well if anyone's interested I ended up going for a [https://www.amazon.co.uk/WD_BLACK-Battlefield-Bundle-speeds-3600MB/dp/B0989X548R/ref=sr_1_3?crid=HJVDEJZY2P23&amp;keywords=wd+black+sn750&amp;qid=1660895871&amp;sprefix=wd+black+sn750%2Caps%2C76&amp;sr=8-3|WD_BLACK SN750](https://www.amazon.co.uk/WD_BLACK-Battlefield-Bundle-speeds-3600MB/dp/B0989X548R/ref=sr_1_3?crid=HJVDEJZY2P23&amp;keywords=wd+black+sn750&amp;qid=1660895871&amp;sprefix=wd+black+sn750%2Caps%2C76&amp;sr=8-3|WD_BLACK SN750) + ACASIS enclosure

*Tags: Errors Debugging, Performance*

---

## 2022-08-20

**Dave** - *11:09:34*

Hardware question: I'd like to have an external drive(s) that's continuously kept synced with my S3 bucket (say once a day is fine). I'd also like to access said drive via a relatively quick connection (presumably USB will be sufficient) - something close enough to as if it was an internal drive. Anyone have any setups/components they can recommend for this?

*Tags: Getting Started*

---

**Jonjonjon** - *12:25:11*

When you add a strategy to a Flumine instance, for backtesting, it calls that func a few times to get the market definition from the historical file. If you have patched open with smart_open, or done something similar to let it work with compressed files, it both takes a lot of time and heats up the disk.

*Tags: Strategies*

---

**Johnny Boston** - *21:14:26*

`aws s3 sync` does what you want too

*Tags: Deployment*

---

**Dave** - *22:31:30*

The question is not regarding how to sync S3, but rather appropriate hardware for mass external storage

*Tags: General Technical*

---

## 2022-08-21

**Newbie99** - *18:55:04*

Completely off topic, but I'm a bit stuck with this...does anyone know how to either:



a) Enter credentials for a chrome extension via Selenium at run time



or



b) Start a new Selenium Chrome webdriver session with extensions already installed?



I can start a new session and load up the extension (Nord VPN in case anyone has gone down a similar route in the past), but I can't work out how to actually log into the Nord VPN chrome extension (I'm using Brave if we're being picky, but essentially that's Chrome).



Just wondering if any of you webscrapers have solved this in the past?

*Tags: Getting Started*

---

**birchy** - *19:03:34*

I've not used selenium but from my web scraping days, the setup was to enable cookies, simulate login request and IIRC the session token was in the headers and/or cookies? The login type was "interactive" without certs and I believe you had to load the main page first to initiate the cookies or something?

In hindsight, I think I've misunderstood the question but will leave my answer anyway. :grinning:

*Tags: Getting Started*

---

## 2022-08-22

**PeterLe** - *18:01:06*

So a question to the pro’s please

So once you have your data (in sample and out of sample etc)..its useful to tweak existing strategies etc I’ve used this lately with some good success (even found a brand new strategy too)



Question is: What is the next step in using the recorded data, do you collect additional data via logging controls and analyse with pandas/db etc

I just wondered what steps you would take from recording the data through to going live with a new strategy (just bullet points and a few pointers would be great for someone new to this approach)

(By the way; I read an entry by [@UGV299K6H](@UGV299K6H) a week or so ago about testing a well thought out hypothesis live and seeing how it plays out. it really struck a chord with me. This tends to be my approach too. Ill still continue with this but looking at alternative approaches too)

Many thanks

*Tags: Getting Started, Feature Engineering, Deployment, Strategies*

---

## 2022-08-23

**liam** - *08:16:45*

My general approach for new strategy development:



• Record raw data (s3)

• Process data to create signals etc. into csv's as and when, I use Strategy classes rather than loggingcontrols (quicker / more data available) through slimmed down flumine simulation (multiprocessing / [speed])

• Load into jupyter using pandas

• Join / process / create more signals if required

• Analyse / model / backtest theoretical pnl / lots of graphs

• Create real strategy / simulate / optimise stake / triggers for market capacity

• Go live

Start to finish is normally a few hours before I get bored :joy:

*Tags: Feature Engineering, Performance, Deployment, Strategies*

---

**PeterLe** - *10:17:38*

Well as you know I'm still learning how to use Python. From knowing nothing, it wasn't as bad as i thought to get the recorder and a few strategies running (the latter with help from others on here and your examples).

I've now started to build out from those initial strategies and 'bolt stuff' on. Its a really good way of learning by the way, by using the simulator to test code (if anyone else is a beginner)

I've also learned Numpy; Pandas, Jupyter and a bit of C# too. I know have my recorders/strategies running on Ubuntu, which was easy to implement and virtually maintenance free....phey!

However, the more I learn about Python, the more I realise there's a lot more to learn, so this takes time and is part of the process. So in answer to your question, there is no one part as such, its a combination of everything

For me though, i just think of the whole thing as another tool/mentality/approach. It wont replace my preferred method of strategy development implementation, which i mentioned in the opening post, I see it more of a tool to enhance that.

I can see that there are some very technically competent folk on here who maybe not making a profit, I think that is because of the path you get led down and how your thought processes develop/channeled if you use this as your sole MO.

Either way, I'm not in any rush and the money is still rolling in, so just enjoying the trip!

*Tags: Getting Started, Feature Engineering, Strategies*

---

**Alessio** - *14:22:16*

Hey folks, inplay q: what is your favorite way of dealing with inconsistent data between betfair and whatever-other-data-source-for-in-play you use? Say, your source is usually good and fast, but is missing some shots.. do you try to build consensus or do you just stick to one source and eat the errors (assuming our source is on average more truthful than the betfair one :wink:

*Tags: Errors Debugging*

---

**liam** - *14:42:48*

Yes and that as a whole over time it will be correct, of course the market can be miss-priced but if I think a team/runner is about to win but the odds are 100/1 for an extended period of time it doesn't make sense to go all in and start backing with the same stake I would be if it was 1.10.



Basically using the wisdom of the crowds to reduce the risk, harder when things are tighter / errors less extreme

*Tags: Errors Debugging*

---

**liam** - *14:49:46*

Do your -ev bets point to errors?

*Tags: Errors Debugging*

---

## 2022-08-24

**VT** - *19:52:36*

Last month I lost a considerable amount for being 'stuck' in suspended markets in football, this is so recurrent that I had to create a specific category to record these losses in my spreadsheet.



Since yesterday the problem has gotten even worse, they are suspending many times for no reason, something like 20, 30 suspensions in a game, most of them short but sometimes it takes more than 1 minute to return.



An obvious option would be to keep money on Pinnacle to close positions there, but it's not that simple because some bets are against time, lay at high odds, etc... and also because Pinnacle removes events from its grid live when they want, limit markets, anyway, this has happened frequently and it's not a matter of 'scout information' why bookmakers (bet365, WilliamHill) keep the bets open.

*Tags: Deployment*

---

## 2022-08-26

**Unknown** - *14:06:52*

Just a question about Ubuntu please.

I have some stuff running on Ubuntu just fine and my intention was just leave it running (for months) if possible with little intervention on my part....

However, I just logged on to see this message and wondered how you others do it and what's best practice. Do you mainly ignore and update periodically?

I dont really want to be stopping and starting if poss. many thanks

*Tags: General Technical*

---

## 2022-08-27

**Newbie99** - *13:34:10*

When backtesting, I'm getting some unexpected behaviour using market.event.get.



Just using a simple worker as follows (purely to see whats coming through for now, obviously this doesn't actually do anything as such):



```def each_way_and_place(context: dict, flumine) -&gt; None:

    for market in [m for m in flumine.markets if m.event_type_id == '7' and m.market_catalogue is not None and m.market_book.status not in ['CLOSED', 'SUSPENDED']]:

        check_market_type(market)



def check_market_type(market):



    if market.market_type == 'WIN':

        place_market = market.event.get("PLACE")

        if place_market is not None:

            print({'main_market_id': market.market_id,

                   'main_market_type':market.market_type,

                   'main_market_status': market.market_book.status,

                   'get_market_id': place_market[0].market_id,

                   'get_market_type': place_market[0].market_type,

                   'get_market_status': place_market[0].market_book.status})

        else:

            print({'main_market_id': market.market_id,

                   'main_market_type':market.market_type,

                   'main_market_status': market.market_book.status})

    elif market.market_type in ['PLACE', 'OTHER_PLACE']:

        win_market = market.event.get("WIN")

        print({'main_market_id': market.market_id,

            'main_market_type':market.market_type,

               'main_market_status': market.market_book.status,

               'get_market_id': win_market[0].market_id,

               'get_market_type': win_market[0].market_type,

               'get_market_status': win_market[0].market_book.status})```

I just get the following:



```1.200622960 added

1.200652220 added

1.200652755 added

1.200622608 added

1.200626498 added

1.200622877 added

1.200652046 added

1.200652131 added

1.200652756 added

1.200652047 added

1.200622609 added

{'main_market_id': '1.200652756', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652755', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652047', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652046', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652756', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652755', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200622609', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622608', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

1.200652133 added

{'main_market_id': '1.200652047', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652046', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652756', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652755', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200622609', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622608', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652047', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652046', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

1.200652135 added

1.200622880 added

1.200622965 added

1.200652050 added

{'main_market_id': '1.200652756', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652755', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200622609', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622608', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

1.200626500 added

1.200652225 added

{'main_market_id': '1.200652756', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652755', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200626500', 'main_market_type': 'WIN', 'main_market_status': 'OPEN'}

{'main_market_id': '1.200622609', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622608', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652225', 'main_market_type': 'WIN', 'main_market_status': 'OPEN'}

1.200626501 added

1.200622882 added

1.200652136 added

1.200652226 added

1.200652052 added

1.200622883 added

1.200622966 added

{'main_market_id': '1.200652756', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652755', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200626501', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200626500', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}{'main_market_id': '1.200622609', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622608', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}



{'main_market_id': '1.200652226', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652225', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200622883', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622882', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652052', 'main_market_type': 'WIN', 'main_market_status': 'OPEN'}

{'main_market_id': '1.200652136', 'main_market_type': 'WIN', 'main_market_status': 'OPEN'}

1.200652137 added

1.200652758 added

1.200652053 added

1.200622967 added

{'main_market_id': '1.200622609', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622608', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}{'main_market_id': '1.200626501', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200626500', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}



{'main_market_id': '1.200652226', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652225', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200622883', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622882', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652053', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652052', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652137', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652136', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200622967', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622966', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200626501', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200626500', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}{'main_market_id': '1.200622609', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622608', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}



{'main_market_id': '1.200652226', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652225', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200622883', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200622882', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652053', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652052', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}

{'main_market_id': '1.200652137', 'main_market_type': 'PLACE', 'main_market_status': 'OPEN', 'get_market_id': '1.200652136', 'get_market_type': 'WIN', 'get_market_status': 'CLOSED'}```

Which seems very odd (i.e. it always shows no PLACE market when checking from the WIN market and when checking from the PLACE market, the WIN market is always closed.



Interestingly, when paper trading this works as expected, i.e. the markets are all open etc.



I'm wondering therefore, has anyone else had issues using this functionality when backtesting (all self recorded files via Flumine, randomly selected dates in June, July and August, the above markets are all GB &amp; IE on 1st or 2nd of July)?

*Tags: Strategies*

---

## 2022-08-29

**D C** - *09:54:07*

Generic question not specific to flumine/BFLW - if you place a bet asynchronously that would fail if placed synchronously, do you get anything at all on the order stream? I am trying to get my head around edge cases like the following example:

1. You place a bet inply with async flag

2. Response comes back with PENDING state.

3. Market suspends before the inplay delay elapses which would be a failed bet under sync bet placement conditions.

What happens here? Zero order stream update for this bet or some kind of response with the customer order ref and a null bet ID or similar that allows you to determine the failure?

Essentially I am asking if we can rely on order strem 100% or if best practice for using async is to have some call or listCurrentOrders in addition for any bets that slip through the net (if that is possible).

*Tags: Errors Debugging*

---

## 2022-09-02

**Newbie99** - *19:10:39*

With regards to balancing EC2 instances / Betfair connections &amp; markets, is there a consensus on the best way to split things up?



Currently I just stick everything on a single T3.micro and in the last few weeks I've been getting a lot of latency warnings, to the point where at the weekends it just stops functioning.



This co-insides with me looking at far more football markets than before and whilst of course my code will be inefficient and there will absolutely be improvements, in terms of a sensible approach to grouping, what is the optimal way?



Currently it feels as though a single instance is fine with possibly somewhere between 2-3k markets (across horse racing and football), but above this it struggles.



So obviously I need to look for bottlenecks in my code, but aside from that, should I create a separate EC2 instance or should I split the football markets up across multiple connections etc?

*Tags: Performance, Deployment*

---

**Newbie99** - *22:02:04*

...and on the efficiency note, is anyone well versed in cprofilev as I was struggling to get the output via a browser window so I can view in real time?



On a local machine it works fine, but when I try to run it on my EC2 instance, I can't seem to route the output to an my elastic ip address, I assumed it would be:



```python3 -m cprofilev -a 0.0.0.0 startup.py```

and that works correctly in the sense that it runs, but I can't see the output anywhere.

*Tags: Deployment*

---

## 2022-09-03

**foxwood** - *09:15:47*

To me that says you are sending the output to IP address 0.0.0.0. If you want to send it to the local machine (ie the machine it is running on) try the loopback address 127.0.0.1 (which is the default if you omit the IP according to docs) and for remote use your current router external IP - if you have a local network then redirect incoming from EC2 IP at router to specific PC.

*Tags: Deployment*

---

**Newbie99** - *09:22:38*

The default output as you say is 127.0.0.1:4000 (or localhost:4000). However I have an elastic IP setup on AWS, which normally I send data to via Flask as follows:



```socketio.run(app, debug=False, host='0.0.0.0', port=PORT_NO)```

I can then view the output as expected from my app.



However (obviously not running my flask app at this point) when I put in the output as 0.0.0.0 and any port from cprofilev the page doesn't exist.



So I'm assuming I'm missing something simple.

*Tags: Getting Started, Errors Debugging, Deployment*

---

**Mo** - *11:20:29*

Another classic book and free although it's a bit more machine learning-y than statistics fundamentals: [https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf](https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf)

*Tags: General Technical*

---

**Newbie99** - *11:25:56*

Ah, so it was quite simple, that worked replacing 0.0.0.0 with the private IP from the AWS console dashboard!

*Tags: Deployment*

---

**Unknown** - *11:37:28*

although the next question is how to interpret the results (I am assuming the issue likely lies within a worker, where I make some API calls, although oddly they are quite infrequent):

*Tags: General Technical*

---

## 2022-09-04

**Newbie99** - *12:18:59*

This Reddit thread (about AWS costs supposedly from a compromised account) are quite scary!!!



[https://www.reddit.com/r/aws/comments/x03vay/hacked_aws_account_is_facing_200000_in_charges/](https://www.reddit.com/r/aws/comments/x03vay/hacked_aws_account_is_facing_200000_in_charges/)

*Tags: Deployment*

---

**Graham** - *12:58:08*

[@UFTBRB3F1](@UFTBRB3F1) I was reading a few of those recently too. But not hacked, just mismanaged - mainly from unknowing startups. 



The billing thresholds don’t actually do anything aside from alerting. But, AWS and GCP have a good track record of forgiving such accounts.



It’s one of my biggest bug bears of them, the pricing is quite difficult to figure out.

*Tags: Errors Debugging, Deployment*

---

**Aaron Smith** - *14:10:48*

Had a friend who forgot to turn somthing off and woke up to a 5k bill. He contacted AWS and they ended up not charging anything. He had to give some written explanation on how he is going to prevent this in the future. Looks like you can screw up once and be forgiven, but maybe shouldnt do it much more than that :smile:

*Tags: Deployment*

---

**foxwood** - *21:46:23*

That motivated me to close the AWS account that I never use !

*Tags: Deployment*

---

## 2022-09-11

**Jonjonjon** - *23:22:24*

I am running almost 200 strategy instances under a single Flumine instance on a single script.



I'm concerned that it might cause performance issues, due to the multiple calls to `check_market_book`

What is the recommended way to check whether or not I am likely to be experiencing latency issues?



Looking though the logs, I have this from the trade log:



`"date_time_created": "2022-09-11 22:03:05.967328", "publish_time": "2022-09-11 22:03:05.914000"`



I believe "publish_time" is the time that comes from the streaming market book update, and "date_time_created" is the time, which is around 53 ms. But assumes that my clock is aligned with the Betfair clock.



How would other users measure this?

*Tags: Performance, Strategies*

---

## 2022-09-12

**liam** - *08:57:34*

That difference is your theoretical tick to trade creation, however like you have mentioned it is based on your clock being accurate and it has the potential to combine/hide network and CPU issues.



In an ideal world you would be monitoring:



• `MarketBook.publish_time` -&gt; `MarketBook.now`: time taken from betfair to your program (ie. mostly network)

• `MarketBook.now` -&gt; `Order.date_time_created`: time taken from MarketBook received to order created ie. time taken to process the book update (probably the one you are interested in if you have 200 strategies)

• `Order.date_time_created` -&gt; `Order.responses.date_time_placed`: time taken from Order creation to Order response received (network / thread pool exhaustion)

We have a [https://github.com/betcode-org/flumine/issues/338|task](https://github.com/betcode-org/flumine/issues/338|task) to try and improve this

*Tags: General Technical*

---

**Fab** - *13:04:50*

In the last week or so I experienced several GitHub "unicorn" errors around this time of day

*Tags: Errors Debugging*

---

## 2022-09-13

**Unknown** - *07:56:59*

You got me thinking so I did some tests yesterday on an instance I have running with 6 strategies that I know are slow at processing, here is the following at order creation:



```latency = (trade.date_time_created - market_book._datetime_created).total_seconds()```

Very strategy dependant but has the potential for the order to make a big difference in pnl / matching

*Tags: Performance, Strategies*

---

**Jonjonjon** - *20:47:40*

Is your latency column the "mean" value?

*Tags: Performance*

---

**Jonjonjon** - *21:18:30*

Shows that Flumine is fast enough despite being written in Python. :tea:

*Tags: General Technical*

---

## 2022-09-14

**Jorge** - *09:26:07*

Hi, I'm facing this problem: I need to load 600 files in live-trading, each of them contains a row of a DF, and concat them into a Pandas DataFrame for analysis. Anyone knows what would be a fast file format to do this? I've tried with .parquet which takes 0.03 secs/file but I need something faster...

*Tags: Feature Engineering, Deployment, Strategies*

---

**Jorge** - *09:27:14*

Reading the file with `fastparquet.ParquetFile()` is very fast but I cannot find a way of concatenating the files without converting to Pandas (which is slow...)

*Tags: Feature Engineering, Performance*

---

**Mo** - *09:30:25*

A few questions:



1. Why does it need to be fast? Can't you read them all on startup and be done with it?

2. Do they need to be separate files? Reading one file will probably be quicker

3. Do you actually need the end result to be a DataFrame? As you say, pandas performance is sometimes not the best 

*Tags: Feature Engineering, Performance*

---

**Jorge** - *09:37:10*

1. Yes, I read them on startup but I have multiple factors and each factor has 600 files so I would like it to be as fast as possible.

2. I save them as separate real-time files.

3. It would be very convenient, the rest of my infra supports Pandas

*Tags: Feature Engineering*

---

**CL** - *09:38:47*

Maybe just try pickle? I'm using feather (from pyarrow) for fast io with small data frames, but if you're python only I think pickle is pretty fast.

*Tags: General Technical*

---

**Mo** - *09:39:40*

Honestly I think you need to solve this by outputting the data differently in the first place. For example, stick it into rows in a database table

*Tags: General Technical*

---

**Jorge** - *09:41:04*

That makes sense [@UBS7QANF3](@UBS7QANF3), but I want to avoid using databases :smile:

*Tags: General Technical*

---

**liam** - *09:41:14*

pandas is crap for trading live

*Tags: Feature Engineering, Deployment, Strategies*

---

**Mo** - *09:41:34*

Very easy to get a database table into pandas as well

*Tags: Feature Engineering*

---

**Jorge** - *09:42:03*

What is your alternative [@U4H19D1D2](@U4H19D1D2)? Database as well?

*Tags: General Technical*

---

**Mo** - *09:42:10*

Maybe SQLite is sufficiently not-database for you

*Tags: General Technical*

---

**liam** - *09:42:52*

for me anything latency sensitive is flat files loaded at runtime

*Tags: Performance*

---

**Jorge** - *09:46:51*

Ah ok I get it, you read the csv with python and avoid pandas

*Tags: Feature Engineering*

---

**liam** - *09:51:27*

Going back to your original question, 'each of them contains a row of a DF'?

*Tags: General Technical*

---

**Peter** - *10:00:43*

I get "I want to avoid using databases" but this really does sound like it's begging for a sqlite database.



Write to that instead of flat files and get sub millisecond reads when you need the data back.



(disclaimer, I'm a recent convert having recently used this approach to solve a processing bottleneck in one of my strategies).

*Tags: General Technical*

---

**ShaunW** - *10:15:04*

Sounds like trying to solve a design issue with brute force. I'd question the need for 600 files by the sniff test if nothing else. And/or I agree with [@U9JHLMZB4](@U9JHLMZB4), wanting to avoid a database doesn't trump needing one.

*Tags: General Technical*

---

**Jorge** - *12:57:27*

ahahaha time to move to a database I guess

*Tags: General Technical*

---

## 2022-09-16

**Zenith** - *11:43:01*

Thanks Mo, appreciate the help.

*Tags: General Technical*

---

**Aaron Smith** - *15:19:14*

I used to create event files myself (pretty much the same way flumine does, not sure if it didnt exist back then or if i overlooked it), but now as i m getting some weird results (vaidation failed due to some negative numbers as [@U4H19D1D2](@U4H19D1D2) probs remembers [https://betcode-org.slack.com/archives/C4H05ML2E/p1663231320648429](https://betcode-org.slack.com/archives/C4H05ML2E/p1663231320648429) ), i wanted to switch to using the method implemented in flumine. Is there anything more it does than creating those event_files that maybe my current code didnt do?

*Tags: Errors Debugging*

---

**Aaron Smith** - *15:23:37*

indeed :smile: though its been working for pretty long, and the new code (using transaction class) looks like it could never produce such error. Well, i ll see once i use flumines internal method :slightly_smiling_face:

*Tags: Errors Debugging*

---

**Unknown** - *21:05:55*

What sort of CPU utilisations do people have on their servers? This is mine. I'm wondering if it's likely to be a problem or not.



It's a machine with 2 CPU cores and 4GB RAM.

*Tags: Deployment*

---

## 2022-09-17

**Unknown** - *09:07:54*

Last 24hrs, tbh yours seems high but as long as you aren't getting latency warnings I don't see an issue

*Tags: Performance*

---

**Jonjonjon** - *10:34:11*

Thanks for sharing. How many Flumine scripts do you run per instance? I think I am doing 4 or 5. I like the simplicity of having everything on one machine

*Tags: General Technical*

---

**Newbie99** - *13:40:23*

Just to come back to this again, I'm having trouble passing parameters, my data is as follows (should it be a list of tuples instead or does it not matter), which are all grouped by event_id):



```[['Y:/betcode/unzipped_files\\1.201875723', 'Y:/betcode/unzipped_files\\1.202058901', 'Y:/betcode/unzipped_files\\1.202058903', 'Y:/betcode/unzipped_files\\1.202058896', 'Y:/betcode/unzipped_files\\1.202058942', 'Y:/betcode/unzipped_files\\1.202020603', 'Y:/betcode/unzipped_files\\1.202020594', 'Y:/betcode/unzipped_files\\1.202020596', 'Y:/betcode/unzipped_files\\1.202020589'], ['Y:/betcode/unzipped_files\\1.202347516', 'Y:/betcode/unzipped_files\\1.202108260', 'Y:/betcode/unzipped_files\\1.202108265', 'Y:/betcode/unzipped_files\\1.202108267', 'Y:/betcode/unzipped_files\\1.202108306', 'Y:/betcode/unzipped_files\\1.202228381', 'Y:/betcode/unzipped_files\\1.202228342', 'Y:/betcode/unzipped_files\\1.202228335'], ['Y:/betcode/unzipped_files\\1.202261399', 'Y:/betcode/unzipped_files\\1.202261353', 'Y:/betcode/unzipped_files\\1.202261358', 'Y:/betcode/unzipped_files\\1.202261360', 'Y:/betcode/unzipped_files\\1.202277070', 'Y:/betcode/unzipped_files\\1.202277031', 'Y:/betcode/unzipped_files\\1.202277029', 'Y:/betcode/unzipped_files\\1.202277024'], ['Y:/betcode/unzipped_files\\1.202093071', 'Y:/betcode/unzipped_files\\1.202084753', 'Y:/betcode/unzipped_files\\1.202084748', 'Y:/betcode/unzipped_files\\1.202084755', 'Y:/betcode/unzipped_files\\1.202084762', 'Y:/betcode/unzipped_files\\1.202346073', 'Y:/betcode/unzipped_files\\1.202346071']]```

My function is as follows:



```def start_backtest_a(chunked_markets, max_workers, snapshot, strategy_names, event_list):



    with ProcessPoolExecutor(max_workers=max_workers) as executor:

        futures = executor.map(startup, chunked_markets, snapshot, strategy_names, event_list)```

Where startup is essentially this (from Liam's example in the docs):



```def run_process(markets):

    client = clients.SimulatedClient()

    framework = FlumineSimulation(client=client)

    strategy = LowestLayer(

        market_filter={"markets": markets},

        context={"stake": 2},

    )

    with mock_patch("builtins.open", smart_open.open):

        framework.add_strategy(strategy)

        framework.run()```

But it needs some parameters, which are causing the issue.



snapshot is a static dict (e.g. {'a': 1})

strategy_names is a list of strategy names (e.g. ['strat_a', 'strat_b'])

event_list is either a list of historic data (e.g. scores data to map against a betfair event) or a bool, so in this instance False as I'm not passing any historic data.



However it appears to be expecting an iterable for each parameter.



```Traceback (most recent call last):

  File "D:/Python37/webpages/backtesting.py", line 484, in &lt;module&gt;

    output_list = start_backtest_a(chunked_markets, CPUs, snapshot, strategy_names, event_list)

  File "D:/Python37/webpages/backtesting.py", line 346, in start_backtest_a

    futures = executor.map(startup, chunked_markets, snapshot, strategy_names, event_list)

  File "D:\Python38\lib\concurrent\futures\process.py", line 674, in map

    results = super().map(partial(_process_chunk, fn),

  File "D:\Python38\lib\concurrent\futures\_base.py", line 600, in map

    fs = [self.submit(fn, *args) for args in zip(*iterables)]

  File "D:\Python38\lib\concurrent\futures\_base.py", line 600, in &lt;listcomp&gt;

    fs = [self.submit(fn, *args) for args in zip(*iterables)]

  File "D:\Python38\lib\concurrent\futures\process.py", line 182, in _get_chunks

    it = zip(*iterables)

TypeError: 'bool' object is not iterable```

*Tags: Errors Debugging, Strategies*

---

**Newbie99** - *13:44:57*

I tried an alternative approach too, but this doesn't work (i.e. it runs, but the same issue arises in that it seems to split up the markets, even though they are grouped), so I think I'm using this incorrectly:



```def start_backtest_b(chunked_markets, max_workers, snapshot, strategy_names, event_list):



    with ProcessPoolExecutor(max_workers=max_workers) as executor:

        futures = [executor.submit(startup, chunk, snapshot, strategy_names, event_list) for chunk in chunked_markets]```

*Tags: Strategies*

---

**Newbie99** - *13:47:22*

So I believe if I'm understanding correctly, if I can pass a single parameter for each of the parameters it expects (apart from markets) then it should work.



But I can't work out how to do that.

*Tags: General Technical*

---

**Newbie99** - *16:10:47*

This is following on from the earlier conversation about backtesting with multi-proc (but isn't specific to chunking and event_processing, or at least I don't think it is...that said who knows).



So, I pass a list of markets to this function called startup, which runs as expected, in this instance it calls a worker, which doesn't run as expected.



Here is the startup function (this appears to run correctly, i.e. I can see the markets are loaded, market catalogues added and profit / orders always show as 0, but at least that confirms the script is working):



```def startup(markets, snapshot={}, strategy_names=strategy_names, event_list=False):

    logger = logging.getLogger()



    custom_format = "%(asctime) %(levelname) %(message)"

    log_handler = logging.StreamHandler()

    formatter = jsonlogger.JsonFormatter(custom_format)

    formatter.converter = time.gmtime

    log_handler.setFormatter(formatter)

    logger.addHandler(log_handler)

    logger.setLevel(logging.CRITICAL)  # Set to logging.CRITICAL to speed up simulation



    start_time = get_utc_time()



    settings = [setting for setting in rc if setting['on'] is True and setting['strategy_name'] in strategy_names]



    client = clients.SimulatedClient(simulated_full_match=False)



    framework = FlumineSimulation(client=client)



    print('Start of chunk', '-' * 150)

    for market in markets:

        print(check_event_id(market))



    with mock_patch("builtins.open", smart_open.open):

        for s in settings:

            max_selection_exposure = s['max_selection_exposure'] if true_or_false(s['max_selection_exposure']) != False else None

            if s['strategy_type'] == 'simple':



                ### ---- Remember to change listener kwargs , "listener_kwargs": {"seconds_to_start": 7200, "inplay":False}



                strategy = betting_strategy(start_time=start_time, settings=s, paper=client.paper_trade,

                                            market_filter={"markets": markets, "listener_kwargs": {"seconds_to_start": 7200, "inplay":False}, "event_processing": True},

                market_data_filter=streaming_market_data_filter(

                fields=[

                    "EX_ALL_OFFERS",

                    "EX_TRADED",

                    "EX_TRADED_VOL",

                    "EX_LTP",

                    "EX_MARKET_DEF",

                    "SP_TRADED",

                    "SP_PROJECTED",

                ]

                ),

                streaming_timeout=2,

                max_selection_exposure=max_selection_exposure,

                max_order_exposure=s['max_order_exposure'],

                conflate_ms=s['conflate'],

                name=s['strategy_name'],



                )



                framework.add_strategy(strategy)





        worker_settings_list = [

            {'function_name': 'get_in_play_football_data', 'function': get_in_play_football_data, 'func_kwargs': None ,'interval': 15, 'start_delay': 0}

        ]



        for f in get_worker_functions(settings):

            function_setting = [ws for ws in worker_settings_list if str(ws['function_name']) == f['function_name']]

            if len(function_setting) &gt; 0:

                function_setting = function_setting[0]



                framework.add_worker((BackgroundWorker(

                            framework,

                            function_setting['function'],

                            func_kwargs=function_setting['func_kwargs'],

                            interval=function_setting['interval'],

                            start_delay=function_setting['start_delay']

                        )))



        ''' Always add Risk Calc worker '''

        framework.add_worker(

            BackgroundWorker(

                framework,

                calc_risk,

                func_kwargs=None,

                interval=0.5,

                start_delay=5

            ))



        ''' Add in Middleware to get Market Catalogue '''

        framework.add_market_middleware(MarketCatalogueMiddleware())



        framework.run()



    for market in framework.markets:

        print("Order Count: {0}".format(len([o for o in market.blotter])))

        print("Profit: {0:.2f}".format(sum([o.profit for o in market.blotter])))



    if strategy_names[0] == 'market_data_extract':

        return write_market_context_to_json(framework)

    else:

        return write_pl_to_json(framework,group_by_market=False)```

Now, when I noticed the worker wasn't producing anything I did a quick test as follows:



```def get_in_play_football_data(context: dict, flumine) -&gt; None:

    print('ABCD')

    s = [m for m in flumine.markets]

    print(s)```

On screen I see the following:



```1.202093022 added

ABCD

[]

Order Count: 0

Profit: 0.00```

So the worker is running as we can see the printout, but how can s be an empty list?

*Tags: Performance, Strategies*

---

**Newbie99** - *19:37:46*

I can probably re-write what I need in a single thread in all honesty for this one, I've got into the habit of using workers as in live otherwise I end up with a lot of latency warnings (probably not for this one as it happens, its not very CPU intensive).

*Tags: Performance, Deployment*

---

**Newbie99** - *19:38:18*

That said I'll try and think how to re-write for middleware as I'd like to get more up to speed with how that works

*Tags: Performance*

---

**Newbie99** - *20:52:03*

Sorry to dwell on this, but looking at: [https://betcode-org.github.io/flumine/markets/#middleware](https://betcode-org.github.io/flumine/markets/#middleware)



I tried the following:



```from flumine.markets.middleware import Middleware



class FootballMiddleware(Middleware):

    def __call__(self, market) -&gt; None:

        if market.event_type_id in ['1', 1] and market.market_catalogue is not None \

            and market.market_book is not None and market.seconds_to_start &lt;= 7200 \

            and market.market_book.status not in ['CLOSED', 'SUSPENDED'] \

            and market.market_type not in ['HALF_TIME_SCORE']:

            update_market(market)```

Adding to the framework as follows:



```framework.add_logging_control(FootballMiddleware())```

But I get the following:



```concurrent.futures.process._RemoteTraceback: 

"""

Traceback (most recent call last):

  File "D:\Python38\lib\concurrent\futures\process.py", line 239, in _process_worker

    r = call_item.fn(*call_item.args, **call_item.kwargs)

  File "D:\Python37\webpages\backtesting.py", line 170, in startup

    framework.add_logging_control(FootballMiddleware())

  File "D:\Python38\lib\site-packages\flumine\baseflumine.py", line 124, in add_logging_control

    [http://logger.info|logger.info](http://logger.info|logger.info)("Adding logging control {0}".format(logging_control.NAME))

AttributeError: 'FootballMiddleware' object has no attribute 'NAME'

"""



The above exception was the direct cause of the following exception:



Traceback (most recent call last):

  File "D:/Python37/webpages/backtesting.py", line 445, in &lt;module&gt;

    output_list = start_backtest_a(chunked_markets, CPUs, snapshot, strategy_names, event_list)

  File "D:/Python37/webpages/backtesting.py", line 365, in start_backtest_a

    mini_output_list = job.result()  # wait for result

  File "D:\Python38\lib\concurrent\futures\_base.py", line 432, in result

    return self.__get_result()

  File "D:\Python38\lib\concurrent\futures\_base.py", line 388, in __get_result

    raise self._exception

AttributeError: 'FootballMiddleware' object has no attribute 'NAME'```

I assumed it would be a simple change:



```class FootballMiddleware(Middleware):

    def __call__(self, market) -&gt; None:

        self.NAME = 'Football_Logging_Control'

        if market.event_type_id in ['1', 1] and market.market_catalogue is not None \

            and market.market_book is not None and market.seconds_to_start &lt;= 7200 \

            and market.market_book.status not in ['CLOSED', 'SUSPENDED'] \

            and market.market_type not in ['HALF_TIME_SCORE']:

            update_market(market)```



But the error still persists, so I'm clearly mis-understanding this. Do you have any suggestions by chance?

*Tags: Errors Debugging, Strategies*

---

**Newbie99** - *21:10:07*

(sorry that may have come across as ungrateful, didn't mean it that way, appreciate all the help)!

*Tags: General Technical*

---

## 2022-09-18

**Newbie99** - *10:16:19*

Sorry just 1 more question on the subject, as it has got me (and I believe a couple of others too) in a bit of a muddle.



Ignoring back-testing for a second and only considering LIVE, when (and why) is it appropriate to use middleware instead of a worker?



I'm thinking of use cases along the following lines:



a) Performing calculations across multiple market types (e.g. WIN / PLACE or OVER_UNDER_X / OVER_UNDER_Y)

b) Receiving live score data from a 3rd party provider and performing some sort of operations on this

*Tags: Deployment*

---

**Peter** - *10:36:26*

Bringing this back to basic principles, workers are executed on a schedule / frequency that you determine and (normally) in a different thread hopefully on a different processor so have minimal impact on your strategy's processing time. Whereas middleware will be triggered with each market update and will delay / extend your strategy's processing.



So which is appropriate is going to depend on the CPU resources needed for your processing and the criticality of having it done for every market update, and oftentimes there won't be a clear answer.



To put this into context with your examples, for a) if your processing is quick and needs updating every time the prices move, you probably want middleware (though you may also want to cache the prices and check that the update has moved the ones you're interested in before executing the bulk of your processing). For b) if you're ingesting and processing a lot of data from an API and/or dealing with its latency and/or are not allowed to make up to 20 calls to it per second, then a worker is likely to be a better solution.

*Tags: Performance, Strategies*

---

**Newbie99** - *11:13:06*

Cool thanks, that is in line with what I suspected, but wanted to make sure, appreciate the clear explanation that is a great help.

*Tags: General Technical*

---

**Newbie99** - *16:02:10*

Yep, that's essentially what I did (hardcoded just to test) so will re-write properly with that in mind.



Once again thank you for your help on this, I think I've got a much better understanding now!

*Tags: General Technical*

---

**Newbie99** - *18:04:58*

One more random question, lets say you are looking at 2 market types (E.g. WIN, PLACE) and lets say there are 500 markets on each, presumably you would just have 1 connection and not worry about it.



But if say there are 4000 markets in total, split evenly as 2000 for each (I know that's unrealistic for these two market types, but I'm just using those as an example), is there any benefit in splitting things out across multiple connections (E.g. WIN on connection 1 and PLACE on connection 2), or does it simply not matter (i.e. all that matters is what you actually do in terms of processing, how many markets per connection is not really relevant compared to the number of markets overall).

*Tags: General Technical*

---

**Peter** - *18:13:14*

Are we talking backtesting, in which case, connections aren't relevant, or live processing, in which case you wouldn't get up to 2000 each for WIN or PLACE markets?



If you're talking live processing then running separate instances of Flumine to achieve separate connections means that you won't be able to link different markets from the same event as they won't be on the same instance.

*Tags: Deployment*

---

**Newbie99** - *20:10:56*

Only talking about LIVE here, just picking random markets as an example, perhaps more realistically if we look at football, lets say we have a single Flumine instance and the market types are:



MATCH_ODDS

OVER_UNDER_25

OVER_UNDER_15

OVER_UNDER_05



That could be circa 4000 markets some days, so I'm just wondering if there is a preferred way to structure that, i.e. 1 connection with all 4, or perhaps 2 connections with 2 market types each. Or does it simply not matter as you're dealing with 4000 markets either way (appreciate its not always that many, just picking a big number as an example in case it makes a difference)

*Tags: Deployment*

---

**Peter** - *20:21:10*

Same response. If your strategy requires you to access data from multiple markets on the same event, they all have to be accessed by the same instance of Flumine, i.e. the same market connection. So if the number of markets (or the processing time) requires splitting them, country codes would be a better splitter than market type.

*Tags: Strategies*

---

**Newbie99** - *21:00:01*

Appreciate the help (again :slightly_smiling_face:

*Tags: General Technical*

---

## 2022-09-25

**D C** - *17:18:46*

Any recommendations of how to deal with other than bog standard CS - currently doing this and it is painfully slow?

*Tags: Performance*

---

**Mo** - *17:19:28*

Can’t remember if I’ve had that specific problem but definitely had accounts closed for a variety of reasons by the trigger happy compliance team

*Tags: General Technical*

---

**D C** - *17:20:10*

It was literally the moment I pressed commit on the address change. I wonder if there is a problem with the address and a previous occupant.

*Tags: General Technical*

---

**D C** - *17:20:30*

Maybe CS will help me before I reach retirement age.

*Tags: General Technical*

---

**ShaunW** - *18:32:47*

[@UUE6E1LA1](@UUE6E1LA1) before I had a direct contact I'd just start the CS convo with "can you raise the following support issue for me"... and paste my carefully worded question. They were always glad to just pass it fwd and it usually got a response inside 24hrs on weekdays.

*Tags: General Technical*

---

## 2022-09-27

**Jonjonjon** - *17:33:31*

Suppose I am using multiprocessing with Flumine to produce data files for a few thousand markets.



At the moment these are feather files.



I want to load these feather files into memory.



I can load the feather files into memory separately. They fit.



However, I cant concatenate them as I run out of ram.



I have tried writing them all into a CSV. But that is too big.



I have tried sequentially writing them into a single parquet which is 1.5gb. but when I try to load that the ram usage explodes so I can't use it.



What would others suggest here?

*Tags: Performance*

---

**Mo** - *17:35:05*

There is no good solution to the problem you describe

*Tags: General Technical*

---

**CL** - *19:16:03*

Try some of the pyarrow functionality - eg pa.concat_tables, and then convert the resulting table to pandas if needed. I've found the arrow libraries to be generally more memory efficient.

*Tags: Feature Engineering, Performance*

---

**Jonjonjon** - *19:55:08*

Thanks [@U0174A50YKS](@U0174A50YKS) I will try that tomorrow. I'm wondering if the problem would go away if I change all my Dataframes to have non-object types i.e. floats.

*Tags: Feature Engineering*

---

**Jonjonjon** - *20:06:57*

`dd.read_parquet` in [https://pandas.pydata.org/docs/user_guide/scale.html|here](https://pandas.pydata.org/docs/user_guide/scale.html|here) looks like it might do what I need too.

*Tags: Feature Engineering*

---

**Dave** - *20:54:22*

Fun fact: pandas started off as a project at a systematic fund

*Tags: Feature Engineering*

---

## 2022-09-28

**river_shah** - *06:44:58*

See if this could work for you: [https://stackoverflow.com/questions/13780907/is-it-possible-to-np-concatenate-memory-mapped-files](https://stackoverflow.com/questions/13780907/is-it-possible-to-np-concatenate-memory-mapped-files)

*Tags: Performance*

---

**Jonjonjon** - *19:31:17*

I am fitting a logistic regression.



It has 20 features that have been standardised to be roughly normal.



Sample size is 20k.



60% of target values are false. 40% are true.



The score (from sklearn) is 0.5.



What should I do to test whether or not my model has been over fitted?

*Tags: Feature Engineering, Strategies*

---

**Unknown** - *19:55:00*

Did you split into training/test data_sets? I m not an expert in machine learning, but it seems very logical that if performance on the training data is significantly better than the performance on the test data that you are overfitting

*Tags: Performance*

---

**foxwood** - *20:02:33*

Randomly split your data into at least 2 sets. Train the model on the first set then see what the built model achieves on the unseen second set. Great result on training and worse performance on validation is overfitting. Lots of articles out there on ways to loosen it up.

*Tags: Performance, Strategies*

---

**Jonjonjon** - *20:16:01*

Suppose it turns out that my model has been over fitted. What steps would you suggest I take, in order to improve it?

*Tags: Strategies*

---

**foxwood** - *22:56:09*

I think [@UBS7QANF3](@UBS7QANF3) is the resident wizard on this stuff - he posted a link recently to a free pdf of a textbook well worth reading - worth searching for. Think whether all the features are useful - if they are not really relevant to the prediction then leave them out since it can mislead the training. Categories can help things along if they represent very different things eg NH racing versus flat. Beware of including any data that would be unknown to your program at the time of running it live eg don't include BSP if it is a pre-race model. Maybe try a binary classification model if you just want yes/no. Worst thing I ever did was leave the result in the data set - training was superb at over 95% :rolling_on_the_floor_laughing:. Correlation matrix might throw some light on meaningful relationships in the data. No easy fixes that I know of unfortunately - just have to  keep at it refining and thinking - rinse and repeat.

*Tags: Errors Debugging, Feature Engineering, Deployment, Strategies*

---

## 2022-09-29

**Paul** - *22:07:11*

Avoiding over-fitting is covered by lots of good resources - big +1 to advice above. 20 features feels like a big space for some types of regression. Tools like AutoGluon (disclaimer: produced by another team at my employer), might help you as it can tell you about feature importance and does a lot of heavy lifting for you. I was taught it because I work for The Firm, but actually, it helps you with a shed ton of this stuff

*Tags: Feature Engineering*

---

## 2022-10-09

**Pos** - *01:30:01*

Hi guys, does anyone know how to calculate EV for run 2nd or 3rd promos in horse racing?

*Tags: General Technical*

---

**Pos** - *16:00:45*

Many bookies will give you the value of your bet back in bonus cash if your horse runs 2nd or 3rd. This may give a horse a +EV. Eg bet $50, get $50 back in bonus bets if it runs 2nd or 3rd.



I need help on how to calculate EV. Would be great if someone can help me work through an example.

*Tags: General Technical*

---

**Unknown** - *16:01:01*

Many bookies will give you the value of your bet back in bonus cash if your horse runs 2nd or 3rd. This may give a horse a +EV. Eg bet $50, get $50 back in bonus bets if it runs 2nd or 3rd.



I need help on how to calculate EV. Would be great if someone can help me work through an example.

*Tags: General Technical*

---

## 2022-10-18

**liam** - *08:40:05*

Probably more helpful for those starting out as it gives a very good high level overview of the stages/process

*Tags: General Technical*

---

## 2022-10-21

**Unknown** - *11:31:25*

Openly discussing pre-event strategy development for which of the following sports would be stepping on your toes?

*Tags: Strategies*

---

## 2022-10-22

**river_shah** - *08:46:57*

[@U4H19D1D2](@U4H19D1D2) I shamelessly copied how you package up `flumine` for some of my projects. Not a major issue but I get deprecation warnings (`SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools`). Do you have a recommendation what the best tool set for pip installable package / wheels is?



Stackoverflow is not particularly helpful: [https://stackoverflow.com/questions/58753970/how-to-build-a-source-distribution-without-using-setup-py-file](https://stackoverflow.com/questions/58753970/how-to-build-a-source-distribution-without-using-setup-py-file)

Seems like `setup.py` is still the easiest way to package up python / shell scripts despite the deprecation warnings.

*Tags: Getting Started*

---

**river_shah** - *09:17:03*

These are the contents of `setup.py` this is the command line used to create the dist

```python setup.py sdist bdist_wheel

....

/usr/local/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.```



*Tags: Getting Started*

---

**river_shah** - *09:39:28*

[@UBS7QANF3](@UBS7QANF3) Is `setuptools` still the recommended way to package up a project that includes python, cython and compiled `.so`? I see that in `package_data` I can list all the non python dependencies. I also see that somehow `setuptools` infers if binary distribution and appends the appropriate abi tags such as this `aarch64.whl`

*Tags: Getting Started*

---

**Mo** - *09:42:26*

I don't know, you've gone past my Python packaging "expertise"

*Tags: General Technical*

---

**Mo** - *09:44:51*

Also package everything and have never run in to this problem. But then I deploy by git cloning and pip install -e .

*Tags: Getting Started, Deployment*

---

## 2022-10-25

**birchy** - *13:21:24*

Question for the pandas gurus: I have a dataframe where column 0 is a datetime and column 1 is populated with booleans. I'm trying to calculate the timedelta between multiple rows where the start time is when col1 = True (rising edge) and the end time is when col1 = False (falling edge). The number of rows between start &amp; end time is variable and can be anything from 1 to 10+. Most of the examples I've found online only deal with diff() on consecutive rows and I'm struggling with the logic to sum the conditional delta from row x to row z. Any suggestions?

*Tags: Feature Engineering*

---

**mandelbot** - *19:38:16*

New python release with faster Cpython. Relevant to bflw?

*Tags: General Technical*

---

**river_shah** - *20:06:03*

have you even been able to install flumine / bflw with 3.11?

*Tags: Getting Started*

---

**river_shah** - *20:08:41*

I am sure this will be user specific but I use `numpy` / `numba` and this code dominates wall clock time relative to flumine / bflw and don't think 3.11 matters much

*Tags: General Technical*

---

## 2022-10-26

**Paul** - *15:04:56*

Exactly. There may be an advantage to having what we call “Chatham House rules” - what’s discussed stays with the attendees. Good questions and worth considering.

*Tags: General Technical*

---

## 2022-11-01

**Newbie99** - *13:23:47*

Actually I think I've answered my own question, just search for ISO2 by nationality! :man-facepalming:

*Tags: General Technical*

---

**Newbie99** - *13:23:53*

[https://gist.github.com/zspine/d7303dd194ff09a9a487](https://gist.github.com/zspine/d7303dd194ff09a9a487)



In case it helps anyone else

*Tags: General Technical*

---

## 2022-11-02

**D C** - *15:07:33*

Struggling to see how it can be a problem my end to be honest even tough its the most likely source

*Tags: General Technical*

---

**D C** - *18:06:11*

Any idea who I could take this up with? I don't have an AM but I have verified these gaps on bots written in 2 different languages running on separate AWS instances. Overlap seems to be just the account and the idiot who wrote the bots - one of which simply dumps received JSON to a file (assuming it can be parsed as JSON). Not really sure what else to try as these gaps are causing me serious problems now - large spots of dead time within races is a bit of a problem.

*Tags: Deployment*

---

**D C** - *23:26:09*

Just one last sanity check here [@UBS7QANF3](@UBS7QANF3) (or anyone who can suggest anything useful) prior to me emailing Neil. Ran 2 pairs of bots tonight on 2 different AWS instances. Each AWS instance runs a passive node.js data GPS stream logger and an active C++ production bot (one with bet placement disabled for obvious reasons).

Gaps in RRC transmission match up between node and C++ bots running on the same instance.

*Tags: Deployment*

---

**D C** - *23:27:14*

Gaps observed on BOTH instances but not over same time intervals. Its almost as if the RRC dropouts are on a per client IP address basis. I am at a complete loss to explain that as being a problem at my end.

*Tags: General Technical*

---

**D C** - *23:48:59*

On the stream API, when making requests you supply an "id" field to match responses to a subscription request. Docs say specifically that



`id - A unique counter you should supply on a RequestMessage and which will be supplied back on a ResponseMessage.`



I've always assumed that the "uniqueness" here is with respect to each connection, rather than accross ALL connections you may use. Essentially I am asking if it is possible that I am causing problems running say 2 streams connections but using the same ID on the market subscription requests? Clutching at straws a bit here but just wondering if people use globally unique "id" fields across their entire production setup or if uniqueness inside each connection is sufficient.

*Tags: Getting Started, Deployment*

---

## 2022-11-03

**Aaron Smith** - *22:40:51*

you should not compare floats with ==, due to floating-point errors, where it would return false even though the values should be equal. Try math.isclose() instead.

*Tags: Errors Debugging*

---

## 2022-11-04

**liam** - *13:31:16*

just email TPD, they are quick to respond and monitor the error on each race

*Tags: Errors Debugging*

---

## 2022-11-06

**Jonjonjon** - *09:15:04*

[@U4H19D1D2](@U4H19D1D2) I decided to change from 2 screen to 1. Definitely helps with focussing.

*Tags: General Technical*

---

**VT** - *17:14:25*

These guys move a lot of money in betting, it would be a real pleasure to spend some time with them helping out at work.

*Tags: Strategies*

---

## 2022-11-07

**Mo** - *13:16:34*

betfairutil version 0.4.0 released: [https://github.com/mberk/betfairutil](https://github.com/mberk/betfairutil)



```### Added



* get_event_id_from_string function

* get_pre_event_volume_traded_from_prices_file

* get_win_market_id_from_race_card function



### Changed



* pandas is now an optional dependency

* Added should_restrict_to_inplay argument to prices_file_to_data_frame

* Made get_runner_book_from_market_book more defensive

* Added LAST_PRICE_TRADED data frame format

* Optionally output runner statuses when converting market books to data frames

* Various README improvements:

    * More hype!

    * Badges

    * Examples```

&gt; ```pandas is now an optional dependency```

[@U4H19D1D2](@U4H19D1D2) this one is for you :point_up:

*Tags: Feature Engineering*

---

## 2022-11-09

**river_shah** - *11:18:13*

Does AWS, GCP etc care that we are gambling using their infrastructure? For example if my account manager at a cloud provider asks what line of work I am engaged in, could I just say professional gambling and it not be a problem?

*Tags: Deployment*

---

**Joel Beasley** - *13:42:56*

[@U01B8031PM1](@U01B8031PM1) TL;DR - no :slightly_smiling_face:



The main cloud providers used to not allow gambling companies but they have done for some time now:

[https://aws.amazon.com/solutions/case-studies/sportsbet-case-study/](https://aws.amazon.com/solutions/case-studies/sportsbet-case-study/)

[https://sbcnews.co.uk/technology/2019/06/28/leovegas-completes-systems-migration-to-google-cloud/](https://sbcnews.co.uk/technology/2019/06/28/leovegas-completes-systems-migration-to-google-cloud/)

*Tags: Deployment*

---

**river_shah** - *13:49:01*

Thats really helpful. Thank you

*Tags: General Technical*

---

## 2022-11-10

**D C** - *12:51:01*

Can anyone point me in the direction of the documentation on how to generate SLL certificates for API access? I've recently upgraded to ubuntu 22.04 which apparently uses SSL 3 and no longer allows lowering security. I always got around this on earlier versions using a local openssl.cnf as described [https://askubuntu.com/questions/1233186/ubuntu-20-04-how-to-set-lower-ssl-security-level](https://askubuntu.com/questions/1233186/ubuntu-20-04-how-to-set-lower-ssl-security-level)  but this no longer works so I think I want to bite the bullet and generate some new certificates. As a side question, I am assuming that we can generate as many or as few SSL cert files as we like for our accounts?

*Tags: General Technical*

---

## 2022-11-14

**liam** - *09:29:25*

Anyone else tried out py3.11 yet? I am seeing a serious improvement in flumine simulation times, M1 chip:



```py3.9:  139 markets in 45.3s

py3.11: 139 markets in 32.7s```

:exploding_head:

*Tags: General Technical*

---

**Mo** - *09:29:54*

Yeah, switched to it in production as soon as it came out. For the performance benefit

*Tags: Performance, Deployment*

---

**river_shah** - *10:23:23*

Amazing. Do you need to do a bflw / flumine rlease?

*Tags: General Technical*

---

**river_shah** - *10:55:54*

Sorry stackoverflow being not too helpful. If a requirement has upper version constraint for python, how do I force pip to ignore it?

*Tags: General Technical*

---

**D C** - *16:12:29*

Would it not be easier to try and generate your own model and generate probabilities from that? Even if you wanted to try something absolutely filthy like curve fitting and extrapolation from these prices you would need to guess how they have applied the margin to each outcome price and remove it. Buchdahl has stuff on margin removal I think although in truth his books are still gathering dust on my shelf. I'm curious as to what use these prices would be to you though even if you could generate them?

*Tags: Strategies*

---

## 2022-11-15

**PeterLe** - *13:48:40*

Just wondered if anyone had upgraded their Python version last night and found it worthwhile?

Im going to read up tonight the best way to do this on ubuntu (on Lightsail) on AWS

is it relativley easy to upgrade? Would you remove the old version completely?

It was easy enough to setup the instance on Ubuntu to start with so maybe create a new instance from scratch ?

Any thoughts please? thanks

*Tags: Getting Started, Deployment*

---

**VT** - *18:36:21*

[@UUE6E1LA1](@UUE6E1LA1)  I could try to build a model, but it would certainly be less efficient than this one. There are factors that change the margins in each quote, the bias of the favorite in the long term, etc... As I said, it's a matter of Buchdahl, he was kind enough to answer an email about this topic. I intend to use this to 'price and project' the most accurate quote possible on lines that are not available in bookies sharps but exist elsewhere.

*Tags: Strategies*

---

**V** - *21:39:44*

The arguments need to be hashable, since under the hood that decorator pretty much just uses a dictionary keyed by the args. Don’t think a RunnerBook is hashable so I’d expect a call to that func to just raise an exception.

*Tags: Errors Debugging*

---

**V** - *21:43:59*

Nope, I stand corrected. Looks like instances of user defined classes _are_ indeed hashable, and the hash defaults to the output of id. Which in CPython I believe is the memory address of the object. So assuming you pass in a reference to the exact same runner book, it _should_ give you what you want.

*Tags: Performance*

---

**V** - *21:45:29*

Reference: [https://docs.python.org/3/glossary.html#term-hashable|https://docs.python.org/3/glossary.html#term-hashable](https://docs.python.org/3/glossary.html#term-hashable|https://docs.python.org/3/glossary.html#term-hashable)

*Tags: General Technical*

---

## 2022-11-16

**river_shah** - *07:09:11*

Why do some packages pin the wheels to specific python versions? Seems like an unnecessary safety precaution. Aren't minor versions meant to be compatible including cpython abi? [@UPMUFSGCR](@UPMUFSGCR) we are not getting to upgrade for sometime it looks like 

*Tags: General Technical*

---

**river_shah** - *08:33:02*

Looking at couple of the MRs / github issues around it, seems like numba will be order a couple of months for next release. Also it does seem llvm / compilation issues arise between python minor versions hence the devs do have to do a fair bit of work to make the package available for 3.11

*Tags: General Technical*

---

## 2022-11-17

**Aaron Smith** - *21:44:54*

Hello ppl! I am thinking about emigrating from the uk to a different country. The destination is not determined at all and i want to consider all possible options. As betfair is my sole income, the most important requirement is that i am able to legally continue with this.



Now, sadly gambling laws are a mess, google lists about this matter are partly out of date, dont seem to consider gambling laws sometimes and also dont differentiate between betfair exchange and sportsbook (as obviously i need the exchange to operate in that country, not only the sportsbook). Also customer support seems useless on this matter, as their statements contradict themselves.



So, does anyone know how to get a trustworthy list on what countries i can consider?

*Tags: Deployment*

---

## 2022-11-18

**Jonjonjon** - *10:23:31*

Does anyone use a state machine to control their logic? I used my own one before I moved to Flumine. Now I just use 'if' statements to control the flow, but it's not efficient as my profiling shows that I'm wasting a lot of time recalculating my exposures, and using that to decide what to do.



E.g.



Calculate exposure 

If exposure is this:

   Do this

Else:

   Do that

*Tags: General Technical*

---

**Newbie99** - *19:43:36*

My solution isn't perfect, but I calculate any exposure metrics in a worker and then save to market.context (creating a dict for each strategy).



I use middleware when backtesting for the same result.

*Tags: Strategies*

---

**Newbie99** - *21:40:49*

A while ago I seem to remember someone on here talking about [http://api-football.com|api-football.com](http://api-football.com|api-football.com), out of curiosity, I believe they refresh the live score once every 15 seconds, but does anyone know roughly how much latency there is in that (i.e. at the point of update, would it be 'live' or is there a noticeable delay)?



For my purposes ms don't matter, its only really if its a large number of seconds away from the other live score services that I guess it could be a problem.

*Tags: Performance, Deployment*

---

## 2022-11-21

**Mo** - *16:50:24*

Here are the details for one of the upcoming webinars I referenced in my talk the other evening:



&gt; Hi,

&gt; 

&gt; Hopefully football fever is now sweeping the country and everyone is in the mood for a topical seminar. As such, the RSS Statistics in Sports section is hosting a webinar on Wednesday 30th November, at 2pm, when Professor Nial Friel will talk about 'Assessing competitive balance in the English first division / Premier league over 40 seasons using a stochastic block model'. For more details please visit: 

&gt; [https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Frss.org.uk%2Ftraining-events%2Fevents%2Fevents-2022%2Fassessing-competitive-balance-in-the-english-first%2F%23fulleventinfo&amp;data=05%7C01%7Cpeter.philipson1%40NEWCASTLE.AC.UK%7C95a31891ea134caf546408dacbd4d1cc%7C9c5012c9b61644c2a91766814fbe3e87%7C1%7C0%7C638046412149476075%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=eE30uxdZWp%2FOwL6BqIWn%2BGTmLgZfLR9x1Z2wuNQx%2BR0%3D&amp;reserved=0](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Frss.org.uk%2Ftraining-events%2Fevents%2Fevents-2022%2Fassessing-competitive-balance-in-the-english-first%2F%23fulleventinfo&amp;data=05%7C01%7Cpeter.philipson1%40NEWCASTLE.AC.UK%7C95a31891ea134caf546408dacbd4d1cc%7C9c5012c9b61644c2a91766814fbe3e87%7C1%7C0%7C638046412149476075%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=eE30uxdZWp%2FOwL6BqIWn%2BGTmLgZfLR9x1Z2wuNQx%2BR0%3D&amp;reserved=0) 

&gt; 

&gt; Online access details will be circulated to those registered ahead of the event.

&gt; 

&gt; RSS Statistics in Sports Section

*Tags: Strategies*

---

## 2022-11-22

**Nicholas vizard** - *21:04:55*

Hey guys,

I hope you are keeping well.



I just had a quick question regarding a particularity I have found in the SP matched volume figures that I have extracted from the historical PRO stream files.

*Is there a reason that the SP traded volume pool can decrease in subsequent time periods for a particular runner?* 



For example in [market id: 1.188384541, selection id: 28467067] I find that the SP lay pool available decreases from a total volume of 138.41  to 89.45 in two subsequent time periods. The particular time periods are the periods prior to and the period of bsp consolidation. I have included the raw sp lay ladders below for reference.



Many thanks for any help you can provide, I am conducting analyses involving trading volumes so identifying why there may be this discrepancy would be much appreciated.

Cheers!



*Period Prior to consolidation (sum of traded volume = 138.41):*

{'p':[1.2,1.15,1.13,1.12,1.11,1.1,1.09,1.08,1.07,1.06,1.05,1.04],'v':[16.05,2.67,2.67,5.35,5.35,16.05,15.36,29.44,2.67,16.05,16.05,10.7]}



*Period of consolidation (traded volume = 89.45):*

{'p':[1.1042944041670215],'v':[89.45]}

*Tags: Strategies*

---

## 2022-11-23

**Nicholas vizard** - *09:58:11*

Thanks for your prompt response, Mo. It seems I may be misunderstanding how to calculate the net volume traded on a particular runner at a particular time point in the stream. My issues seem to arise when calculating the sp_traded_volume. For clarity, my strategy has been the following:



*1.      Let total traded volume for a particular runner,i, at time point t, equal the limit_traded_volume on that runner + the sp_traded _volume on that runner*



*2.      Calculate the limit traded volume as the sum of all volume values available on the limit traded volume ladder*

          _for example, with the limit traded volume ladder: {'p':[1.05,1.06,1.07],'v':[5,10,15]}_ 

          _I would return 30  as the limit traded volume at this time point (sum of the volume values)_ 



*3.       Calculate the sp_traded_volume as the minimum of either:*

           *a. the sum of the size objects on the sp_available_to_back_ladder or,*

           *b. he sum of the size objects on the sp_available_to_lay ladder divided by  (bsp -1)*



          _For example, with :      BSP = 2        sp_available_to_back_ladder: {'p':[1.05,1.06,1.07],'v':[100,20,20]}                sp_available_to lay ladder: {'p':[1.05,1.06,1.07],'v':[20,20,20]}_

          _I would return 60 as the sp traded volume at this time point (the sum of the sp_lay ladder (60) divided by the BSP -1 (1))._



It follows that my total traded volume would be 90 in this example (30 limit traded volume + 60 sp traded volume).



I  would be amazing If you could identify any problems with this strategy. Or alternatively, if you are able to point me to documentation that may facilitate my understanding of sp and sp traded volumes that would be much appreciated.

Thank you so much for your help Mo, it truly is appreciated!

*Tags: Strategies*

---

## 2022-11-25

**liam** - *11:24:24*

Anyone successfully build docker images on GitHub actions for ARM64 (EC2 graviton), I am ready to launch my laptop out the window

*Tags: Deployment*

---

**river_shah** - *15:01:52*

I tried, so many errors. qemu crashes and bugs

*Tags: Errors Debugging*

---

**river_shah** - *15:05:01*

Surprisingly multi arch docker builds are not as seamless as one would like. I got a ton of crashes first and a then even after I had image building, many unit test failures for code with numpy / numba

*Tags: General Technical*

---

## 2022-11-26

**Mo** - *16:58:15*

Lex Fridman's latest guest is Guido van Rossum (creator of Python): [https://youtu.be/-DVyjdw4t9I](https://youtu.be/-DVyjdw4t9I)

*Tags: General Technical*

---

**Newbie99** - *19:09:40*

I suspect the answer is no, but did anyone notice any strange data from Betfair (football or horses) today (sorry thats a bit vague as I'm not sure what I'm looking for precisely)?



In short, for no apparent reason (that I can see), all strategies I'm running across football and horse racing didn't cancel any orders after 11:00 this morning (so I've only been getting filled @ -EV prices all day), I have made no code changes and there are no errors in the logs (the logs show no cancel request appears to have been sent).



Therefore all I can assume is that some data is being mishandled at my end (probably something stupid like a None value instead of whatever it should be), but I'm struggling to find what it could be (I've restarted the EC2 instance and its working fine now).



Appreciate its almost certainly just something weird that I have done, but just thought I'd check on the off chance anyone spotted any weird streaming data (I have it recorded so if there is anything should be able to find it and hopefully replicate, just wanted to save time in case anyone else had come across anything).

*Tags: Errors Debugging, Deployment*

---

## 2022-11-27

**Newbie99** - *10:00:28*

Well that opened my eyes to the concept of people 'making a living betting on reality tv'!!! I had no idea there were enough markets/volume for that (ignoring the difficulty of how to price anything)!

*Tags: Strategies*

---

**PeterLe** - *12:04:28*

I was having a think about this after Liam posted,...I wasn't at my desk for most of the day, but when i was,  I did notice that there were a t least a couple races where I had a large profit on selections which then traded very low in odds, which then went on to lose.

So it could easily have been a good day too. Easy enough to modify the strategy but it all equals out at the end of the month.

*Tags: Strategies*

---

**river_shah** - *12:12:23*

I had one of the worst days for a particular strategy (that is typically fairly consistent / low variance). Haven't looked at any logs yet. Most other strats (not using cancels) were fine.

*Tags: Strategies*

---

**Aaron Smith** - *12:17:27*

the strategy that on my end threw money around like a fresh lottery winner in a strip club was also relying on cancels. Sadly i m just to consumed with private life atm to really look into it, so i m just letting things run and hope for the best, but i ll be curious if you guys find anything intresting

*Tags: Strategies*

---

**liam** - *12:20:46*

I don’t have any serious errors from yesterday 

*Tags: Errors Debugging*

---

**PeterLe** - *12:25:52*

I had four strategies running on Flumine (relying on cancels) all four lost but very tiny amounts, I also lost my betangel strategies too so maybe there is nothing wrong with Flumine. (First at Navan looks good:grinning:)

*Tags: General Technical*

---

**D C** - *14:38:56*

Only thing I did notice which was very unusual was that the GPS stream seemed to be having problems in the sense that when my socket receive data handlers fired I often would be receiving multiple messages at once. Up to 17 at once which was very unusual. Probably an issue my end using async socket components but as I say, very unusual relatively speaking.

*Tags: General Technical*

---

## 2022-11-28

**Newbie99** - *16:34:44*

I finally got round to re-running the data from Saturday and it all worked fine, no errors, orders were cancelled as expected looking at the backtest results. So what happened in reality is a complete mystery :man-shrugging:

*Tags: Errors Debugging*

---

**Newbie99** - *18:34:03*

Nope, logs all read as normal, no errors at all. I can however see that it wasn't sending cancel requests for a chunk of the day, so the problem definitely occuered at my end.

*Tags: Errors Debugging*

---

## 2022-12-07

**river_shah** - *09:46:54*

Does anyone have a helpful code snippet on how to stream logs to s3 or gcp bucket from python in a cloud provider agnostic way. Can `smart_open` do the streaming? I see examples like this but platform specific: [https://cloud.google.com/python/docs/reference/logging/latest/handlers-cloud-logging](https://cloud.google.com/python/docs/reference/logging/latest/handlers-cloud-logging)

*Tags: General Technical*

---

**liam** - *10:20:48*

i just use docker `awslogs` to pipe straight to AWS cloudwatch, [https://docs.docker.com/config/containers/logging/gcplogs/|gcp](https://docs.docker.com/config/containers/logging/gcplogs/|gcp) equivalent

*Tags: Deployment*

---

**river_shah** - *10:25:25*

this looks good, thanks. so the python code itself knows nothing about `awslogs` or `gcplogs`?docker handles / abstracts the streaming entirely?

*Tags: Deployment*

---

**river_shah** - *10:30:23*

perfect, today I learned. so far was was writing logs via gcp libs in python. this is much better.

*Tags: General Technical*

---

## 2022-12-11

**Alessio** - *22:18:02*

It's insane it took them so long to get even a minimal fix

*Tags: Errors Debugging*

---

## 2022-12-12

**D C** - *15:49:40*

Yes. I don't doubt that he is up to something dodgy, I was more asking the question as a matter of principle - is there any way this could be done legitimately and safely from an account security point of view.

*Tags: General Technical*

---

**George** - *15:54:42*

Everyone has a different risk tolerance of course but in my case I generally get referred by people who know me / existing happy customers and that helps. I have never had anyone worry about sharing account details - easy to set up a subaccount with a small balance until you get comfortable.



As a matter of principle i believe the risk is confined to the value of the funds in the account - whether that counts as "safe" or not is in the eye of the beholder!

*Tags: Multi Client*

---

**PeterLe** - *15:57:52*

George - If you have numerous usernames all via the one IP address doesnt betfair question that?

*Tags: General Technical*

---

**D C** - *15:59:56*

I also question the security risk being limited to account funds - as you (or anyone who hacked you and obtained user details) would be able to login to any user account that didnt have 2FA setup and see their address, phone etc. If nothing else that is a risk of identity theft. Not saying you would of course, and if you customers are happy with that risk its their business. I just cant agree that risk is isolated to current account funds.

*Tags: Getting Started*

---

## 2022-12-13

**Jorge** - *14:26:49*

Hi, are there any other Sports betting exchanges that offer Websocket API? I'm looking to see if it is possible to scale a strategy using more exchanges...

*Tags: Strategies*

---

**ShaunW** - *15:08:00*

It's not just the person you give your details to that's the problem, it's their security and who else might discover it.  As an agent you'd certainly need a rock solid contract to establish/deny liability. You could be sued for being irresponsible with what's intended to be confidential under the DPA.

*Tags: General Technical*

---

## 2022-12-16

**AP** - *06:16:09*

[https://www.kaggle.com/code/bkumagai/bayesian-velocity-models-for-horse-race-simulation/notebook|https://www.kaggle.com/code/bkumagai/bayesian-velocity-models-for-horse-race-simulation/notebook](https://www.kaggle.com/code/bkumagai/bayesian-velocity-models-for-horse-race-simulation/notebook|https://www.kaggle.com/code/bkumagai/bayesian-velocity-models-for-horse-race-simulation/notebook)

*Tags: Strategies*

---

**liam** - *08:58:13*

I have a SimpleStrategy which places a single order at 1.01 on a market/selection and then cancels, invaluable for validating changes/errors etc

*Tags: Errors Debugging, Strategies*

---

## 2022-12-18

**Mo** - *18:56:47*

Looks like the problem is this file: `botocore/data/s3/2006-03-01/endpoint-rule-set-1.json.gz` which is not actually compressed. This gets read as part of `smart_open` trying to read directly from S3 but because `open` is patched with `smart_open`, `smart_open` tries to be clever about reading a file with a `.gz` extension and pukes when it discovers it's not actually compressed

*Tags: General Technical*

---

## 2022-12-20

**VT** - *05:20:07*

I believe that showing these values ​​can help attract new people to Betfair, if there's one thing these guys want is more people clicking on Betfair markets.

*Tags: General Technical*

---

**Jonjonjon** - *20:18:45*

Ah. That's a good point So he's hoping people think they can beat him at his game. Brave of him to share photos of his family on there as well though. If it was me, I'd hire a model to pretend to me be.

*Tags: Strategies*

---

## 2022-12-29

**Jonjonjon** - *08:51:34*

In the UK, how many professional Python developers are there, Vs the number of professional footballers?

*Tags: General Technical*

---

**Mo** - *09:28:20*

This sounds like an interview question

*Tags: General Technical*

---

**Jonjonjon** - *09:41:45*

No.. it's a fatherhood question. I'm pondering the odds of success for a child aiming to be a footballer Vs a Python dev. I was sent something about a premier League player who earns minimum wage. And he must be pretty amazing. So I have a feeling that a low level Python developer probably earns more than a low level pro footballer.

*Tags: General Technical*

---

**PeterLe** - *10:28:42*

What’s the best paid software tech job these days? For example would a DBA earn more than a Python dev?

*Tags: General Technical*

---

**D C** - *10:42:54*

£35k without a degree as an apprentice python dev???? F*** me the world has changed a lot.

*Tags: General Technical*

---

**Paul** - *10:56:20*

It’s all supply/demand market economics as with anything, and this slack should understand better than most. Anything you learn at Uni - Python/Java/C++ pays less well than the languages you have to teach yourself and can find an excited CTO for - Ruby, Go, Elixir, Haskell, OCaml, for example

*Tags: General Technical*

---

**Paul** - *10:57:51*

I did a total of 12 hours of interviews to get into Amazon, spread over 2 batches. None of them were HR - all engineers and engineering managers asking about my experience and a few simple problem solving tasks 

*Tags: General Technical*

---

**liam** - *16:09:07*

No question that my children will be learning to program (wether they like it or not :joy:) skill for life and if you have experience you can literally walk into a job in any industry you want. 



Sports person is a huge risk in my eyes, only the top paid well / injury can put a stop to everything etc. Can’t remember his name but there was a welsh rugby player who studied at Cardiff to be a doctor whilst playing nationals, very wise 

*Tags: General Technical*

---

**Jonjonjon** - *17:14:40*

Do you think that AI stuff will help to take programming to the next level? I don't think it will put programmers out of a job. For example, it won't stop me punting on Betfair. If anything it should make programming faster, though I have yet to try it.

*Tags: General Technical*

---

## 2022-12-30

**Paul** - *08:53:40*

I’m in two minds. In the “For AI” camp: ChatGPT is already better than 50% of developers at solving routine problems. The AI code completion tools from GitHub and AWS might run into licensing issues (they’re open source code without attribution), but once that’s solved we are probably 5 years away from programmers just having to write unit and integration tests, and 10 from just needing to write success criteria in a scope doc. 

*Tags: Deployment*

---

**Paul** - *08:56:10*

In the “Against”: those licensing issues might be insurmountable, and most programming work is actually about debugging and refactoring. Every line of code in a large code base gets touched multiple times in its lifetime, and I’m not seeing any progress on AI in refactoring use cases, so it’ll be interesting to see how that progresses.

*Tags: Errors Debugging*

---

**Alessio** - *10:41:42*

Very interesting. I'm also in the "you can't remove the human, only build helping tools". The main reason is that all those tools may be good for a first write, but then you can't easily evolve whatever you have, update, etc... plus the licensing issues (Oracle vs Google, I am looking at you)

*Tags: General Technical*

---

**Mo** - *12:18:48*

I've ended up with a surplus copy of [https://pipdecks.com/pages/idea-tactics-card-deck|Idea Tactics](https://pipdecks.com/pages/idea-tactics-card-deck|Idea Tactics) - it's a deck of cards that helps you with idea generation. I think it'll probably be more useful if you work with a team but it can definitely also be used solo. Let me know if you’re interested and I’ll pick a winner at random

*Tags: General Technical*

---

**Mo** - *12:41:13*

Administrative error by the company

*Tags: Errors Debugging*

---

## 2022-12-31

**PeterLe** - *18:55:45*

JonJon read this, a great book. “The man who solved the markets” Jim Simon. That will answer you question 

*Tags: General Technical*

---

## 2023-01-01

**river_shah** - *20:09:03*

I started late 2020 on development and deployed early 2021. I work on sports betting on a few sprints a year, but it is fully automated and at a scale where it makes sense to make it grow and polish to see how much more I can squeeze out. Got a few things working well, others not so much. I have other tradfi trading models as well which take the bulk of my time

*Tags: Deployment, Strategies*

---

**Mo** - *20:09:06*

Happy new year all. My plan is to collaborate on some projects with some of you guys



Recently I have started doing some freelance work with a former colleague and it has made me realise how useful it is to work with someone who understands the modelling side of things. That’s something that my syndicate currently lacks 

*Tags: Strategies*

---

**D C** - *20:20:58*

My plan is to model pre-race horses and dogs. I've been finding the GPS profits dipped off considerably and I've spent all year trying to force it but I feel for all the hours put in I've got nothnig from it. Going to try good old fashioned modelling and value betting. Basically 2023 I need to make every hour on this stuff useful rather than getting tunnel visioned on a single thing.

*Tags: Strategies*

---

**AP** - *21:30:56*

My plan is to continue with in-play racing and also build some fundamental pre off models for UK and AUS racing. I have collected all the data so a matter of creating a good model and optimising execution.

*Tags: Strategies*

---

**Mo** - *21:42:57*

In terms of me learning something new, there are the guys with finance backgrounds, and there also people working outside of my core sports. But it’s also not necessarily about learning something new - it’s also about having someone to ask the right questions/be able to bounce ideas off of to get the best out of me

*Tags: General Technical*

---

**D** - *22:35:46*

Happy New Year to everyone :tada: My goals are to try and diversify my strategies to be less dependent on what's currently working for me, and to try and get more into Flumine.

*Tags: General Technical*

---

## 2023-01-02

**Jorge** - *08:15:25*

Happy New Year all! This year I finally have time to focus in the modelling part of the strategies, I will combine it with some freelancing developing projects, instead of the full time employment I had last years :slightly_smiling_face:

*Tags: Strategies*

---

## 2023-01-03

**ShaunW** - *05:36:58*

It's experience that adds the zeros to your wages.  The world isn't short of bedroom programmers but finding someone who can be productive in your sphere from day 1 is hard.  Quality is an issue too, zero errors isn't a goal it determine whether you get a binbag on your desk... It's all just like any trades (work) really, given a week most people could plaster a room reasonably well but a pro will be in and out in a morning, and do it better.

*Tags: Errors Debugging*

---

**Aaron Smith** - *21:09:33*

most successful bettors started with a negative pnl i would assume. The major difference between losing 1k and 50k is risk management. I think someone who lost 50k could still turn it around theoretically, but at the very least they should heavily rethink their approach to testing and scaling. Everybody writes a bad strategy sometimes, even the ones who selected &gt;300k, but they wouldnt lose 50k on it.

*Tags: Strategies*

---

**Jonjonjon** - *22:29:10*

Ah. I understand now. The lurker who appears every time there's a mortgage question must love it there.

*Tags: General Technical*

---

## 2023-01-12

**Michael** - *00:08:24*

An old colleague reached out an offered me a job as a machine learning engineer at a online retailer - I'd just started a role in finance in M&amp;A but salary will be better than my base (probably in total, since bonus will be less than finance) but I assume hours will be far better - Does anyone know what the pay progression is like for ML engineers and what it tops out at?

*Tags: General Technical*

---

**Mo** - *08:35:26*

I use a very similar approach (not my own work) for financial markets but it's not immediately obvious to me how to apply this to the kind of betting strategies I run

*Tags: Strategies*

---

**liam** - *09:06:25*

A bit of both, I use something similar for 'backtesting' before moving to flumine 'simulation'.



Basically consists of a very wide table and I just filter / order / if till profit appears

*Tags: General Technical*

---

**river_shah** - *10:21:13*

The problem Prado goes on and on about is maybe more appropriate for low frequency trading...

*Tags: Strategies*

---

**river_shah** - *13:56:27*

I am sure one can derive bounds on this but selection bias from backtests can be more pronounced when the strategy information ratio is low. If your strategy trades once a year (for example long only mutual fund) and then holds, with an information ratio of 1), running millions of backtests will induce massive bias in your portfolio selections. If on the other hand you are like [@U4H19D1D2](@U4H19D1D2) and trade a 100K times a day with effectively max IR (information ratio) you can rest assured that any backtest induced selection bias will be low.

*Tags: Strategies*

---

**river_shah** - *14:26:05*

page 13 of pdf goes over this: [http://www.ams.org/notices/201405/201405FullIssue.pdf](http://www.ams.org/notices/201405/201405FullIssue.pdf) If your strategy sharpe ratio is very high just ignore this

*Tags: Strategies*

---

## 2023-01-13

**Mo** - *08:13:27*

Obviously in the absence of feature requests, what I add to betfairutil is whatever I'm currently working on. I've been finding recently that it really helps not to be lazy about just reading everything into memory as this allows me to saturate my CPU with workers



```  * get_market_books_from_prices_file

  * get_minimum_book_percentage_market_books_from_prices_file```

Are two other examples. Previously I would probably just have read the entire set of market books into memory then use bisect functions to find the ones I care about

*Tags: Feature Engineering, Performance*

---

**Unknown** - *10:23:39*

Hi All, the above issue occurs when there's a problem with our virtual stream producer, which causes invalid virtual prices to be displayed via all channels (including the Stream API).  I can confirm that there is an item on our development roadmap to fix this within Q2 this year.

*Tags: Errors Debugging*

---

## 2023-01-16

**D C** - *11:34:25*

I know some of you here put a lot of importance in performance when it comes to simulating/backtesting etc. I don't use flumine/BFLW, but from what I read people mostly use S3 storage, decompress raw JSON stream  files and run backtests like that (please correct if wrong). Given performance considerations, I was wondering if anyone uses or has given thought to utilising an alternative file format to give processing an extra zip? I'm working on some GPS stuff at the moment and it's occurring to me that a large proportion of processing time is down to JSON parsing every time I run analysis. I was wondering if anyone has tried binary file formats or something similar? Not sure if I will eventually do this as it may be a premature optimisation but I've worked a lot with binary data files which has made me start thinking about going down this route.

*Tags: Performance*

---

**D C** - *11:57:41*

Well yes. Probably should have specified I don't use Python - does  it not play nicely with binary format file data?

*Tags: General Technical*

---

**Alessio** - *11:59:42*

the other thing to consider is that if one day you need to load _some stuff_ in a python script you need to rewrite your writer/loader

*Tags: General Technical*

---

**D C** - *12:01:47*

Yeah I know what you mean. Mods can be tricky. I'm thinking of basic stuff though. Let's take a stupid example - backtesting a lay the field strategy inplay. You are parsing JSON time and time again but ultimately you are only interested in a handful of coefficients calculated from that entire data file. Its a poor example probably. OBviously it would only work for a very limited and targeted type of backtest/simulation - I was just wondering if anyone had tried this kind of thing.

*Tags: Strategies*

---

**Ralegh** - *12:02:43*

I process betfairs data into parquet files then load them in and do most of the proof of concept and idea testing in pandas where it takes hardly any time, with flumine as the last step

*Tags: Feature Engineering*

---

**D C** - *12:05:04*

Well a market book is an ideal structure to store in a binary format surely ? It's fixed type (double/float) and fixed size. Essentially its a mulidimensional matrix at heart

*Tags: Errors Debugging*

---

**liam** - *12:34:15*

In python it’s the creation of objects that takes the large majority of time as shown by the Rust library, reading json isn’t worth the optimisation. Have you profiled your code? 



I use s3 for storing the data but have a local cache (~100gb) to remove the network latency 

*Tags: Performance*

---

## 2023-01-19

**Unknown** - *17:07:33*

Following on from Jorge's post about freelancing platforms, I just saw this (below) - I can't enquire any further because I'm not a "Preferred freelancer". It got me thinking though, would it be an idea to add a "jobs" channel for when similar sports modelling jobs come up?

*Tags: Strategies*

---

## 2023-01-20

**Mick** - *08:07:35*

For the record I'm certainly not promoting [http://freelancer.com|freelancer.com](http://freelancer.com|freelancer.com) (which has many flaws) - my suggestion for a jobs channel was in relation to modelling jobs from _any_ source.

*Tags: Deployment, Strategies*

---

**liam** - *18:20:07*

Happy to add more channels, the problem is I have to invite everyone so people get spammed, comes down to the question of if we want loads of channels like the AUS group 

*Tags: General Technical*

---

**Mick** - *18:32:58*

No worries. To be honest I thought my suggestion might have led to a discussion of where to find modelling jobs but seeing how quiet this thread is, perhaps it's not such a hot topic!

*Tags: Strategies*

---

## 2023-01-23

**birchy** - *22:42:46*

I don't have the body or looks to apply for a modelling job.

*Tags: Strategies*

---

## 2023-01-24

**John Foley** - *10:27:08*

Yeah interesting results. Kinda surprised that “both” is leading so significantly as this way requires the most engineering, joining from different data sources, possibly building databases, etc 

*Tags: General Technical*

---

## 2023-01-25

**PeterLe** - *13:11:50*

:thinking_face: If you were to run the exact same strategy (inc stakes), on the same system, on multiple accounts, how close would you expect the end of month profits to be on each account?

*Tags: Strategies, Multi Client*

---

**PeterLe** - *13:24:33*

Thanks Mo, seems a bit of an obscure question but there is some thought about it.

As we all know you wouldnt get the same results if you had a single account with a single stake that matches the combined value of all the others.

I was thinking more around the 50ms matching cycle and the placing of orders etc. Im doing some testing at the moment, but the results are not quite what I expected.

*Tags: General Technical*

---

**river_shah** - *13:38:17*

It will be very strategy and stake size dependent. Each of the replicated strats is essentially a competitor and what is worse, a competitor that knows your entire signals / strats. If staking big enough, market impact will shoot through the roof

*Tags: Strategies*

---

**river_shah** - *13:39:53*

I don't know much about inplay horses so won't comment. I know for other bet sized constrained markets, multiple strategy replicates typically result in very bad performance for high stakes

*Tags: Performance, Strategies*

---

**Paul** - *14:25:18*

My main problem is lack of transparency. I’m using bflw in a loop over the non streaming api BTW, so only myself to blame..

*Tags: General Technical*

---

**Paul** - *14:25:38*

I shall be converting that strategy to flumine tonight as it is otherwise profitable… :-)

*Tags: Strategies*

---

## 2023-02-01

**birchy** - *18:24:49*

I've used Linux on all of my work machines for about 20 years and recently gained access to a MacBook air M1 a few months ago. Although similar to Linux (Ubuntu, Mint, Debian, etc), I did/do find the keyboard shortcut mappings take a while to get used to. Overall it's a been positive experience. Once you have the thing setup (Pycharm, etc) the experience is not much different to any other OS. My main advice would be to ensure you research the installation process for any software you need as there's usually a specific Apple Silicon version. The default Intel versions _will_ install OK but I've had "wrong architecture" issues in the past, particularly with python/numpy/pandas while running in Pycharm. That's usually related to the python interpreter used by Pycharm and you have to point it at the full path rather than the/bin/python3.11 it suggests is available.

*Tags: Getting Started, Feature Engineering*

---

## 2023-02-09

**liam** - *10:47:12*

*[https://promos.betfair.com/promotion?promoCode=CHELTHISTDATA|Cheltenham Festival - Free Exchange Historical Data](https://promos.betfair.com/promotion?promoCode=CHELTHISTDATA|Cheltenham Festival - Free Exchange Historical Data)*



_The Betfair Historical Data service provides time-stamped Betfair Exchange data for purchase &amp; download to registered Betfair customers_

_To mark the up and coming Cheltenham Festival (14th-17th March) we are offering the following free data packages (worth £1097) covering the Cheltenham Festival period over the last 4 years._



_• Horse Racing - ADVANCED data – March 2019-2022_

_• Horse Racing - PRO data - March 2019-2022_

*Tags: Data Quality*

---

**PeterLe** - *12:04:20*

I saw that Liam in the newsletter. So (and hope this isnt a stupid question!) but can it be used in its raw format to use with Flumine backtesting?

*Tags: General Technical*

---

**Nicholas vizard** - *12:21:01*

Hey guys,

Hope everyone is keeping well.



I am attempting to parse Betfair historical stream data (bz2 files) to CSV using the modules Betfair_Data and Betfair Lightweight in Python.

However, when parsing the bz2 files using Betfair_Data, I am receiving the print statement _“ (JSON Parse Error) missing required field &lt;marketType&gt; at line X column Y“_, and consequently, data on the markets that exhibit this error are not included in my final csv.



*I was wondering if somebody may be able to point me to the module (or help me modify the module), such that the bz2 files that are missing the MarketType entry are still parsed with market_type = NaN, rather than excluded from consideration.* 



As a side note, I have confirmed that this issue is indeed arising because in several of the raw bz2 files provided by Betfair, the marketType entry is missing.

Any help that could be provided would be much appreciated!



Cheers!

*Tags: Errors Debugging*

---

**Unknown** - *12:27:03*

Apologies, I am rather new to Python. My load_markets functionality uses betfair lightweight, though this module is imported via betfair_data.

*Tags: Getting Started*

---

**liam** - *12:28:52*

So you are using the `betfair_data` library but in 'betfairlightweight' format, therefore a bug in the Rust library, I would create an issue on the [https://github.com/tarb/betfair_data/issues|repo](https://github.com/tarb/betfair_data/issues|repo) however I am not sure how active Rob is

*Tags: Errors Debugging*

---

## 2023-02-10

**Nicholas vizard** - *11:07:48*

Hey Mo thanks for your pseudo code. I have transitioned to Betfair lightweight and it has indeed resolved my issue involving the bz2 files that are missing the market_type entry. I am now able to parse the details of the markets who are missing market_type entires with market_type as NaN in my CSV, rather than skipping over them entirely. However, using betfair lightweight, I have discovered an analogous problem for bz2 files that are missing the market_time entry. Betfair lightweight is unable to handle bz2 files that are missing the market_time entry: specifically I recieve the tpye error: __init__() missing 1 required positional argument: 'marketTime'. The obvious solution is to skip these markets entirely though a try and except, however I would like to retain these markets with an NaN. Do you know if this is possible/how one would go about modifying the code so that this is the case?



Thanks again for your help

*Tags: Errors Debugging*

---

**Unknown** - *11:48:22*

Hey Mo, here is an example of a Market that exibits the marketTime type error. Please also see my consult output on this market:

*Tags: Errors Debugging*

---

## 2023-02-20

**foxwood** - *14:49:48*

From my logs I had a few 503 errors on the order stream at about 13:32. Only about a dozen log entries but nothing after that. Didn't seem to affect any of my stuff but not bothered to look in detail - some on BA seemed to get hammered because greening bets were placed but not being shown as matched (presumably order stream issues) - so they closed position again and again. BF did refund one of them about £700 apparently.

*Tags: Errors Debugging*

---

**Newbie99** - *21:11:58*

I'm completely new to Mac OS and google is very limited on the subject of network drive mapping issues, so hopefully someone here has faced similar.



I have a (linux based) NAS where I store all my market recorded data, I have the drive mapped on a windows PC and can access files easily without any major lag, however when I mount the drive via terminal in Mac OS the performance is really poor, for example the same folder (containing approx 12k recorded market files) takes &gt; 30 seconds to return results from the command line (compared to virtually instantaneous on the windows machine).



The other confusing thing is that via SSH performance is fine from both the windows machine and the mac.



Obviously the solution seems to be, SSH rather than try to map the drive, but does anyone have any ideas why this could be happening (all machines are on the same WIFI network and physically in the same room)?

*Tags: Getting Started, Performance*

---

**birchy** - *23:21:09*

Maybe something like this? [https://apple.stackexchange.com/questions/239536/slow-performance-accessing-ubuntu-samba-folders/239559#239559|https://apple.stackexchange.com/questions/239536/slow-performance-accessing-ubuntu-samba-folders/239559#239559](https://apple.stackexchange.com/questions/239536/slow-performance-accessing-ubuntu-samba-folders/239559#239559|https://apple.stackexchange.com/questions/239536/slow-performance-accessing-ubuntu-samba-folders/239559#239559)

*Tags: Performance*

---

## 2023-02-21

**Newbie99** - *17:34:33*

Thanks [@U016TGY3676](@U016TGY3676) it seems on some older Macs the issue may well have been to do with SMB protocol, but it seems a lot of people are suffering the same fate with the latest OS and recent M series chipsets too, so it seems like a bug at this stage (but I'll work my way through those settings and see if any help).



A bit annoying, but via SSH its fine, so that will have to do as a stopgap for now (tbh via python it doesn't matter too much anyway, SSH is fine, just a bit annoying when you want to simply drag and drop a single folder or similar)!

*Tags: Errors Debugging*

---

## 2023-03-01

**Paul** - *18:03:33*

This free event is happening in my office in April and might touch on subjects of interest here. I know one of the organisers works with some bookmaker trading desks and I’m hoping to get him or his customers to leak some alpha in a nearby bar afterwards. [https://awsdeepdivesdays.splashthat.com|https://awsdeepdivesdays.splashthat.com](https://awsdeepdivesdays.splashthat.com|https://awsdeepdivesdays.splashthat.com)

*Tags: Deployment, Strategies*

---

## 2023-03-03

**D C** - *14:23:54*

It always misbehaves a little.... But I've seen no glaring errors today. Been 2 Steward's in the first 2 races though - 2nd race between the first 3 runners

*Tags: Errors Debugging*

---

## 2023-03-05

**Derek C** - *15:09:47*

Not really answering your question but: [https://www.tpd.zone/status/](https://www.tpd.zone/status/)

*Tags: General Technical*

---

## 2023-03-06

**PeterLe** - *14:33:53*

Sorry for the basic question....

If I wanted to run the back test and capture infomation as it was running for analysis using pandas/jupyter...

Would I use juypterloggingcontrol.py

or

backtestloggingcontrol.py



Am i correct in thinking that  juypterloggingcontrol.py is used AFTER running the back test

whereas backtestloggingcontrol.py is used DURING backtesting



Could someone please explain the difference (in very basic terms) please?

(Still on 100 days of code, maybe i should finish that first! :grinning:)

Thanks in advance

*Tags: Feature Engineering*

---

**PeterLe** - *14:38:07*

TPD were scheduled to do a workshop  today at Wolvs :

-------  TPD Wrote : --------------

Good Morning, in case you are not aware we are running a Workshop at Wolverhampton racecourse on Monday 6th March. The broad agenda being; arrive late afternoon, meet the TPD team, a few presentations re various elements of the service.



The first race is at 5:30pm and the final race at 8:30pm. We plan to do some live betting in the races.



This is a totally free event, there are a limited number of places remaining, if you would like a place reserving please drop an email to [mailto:support@tpd.zone|support@tpd.zone](mailto:support@tpd.zone|support@tpd.zone).

--------------------

There is an email address there DC if it helps?

*Tags: Deployment, Strategies*

---

**Luke Stevens-Cox** - *15:29:51*

Hi guys, new to this slack and sports modelling has anyone done any golf modelling and have any resources they'd be willing to share around where they started or anything they found useful? Thanks

*Tags: Getting Started, Strategies*

---

## 2023-03-12

**D C** - *16:36:13*

Are there TPD problems today? TPD status page looks ok but times there are an hour ahead from the market times on BF - I know US daylight savings dates are not the same as ours. Anyone else had no data?

*Tags: General Technical*

---

## 2023-03-13

**Neil T (Betfair)** - *16:02:56*

_*"It seems that Gmax's racelist systems didn't track the post time correctly causing an hour mismatch of races, strangely it only affected the racelist feed and most internal Gmax systems weren't affected. It's been fixed now and we don't expect a repeat for tonight's fixtures but we will monitor it closely as soon as the races are added to the racelist API,*_



_*Apologies for the inconvenience caused"*_

*Tags: Errors Debugging*

---

## 2023-03-16

**river_shah** - *14:59:06*

My model is to blindly back anything ridden by Rachel Blackmore....[https://www.youtube.com/watch?v=neQwFEzUmiE|60% of the time, it works every time](https://www.youtube.com/watch?v=neQwFEzUmiE|60% of the time, it works every time).

*Tags: Strategies*

---

## 2023-03-18

**PeterLe** - *10:52:49*

Do you think Chat GPT4 can make a successful trader (gambler :grinning:) even better? (Ive used GPT-3 to help me with simple code errors, but Im thinking beyond that)

*Tags: Errors Debugging*

---

**river_shah** - *11:41:13*

```As a trading system, I have many decision rules and thresholds. How should I optimize and combine the thresholds and rules?



Optimizing and combining decision rules and thresholds in a trading system involves selecting the best set of rules and parameter values that maximize your trading strategy's performance, given your objectives and constraints. Here's a step-by-step guide to help you:

Define objectives and constraints: Clearly state your objectives, such as maximizing returns, minimizing risk, or achieving a specific risk-return profile. Also, consider constraints like trading costs, capital requirements, and any regulatory restrictions.

Pre-process data: Clean, preprocess, and organize historical market data to use in your analysis. This data will be used to backtest and optimize your trading strategy.

Create a set of candidate rules: Develop a diverse set of trading rules based on technical indicators, fundamental analysis, or other signals. Make sure these rules are modular and can be combined or adjusted easily.

Split data into training, validation, and testing sets: Divide your historical data into separate sets to prevent overfitting and to ensure that your strategy performs well on unseen data.

Develop a performance metric: Choose an appropriate performance metric (e.g., Sharpe ratio, Sortino ratio, or information ratio) to evaluate your trading strategy. This metric should align with your objectives and constraints.

Optimize decision rules and thresholds: Using the training data, perform optimization to find the best combination of rules and thresholds. There are various optimization methods, such as:

Grid search: Systematically test various combinations of rules and thresholds within a predefined range.

Random search: Test random combinations of rules and thresholds within a predefined range.

Genetic algorithms: Apply evolutionary algorithms to find the optimal combination of rules and thresholds.

Bayesian optimization: Use probabilistic models to optimize the selection of rules and thresholds.

Validate the optimized strategy: Apply the optimized strategy to the validation dataset to assess its performance. If it does not meet your objectives, consider refining the rules, thresholds, or optimization method and repeat the process.

Backtest on out-of-sample data: Once you have validated your optimized strategy, backtest it on the testing dataset to evaluate its performance on unseen data. This step helps ensure the robustness of your strategy.

Monitor and update: Regularly monitor your trading strategy's performance and update the rules and thresholds as needed. Markets evolve over time, and your strategy may need to adapt to changing conditions.

Remember, optimizing and combining trading rules and thresholds is an iterative process that requires continuous monitoring and adjustments. A successful trading system should balance the need for robustness, simplicity, and adaptability to market conditions.```

A more concrete code example useful for trading:



```What is mean variance optimization? Implement MVO using numpy, ensure positivity constraint, shrink covariance matrix to make sparse portfolios. use L-BFGS-B as optimizer





Mean Variance Optimization (MVO) is a portfolio optimization technique developed by Harry Markowitz in his Modern Portfolio Theory. The goal of MVO is to find the optimal allocation of assets in a portfolio that maximizes the expected return while minimizing portfolio risk, as measured by portfolio variance.

Here's an example of MVO implementation in Python using NumPy, SciPy, and a shrinkage method to obtain a sparse portfolio with positivity constraints:

python```



```import numpy as np

import pandas as pd

from scipy.optimize import minimize



def mean_variance_optimization(returns, cov_matrix, target_return, shrinkage_factor=0.5):

    num_assets = len(returns)

    

    # Objective function: Portfolio variance

    def portfolio_variance(weights, cov_matrix):

        return weights.T @ cov_matrix @ weights

    

    # Shrink covariance matrix

    avg_variance = np.mean(np.diag(cov_matrix))

    shrunk_cov_matrix = (1 - shrinkage_factor) * cov_matrix + shrinkage_factor * avg_variance * np.identity(num_assets)

    

    # Constraints

    constraints = (

        {"type": "eq", "fun": lambda w: np.sum(w) - 1},  # Sum of weights equal to 1

        {"type": "eq", "fun": lambda w: np.dot(returns, w) - target_return},  # Target return

    )

    

    # Bounds: positivity constraint

    bounds = [(0, 1) for _ in range(num_assets)]

    

    # Initial weights

    initial_weights = np.ones(num_assets) / num_assets

    

    # Minimization using L-BFGS-B

    result = minimize(portfolio_variance, initial_weights, args=(shrunk_cov_matrix), method="L-BFGS-B", bounds=bounds, constraints=constraints)

    

    return result.x



# Example usage

if __name__ == "__main__":

    asset_returns = np.array([0.05, 0.1, 0.12])

    covariance_matrix = np.array([

        [0.1, 0.05, 0.01],

        [0.05, 0.2, 0.02],

        [0.01, 0.02, 0.3],

    ])

    

    target_return = 0.1

    shrinkage_factor = 0.5

    

    optimal_weights = mean_variance_optimization(asset_returns, covariance_matrix, target_return, shrinkage_factor)

    print("Optimal Weights:", optimal_weights)```

*Tags: Data Quality, Feature Engineering, Performance, Strategies*

---

**river_shah** - *11:45:55*

If I know favourites are over bet in signifiant horse races, what should I do?





If you believe that favorites are overbet in significant horse races, it means that the public is putting too much money on the favorite horses, causing their odds to be lower than their true probabilities of winning. In this case, you can consider the following strategies to potentially take advantage of this market inefficiency:

1. Bet on non-favorites: Focus on betting on non-favorite horses that may have higher odds than their true probabilities of winning. These horses may be undervalued due to the overbetting on the favorites, which can create potential value bets.

2. Look for value in exotic bets: Exotic bets, such as exactas, trifectas, or superfectas, involve predicting the order of finish for multiple horses in a race. Since most bettors tend to focus on favorites, there may be value in including non-favorite horses in your exotic bets.

3. Bet on races with less public attention: Large races tend to attract more casual bettors who tend to overbet favorites. By focusing on races with less public attention, you may find more accurately priced odds, allowing you to identify value bets more easily.

4. Utilize a data-driven approach: Collect and analyze historical data on horses, jockeys, trainers, and race conditions to build a predictive model. This can help you identify undervalued horses and make more informed betting decisions.

5. Implement a disciplined bankroll management strategy: To minimize your risk, use a disciplined bankroll management strategy, such as betting a fixed percentage of your bankroll on each race. This can help protect your bankroll from significant losses due to unexpected race outcomes.

6. Monitor the odds movement: Keep an eye on the odds as they change leading up to the race. You may find value bets if you can identify and capitalize on any discrepancies between the odds and your assessment of each horse's true probability of winning.

Remember, betting on horse races always involves a level of risk. While you may be able to identify value bets by exploiting the overbetting on favorites, it's essential to have a disciplined approach to bankroll management and be prepared for potential losses.

*Tags: Data Quality, Errors Debugging, Strategies*

---

**river_shah** - *11:47:00*

Why is Kelly a good bank roll management scheme?





The Kelly Criterion, developed by John Larry Kelly Jr., is a bankroll management strategy that aims to maximize the expected growth of your bankroll over time. It determines the optimal fraction of your bankroll to bet on each opportunity, based on the estimated probability of winning and the odds offered. The Kelly Criterion is considered a good bankroll management scheme for several reasons:

1. Maximizes expected growth: The Kelly Criterion is designed to maximize the expected growth of your bankroll by considering both the probability of winning and the payoff of the bet. This ensures that you are investing the optimal amount for each bet, maximizing your potential returns over time.

2. Minimizes risk of ruin: By betting a proportion of your bankroll, the Kelly Criterion helps you avoid the risk of losing your entire bankroll in a short period. The risk of ruin decreases as you use a smaller fraction of the optimal Kelly bet, providing a balance between risk and potential returns.

3. Adjusts for varying bet sizes: The Kelly Criterion dynamically adjusts the bet size based on your current bankroll and the odds of each opportunity. This means that as your bankroll grows, your bet sizes will also increase, enabling you to capitalize on your success. Conversely, when your bankroll decreases, your bet sizes will decrease, protecting you from further losses.

4. Takes probability and odds into account: Unlike other bankroll management strategies, the Kelly Criterion considers both the probability of winning and the odds offered by the bet. This allows you to make more informed decisions and better manage your risk, as you are not only considering the size of your bankroll but also the potential returns and the likelihood of success.

5. Encourages disciplined betting: The Kelly Criterion promotes disciplined betting by requiring you to carefully estimate the probability of winning and compare it to the odds offered. This approach encourages a more analytical and systematic approach to betting, which can lead to better long-term results.

However, it's worth noting that the Kelly Criterion has some limitations:

• It requires accurate estimation of the probability of winning, which can be challenging in practice.

• It can lead to relatively large bet sizes if the perceived edge is significant, increasing the risk of large losses.

• It may not be suitable for risk-averse bettors, as it focuses on maximizing expected growth rather than minimizing risk.

Despite these limitations, the Kelly Criterion remains a popular and effective bankroll management strategy due to its ability to maximize expected growth while minimizing the risk of ruin.

*Tags: Strategies*

---

**river_shah** - *11:48:29*

Sometimes I like to bet the farm. Is that a good strategy?





Betting the farm, or wagering your entire bankroll on a single bet, is generally considered a high-risk strategy and is not advisable for most bettors. Here are several reasons why betting the farm is not a good strategy:

1. Risk of ruin: Betting your entire bankroll on a single bet exposes you to a significant risk of losing everything if the bet does not go in your favor. This can be emotionally and financially devastating, especially if you've spent a considerable amount of time building your bankroll.

2. No room for recovery: When you bet the farm, you leave no room for recovery if the bet goes against you. A more prudent approach would involve placing smaller, calculated bets that allow you to recover from losses and maintain a more consistent betting strategy.

3. Inefficient capital allocation: Betting the farm usually implies that you are overconfident about a particular outcome. However, even in situations where you have a strong edge, it is more efficient to allocate your capital across multiple bets to maximize the long-term growth of your bankroll.

4. Encourages emotional decision-making: Betting the farm can lead to emotional decision-making, as you are likely to be more concerned about the immediate outcome rather than focusing on the long-term growth of your bankroll. Emotional decisions often lead to poor results, as they are not based on a sound analysis of probabilities and odds.

A more sensible approach to betting involves using a disciplined bankroll management strategy, such as the Kelly Criterion, fixed percentage betting, or fixed-unit betting. These strategies aim to balance risk and reward, maximizing the long-term growth of your bankroll while minimizing the risk of ruin. By following a disciplined approach, you can enjoy betting while protecting yourself from significant financial losses.

*Tags: Errors Debugging, Strategies*

---

**river_shah** - *11:48:54*

^ Joke question

*Tags: General Technical*

---

**PeterLe** - *13:09:53*

In response to the question : summarise the key points from the book - efficiency of racetrack betting markets by william T Ziemba and which is the most optimal strategy:



"Efficiency of Racetrack Betting Markets" is a book by William T. Ziemba and Donald B. Hausch that provides a comprehensive analysis of the betting markets in horse racing. The book examines the efficiency of these markets and explores various strategies for betting on horse races. Here are the key points from the book:

1. Market efficiency: The authors argue that racetrack betting markets are relatively efficient, meaning that odds generally reflect the true probability of outcomes. However, they also point out that there are inefficiencies that can be exploited by astute bettors.

2. The favorite-longshot bias: The book discusses the well-known favorite-longshot bias, which is the tendency for bettors to overbet longshots and underbet favorites. This bias can lead to consistent losses for bettors who consistently back longshots.

3. The importance of data: The authors emphasize the importance of using data to make informed betting decisions. This includes historical data on horse performances, track conditions, and other relevant factors.

4. Handicapping: Ziemba and Hausch provide a detailed overview of various handicapping methods, such as speed ratings, pace analysis, and form analysis. They argue that successful handicapping is essential for consistently identifying value bets.

5. Optimal betting strategies: The book examines several betting strategies and their potential profitability, such as the Kelly Criterion, proportional betting, and fixed fractional betting.

6. Market efficiency and arbitrage opportunities: The authors explore the existence of arbitrage opportunities in racetrack betting markets, where bettors can lock in a profit regardless of race outcomes.

7. Risk management: The book emphasizes the importance of managing risk in betting, highlighting that the optimal betting strategy should take into account the bettor's risk tolerance and bankroll size.

The most optimal strategy, according to the authors, is using the Kelly Criterion. This betting strategy involves adjusting bet sizes based on the perceived edge and the bettor's bankroll. The Kelly Criterion is known for maximizing long-term growth while also managing risk. However, it's important to note that the success of this strategy depends on the bettor's ability to accurately estimate the true probabilities of race outcomes and identify value bets.

*Tags: Data Quality, Errors Debugging, Performance, Strategies*

---

**foxwood** - *17:06:06*

I found the best results came from drilling down from the answer into a deeper question using the same terms the chat used, It gets down to some serious code and ML ideas. You do need to use everything with caution and detailed testing/review though since it does get things wrong as [@U01B8031PM1](@U01B8031PM1) pointed out re hallucinations. The idea of a book summary by [@UQL0QDEKA](@UQL0QDEKA) is useful - far better than Amazon reviews - although it might have nicked the text from there or similar.

*Tags: General Technical*

---

## 2023-03-19

**Michael** - *17:27:46*

Generally, it gets code right but the issue is more the model being natural language and therefore ambiguity, so it is right but might not do 100% what you meant it to. I saw someone suggest you could let it access your shell and then use it to iterate your code as it runs and runs into errors, very interesting use case but it would probably get itself stuck in circles at some point

*Tags: Errors Debugging, Strategies*

---

## 2023-03-20

**river_shah** - *15:26:48*

Who wrote betfairlightweight?





Betfairlightweight is an open-source Python library designed to interact with the Betfair API. It was created by Liam Pauling, a software developer who has contributed to various open-source projects. You can find the betfairlightweight repository on GitHub: [https://github.com/liampauling/betfair](https://github.com/liampauling/betfair)

*Tags: General Technical*

---

**river_shah** - *15:48:38*

Why is Liam Pauling a fictional person and how does Liam Pauling become a real person?





I apologize for any confusion. There may have been a misunderstanding in my previous responses. Based on the information available to me, Liam Pauling appears to be a real person, not a fictional character. He is a software developer who has contributed to open-source projects, such as the betfairlightweight library.

*Tags: General Technical*

---

**PeterLe** - *16:06:15*

I used chat gpt4 last night and just playing around, asked it to make suggestions on the monte carlo code provided by [@U016TGY3676](@U016TGY3676) and how it may be improved.  it provided a new version but automatically added in calculations for the 5th and 95th percentiles (which I didnt ask for) . I then read up on what they were. It seems that the key is know which questions to ask in the right order :grinning:

*Tags: General Technical*

---

**birchy** - *16:15:46*

Funnily enough I had to Google chat gpt in order to find out how to get/use it. Was quite impressed tbh. I asked a few generic questions about prediction of probabilities and it offered several insights and code snippets that would be a good starting point.

It's basically a glorified Google search but without all the obfuscations and diversions.

*Tags: General Technical*

---

## 2023-03-23

**Peter** - *08:40:28*

Bard's no better. "The Betfairlightweight Python library was written by oksidisko. It is a lightweight, super fast wrapper for Betfair API-NG (with streaming) that allows all betting operations (including market and order streaming) and most account operations."

*Tags: Strategies*

---

## 2023-04-02

**Paul** - *09:29:08*

The article itself states that most experts reckon that the models out there can break even at the track (i.e. they break even at 120%), and the CAW players make their profits on that 10% rebate.

*Tags: Strategies*

---

**Paul** - *10:28:30*

It raises the question of why they're not putting more into exchanges - with &lt; 104% over-round on most US races from what I've eyeballed - but perhaps they are.

*Tags: General Technical*

---

## 2023-04-03

**river_shah** - *13:01:00*

Anyone try this with bflw / flumine? Looks promising. Either build standalone binary (which likely won't work with bflw / flumine) or just jit compile critical functions:

[https://github.com/exaloop/codon](https://github.com/exaloop/codon)

*Tags: General Technical*

---

**river_shah** - *13:01:25*

Better than numba as that only deals well with numpy loops

*Tags: General Technical*

---

## 2023-04-12

**D C** - *10:58:34*

Yes there are many questions about it not least of which is how you define a "horse that leads". These numbers look like they are arrived at with proform and I don't currently use that but I do wonder what a similar analysis would look like using GPS data.

*Tags: General Technical*

---

## 2023-04-17

**Paul** - *10:10:02*

I’m stacked at the moment but will get some sorted next month perhaps. There is also the AWS event this week I posted a while back, could be if interest to some of you

*Tags: Deployment*

---

## 2023-04-25

**Unknown** - *12:09:03*

Not sure if anyone also does crypto trading but I've been collaborating with a crypto data provider ([http://CCData.io|CCData.io](http://CCData.io|CCData.io)) as a software dev. Got you a free data bundle to play with, usually sold for ~$1k.



Data is in CSV format containing all trades (spot + futures) and order book changes (spot only) for Binance BTC-USDT for 1-31 March 2023. See the attached PDF for data format info and instructions on how to re-play the order book.



[https://bit.ly/march2023-trades](https://bit.ly/march2023-trades) (~7GB compressed)

[https://bit.ly/march2023-obsnapshots](https://bit.ly/march2023-obsnapshots) (~20GB compressed)

[https://bit.ly/march2023-obupdates](https://bit.ly/march2023-obupdates) (~27GB compressed)

*Tags: Strategies*

---

## 2023-05-04

**Jonjonjon** - *22:14:22*

On the website, it' possible to lay £2.00  at odds of 2.0 And then modify the betsize to £2.10. The additional £0.10 will be a new bet. Is this possible with Flumine?

*Tags: General Technical*

---

## 2023-05-06

**Ruben** - *17:06:26*

bit of a random Q: is there anything similar to flumine but for financial markets? Meaning the ability to clearly define triggers and run multiple strategies efficiently, managing orders, etc; for stocks, forex, options...that you could then use with one or more brokers

*Tags: General Technical*

---

## 2023-05-09

**Newbie99** - *13:19:49*

I've recently switched to a new MacBook pro, from an old windows machine and as I knew performance was rubbish on that, I didn't worry too much, just left things processing overnight etc. However with an M2 Max I was expecting super fast backtesting, but compared to the results people post on here I seem to be way behind (e.g. 16k pre-race horse racing markets, 1 hour before the off takes circa 3 hours).



My code is as follows:

```def start_backtest_a(chunked_markets, max_workers, profit_sum, in_play, seconds_to_start, event_processing,

                    strategy_names, match_all, middleware):



    _process_jobs = []

    with futures.ProcessPoolExecutor(max_workers=max_workers) as p:

        for m in chunked_markets:

            _process_jobs.append(

                p.submit(startup,

                         profit_sum=profit_sum,

                         in_play=in_play,

                         seconds_to_start=seconds_to_start,

                         event_processing=event_processing,

                         markets=m,

                         strategy_names=strategy_names,

                         match_all=match_all,

                         middleware=middleware

                )

            )

        for i, job in enumerate(futures.as_completed(_process_jobs)):

            try:

                mini_output_list = job.result()  # wait for result

                output_list.extend(mini_output_list)

                progress = len(m) * i+1

                time_taken_seconds = (datetime.datetime.utcnow() - sim_start_time).total_seconds()

                time_taken_minutes = time_taken_seconds / 60

                percentage = progress / total_markets

                time_taken = time_taken_minutes if time_taken_minutes &gt; 2 else time_taken_seconds

                time_remaining = (time_taken / percentage) - time_taken

                time_measure = 'minutes' if time_taken_minutes &gt; 2 else 'seconds'

                print(f'Currently on market {progress} / {percentage*100:.2f}% of {total_markets}, '

                      f'time taken so far is {time_taken:.2f} {time_measure}, estimated time remaining is {time_remaining:.2f} {time_measure}, ')

            except Exception as e:

                print(f'Exception {e}.')

        return output_list```

With startup being as follows:



```def startup(markets, profit_sum, in_play, seconds_to_start, event_processing, strategy_names, match_all, middleware=False):

    logger = logging.getLogger()



    custom_format = "%(asctime) %(levelname) %(message)"

    log_handler = logging.StreamHandler()

    formatter = jsonlogger.JsonFormatter(custom_format)

    formatter.converter = time.gmtime

    log_handler.setFormatter(formatter)

    logger.addHandler(log_handler)

    logger.setLevel(logging.CRITICAL)  # Set to logging.CRITICAL to speed up simulation



    start_time = get_utc_time()



    # Gets a list of strategy settings

    settings = [setting for setting in rc if setting['on'] is True and setting['strategy_name'] in strategy_names]



    client = clients.SimulatedClient(simulated_full_match=match_all)



    framework = FlumineSimulation(client=client)



    # with mock_patch("builtins.open", smart_open.open): # Commented out as files will be unzipped prior to running

    for s in settings:

        max_selection_exposure = s['max_selection_exposure'] if true_or_false(s['max_selection_exposure']) != False else None

        include_virtual_prices = "EX_BEST_OFFERS_DISP" if true_or_false(

            s['include_virtual_prices']) is not False else "EX_ALL_OFFERS"

        if s['strategy_type'] == 'simple':



            strategy = betting_strategy(start_time=start_time, settings=s, paper=client.paper_trade,

                                        market_filter=create_market_filter(markets, in_play, seconds_to_start, event_processing),

            market_data_filter=streaming_market_data_filter(

            fields=[

                include_virtual_prices,

                "EX_TRADED",

                "EX_TRADED_VOL",

                "EX_LTP",

                "EX_MARKET_DEF",

                "SP_TRADED",

                "SP_PROJECTED",

            ]

            ),

            streaming_timeout=2,

            max_selection_exposure=max_selection_exposure,

            max_order_exposure=s['max_order_exposure'],

            conflate_ms=s['conflate'],

            name=s['strategy_name'],



            )



            framework.add_strategy(strategy)



    ''' Add in Middleware to get Market Catalogue '''

    framework.add_market_middleware(MarketCatalogueMiddleware())



    if middleware is not False:

        framework.add_market_middleware(middleware)



    framework.add_market_middleware(RiskMiddleware(framework))



    framework.run()```

I presume that calling the middleware could be an issue and also potentially my structure is wrong (i.e. in terms of trying to multiprocess at the wrong point).



I did try to get chatGPT to re-write things and it tried to use:



_with mp.get_context('spawn').Pool(max_workers) as pool:_ 



However I couldn't get it working (i.e. it never actually ran the framework, so I couldn't work out how to proceed).



Appreciate this is a bit of a '_how long is a piece of string_' situation, but is there a fairly generic approach to using multi processing with middleware that perhaps I could use as a template?

*Tags: Errors Debugging, Performance, Strategies*

---

**liam** - *13:23:08*

What are we looking at here? Is it a simulation as I see paper trade client? a streaming market filter? no listener_kwargs?

*Tags: General Technical*

---

**Newbie99** - *19:06:36*

```ncalls  tottime  percall  cumtime  percall filename:lineno(function)

      113    0.002    0.000  585.570    5.182 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:199(as_completed)

      114    0.001    0.000  585.563    5.137 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:604(wait)

      114    0.003    0.000  585.562    5.137 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:288(wait)

     2480  585.558    0.236  585.558    0.236 {method 'acquire' of '_thread.lock' objects}

   1998/1    0.019    0.000   10.578   10.578 {built-in method builtins.exec}

        1    0.000    0.000   10.578   10.578 backtesting.py:1(&lt;module&gt;)

        1    0.002    0.002    8.888    8.888 backtesting.py:288(start_backtest_a)

  1979/22    0.004    0.000    1.383    0.063 &lt;frozen importlib._bootstrap&gt;:1167(_find_and_load)

  1960/22    0.004    0.000    1.382    0.063 &lt;frozen importlib._bootstrap&gt;:1122(_find_and_load_unlocked)

  1874/23    0.003    0.000    1.379    0.060 &lt;frozen importlib._bootstrap&gt;:666(_load_unlocked)

  1630/23    0.002    0.000    1.379    0.060 &lt;frozen importlib._bootstrap_external&gt;:934(exec_module)

  4574/43    0.001    0.000    1.370    0.032 &lt;frozen importlib._bootstrap&gt;:233(_call_with_frames_removed)

  894/160    0.001    0.000    1.056    0.007 {built-in method builtins.__import__}

 2336/977    0.002    0.000    0.919    0.001 &lt;frozen importlib._bootstrap&gt;:1209(_handle_fromlist)

        1    0.000    0.000    0.688    0.688 /python_files/football_data.py:1(&lt;module&gt;)

4684/4545    0.045    0.000    0.350    0.000 {built-in method builtins.__build_class__}

        1    0.000    0.000    0.335    0.335 /python_files/validation_functions.py:1(&lt;module&gt;)

        1    0.000    0.000    0.334    0.334 /python_files/import_historic_horse_data.py:1(&lt;module&gt;)

     1630    0.005    0.000    0.325    0.000 &lt;frozen importlib._bootstrap_external&gt;:1007(get_code)

        1    0.000    0.000    0.309    0.309 backtesting.py:212(generate_event_groupings)

        1    0.000    0.000    0.297    0.297 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/holtwinters/__init__.py:1(&lt;module&gt;)

        1    0.000    0.000    0.297    0.297 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/statsmodels/tsa/holtwinters/model.py:1(&lt;module&gt;)

        1    0.000    0.000    0.249    0.249 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:1(&lt;module&gt;)

        1    0.000    0.000    0.231    0.231 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/__init__.py:1(&lt;module&gt;)

        1    0.013    0.013    0.222    0.222 backtesting.py:270(&lt;listcomp&gt;)

    39431    0.214    0.000    0.214    0.000 {built-in method posix.stat}

     1630    0.002    0.000    0.214    0.000 &lt;frozen importlib._bootstrap_external&gt;:1127(get_data)

1874/1863    0.002    0.000    0.194    0.000 &lt;frozen importlib._bootstrap&gt;:566(module_from_spec)

        1    0.000    0.000    0.194    0.194 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/__init__.py:1(&lt;module&gt;)

     1637    0.188    0.000    0.188    0.000 {method 'read' of '_io.BufferedReader' objects}

  234/229    0.000    0.000    0.173    0.001 &lt;frozen importlib._bootstrap_external&gt;:1231(create_module)

  234/229    0.170    0.001    0.172    0.001 {built-in method _imp.create_dynamic}

        1    0.000    0.000    0.172    0.172 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_stats_py.py:1(&lt;module&gt;)

      100    0.000    0.000    0.164    0.002 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/artist.py:159(_update_set_signature_and_docstring)

       99    0.000    0.000    0.161    0.002 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/artist.py:126(__init_subclass__)

       33    0.000    0.000    0.148    0.004 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:108(import_module)

       33    0.000    0.000    0.148    0.004 &lt;frozen importlib._bootstrap&gt;:1194(_gcd_import)

        1    0.000    0.000    0.140    0.140 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/distributions.py:1(&lt;module&gt;)

        1    0.000    0.000    0.137    0.137 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/figure.py:1(&lt;module&gt;)

        1    0.000    0.000    0.129    0.129 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/projections/__init__.py:1(&lt;module&gt;)

      112    0.000    0.000    0.110    0.001 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/artist.py:1841(kwdoc)

     2025    0.039    0.000    0.103    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py:762(submit)

        1    0.000    0.000    0.100    0.100 /python_files/misc_functions.py:1(&lt;module&gt;)

        1    0.024    0.024    0.099    0.099 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:1(&lt;module&gt;)

  234/167    0.000    0.000    0.096    0.001 &lt;frozen importlib._bootstrap_external&gt;:1239(exec_module)

  234/167    0.017    0.000    0.096    0.001 {built-in method _imp.exec_dynamic}

        1    0.000    0.000    0.096    0.096 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/__init__.py:1(&lt;module&gt;)

        1    0.000    0.000    0.095    0.095 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/smart_open/__init__.py:1(&lt;module&gt;)

        1    0.000    0.000    0.095    0.095 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/flumine.py:1(&lt;module&gt;)

        1    0.000    0.000    0.094    0.094 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/smart_open/smart_open_lib.py:1(&lt;module&gt;)

        1    0.000    0.000    0.094    0.094 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/baseflumine.py:1(&lt;module&gt;)

      112    0.002    0.000    0.094    0.001 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/artist.py:1602(pprint_setters)

        1    0.000    0.000    0.093    0.093 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/smart_open/doctools.py:1(&lt;module&gt;)

        1    0.000    0.000    0.093    0.093 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/smart_open/transport.py:1(&lt;module&gt;)

        9    0.000    0.000    0.093    0.010 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/smart_open/transport.py:32(register_transport)

        1    0.000    0.000    0.093    0.093 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/api.py:1(&lt;module&gt;)

        1    0.000    0.000    0.092    0.092 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/colorbar.py:1(&lt;module&gt;)

        1    0.000    0.000    0.089    0.089 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/strategy/strategy.py:1(&lt;module&gt;)

     1937    0.008    0.000    0.088    0.000 &lt;frozen importlib._bootstrap&gt;:1056(_find_spec)

     1630    0.002    0.000    0.086    0.000 &lt;frozen importlib._bootstrap_external&gt;:727(_compile_bytecode)```

*Tags: Feature Engineering, Strategies*

---

**Newbie99** - *19:41:14*

```  ncalls  tottime  percall  cumtime  percall filename:lineno(function)

   288135    1.555    0.000  662.991    0.002 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/simulation/simulation.py:109(_process_market_books)

        4    0.000    0.000  467.806  116.951 /python_files/backtesting_functions.py:44(startup)

        4    0.232    0.058  467.637  116.909 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/simulation/simulation.py:29(run)

  1134046    8.263    0.000  459.433    0.000 /python_files/market_making.py:36(place_passive_order)

  9757016   17.160    0.000  396.170    0.000 /python_files/place_order_functions.py:327(place_or_cancel)

   1992/1    0.020    0.000  282.462  282.462 {built-in method builtins.exec}

        1    0.000    0.000  282.462  282.462 backtesting.py:1(&lt;module&gt;)

        1    0.000    0.000  280.392  280.392 backtesting.py:325(start_backtest_b)

  1151150    0.395    0.000  267.220    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/utils.py:235(call_strategy_error_handling)

   287798    0.840    0.000  243.036    0.001 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/simulation/simulation.py:154(_process_simulated_orders)

   574944    0.413    0.000  242.620    0.000 /python_files/betting_strategy.py:53(process_market_book)

   559802    0.202    0.000  241.037    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/utils.py:272(call_process_orders_error_handling)

   559802    0.632    0.000  240.835    0.000 /python_files/betting_strategy.py:68(process_orders)

  4342013   47.805    0.000  154.966    0.000 /python_files/place_order_functions.py:577(validate_new_order)

  1152415    0.544    0.000  150.247    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/utils.py:255(call_middleware_error_handling)

  4784556    3.025    0.000  102.676    0.000 /python_files/place_order_functions.py:310(cancel_orders_by_price)

   288103    1.304    0.000   78.054    0.000 /python_files/risk_worker.py:9(__call__)

121605882   50.622    0.000   73.601    0.000 /python_files/validation_functions.py:769(true_or_false)

 20833220   20.227    0.000   72.348    0.000 /python_files/place_order_functions.py:924(get_limit)

   576206   14.875    0.000   71.167    0.000 /python_files/risk_functions.py:31(calc_exposure_metrics)

   288104    0.207    0.000   62.674    0.000 /python_files/competition.py:121(__call__)

 14541572   31.843    0.000   61.683    0.000 /python_files/risk_functions.py:127(get_runner_exposure)

   287472    0.419    0.000   61.392    0.000 /python_files/competition.py:146(update_market)

   287472    0.980    0.000   60.909    0.000 /python_files/competition.py:187(update_modelled_price_list)

  4784556   11.933    0.000   60.852    0.000 /python_files/cancel_and_replace.py:12(cancel_orders)

 55674710   31.552    0.000   48.538    0.000 /python_files/validation_functions.py:725(check_race_type_by_country)

  1136008    3.174    0.000   45.434    0.000 /python_files/validation_functions.py:47(validate_market_book)

   287472    0.664    0.000   42.708    0.000 /python_files/competition.py:221(&lt;listcomp&gt;)

  2486230    2.362    0.000   42.045    0.000 /python_files/competition.py:234(update_runner_price)

  2486230    1.287    0.000   39.121    0.000 /python_files/competition.py:171(get_runner_name)

  2486230    4.873    0.000   37.716    0.000 /python_files/competition.py:172(&lt;listcomp&gt;)

  9757016   10.321    0.000   36.596    0.000 /python_files/market_making.py:6(create_runner_dict)

  1440123    3.603    0.000   35.733    0.000 /python_files/place_order_functions.py:228(construct_price)

 28978669   10.676    0.000   32.843    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/betfairlightweight/resources/bettingresources.py:8(__getitem__)

   576206    6.713    0.000   29.727    0.000 /python_files/risk_functions.py:46(&lt;listcomp&gt;)

  1134046    2.796    0.000   26.220    0.000 /python_files/validation_functions.py:163(validate_order_windows)

  5095443   10.677    0.000   25.777    0.000 /python_files/place_order_functions.py:138(get_benchmark_percentage_and_tolerance)

   576206    0.372    0.000   24.206    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/strategy/strategy.py:101(check_market)

   576206    0.590    0.000   23.735    0.000 /python_files/betting_strategy.py:37(check_market_book)

  9757016    4.906    0.000   22.284    0.000 /python_files/misc_functions.py:72(get_runner_info)

 43650454   10.245    0.000   21.749    0.000 /python_files/risk_functions.py:135(validate_order_has_risk)

   288166    0.864    0.000   21.579    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/streams/historicalstream.py:204(_read_loop)

 28978669    7.751    0.000   20.991    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/betfairlightweight/utils.py:69(to_snake_case)

 10891063   11.955    0.000   19.219    0.000 /python_files/validation_functions.py:254(check_market)

 14541572   18.712    0.000   18.712    0.000 /python_files/risk_functions.py:130(&lt;listcomp&gt;)

380141490   17.861    0.000   17.863    0.000 {built-in method builtins.isinstance}

  9757016   16.306    0.000   16.887    0.000 /python_files/misc_functions.py:73(&lt;listcomp&gt;)

   287472    2.668    0.000   16.183    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/shin/__init__.py:5(calculate_implied_probabilities)

  4342013    3.838    0.000   15.908    0.000 /python_files/place_order_functions.py:565(get_benchmark_value)

  1134046    1.803    0.000   15.850    0.000 /python_files/validation_functions.py:76(get_price_at_post_time)

   589543    0.445    0.000   15.093    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/streams/historicalstream.py:187(on_data)

 51813748    8.634    0.000   13.955    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/order/order.py:436(size_matched)

   589543    1.351    0.000   13.903    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/streams/historicalstream.py:30(_process)

 14497067    3.100    0.000   12.459    0.000 {built-in method builtins.sum}

   589543    1.884    0.000   12.020    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/betfairlightweight/streaming/cache.py:234(update_cache)

 28980260   11.731    0.000   11.731    0.000 {method 'sub' of 're.Pattern' objects}

  4342013   11.682    0.000   11.682    0.000 /python_files/place_order_functions.py:571(&lt;listcomp&gt;)

  1134046    1.977    0.000   11.560    0.000 /python_files/validation_functions.py:88(&lt;listcomp&gt;)

144563009   11.485    0.000   11.485    0.000 /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/strategy/strategy.py:249(name)

  4342013   11.182    0.000   11.182    0.000 /python_files/misc_functions.py:148(create_ordered_dict)```

*Tags: Errors Debugging, Strategies*

---

**Newbie99** - *19:56:16*

```  ncalls  tottime  percall  cumtime  percall filename:lineno(function)

  2408686   18.768    0.000 1041.182    0.000 /python_files/market_making.py:36(place_passive_order)





Called By:



   Ordered by: cumulative time

   List reduced from 9630 to 1 due to restriction &lt;'place_passive_order'&gt;



Function                                                                       was called by...

                                                                                   ncalls  tottime  cumtime

/python_files/market_making.py:36(place_passive_order)  &lt;- 1229074    9.614  554.391  /python_files/betting_strategy.py:53(process_market_book)

                                                                                  1179612    9.155  486.792  /python_files/betting_strategy.py:68(process_orders)





Called:



   Ordered by: cumulative time

   List reduced from 9630 to 1 due to restriction &lt;'place_passive_order'&gt;



Function                                                                       called...

                                                                                   ncalls  tottime  cumtime

/python_files/market_making.py:36(place_passive_order)  -&gt; 2408686    0.271    0.271  /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/flumine/strategy/strategy.py:249(name)

                                                                                 21826158   23.419   83.258  /python_files/market_making.py:6(create_runner_dict)

                                                                                 21826158   38.883  897.773  /python_files/place_order_functions.py:327(place_or_cancel)

                                                                                 21826158   25.190   40.984  /python_files/validation_functions.py:254(check_market)

                                                                                  2408686    0.128    0.128  {method 'keys' of 'dict' objects}```

*Tags: Strategies*

---

## 2023-05-10

**Newbie99** - *07:45:06*

Cool thanks Liam, at a high level what is happening (I think), is my conditional cancel logic (for some pre race strategies I only cancel if the model believes fair value has changed, rather than every x seconds).



Then the other part is reading values from a deeply nested JSON file to get values and that involves multiple loops.



Will get the functions, there's nothing proprietary as such, just inefficient code I think!

*Tags: Strategies*

---

**liam** - *07:48:20*

The best way to speed up python is to not run python, so anything you can do to not call code if not required is your best option first

*Tags: Performance*

---

**Newbie99** - *08:50:45*

Its funny, but I wrote these functions, probably 2, maybe 3 years ago now (albeit they have grown into very slow moving monsters over time)! Back then they seemed to make sense!!!



I think the bulk of the issue is the sheer inefficiency of these two, as they get called a lot as part of my order validation (or cancellation) process:



```def check_race_type_by_country(race_type, market_name, event_type_id, country_dict):



    race_type = return_race_type(race_type, market_name, event_type_id)



    maiden = True if 'Mdn' in market_name else False



    if country_dict != False and isinstance(country_dict, dict):

        price = False

        # If a dict is in the config, it will match by country and race type

        maiden_list = [v for k,v in country_dict.items() if race_type == k]

        if len(maiden_list) &gt; 0:

            if isinstance(maiden_list[0], list):

                for m in maiden_list[0]:

                    if 'Mdn' in m.keys() and maiden is True:

                        price = m['Mdn']

                    else:

                        if 'default' in m.keys():

                            price = m['default']

            else:

                price = maiden_list[0]



        else:

            if 'default' in country_dict.keys():

                if 'odds' not in country_dict.keys() and 'runners' not in country_dict.keys():

                    maiden_list = country_dict['default']

                    if isinstance(maiden_list, list):

                        for m in maiden_list:

                            if 'Mdn' in m.keys() and maiden is True:

                                price = m['Mdn']

                            else:

                                if 'default' in m.keys():

                                    price = m['default']

                    else:

                        price = maiden_list

                else:

                    price = country_dict

    else:

        # If a single price (rather than a dict) is in the config, then it will set this for all valid markets

        if isinstance(country_dict, float) or isinstance(country_dict, int):

            price = country_dict

        else:

            price = False

    return price



def true_or_false(setting, country_code=False, market_id=False, market_type=False):

    if not isinstance(setting, list):

        if setting == 'True':

            return True

        elif setting == 'False':

            return False

        else:

            return setting

    else:

        if country_code is False or country_code is None or country_code == 'False':

            if setting == 'True' or setting is True:

                return True

            elif setting == 'False' or setting is False:

                return False

            else:

                if market_id is False:

                    if isinstance(setting, list):

                        default = [s for s in setting if isinstance(s, dict) and 'default' in s.keys()]

                        if len(default) &gt; 0:

                            if market_type is False:

                                return default[0]['default']

                            else:

                                market_type_benchmark = [s for s in setting if isinstance(s, dict) and market_type in s.keys()]

                                if len(market_type_benchmark) &gt; 0:

                                    return market_type_benchmark[0][market_type]

                                else:

                                    return default[0]['default']

                        else:

                            return setting

                    else:

                        return setting

                else:

                    for s in setting:

                        if market_id in s.keys():

                            if s[market_id] == 'True':

                                return True

                            elif s[market_id] == 'False':

                                return False

                            else:

                                return s[market_id]

                        else:

                            default = [s for s in setting if 'default' in s.keys()]

                            if len(default) &gt; 0:

                                if market_type is False:

                                    return default[0]['default']

                                else:

                                    market_type_benchmark = [s for s in setting if

                                                             isinstance(s, dict) and market_type in s.keys()]

                                    if len(market_type_benchmark) &gt; 0:

                                        return market_type_benchmark[0][market_type]

                                    else:

                                        return default[0]['default']

                            else:

                                return False

                    else:

                        default = [s for s in setting if 'default' in s.keys()]

                        if len(default) &gt; 0:

                            if market_type is False:

                                return default[0]['default']

                            else:

                                market_type_benchmark = [s for s in setting if

                                                         isinstance(s, dict) and market_type in s.keys()]

                                if len(market_type_benchmark) &gt; 0:

                                    return market_type_benchmark[0][market_type]

                                else:

                                    return default[0]['default']

                        else:

                            return False

        else:

            for s in setting:

                if isinstance(s, dict):

                    if country_code in s.keys():

                        if s[country_code] == 'True':

                            return True

                        elif s[country_code] == 'False':

                            return False

                        else:

                            if isinstance(s[country_code], dict):

                                if market_type in s[country_code].keys():

                                    return s[country_code][market_type]

                                else:

                                    if 'default' in s[country_code].keys():

                                        return s[country_code]['default']

                                    else:

                                        return False

                            else:

                                return s[country_code]

                    else:

                        if market_id is False:

                            default = [s for s in setting if 'default' in s.keys()]

                            if len(default) &gt; 0:

                                if market_type is False:

                                    return default[0]['default']

                                else:

                                    market_type_benchmark = [s for s in setting if

                                                             isinstance(s, dict) and market_type in s.keys()]

                                    if len(market_type_benchmark) &gt; 0:

                                        return market_type_benchmark[0][market_type]

                                    else:

                                        return default[0]['default']

                            else:

                                return setting

                        else:

                            if market_id in s.keys():

                                if s[market_id] == 'True':

                                    return True

                                elif s[market_id] == 'False':

                                    return False

                                else:

                                    return s[market_id]

            else:

                default = [s for s in setting if isinstance(s, dict) and 'default' in s.keys()]

                if len(default) &gt; 0:

                    if market_type is False:

                        return default[0]['default']

                    else:

                        market_type_benchmark = [s for s in setting if

                                                 isinstance(s, dict) and market_type in s.keys()]

                        if len(market_type_benchmark) &gt; 0:

                            return market_type_benchmark[0][market_type]

                        else:

                            return default[0]['default']

                else:

                    if isinstance(setting, list):

                        return setting

                    else:

                        return False```

setting in the above refers to a dict, on startup I open a json file which contains various parameters.



An example would be something like this:



```    {

        "event_type_ids": [

            7

        ],

        "strategy_name": "strategy_xyz",

        "country_codes": false,

        "market_types": [

            "WIN"

        ],

        "execution_market_types": [

            "WIN"

        ],

        "pre_event_order_window": [

            {

                "GB": [

                    {

                        "start": 3600,

                        "duration": false

                    }

                ],

                "IE": [

                    {

                        "start": 3600,

                        "duration": false

                    }

                ],

                "US": [

                    {

                        "start": 3600,

                        "duration": false

                    }

                ],

                "FR": [

                    {

                        "start": 3600,

                        "duration": false

                    }

                ],

                "AU": [

                    {

                        "start": 3600,

                        "duration": false

                    }

                ]

            }

        ]}```



*Tags: Performance, Strategies*

---

**Newbie99** - *09:41:41*

Yeah I suspect almost all of it can go! I simply didn’t realise how much of an impact it was having until I started Backtesting a new strategy (it only comes up in certain situations as anything in-play for example would already bypass this logic so haven’t noticed for a while)!



Seeing the cprofile results was quite an eye opener, I think this particular strategy generated a lot more orders that triggered this logic so really highlighted the inefficiency!

*Tags: Strategies*

---

**liam** - *09:53:47*

Just run it with a base strategy that does nothing and aim for that

*Tags: Strategies*

---

## 2023-05-12

**liam** - *08:26:35*

The title and description really doesn’t help the cause 

*Tags: General Technical*

---

**ShaunW** - *14:59:00*

Only approx 58.6% of the time [@USWDY5P7G](@USWDY5P7G) . :wink:  The morality model certainly isn't short of inputs so any conclusion is a range at best.

*Tags: Strategies*

---

## 2023-05-25

**Mo** - *11:22:03*

Less reason to have them now we have order and strategy refs but they predated those 

*Tags: Strategies*

---

**Herugrim** - *11:34:17*

Yeah and because you pay commission per market per account you would generally end up paying more commission, especially if your accounts ran competing strategies. It’s painful to setup and even more painful to manage. 



IMO the only reason to need one is if you were deploying bots that have to potential to go rogue and drain your balance, but that comes back to improving your coding and best practices. It’s easier just to use strategy refs

*Tags: Getting Started, Deployment, Strategies*

---

**PeterLe** - *11:51:26*

The first question should be ‘do I need one’, if you can’t answer that then no point applying

*Tags: General Technical*

---

**Jonjonjon** - *11:53:07*

Currently running 350-400 Flumine Strategy instances...

*Tags: Strategies*

---

**Sen** - *19:49:09*

For those who have built a big bankroll (not me by the way) - do people just leave the money in Betfair? I can imagine a big syndicate could have several million - would they leave it all in their betfair account?

*Tags: General Technical*

---

**mandelbot** - *19:54:46*

I'm nowhere near that but I just leave enough to cover my drawdown + some. Why should you leave money on there you don't use when you could buy bonds or shares etc intead? Not to mention risk a strategy going haywire and wiping you out

*Tags: Strategies*

---

## 2023-05-26

**Jonjonjon** - *07:53:25*

Still, I'd prefer to have more in my bank account than Betfair. I don't have the expertise to know if Betfair did it in a way that is safe.



E.g. I could back £1m @1,000. That would let me lay £1m@990.

There could be some sort of exchange error leading to the cancellation of the back.

I would owe more than my deposit

*Tags: Errors Debugging*

---

## 2023-05-28

**Sen** - *17:16:24*

Thank you all that's very helpful

*Tags: General Technical*

---

## 2023-06-02

**Newbie99** - *11:11:55*

Does anyone have any good suggestions for keeping 2 MySQL databases in sync (appreciate there's no 'right' answer to this, just curious how others do it), currently for example I call listclearedorders twice, once from each machine with the DB on every time I need to update. But replication seems like a better solution, so would like to go down that route, especially as I want to be smarter about adding other static data fields that it makes more sense to create once and then replicate.

*Tags: General Technical*

---

**Peter** - *14:18:09*

You're right that there are different approaches to database replication. The [https://dev.mysql.com/doc/refman/8.0/en/replication-solutions.html|MySQL documentation explains many of them](https://dev.mysql.com/doc/refman/8.0/en/replication-solutions.html|MySQL documentation explains many of them). But it's a pretty technical area and I wouldn't try to set it up and manage it yourself unless you're an experienced DBA (i which case why ask the question?).



The right solution absolutely depends on why you need a replicated database, so how others do it is pretty irrelevant. but since you asked, it's a standard feature of most cloud database services including AWS's RDS, which is how I do it, allowing me to focus on my trading apps and not get bogged down with irrelevant database issues.

*Tags: Feature Engineering, Deployment, Strategies*

---

**Peter** - *14:39:29*

Ah. For that I'd simply generate a backup with mysqldump from your primary database and then restore it to your laptop version. Stick this in a shell script (it's only two lines) and run it as needed on your laptop.



Though I would also consider whether you need to do this at all. Most of my analysis is done locally, but the data is loaded when needed from my remote primary database, often directly into Pandas using read_sql()

*Tags: Feature Engineering*

---

**Peter** - *14:45:46*

Sorry, meant to post [https://www.sqlshack.com/how-to-backup-and-restore-mysql-databases-using-the-mysqldump-command/|this link](https://www.sqlshack.com/how-to-backup-and-restore-mysql-databases-using-the-mysqldump-command/|this link) with my earlier answer.

*Tags: General Technical*

---

**liam** - *18:06:06*

Is it that slow? I use RDS on AWS all day

*Tags: Performance, Deployment*

---

**Newbie99** - *18:29:55*

The only reason I use a local DB is to save on costs as I was a bit worried they could spiral with AWS?

*Tags: Deployment*

---

## 2023-06-05

**foxwood** - *22:56:17*

That's all I've ever done - add a massive list of files to be processed as part of the strategy constructor

```market_filter={"markets": markets,

               "listener_kwargs": { ...```

If only called with one market then there would be a significant overhead of having to teardown / construct the strategy every time a file was to be processed. Or have I misunderstood the question or some subtle point ?

*Tags: Strategies*

---

**Jonjonjon** - *23:01:54*

At the moment I only do 1 market at a time, using the multiprocessing module to run lots in parallel.

I've noticed that my NVME (Samsung EVO 970 plus) is getting a bit hot, at 70C, and am asking the question to see if reorganising things can help to reduce the strain on the device.

This evening, I've tried running multiple backtests per worker, instead of creating a new worker per backtest. That has increased the speed of the backtests at the cost of increase my drive temp.

*Tags: Performance*

---

## 2023-06-06

**Jonjonjon** - *13:27:42*

I would have thought it would take longer too, as it will need to create new processes and restart Flumine etc... I would also expect it to use  less memory, which may or may not be a concern (I was too tight and only bought 32gb ram).

*Tags: Performance*

---

**PeterLe** - *20:46:58*

In-play only UK/Ire Horses

I just tried running a strategy on the Dogs, 28472 Markets, took 9:17 (So not easy to compare)



```STRATEGY_KWARGS = {'inplay': False, 'seconds_to_start': 660} ```

*Tags: Strategies*

---

**Jonjonjon** - *22:46:00*

Ah no worries. I managed to work it out.



Every time a new process is spawned, it uses up the same amount of RAM as the parent process. My parent process used up a lot of RAM as it had loaded a lot of data about the 38K markets. So to solve my problem I just had to delete the unnecessary data and call `gc.collect()`.

*Tags: General Technical*

---

## 2023-06-07

**PeterLe** - *13:14:05*

Quick Question please: ..Can I run Flumine in paper_trade on an account that is also using a separate application to place live bets without it messing up the paper_trade results? does it merely just subscribe to the stream ignoring all live bets? Thanks

*Tags: Deployment*

---

**liam** - *13:15:20*

Yeah no problem, it uses the simulation engine so doesn’t even subscribe to the order stream 

*Tags: General Technical*

---

**D C** - *14:51:16*

Its fine for what I currently have which just runs on win markets but going forward will need restructuring. More than 10 lines of code unfortunately. Tempting to bin C++ and commit to python but I am too far down the road now.

*Tags: General Technical*

---

**liam** - *14:57:20*

Its an overview and probably telling you stuff you already know but I liked it, good chapter on abstractions / classes etc that relate to this problem

*Tags: General Technical*

---

**foxwood** - *18:05:25*

Bite the bullet and refactor into a GPSdata class. One data instance per event in a base market class shared and inherited by the sub-markets. If you've got proper stuff going in C++ I'd stick with that rather than switch to Python and it's own brand of weird. Having said that I started auto-converting flumine to C++ initially but abandoned that due to having to implement the lower level foibles and libraries of Python. Considered it more important to start recording data / betting / losing money than worry about the language.

*Tags: Strategies*

---

## 2023-06-08

**Mo** - *12:09:30*

Not available unless you scrape it at the time. Regarding just runner/competition names, [https://github.com/mberk/betfairmappings](https://github.com/mberk/betfairmappings) can help

*Tags: General Technical*

---

## 2023-06-10

**Jonjonjon** - *16:53:23*

How do people manage their data/backtesting order?



My data is in zip files. 1 zip per day, containing one archive per market.



At present I use the multiprocessing module with a custom process pool which handles one market/archive per Flumine backtest run. I allow each worker process to run 8 backtests before it respawns.



I'm using a 3950x CPU (16c/32t) with Evo 970 plus nvme.



To prevent concurrent file access (which I am assuming will be slower than serial access), I use a multiprocessing.Lock to only allow one archive to be read at a time.



With this setup, my CPU usage tends to vary from 80-90%. So there should be scope to use it more. I am assuming that it is less than 100% due to the multiprocess lock.



However, after a few minutes, my NVME temp mazes out at 70c, which is at the higher end of its operating range. So I believe it's maxing out.



What do other people here do?

*Tags: Getting Started, Performance*

---

**Dave** - *17:56:07*

I unzip everything first, split my list of files into chunks of size x (for me x=4 is optimal), create a flumine instance for each chunk, and then pass the list of flumine strategies to y workers (y = n_cpus), collect all results at the end, merge, generate a report

*Tags: General Technical*

---

**Jonjonjon** - *20:00:02*

Thanks everyone for sharing. I use zip files as I read somewhere that having lots of small files can cause performance issues on the disk

*Tags: Performance*

---

**AndyL** - *20:53:30*

Silly question, but who actually manages the hardware that get put in the Saddles ?

*Tags: General Technical*

---

## 2023-06-11

**foxwood** - *09:56:09*

That's true for traditional disk drives where lots of small files are sprinkled around the drive at random. The needed head movement and rotational latency wastes significant amounts of time. With ssds' that problem goes away. The remaining issue is that of finding the true file address which means searching directory sectors. While ssd's still have to do that, the time taken and access speed to the directory sectors is very fast. I organize my files in folders by event type and date (eg "HR230611" for today's horses) which helps minimize the search time when the strategy is given a long list of files to work through for backtest.

*Tags: Performance, Strategies*

---

**Mo** - *10:22:34*

[@U01PJ5YMFBJ](@U01PJ5YMFBJ) if you want some insight into the practicalities of TPD on course activities, this is a fun read: [https://www.totalperformancedata.com/2022-5-31-a-day-in-the-life-of-a-tpd-operator/](https://www.totalperformancedata.com/2022-5-31-a-day-in-the-life-of-a-tpd-operator/)

*Tags: Performance*

---

**D C** - *11:10:57*

I think there is a lot of tech like this. I was working  for someone a couple of years ago that asked me to look at NFL tracker data - [http://nfl.com|nfl.com](http://nfl.com|nfl.com) have a live tracker page for certain games (at least they did). I also worked for a single day at Hawkeye many moons ago but that stuff is all camera based. People have been striving to do this stuff for years. I suppose the problem for many companies is the entry step  into the regulatory bodies around sports. The cynic in my tells me it has to be a great opportunity for sports governing bodies to generate themselves some healthy backhanders.

*Tags: Deployment*

---

**D C** - *11:32:09*

[https://www.amazon.co.uk/Betfair-Trading-Made-Simple-Ultimate/dp/1980887039/ref=sr_1_1?crid=3PIPU3F84WQ9X&amp;keywords=caan+berry+betfair&amp;qid=1686479509&amp;sprefix=caan+berry%2Caps%2C90&amp;sr=8-1|https://www.amazon.co.uk/Betfair-Trading-Made-Simple-Ultimate/dp/1980887039/ref=sr_1_[…]+betfair&amp;qid=1686479509&amp;sprefix=caan+berry%2Caps%2C90&amp;sr=8-1](https://www.amazon.co.uk/Betfair-Trading-Made-Simple-Ultimate/dp/1980887039/ref=sr_1_1?crid=3PIPU3F84WQ9X&amp;keywords=caan+berry+betfair&amp;qid=1686479509&amp;sprefix=caan+berry%2Caps%2C90&amp;sr=8-1|https://www.amazon.co.uk/Betfair-Trading-Made-Simple-Ultimate/dp/1980887039/ref=sr_1_[…]+betfair&amp;qid=1686479509&amp;sprefix=caan+berry%2Caps%2C90&amp;sr=8-1)

*Tags: Errors Debugging, Strategies*

---

**TT** - *12:11:38*

I'm guessing you need a reasonable turnover/commission for getting access to the betfair supplied gps feed?

Has anyone integrated the feed from TPD directly with flumine?

*Tags: General Technical*

---

**bb** - *15:28:44*

These are not very mathematical and a bit outdated now but help to see the basis to a few of the more “traditional” handicapping approaches:



• Mordin on Time: A more general view of early approaches to using race times/sectionals

• Anything by Andrew Beyer: similar to above but very USA focused

• Anything by Don Scott: Pretty old and hard to get a hold off but good at getting an early perspective into weight based handicapping/ratings 



*Tags: General Technical*

---

## 2023-06-14

**Aaron Smith** - *12:51:51*

this may be an odd and unnecessarry Q, but anyways: In flumine.BaseStrategy.process_market_book we get a Market and a MarketBook object, however a Market already contains the MarketBook under Market.market_book. Is there any reason we are still getting them both separately? Can the MarketBook i am given ever differ from what i get in Market.market_book?

*Tags: Strategies*

---

## 2023-06-15

**liam** - *08:47:26*

Are you using flumine?

*Tags: General Technical*

---

**liam** - *09:03:18*

Logging controls is the 'flumine' way, many modify [https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|this](https://github.com/betcode-org/flumine/blob/master/examples/controls/backtestloggingcontrol.py|this) example

*Tags: General Technical*

---

**Tom** - *09:06:22*

Legend, cheers. I have a shitty logging control instance I copied from a walkthrough somewhere once but didn't do much (anything) to improve it.



Are these to hold custom data so I can put in my strategy-code and pull those out of the cleared orders file?

```    "market_note",

    "trade_notes",

    "order_notes",```



*Tags: Strategies*

---

**Tom** - *09:08:04*

I had put some notes through with the orders, but wasn't sure if I had intefered with some mechanism of the Trade object or create_order function so deleted them - but can any/all of those be custom notes without interfering with how flumine works?



Sorry I have spent a lot of time at this but still have so much to learn

*Tags: General Technical*

---

## 2023-06-16

**Johnny** - *14:30:02*

Hi all.  I've been using bflw/betcode on my local machine and want to change machines now.  Are there any recommended Docker images that you guys use or is it better to create my own one for this?

*Tags: General Technical*

---

**liam** - *15:19:10*

this is mine



```FROM python:3.11.3



RUN apt-get -y update



# build flumine

ADD . /flumine-prod

WORKDIR /flumine-prod



# install py libraries

RUN pip install -r requirements.txt



CMD python main.py $ENV $INSTANCE```

*Tags: Getting Started*

---

**Jonjonjon** - *17:36:15*

Has anyone managed to use Kelly successfully to compound big returns, or are there caveats that would prevent it working on Betfair? At present I just use  level bet sizes.

*Tags: Strategies*

---

**liam** - *17:38:44*

Yeah market capacity kills Kelly, Kelly bet sizing (per odds) is powerful though 

*Tags: Strategies*

---

**R** - *18:02:49*

can confirm.  liquidity is really the issue when using kelly.  Assuming your model/pricing is not terrible.

*Tags: Strategies*

---

## 2023-06-18

**Laybot McBackbot** - *15:00:14*

Hmm.... Does anyone know if Betfair settled a football match from a small league incorrectly and nobody complained, it will automatically fix it later? This is the second time recently I found them settling bet wrongly and I had to contact them.

*Tags: Errors Debugging*

---

**Laybot McBackbot** - *15:01:03*

Happened to dogs in the past but quickly fixed.

*Tags: Errors Debugging*

---

**Peter** - *16:36:45*

How can we know? If a mis-settlement occurs and they fix it (I've see and reported them too), it could have been because they caught it, or their service provider notified them of an error in their feed, or a customer reported it so they double checked it - but we can't see which it was.



Given the volume of markets they manage, I personally doubt that they spend time re-visiting them after settlement in case they got it wrong, but for a definitive answer, you'd need to ask Betfair whether they have an internal process to do so.



I can though confirm that when I've reported them, they've been fixed very quickly.

*Tags: Errors Debugging*

---

**Peter** - *18:07:09*

That wide a variation in the time to fix, suggests that they are very willing to make corrections when they become aware of them, but that there's no systemic process in place to check post-settlement. Not a criticism - I wouldn't design one in either - all the focus should be on catching errors prior to settlement, with no we can always correct it later loophole.

*Tags: Errors Debugging*

---

## 2023-06-19

**Laybot McBackbot** - *16:15:01*

They eventually fixed it but not before I told them I am not a noob.

*Tags: Errors Debugging*

---

**Aaron Smith** - *16:28:04*

wasnt meant to be an excuse, rather my guess on what is more likely going on. Its obviously still pretty bad. Not sure how they could go about fixing that rather than having a better trained CS though. Personally i m sure i d go insane working at betfair CS, so i cant really blame them :smile:

*Tags: Errors Debugging*

---

**Dave** - *19:18:13*

Settlement issues are best resolved via social media support, they are far superior.

*Tags: General Technical*

---

**Laybot McBackbot** - *20:13:03*

[@U0128E7BEHW](@U0128E7BEHW): It was indeed through Twitter. I was pissed because she treated me like I was a retard but decided to look at her profile on LinkedIn before going full Karen as she might be new (and I am not that heartless!). Saw that she had only been working in the gambling industry for six months so I thought she was just new and not to get her into trouble so I moved on. Her colleague fixed that thing anyway.

*Tags: Errors Debugging*

---

**D C** - *21:34:18*

"treated me like I was a retard" - I think thats a very strong take. Sounded to me just like someone with incomplete knowledge trying to explain something that they don't understand and actually trying to be helpful (but failing).

*Tags: General Technical*

---

## 2023-06-21

**Jorge** - *08:31:40*

Makes sense, does it work in flumine as `strategy = BacktestBaseStrategy(market_filter={"markets": market_file_paths})` ?

*Tags: Strategies*

---

**Mo** - *08:35:14*

I don't use flumine but you need to patch `open` with `smart_open.open`: [https://betcode-org.github.io/flumine/performance/#file-location](https://betcode-org.github.io/flumine/performance/#file-location)

*Tags: Performance*

---

**Jonjonjon** - *10:49:17*

If removing "framework._market_middleware", what sort of performance benefits do people see?

*Tags: Performance*

---

**AndyL** - *21:36:50*

in fact given this month's performance, I think i'm an omeaba !

*Tags: Performance*

---

## 2023-06-23

**Andy** - *08:41:05*

From the example on the betfair help page of just applying deductions to ‘winnings’ I would work that out as $158 x 13.25 odds = $2093 potential winnings originally. Then apply 72.33% deduction = $586 profit. But I ended up getting $976 profit :thinking_face: :thinking_face: 

*Tags: General Technical*

---

**Jonjonjon** - *21:56:25*

I am using the multiprocessing library a lot for backtesting.

My Python environment is on my primary drive.

My data is on the secondary drive.

When I start up a new process, does that involve IO on from the primary drive where the Python environment is?

*Tags: General Technical*

---

**Mo** - *22:16:41*

I think you will find you were receiving 10 updates a second as usual but that the speed was constant for 1 second’s worth of updates. When I first started using the feed I observed the speed only updated once a second. This is because the speed was not being calculated from changes in location but comes directly from the GPS chip based on the Doppler Effect. 



I don’t pay close attention to the speed field so didn’t realise it had changed to a higher frequency which you seem to be implying it did. My first question is whether it is still coming direct from the chip or whether it is now being based on changes in location

*Tags: Performance*

---

**Jonjonjon** - *22:41:40*

I just tested it. Removing the Simulation middleware improves performance by about 25%.

*Tags: Performance*

---

## 2023-06-24

**James** - *07:24:44*

Multiprocessing doesn’t share memory by default though.  so you should use shared memory if you don’t want to repeat work for something you need in all processes.

[https://docs.python.org/3/library/multiprocessing.shared_memory.html](https://docs.python.org/3/library/multiprocessing.shared_memory.html)

*Tags: Performance*

---

**Jonjonjon** - *08:11:33*

No. Writing to an old spinning disk. I worked out that it was accessing the primary drive for the database:man-facepalming::skin-tone-6:

*Tags: General Technical*

---

## 2023-07-05

**Jonjonjon** - *21:21:49*

Does anyone have a version of this function that can be used on a Pandas Series?



```def get_nearest_price(price, cutoffs=CUTOFFS):

    if price &lt;= MIN_PRICE:

        return MIN_PRICE

    if price &gt; MAX_PRICE:

        return MAX_PRICE

    price = as_dec(price)

    for cutoff, step in cutoffs:

        if price &lt; cutoff:

            break

    step = as_dec(step)

    return float((price * step).quantize(2, ROUND_HALF_UP) / step)```

*Tags: Feature Engineering*

---

## 2023-07-06

**Jonjonjon** - *09:24:27*

Yes but it takes 38 seconds on my pc. I'm hoping to make it instant with some clever Pandas stuff.

*Tags: Feature Engineering*

---

## 2023-07-07

**casper** - *17:37:56*

[@UGV299K6H](@UGV299K6H) have you tried throwing this question into Chat GPT? This seems like the kind of question it will quickly solve for you. Or provide a better solution for what you are trying to achieve.

*Tags: General Technical*

---

## 2023-07-10

**Charaka A** - *18:07:30*

I was trying to visualise the live ladder using Flumine, anyone has suggestions on how to go about this. Initially thought of writing ladders to a queue and have a thread read from the queue and display the runner ladder however this doesn't work. Would appreciate thoughts on this if anyone has done this before

*Tags: Deployment*

---

**Jonjonjon** - *21:52:01*

Suppose I have backtested a strategy. I am only making 1 back bet per market.



I have a series of `n` P&amp;Ls.



What's the preferred way to generate a p-value via Monte Carlo?



• Randomly resample the `n` P&amp;Ls. Then sort them and look for the quantile where it crosses above zero.

• Estimate the fair odds (perhaps use the best back price at scheduled off). Then use the fair odds to and my matched prices to simulate several streams of returns. Then sort them and look for the quantile where it crosses above zero.

*Tags: Strategies*

---

## 2023-07-12

**Mo** - *04:52:54*

I realise your question is a bit tongue in cheek but:



1. Based on my experience of attending the conference last year, expenses will _probably_ be capped at £500 per person but please don’t hold me to that

2. There is the potential to present remotely which, again, is not guaranteed but I would be strongly advocating on your behalf to allow this 

*Tags: General Technical*

---

## 2023-07-15

**Alex** - *19:34:57*

My guess is: these events receive sponsorship money from (traditional) bookmakers. Bookmakers get adversely selected when people engage in courtside latency arb -&gt; bookmakers push to stop courtside betting.

*Tags: Performance, Strategies*

---

**jackofallspades** - *19:55:27*

Maybe paid "official" event data providers are behind it? I guess that there will be attempts of pitch-siding as long as affordable event data with minimum latency is not available.

*Tags: Performance*

---

## 2023-07-17

**PeterLe** - *09:39:40*

I enjoyed reading that too [@U01B8031PM1](@U01B8031PM1). Id strongly recommend "The man who solved the market" about Jim Simons. He's up there with Ed Thorpe in my opinion. What i enjoyed about this book is that even at the level Jim was involved at, with th resources he had at his disposal, he still had doubts on his automation strategies (as we all do at times). Super smart guy.

*Tags: General Technical*

---

**Mo** - *11:40:53*

I don’t remember being particularly impressed with The Man Who Solved the Market. I’m going to have to give it another read

*Tags: General Technical*

---

## 2023-07-20

**Jonjonjon** - *09:46:58*

Good point on transaction costs. But for UK shares, doesn't stamp duty make them prohibitively expensive too? I guess I will have to look at stuff where that isn't a problem too.

*Tags: General Technical*

---

## 2023-07-22

**Alex** - *06:08:27*

I trade quant equities in my day job. It is definetly possible to make money, but it is not a trivial problem. If you just want to play around a bit, you are likely better off with crypto. ETF's are tough, you are essentially trading indices, you'll end up with very low sharpe ratio's there. Better to trade futures right away. Depending on the kind of strategy you want to run you will end up with a low return on capital, so you rely on leverage to make it worthwhile.

*Tags: Strategies*

---

## 2023-07-23

**Alex** - *08:23:20*

Yeah, data is a lot easier to come by (and cheaper) in crypto. Binance is the one with the best liquidity, data is good, no orderbook data (you can apply for it though). It all depends on the kind of strategy that you want to run.

*Tags: Strategies*

---

## 2023-08-04

**D C** - *13:11:21*

Can anyone recommend a path-of-least-resitance method of installing python on macbook? I recently bought one purely for music production but I would quite like to do a little scripting with it too just to enable me to get a bit more use out of it. I know there will be a multitude of search engine results but I've more faith in a recommendation from here tbh.

*Tags: Getting Started, Deployment*

---

**Burrito** - *16:41:25*

What CPU utilization should a user expect on an AWS micro instance, running a strategy that does nothing, but which is subscribed to every horse racing market?

*Tags: Deployment, Strategies*

---

**Adam** - *17:54:45*

You could also try using Miniconda or some Anaconda variant ([https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html))



Some Python libraries are still problematic with Apple silicone and letting conda manage packages/installs for you can save a lot of time/headaches.

*Tags: Getting Started*

---

## 2023-08-05

**thambie1** - *11:18:13*

Just finished reading, vastly preferred it over 'The Man Who Solved the Market'. Had more of a narrative, given it was an autobiography. The Simons book often felt like a load of uninteresting facts to fill the space.

*Tags: General Technical*

---

## 2023-08-08

**Vlad Gavrilov** - *14:17:49*

I’ve played around with it, thought that a temporal fusion transformer model could be useful to predict how market movements play out.. but never got too far into it. The model structure seems appropriate and useful for this application. One day!

*Tags: Strategies*

---

## 2023-08-11

**liam** - *19:46:17*

Anyone tried this on flumine yet?



[https://github.com/sybrenjansen/mpire|https://github.com/sybrenjansen/mpire](https://github.com/sybrenjansen/mpire|https://github.com/sybrenjansen/mpire)

*Tags: General Technical*

---

## 2023-08-13

**D C** - *16:12:43*

I've been chatting here with some people and I'm considering starting to use flumine in order to get around some issues I am having with the HTTPS client component that I currently use in my own setup. I've a question about the use of thread pools really. At times I will need to place bets across many distinct strategies in a way that they are all fired within as little as 1 millisecond of eachother. This causes the component I use a few problems the result being that my requests are queued in an opaque manner and I suffer placement latency.



When using a thread pool I'm trying to find out what the lay of the land is. Alternatively, if I write my own thread pool trying to find a best practice implementation based around the betfair API:



1. Does each thread in the pool maintain a HTTPS connection to the server (in the keep-alive sense) at all times so that when called up it is ready to immediately transmit the request, or does it sit idle and go through the whole SSL handshake process every time?

2. Are threads created at the start of the program and persist until it terminates? I am guessing this is the case due to overheads in firing up new threads in an on-demand manner?

3. Within each thread, is a "global" session token shared across the entire application, or does each thread make a separate login and manage its own connection? If the latter, is that frowned upon by betfair (do they have a limit on the number of active sessions each user account can make)?

I am a bit of a dunce with how HTTPS works under the surface and I am trying to get some support for the components I am using but the CS reps are all but accusing me of trying to create something that causes a DOS on a target so I'm getting nowhere (other than getting pissed off with them). When mentioning that I might want to fire off several requests to a server within a single figure millisecond time interval I am being told that my use case is "very unusual" and they are proving to be very unhelpful.

*Tags: Getting Started, Performance, Deployment*

---

**Lee** - *16:29:44*

Seems a bit drastic migrating your whole project for a bug. Maybe ask here or bdp for help with that?

Have you tested to see if placing bets 1ms to 10ms apart really has the impact you think it does?

With regards to flumine, strategies are run sequentially for each update so depending on what your strategies are doing it’s unlikely you can loop through all them and execute in under 1ms.



In regards to your questions,

1. Maintains a session

2. They are created when needed and recreated of older than 200 seconds

3. Yes

Most of that logic is [https://github.com/betcode-org/flumine/blob/master/flumine/execution/baseexecution.py|here](https://github.com/betcode-org/flumine/blob/master/flumine/execution/baseexecution.py|here) 

*Tags: Errors Debugging*

---

**D C** - *16:39:00*

It appears that my component is limited to 6 max parallel connections to the server. Last year this cost me a lot of money as I was not using async bet placement. So lets say I had 15 strategies, each wanting to have bets placed (inplay). 6 would get sent straight away, but the remaning 9 would be queued until one of the 6 connections was free. Inplay horses that takes 1 second. My strategies could request more bets to be placed on any price update - so you see how quickly that could escalate. I've changed my stuff significantly since then but I still get the odd excessive lag if things line up in the right (wrong) way. It is a problem that would simply disappear completely with a thread pool I feel

*Tags: Deployment*

---

**Lee** - *16:41:50*

Yeah that doesn’t sound right, even with the 1 second delay never had a problem like that.

*Tags: General Technical*

---

**Lee** - *16:42:36*

What errors do you get?

*Tags: Errors Debugging*

---

**D C** - *16:43:02*

17 second bet placement latency was the worst I saw. Cost me in the region of 20k I estimated

*Tags: Performance*

---

**D C** - *16:45:11*

Any obviously that bottleneck and latency would just get worse and worse and also apply to cancellations. That is what battered me - leaving the fruit to be picked off.

*Tags: Performance*

---

**Lee** - *16:51:06*

if you try more than 6 parallel requests, what error do you get?

*Tags: Errors Debugging*

---

**D C** - *16:52:19*

There is no error. Just latency buildup. Writing further requests to this component just results in it queuing them until it can send

*Tags: Errors Debugging, Performance*

---

**D C** - *16:57:30*

I've modded significantly since last year - async placement flag, collating bets into fewer requests, no further (explicit) use of a strategy ref string etc.

*Tags: Strategies*

---

**D C** - *16:58:13*

But I am soon to roll out some new strategies, so this will again be an issue going forwrad. Hence the trying to get some help from the 3rd party support or writing out my own thread pools, or using flumine instead.

*Tags: General Technical*

---

## 2023-08-14

**Mo** - *07:27:43*

I really don't think this is an area where you want to be relying on a 3rd party that doesn't understand your use case. It does seem strange to me that there isn't more out there regarding low latency HTTPS connection pools but I guess it's too niche/people are too protective of their own implementations. I have my own in C, originally built on top of libcurl but now using my own custom HTTPS client. Whether you need to do that or not depends on whether you really need what that offers you over the flumine implementation which, from a first glance at the code [@UUCD6P13J](@UUCD6P13J) shared, looks solid. Not that I would expect anything else!



I highly recommend when pushing requests to a pool like this that there is a check immediately before bet placement between the time the request was generated and the time now and discarding anything greater than a tight threshold. That would have avoided your previous problems but no doubt would not have been possible if using a 3rd party component that you have no internal access to

*Tags: Performance*

---

**D C** - *09:31:55*

Yeah all good points Mo. That is the problem with something async but internally queues it without any means of letting you know. Piss poor but I suppose it works for most people's needs. I think I will start to move to flumine just to gather data which should allow me to get used to the code base. At same time I will give the suggestion of [@UHV5QTKDZ](@UHV5QTKDZ) a go because this actually doesn't look like too much work but also integrates with the rest of my code base.

*Tags: General Technical*

---

## 2023-08-17

**Mo** - *09:01:16*

The intention is the results will be equal up to floating point error

*Tags: Errors Debugging*

---

**Lee** - *14:41:11*

Just looked at the changes, its’s a very nice example how to use rust with python

*Tags: General Technical*

---

**foxwood** - *16:29:19*

Had to install rust from [https://rustup.rs/](https://rustup.rs/) which was new to me. Numbers matched exactly - several thousand calls - shin output used in other calcs - identical down to 14 decimal places ! It was using `_optimise_rust` when I stepped it but no idea of speed difference since just used the new one as was for an existing strategy that uses the current release - not time critical for me.

*Tags: Getting Started, Performance, Strategies*

---

## 2023-08-18

**Mo** - *09:50:20*

Sorry, documentation says 3 minutes: [https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Best+Practice#BestPractice-HTTPPersistentConnection](https://docs.developer.betfair.com/display/1smk3cen4v3lu3yomq5qye0ni/Best+Practice#BestPractice-HTTPPersistentConnection)



&gt; *Please note*: Idle keep-alive connection to the API endpoints are closed every 3 minutes.

Not sure if that is still accurate since the move to Cloudflare. [@UNW8Q88EL](@UNW8Q88EL)?

*Tags: Deployment*

---

## 2023-08-19

**river_shah** - *00:11:10*

Guys, what is the secret to this winning strategy?

*Tags: Strategies*

---

## 2023-08-21

**Unknown** - *13:24:57*

Did you know the Betfair API has documentation?

*Tags: General Technical*

---

## 2023-08-22

**Newbie99** - *13:02:52*

A bit of a random dumb question, but I was looking at [@U4H19D1D2](@U4H19D1D2)’s thread on ML and there’s one (really basic) piece that confuses me.



Let’s assume I have a basic ‘model’ that obviously uses flumine recorded data for backtesting (which also takes place in flumine).



Let’s pretend the ‘model’ simply tries to back any runner where say VWAP * x &gt; best available back price (where x = a percentage set by me currently).



How can I ‘train’ my model, as the code is written for streaming data?



Do I have to re-write everything to look at a large Pandas/PySpark data frame with all the raw data?



I’m presuming not and I’m misunderstanding how it works, but it does confuse me as the examples I’ve seen all seem to take numpy arrays as inputs or Pandas data frames!

*Tags: Feature Engineering, Strategies*

---

**liam** - *13:10:00*

Not a stupid question, easiest way is to create a flumine strategy which writes all the data to a csv (variables + W/L of runner etc) -&gt; load into pandas



[https://github.com/betcode-org/flumine/blob/master/examples/strategies/pricerecorder.py](https://github.com/betcode-org/flumine/blob/master/examples/strategies/pricerecorder.py)

*Tags: Feature Engineering, Strategies*

---

**liam** - *14:51:07*

Yep, flumine is for live/simulation but when it comes to modelling/backtesting you want to get things into pandas

*Tags: Feature Engineering, Deployment, Strategies*

---

**Newbie99** - *14:58:55*

Cool thanks, that is very helpful, will be interesting to explore!

*Tags: General Technical*

---

**PeterLe** - *15:01:49*

In a similar post to the above, I was recently inspired by Joe at the meet up who talked a little about ML.

Im only just getting to grips with Python but thought Id have a stroll down the ML path to see what I could find. if you dont look you dont find :grinning:

These are the steps Ive taken so far but would welcome any thoughts as to my approach and whether Im going off course...(remember this is all new to me)

Steps :

Capture recorded data with Flumine.

Then use the PriceRecorder to extract certain features to a CSV (for about a month of racing UK /IRE)

Using this ;-



`import pandas as pd`

`import numpy as np`

`from sklearn.model_selection import train_test_split`

`from sklearn.ensemble import RandomForestClassifier`

`from sklearn.metrics import accuracy_score`



Then Loaded the data into a df...

Clean the data to remove NaN

Train a random forest classifier making predictions.

(I also wanted to plot  the partial dependence but having problems with the code for now...)



Then setup some features Im interested in ...(winner as a target)



`features = ['last_price_traded', 'back', 'lay', 'back_book', 'lay_book', 'ltp_book', 'Spread', 'cross_matching']`

`X = df[features].copy()`

`X['cross_matching'] = X['cross_matching'].astype(int)`

`X = X.fillna(X.median())`

`y = df['winner']`

`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`



`back_book_values = np.arange(1.19, 1.21, 0.01) # Just used a ouple here as a test..`



1.Then setup a simple system...

2.Then setup a system using an ML strategy...



...and determine the 'Feature importance' like so:

`feature_importance = random_forest_model.feature_importances_`

`feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})`

`feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)`

`print(feature_importance_df)`



After running for a while I got the output like so:



# Random Forest Accuracy: 0.9120607771513096

# Total Profit/Loss using Simple strategy: £-193834.88816246387

# Total Profit/Loss using ML strategy for X 1.19: £17935.374273080262

# Random Forest Accuracy: 0.9120607771513096

# Total Profit/Loss using Simple strategy: £-193834.88816246387

# Total Profit/Loss using ML strategy for X 1.2: £17327.057237254136

# Random Forest Accuracy: 0.9120607771513096

# Total Profit/Loss using Simple strategy: £-193834.88816246387

# Total Profit/Loss using ML strategy for X 1.21: £16570.917359458937

# Best back_book value: 1.19, Profit: £17935.374273080262

#    Feature  Importance

# 3  back_book    0.209721

# 4   lay_book    0.203197

# 5   ltp_book    0.197272

# 2   lay    0.126964

# 0   last_price_traded    0.111824

# 1     back    0.082254

# 6     Spread    0.065538

# 7     cross_matching    0.003230



I can see that the ML strategy beats the simple strategy...and the back_book is the feature with the most importance...



So my question is: How do you uncover what makes the ML model significantly better?

Is it by looking at (and trying to understand the individual decision trees (a subset off)

Other things that seem relevant are a Partial Dependence Plot or form of Correlation Analysis?

What would the pro's suggest as a next step from the feature importance? Thanks in advance

*Tags: Getting Started, Feature Engineering, Strategies*

---

**Rishab** - *18:05:04*

You can look at Adjusted R sq. to find out if adding another feature actually improves the model performance or not

*Tags: Feature Engineering, Performance, Strategies*

---

**PeterLe** - *19:14:03*

Thanks [@U02RN7YDRQ9](@U02RN7YDRQ9) yes I intend to split out certain things and test. Although I do know that the ltp book and lay book do have a bearing on results as Im running this  as a live strat

I agree, the differences between the two strat does look suspicious. The results were taken from one of the first tests I ran, as I progressed it looked more like this :



```# Total Profit/Loss using ML strategy: £9322.959999999966

# Total Profit/Loss using simple strategy: £2207.2800000000384```

It was interesting (and though provoking for me) to think that ML could turn a large losing strat into a positive? :thinking_face:

The data was split into two sets (80% training, 20% testing). there is no separate validation set in the code. Thanks for this, Ill edit to include this.

Train : 60%

Test: 20%

Validation ; 20%

(Would that look about right?)

Re PM: There is a slice of secret sauce in here :grinning:, come to he next meet up if you can, worth th trip :grinning:

[@U05KECSV68N](@U05KECSV68N) Thanks for the reply. Ive just read up on that...AmI correct in thinking that R-squared is more suited to regression models (Whereas the bit that gave me the most insight in the code was a RandomForset Classifier and that it may not be a great fit for that?)

By the way, Im not just going to use the regression and Random Forest, Im going to look at other methods too, its just as a learning exercise if nothing else.

My main questoin was, once you had an ML Model how do you then interpret whats happening in he background so you can incorporate those things into a live environment?

(This is all in play by the way)

*Tags: Deployment, Strategies*

---

**PeterLe** - *19:23:40*

Sorry forgot....I also thought that this would lend itself well to including TPD data too..

I do have the feed in the betfair API and I record it using a C# program

I dont have Flumine recording it (I dont know who to do this just yet)

I might test TPD inisolation in the future? :+1:

*Tags: General Technical*

---

**Rishab** - *19:42:10*

So R2sq is a strictly increasing function wrt no. of features. So if u just keep on increasing features ur R2 will increase but ML models suffer from something known as curse of dimensionality. So Adjusted R2 takes this into consideration &amp; tells you the ideal point where the variance is balanced wrt to no. of features. To answer your second question ML models are generally complex in nature,  just with 4-5 features you can interpret a RF using the tree but can't do the same for a large number of features. I think in general you can't find exactly what the model is doing(i.e there are more complex model that combines various trees to make stronger models), but you can get a good feel for it by understanding the general working of the model, then using tools like feature imp., R2, confusion matrix etc

*Tags: Feature Engineering, Strategies*

---

**PeterLe** - *19:53:01*

OK Rishab I understand that now. This maybe useful to prevent adding many features that does little to improve the results. The first thing I noticed when starting off down this road was how much longer it takes when you are adding more and more.

I need to read more about them tools as they are new to me.



Just a general question to you or anyone. have you found ML useful in in-play markets? I can see how this would work in pre off markets but lesser so inplay? Thakns

*Tags: Getting Started, Feature Engineering*

---

**AndyL** - *20:08:56*

[@UQL0QDEKA](@UQL0QDEKA) So about a random forest classifier, am I right in thinking the key to that is the "decision trees" ? ie.you've created some secret sauce decision tree alogorithm, whose parameters you've trained to get a better prediction?

or in other words, you have a set of decision trees like say:

     DecisionTree1: Win%1 = a*Feature1 + b*Feature2 + c*Feature3

     DecisionTree2: Win%2 = d*Feature4 + e*Feature5 + f*Feature6

Prediction = MajorityVote(Win%1, Win%2)

and running the dataset through Pandas...refines to give you a,b,c,d,e,f parameters for your best optimized "sauce"?

*Tags: Feature Engineering*

---

**PeterLe** - *20:47:07*

[@U4H19D1D2](@U4H19D1D2) Ive just found it an interesting topic. The standout for me is that there is no right or wrong way of doing it. Is all subjective. I thnk it helps if you have a good understanding of the markets to start with.

*Tags: General Technical*

---

**PeterLe** - *21:08:42*

[@U01PJ5YMFBJ](@U01PJ5YMFBJ) I started out by learning how to create the CSV  (using the price recorder) into Pandas DF's etc. (I know you are much more accomplished than me in terms of programming by the way)

The added in a couple more columns to include winner, P/L Sum of the books etc

I then started with something simple like regression

And then a random forest (ive only got the estimators set low for the time being)

I have two strats one a simple one and one an ML. They both use the same parameters eg, if the simple strat has a condition tha says back &lt; 10 then so does the ML.

to answer your question - Kind of :grinning: (remember we all do things differently and I know next to nothing about this) You need to have a 'Target'.  In my case I chose the target as 'winner' (from that you can determine whether you bet won or lost) Set up a value in the P/L column in your CSV based on say £1. if you dont have the CSV data (Which is every update) you need to get that up and running first (Lee helped me get this running, but is simple enough). use the price recorder against your recorded data (One month is plenty)

ChatGPT is great for this sort of thing it bootstraps your learning,

For your simple model just create something simple like lay the fav (in running) when X occurs. The ML will work it out for itself. The problem I had is understanding what the ML did so that I could employ that in my live stuff. Ive got some new stuff to look at now thanks to the earlier posts.

*Tags: Feature Engineering, Deployment, Strategies*

---

**AndyL** - *21:55:52*

Thanks [@UQL0QDEKA](@UQL0QDEKA) so yeah the programming i'm good with, my head is just missing some part of the "workflow" here, I think i'm nearly there with your help above.

So in my huge data.csv, i've got something like:

```market_id, selection_id, secToStart, lay_price, winner, P/L

1.1111,    1023,         -12.1,      1.08,      False,  £1

1.1111,    1023,         -12.2,      1.06,      False,  £1

1.1111,    1023,         -12.3,      2.46,      False,  £1

...```

The "classifier" is basically going to tell me "when to place the bet" ?

So I don't see how from above the ML is going to work out when to place a bet?

Don't you need a running cumulative P/L ?

The end goal is when I run this "model" over a dataset, it achieves the best net Profit having made a decision of "when to place a bet" over all the markets.

My head is still missing what it's trying to tell me!

I'm going to ask ChatGPT again!

*Tags: Strategies*

---

**AndyL** - *22:30:18*

Doh, penny dropped finally!

So a Random Forest Classifier, is for "classifying" groups as best as possible,  so you need to have a strategy to start with say "X", which says makes £1000, and you can then train a RFC to optimize the "X" entry points for "profit". So once you have trained your RFC, when using "live", rather than doing "X", you simply ask "RFC" will the entry here be profitable? Yes or No ? .... and with a bit of luck you may end up with £2000 !

Right, so I just need to find a decent "X"......!

*Tags: Deployment, Strategies*

---

## 2023-08-23

**PeterLe** - *09:35:27*

For X, Think of something that makes sense/logical (or gut feel). then branch out and see where it takes you

By the way, I recorded he following in my CSV:





```def process_market_book(self, market, market_book):

    with open(self.file_directory, "a") as f:

        writer = csv.DictWriter(f, fieldnames=HEADERS)

        for runner in market_book.runners:

            writer.writerow(

                {

                    "market_id": market_book.market_id,

                    "publish_time": market_book.publish_time,

                    "status": market_book.status,

                    "inplay": market_book.inplay,

                    "selection_id": runner.selection_id,

                    "last_price_traded": runner.last_price_traded,

                    "back": get_price(runner.ex.available_to_back, 0),

                    "lay": get_price(runner.ex.available_to_lay, 0),

                    "sp": runner.sp.actual_sp,

                    "cross_matching": market_book.cross_matching,

                    "runner_matched": runner.total_matched,

                    "venue": market.venue,



                }

            )```

and I included SP and Runner Matched in the features of the ML. For my  Inplay strat it rated SP and Runner Matched of high importance using ML, which is what you would expect. This gave me some confidence that the model was working as intended.

PS looking at the CSV header you posted I think you need to add more stuff in there as a minimum back book, lay book, Back,lay and LTP etc

*Tags: Feature Engineering, Strategies*

---

**D C** - *09:57:07*

Thinking of using flumine to backtest but I am pretty sure my data exists in a format slightly different to that recorded by bflw and/or betfair pro data. Basically can someone tell me how I need to modify it or provide a couple of lines example code from a flumine/bflw recorded market log?



My data is recorded as a | delimited string on a per market basis as follows:



message receive timestamp | pt extracted from main message | JSON string of market change message extracted from the list in the main message



Basically I parse a message, Identify market for each individual msm contained in the mc list and write that mc to the log file for the market in question. Also scattered in the file are calls to response of listMarketCatalogue that I will call whenever a suspension is detected (easily identified and removed).



In short, how much alteration is required to get into a flumine compatible format?

*Tags: General Technical*

---

**PeterLe** - *10:11:57*

Morning Joe. This was really my first attempt at looking at ML. Probably best described as a random walk.:grinning:

My initial thoughts were, how to use ML to enhance, refine existing starts and secondly; use ML to look at the recorded data I had and run it against that to see what it found. (no preconceived ideas etc)

Having read up a little, I thought that feature importance may be a good place to start.

I did learn something from the feature importance (Which is not shown above). It is something that I haven't used in my in play stuff but now that ML has made it aware to me, it makes perfect sense and Im testing that in a live environment (1 day in).

As input Joe, maybe you could tell me the basic building blocks how you might go about this (just bullet points will do please)

ie :

• Record Live update data from the API (Doing that)

• use the price recorded to capture various variables (eg back, lay, ltp, books etc ) to a large CSV (Doing that)

What generic steps would you take from this point?

Thanks Joe

(PS I need to go offline for a few hours Joe, work calls - Thanks)

*Tags: Feature Engineering, Deployment*

---

**Joe** - *11:02:35*

These are two quite different tasks, 1) optimise strategy parameterisation using ML and 2) generating new strategies using ML, I'm not going to discuss 2 as it is vast topic and I've used many different approaches from simple recurrent networks to genetic programming.



Task 1 however is easier to describe. You have a set of (many 1000s of) markets with supporting data, M. You have a strategy S (m, p) that takes a single market's data m and p parameters and returns a profit. S is just conditional logic and state (e.g. its current position), p are the parameters of that logic (e.g. the 'x' in if (price &lt; x) ). Your goal is to find p that maximises something you want, we'll use profit here but in reality you'll want to fiddle with this. The complexity is you (usually) cannot label up all the data in M with a dependent variable "should_i_bet", if you can then easy - simple classification problem solvable through any supervised ML procedure, however in almost all cases you cannot since the answer to "should_i_bet" is infact what we are searching for.



A way around this is currying the above into a new function F (p) = C(S, M) which returns the total profit when S is run over the full set of markets M with params p.



We can now use brute force, or preferably some guided brute force (unsupervised ML) to find p that maximises profit.



We do the usual train / test split on the data, and start searching for p with an appropriate search algorithm, I would suggest particle swarm optimisation as a simple starting point. I don't use python but there will definitely be implementations of PSO available.



So we effectively execute

``` MTrain, MTest = split(M)

 FTrain = C(S, MTrain)

 FTest = C(S, MTest)

 p = PSO.search(Ftrain, Ftest) ```

So that is one way to do it, there are many others but which is right depends completely on how you phrase/frame the problem you are trying to solve. The obvious drawbacks of this approach are 1) you need a strategy to optimise, 2) there are many tricks that are needed to avoid overfitting / curse of dimensionality, 3) you need to quite a lot of hardware, code and data optimisation to get the execution frequency required for this type of ML.



One implication of rephrasing an existing strategy for this type of search is you may find other applications of it. Imagine the profit surface wrt p looks like the Alps. You have manually tweaked p over the years and are squarely centered on Mont Blanc. With a bit of ML guided search with some diversity forced into the mix, you maybe able to find p for other profit peaks such as the Matterhorn or Finsteraarhorn. What you have now achieved is not an ensemble but a set of independent profitable strategies.

*Tags: Strategies*

---

**PeterLe** - *15:53:18*

[@U030GKBMCBF](@U030GKBMCBF) Just some feedback...

I asked chatgpt to comment on your suggestion in the context of my code...this is what is said ;



_The advice your colleague provided is quite accurate. Default feature importances from Random Forest models in scikit-learn can indeed be biased, particularly when the dataset includes different types of features (e.g., categorical and numerical). This bias might lead to incorrect conclusions about the importance of the features._

_In your code, you were using the default feature importance method by calling the `feature_importances_` attribute from the Random Forest model. This approach calculates feature importance based on the average depth at which each feature appears in the trees of the forest. While it is a common approach, it can be misleading._

_A more reliable way to assess feature importance is to use permutation importance. Permutation importance works by randomly shuffling the values of a single feature and measuring the resulting decrease in the model's performance. This decrease reflects the importance of that feature._



(provided some suggestions for code)



_This method will give you a more unbiased estimate of feature importance, taking into account the potential correlation between features and the different scales and types of features._

_Remember to remove or comment out the old code that calculated feature importance using `feature_importances_`._

_So, to answer your question, considering permutation importance would be an excellent improvement to your code, and it aligns with best practices in machine learning._



So spot on, thanks again :+1:

*Tags: Feature Engineering, Performance, Strategies*

---

**PeterLe** - *17:32:16*

Yep he plus version Foxwood

Ive just recoded to include the comments by Leo, results are:

Random Forest Accuracy: 0.9062742305480078

Total Profit/Loss using Simple strategy: £26007.66999999987

Total Profit/Loss using ML strategy for X 1.19: £22294.659999999945

             Feature  Importance

0  last_price_traded    0.116026

1               back    0.093928

2                lay    0.107229

3          back_book    0.206596

4           lay_book    0.203972

5           ltp_book    0.193442

6             Spread    0.075818

7     cross_matching    0.002990

(note: I found an error in my simple strategy :grinning: that why it was such a massive negative in previous text)

What is interesting now is that the ML seems to give a worse result :thinking_face:

*Tags: Errors Debugging, Feature Engineering, Strategies*

---

## 2023-08-24

**Unknown** - *13:41:58*

So this is the plot [@U4H19D1D2](@U4H19D1D2) in conjunction with this info...

Validation Accuracy: 0.8703854015340546

Test Accuracy: 0.8699371399724771

Total Profit/Loss using Simple strategy: £26015.709999999857

Total Profit/Loss using ML strategy for X : £25605.64000000001

The interesting thing is when this was printed out initially, it looked like the ML model wasnt as good as the simple strat.

That's not the case though as you will see the ML beat the simple strat for the same number of bets.

I found that the partial dependence plot interesting two when I chose two random features.

I can see from that, that I'm in the right ball park area, with a bit of tweaking

My initial thoughts now are to maybe create another CSV for a different month of data to see if the feature importance is similar for both months.

Then I will delve down a bit deeper into the feature importance and partial dependence.

Then Ill explore something ML related...

NB: Early on in this, I found something that I hadn't really considered for inplay before&lt; i left it out for this discussion (for obvious reasons) but keen to look deeper.

Anyway with that; Ill stop boring you all with this. I feel confident to take this further in the background and explore

if nothing else I've enjoyed my first venture into ML (even though the wife called me a 'geek' when I excitedly shown her how the 3D plot could pivot :joy:)

Just wanted to thank those who contributed in this thread and DM's cheers

*Tags: Feature Engineering, Strategies*

---

## 2023-08-25

**Mo** - *13:12:45*

One of the entrants to the Women's World Cup prediction competition I was helping to organise has released his contribution, a novel method for removing the overround from odds: [https://github.com/gotoConversion/goto_conversion](https://github.com/gotoConversion/goto_conversion)



Looks intriguing but unfortunately my method of scoring predictions on my data set doesn't agree with his results (my conclusion is Shin is still better)

*Tags: General Technical*

---

**D C** - *14:22:52*

I find these methods interesting, but whenever I start digging into it I am always left confused about how you interpret things. For example, in Mo's linked competition entry, the entrant seems to take Brier score as their choice of metric for determining that their method is "better" than Shin, power etc.



I've seen lots of people talk about Brier but how is this affected by multiple "measurements" of an event? For example, is a Brier score still "valid" if it is calculated for all price changes on an event from opening show to closing price? I can see that it might be so in the case of monotonically increasing/decreasing odds but we all know that is never satisfied.  Similarly, can you use a Brier score for an in-play model where we have essentially a time series of updated probabilities?

If not, what other metrics are available for assessing your modelled probabilties in cases where we have longitudinal probabilties per event/participant pairing?



I'm very low tech in this regard and I basically use profit as the metric/justification that my price estimates are "good" (however you interpret that).

*Tags: Strategies*

---

**D C** - *14:29:53*

Yes I can see the sense in that. It again leads to numerous questions. For foorball, the game is 90 minutes (give or take injury time). But how about a tennis match of indeterminate duration? Similarly, how about uniformity of model performance with respect to time? I guess I am not expecting any answers, but every time I try to analyse things in a statistically sound manner I am always just left scratching my head when it comes to inplay.



As you say Mo, one prediction per event makes everything more simple but in truth I don't know where to start when it comes to open ended IP stuff.

*Tags: Performance, Strategies*

---

**Mo** - *14:44:31*

I think this is simply an open problem and one which doesn't seem to get much attention in academia



My intuition is that if you subsample to some reasonably small number of predictions per event then everything about state dependence (scoreline, time remaining, etc. etc.) comes out in the wash (provided you have a large enough sample of events)

*Tags: General Technical*

---

**Mo** - *14:46:43*

Obviously a great way to score predictions is to backtest but that has its own set of problems (e.g. computational cost, double counting liquidity etc. etc.)

*Tags: General Technical*

---

**D C** - *14:59:46*

Maybe it should be added to Hilbert's list. Everything you say does seem sensible Mo, but there always seem to be more questions - like how do you adjust for volumes and number of bets placed? When model disagrees with market, you bet more, and in a longer event (4 mile chase versus 5 furlong sprint) you have more time to disagree. I do tend to analyse things by stratifying slightly by event type but still no idea if this is valid or not.



I can see why the likes of Buchdahl only focus on pre-off markets and relies on pinnacle closing lines to reach his conclusions.



I should probably stop thinking about it - it only serves to exacerbate my imposter syndrome.

*Tags: Strategies*

---

## 2023-08-28

**PeterLe** - *11:31:28*

Morning All,

I asked ChatGPT this question :

_I have a C# program that I run on a local PC._

_Id like to run it on a virtual server (AWS)_

_What's the easiest way to package the program and all its dependencies into a single bundle that I can easily deploy on a virtual server_

_Can you make suggestions_



it replied as follows :



Certainly! Packaging a C# program along with its dependencies for deployment on a virtual server can be accomplished in a variety of ways. Here are some common methods:

1. Publish as Self-Contained Deployment

A self-contained deployment (SCD) includes everything needed to run your application: the .NET runtime, .NET libraries, and your application and its dependencies. This method is advantageous because it isolates your application from any .NET changes on the system.

Steps:

1. Open your project in Visual Studio or use the command line.

2. Publish your project as a self-contained deployment.

Using Visual Studio:

• Right-click the project -&gt; Publish -&gt; Choose "Folder" -&gt; Set Deployment Mode to "Self-contained" -&gt; Publish

Using Command Line:

```bash



dotnet publish -c Release -r &lt;RUNTIME_IDENTIFIER&gt; --self-contained true ```

Replace `&lt;RUNTIME_IDENTIFIER&gt;` with the runtime identifier for your target system, like `win-x64` for a 64-bit Windows OS.

2. Publish as Single File

.NET 5 and .NET Core 3.1 introduced the option to package your application as a single file.

Steps:

1. Open your project in Visual Studio or use the command line.

2. Publish your project as a single file.

Using Visual Studio:

• Right-click the project -&gt; Publish -&gt; Choose "Folder" -&gt; Enable "Produce Single File" -&gt; Publish

Using Command Line:

```bash



dotnet publish -c Release -r &lt;RUNTIME_IDENTIFIER&gt; /p:PublishSingleFile=true ```

3. Use Docker

If your virtual server supports Docker, this could be another straightforward option. You can package your application as a Docker container, which would include everything needed to run it.

Dockerfile example:

```Dockerfile



# Use the official image as a parent image FROM [http://mcr.microsoft.com/dotnet/aspnet:5.0|mcr.microsoft.com/dotnet/aspnet:5.0](http://mcr.microsoft.com/dotnet/aspnet:5.0|mcr.microsoft.com/dotnet/aspnet:5.0) AS base WORKDIR /app EXPOSE 80 # Use SDK image to build the app FROM [http://mcr.microsoft.com/dotnet/sdk:5.0|mcr.microsoft.com/dotnet/sdk:5.0](http://mcr.microsoft.com/dotnet/sdk:5.0|mcr.microsoft.com/dotnet/sdk:5.0) AS build WORKDIR /src COPY ["YourApp/YourApp.csproj", "YourApp/"] RUN dotnet restore "YourApp/YourApp.csproj" COPY . . WORKDIR "/src/YourApp" RUN dotnet build "YourApp.csproj" -c Release -o /app/build FROM build AS publish RUN dotnet publish "YourApp.csproj" -c Release -o /app/publish FROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT ["dotnet", "YourApp.dll"] ```

Then you can build and run the Docker image.

```bash



docker build -t your-app . docker run -p 80:80 your-app```

To those of you who live and breath this stuff; which method would you recommend? I'll work it out myself if someone can give me a steer please. Thanks

*Tags: Deployment*

---

**PeterLe** - *11:46:02*

Thanks DC

This is the answer I git back on that suggestoin ;



Your colleague's suggestion of static compilation is more commonly associated with languages like C and C++, where the idea is to include all libraries directly in the executable. This results in a larger file size but removes dependencies on shared libraries.

In the C# and .NET ecosystem, the concept doesn't translate directly because .NET applications typically rely on a separate runtime to execute. However, the self-contained deployment option is somewhat similar. In a self-contained deployment, the .NET runtime and all dependencies are bundled with the application. This makes the application larger but ensures it can run on any system without requiring a separate runtime or dependencies.

Pros and Cons of Self-Contained Deployment

Pros:

• No need to worry about runtime dependencies or versions on the target system.

• Simplified deployment as everything needed to run the application is bundled together.

Cons:

• Larger file size, as your colleague pointed out.

• Updating dependencies or the runtime means redistributing the entire application.

While C# doesn't offer static compilation in the same way that C/C++ does, self-contained deployments achieve a similar objective of packaging an application and its dependencies into a single bundle. It's a good option when you want to isolate your application from system-wide changes or when you're not sure whether the target system has the necessary runtime and dependencies.

In summary, if you're looking for an approach in the C#/.NET world that's akin to static compilation in C/C++, self-contained deployments are your closest option.



maybe Docker?

*Tags: Deployment*

---

**Andrew** - *11:54:40*

Before moving to Flumine I was using C#. Click-Once deployment works, or even use XCOPY or RSync over SSH to your host. .NET doesn’t need installing. Copying package files works fine.

*Tags: Getting Started, Deployment*

---

## 2023-09-02

**AndyL** - *17:09:43*

I must admit i'm rather old school (matching my age!), and like to run python strategies and stuff directly from the command line. But i'm trying to get to grips with Juypter, and struggling!, firstly to get it to work on Mac M1, due to this bug : [https://github.com/jupyter/notebook/issues/6974](https://github.com/jupyter/notebook/issues/6974)

Eventually got past that with their workaround... downgrading...

Then i'm trying to do a noddy plotly example:

```import plotly.express as px

fig = px.bar(x=["a", "b", "c"], y=[1, 3, 2])

fig.show()```

Now it displayed once!

But now doesn't any more....

Looking at the Jupyter console, I see:

```[W 17:03:38.386 NotebookApp] 404 GET /static/plotly.js (::1) 0.830000ms referer=[http://localhost:8888/notebooks/workspace/Test1.ipynb](http://localhost:8888/notebooks/workspace/Test1.ipynb)```

As though it's cached it, but now can't find it...?

I'm all for these IDEs to help you, but as ever you have to use them has they expected...?

*Tags: Errors Debugging*

---

## 2023-09-04

**foxwood** - *10:30:45*

Trivial change for me - my usage is in a commonly used utility function so just one liner across everything. I do doctor the output probs to scale up to a minimum probability of 0.001 to keep things in line with maximum BF odds which is one of the reasons it's buried in a function. My odds are already in a known selection order in the list argument so as long as they come back in the same order (!) the mapping is known. Tried several methods for removing the margin from the book and shin "feels" about right.



Edit: Shows how un-python I am compared to your stuff - I take 2 lines to do it

`shinDict = shin.calculate_implied_probabilities(odds)`

`probs = shinDict.get(*"implied_probabilities"*)`

*Tags: General Technical*

---

## 2023-09-05

**Unknown** - *10:06:18*

Big day for [https://www.pepy.tech/projects/betfairlightweight|betfairlightweight](https://www.pepy.tech/projects/betfairlightweight|betfairlightweight)

*Tags: General Technical*

---

**ShaunW** - *21:51:15*

Perfect choice of lolly. Congrats Liam a million is something special.  I'm not sure about the £1 per download [@UQL0QDEKA](@UQL0QDEKA), if they all had a £1 bet sometimes it would help:grin: .

*Tags: General Technical*

---

## 2023-09-06

**Justice** - *19:20:05*

If anyone uses C#, I am writing an easy to use client similar to betfairlightweight. It is still a work in progress and I am looking to collaborate with other developers and improve my skills. So please criticize/provide feedback and open issues/pull requests. See the repo here: [https://github.com/BrandonWoodward/BetfairDotNet](https://github.com/BrandonWoodward/BetfairDotNet)

*Tags: General Technical*

---

**MacrcoPolo** - *22:57:53*

Anyone using TPD can you PM me please if you're happy to answer some questions

*Tags: General Technical*

---

## 2023-09-09

**thambie1** - *21:58:59*

[https://www.washingtonpost.com/world/interactive/2023/tennis-match-fixing-gambling-investigation-belgium/](https://www.washingtonpost.com/world/interactive/2023/tennis-match-fixing-gambling-investigation-belgium/)

*Tags: Errors Debugging*

---

## 2023-09-10

**D C** - *14:31:50*

I've managed to wrap my brain up in knots thinking about cross matching and traded volumes and am in need of a sanity check. In a simple example of a 2 selection event, this is how I see things working (please correct if nonsense). We start on an empty order book, I offer to back selection A at 80.0 for £1. This results in a virtual £79 @ 1.01 available to back on selection B and a real £1 available to lay at 80.0 on selection A. Someone decides to take the worse value on offer and backs selection B at 1.01 for £79. Disregarding commission, if A wins, I win £79 and they lose £79. If B wins, I lose £1 and they win 79p and Betfair pocket the extra 21p.



My first question is, how does this matching of orders end up represented to us in terms of traded volume amounts? The 1.01 is virtual, the 80.0 is real. Do we see a traded volume of £1 at 80 on A and £80 at 1.01 on B (despite the 1.01 not being a "real" order) ?



Secondly, if the above were repeated in a mature market, such that there was already money available to back selection B at 2.0 and I place the same back on A at 80.0 (way above current best available displayed price) does the cross matching still happen (i.e. would extra volume appear as a virtual 1.01 back price on B) or would it be ignored because a much better price is available already. I suppose I am asking does XM just get implemented when the ladder is thin to try and reduce the spread, or does it happen for ALL orders submitted to the market.

*Tags: General Technical*

---

**Mo** - *14:35:38*

To answer your last question - all orders 

*Tags: General Technical*

---

**Joe** - *15:59:10*

I think it's configured to 50Hz, so 20ms, this a tradeoff between per order latency and batch sizing for efficient block (storage) persistence and packet utilization. It can certainly vary based on load, network events, storage events, etc. Betfair can also change it whenever they want to.

*Tags: Performance*

---

## 2023-09-11

**Jonjonjon** - *19:53:13*

Has there been anything unusual about today's racing? My models have behaved very strangely

*Tags: Strategies*

---

**Jonjonjon** - *19:56:56*

Ha yes that's what I meant. My forecasting model has had a bad day.:disappointed:

*Tags: Strategies*

---

**Jonjonjon** - *20:23:23*

Maybe there's someone new in town? Or perhaps [@UBS7QANF3](@UBS7QANF3)  has solved horse racing? :disappointed:

*Tags: General Technical*

---

## 2023-09-13

**Unknown** - *08:39:52*

Just been playing around with [https://bloomberg.github.io/memray/index.html|memray](https://bloomberg.github.io/memray/index.html|memray) very neat for anyone who is looking for a memory profiler, good news is that bflw/flumine looks to be memory leak free still :smile:

*Tags: Performance*

---

**river_shah** - *11:26:40*

I am getting some conflicting answers between stack overflow and (insert favourite LLM here). Can `smart_open` be used to incrementally update a file kept on a cloud bucket? I thought bucket objects are immutable but `smart_open` docs seems to suggest that it is able to append lines. Is that actually the case?



Is `smart_open` just abstracting by writing to local temp file and then replacing / flushing remote file. If that is the case that would get very inefficient for large files. If anyone knows what is happening under the hood, will be very helpful. Thanks.

*Tags: General Technical*

---

**liam** - *11:37:50*

[https://github.com/RaRe-Technologies/smart_open/blob/develop/howto.md#how-to-write-to-s3-efficiently|This](https://github.com/RaRe-Technologies/smart_open/blob/develop/howto.md#how-to-write-to-s3-efficiently|This) help?

*Tags: General Technical*

---

**river_shah** - *11:40:19*

Ok, so my understanding now is that either with s3 or gcp, multipart uploads or composite objects will get used. hence these are true streaming writes and will remain efficient for large blobs.



[@U4H19D1D2](@U4H19D1D2) you agree with this?

*Tags: General Technical*

---

**Mo** - *17:08:34*

Can anyone point me in the direction of a Python bivariate Poisson implementation?

*Tags: General Technical*

---

**Riccardo Fresi** - *18:15:19*

Already check this? [https://scikit-learn.org/stable/auto_examples/linear_model/plot_poisson_regression_non_normal_loss.html#|https://scikit-learn.org/stable/auto_examples/linear_model/plot_poisson_regression_non_normal_loss.html#](https://scikit-learn.org/stable/auto_examples/linear_model/plot_poisson_regression_non_normal_loss.html#|https://scikit-learn.org/stable/auto_examples/linear_model/plot_poisson_regression_non_normal_loss.html#)

*Tags: Strategies*

---

## 2023-09-14

**Mo** - *07:29:40*

Thanks [@U02GGCCLTKM](@U02GGCCLTKM). I didn't realise it was you who had asked that SO question



The vectorization makes my head hurt. I think you might be able to make it faster using the loggamma function a la [https://github.com/cran/bivpois/blob/master/R/pbivpois.R](https://github.com/cran/bivpois/blob/master/R/pbivpois.R) but I can't tell because I can't work out how to fit this into the vectorization

*Tags: General Technical*

---

**John Foley** - *10:31:34*

haha yep, fun little puzzle. i think you’re probably right as the scipy loggamma is written in cython. the speed increases may be cancelled out by trying to figure out how to fit it in though lol

*Tags: Performance*

---

## 2023-09-15

**liam** - *13:44:13*

Has anyone looked at optimising the `buffer_size` when reading off the stream?



For context bflw defaults to [https://github.com/betcode-org/betfair/blob/0aadd60ab2c2dcebeedfbc8b661bd257aec46435/betfairlightweight/endpoints/streaming.py#L27|1024](https://github.com/betcode-org/betfair/blob/0aadd60ab2c2dcebeedfbc8b661bd257aec46435/betfairlightweight/endpoints/streaming.py#L27|1024) (no idea why I chose this) but it seems this could probably be optimised by increasing it however unsure how/when things would start to deteriorate? We don't do anything with the data till we receive the `\r\n` so I would have thought just bumping it would make things faster :thinking_face:



Also looking at using `socket.makefile` in this [https://github.com/betcode-org/betfair/pull/540|PR](https://github.com/betcode-org/betfair/pull/540|PR)

*Tags: General Technical*

---

**thambie1** - *13:54:39*

Using a different code base, but I've found a larger buffer size to be particularly helpful on startup when a lot of data needs to be pulled to get the most recent snapshot of all market data before streaming can begin. I use 2MB.

*Tags: General Technical*

---

**liam** - *14:18:39*

[@U05PD1LRGGH](@U05PD1LRGGH) has a good point here in regards to waiting for the last two chars, thoughts?



```Increasing the buffer size will make it more likely that there's

less-than-one-full-buffers worth of data to read and increase the chance

that the last two characters read will be CRLF.



My gut feeling is that in all likelihood during real world usage the

original code will be faster on average as long as the buffer is set

appropriately, as on a low latency connection I believe a single message

will be read in totality much more often than not.



It will have the chance of spikes of latency for individual messages if

they ever get stuck in the buffer as described, but again my suspicion is

that this would actually be rare.



I think you should not merge this and revert the other commit.```

*Tags: Performance*

---

**foxwood** - *14:38:34*

Never looked at the low level feeds in flumine but presume the socket handling / buffering lives in it's own thread world and will manage things with multiple buffers etc as needed ?

*Tags: Deployment*

---

**liam** - *16:09:51*

bflw handles it all, my understanding is that the concern that the large buffer has the potential for lots of messages in a single `recv`



Because we check the end of the message for the line feed we could be left processing without sending the message out.

*Tags: General Technical*

---

**foxwood** - *20:55:07*

Looking at a random recorded dogs file of ~1MB with ~5k lines 96% were less than 512 but only 6 selections of course - will vary by market type / sport. Maybe analyse lots of files and set optimum buffer size by `event_type_id` ? If you went for 4096 you'd get a message per buffer (for dogs anyway) which would be fastest poss.



Looked at the parsing in `_receive_all()` and while it's quick and easy it's surprising that `makefile()` performs so badly on what should be it's native platform ! This link might be of interest and discusses same sort of issue and also usage of `asyncio` package (and an alternative hand-crafted solution) which provides line based reading of the socket stream [https://stackoverflow.com/questions/29023885/python-socket-readline-without-socket-makefile](https://stackoverflow.com/questions/29023885/python-socket-readline-without-socket-makefile)

*Tags: General Technical*

---

**Pete** - *21:06:06*

what you should use for your socket receive buffer size is something that very much depends



with a low latency connection, fast processing of received messages and smallish message sizes from bf I would imagine you will quickly get diminishing returns from larger and larger buffers



this is also something you can test by recording how often the receive buffer you use is completely full

*Tags: Performance*

---

**foxwood** - *21:43:57*

Maybe it's a case of "it aint broke" ? Could supply a `buffer_size` argument in the strategy constructor that feeds down into `MarketStream` to allow users to try their own buffer sizing - bit like the current `market_filter` ? That could provide some useful feedback as to what works best.

*Tags: Strategies*

---

## 2023-09-16

**Mo** - *08:39:54*

There's the [https://betcode-org.github.io/faq/|FAQ](https://betcode-org.github.io/faq/|FAQ) but personally I think some kind of getting started in your "career" document is missing from the betcode resources. Not just how do you get started running a strategy in flumine but how do you get started setting up all of the processes you will need. Feel free to get started on this as you continue to make mistakes :wink:

*Tags: Getting Started, Strategies*

---

**Riccardo Fresi** - *10:26:36*

Surely it will help!

*Tags: General Technical*

---

## 2023-09-18

**Jonjonjon** - *19:08:39*

For a Python developer familiar with Flumine, but no modern financial experience, which Python API for Interactive Brokers would be most suitable forbacktesting at a tick level, where the order book depth is simulated in a similar way to Flumine?

*Tags: General Technical*

---

**Jonjonjon** - *21:11:35*

How much latency would I expect trading via IBKR?

*Tags: Performance, Strategies*

---

**Ralegh** - *21:14:21*

Can’t speak from experience but I’d expect ms minimum, depending on server location, but you’re competing with people with microsecond or even nanosecond latency for higher tech exchanges 

*Tags: Performance, Deployment*

---

## 2023-09-19

**Jonjonjon** - *08:55:46*

I've seen repos by people who have forked it and continued the work, but something about that makes me feel uncomfortable. Maybe I'm being paranoid. But before I started using bflw and Flumine I'd gone through every line of code to check for data theft issues

*Tags: General Technical*

---

**Paul** - *08:56:51*

Have you checked every line of the python source code? What about your OS? 

*Tags: General Technical*

---

**Mo** - *09:04:14*

flumine for financial markets would be greatly appreciated if you wouldn't mind

*Tags: General Technical*

---

**Ralegh** - *09:13:30*

Which asset class and time frame? [@UPMUFSGCR](@UPMUFSGCR) 

Id suggest focusing on getting good forecasts/models (which needs good data) before worrying about simulation. Should be able to manage with some pandas 

*Tags: Feature Engineering, Strategies*

---

**casper** - *19:07:24*

[@U4H19D1D2](@U4H19D1D2) Saw your comment on the PR (below). So this is getting scrapped? Also, any benefit in increasing the buffer size higher than 1024, have you tried different buffer sizes?



```Just did some real world testing on this, when subscribed to all racing markets and all data I see no improvement in latency comparing this branch to master with roughly only 4% of updates greater than 1024 bytes.



Interestingly when a large update comes through (&gt; 4000 bytes) master is quicker.```

*Tags: Performance*

---

## 2023-09-20

**river_shah** - *10:14:29*

Maybe worth digging if TradingView supports python connectors. 1hr+ horizons in microcaps etc likely could work on NYSE for a sharp smaller trader

*Tags: Strategies*

---

**river_shah** - *10:25:20*

Yes, sorry more difficult as in the tech / modelling

*Tags: Strategies*

---

**river_shah** - *10:27:10*

I don't use it but I think it allows easy integration with your PB / positions and possibly some python or other libs with which you can integrate your systems in

*Tags: General Technical*

---

**Ralegh** - *10:28:48*

I’m guessing you’re an (ex) quant [@U01B8031PM1](@U01B8031PM1) is your betfair stuff more like trad trading or modeling outcomes?

*Tags: Strategies*

---

**river_shah** - *10:38:30*

Well depends on strategy modules. Some are very focused on betting that have no translation for other markets. But many things are shared. Crypto volumes are falling off a cliff but what it means is that larger HFTs pulling back due to regulatory concerns. Better for solo / small teams

*Tags: Strategies*

---

**Jonjonjon** - *10:40:54*

[@U01B8031PM1](@U01B8031PM1) have you found the free historical data from Binance useful?

*Tags: Data Quality*

---

**river_shah** - *10:51:33*

No using flumine (thank lord for [@U4H19D1D2](@U4H19D1D2)) The modelling layer wrote myself and then started to refactor it to be general purpose across markets

*Tags: Strategies*

---

**river_shah** - *10:52:31*

I suck(ed) at infra pieces as always had teams of engineers to help with that. had to learn this side of trading systems

*Tags: Strategies*

---

**river_shah** - *10:53:20*

But essentially most infra is a solved problem for all but the lowest latency trades and should be delegated to vendors or open source libraries

*Tags: Performance*

---

**river_shah** - *11:08:38*

so i think it makes total sense to keep betfair / sports modelling in the mix while looking at other markets. the math and principles underlying these are the same

*Tags: Strategies*

---

## 2023-09-26

**foxwood** - *10:32:37*

Looking to change my server provider so checking out the confusing Amazon offers and it ended up suggesting a server at 4 times the cost I currently pay ! I've probably ticked the wrong boxes so can anyone who runs a Windows server with Amazon (ec2 ?) give an indication of the size/model reference they find works for live running about 10 strategies 24x7 with about 40GB storage and all backtest / development done locally ? Tried a different configuration and a "t3" seemed a vague possibility - sadly it's a jargon nightmare.

*Tags: Deployment, Strategies*

---

**PeterLe** - *17:16:50*

I use lightsail too [@U02RN7YDRQ9](@U02RN7YDRQ9) It charged by the month unlike EC2 (ping times the same etc)

*Tags: Deployment*

---

## 2023-09-30

**AndyL** - *18:06:50*

When a "user" reports a "bug" in a GPT-AI written piece of software who debugs the problem?

"Hey GPT what ye doin putting bugs in this crap? fix it now!!"

*Tags: Errors Debugging*

---

**river_shah** - *18:20:58*

The `gpt-manager` gets angry and writes a lengthy negative performance review for `gpt-engineer` forever impeding promotion / compensation progress

*Tags: Performance*

---

**river_shah** - *18:40:16*

[https://github.com/AntonOsika/gpt-engineer/blob/main/ROADMAP.md](https://github.com/AntonOsika/gpt-engineer/blob/main/ROADMAP.md) The plan is to let llms write the tests and debug failing tests too

*Tags: Errors Debugging*

---

## 2023-10-03

**Johnny** - *16:51:30*

Have you got a subscription?  Wonder if actual performance is anything like the video

*Tags: Performance*

---

## 2023-10-04

**PeterLe** - *16:29:08*

You will enjoy chapter 3 [@UBS7QANF3](@UBS7QANF3) although I'm embarrassed to say I got a basic stats question wrong on the dice :astonished:

*Tags: General Technical*

---

## 2023-10-10

**Carl** - *17:08:35*

Keeneland does appear to be correctly mapped as code #75. I can also see there's been 5-figures of volume from TPD users at Keeneland so it seems to be working ok, please do DM me any errors you're seeing and we can dig a little deeper.



I'm told Belmont at the big A is the name of a meeting they do which is actually raced at the Aqueduct 28 day fall meeting because they are doing work to Belmont park.

*Tags: Errors Debugging*

---

**D C** - *18:02:32*

Hi [@U02GSMUSG56](@U02GSMUSG56) . Thanks for the info. To be fair, I get no errors - just don't get any GPS data for anything from Keeneland for some reason.

*Tags: Errors Debugging*

---

## 2023-10-26

**Mo** - *07:26:10*

[@U4H19D1D2](@U4H19D1D2) has posted some links to Robot James's material recently ([https://betcode-org.slack.com/archives/C4H05KKMY/p1697789268560849](https://betcode-org.slack.com/archives/C4H05KKMY/p1697789268560849) and [https://betcode-org.slack.com/archives/CTPL3R3FU/p1695907640349259](https://betcode-org.slack.com/archives/CTPL3R3FU/p1695907640349259)). Here's another banger: [https://twitter.com/therobotjames/status/1717053798739546221](https://twitter.com/therobotjames/status/1717053798739546221)



If you liked them, he's running another iteration of his 4-week [https://robotwealth.com/membership-levels/?pa=9A165184AF|Trade Like A Quant](https://robotwealth.com/membership-levels/?pa=9A165184AF|Trade Like A Quant) course with sign ups open until Monday. I took it last year, really enjoyed it and thought it was well worth the money ($499). He runs it roughly twice a year and if you sign up you get lifetime access so I'll be participating again as it's always good to go over the fundamentals and he refines the content every time he runs it



If this sounds like a sales pitch, I would get a 10% referral fee if you sign up through this link but I'm more than happy to have a frank discussion about the course and answer any questions. Whether you want to facilitate my kick back or not, you can use the discount code TLAQTENOFF to get 10% off yourself

*Tags: General Technical*

---

**Mo** - *09:37:15*

Material releases on a weekly basis but you do it at your own pace. There are live weekly webinars which are worth attending if you can as you can pose questions but not essential to do so as they are recorded and you can always submit questions ahead of time

*Tags: Deployment*

---

**Mo** - *11:32:57*

I believe so. It’s teaching you to think about markets and where there might be inefficiencies that you are in a position to exploit and how to do that in a process driven way. Although the markets talked about in the course are tradfi/crypto, the principles apply to any kind of market. Robot James started taking an interest in betting markets over the past year or so so for all I know he will at least touch on these as well



I thought some of the best content in the course was Robot James doing a live demo of some exploratory data analysis. Fundamental stuff which can apply to any kind of data but the value is in the way he articulates it. That part gave me an idea for a new (small scale) betting strategy that more than covered the cost of the course

*Tags: Deployment, Strategies*

---

**D C** - *11:49:46*

Here is an example of something that gives me reservations [@UBS7QANF3](@UBS7QANF3) maybe you could help:



"People overpay for comfy sh!t like positive skew"



A sample of a Robot James tweet. Now I've not idea what that means (other than the raw definition) and no idea what I would even google to reveal the meaning. Does the course contain stuff like this and if so is it clearly explained?

*Tags: General Technical*

---

**H** - *15:46:32*

Stupid question maybe: is there an easy way to persist Betfair sessions/logins between processes in betfairlightweight?

In particular, if a Python process shuts down and then comes back up, can I persist the session on disk somehow? Or does everyone just call `login()` again when the process comes back up?

*Tags: General Technical*

---

**Peter** - *15:54:43*

The login response is very quick, so like [@UBS7QANF3](@UBS7QANF3) I just login for each discrete betfairlightweight process. Never found a reason to complicate this.

*Tags: General Technical*

---

**Peter** - *15:57:54*

If you're firing off multiple requests per second for the same strategy, that's a pretty big clue that you should be using Flumine. But for housekeeping, keep it simple.

*Tags: Strategies*

---

**H** - *15:59:43*

Ah Flumine seems to have moved on since I last looked at it! I remember it just being a backtesting framework

*Tags: General Technical*

---

## 2023-10-27

**thambie1** - *18:40:08*

I launch a cron job every minute, which would login and execute some api requests. Got an email from Betfair politely asking me to reduce the number of logins. Started persisting sessions using a database since then

*Tags: General Technical*

---

## 2023-10-31

**D C** - *13:22:04*

This may have been asked before, but what type of workflow to people have from idea to live deployment? Although I am currently changing my ways, I've never done anything more than pretty rough and dirty backtesting on things, preferring to just go from idea -> basic analysis -> implementation -> min stakes live -> kill strat or work on staking.



I do things "properly" when it comes to things involving fundamental analysis because I am more at home in that environment, but for purely market data driven stuff that is how I do things.



Despite not caring much what anyone thinks of it, I readily accept that my approach will be considered by many to be a filthy way of going about things and so I am curious about the work flow of others here (assuming people are willing to share of course). Specifically I am talking about the process for totally new ideas rather than refinement of something already in place. Also interested in if people backtest/simulate to "mine" for ideas or just for verification something might be feasible in reality.

*Tags: Deployment*

---

## 2023-11-02

**PeterLe** - *17:13:05*

been out all day Liam (unexpectedly)...

I made some changes to a few systems and was hoping to watch what happened...left them running anyway

Having a quick look, I think every strategy has made a profit today, but not massive PL (At one time Liam that image above would have paid for a family holiday, not these days sadly :neutral_face:)

(Two races had XM off, Thurles and one at Wolv), did ok on them

Hope you are having a good day Chaps! :grinning:

*Tags: Strategies*

---

## 2023-11-03

**Mo** - *17:02:57*

This has now been released and published to PyPI



Summary of the changes:



1. Now uses a Rust optimiser by default which is about twenty times faster than the original Python code

2. By default will now just return the implied probabilities which should make calling code more concise

3. You can now pass in a mapping from identifier to odds and get back a mapping from identifier to probability which also has the potential to significantly simplify calling code

*Tags: General Technical*

---

## 2023-11-06

**Johnny** - *13:32:04*

I guess you are referring to "event_processing":True ... after adding that, the strategy can't find the market_catalogue files (.json.gz) which are in the same place as the market files (.gz)

*Tags: Strategies*

---

**Johnny** - *13:36:01*

Tried providing full path, and manually pushing market_catalogue into the market object, but in truth I think I just need to understand how the strategy and framework program flow works!

*Tags: Strategies*

---

**liam** - *13:38:59*

Yeah, I don't really understand your problem



&gt; strategy can't find the market_catalogue files

Catalogues are for markets, added via middleware, do you have all the catalogues? / or do you want to skip some?

*Tags: Strategies*

---

**Johnny** - *13:54:44*

Yeah the catalogues are all there - I populate the market filter using a list of market ids where both the .gz and .json.gz present.  Then in check_market_book (in simulation) I look for the market type and do logic based on the type of market - and that's where the strategy finds 'None' where I would expect it to find the file.  I'll check out the middleware docs as haven't tried that avenue

*Tags: Strategies*

---

**D C** - *14:55:09*

Does anyone who obtains TPD via betfair ever come across the stream feed time parameter is sometimes later than the betfair publish time parameter? It's not all the time and I've not noticed if off by more than 200 millisecs. Just be curious to know if its an actual thing or a bug with my gps collector program. I've never thought to check it in actual production code just always assumed chronological ordering would be a given.

*Tags: Errors Debugging, Deployment*

---

**D C** - *14:58:05*

Yeah I am not reading anything sinister into it at all, just curious if I had a problem. As you say, perfectly plausible explanations but always good to get a sanity check. Only noticed it working on something new and just thought I'd ask.

*Tags: General Technical*

---

**liam** - *15:05:50*

Latency certainly impacts EV for me

*Tags: Performance*

---

## 2023-11-07

**Jonjonjon** - *21:56:32*

Look up the module it's in. Suppose it's in `flumine.streams` (I haven't looked that up so it's probably wrong).



You'd need something like this script that runs the code:



```import logger



streams_logger = logging.getLogger("flumine.streams")

streams_logger.setLevel(logging.CRITICAL)```

*Tags: General Technical*

---

## 2023-11-09

**liam** - *08:48:00*

Similar design to flumine but covering crypto



[https://github.com/nautechsystems/nautilus_trader/](https://github.com/nautechsystems/nautilus_trader/)

*Tags: General Technical*

---

**Ralegh** - *08:49:17*

I’ve got it working with betfair data in the past, very fast but was a bit finicky so didn’t want to abandon flumines maturity

*Tags: General Technical*

---

**liam** - *08:50:45*

Looks like the core is in rust, I can't really see how its matching orders, I am going to assume its very naive in that regard compared to how flumine does it

*Tags: General Technical*

---

**Jonjonjon** - *19:13:10*

Has anyone tried putting the full data from Betfair files into a database? If so, what did they use?

*Tags: General Technical*

---

## 2023-11-10

**Brett Riley** - *02:00:40*

I use custom python or a modified Flumine strategy file

*Tags: Strategies*

---

**river_shah** - *10:11:31*

flatfiles are generally sufficient. even petabyte scale market data pcaps operate fine with them and throwing a db in the mix for full data handling is likely bad design.



maybe for derived data one could use databases. even then putting processed data into arrow or your favourite portable data format files is better

*Tags: General Technical*

---

## 2023-11-11

**Adrian** - *06:57:07*

What is the benefit of keeping it all in a database as opposed to just the original format on the hard drive? I think about learning SQL all the time but the simplicity of using files straight off the disk keeps me from getting started. I imagine it's good if you want to run queries on a bazillion rows at once but so far pandas + flumine + disk has been adequate.

*Tags: Getting Started, Feature Engineering*

---

**Ralegh** - *10:22:31*

Fwiw most experienced people I know (inc river) do use flat files especially if you’re using it for research - you’re not gonna get any pnl gain from using sql. I personally used a db because it’s convenient to record market prices and my orders at the same time and check them with queries in real time but that’s more for debugging and not necessary 

*Tags: Errors Debugging*

---

## 2023-11-12

**Adrian** - *22:52:15*

This is a newbie question as I'm moving over from Jupyterlab and Sublime to Pycharm. So learning how packages and projects work is a learning curve of its own. What is the best practice for working with the flumine package. Should I create my strategies within the flumine directories and then import my custom functions there? Or should I create a new project/venv separately with all my modules and import flumine into there instead? I would like to still be able to explore the flumine package and its variables through the debugger. Thanks

*Tags: Errors Debugging*

---

**Adrian** - *22:57:47*

Thanks JL. So that would be a new directory for my project with a new venv and then import flumine there?

*Tags: General Technical*

---

**JL** - *23:03:22*

yes, basically in your created directory:

```python3 -m venv .venv

source .venv/bin/activate

pip install flumine```

*Tags: Getting Started*

---

## 2023-11-13

**liam** - *08:13:52*

As above, here is an example repo



[https://github.com/liampauling/flumine-strategy-development](https://github.com/liampauling/flumine-strategy-development)

*Tags: Strategies*

---

**foxwood** - *09:35:48*

As [@U4H19D1D2](@U4H19D1D2) says - also I'd recommend subfolders in your strategies directory to keep related / similar strategies together - makes later navigation and searching in PyCharm a lot easier than having to scroll through long lists of files. With PyCharm you can easily search the venv flumine folder to see the sources, place breakpoints, step through and generally wander about.

*Tags: General Technical*

---

**Adrian** - *20:46:15*

This is cool, thank for all the help! I just imported flumine into my new venv and it worked seamlessly. I didn't think it would be that easy.

*Tags: General Technical*

---

## 2023-11-14

**PeterLe** - *17:45:23*

Just noticed I’m getting a message “temporary ban too many requests” when trying to log in via the Betfair app, (on two accounts) anyone know how long “temporary is” please?  I guess I would also need to restart those two flumine instance at some point? Any idea anyone please ? 

*Tags: General Technical*

---

**foxwood** - *21:35:02*

Sounds like an automated hack where they are using your username / email. 2FA should keep them out and just leave the flumine running - that requires your cert so should be fine. When you do manage to login via the app you should be able to see the recent login attempts. Been a lot of this mentioned on BA in recent times.

*Tags: General Technical*

---

**PeterLe** - *23:00:39*

Thanks gents, yes I thought the same [@U02RN7YDRQ9](@U02RN7YDRQ9) I hadn’t read it properly till [@UBS7QANF3](@UBS7QANF3) just pointed it out that it was ‘successful’ logins, I couldn’t possibly have done that manually, but flumine has been running on multiple accounts for many months and I’ve never seen it before? 

I’ll just leave flumine running and check every other day the balances via the master account 

thanks for the thoughts though both

*Tags: Multi Client*

---

## 2023-11-15

**foxwood** - *08:52:52*

Whoops - my bad for not picking up on that key word. Checking the list of recent logins at BF and the flumine logs should lead to an answer.

*Tags: General Technical*

---

**D C** - *08:55:36*

Seems a bit self-indulgent to complain about it and its a very first-world problem. We as automated players have the best of it too - I would not last a month being a manual trader/gambler/poker player stuck at a desk/table for hours on end.

*Tags: General Technical*

---

**D C** - *09:42:40*

[@UQL0QDEKA](@UQL0QDEKA) I did try this. I was out of work at the peak of pandemic as my contract was not renewed so turned to this full time. Was approached by a betting company and started working there - great chaps but I honestly could not get motivated. I was getting paid a quarter of what I was making in profits on Betfair and the London commute was costing me 3 hours a day (had to be on site 3 days a week). That combined with not enjoying what they had me working on meant my motivation just dropped off a cliff and I ended up resigning. I think that I would have the same problem anywhere else now so if I did end up on the grid again I think I would have to just be self-employed in some way. Didn't help that it was a startup and most of the people were really enthusiastic youngsters at that live-to-work stage of their lives. They were all great people but I am at that age now where going on the piss after work is not what I am looking for so I missed out on a lot of the social stuff I would have lapped up 20 years ago. The penny finally dropped when they had some golf up on one of the internal TVs and some young shaver referred to Sergio Garcia as "one of the old guard"

*Tags: Deployment, Strategies*

---

**liam** - *11:30:59*

Over the years nearly everyone has questioned my day job when I have betfair. I think the post sums it up well but looking back now it has certainly accelerated my wealth from being able to lean on what the average joe considers normal (for example mortgages)



There is more to it as well, I only contract about a day a week now but get invited to socials, leaving drinks, Christmas parties etc, all excuses to leave the screen and pretend to be normal once a month. Regarding the work I am currently exploring on integrating an LLM on a result set in real time, interesting / real world problems that get visibility from others which makes it more rewarding. Coming up to over 2 years at my current role I am probably due a change..

*Tags: General Technical*

---

## 2023-11-18

**Jimmy** - *14:18:34*

Python question:



We are looping around runners in a market. (standard stuff)



Question is what would be the most pythonic way of getting the price of the next runner (or None if there isn’t one)?

*Tags: General Technical*

---

**Jimmy** - *19:46:00*

Solved it by processing the book differently — which is a bit of a cheat but still…

*Tags: General Technical*

---

## 2023-11-20

**Adrian** - *10:35:19*

So i decided to take the plunge and start learning two big things over the last week. SQL and Pycharm. Can't say i think much of the former, but the latter is and absolute game changer. Regarding SQL, it takes me eight times longer to load my database up than loading it from pickle. Even longer to save it. The only case i can see this being useful is if I kept the thing open, sending in data to it periodically. At the moment pandas/pkl is so fast i can recreate my entire dataset from file faster than SQL can load. And anything that involves conversion between the two... forget about it :sweat_smile:

*Tags: Feature Engineering*

---

**Adrian** - *11:00:02*

I think I might be able to skip SQL altogether and go for something like MongoDB. It's looking pretty promising from what i've seen. It could possibly even store ml models and associated dataframes/transformer objects,

*Tags: Feature Engineering, Strategies*

---

**Jonjonjon** - *11:34:52*

Thanks for sharing your findings.



Won't MongoDB be worse than SQL? A well designed SQL database will generally outperform MongoDB.

*Tags: General Technical*

---

**Ralegh** - *13:56:54*

To be honest if you’ve got flat files working with your setup there’s basically no reason to change. Also storing ML models in a database seems kinda pointless to me, how would you use it any different to on disk?

*Tags: Getting Started, Strategies*

---

**Adrian** - *20:18:14*

Mongo could be worse, I don't have any experience with it so... I'll try a few things, as long as they have a python interface. Pandas own write to SQL library failed to complete at all with my final dataset without it being split up into parts, even then it was problematic (creating ghost entries).

Although the flat files thing is working, it's getting messy- i've got raw, unprocessed data, then cleaned, workable data, then formatted data, then finally transformed data. Trying to keep it all linked with folders and file names seems cursed.

*Tags: Errors Debugging, Feature Engineering*

---

## 2023-11-21

**Jimmy** - *09:57:38*

Simulations against data — all bets under 2 are being rejected (even the ones above £1, which would be fine live). Is there a setting I’m missing.



(Apologies for the recent surge in daft questions!)

*Tags: Deployment*

---

**foxwood** - *10:34:59*

laying ? default `max_order_exposure` is 10.00 [https://betcode-org.github.io/flumine/strategies/#parameters](https://betcode-org.github.io/flumine/strategies/#parameters)

*Tags: General Technical*

---

**Unknown** - *15:59:31*

Can anyone recommend study material so I can learn how to calculate the correct score for live football matches based on handicap and goals data?

*Tags: Deployment*

---

**Mo** - *17:03:07*

Step one: take your pick of an assumed joint probability distribution for the goals. Some suggestions:



1. Bivariate Poisson ([https://betcode-org.slack.com/archives/C4H05KKMY/p1694621314786749](https://betcode-org.slack.com/archives/C4H05KKMY/p1694621314786749))

2. Bivariate Weibull count model ([https://www.sciencedirect.com/science/article/abs/pii/S0169207017300018](https://www.sciencedirect.com/science/article/abs/pii/S0169207017300018))

Step two: use numerical optimisation to fit the parameters of your chosen distribution to the available odds on the AH/total lines (optionally include other markets as well)



Step three: use the fitted parameters to calculate the matrix of probabilities of each scoreline

*Tags: Strategies*

---

**Unknown** - *23:08:24*

Hi all,

In my little spare time I've been working on various pre-race odds modelling ideas from scraped Racing Post data, but I've no experience writing betfair trading bots and none of the ideas i had have worked out, so I'm looking for anyone else that wants to partner up and use my highly organised/normalised database including:

• back history as far back as you want (currently it is back to about 2008 but there is no reason I can't add more)

• daily racecards parsed into the databased and marked as "racecard" in a status field

• as soon as results are available they are fetched and committed to the database to replace the racecard

• some custom things I made such as trainer/jockey/horse observed/expected ratios based on SP, and collateral horse ratings.

• map tables to identify the matching meeting/race/horse records between BF and RP (only back to ~2015)

Attached is a diagram of the schema that will be included, so you can see how verbose it it. It includes pretty much everything that is available in the RP results page.

The database is maintained in the cloud, so I think the easiest way to onboard would be to supply anybody interested with a read-only username/password. A possible alternative is async replication but I've never set that up before so it might be a lot of hassle.

Send me a message if you're interested or have any questions :)

*Tags: Strategies*

---

## 2023-11-22

**Justice** - *09:57:02*

According to the webpage, he is a data scientist at TPD: [https://www.totalperformancedata.com/about-us/](https://www.totalperformancedata.com/about-us/)

*Tags: Performance*

---

**D C** - *10:00:50*

Yeah I have had discourse with a person (data scientist) from TPD called George Swindells a few years ago which is why I asked the question. Could be pure coincidence though (I used to have a uni lecturer with the same name as me!).

*Tags: General Technical*

---

**D C** - *10:01:47*

But also, I did ask here some while ago if we had any TPD employees on the forum that we could ask questions but there was no response.

*Tags: General Technical*

---

**George Swindells** - *10:38:34*

Hi, yes I'm the GS from TPD :slightly_smiling_face: Sorry DC I only recently joined to ask about interest in my RP database so I haven't seen any older messages about TPD and I don't monitor this page much as I already have a litany of apps and tabs open for work and want to try to keep then number down. If I get tagged in something then I get an email notification so if you have any questions you can get my attention that way

*Tags: General Technical*

---

**AndyL** - *18:58:37*

Did I meet you in the Darts "red" team last week [@U066B8Z0L3F](@U066B8Z0L3F)? seem to remember you mentioning RacingPost to me and fundamentals...

Your database looks quite neat. I tried fundamentals on the greyhounds and failed misserably...!

*Tags: Errors Debugging*

---

## 2023-11-24

**D C** - *13:17:29*

[https://twitter.com/Ascot/status/1728034480445608109](https://twitter.com/Ascot/status/1728034480445608109)



Just saw this pop up on my feed. Likely nobody knows but do you think these win% are generated from the same model that they sell to bookies to allow them to offer inplay odds?

Are TPD allowed to trade on Betfair? If so, do they?

*Tags: Strategies*

---

**D C** - *20:32:52*

RNG :joy:  I've not used a bookied in years so I don't know if they actually do offer inplay horses now but I remember asking TPD about their price model and I was told it was only available to bookies.

*Tags: Strategies*

---

## 2023-11-27

**Javier Martín Pérez** - *15:46:46*

Hi! Not sure if anybody else has this problem but in terms of football trading Saturday and Sunday afternoons require a lot of computing and need to upgrade my server. At the moment I am using [http://MVPS.net|MVPS.net](http://MVPS.net|MVPS.net) and the prices grow a bit too much when you go from 4 processors to 8. However I have seen others like OVH that offers the same for a quarter of the price. Any experience with them?

*Tags: Deployment, Strategies*

---

**Peter** - *16:00:19*

Make sure you know what you're getting if you go for a cheaper option.



I went down that route a few years back and got a big VPS at a really good price. However, when I stepped up the volume to use that power, they severely throttled my throughput to the vCPUs arguing that my processing load contravened their "fair use" policy. So headline power isn't necessarily what you'll get in practise.



I also had issues with the IP address allocated to the VPS, as despite being repeatedly assured that the appropriate registries had been updated to show the VPS as in the UK, which I believe it was, Betfair (most likely going of the IP address) has never accepted this.



Many people here just use AWS. I have for the past three years and have never had any issues.

*Tags: Deployment*

---

**Johnny** - *16:11:18*

How does one know when more compute or memory is needed?  Is it the latency warnings?

*Tags: Performance*

---

**Javier Martín Pérez** - *16:13:06*

Yes, in my case is latency but also the use of the CPU going above 60% which is not ideal in theory

*Tags: Performance*

---

## 2023-11-29

**Justice** - *12:13:15*

A quick question George. I am looking to migrate my database to the cloud rather than running it locally. What cloud provider and service do you use? I have a Postgres database and I'm most familiar with Azure but I'm exploring my options

*Tags: General Technical*

---

**George Swindells** - *12:56:52*

I use AWS RDS because it's the cloud provider with which I'm most familiar, I doubt there is much difference between all the big providers so I would say just choose whichever you know best. Though a colleague recently had a lot to say about how awkward it is to migrate a database out of the AWS ecosystem to deploy elsewhere, and said in Azure it's much simpler but I don't know about this first hand.

*Tags: Deployment*

---

## 2023-12-01

**Jimmy** - *09:53:00*

Thanks Liam.



Is there a helper before I start hacking? (I’ve made that mistake before!)



And will it get me a visit to the naughty step?

*Tags: General Technical*

---

**liam** - *10:02:15*

Regarding its use, you will just pay the transaction change if applicable and you will be blocked if trying to do it at low odds where you have &lt;0.01 liability but you will get a cryptic error for that

*Tags: Errors Debugging*

---

**Jimmy** - *11:42:43*

Thanks Liam — don’t think I’ll hit that error path. Appreciate your help

*Tags: Errors Debugging*

---

**Unknown** - *14:47:45*

Can I get some advice on the following simulated result chart please? Should point out that this is done using my own simulator/backtester (whatever you want to call it) and not flumine. Chart is cumulative profit across markets ordered chronologically - its about a year of data. Basically to me it looks like something that was doing well, but something changed and its flattened out. I know the only real way to test is to run it but in general how would a chart like this lead people to proceed ? Bin ? Run it and see ? Even if I subsequently discover issues with my code, the question still stands as I could potentially come across similar profit curves if I did use flumine. What kind of things do people to do to try and get to the bottom of the reasons for the flattening curve gradient?

*Tags: General Technical*

---

**D C** - *15:04:15*

Its basically testing value prices from a new model - lay bets only offered at a fixed scaling of the model value price (max 50-1 offered). Inplay horses.

*Tags: Errors Debugging, Strategies*

---

**D C** - *20:46:13*

I don't do much with lay bet placements so it is very naive - just laying to win a flat stake if it is odds against and laying to win a slightly larger flat stake if it is odd on. Until I can work out kelly stakes appropriate for laying I've just kept if very simple.

*Tags: Strategies*

---

**liam** - *20:47:36*

Just lay to a fixed liability if you want to keep it simple, be interesting to see how the graph changes along with roi 

*Tags: Errors Debugging*

---

**D C** - *20:48:23*

OK I will rerun it laying to lose fixed amount.

*Tags: Errors Debugging*

---

**Jonjonjon** - *21:23:37*

Are the default workers `poll_account_balance` and `poll_market_closure` important? Would there be any unwanted side effects if I turned them off?



I'm asking as I'm running a lot of Flumine bots under a single account, and keep TIMEOUT_ERROR's due to too many requests.

*Tags: Errors Debugging*

---

## 2023-12-02

**Peter** - *09:20:47*

These aren't executed with high frequency: every 60s for `poll_market_closure` and every 120s for `poll_account_balance`  so shouldn't make a huge difference to your requests count.



If that is enough to cause "too many requests"-type errors, then time may be better spent looking at how to combine your strategies under a smaller number of Flumine instances.

*Tags: Errors Debugging*

---

**Unknown** - *10:36:54*

Same output but laying to fixed liability

*Tags: Errors Debugging*

---

**Mo** - *10:42:13*

Sort out your Kelly staking 

*Tags: Strategies*

---

## 2023-12-03

**Mo** - *11:47:48*

I've seen it advertised as an AWS S3 killer but haven't tried it myself

*Tags: Deployment*

---

**river_shah** - *12:09:35*

Have you guys managed to run container registries on it? Seems like AWS / GCP artifact registries also become obsolete with this. Both cloud buckets with their egress charges and artifact regustries are egregiously priced on AWS / GCP and can't wait to optimize that out.

Did you guys discover any downsides for R2 / cloudflare?

*Tags: Deployment*

---

## 2023-12-04

**Johnny** - *10:22:05*

I'm just using the example marketrecorder.py.  It seems to die (docker container restarts) on match days which means I have a load of incomplete market files - been checking the logs and get a load of "latency high" lines followed by a timeout error.  Maybe subscribing to too many markets is the issue, will try narrowing it down next



```{"asctime": "2023-12-03 13:12:51,407", "levelname": "ERROR", "message": "_get_cleared_market error", "exc_info": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/site-packages/flumine/worker.py\", line 235, in _get_cleared_market\n    cleared_markets = betting_client.betting.list_cleared_orders(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/betting.py\", line 434, in list_cleared_orders\n    (response, response_json, elapsed_time) = self.request(method, params, session)\n                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 54, in request\n    self._error_handler(response_json, method, params)\n  File \"/usr/local/lib/python3.11/site-packages/betfairlightweight/endpoints/baseendpoint.py\", line 80, in _error_handler\n    raise self._error(response, method, params)\nbetfairlightweight.exceptions.APIError: SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.221745228'], 'customerStrategyRefs': ['d69966378a3d'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00af825869', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00af825869', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}", "trading_function": "list_cleared_orders", "response": "SportsAPING/v1.0/listClearedOrders \nParams: {'betStatus': 'SETTLED', 'marketIds': ['1.221745228'], 'customerStrategyRefs': ['d69966378a3d'], 'settledDateRange': {'from': None, 'to': None}, 'groupBy': 'MARKET'} \nException: None \nError: {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00af825869', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}} \nFull Response: {'jsonrpc': '2.0', 'error': {'code': -32099, 'message': 'ANGX-0010', 'data': {'APINGException': {'requestUUID': 'ie2-ang26b-prd-09131022-00af825869', 'errorCode': 'TIMEOUT_ERROR', 'errorDetails': ''}, 'exceptionname': 'APINGException'}}, 'id': 1}"}```

*Tags: Errors Debugging, Performance, Strategies*

---

**Unknown** - *10:33:21*

It might be unrelated actually as that error seems to come up fairly often and it just looks like the server isn't responding.  Just went back a bit further and see a cryptic "Killed" line in the logs, and then the container restarts on the next line... I'll do a smaller market filter and report back.



CPU is 32 cores of a Xeon from 2017, 32gb allocated.

*Tags: Errors Debugging, Deployment*

---

**Burrito** - *11:06:29*

What data comes out of the `get_scores` api? Does it provide Football Scores?

I see an example here: [https://github.com/betcode-org/flumine/blob/3d697cdb4d186b66af574afcf8001f18776f331d/examples/workers/inplayservice.py#L17](https://github.com/betcode-org/flumine/blob/3d697cdb4d186b66af574afcf8001f18776f331d/examples/workers/inplayservice.py#L17)



Apologies for not doing this myself but I'm behind a corporate firewall.

*Tags: General Technical*

---

## 2023-12-10

**Jonjonjon** - *17:29:33*

Isn't there a character on here who always asks why anyone would need a mortgage, whenever these sorts of questions arise? What happened to them?

*Tags: General Technical*

---

**Paul** - *18:15:15*

When I've hired, if somebody had put "self-employed algorithmic trader", and then had put down skills across data science, coding and money management, whether it was sports or fiscal markets, I wouldn't have cared: interview would have been booked, we would have spent half the interview talking about it, and it would have been a positive sign that somebody had dived into a difficult challenge and solved it, and that's great. I would have expected them to be honest about their motivation and if they'd said "TBH, I'll be gone in 2-3 years, I'm just doing this for the paperwork", I'd know where I stood, no problem.

*Tags: General Technical*

---

**Paul** - *18:18:01*

However, in bigger firms you need to first get past recruiters, and they're about as unimaginative as you'd expect. I'd consider putting more of the skills down and just put yourself down as "self-employed", and say you were working on your own thing for a while, indie-hacker style. You can be honest with the hiring manager (and I'd encourage you to be so), but the recruiters are normally risk averse unless you have a very niche skill (e.g. right now you could be a felon having just done 5 years inside, but if you know how to build an LLM, you're getting an interview loop at MSFT, GOOG, META or AMZN).

*Tags: General Technical*

---

## 2023-12-12

**D C** - *11:03:18*

I can see why people would find the drone feed more useful - more for the angle than the latency difference (especially in the finishing straight). Never used it myself but seen it posted that people have paid £500 a day for these pics. Could be absolute bollocks but thats quite a deficit to be making up the markets on a daily basis.

*Tags: Performance*

---

**D C** - *12:23:12*

Interesting. I don't think it boils down to the amount of people who have access, rather the amount of those that know how to use it properly. Same goes for TPD - now its integrated into Bet Angel/GrussBetMover (and a lot cheaper than it used to be) I'd expected to see profits diminish but that has not happened.

*Tags: General Technical*

---

**Justice** - *12:51:42*

I can tell you it was unbelievably good for around 6 months since racing returned after covid. Then it started to get harder once more started teaming up to purchase drones. Then one particular individual, whose business model is not to bet but rather sell the pictures (also sold facetime pictures back in the day), purchased a drone. That killed it completely as it opened access to 100+ other players

*Tags: Strategies*

---

**Justice** - *14:56:36*

[@UUE6E1LA1](@UUE6E1LA1) That was many years ago, long before it was available with BetAngel etc. It was offered as a raw UDP stream sent direct via a fixed IP address. I only trailed it for probably 2 dozen meetings and didn't proceed any further as I was unimpressed with the accuracy of the data. But I have heard it has improved recently

*Tags: Errors Debugging*

---

**D C** - *15:07:07*

Interesting. I can't help but feel that you might have missed a trick. I mean, I agree with you about the occasional positional errors but to go to such lengths to pay for the data and write a stream listener app AND a viewer and then give up is an odd one. I wish I'd had access around when you did as there were far fewer GPSers around then. Out of interest what were you paying back then when you had it. I think I was quoted about £40 a meeting but you are the only person I've ever spoken to who has paid for the UDP feed direct from TPD as opposed to getting it via Betfair or OTS trading applications.

*Tags: Errors Debugging, Strategies*

---

**George Swindells** - *15:09:43*

[@U05N9773A23](@U05N9773A23) Best to email the sales team ([mailto:info@totalperformancedata.com|info@totalperformancedata.com](mailto:info@totalperformancedata.com|info@totalperformancedata.com) i think) to see what they're offering these days, I don't get involved in that process much anymore unless I'm asked to prepare a sample of data for a prospective client

*Tags: Performance*

---

**Justice** - *15:17:11*

[@UUE6E1LA1](@UUE6E1LA1) We are talking over 4 years ago. I contacted them directly and we agreed a select number of meetings on trial, mostly jumps. I can't remember the exact cost but it was far cheaper than £40 per meeting, perhaps as low as £10, but again it was just a trial. The direct UDP feed was the only way to consume the data back then. Perhaps it has improved, but for me, the positional errors were frequent, and sometimes very significant

*Tags: Errors Debugging*

---

**Justice** - *15:27:20*

[@UUE6E1LA1](@UUE6E1LA1) I accept a margin of error, and the odd glitch but, at least back then, it was far too frequent to warrant the significant effort to train a model or code some automation strategy. It must have improved since

*Tags: Errors Debugging, Strategies*

---

## 2023-12-13

**D C** - *22:16:42*

Could anyone be so kind as to point me to the file that deals with simulating the matching of unmatched orders in the flumine repo?

*Tags: General Technical*

---

## 2023-12-14

**liam** - *08:26:16*

[https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/markets/middleware.py#L182|here](https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/markets/middleware.py#L182|here) and [https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/simulation/simulatedorder.py#L36|here](https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/simulation/simulatedorder.py#L36|here)

*Tags: General Technical*

---

**liam** - *10:07:14*

Yeah that happens [https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/simulation/simulatedorder.py#L64|here](https://github.com/betcode-org/flumine/blob/bc07dd69870f368ccb5a8186fbf59206fa8f4313/flumine/simulation/simulatedorder.py#L64|here) along with lots of other stuff to further replicate betfair settings/bet options/piq

*Tags: General Technical*

---

**D C** - *11:15:34*

OK I've spotted a few errors in my code already from this. I had not implemented any place in queue stuff yet and knew I had to do so but when going through the code in `simulatedorder.py` I came across this:



    `def _calculate_process_traded(self, publish_time: int, traded_size: float) -&gt; float:`

        `_traded_size = traded_size / 2`



Does this mean that regardless of odds, the traded volume as supplied by the API is simply a doubling of the BACK stakes matched?

*Tags: Errors Debugging*

---

**D C** - *11:20:38*

I can at least console myself with the fact that its a very easy bug to fix.

*Tags: Errors Debugging*

---

**D C** - *16:20:11*

[@U4H19D1D2](@U4H19D1D2) does flumine attempt to adjust the position in queue values based on reductions in ATL/ATB ladders due to cancellations rather than matches in the traded amounts deltas ?

*Tags: General Technical*

---

## 2023-12-28

**Adrian** - *22:45:43*

So I'm nearly at the finish line after 9 months of building a start-to-finish ML app in python including learning how to code properly along the way. I spent 6 months doing something similar that failed a couple of years ago. I've spent nearly 4 years total trying to make money with Betfair. And I'm wavering at the finish line. I took a break for the holidays and it's made me reflect on how hard I've been working on this project and how many hours I've put in (virtually every waking hour outside of work) for no result yet because it's not finished and I haven't put it to use. I'm writing this to get some inspiration to finish it. How many of you have been in this situation and pushed through to find the rewards? Is it worth it? Do you actually make a good living doing this? The opportunity cost of doing something else is now weighing heavily as the project drags on I fear wasting time on something that doesn't pay off in the end.

*Tags: Errors Debugging*

---

## 2023-12-29

**Adrian** - *08:53:57*

[@UQL0QDEKA](@UQL0QDEKA) i have used the backtester in limited capacity only since I only have free historical data to work with. That can only give me a rough indication of whether or not I am beating SP, but not how my execution if performing. I have created a simulation using last traded prices of that data and at this point can only make an estimated guess as to how well I would get matched because there is no volume data and the intervals are unusable. This has been one of the major hurdles of production.. actually having quality data to work with. Unfortunately betfair requires you to put money down in order to get data one way or another. So there is that barrier to entry to contend with

*Tags: Data Quality, Deployment*

---

**Mo** - *08:59:57*

How can you be building ML models if you don't even have decent price data? Stop fucking around and just start recording the price stream

*Tags: Strategies*

---

**D C** - *10:14:03*

I'd been at it for years off and on. Started botting on the SOAP API but only data gathering. In truth everything I was doing was pretty half arsed - the only things I had working models for there was zero money available on Betfair (MLB basically). I turned it around getting on for 4 years ago now. Started off at minus £50K after years of recreational betting and failed "systems" (although on the plus side that heavy usage means I still don't pay PC)

*Tags: Errors Debugging, Strategies*

---

**AndyL** - *14:46:05*

[@U053KV09FKP](@U053KV09FKP) I prefer the "fail fast" approach, although saying that i've recorded 2 years worth of data now, and have developed lots of useful Python bits and pieces, so if I have an "idea" or "whim" I can throw something together quickly (say 1 hour) and churn it through a month's worth of data in the Simulator, then see what it shows me... Analysis of what it shows me is also key. That's my 2cents, i'm only a minnow in this game though!

*Tags: General Technical*

---

## 2024-01-03

**Peter** - *16:58:04*

Providing liquidity isn't a problem for most pros. It's finding enough liquidity on the other side to match against. So if liquidity overall is down that suggests to me that non-pros are betting less, rather than more.

*Tags: Strategies*

---

## 2024-01-04

**D C** - *13:39:13*

A few discussions on here recently got me thinking and I wanted to pose a question about CLV / BFSP efficiency. The TLDR is basically:



_Betfair betting volumes are in decline over recent years, could this lead to BFSP becoming less accurate?_



I am asking this as much to fill gaps in my own knowledge and understanding, but AFAIK, the whole CLV premise is based upon prices converging to probability X at time of event start because of information flow over time and sharper players exploiting value when it presents itself (I am guessing this is analogous to market efficiency hypothesis in finance??). So IF we were to show that BFSP was STILL just as accurate 5 years ago as it was now, could you effectively deduce that it is only "dumb" money that is abandoning the markets? If you actually wanted to measure the efficiency of BFSP and its fluctuation over time, what statistical approaches could you use? I know people use brier score to rate probabilistic forecasts so could you use something like this split over a time partition and compare? Up to know, I've not really cared much about CLV as I exclusively bet IP where it is not really applicable. Similarly, I've not been much bothered with measuring my edge (until recently never even bothered calculating ROI until a discussion on here with someone) and just let profit be the measure (I don't lose sleep if Joseph Buchdahl labels me a victim of survivorship bias). But I want to move into pre-off horses and so been thinking more and more about BFSP and the recent drop in volume topic got me thinking about this. I often hear that BFSP is "accurate on average" but never seen any hard numbers and certainly never an analysis of its accuracy change over time.

*Tags: Strategies*

---

**Peter** - *18:30:16*

You can validate the statement that they are accurate on average visually by inverting them to get the implied probability, grouping them into bins, and plotting the win rate for each bin. Apart from the tails they'll fall nicely into a straight upwardly trending line.



You could quantify the variance using a measure such as mean squared error, and see if this varied over time.



But I would challenge the idea that the accuracy of BSP could tell us much about whether it is smart or dumb money exiting the market. If one accepts wisdom of the crowds as a major contributor to prices converging to true odds,  then it's not necessary for the guesses (bets) to be good, just (relatively) independent.

*Tags: Errors Debugging*

---

## 2024-01-06

**PeterLe** - *11:05:14*

What would be the maximum number of strategies you would consider running in flumine? (Strategies that place a high number of bets on a single account)

would it be better to run less strategies on more instances? Thanks

*Tags: General Technical*

---

**Jonjonjon** - *12:00:23*

The latency on the final one increases to about 0.15s

*Tags: Performance*

---

**Alex A** - *12:16:32*

What’s a back to lay strategy?

*Tags: Strategies*

---

**liam** - *12:35:02*

I normally don’t go above 5, strategy dependant, they are called sequentially and in order so it depends how sensitive you are to latency. When optimising the preference would be 1 strategy per instance, I record tick to trade to monitor this 

*Tags: Performance, Strategies*

---

**PeterLe** - *12:39:53*

latency is important to me.

So by example; If you wanted to run say 5 strats (on one account) that pace a high number of bets then ideally one start per instance rather than 5 starts per instance. Optimal would be to run the starts on separate instances/accounts I expect?

*Tags: Performance*

---

**liam** - *12:43:15*

If you record the latency per bet and plot it, you can see how sensitive you are to 0.001/0.01/0.10s per latency

*Tags: Performance*

---

**AndyL** - *15:31:26*

[@U4H19D1D2](@U4H19D1D2) "tick to trade", so does this mean the time between your strategy seeing the "signal" and the time the trade is placed/matched ?

*Tags: Strategies*

---

**liam** - *18:47:27*

Yeah removing network latency and just focusing on what flumine is doing 

*Tags: Performance*

---

## 2024-01-07

**Unknown** - *23:35:23*

Here you go [@UUE6E1LA1](@UUE6E1LA1) Even allowing for time zones I haven't ever recorded a -£2,185 in any 24hr period, I'd have noticed.  Maybe it's fixed now but the screenshot is from when I first noticed the feature was there.  The 9th was correct so I'm not interpretting it incorrectly, and the 11th is wrong too as I lost about 450 vs the -350 it shows.

*Tags: Errors Debugging, Feature Engineering*

---

## 2024-01-08

**liam** - *20:10:55*

[http://www.stat.columbia.edu/~gelman/research/published/standarderror.pdf|http://www.stat.columbia.edu/~gelman/research/published/standarderror.pdf](http://www.stat.columbia.edu/~gelman/research/published/standarderror.pdf|http://www.stat.columbia.edu/~gelman/research/published/standarderror.pdf)

*Tags: Errors Debugging*

---

## 2024-01-09

**lorenzo** - *08:16:52*

Hi [@UPMUFSGCR](@UPMUFSGCR), quick noob Q. How do you account for the `MAX_CONNECTION_LIMIT_EXCEEDED` errors? Do you "bundle" strats together under one/couple market filters?

*Tags: Errors Debugging*

---

**Jonjonjon** - *08:27:26*

I run them under a single Flumine instance

*Tags: General Technical*

---

**lorenzo** - *08:43:45*

thanks of reply! just to double check - adding each one of the 100 with `add_strategy` ?

*Tags: Strategies*

---

## 2024-01-15

**liam** - *21:00:54*

Yep, the basics in how to calculate probability (correctly) is something I am missing and sites like this make it very easy 

*Tags: General Technical*

---

## 2024-01-16

**Mo** - *12:29:45*

This is well and truly random but I've been playing this game recently: [https://store.steampowered.com/app/1404850/Luck_be_a_Landlord/](https://store.steampowered.com/app/1404850/Luck_be_a_Landlord/) (also available on iOS and Android) and thought it might appeal to some of you other degenerate gamblers. The setup is bizarre but you're basically building a slot machine symbol by symbol where every symbol is unique in terms of how much money it pays out and its interactions with the other symbols in your machine. It's very good for making you think about how to maximise expected value

*Tags: Getting Started*

---

**Greg martin** - *13:30:01*

Hi all just joined the slack group. The free version of Slack only lets me see how to 90 days of previous messages. 



How do I see the archive of messages in the group? Slack premium? How do I pay/sign up for that etc 

*Tags: General Technical*

---

## 2024-01-17

**Andrey Luiz Malheiros** - *19:29:19*

Hey guys, how much time on average does it take to run a simulation of a single strategy for 2000 markets?

*Tags: Strategies*

---

**Jonjonjon** - *19:38:56*

If you haven't already, please read this page: [https://betcode-org.github.io/flumine/performance/](https://betcode-org.github.io/flumine/performance/)

*Tags: Performance*

---

**Andrey Luiz Malheiros** - *22:41:57*

Yes, I am using performance suggestions, including multiprocessing. But thank you anyway, I will profile my code and see what is happening.

*Tags: Performance*

---

## 2024-01-18

**PeterLe** - *12:37:19*

I just fed some of my code into Chatgpt for comments on how to optimse.

it suggested that this code ;



```def calculate_book_percentage(runners):

    back_book = 0

    lay_book = 0

    ltp_book = 0



    for runner in runners:

        if runner.status == "ACTIVE":

            try:

                back = get_price(runner.ex.available_to_back, 0)

                if back:

                    back_book += 1 / back

            except AttributeError:

                return None



            try:

                lay = get_price(runner.ex.available_to_lay, 0)

                if lay:

                    lay_book += 1 / lay

            except AttributeError:

                return None



            if runner.last_price_traded:

                ltp_book += 1 / runner.last_price_traded



    return round(back_book, 4), round(lay_book, 4), round(ltp_book, 4)```

be replaced by this code

```def calculate_book_percentage(runners):

    back_book, lay_book, ltp_book = 0, 0, 0



    for runner in runners:

        if runner.status != "ACTIVE":

            continue



        back = get_price(runner.ex.available_to_back, 0)

        lay = get_price(runner.ex.available_to_lay, 0)

        ltp = runner.last_price_traded



        if back:

            back_book += 1 / back

        if lay:

            lay_book += 1 / lay

        if ltp:

            ltp_book += 1 / ltp



    return round(back_book, 4), round(lay_book, 4), round(ltp_book, 4)```

The rationale presented as ;

Key Changes:

1. Removed `try-except` Blocks:

    ◦ The original version used `try-except` blocks to catch `AttributeError` if the `available_to_back` or `available_to_lay` prices were not available. This can be inefficient in a loop.

2. Direct Checks for Price Availability:

    ◦ The optimized version directly checks if the `back` and `lay` prices are available using simple `if` statements, which is more efficient than handling exceptions.

3. Simplified Logic:

    ◦ Streamlined the logic to be more concise and straightforward, improving readability and performance.

By making these changes, the function becomes more efficient, especially in a real-time data processing context where

every millisecond counts



I've tested in back tests (all ok) and ran it live yesterday, all OK.

As I only know a very basic amount about Python, would any more experienced coders comment as to whether it is a positive change for the better? Thanks

*Tags: Errors Debugging, Performance, Deployment*

---

**Mo** - *12:45:22*

I agree with ChatGPT's comments - I'd rather explicitly check for usable data ahead of time than rely on try-except. While the latter I think is sometimes considered more "Pythonic", I still prefer the code-style of the former and there are performance considerations

*Tags: Performance*

---

**PeterLe** - *13:01:49*

Thanks [@UBS7QANF3](@UBS7QANF3) I hadnt thought of looking in your utils package. When I comapred your version with the ChatGpt version it stated that there were some pros ie :

(Where it states 'Your' it means betfairutils)

• Complexity: Your version adds a bit more complexity due to additional type checks and handling different scenarios (like the `Side.BACK` check). While this might be necessary for your specific use case, it can introduce slight overhead compared to the more streamlined version.

• Flexibility: Your version is more flexible in handling different data structures (like `PriceSize` objects and dictionaries), which can be advantageous if your data comes in various formats.

• Error Handling: Neither version uses explicit exception handling within the loop, which is good for performance. However, the reliance on external functions like `get_best_price_size` and `iterate_active_runners` means that error handling should be considered within these functions to avoid unexpected crashes.

• Readability and Maintainability: The use of type hints and clear separation of logic in your version can make the code more readable and maintainable, albeit at a slight cost to performance.

and conclusion ;

Conclusion:

• Performance: The streamlined version I provided is likely to be slightly faster due to its simplicity and direct approach. However, the difference might be marginal depending on the implementation details of the helper functions you use.

• Applicability: If your codebase frequently deals with different data structures for market data or requires additional checks like the `Side.BACK` logic, your version could be more suitable despite the potential slight performance trade-off.

So it may suit the more accomplished/better programmer than me (mine is just very basic stuff)? Ill need to just try and understand it better really and see if it would benefit me?

Hi [@UUCD6P13J](@UUCD6P13J) no ive never used cprofile before. Is it worth learning as a relative beginner or is it more intended for the advanced programmer?

*Tags: Getting Started, Errors Debugging, Performance*

---

**Mo** - *13:07:21*

Again, I think the comments are fair. betfairutil code is primarily designed to be readable, defensive, and composable with less emphasis on performance.



My function wouldn't give you the book percentage based on the last traded price and there's probably not a trivial way to do so using other betfairutil functions so I think it's entirely reasonable to keep using your function/ChatGPT's optimised version of your function.



I'm just always on the lookout for feedback on betfairutil.

*Tags: Performance*

---

**Lee** - *13:10:18*

Entirely depends on your goals. If you want to optimise for speed/latency it’s essential. You need to have a baseline measurement to know where the bottlenecks and if your changes actually make any difference otherwise it’s just guesswork.

*Tags: Performance*

---

**ShaunW** - *13:48:21*

Didn't know that [@UQL0QDEKA](@UQL0QDEKA) I use 4.5 and it told me I couldn't give it a whole project? Fully compiled [@UUE6E1LA1](@UUE6E1LA1) I don't have any special setting for the compiler. With placement being anywhere from 80ms to 170ms I spend more time on improving the strategy than trying to shave off half a millisecond. I process market change messages and orders asynchronously anyway so not struggling for speed too much.

*Tags: Performance, Strategies*

---

**PeterLe** - *14:35:35*

Yes you have to drag and drop the zipped folder Shaun ;

I asked ;

You

if i were to upload it can you understand a full C# solution





ChatGPT

Yes, I can understand and analyze a full C# solution. If you upload the files, I can review the code, answer questions about it, suggest improvements, or help with debugging. Please ensure that the files are in a format that I can access, such as a ZIP file containing the solution and its associated project files.

*Tags: Errors Debugging*

---

**PeterLe** - *14:52:41*

Thanks for your help folks; helps keep it interesting as a beginner :+1:

*Tags: Getting Started*

---

## 2024-01-19

**PeterLe** - *12:47:29*

[@U0128E7BEHW](@U0128E7BEHW), [@UUE6E1LA1](@UUE6E1LA1), [@UEA14GBRR](@UEA14GBRR), you guys seems to know C#...do you mind if I ask a question please?

One of the applications Im running is an old version...its been chugging away for years so reluctant to change really...

However I got this feed back from ChatGpt :

Usage of HttpWebRequest: The code snippet shows the use of `HttpWebRequest`. While this is still a valid class in .NET, it's considered somewhat outdated compared to newer HTTP client libraries like `HttpClient`. If not already updated later in the code, consider using `HttpClient` for more efficient network operations and better support for asynchronous operations.

-----

in your view, would you think this a priority to change to HttpClient ?

(It may well be that the outdated version is successful because it is slower perhaps, so if I did update, maybe Id run AB tests  old v new etc)

Anyway, Id welcome your thoughts please? (Im wondering if its a no brainer to update to asynchronous?) Thanks

*Tags: Performance*

---

**birchy** - *13:04:52*

The streaming stuff would be through a socket, so http client (like python requests) would only be used for polling stuff like login, get balance, etc?

*Tags: General Technical*

---

**D C** - *13:07:16*

I don't "know" C# really [@UQL0QDEKA](@UQL0QDEKA) - I just work with compiled languages rather than interpreted languages (hence the earlier question). While updating can be a good thing, if you've been running an app profitably for YEARS, why risk changing it? Maybe base a new app off the old code, update all internals then run it with a different strat (with roughly same bet placement density) and compare bet placement latencies and see if there is a significant difference? Then if you notice a change (for the better) consider upgrading the old app?  Using 3rd party closed source components is always tricky - quality of documentation can vary! I was burned heavily in 2022 using a 3rd party async HTTPS component that I had failed to read the small print for.

*Tags: Errors Debugging*

---

## 2024-01-20

**AndyL** - *19:27:45*

[@UQL0QDEKA](@UQL0QDEKA) i had a serious performance issue a couple of months back and i used cprofilev and reduced my processing time by a factor of 5, it’s really easy to use

*Tags: Performance*

---

**Ralegh** - *23:06:55*

That’s bizarre, did anyone tell them you can run python without an ide?

*Tags: General Technical*

---

## 2024-01-21

**Ralegh** - *09:15:38*

Seems to be, again weird the lack of tech knowledge, you’d assume they didnt write much of the code themself, maybe someone who kept strategy code from a firm (maybe a crypto firm that went bust like alameda)

*Tags: Strategies*

---

**Ralegh** - *10:14:59*

Depends who you believe, Michael Lewis says they were extremely profitable (without customer funds) and that their traders were pretty arrogant about it. Their first big trade was a mass crypto cross-exchange bot and the twitter post seems to be operating on several exchanges. I think traditional quant firms have taken that over now, and I’ve heard of one team at a HF who made billions over the last few years doing that (with more complex strategy ofc), so there was definitely profit to be made before competition arrived. 

*Tags: Strategies*

---

**Ralegh** - *10:36:04*

Significantly higher startup costs though, and you can only make that money on the best fee tiers. Like you need probably $1-5M for data and model calibration (compute costs on 5 years of tick data across 100 symbols, 30 exchanges), these guys are at HFs so they have much more support. Models meaning you need to have short term price forecasts which is where (I assume) a lot of the alpha is, and that requires tons of signal research. Then you need to be doing probably $100M-$1B or more monthly volume across the exchanges to get low enough fees to be profitable. 

*Tags: Strategies*

---

**Ralegh** - *10:37:44*

These guys can bring models from tradfi that have been in development since years before crypto exchanges even existed. 

*Tags: Strategies*

---

**Jonjonjon** - *10:38:02*

Surely the models required are very different?

*Tags: Strategies*

---

**Ralegh** - *10:41:06*

I assume they’re mostly looking at LOB and trade data, and you should be able to calibrate that to crypto, there’s probably some idiosyncratic differences like order types on exchanges but that might be fixable with small changes or through the calibration. 

*Tags: Errors Debugging*

---

**Ralegh** - *19:23:32*

Jiggling about with servers to get a good connection is a valid strategy 

*Tags: Deployment, Strategies*

---

**Jonjonjon** - *19:46:22*

This is what I get from a grep on my logs. Is that latency value how long it takes to place the order?



```cat my_log_file.txt | grep execute_place | grep -o -P  '\"latency\"(.*?),'

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0043,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0045,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.026,

"latency": 0.0003,

"latency": 0.0006,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0004,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0042,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0045,

"latency": 0.0034,

"latency": 0.0001,

"latency": 0.0053,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0027,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0028,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0005,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0027,

"latency": 0.0073,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0044,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0171,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0033,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0,

"latency": 0.0002,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.005,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0092,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0006,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0073,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0004,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0006,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0073,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0019,

"latency": 0.0057,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0035,

"latency": 0.0003,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0,

"latency": 0.0,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0043,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0055,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0003,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0165,

"latency": 0.0001,

"latency": 0.0002,

"latency": 0.0001,

"latency": 0.0001,

"latency": 0.0001,```

*Tags: Performance*

---

## 2024-01-22

**Paul** - *15:33:19*

The brakes Betfair apply to latency sensitive strategies are called “transaction fees”. :joy: We have all paid them and moved on. :clown_face: If you’re a millisecond faster than the next guy, good for you, but just remember EV extracted through exploiting low latency is hard to keep as an advantage, as it’s the easiest capability to “just” spend money solving for. Only a matter of time before someone is consistently a nanosecond faster than you.

*Tags: Performance*

---

**foxwood** - *16:10:00*

Bored so thought I'd try that ping on my new Irish Lightsail server - it's meaningless for what I do but shows that milliseconds are too coarse for latency measurement these days

`Approximate round trip times in milli-seconds:`

    `Minimum = 0ms, Maximum = 1ms, Average = 0ms`

*Tags: Performance, Deployment*

---

**Jonjonjon** - *16:15:11*

What is RTT? The numbers are from a Flumine log file.

*Tags: General Technical*

---

**Paul** - *16:25:23*

It’s from flumine logs, pretty certain it should be RTT of the api operation. When you’re just pinging the servers from the command line you’re getting a different (lower, faster) RTT down in the ICMP. Coincidentally the original inventor of ping (and ntp), died last week.

*Tags: Deployment*

---

**Paul** - *16:38:09*

If your EV is latency dependent, possibly awful. If you’re not, it’s less thank a blink of an eye and you’re miles ahead of the betangel lot. :shrug: 

*Tags: Performance*

---

**Paul** - *16:42:08*

Also might be worth looking at the distribution of latencies. [@U4H19D1D2](@U4H19D1D2) posted about being non-profitable at 250ms added latency the other day. If you were running that strategy with p95 +/- 10ms, you’d be probably fine. But at p99 +/- 500ms, maybe not…

*Tags: Performance, Strategies*

---

**liam** - *19:15:22*

That is place, cancel or replace latency which has an overhead on the betfair side 

*Tags: Performance*

---

## 2024-01-23

**D C** - *21:20:01*

Yeah I agree. I suppose it is probably easier if you are focused on one out of the stalls, but picking one out of the pack at a quick glance seems like it has a lot of potential to get wrong.  I don't know much about how these inplay manual lads go about their business anyway though.

Makes you wonder what proportion of bets matched are the result of a manual error.

*Tags: Errors Debugging*

---

## 2024-01-27

**ShaunW** - *15:36:27*

I'm trying to fix my broken Countal Slide loop.

*Tags: Errors Debugging*

---

## 2024-01-28

**liam** - *21:07:03*

Doesn’t really answer your question but the price is different enough between scheduled and actual BSP that I doubt it’s that accurate 

*Tags: General Technical*

---

## 2024-02-02

**Jonjonjon** - *20:29:38*

I had a go at fitting Poissons models a few years ago, but my methodology didn't lead to strong returns.

*Tags: Strategies*

---

## 2024-02-03

**Paul** - *11:39:19*

Transformer architectures are coming for time series forecasting. [https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html|https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html](https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html|https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html) 

*Tags: Strategies*

---

**Herugrim** - *12:27:26*

It’s just NSW tracks that are the problem for both awful MBR and turnover charge. They’ll have an MBR of 10. The rest of Aus is 7. 

*Tags: General Technical*

---

## 2024-02-04

**Paul** - *09:11:55*

Few people need to actually build these things, you want to use someone else's model. What made me curious about this one - due to be released later this year - is that its trained on "100 billion" time series data points, which I think is relatively small, and it includes some "public domain financial series". Is that going to be good enough to make predictions on price movement on betfair? Will be interesting to see.

*Tags: Strategies*

---

**Paul** - *09:13:46*

A few months back there was a release of some time series model or another, and the orange website was full of people saying "we've given up on ML approaches to time series - it's all rubbish, just do some moving averages, it's useful", which surprised me, although I've not dived in much yet into that stuff yet (but planned to)

*Tags: Feature Engineering, Strategies*

---

**Jonjonjon** - *09:28:58*

Can that timesfm model be downloaded? If so Google for it, I just find the article you shared above

*Tags: Strategies*

---

**Paul** - *16:42:34*

Not yet, the article suggests they're releasing it later this year after they've done the usual ethical and moral rails tweaking that all these models need to go through these days.

*Tags: Strategies*

---

**Jonjonjon** - *17:05:14*

Are there other pre trained models available to try? Apologies but I have little experience in the use of pre trained models.

*Tags: Strategies*

---

## 2024-02-05

**James** - *09:41:02*

Would anyone be open to contributing/helping fund a shared data pool for the sake of backtesting?

Something formatted specifically for flumine, market catalogues, historical data etc?



I feel like we’re likely all recording the same data, and going through the same pain of pulling/zipping/managing/paying to store the data in s3 and alike, and the pulling and unzipping and backtesting. Surely there is some demand here for a simpler way to do it where you can just point and shoot, a paid flumine plugin/addon to cover the data charges and storage costs.



I haven’t at all looked into the ts&cs on this stuff so probably couldn’t even if there is demand but surely this (like flumine) seems something to build once and share.

*Tags: Data Quality*

---

**D C** - *09:46:11*

I'd be surprised if this doesn't breach T&amp;C to be honest. For example, I've been logging horses and dogs for years. But tomorrow I might fancy analysing football and the only way I could do that is to buy historical data. If this were setup, I could just piggyback other users historical data. Surely it's no different to data sharing?

*Tags: Getting Started, Data Quality*

---

## 2024-02-09

**PeterLe** - *12:15:50*

I'm not sure how to use this :

`customer_strategy_ref`

I take it if you are running more than one strat on a single account, you can set it within the strat eg laysys1, laysys2 then when looking at results you can determine the results of each strat. Is that how you guys use it?

if so how/where do you set set it?

Sorry I know its a basic question, but if you don't know you dont know :grinning:

Thanks in advance

*Tags: Strategies*

---

**Alex A** - *12:18:54*

It’s also useful if you have multiple strategies that might bet independently on the same market, and you don’t want them messing with bets from another strategy.

*Tags: Strategies*

---

**Alex A** - *12:20:15*

By filtering the order subscription to a set of strategy refs.

*Tags: Strategies*

---

**liam** - *12:24:08*

Is this in reference to flumine Peter? As we use it to isolate individual running instances and not strategies 

*Tags: General Technical*

---

**PeterLe** - *12:44:02*

Thanks Alex,

Yes for use with Flumine Liam. So if I have a single instance (running on one account) with say 5 strats, you cant set the customer_strategy_ref per strategy?

In that case (and assuming you are running on one account) would you have five separate instances each with the customer_strategy_ref set for that instance only?

hope that makes sense? Thanks

*Tags: Strategies*

---

**liam** - *12:46:16*

No, flumine is designed for you to use logging control to store your order data and you should ignore the strategy ref

*Tags: Strategies*

---

**PeterLe** - *12:57:04*

Right I need to learn how to do that then :grinning:

( i have the notes set up already)

Thanks Liam

*Tags: General Technical*

---

**ShaunW** - *14:34:14*

Sounds like you guys use logging as some sort of temp db?  Why don't you just stick the CustStrategyRef on the orders? There's clearly a good reason for the flumine way, it but I can't see it.

*Tags: Strategies*

---

**D C** - *15:25:32*

I used to find strategy reference string a really useful thing but it ultimately ended up hampering my performance and in conjunction with other things, cost me a lot of money.

I don't use it at all now and just use distinct suffix per strategy on customer order reference strings to distinguish between strats. You live and learn...

*Tags: Errors Debugging, Performance, Deployment, Strategies*

---

**PeterLe** - *17:17:43*

Thanks [@UUE6E1LA1](@UUE6E1LA1) that interesting. I like to think my stuff is like a caterham 7, chassis and an engine no mod cons :grinning:

mind you im still getting a mini performance so we will see :grinning:

*Tags: Performance*

---

## 2024-02-12

**D C** - *13:19:31*

This is an unusual question and I will try to keep it brief. Applied for mortgage with partner as an unemployed person (technicallly true). Large deposit, mortgage approved by lender no problem, but conveyancing solicitors want evidence of winnings from Betfair account. I've provided what I have (12 month P&amp;L screenshot from account and what account statement you can get from web pages) but I suspect that more evidence will be required.

I don't have an account manager, so could anyone suggest a contact within Betfair that I could try if I need something from them confirming profits?

Anyone else had this issue before?

*Tags: General Technical*

---

**Gooat** - *13:32:41*

Had the recent questionnaire from Vanguard? [@U4H19D1D2](@U4H19D1D2)

*Tags: General Technical*

---

**D C** - *13:41:10*

I'll see how it pans out. If they want more and BF are unwilling to help out  then they can take it or leave it  I guess.

*Tags: General Technical*

---

**ShaunW** - *14:56:22*

CS used to provide letters stating your PL but I'm not sure they do now.  What some do (incl me) is try to withdraw a regular monltly amount on the same day, although choosing a figure is hard when you know how it can fluctuate.  That regular income usually enough for basic checks but mortgages are a different prospect.



You say you suspect more will be required, suspicion might not turn into a problem. It's money laundering requirement so you just have to prove it's legal rather than proving its 'legitimate' in any way.

*Tags: General Technical*

---

## 2024-02-13

**Javier Martín Pérez** - *11:25:55*

Yeah someone from Betfair told me they had produced such statements in the past and wouldn´t have a problem producing a new one, but that was around 2 years ago so not sure if that changed.

*Tags: General Technical*

---

**AndyL** - *19:21:53*

Ooo [@UEA14GBRR](@UEA14GBRR) the question begs on how you measure turnover!!? Lay stake or liability….

*Tags: General Technical*

---

**AndyL** - *19:28:02*

Yeah me too, but it always generates a great conversation that question :-)

*Tags: General Technical*

---

## 2024-02-15

**D C** - *16:42:33*

Part of the motivation for my question is to look at ways to legitimately bet in other countries. I'm very concerned that the UK gambling industry is going to shit itself thanks to the interference from the UKGC. I regularly lose £1k + a day and without a job I will trigger one of these affordability checks. With no real employment, I will fail such a check and run the risk of having my account closed. I realise nothing is set in stone yet but I don't want to wait for it to happen before coming up with ideas to perpetuate my ability to keep on doing this.

*Tags: General Technical*

---

**D C** - *18:18:41*

I think maybe read the white paper - if it passes in the form it is in currently, then I see myself (any maybe others) having problems carrying on in this game. UKGC seem to want to base it all on losses rather than deposits but it that reverses we will all likely be fine. Fingers crossed anyway.

*Tags: General Technical*

---

## 2024-02-17

**D C** - *22:42:34*

Yeah there was an update to include fence distances for jumps races. Can't seem to find the documentation anywhere. Must be on an old machine somewhere.

*Tags: General Technical*

---

## 2024-02-19

**Unknown** - *16:57:24*

The last drinks inspired me to turn a flat strategy into a profitable one based on the last 13 days of data, so it pays for itself if you're prepared to think a bit about what people are saying. :slightly_smiling_face:

*Tags: Strategies*

---

**Paul** - *17:43:20*

It’s normally half a dozen, but still early days. Problem with bigger meets is getting them organised around content. Will discuss tomorrow a possible Spring meetup.

*Tags: General Technical*

---

## 2024-02-26

**D C** - *19:05:48*

No bets placed. That is rare unless the feed is down or had severe errors.

*Tags: Errors Debugging*

---

## 2024-02-27

**PeterLe** - *21:03:09*

Maybe someone can give me a steer on this please...

Within my strat, order object I have this code ;



```trade = Trade(

    market_book.market_id,

    runner.selection_id,

    runner.handicap,

    self,

    notes=collections.OrderedDict(

        {

            "back_odds": back,

            "lay_odds": lay,

            "last_price_traded": runner.last_price_traded,

            "publish_time": market_book.publish_time,

            "overround": back_book,

            "underround": lay_book,

            "race_type": market_book.market_definition.race_type,

        }```

I can see the information is being captured and Id like to be able to start looking at this in more detail. (maybe a database perhaps)

Q: At the the time the data is being captured, how do you save it? Is it stored in memory, a file or output to something else

I just wondered whats the best way so I can start to learn, if you could just point me in the right direction that would help..I can pick it up fom there

Thanks

*Tags: Performance*

---

## 2024-02-28

**Peter** - *12:00:04*

What [@UUCD6P13J](@UUCD6P13J) says, and yes a database. I write the orders to it when they're placed and my logging control then dips in again to update those records with the result whe the market it settled. because logging controls are threaded there's unlikely to be any impact on the performance of your strategies when making calls to  the database, even if it's remote (as mine is).

*Tags: Performance*

---

**PeterLe** - *16:55:05*

Thanks Peter. I was thinking about this last night after Lee sent his message

I did something similar when I was going down the ML path, ie I was running the backtest against recorded markets and out putting the bits i was interested into a CSV...then into Pandas. -&gt; ML etc

I wasn't quite sure i this was the way to do when running live strategies and if that was the right way of doing it etc

Thanks for the pointers

*Tags: Feature Engineering, Deployment*

---

## 2024-02-29

**D C** - *13:29:57*

Ahhh thanks for this. I can see several entries market "Fix" and "Error". I guess it is that.

*Tags: Errors Debugging*

---

## 2024-03-03

**Mo** - *18:41:08*

Can’t you easily answer this question with the data you scrape?

*Tags: General Technical*

---

## 2024-03-08

**PeterLe** - *17:10:10*

Quick question please: What maintenance if any should we be doing periodically on Flumine ?

Ie should we be clearing out logs etc as part of good practice; Anything else?

Thanks for any info/advice

Sorry for basic question! :confused:

*Tags: General Technical*

---

**Paul** - *17:22:21*

I’m willing to wager a pint that some people here haven’t typed `pip install flumine --upgrade` in a long time… :slightly_smiling_face:

*Tags: Getting Started*

---

**ShaunW** - *18:44:48*

Usual caviat about flumine exposure [@UQL0QDEKA](@UQL0QDEKA) but my view would be to start each day the same, cleared logs, archived data, clock set, ie everything just like day 1. Then it should theoretically run indefinatly. All Mrs W needs to do is change the logon/api key, pay AWS, and it should keep paying out should the worst happen without any interaction with it. :wink:. Automation init, needs to be automated.

*Tags: Deployment*

---

**PeterLe** - *21:42:44*

hi Shaun, Yes i do those keys things but i couldnt find the logs for Flumine :grinning:

nice avatar! :grinning:

*Tags: General Technical*

---

## 2024-03-09

**Dave** - *15:33:05*

Only updated my flumine recently from 1.21.4 (2021 or early 2022 i think)...frightening experience to say the least. write good tests people !

*Tags: General Technical*

---

## 2024-03-11

**ShaunW** - *12:34:18*

You've got the same problem as the bingo addicts in the Gala advert, you're seeing references everywhere you look:wink:.

*Tags: General Technical*

---

## 2024-03-17

**Mo** - *21:13:35*

But I know the organisers and they're legends within the football modelling space (e.g. [https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9884.00366](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9884.00366))

*Tags: Strategies*

---

## 2024-03-20

**Michael** - *17:21:55*

If you tell them that they will smell an opportunity, ask you a lot of questions and offer you all kinds of investment products. You can say "no thanks" but it'll extend the discussion. My bank account manager courtesy calls me periodically and I basically just get her off the phone as fast as I can as I don't want to talk about where my money comes from but I also don't want to get quizzed and look shifty trying to tell lies. Banks have been closing a lot of accounts recently on the slimmest of concerns because they're so worried about money laundering and proceeds of crime. Gambling is a real red flag for all that. My own policy is never to mislead, but also to keep a low profile. That and to keep accounts with a few different banks just in case.

*Tags: General Technical*

---

**ShaunW** - *17:47:34*

.... you'll get somewhere without being interested, but it undoubtedly helps if you are.

*Tags: General Technical*

---

## 2024-03-21

**Johnny** - *10:26:24*

I've got HSBC Premier and just transfer a few grand in and out of it each month from other accounts, and have used it for crypto (directly) and betfair (via paypal).  Never had any questions asked

*Tags: General Technical*

---

## 2024-03-22

**Johnny** - *10:56:05*

Does the name flumine rhyme with "blue - sign" or "blue - queen" or "thumb - inn" ... etc?

*Tags: General Technical*

---

**Derek C** - *16:42:28*

someone should phone these people and see how they pronounce it when they answer: [https://pablobuttice.com/en/flumine-north-beach-miami/](https://pablobuttice.com/en/flumine-north-beach-miami/)

*Tags: General Technical*

---

**ShaunW** - *22:11:14*

I say flu-mean but it's Liam's word so his choice :wink:

Or.... How do you pronounce 'flumine' it's a faux Latin product name. 



ChatGPT

"Flumine," if treated as a Latin-derived word, would likely be pronounced with a classical Latin pronunciation, which could sound like "FLOO-mee-nay." However, given that it's a modern, faux Latin name, an Anglicized pronunciation like "FLOO-mine" might also be common. The choice often depends on the preference of the creators or the commonly accepted pronunciation among its users.

*Tags: General Technical*

---

## 2024-03-25

**D C** - *12:14:48*

As I said, until a chat a few months ago with Lee I never even calculated ROI at all. I've no doubt there is lots of room to improve. I'm sure my execution is naive compared to most but my models just don't perform well backing under 2.0 for some reason.

*Tags: Strategies*

---

**Michael** - *12:20:04*

I don't think that struggling to find value shorter than 2 needs to be a big problem, there's plenty of money elsewhere in the market. I would just focus on that and worry about shorter prices another time.

*Tags: General Technical*

---

**Unknown** - *12:31:43*

Example here of a strategy where I focussed on removing the neg ev bets at the same time prioritising less bets over total profit, bottom graph is ROI which nearly doubled over 6 months ish

*Tags: Strategies*

---

**ShaunW** - *13:27:22*

Very interesting. I've recently started running an in-running strategy ( everything prior had been pre-race and small edge/high volume) . I've been getting iro 15%+ vs < tenth of that pre and I thought it was wildly unrealistic and unsustainable. Maybe not.    



Biggest difference though is that without a benchmark to measure EV I'm at the mercy of results which is a novelty. I don't usually care what the cash is so long as the underlying EV is there. 



All good fun though, I was bored to death with pre and in-running has been a nice change.  ..... But it's come about cos I improved/rewrote my results analyser, tested it on some 3year old backtest logs I still had, and it revealed a parameter tweak that made it profitable.  :face_with_rolling_eyes:

*Tags: Strategies*

---

**ShaunW** - *14:02:18*

Thx [@UGV299K6H](@UGV299K6H), need to wrap my head round that. But lots of bets so results aren't fluctuating as much as I thought they might. Yes it's small vol, I haven't coded up the TPD stuff as it's not as simple for me as it is in Flumine.  %complete is all I need from it (obv so far it doesn't use data it wasn't getting) , but my duration algo isn't too bad as it is and it's early in the race so duration accuracy isn't a big deal.

*Tags: General Technical*

---

**Michael** - *14:08:34*

It's only really useful in certain circumstances, but say you need to analyse the relative performance of two groups of back bets at long odds; if you do that just by using the final result then you'll miss a lot of data because you might be missing out on a lot of bets that nearly won and seeing your results skewed by just a few that made it over the line by a nose. If you pseudo-settle all bets according to whether BATB &lt; 1.2 at any point after your bet matches  then you can capture much richer data and make a better comparison between the groups.

*Tags: Performance*

---

**ShaunW** - *14:25:55*

Assume nothing.. ,.it helped.

*Tags: General Technical*

---

**Michael** - *14:43:35*

....but yeah I guess if you had a model that out-performed price in all situations they you could evaluate according to whether win-probability &gt; x at any point before finish.

*Tags: Strategies*

---

**liam** - *15:42:01*

I had to look that up, my comments are more to question the strategies / staking / analysis he is applying if pnl is volatile 

*Tags: General Technical*

---

**Michael** - *16:49:42*

Ok so if you took it to an extreme then you could see total profits tail off if you demanded too much margin but in practice that's never the problem.

*Tags: General Technical*

---

**D C** - *16:53:05*

I think my biggest problem is with staking and exposures to be honest and this is why I do get battered on occasion. Model prices change, but it is still a mystery as to how best spread my exposure across the duration of the race (do you go apeshit on value once they are first out of the gate or save some exposure for later for example). This of course is related to staking as I know that for certain points in the race my models perform better than at others. I think if I had a model that was flawless from start to finish in the race life would be easier but thats never likely to happen to me. I've done things similar to [@U4H19D1D2](@U4H19D1D2)’s chart above where I retrospectively "prune" future bets based on finding parameter ranges on old bet histories which do badly. I do suffer from having too many different strategies running simultaneously and I do not truly understand how they interact with one another (be that positively or negatively)

Maybe I should strip things back a bit and go for lower and more stable returns.

*Tags: Strategies*

---

**Michael** - *16:59:25*

[@UUE6E1LA1](@UUE6E1LA1) I think that's what a lot of players look like (I know 'cause they dm me) and it's the essence of the problem that I'm getting at. Without seeing exactly what you're doing one can't be precise but my instinct just looking at what you're saying is that you should probably just rein it all in a bit. Bet where you know you're most profitable at slightly below what you hope is the optimum stake and if you want to try ideas to expand your opportunities then do it very minimally with the smallest stakes, tracking net profit against stake when/if you scale up. It doesn't pay to rush in this game, try stuff out very softly.

*Tags: General Technical*

---

**D C** - *17:07:10*

Yeah that does make sense, but the trouble is you don't know that the race will evolve that way until it is in action. I never bet when I expect to lose - I think its related to exposure. I won't know that the 6/4 favourite hits the front and never get challenged until the race is done - doesn't mean that the bets I've placed on the rest of the field were not value at the points where the model thinks it is value.

*Tags: Strategies*

---

**D C** - *20:15:47*

I don't know what to say - my models are based purely on fundamentals and at plenty of stages they will see what it considers to be value. Based on your suggestions though I guess if I want to reduce profit volatility I might want to apply some market based filtering on top of things.

*Tags: Strategies*

---

**Michael** - *20:30:26*

[@UUE6E1LA1](@UUE6E1LA1) You're just looking for something that separates better bets from less good bets, that could be something to do with the way you're analysing the race or it could be something to do with the market conditions, or something else like understanding that your model only out-performs the market at certain stages of the race, anything as long as you can show it with reasonable confidence and it makes sense. Once you've got that in place you can go back and look at your other variables and see if they predict profit, if they don't then you ditch them. That way you can continually drive up your margin without your volume trending towards zero.



I'd have to say that I don't think reducing profit volatility is a goal in itself as it will mostly come down to the odds you're betting at. The better goal is just to drive up margin however you measure it.



[@UEA14GBRR](@UEA14GBRR) from my experience going for a lot of bets at low EV pretty much the worst thing you can do in running. You'll get hammered by adverse selection and you'll be continually rigging the market against yourself by not letting value develop where it might otherwise have done.

*Tags: Strategies*

---

## 2024-03-26

**AndyL** - *21:50:28*

pandas errors can be so cryptic, just trying to "bin" a DataFrame, what am I not understanding?

```   selection_id         BSP  winner  

0      41569073    2.129299   False  

1      61343324    2.640000   False  

2      26741931   14.107778   False  

3      61939657   55.000000    True  

4      62819706  120.000000   False  

---&gt; 29 df['bsp_bin'] = pd.cut(df['BSP'], bins=4)

TypeError: putmask: first argument must be an array```



*Tags: Errors Debugging, Feature Engineering*

---

**AndyL** - *21:59:25*

suspect there's something wrong with my df, if I do a noddy test it's fine, but tying to read df from a csv, gets above error, even though df shape and dtypes look good...

*Tags: Errors Debugging*

---

**AndyL** - *22:20:24*

yeah, rookie error, did'nt dropna

*Tags: Errors Debugging*

---

**Gooat** - *23:25:38*

Love / hate pandas / jupyter

*Tags: Feature Engineering*

---

**Ralegh** - *23:28:43*

I’m enjoying using dicts of numpy arrays and numba njit to write manual transformations these days (though I used a narrow subset of pandas functionality)

*Tags: Feature Engineering*

---

## 2024-03-27

**Ralegh** - *08:40:00*

Yeah mostly before fit in research code, e.g I might have a big df with histories for some horses - if you wanted a value from 5 rows ago as a feature you could do a pandas groupby then shift, with numpy it’s a little tricky, but with numba you can have def group_shift(group_ids, values, offset) which manually  does the bounds checks and it’s still very fast (probably faster than groupby)

*Tags: Feature Engineering*

---

**D C** - *15:10:16*

Anyone experiencing problems today? I've had a total of 4 different bots running on distinct servers ALL crap out at around 13:30 today. NO_SESSION and HTTP 400 errors amongst other things?

*Tags: Errors Debugging, Deployment*

---

**AndyL** - *22:11:03*

1month of record gb racing data to Pandas csv == 16Million lines !

*Tags: Feature Engineering*

---

## 2024-03-28

**AndyL** - *09:41:13*

Yeah that’s my issue, ive got a noddy bit of pandas and reckon it will take 12hours to run !

*Tags: Feature Engineering*

---

**PeterLe** - *09:48:07*

I was just looking at some notes I made when I looked at this.

```# Random Forest Accuracy: 0.9120607771513096

# Total Profit/Loss using Simple strategy: £-193834.88816246387

# Total Profit/Loss using ML strategy for sys4: £17935.374273080262```

I found out other things too that Ive never considered before. One is so obvious now but Id never noticed it.

Just enjoy the journey!

*Tags: Strategies*

---

**ShaunW** - *13:17:18*

Design a more efficient test? Or just use every 3rd or 4th update. ML is just analysis, a guide, so doesn't need the resolution a simulation does.    Modern hardware speeds means loading everything or just running backtests has become de regueur,   but reintroduce some of the forgotten methodology that makes analysis a distinct disciple in itself.   We had terabytes of data back in the 90s and pathetic hardware, still managed to develop strategy without waiting a month for a figure.

*Tags: Performance, Strategies*

---

## 2024-03-29

**AndyL** - *12:31:19*

optimized my pandas vector processing, should process the 16M row input in a mere 18hours :slightly_smiling_face:

*Tags: Feature Engineering*

---

**JL** - *13:01:56*

depending on what operations you do, might be worth checking

[https://github.com/thedataincubator/data-science-blogs/blob/master/sqlite-vs-pandas.md](https://github.com/thedataincubator/data-science-blogs/blob/master/sqlite-vs-pandas.md)

*Tags: Feature Engineering*

---

**AndyL** - *16:18:08*

just the standard pandas &amp; numpy, matplotlib, don't know half those others, they tend to suit specific tasks...

*Tags: Feature Engineering*

---

**AndyL** - *16:19:03*

anyway i've fixed the bathroom sink this afternoon while it's been churning.... so not all bad :smile:

*Tags: Errors Debugging*

---

**Oliver** - *18:31:37*

numba is good if your code is slowed down by the python logic gluing all the pandas bits together (assuming you can't just use pandas more efficiently), so you can use something like `@numba.jit` to compile some block of code into machine code without you having to deal with it much. Its unlikely to be of huge value to you right now if pandas and numpy are new to you though as it is usually the use of pandas that can be improved most first.



PyArrow can be used as an alternative backend/storage engine for pandas, it has some merits, in particular if you write your data to disk and read it back later. Still fairly new in pandas so could be an excuse to avoid it as well, but it can read a CSV in parallel and be a lot faster.



I'd have thought you could get a fair bit more speed out of of pandas/python if you wanted as 250 rows a second sounds fairly slow to me so I imagine there's other places you can get speed first. I'd recommend profiling a run with a subset of data using [https://github.com/P403n1x87/austin?tab=readme-ov-file#synopsis|austin](https://github.com/P403n1x87/austin?tab=readme-ov-file#synopsis|austin) and then viewing the results with [https://github.com/jlfwong/speedscope?tab=readme-ov-file#speedscope|speedscope](https://github.com/jlfwong/speedscope?tab=readme-ov-file#speedscope|speedscope). This is probably to key combination I've found for optimising this kind of code.



Then again it sounds like you/your house benifits from the processing time [https://xkcd.com/303/](https://xkcd.com/303/)

*Tags: Getting Started, Feature Engineering, Performance*

---

**Jonjonjon** - *21:11:27*

I'm not sure what you're doing, but using Flumine to scan over and pick out bits of data (such as the full ladder at very minute for the last hour)  would take under 90 seconds on modern hardware.

*Tags: General Technical*

---

**AndyL** - *21:25:27*

so yeah it is slower than I was hoping!

so the obvious problem is no-one is going to tell you "Alpha"

so i'm trying to calculate various features and various "triggers", then plot various plots to see how such features &amp; triggers vary against other features, with a hope of finding "Alpha" :slightly_smiling_face:

*Tags: Feature Engineering, Performance*

---

## 2024-03-30

**AndyL** - *13:24:50*

I must say I find there's a knack of writing pandas stuff, for example I want to create the cumsum() of one column and write it into a new column. I know this can be done in one line, but I don't currently know what that one line is...?!

*Tags: Feature Engineering*

---

**ShaunW** - *14:42:43*

Focus on answering specific questions rather than all that 'various' scattergun stuff and youll be able to design a far more efficient extracts to work with. Sounds like a problem with your steering rather than horsepower.

*Tags: General Technical*

---

**Unknown** - *18:11:16*

i'm getting there.. this is looking more like it, although in reality i'm just honing my analysis/pandas/plots skills with this, and it's quite good fun!

*Tags: Feature Engineering*

---

## 2024-04-02

**Jonjonjon** - *18:12:06*

I would like a historic recording. Yes thanks I have already used docker stats but I think my Mickey mouse code is slowly increasing Ram and CPU over time. A historic recording will help me check this.

*Tags: Performance*

---

**Fab** - *20:52:02*

I suggest you use something like [http://phind.com|phind.com](http://phind.com|phind.com) to answer some questions to the AI.

*Tags: General Technical*

---

**Jonjonjon** - *21:12:50*

Ah it suggested I put that into a script, and use crontab to run the script. It is working now. Thank you for taking the time to help me!

*Tags: General Technical*

---

## 2024-04-04

**liam** - *19:52:46*

Yeah as above, sort of hinting at maybe the strategy is good but the execution is letting it down 

*Tags: Strategies*

---

## 2024-04-06

**river_shah** - *13:40:31*

That is a very interesting quant problem

*Tags: General Technical*

---

**Paul** - *13:40:37*

Most insurance under-writers can’t pay out everything hitting. It sometimes takes a bad beating as an industry (for example, Lloyd’s in the 1980s), but the model is mature enough nobody is going bust if everyone involved has done their maths and got the right excel spreadsheets. If that’s how they have positioned themselves in the sports betting market, good luck to them!

*Tags: Strategies*

---

**river_shah** - *13:47:40*

Ok so basically has to be a multi billion dollar bankroll to hedge this

*Tags: General Technical*

---

**river_shah** - *13:48:55*

Almost feels like a bank exotics desk problem

*Tags: General Technical*

---

**Ralegh** - *15:49:22*

I assume the margins are large enough that they can get away with models that are 70% of the way there and focus on having traders ticking up/down parameters like in OMM, I know SIG likes more manual/intuitive trading vs full systematic, though they couldn’t look at flow on millions of different combinations of multiples. They could model correlation between bet types in generic cases and have the traders tweak them for specific matches, then price based on those discounts

*Tags: Strategies*

---

## 2024-04-07

**Fab** - *22:36:58*

Also, if your automation runs on a Linux cloud server (for example an AWS machine), you can transform that into your personal VPN server.



This way you'd connect to Betfair from your smartphone/browser abroad via your own VPN which means using your usual IP address.

*Tags: Deployment*

---

## 2024-04-08

**Paul** - *08:13:36*

Or, you know, you could respect local laws. :-) 

*Tags: Deployment*

---

**Jonjonjon** - *09:10:03*

Sorry, my VPM question was in response to [@USWDY5P7G](@USWDY5P7G)'s suggestion that I turn my Linux cloud server into a personal VPN server.

*Tags: Deployment*

---

**Paul** - *09:13:47*

Well, wait a second. I would not run vpn software on the same instance as where my prod strategies are. Also, depending on how that server is set up (EC2? Fargate?), you might be trying to run a container inside a container. That’s potentially not great for a bunch of reasons.

*Tags: Deployment*

---

**Paul** - *09:17:01*

To be honest unless you have an explicit reason to not use something like NordVPN, and you can explain and quantify the impact of running it on your prod strategy instance you should probably just buy some vpn software or just enjoy your holiday and leave things running while you’re away. If you’re worried, switch things off for a week or two. 

*Tags: Strategies*

---

## 2024-04-09

**liam** - *18:29:12*

I spent a good chunk of time Nov-Feb applying what I do to racing and made progress however I spent 90% of my time getting very angry with the feed/betfair which they have now finally fixed. Turning over a decent amount per game but just waiting on more data before pushing things further 

*Tags: Errors Debugging*

---

## 2024-04-15

**D C** - *11:22:35*

"aspire to be bigger than Wetherhspoons". What a depressing business model...

*Tags: Strategies*

---

**Paul** - *11:23:07*

The best parts from the perspective of this group are how he got the job (he figured out how to market make in a game the bank setup, but in a way that others didn’t), and then how he made his money was stupendously easy.

*Tags: Getting Started*

---

**D C** - *14:43:42*

I've a quick question about PC. Each time PC is taken, is it simply X% of your winnings per week (where X is your personal rate) minus your generated commission for that same week? If so, does it include things like the australian turnover charges?

*Tags: General Technical*

---

## 2024-04-16

**Paul** - *09:15:00*

Last week I had 2 x transatlantic flights which had to be filled, and 2 x nights in a Crowne Plaza next to a strip mall. That helped. The rest of the time is not so easy, but I prioritise reading over a lot of other stuff. I don’t do social media, I rarely (couple of times a month) play games, I can only code for so long, most TV is dull so I’m coding or reading while sat on the sofa with my partner… I commute a day or two a week and audio book or kindle my way through that

*Tags: General Technical*

---

**Paul** - *13:56:44*

Found this [https://blog.abctaylor.com/what-would-happen-to-low-latency-trading-if-exchanges-moved-to-the-cloud/|blog thinking through what would happen if a stock market went full cloud](https://blog.abctaylor.com/what-would-happen-to-low-latency-trading-if-exchanges-moved-to-the-cloud/|blog thinking through what would happen if a stock market went full cloud) quite interesting, but interesting parallels to BF, et al. :thinking_face:  HN discussion thread is [https://news.ycombinator.com/item?id=40050717|here](https://news.ycombinator.com/item?id=40050717|here)

*Tags: Performance, Strategies*

---

**Paul** - *17:11:19*

The bit I picked up from it is if you’re dealing with an exchange where you latency is basically normalised (and, let’s face it, we are), it means that HFT isn’t really practical. And it isn’t in BF anyway because of transaction charges that eat away at profit unless your volumes are very lumpy. It’s interesting in fiscals they kind of dream to be in this situation to level the playing field. :slightly_smiling_face:

*Tags: Performance*

---

## 2024-04-17

**D C** - *16:54:42*

Remember Liam calling them an RNG which seems about right. Sky pics slow too which won't help when comparing to market.

*Tags: Performance*

---

**liam** - *20:14:32*

So anyone do this?



&gt; Smart quant crypto traders will spin up many thousands of EC2 instances, measure latency to the exchange, and only keep the best instances, continually. This process allows them to eventually get EC2 instances to trade from probably in the same rack, or maybe on the same bare metal box, as the exchange. 

*Tags: Performance, Deployment*

---

**Michael** - *20:19:53*

I had an interesting conversation once with one of the TPD guys about how they developed their prices model, he had been involved in trying to improve their early version which TPD had bought from a BF user. What I learned was that their target was to develop a model who's prices matched the BF prices, in other words they just assumed the BF prices to be true and assessed their model according to how well it replicated them. They didn't consider the prospect that the BF prices might not be true at all. I thought that was just wonderful.

*Tags: Strategies*

---

**Michael** - *20:50:02*

There are many obvious shortcomings but I can totally see why they did it that way. From the perspective of their prospective customers (bookies) the most important thing is to avoid creating opportunities for arbitrage with BF. The value of the bets can be generated just by apply an over round so the model needn't be intrinsically amazing. I can also see that trying to evaluate against actual outcomes would be a nightmare, especially given that the data set is relatively small. Still, I thought it was interesting, prior to that conversation I wondered if TPD had a model that could be simply deployed to out-bet us, but then I realised that they weren't even trying to make one. Their model has to generate accurate prices for every runner from start to finish, our job is much easier because we only have to be able to point and laugh when someone else is getting it wrong. The other interesting thing was that the developer wasn't interested in botting the markets himself. If I had access to his skills and resources I'd be all over that but it just didn't seem to be his bag, he seemed to think it was futile because BF prices are true, which is sort of right and wrong at the same time.

*Tags: Deployment, Strategies*

---

## 2024-04-18

**Alex A** - *01:59:54*

When I first start my process up, I measure the latency (publish time vs local receive time). and restart if it’s over some threshold.

*Tags: Performance*

---

**Justice** - *17:40:40*

I have a probabilistic model using the TPD data and biggest problem by far is the accuracy of the data...

*Tags: Strategies*

---

## 2024-04-23

**Brad** - *13:36:11*

They do lean toward MS. Which is funny now that so much data is handled simply in python. The pyspark book is good. PySpark is starting to gain traction.

*Tags: General Technical*

---

## 2024-04-26

**PeterLe** - *21:13:22*

A quick question please if someone can advise. I was looking at environmental variables (As I read on here that Storing App keys, passwords etc is best achieved via .env files?)

Is that so and if it is, How do you get around 2FA thats appended on the password? (hope that makes sense and I haven't misunderstood how its used).

I also notice that there is AWS Secrets Manager too?

If someone can give me a pointer on best practice, for storing and retrieving these key bits of data,  I can work it from there

Thanks



..Edit : Having read up a little, it seems this isnt an ideal way to go about it. So ill prob just input the 2FA's for each account manually..no big task really..

*Tags: Deployment*

---

## 2024-05-01

**PeterLe** - *14:30:58*

Thanks Chaps, I might give the Billy Walters a miss Paul!

I recently finished 'Algorithms to live by'...A bit of a mixed bag

There were some things that I will go back over but some sections/Chapters even that were a waste of time

(Helped me think more about Financial planning in future retirement) OK if you want to 'spend' an audible credit though

*Tags: Deployment*

---

**PeterLe** - *15:09:24*

Let me know what you think Mo when you have read it

I have Michael Lewis - Liars Poker which ive been meaning to read for a while (and permanent record - Ed Snowden..find it a bit slow TBH)

You might enjoy this too if you havent read it : [https://www.amazon.co.uk/Bitcoin-Billionaires-Genius-Betrayal-Redemption/dp/B07P75J5MW/ref=sr_1_1?crid=1DCLMGCYTZAG4&amp;dib=eyJ2IjoiMSJ9.RgdEWhLg_WhCKNfP4LIho-17nuVuZO-HTFZ_-Joey7rQUNOdo2bTIQSmuXj3fK6wgJE2wCZehwIDU8_cnnBLkokPR1TF6BUDBlhM-hQeawYTO9BZLrDt2d_y05RF9dkCJ314nKnyaEqOdmivBlW23yKx1a7FIjNokBibne2-uh4RHmzti6e7h69ZVSRYKSaZGPrIEh6uw4FPICZlS4Lag_-zw_TyfL6fwrXDypRbbcY.6EsP9U-reR_p1qmixo-_0Xi-uf7Y6_gU6R7R6f8WNCk&amp;dib_tag=se&amp;keywords=bitcoin+billionaires&amp;qid=1714572380&amp;s=books&amp;sprefix=bitcopin+billionaires%2Cstripbooks%2C71&amp;sr=1-1|https://www.amazon.co.uk/Bitcoin-Billionaires-Genius-Betrayal-Redemption/dp/B07P75J5M[…]books&amp;sprefix=bitcopin+billionaires%2Cstripbooks%2C71&amp;sr=1-1](https://www.amazon.co.uk/Bitcoin-Billionaires-Genius-Betrayal-Redemption/dp/B07P75J5MW/ref=sr_1_1?crid=1DCLMGCYTZAG4&amp;dib=eyJ2IjoiMSJ9.RgdEWhLg_WhCKNfP4LIho-17nuVuZO-HTFZ_-Joey7rQUNOdo2bTIQSmuXj3fK6wgJE2wCZehwIDU8_cnnBLkokPR1TF6BUDBlhM-hQeawYTO9BZLrDt2d_y05RF9dkCJ314nKnyaEqOdmivBlW23yKx1a7FIjNokBibne2-uh4RHmzti6e7h69ZVSRYKSaZGPrIEh6uw4FPICZlS4Lag_-zw_TyfL6fwrXDypRbbcY.6EsP9U-reR_p1qmixo-_0Xi-uf7Y6_gU6R7R6f8WNCk&amp;dib_tag=se&amp;keywords=bitcoin+billionaires&amp;qid=1714572380&amp;s=books&amp;sprefix=bitcopin+billionaires%2Cstripbooks%2C71&amp;sr=1-1|https://www.amazon.co.uk/Bitcoin-Billionaires-Genius-Betrayal-Redemption/dp/B07P75J5M[…]books&amp;sprefix=bitcopin+billionaires%2Cstripbooks%2C71&amp;sr=1-1)

*Tags: Errors Debugging, Performance*

---

**PeterLe** - *15:14:16*

Cheers :+1:

By the way; I loved reading this :[https://www.amazon.co.uk/American-Kingpin-Criminal-Mastermind-Behind/dp/B071JPMB18/ref=sr_1_1?crid=EVJ5LBULM89K&amp;dib=eyJ2IjoiMSJ9.Aoli_NlheBcrIZOdQYbxxepAU38Hx2Sqn-K0OiWf_NZV8ThtXCTVgrGO4is1nHBZ-Xh9lAOlNWChE--ax4dCDs_JHSlF7FDdJZNoHNB1w7YRf09yo6TPDX2LUuMGlQsmGhykMoYCOx2PPSoe2NWlLFAhWMQSi95P_AhjEmVw-2L1UiuQtQ0Erta7NgbEKxGg24BTlVTwPSRXgcaOf_XYlx16uvXRCrWPhM8n5g8GOy0.HIJH3QbZc6V46ZT9W1FB2n0QRI5ZaS_Fotho6_sVb5w&amp;dib_tag=se&amp;keywords=american+kingpin&amp;qid=1714572777&amp;s=audible&amp;sprefix=american+kingpin%2Caudible%2C61&amp;sr=1-1|https://www.amazon.co.uk/American-Kingpin-Criminal-Mastermind-Behind/dp/B071JPMB18/re[…]777&amp;s=audible&amp;sprefix=american+kingpin%2Caudible%2C61&amp;sr=1-1](https://www.amazon.co.uk/American-Kingpin-Criminal-Mastermind-Behind/dp/B071JPMB18/ref=sr_1_1?crid=EVJ5LBULM89K&amp;dib=eyJ2IjoiMSJ9.Aoli_NlheBcrIZOdQYbxxepAU38Hx2Sqn-K0OiWf_NZV8ThtXCTVgrGO4is1nHBZ-Xh9lAOlNWChE--ax4dCDs_JHSlF7FDdJZNoHNB1w7YRf09yo6TPDX2LUuMGlQsmGhykMoYCOx2PPSoe2NWlLFAhWMQSi95P_AhjEmVw-2L1UiuQtQ0Erta7NgbEKxGg24BTlVTwPSRXgcaOf_XYlx16uvXRCrWPhM8n5g8GOy0.HIJH3QbZc6V46ZT9W1FB2n0QRI5ZaS_Fotho6_sVb5w&amp;dib_tag=se&amp;keywords=american+kingpin&amp;qid=1714572777&amp;s=audible&amp;sprefix=american+kingpin%2Caudible%2C61&amp;sr=1-1|https://www.amazon.co.uk/American-Kingpin-Criminal-Mastermind-Behind/dp/B071JPMB18/re[…]777&amp;s=audible&amp;sprefix=american+kingpin%2Caudible%2C61&amp;sr=1-1)

Fab book (Film was crap though :grinning:)

*Tags: Errors Debugging*

---

## 2024-05-02

**JL** - *10:35:21*

are there any way to set `self.client.account_funds.available_to_bet_balance`  accessed through `process_market_book` when simulating on historical data?

*Tags: Data Quality*

---

**liam** - *10:39:42*

I am questioning why you would want to know your balance from within a strategy 

*Tags: Strategies*

---

**JL** - *10:40:28*

ah, it's for dynamic bet sizing

*Tags: General Technical*

---

**JL** - *10:43:34*

yeah I'm using the Kelly criterion

*Tags: Strategies*

---

**JL** - *10:46:58*

I'm guessing it's because of the chance of only getting partially filled? right now it works because I'm using a large fraction for fractional Kelly

*Tags: Strategies*

---

**liam** - *10:49:18*

What are you trying to do? Kelly is for optimising bet size using ev however in betting markets ev is so dependant on bet size/capacity that it has limits

*Tags: Strategies*

---

**liam** - *10:57:26*

In my experience its far more valuable (and profitable) to improve your EV calculation and work off a variation of kelly with a fixed balance

*Tags: Errors Debugging, Strategies*

---

**liam** - *10:59:55*

But if you want the pain you can get your clients from within a strategy using `self.clients`

*Tags: Strategies*

---

**JL** - *11:15:19*

haha I don't know, you can get 10-20£ on back with not problem. Lay is a much worse though

*Tags: General Technical*

---

**JL** - *13:45:03*

[@U4H19D1D2](@U4H19D1D2) oh I misunderstood. I meant the actual computation of EV using your predicted probability and the odds available. So just a better predictive model, got it

*Tags: Strategies*

---

## 2024-05-14

**liam** - *09:57:42*

[https://markrbest.github.io/message-arrival-rates-and-latency/|Message Arrival Rates and Latency](https://markrbest.github.io/message-arrival-rates-and-latency/|Message Arrival Rates and Latency)

*Tags: Performance*

---

**Johnny** - *10:12:32*

Quite relevant for me, currently trying to streamline my process_market_book, as when the football markets get busy I'm getting epic latency which goes away when things quiet down

```{"asctime": "2024-05-12 04:48:03,422", "levelname": "WARNING", "message": "[MarketStream: 2016]: Latency high: 865.0007269382477"}

{"asctime": "2024-05-12 04:48:03,425", "levelname": "WARNING", "message": "High latency between current time and MarketBook publish time", "market_id": "1.228296017", "latency": 2898.2553684711456, "pt": "2024-05-12T03:59:45.170000"}```

*Tags: Performance*

---

**Johnny** - *10:41:31*

Yeah I'm doing too many lookups and calcs in the strategy, need to rethink the logic probably

*Tags: Strategies*

---

**liam** - *12:01:04*

Looks like you have latency issues and CPU issues based on both those warnings, hard to offer help without seeing a profile or the code

*Tags: Performance*

---

**Peter** - *18:13:32*

Wondering whether anybody else has been having problems withdrawing funds from Betfair?



I made a withdrawal 10 days ago that didn't arrive in my bank account, so I chased it. Today I've been informed that the withdrawal had been declined. I wasn't told this and to date haven't been given a reason - just a suggestion that I try again.



Worse, the funds had been taken from my account and weren't returned to it until I queried their non-arrival at my bank. This all feels very sketchy.

*Tags: General Technical*

---

**thambie1** - *18:48:47*

started with Revolut, worked perfectly until they shut it down. Used Halifax &amp; HSBC since. Both have stayed open, but had problems with large amount card withdrawal/deposits on both. Currently using 'Bank Transfer'

*Tags: General Technical*

---

## 2024-05-15

**river_shah** - *07:50:47*

Holy smokes: [https://chatgpt.com/?model=gpt-4o](https://chatgpt.com/?model=gpt-4o)

*Tags: Strategies*

---

**Justice** - *07:59:14*

When all this AI stuff first came out, I was one of those that thought it would allow every degenerate gambler to write sophisticated algorithms with ease and markets would become far more efficient.



Now I'm really not so sure. It's a useful tool that saves a lot of time. Imo it's a more efficient replacement to trawling through stack overflow posts (or god forbid actually posting a question on there) but there's no way you could create anything non-trivial if you didn't know what you were doing

*Tags: General Technical*

---

**Ralegh** - *08:22:31*

I think especially for tradfi there’s so little publicly available knowledge that these models won’t be able to give good advise on the trading side. Coding side useful of course

*Tags: Strategies*

---

**PeterLe** - *08:37:14*

I read up a little on this yesterday, I understood that whilst 4o is faster, the responses may not be as good as the existing GPT4, so ill stick with that for now



Im surprised how much it knows about Flumine too



...makes you wonder what it will be like in a few years

*Tags: General Technical*

---

**Johnny** - *11:12:49*

I've found it is useful in fixing errors or figuring out how to do something very specific, as long as you know exactly what it is you want to achieve.  Big-picture stuff, not much use

*Tags: Errors Debugging*

---

**Peter** - *14:07:57*

Just received a scarcely believable email from them suggesting that it might have been rejected because of technical issues at the time of the request. Fair enough.



But it then goes on to say that they "are only able to locate stuck/rejected withdrawals individually, and it is the customer's responsibility to inform us of any such issues regarding their accounts."



So basically if they have a technical problem, it's up to us to spot it, and until we do they'll hold on to the funds that they've already deducted from our accounts.

*Tags: General Technical*

---

**Chris** - *15:12:34*

From knowing absolutely nothing  about python except a few basic lines chatgpt 4 has written me an xgboost model predicting probabilities , webscraping racecards with scrapy and implementing it all to use with flumine.

Backtesting (thanks peterle) with only 3 months of data so far.

I found chatgpt4 much better compared to 3.5 which kept sending me around in circles. 

*Tags: Strategies*

---

**Johnny** - *16:58:23*

I've been working on some RAG lately - getting into it still but trying stuff with Milvus, Langchain, and currently neo4j.  Not plugged flumine into it yet (I can lose my money easily enough without AI)

*Tags: General Technical*

---

**Jonjonjon** - *21:26:49*

Has anyone tried using a LLM with Flumine yet?

*Tags: General Technical*

---

## 2024-05-16

**Adrian** - *01:47:45*

[https://www.youtube.com/watch?v=GAj9G8rkg3s](https://www.youtube.com/watch?v=GAj9G8rkg3s)

The fact that someone like yourself Chris with no python knowledge can now knock up a fully working simulation and backtested model means we're all kinda fucked. This is the worst AI will ever be, in 6 months it will be 50 times better than it already is now. Everyone's edge will disappear cause the AI will be reinforcement learning better than any of us can understand the markets. The only difference between who wins and who loses is who can dedicate the most computational power to each problem. Link related.

*Tags: Strategies*

---

**Johnny** - *09:51:39*

I think to implement RAG, one would need to find a suitable set of variables to represent either the current state (marketbook or equivalent) or the time series leading up to the current state - then learning a vector embedding for this so the model can search for similar states seen before and therefore potential similar outcomes.  Not sure if there are many pre-trained embedding models for this kind of data... probably something out there in the financial trading world

*Tags: Strategies*

---

**Johnny** - *10:35:13*

For a single point in time I'd agree but if you're looking at a time series then you'd need some way to put the data into a uniform shape to feed the model

*Tags: Strategies*

---

**Ralegh** - *10:41:20*

Orderbook as uniform shape is fairly easy? You just take top K levels over a T look back period, put in some transformer/cnn/lstm model, as Tx2K (or 4K with prices). 

*Tags: Strategies*

---

**Johnny** - *10:51:55*

[@U03FS7KM2NL](@U03FS7KM2NL) yep - I guess when I say "embedding" I mean a representation to store the state, which you've said can be done with a model of some kind

*Tags: Strategies*

---

**river_shah** - *11:13:05*

`We find that surpassing the performance of a simple LSTM in the return forecasting task is surprisingly challenging.`



I am going to stick with ridge regression until you pry it out my cold dead hands

*Tags: Performance*

---

**river_shah** - *11:22:57*

The Kolm paper is good but feature engineering + ridge is still SOTA. It's too bad he does not have that as the baseline model

*Tags: Feature Engineering, Strategies*

---

**Johnny** - *11:26:43*

Maybe he didn't have access to a SOTA model...

*Tags: Strategies*

---

**river_shah** - *11:33:04*

Yes, the thing is in his preamble he goes on precisely how the model is being constructed. So you know why not do that extra step, write some of the features out by hand (rather than lstm hidden representations) and fit ridge with GCV and show us the full multi horizon alpha term structure. I'd bet even this basic approach matches lstm illustrated performance (let alone what can be achieved by grinding harder at the problem use ridge + domain knowledge)

*Tags: Feature Engineering, Performance, Strategies*

---

**river_shah** - *11:34:24*

I guess then he'd have to say:

`We find that surpassing the performance of a simple linear regression in the return forecasting task is surprisingly challenging.`

*Tags: Performance*

---

**Ralegh** - *11:56:19*

I think ridge+feature engineering given enough time and ideas may be sota but for stuff like HFT I have heard deep learning, (and also deep RL for execution/optimiser). There’s just so much data and you can fit to it quickly eg blackrock deploying a new execution algo could be factored in if you recalibrated every day but those transient signals might not fit into features that you’ve come up with historically unless you were literally coming up with new ideas every day. 



I think XTX is pretty big on deep learning and their whole thing is taking large positions while making markets so I assume their forecasts are good. That being said regression is like concrete or steel and probably is the final arbiter of what goes in a forecast.



Also ridge + features are a lot handier for transfer learning. If you moved to a new market with little historical data you’d feel pretty confident just copying stuff across. Would be easier to manipulate and remove features (weight = 0) without the required data in the new market than trying to break apart a web of neural network shenanigans. If I’ve learned anything from success stories the easiest way to make money is take a good strategy and apply it to an inefficient/new market.

*Tags: Data Quality, Feature Engineering, Deployment, Strategies*

---

## 2024-05-17

**V** - *13:21:13*

Anyone know how to raise the exposure limit on betfair?

*Tags: General Technical*

---

## 2024-05-29

**Dave** - *19:36:31*

I aim for around min 5% in backtest. Once deployed, as long as it is positive and has no negative impact on my other strategies (latency, wasting streaming bandwidth etc) then that's enough to justify running it

*Tags: Performance, Deployment*

---

**Michael** - *21:20:36*

0.1% does seem very low. It wouldn't take much of a losing streak to turn that negative. On the other hand it might be a platform to build from, if you think you've got a decent chance of improving it when you've got enough data then you might well run it just for that. You'd certainly want to be sure that you're not canibalising any of your other betting though, that seems like a big risk with such a low margin strategy.

*Tags: Strategies*

---

## 2024-05-30

**liam** - *12:21:31*

Hmm, I assume it would also need historical data as well?



Yeah too good, very depressing being back

*Tags: Data Quality*

---

## 2024-05-31

**Paul** - *16:08:49*

Interestingly I was thinking about building something like this - helping understand past bets a little better - for macOS and iOS for my own purposes (I’m very much in the apple ecosystem), in the next few weeks. If I throw a few screenshots up and people like it, I might bother to talk to BF about making it a registered app with them and getting it into app stores.

*Tags: General Technical*

---

**PeterLe** - *21:21:32*

The way I use it some times DC is to have my prod system running on AWS (Ie Python) and then use betangel on my local PC (Doing nothing but to act as a visual aid) That way there is no overhead.

It may just be the way my brain works but I find it useful to watch what's happening rather that read the logs etc

*Tags: Deployment*

---

## 2024-06-01

**Paul** - *10:55:40*

About that. It seems - based on interviews and bits and bobs I’ve picked up over the years - that Star Sports model is to lay a book to a common payout, but take a liability on a horse they don’t like at or near the head of the market. They then rely on the 1.5% a runner over round they get to make decent money 2/3 of the time and take a knock 1/3 of the time (in the long run). It’s a very old school way of book making, Vic Chandler senior would recognise it from his days on the rails. Given Ben started as an assistant to a bookie at a dog track and he’s now got multiple shops, a decent website, quite a few staff and he’s sponsoring a fair few things, seems to work for him.

*Tags: Strategies*

---

**D C** - *12:45:57*

Is it possible to increase your implied commission on losses by increasing your own personal commission rate, or is it fixed at 3% regardless?

*Tags: Errors Debugging*

---

**ShaunW** - *20:09:28*

Implied comm rate is fixed, across all markets, even if you choose a higher UK base rate via the 'rewards plan' levels. FYI You can't change your base comm rate on Antipodean markets and MBR discounts earned on those markets don't affect the implied 3%.

*Tags: Errors Debugging*

---

## 2024-06-02

**river_shah** - *14:09:35*

To clarify, this is on track exposure that he's accumulated and then partially hedged off with exchanges?



I'd be hard pressed to acquire this level of risk on exchange alone without significant mkt impact (regardless of modelling confidence)

*Tags: Strategies*

---

## 2024-06-09

**Mo** - *13:37:11*

That comparison looks like a smoking gun that the problem is with Betfair, [@UUE6E1LA1](@UUE6E1LA1)

*Tags: General Technical*

---

**D C** - *13:39:33*

I can ask the question anyway

*Tags: General Technical*

---

**D C** - *13:55:44*

I emailed Neil about it. I was just hoping that someone might be experiencing the same problems. Unless you run multiple GPS streams though there is no frame of reference for comparison I suppose and you'd just assume it was a TPD level dropout :man-shrugging:

*Tags: General Technical*

---

**D C** - *19:53:56*

Yeah I have sent the connection ID and details to Neil via email. It's all on AWS Dublin.

*Tags: Deployment*

---

## 2024-06-10

**D C** - *13:36:36*

OK thanks [@U01335QG2G3](@U01335QG2G3) this pretty much nails it down as not my code that is the problem, If nothing else this helps me no longer waste time trying to find problems in my code!

*Tags: General Technical*

---

## 2024-06-12

**Leo** - *19:34:20*

Hey [@U4H19D1D2](@U4H19D1D2) how are you managing flumine versions without tags or release on gh 

*Tags: General Technical*

---

## 2024-06-13

**Jonjonjon** - *21:11:22*

In my streaming file for 1.228022652, I see 68651862 was declared a loser well before the race started. Chelmsford City. 25th April 2024.

Is this common?

*Tags: General Technical*

---

## 2024-06-16

**Dave** - *18:58:27*

Outside of flumine I use the historical generator stream from bflw, replay the files and handle it tick by tick. You don't need all ticks going back to when the market was open, so you can cache the bits you need yourself as you process each next tick. The advantage here as well is that this is how you'll process market data in production, so you can run the same logic for things like feature generation for both historical and realtime data.

*Tags: Feature Engineering, Deployment*

---

**Ralegh** - *19:23:48*

Is this live? For research I would just get a big ec2 instance

*Tags: Deployment*

---

**Justice** - *19:24:31*

[@U03FS7KM2NL](@U03FS7KM2NL) Research, testing and model training

*Tags: Strategies*

---

**Justice** - *19:31:05*

[@UEA14GBRR](@UEA14GBRR) Yes I could use SQL, with a properly normalized database. But I am going to have to de-normalize and load into memory at some point to train my model/test/visualize etc.



I could lazily iterate which would avoid memory issues as [@U0128E7BEHW](@U0128E7BEHW) suggested but it would be awfully slow and I'm impatient. Perhaps I just need more compute.

*Tags: Performance, Strategies*

---

**Jonjonjon** - *19:45:56*

I store in feather using Pandas. how you store and organise the data has a big effect. Might be worth looking at how HFT's store and manage their data. It's very valuable knowledge.



Also,  it's one of the few areas where the nonsense software engineers get tested on in interviews actually might have relevance.

*Tags: Feature Engineering*

---

**Ralegh** - *20:27:39*

Flat file is generally the best, you don’t stream to parquet so you either stream to (eg) CSV or betfairs json format then batch convert to parquet, or batch convert historical data to parquet. [https://signalsandthreads.com/state-machine-replication-and-why-you-should-care/|https://signalsandthreads.com/state-machine-replication-and-why-you-should-care/](https://signalsandthreads.com/state-machine-replication-and-why-you-should-care/|https://signalsandthreads.com/state-machine-replication-and-why-you-should-care/) - good reading, generally advice is to have writing be single threaded (ie don’t need a dbms) which reduces complexity. If JS can handle their shittons of data in a single thread (and most financial exchanges) then almost anyone can. My betting stuff is set up roughly similar, all data gets logged to disk and the trading is full deterministic so I can fully replicate a days data in the right order and see exactly why everything happened. Each day gets zipped as one file and put in S3, about 100MB each

*Tags: Data Quality, Strategies*

---

**Rob** - *23:56:22*

I tend to work in RAM, would consider:



• don't store every row if you don't need to - does every row change every tick? if not, store each unique once with a from/to datetime

•  use the smallest possible data types

• do feature engineering or get feature importance on a smaller sample, and then build your model on a much dataset of columns that amtter  - obviously YMMV, but I don't build models with the full set of traded volumes at every price

• sample - lots of the time, you're not going to get a massively different answer with a subset that does fit in RAM

• buy more RAM (it's relatively cheap compared to the time you're investing - 128Gb of DDR5 isn't crazy)

• get it working locally on a sample, then use a cloud server (e.g. EC2) to fun your full build

*Tags: Feature Engineering, Deployment, Strategies*

---

**Rob** - *23:58:38*

As someone else said, I would personally prioritise using the exact same code in production vs development, otherwise, with just me in my spare time,  the chance of making a mistake there is too large (different story if you're a massive business with the resource for lots of testing)

*Tags: Deployment*

---

## 2024-06-18

**D C** - *14:39:04*

Anyone having severe GPS feed problems in the first at Ascot?

*Tags: General Technical*

---

**D C** - *15:10:25*

Shit. I managed £4.54 after commission. Lots of "Bet placement blocked due to GPS errors messages" still. Lots.

*Tags: Errors Debugging*

---

**AndyL** - *15:34:35*

i'm your son, so do you have a winning strategy account running for me please...??

*Tags: Strategies*

---

## 2024-06-20

**river_shah** - *06:50:13*

Glad to hear and wasn't being a sour about it. That race was a small net win across models. British racing is pretty laissez-faire. That wander would have been a definite issue in the US

*Tags: Strategies*

---

## 2024-06-21

**fax** - *08:14:57*

Hi all,

I'm doing a PhD in sports forecasting (officially computer science). I'm currently mapping out my research goals. Got a question for you people... If you were in my position, what would you think is worthwhile researching?



I've got my own ideas, so even some feedback on these could be good:

- graph neural networks (i.e., [https://summit.sfu.ca/_flysystem/fedora/2022-08/input_data/22492/etd21919.pdf](https://summit.sfu.ca/_flysystem/fedora/2022-08/input_data/22492/etd21919.pdf))

- increasing profit through decreasing correlation with market prices (i.e., [https://www.sciencedirect.com/science/article/pii/S0169207022000292](https://www.sciencedirect.com/science/article/pii/S0169207022000292))

- using football match event data (i.e., [https://www.sciencedirect.com/science/article/pii/S016920702300033X](https://www.sciencedirect.com/science/article/pii/S016920702300033X))

*Tags: General Technical*

---

**Mo** - *08:40:44*

The other two are interesting only as academic curiosities. Holmes and McHale backtest versus Bet365 which are not real prices so any claims their model is market beating cannot be supported

*Tags: Strategies*

---

**Leo** - *08:42:02*

Would probably agree, ties in closely with a problem I've grappled with a fair bit with fundamental models where most "accuarate" model != most profitable model all of the time. Seen hundreds of the first type of paper I.e. here's a model applied to some historic sports data and as mo said maybe interesting academically are almost always useless    

*Tags: Strategies*

---

**liam** - *09:32:19*

Being completely honest, not sure I have found a single paper that a) I find interesting and b) actually understand, they all seem just full of pointless maths and equations.



The most interesting part of sports right now is live data / tracking / ai tracking etc. something which fits more into CS as well



[https://www.totalperformancedata.com/](https://www.totalperformancedata.com/)

[https://jabbr.ai/](https://jabbr.ai/)

[https://pysport.org/](https://pysport.org/)

[https://www.statsperform.com/artificial-intelligence-in-sport/](https://www.statsperform.com/artificial-intelligence-in-sport/)

*Tags: Performance, Deployment*

---

**D C** - *10:24:51*

I agree with Liam 100%. The fact that you are even asking this question suggests that you have an open book and are not bound to an already written research proposal (???) so I would definitely go down the path of looking at positional/tracking data and some fundamentals based modelling. It is possible that doing this via a phd route might get you some "free" data to work with too. I did something along these lines in my last job for NFL data and to be honest I found it really interesting. Should counter that with the fact that I found nothing "useful" but I was doing this in a corporate setting, whereas you will not have that kind of pressure and have more time and (presumably) better guidance.

*Tags: Strategies*

---

**D C** - *10:27:31*

Most importantly choose something that you really are interested in though. Doing a Phd is a fucking slog at times - particularly when you feel you are getting nowhere. A genuine interest and passion for the research area can really really help you grind through those periods.

*Tags: General Technical*

---

## 2024-06-23

**D C** - *13:48:52*

[@U05EXF0UXHB](@U05EXF0UXHB) I think Liam's perspective is perfectly acceptable from someone who is a practitioner rather than someone doing this for academic interest or qualifications. For someone doing a PhD it is probably more important to find something that they are interested in AND that the supervisor genuinely has some knowledge of as it can be a very lonely game. You need to work out if you are doing the Phd in the hopes that you end up with a profitable betting model, or to benefit from the research training and qualification it gives you when you are finished.

For someone who has a similar mindset to my own, I'd be very worried about the former overwhelming the latter otherwise worst case scenario you end up with neither.

*Tags: Strategies*

---

**mk19** - *14:05:57*

[@UUE6E1LA1](@UUE6E1LA1)  'I don't understand = pointless maths' is still a bold claim, and then suggesting computer vision which is a solved domain. 



Anyway, I'm not sure what PhD program is this, but normally you need to have the topic of specialization to start not find it later. A profitable model is not a significant contribution, so I guess there shouldnt be a worry for that

*Tags: Strategies*

---

**D C** - *14:21:28*

It's why a good supervisor is so important. When you start out, you haven't the skill nor background to know it a paper is good/relevant - you need your supervisor to be  helping you separate the wheat from the chaff.

*Tags: General Technical*

---

**liam** - *14:36:22*

I guess we have a different opinion on what solved means but yes everything I do is original, I think it’s my only edge tbh 

*Tags: General Technical*

---

## 2024-06-26

**liam** - *19:54:33*

I am confused, you pay commission per market so if you have your pnl it’s p x c? Or am I misunderstanding your question?

*Tags: General Technical*

---

## 2024-06-28

**James** - *02:13:51*

Hey, I’ve been calling the an undocumented, but public api to provide some race info to a manual in play trader. They want to know at a quick glance, Driver/Jockey, track conditions etc and bookie sites and other racing sites are bloated and load slowly.



It was running fine for about a year, and a little while back they blocked access to their API from a massive number of cloud providers (I assume by IP ranges) from AWS/GCP right down to digital ocean and Vultr.



As a temporary solution I have a local server running on the network for this trader, and his IP can access the API without any issues. I want to host it again so it can be accessed away from his home network (without a VPN) and it has CORS settings in place meaning it needs to happen on a server rather than client side. Any ideas from this crowd? I know its more softwarey/infrastructurey than the data questions that usually end up here but thought I’d ask all the same.

*Tags: Performance, Deployment*

---

**liam** - *06:51:30*

Which endpoint are you calling? I use aws and haven’t had any issues 

*Tags: Deployment*

---

**foxwood** - *10:43:41*

Couple of their IP's show they have a presence on AWS [http://ap-southeast-2.compute.amazonaws.com|ap-southeast-2.compute.amazonaws.com](http://ap-southeast-2.compute.amazonaws.com|ap-southeast-2.compute.amazonaws.com) - try hosting in that region ?

*Tags: Deployment*

---

## 2024-06-29

**James** - *03:03:08*

Yeah I have tried on AWS in that region, and I could do a VPN. Just a lot of stuff around for something that had been working fine :face_with_rolling_eyes:

Thanks.

*Tags: Deployment*

---

## 2024-06-30

**river_shah** - *15:30:51*

I don't have a particular model for this, but surely England priced at 5.0 for the Euros seems way too optimistic 

*Tags: Strategies*

---

**lorenzo** - *15:41:07*

After the draw I do think it’s going to be a bit easier to get far along (and possibly to the end). I also have no model but I’m not sure 5.0 is really value now 

*Tags: Strategies*

---

## 2024-07-01

**Paul** - *17:51:15*

Look at the tournament bracket. Switzerland is the hardest match they’ll have in terms of World rankings until final. If you model it with ELO (which is all rankings really are a proxy for), factor in they are more likely to handle extra time and penalties well based on player form compared to the players they are facing, the price feels about right to me. People buying into media narrative of Southgate mediocrity - the same people calling for his resignation at 90’ + 4 last night - are potentially the mugs on the other sides of your bets. All he needs to do is tweak some positions and they’re going to be getting a *lot* more attempts on goal…

*Tags: Strategies*

---

**river_shah** - *17:55:30*

My uber fantastic model tells me (three multiplications that I have pulled out of a hat) that price should be closer to 6.5

*Tags: Strategies*

---

**Paul** - *17:58:45*

That’s not an awful model… :-)

*Tags: Strategies*

---

**Paul** - *18:02:12*

You’re lumped out on France a bit. What’s your secret model there, hmm?

*Tags: Strategies*

---

## 2024-07-02

**D C** - *08:11:53*

Just logged into one of my AWS servers to find that it must have rebooted overnight. Bots on the server have been running for about 18 months uninterrupted. How common is it for AWS stuff to just reset like that? Memory and CPU and disk usage were all very low. It's no big deal I guess, but I've never seen Linux just reboot like that for no (obvious) reason.

*Tags: Performance, Deployment*

---

**Unknown** - *13:34:00*

I guess I will ping some further observations and punting log as it makes watching the tournament more interesting. I make no claims to having any alpha in this as my systematic strategies don't touch this.



Portugal actually drifted out despite winning their game. Less than stellar performance and Ronaldo seems very unconvincing. When Portugal was drifting out, someone started backing England some more. Causal? It seems like regardless of weaker or stronger teams getting kicked out of tournament, there is a wall of money backing England.



There were a couple of £1M bets during the Portugal/ Slovenia penalties (To Qualify market). Maybe [@U4H19D1D2](@U4H19D1D2) has started betting on football

*Tags: Performance, Strategies*

---

## 2024-07-04

**Jonjonjon** - *13:20:08*

How hard would it be to update Flumine to do that?

*Tags: General Technical*

---

**Tom** - *22:34:27*

Hi gentlemen. I'm wondering how to add and drop markets in a running Flumine instance successfully? Seems flumine.remove_market won't do it?

*Tags: General Technical*

---

## 2024-07-05

**liam** - *08:25:12*

Best practice is to have a filter wide enough to pull everything in and just ignore the ones you don't want using the `check_market_book`  This is because when streaming you can't 'add' or 'remove' markets



More info [https://betcode-org.github.io/betfair/streaming/|here](https://betcode-org.github.io/betfair/streaming/|here)

*Tags: General Technical*

---

**Tom** - *10:50:39*

Right. I add market_ids, so I thought it only added those.



market_filter = streaming_market_filter(

            market_ids=market_ids,

            event_type_ids=['7'],

            country_codes=['AU', 'NZ'],

            market_types=['WIN', 'PLACE']

            # turn_in_play_enabled=False

    ),

*Tags: General Technical*

---

**Tom** - *10:56:09*

I've been running a script on betfairlightweight to collect data (and order execution on flumine; but was slowly trying to get my data collection through flumine / OOP but don't want to mess up what the script is doing.



That makes it a lot easier

*Tags: Performance*

---

**liam** - *10:57:16*

I would advise creating a new flumine instance for data collection anyway as it would be something you start and never stop but a flumine instance running live strategies is likely to need the odd start/stop/restart/update

*Tags: Deployment*

---

**Tom** - *10:58:44*

I've got a flumine data collection, but it picks up a pkl file from the script. Am trying to move towards that

*Tags: General Technical*

---

**Ammar** - *15:02:57*

~yep, this is where that whole database thing i was talking about a while back came into it~



Misread. Not done any sportsbook stuff yet 

*Tags: General Technical*

---

## 2024-07-09

**Simon Chan** - *16:42:46*

Maybe a weird question:

I recalled that someone here posted a photo of some paragraph from a book a while ago. I don't remember what it said exactly but what I can paraphrase from memory is: it talks about  the author (or someone else)  learning /using advanced technical concepts (mathematics, computer science) in order to help trading, but is not interested 

 in these concepts on their own at all, as these are just useful tools to make money.  There was also discussion on this sentiment and I think most folks here disagreed/ were not warmed to it.



I can't find the post now because it is way past the 90 days history limit by Slack.  It is probably a wild guess, but does anyone know the book, or know who posted it and/or have archived the post?  I'm interested in reading the book further (part of the academic research I'm doing).

*Tags: Performance, Strategies*

---

**Paul** - *17:29:17*

Ok, so let me explain. I regularly read about an area of maths, or comp sci, and I think “wait, there could be a strategy here”. I think a lot of foundational thinking in this space starts with the abstract and needles its way into concrete stuff. Pascal, Shannon, Kelly, Thorp, Bentner, many others: they looked at some maths and saw an interesting thing that then became a way to make money. Shannon noticed the money making oops but did nothing about it. Thorp noticed the maths and ended up building the world’s first wearable computer to apply it. If you only ever see theory as a means to making money, you’ll only ever look at stuff that is “obvious” in terms of its alignment to money making.

*Tags: Strategies*

---

**PeterLe** - *18:41:34*

If you only have a hammer in your toolbox DC, then every problem looks like a nail:grinning:

*Tags: General Technical*

---

**river_shah** - *18:43:47*

More hammers, more problems

*Tags: General Technical*

---

**PeterLe** - *18:46:02*

I was just thinking. One of the best traders (Gambler) i know once told me that he never really uses anything much beyond GCSE maths.

If you were to create two categories for successful gamblers, one using simple based maths and one using sophisticated models, which group would you expect to make the greater combined profit?

*Tags: Strategies*

---

## 2024-07-10

**Paul** - *00:08:03*

My hot take: you should apply and understand the tools you use, and it normally pays off to understand more tools than you know how to use today.

*Tags: General Technical*

---

## 2024-07-16

**Joe** - *12:27:44*

If you are going to the cost and trouble of subverting an election result then laying the obvious known winner for a few million of liability so you can point to the bookies and say, "look the bookies think something is up with this result" helps massively with your engineering of the hillbilly mind.

*Tags: General Technical*

---

**Paul** - *21:04:43*

This looks great, but building models in R is only slightly less unhinged than writing them in Excel. Bit easier to port, mind.

*Tags: Strategies*

---

## 2024-07-17

**Paul** - *12:05:51*

The R code is definitely understandable and could be ported. I was reading through some of the first chapter on MCMC this morning and nothing looked too hard to port to python, although I’m not familiar with differences between RStan and PyStan (yet). Tempted to write Python versions of each of his code listings and whack them up on GitHub. The theory sections are pretty in-depth, and for some of it I’m definitely lost (so I’m going to have to go back through sections like conjugate priors, for example, slowly, and with a google machine at my side), but the code looks like something I can pick up and use and play with.

*Tags: Performance*

---

**Mo** - *12:11:22*

With `pystan` and `numpy/pandas` there's really no reason to miss out on what I suspect will be excellent material just because you're dogmatic about programming languages

*Tags: Feature Engineering*

---

**Paul** - *13:06:02*

I’m looking forward to giving the core model building chapters a read later, though. It seems we are on the verge of forming a book club on this one. :slightly_smiling_face:

*Tags: Strategies*

---

## 2024-07-18

**Unknown** - *14:41:41*

Twilight zone American democracy. Kamala feels like a value bet. No model, not systematic. Just a punt

*Tags: Strategies*

---

## 2024-07-19

**D C** - *09:31:37*

Is it confirmed that crowdstrike is the source of the problem?

*Tags: General Technical*

---

**ShaunW** - *12:40:57*

No serious company should be using automatic updates for anything. Sht happens and that's why there's update testing and controlled rollouts. Crowdstrike problem, compounded by lack of basic IT procedures. I don't apply updates automatically due to the risk, and all I'm doing is having a fee bets. :thinking_face:.

*Tags: General Technical*

---

## 2024-07-23

**Mo** - *12:42:56*

&gt; The Department of Economics at the University of Crete welcomes you to attend a webinar on Thursday 25 July at 19.00 GREEK time.

&gt; 

&gt; Title: Predicting full retirement attainment of NBA players

&gt; 

&gt; Presenter: Giorgos Foutzopoulos, Private Company

&gt; 

&gt; Abstract: Τhe aim of this analysis is to predict whether an National Basketball Association (NBA) player will be active in the league for at least 10 years so as to be qualified for NBA's full retirement scheme which allows for the maximum benefit payable by law. We collected per game statistics for players during their second year, drafted during the years 1999 up to 2006, for which, information on their career longetivity is known. By feeding these statistics of the sophomore players into statistical and machine learning algorithms we select the important statistics and manage to accomplish a satisfactory predictability performance. Further, we visualize the effect of each of the selected statistics on the estimated probability of staying in the league for more than 10 years.

&gt; 

&gt; Zoom link: [https://uoc-gr.zoom.us/j/88659969718?pwd=g6bjYPDCuUQo1bzVxjjbgQL4xFN1f3.1|https://uoc-gr.zoom.us/j/88659969718?pwd=g6bjYPDCuUQo1bzVxjjbgQL4xFN1f3.1](https://uoc-gr.zoom.us/j/88659969718?pwd=g6bjYPDCuUQo1bzVxjjbgQL4xFN1f3.1|https://uoc-gr.zoom.us/j/88659969718?pwd=g6bjYPDCuUQo1bzVxjjbgQL4xFN1f3.1)

*Tags: Performance*

---

## 2024-08-01

**AndyL** - *20:48:27*

blimey sweating over a new strategy takes on a new meaning when my Mac is running a long analysis and it's 30deg outside !!

*Tags: Strategies*

---

## 2024-08-06

**Paul** - *23:08:11*

Apparently I “spilled alpha everywhere” tonight by asking one question. Turn up next month, buy me a drink, I might ask the same question again… 

*Tags: General Technical*

---

## 2024-08-07

**Tom** - *07:10:03*

IMO Taleb rationalised his luck in the '87 crash, not just with the money he received being the result of some high minded trading strategy, but into a feature of intellectual superiority.

*Tags: Feature Engineering, Strategies*

---

## 2024-08-08

**Paul** - *16:40:04*

If it’s easier you can buy me a plane ticket and pay for my hotel, and then I’ll ask the question in a small special ceremony. I’ll even wear a tie.

*Tags: General Technical*

---

## 2024-08-24

**Jonjonjon** - *14:54:24*

What's the recommended way to work out the best optimisation route for calibrating tabular models such as xgboost, catboost, random forest etc ..?



My models are taking around 100seconds to fit on my cpu. I fit hundreds of models.



I use a 16 core Ryzen 3950x cpu



I have found that it's best to do this using 16 processes, allowing each model fit to use 2 CPUs.

To improve performance, I guess I have the options to

• upgrade CPU to 9950x

• get a GPU

• try a cloud machine

I'm not keen on just buying a machine with a 9950x to see how much better it will be due to the cost, and my suspicions that it might only give me 50-100% improvement.

From reading on GPUs I might only get 2-5x improvement, but those articles were with different cpus and older GPUs.

I'm not an expert on the cloud, and am worried about potential costs and complexity.

What is a good workflow to identify to best way forward for me?

*Tags: Performance, Strategies*

---

**thambie1** - *15:16:34*

Fitting your models once for production doesn't sound that expensive. Doing it over and over again while iterating on your models may be. Find a way to iterate on your models without training all of them fully. Can you train and analyze just 10% of your models?

*Tags: Deployment, Strategies*

---

**Ralegh** - *22:09:31*

Easiest way is use a large EC2 spot instance, you can  100+ cores and 1TB of ram for 1-2£/hour

*Tags: Deployment*

---

## 2024-08-25

**Ralegh** - *09:43:42*

My workflow is store everything in S3, then just write a few python/bash scripts to install all requirements and download the data i need, if the output is fitted model then you can just upload back to S3, boto3 is fine for that

*Tags: Getting Started, Strategies*

---

**Ralegh** - *09:45:28*

Bit of hassle first time but worth it, there’s a few awkward things with AWS like you need to add a security group to enable ssh and I think you need an IAM thing set up for S3 

*Tags: Getting Started, Deployment*

---

## 2024-08-26

**Unknown** - *14:27:51*

Racehorse Success Secret: Gut Bacteria in Foals Could Predict Future Champions!



A recent Nature article examines how the gut microbiome of young racehorses influences their future health and athletic performance. Researchers found that foals with higher gut bacterial diversity at one month old were less likely to develop respiratory diseases and performed better in races up to three years old. Conversely, antibiotic exposure in the first month reduced microbial diversity, increased disease risk, and negatively impacted racing success. These findings highlight the importance of early gut health in determining long-term outcomes.



For more details, you can read the full article here: [https://www.nature.com/articles/s41598-024-64657-6](https://www.nature.com/articles/s41598-024-64657-6)

*Tags: Performance*

---

## 2024-08-28

**birchy** - *20:53:34*

We're in very different leagues. I still run simulation and model training on a $20 Lightsail instance. And only yesterday, I coded up a burst capacity monitor using boto3 to put my process to sleep when I've hammered the server and need to wait for some more credits to build up. :grinning:

*Tags: Deployment, Strategies*

---

**Rob** - *22:25:53*

The 9950 benchmarks somewhere towards double the 3950x, so I'd expect you're right about the speed up you'd get. After that you're pretty much in threadripper territory, if you don't want to cloud.



Obviously don't know what you're doing, but I tend to just do as much as I can in a reasonable amount of time. Most ML stuff has diminishing returns (e.g. you can build a model that's 98% as good in 1/100th of the time), but sometimes you need the extra performance.

*Tags: Performance, Strategies*

---

**Rob** - *22:44:08*

a few guesses...



• if you're building lots of models because you're segmenting upfront (e.g. a separate model for close to the off vs the day before) I'd try skipping this and building a model across all segments (e.g. include time before the off as a feature), as ML models can do a good job of replicating this segmentation

• if you're building lots of models because you're trying lots of hyperparameters, there are bayesian methods that should find the optimal set faster

*Tags: Feature Engineering, Strategies*

---

## 2024-08-29

**Jonjonjon** - *19:03:36*

It's the first reason that you suggested

 I'm segmenting up front for both long and short term models. I'll try what you suggest and see what happens...

*Tags: Strategies*

---

## 2024-09-02

**D C** - *10:57:41*

Can anybody please explain to me the value of placing BSP bets. I recognise it may come across as a stupid question, but what value do people get from using it? You don't know what it will be so it appears that you can't use it for fundamental based approaches. It seems to be overall 0EV (from what I hear - correct if wrong) so can't see much value there.

At a push I can only think of 2 useful situations:



1. People with large positions pre-off using it as a last resort hedge in case of internet outage etc.

2. Because it is 0EV using it to churn turnover to reduce PC

Can anyone explain to me in easy to understand terms what I am missing here and how it is conceivable theoretically to obtain any value from it?

*Tags: General Technical*

---

**D C** - *11:14:32*

So this would require some decent modelling/estimation of what SP will actually be at calculation?

*Tags: Strategies*

---

## 2024-09-03

**D C** - *16:52:25*

[@UNQGKT0CR](@UNQGKT0CR) but if you had a fundamental model, surely you'd be better off just monitoring the market and trying to get matched +EV during the market evolution? Whichever way I look at it I just can't see what type of customers see SP betting as attractive (aside from the previously mentioned  0EV hedge to reduce variance in P&amp;L)

*Tags: Strategies*

---

**D C** - *16:58:50*

OK [@US2RWCWKY](@US2RWCWKY) I think your last point is the one that makes sense to me. Finding situations where you suspect the BSP bet is +EV - despite not knowing what the price is. I think this is where my mental block is. It just feels strange to be betting without knowing what price you will get. But if you've established situations where you know/suspect that regardless of what you end up with, it will be +EV then I see the appeal. Now I can just wrap my brain up in knots trying to think about how you would go about that problem.

*Tags: Strategies*

---

## 2024-09-04

**D C** - *12:06:24*

I have done this and if I ever turn up to one of these meets I can tell you of my own horror story with these RNG money drainers. Never had what I'd describe as a rock bottom problem but they did very negatively impact on my life and finances. I say "they did" but the reality of it is that it was me that was the problem. In truth, if they didn't exist I would not have HAD a problem but I refuse to blame anyone other than myself for my problems and that is where I deviate from the philosophy of the anti-gambling grifters out there.

*Tags: General Technical*

---

**Michael** - *13:29:03*

Obviously it's up to you ([@UUE6E1LA1](@UUE6E1LA1)) to frame the problem you had in whatever way you find most helpful. That said; I think it's possible to adopt a middle ground which both accepts personal responsibility and recognises that people (including oneself) are subject to manipulation by others. I certainly don't absolve the gambling industry of the harm it causes, nor even wholly myself.

*Tags: General Technical*

---

**D C** - *13:38:53*

Oh I agree and I don't absolve the industry of the harm it causes completely. But ultimately we do things we know we shouldn't or that will have a negative impact and ultimately that lies with the individual. Having said all that, if I were to place blame anywhere I would place it with credit card companies. Obviously it is very specific to my case, but the way these companies make it so so easy to just borrow more is disgraceful. Not sure if it still happens now, but every time I would near my credit limit, the companies would increase it by a couple of grand - without notice and not at my request. It is a complex setup because if I were not already heavily gambling to reduce my debt, I would never have made use of that extra credit and so the situation just got worse and worse until I reached the point of saying enough was enough. Strangely, it was taking out a Wonga payday loan that provided the biggest wake up call and I got myself straight after that point (after several years).

The strangest thing for me though is that the only issue I would have was with RNG games - never with sports betting and it really irks me that the UKGC refuse to distinguish between these types of betting. That said, many are able to play them for entertainment and suffer no problems at all so it really is a complicated issue.

*Tags: Getting Started, Strategies*

---

**thambie1** - *13:43:10*

That begs an interesting question [@UGV299K6H](@UGV299K6H). Do you think what we do, automated betting, causes harm? You seem to imply it at the end there

*Tags: Strategies*

---

**Michael** - *16:47:07*

[@U01DCR5PXDY](@U01DCR5PXDY) I have mixed feelings about it. I think people should be free to gamble and most people who gamble do so without it causing a problem, framed that way my conscience is clear. On the other hand; BF has exploited some of its vulnerable customers in ways that I think are wholly wrong and I can't deny that I am part of the mechanism of that exploitation.  Then again - virtually everything I do causes harm at some level, even if it's just the general harm of consumption. Overall I'm more occupied by the guilt of my environmental footprint than by that of my involvement in betting.

*Tags: Strategies*

---

## 2024-09-06

**Sam G** - *21:41:22*

Sorry guys, i realise i missed this one a few days back. Would love to attend the next one - is it fixed on October 15th now ? Thanks again [@U012XF5CNPN](@U012XF5CNPN) [@US2RWCWKY](@US2RWCWKY)

*Tags: Errors Debugging*

---

## 2024-09-13

**Paul** - *14:20:46*

I was listening to Nate Silver’s latest book, and as predicted he’s drifting like a boat :slightly_smiling_face:, but the other night I got to the point where he was talking about slots advantage players, and it actually does sound like there is +EV strategy lurking in there, just not widely known. Some of the podcasts I listen to (Risk of Ruin for example), sometimes cover video slots APs who seem to make a decent living with much less risk than Blackjack card counting, and with less variance than poker (even cash games), so I do wonder if I’m just being a prig about it. Silver made the point that many players don’t even want to win (sirens going off, staff coming over to shake your hand, becoming the centre of attention, etc.), which is indicative of a problem to me. But it does seem winnable as a form of gambling with the right approach (casino machines with particular payout mechanics, knowledge of the games themselves, etc.). Not my thing (haven’t the patience to spend 10 hours trawling around checking machines for a possible +EV setup), but I do wonder if it’s the approach to the game that’s the problem, not the game sometimes…

*Tags: Getting Started, Strategies*

---

## 2024-09-15

**Michael** - *11:54:21*

Sure, it's a question of balance.

*Tags: General Technical*

---

**Jonjonjon** - *14:09:01*

But at that point it just becomes a question of whether or not the individual finds it enjoyable.

*Tags: General Technical*

---

**D C** - *14:13:14*

I'd actually speculate that it might be just as big a problem for those who are profitable, get used to it, lose the edge in some way and then start chasing things.

*Tags: General Technical*

---

**ShaunW** - *14:22:13*

Automation is the antidote to problem gambling imo. Once you've found out how hard it is to find an edge using serious data/analysis etc it makes it virtually impossible to have a casual bet without seeing how futile that is.

*Tags: General Technical*

---

**D C** - *14:22:38*

I kind of have it, and in truth, I think that the affordability check stuff would help. I keep a larger (and fairly constant) bank than I really need, but if that disappears, I won't be depositing again. I'd like to think that if I even lost half of it I'd cash out but in truth would probable let it ride. I'd never get away with depositing the funds to claw that bank back.

*Tags: General Technical*

---

**ShaunW** - *15:57:55*

In that example [@UPMUFSGCR](@UPMUFSGCR) the risk was always £90 for that very reason. Tech is famously falable and it's naive to assume the worse case scenario won't occur, especially if you're betting 247.



But I'd hope not thinking about that risk adequately would be a one time error, and as such it might not be a reason to stop. Unless you do it twice.

*Tags: Errors Debugging, Strategies*

---

**D C** - *21:20:34*

Some yeah but it depends on how much data there is available. The AW tracks for instance because there are just so many more meetings and therefore more data to build a model with so I can run a per-track model for each. Do you?

*Tags: Strategies*

---

**AndyL** - *22:27:10*

I'm going to ask a really dumb question probably(!) but I keep seeing [@UQL0QDEKA](@UQL0QDEKA) posting these 1000 winners, and everyone seems to join in... So I am guessing there's some value in betting in certain cicumstances on 1000.0 (obviously!) I guess if the horse is still on all 4's it might be value???

*Tags: Strategies*

---

**PeterLe** - *23:06:47*

Well I guess I should comment as I posted the image..

My experience is that recent times are different than in previous times (ie 5-15 years ago), in previous times you could get matched easier and for larger stakes.

These days, there is usually at least one a day, I merely post them to show that they are happening. I would expect there to be at least one or two over the next couple of days. So we _know_ they will happen, but catching one is something completely different. (Although Liam did ok :money_mouth_face:)

I haven't checked all my accounts, but fairly certain I didn't get matched at high odds.

The thing that intrigued me about this one is that TPD was present and you may have thought that there was some indication, who knows.

I've always had an interest in these big priced winners...at what point does something become a 1000/1 shot?



This was one of the first wins for me :



[https://www.youtube.com/watch?v=hjb9EVY1S60](https://www.youtube.com/watch?v=hjb9EVY1S60)

I think i got matched for +£4

So to answer your question And, Yes there is value backing at 1000, but there is also value laying at 1000 too



(*edit: I may be wrong about the £4 matched on the above, I think it was on the 15:30 at Leicester 28 may 2013 )

*Tags: General Technical*

---

## 2024-09-16

**Justice** - *08:35:20*

[@UUE6E1LA1](@UUE6E1LA1) I also find that Chester is shit on the data for my strategy. Along with Lingfield. I have long since been suspicious of the way TPD calculate the distance to the finish based on the running line. I notice strange anomalies in races where horses run wide etc.

*Tags: Strategies*

---

**Justice** - *08:38:38*

I don't have access to those files otherwise I would. [@UGV299K6H](@UGV299K6H) Perhaps it's a coincidence then, I just get frustrated with how often my model is making poor decisions due to errors in the data. Though I suppose if it was that good they wouldn't have made it available :joy:

*Tags: Errors Debugging, Strategies*

---

**D C** - *08:38:51*

I have to admit that when I watch "replays" of the race GPS feed I often witness unexplained lateral (as in perpendicular to current velocity vector) movement that is not apparent in a video replay of the race. But measurement error has always occurred and in all honesty I do think it has improved.

*Tags: Errors Debugging*

---

**D C** - *08:46:50*

I think if you're dealing with fundamentals [@U01PJ5YMFBJ](@U01PJ5YMFBJ) then it makes sense to factor in the environment. I'm no tennis modeller, but I'd imagine that clay court stats for a player are less impactful than grass courts when modelling wimbledon prices.

*Tags: Strategies*

---

**D C** - *08:55:43*

Biggest problem for me [@UGV299K6H](@UGV299K6H) is the dropout issue. It's not an issue in a money loss sense, more of missed opportunity sense.

*Tags: General Technical*

---

**Justice** - *09:00:14*

[@U4H19D1D2](@U4H19D1D2) Sadly I knew nothing about automation or machine learning back then so didn't make use of it- opportunity missed for sure

*Tags: General Technical*

---

**D C** - *09:07:25*

[@U05N9773A23](@U05N9773A23) to echo the advice I was given by someone on here when I first signed up: "you don't need machine learning".

*Tags: General Technical*

---

**liam** - *10:35:13*

Agreed, I have found the more you try and do with the data the worse it gets, keep it as raw as possible, there are going to be errors but considering you are against users who are betting almost blind it doesn't really matter

*Tags: Errors Debugging, Strategies*

---

## 2024-09-17

**D C** - *18:36:26*

Anyone having problems with GPS at Newcastle tonight? 2 races in and I've not placed a bet yet.

*Tags: General Technical*

---

## 2024-09-18

**PeterLe** - *12:11:52*

By the way, I noticed in the BA forum that the TPD data via BA is now transmitted indicating whether a transponder has been mis assigned (ie to the wrong horse) and also some other errors

We dont get this via Betfair direct

*Tags: Errors Debugging*

---

**Unknown** - *12:18:11*

> To provide the definitive detail regarding TPD transponder / data errors. Below is the flow of the messages, from the data provider, Gmax,to the Bet Angel platform.

> 

> With regard to what Bet Angel displays :-

> When an "Assignment" warning occurs, the Pars Chart and the Real-time Map show a Red banner saying "Transponder Assignment Error"

> 

> When any other warning occurs, an Orange banner is displayed on those screens saying "TPD Warning: " + the warning string itself. I.e. currently 'Clock' or 'Field'.

> 

> For the Automation Conditions, Bet Angel does not distinguish between Clock & Field, they are both treated as 'Data Accuracy Warnings'. The Transponder Assignment Error can be tested individually in an Automation Condition.

*Tags: Errors Debugging*

---

## 2024-09-19

**Joe** - *19:23:04*

Problems like R4 the wrong horse and unsuspending would usually be fixed by voiding bets that occurred in the false future then undoing and redoing R4. But the general principle of rolling back a market to a previous state then voiding out the false future should always be applied.

*Tags: Errors Debugging*

---

**Joe** - *19:37:04*

Anyway the principle was always to void out false futures to avoid all these problems with expo, so if it is really happening we need to tell BF.

*Tags: General Technical*

---

## 2024-09-21

**Mo** - *15:26:56*

I think the term microservices is overused but one advantage of separating out different parts of the system to individual components unlike flumine’s monolithic architecture is that restarting specific components to pick up new config can be a lot less painful than restarting the entire system 



I have considered config file watching in the past; you could alternatively implement an API that lets you modify your internal state (as well as read it - facilitates monitoring and other GUI applications)

*Tags: General Technical*

---

**TT** - *18:20:36*

If you are using flumine and aws could you just store them in ssm parameter store and poll it periodically with a worker?

*Tags: Deployment*

---

## 2024-09-23

**Joe** - *12:46:14*

It will show as percentage of a single core by default, moreover depending on what threading model you are using if you are running multiple threads in say java they will be grouped under one entry by default, so it will display the sum of the child process cpu usage as a percentage of a single cpu even though it will be spread over many cpus concurrently.

*Tags: Strategies*

---

## 2024-09-25

**Jonjonjon** - *00:23:11*

What sort of performance boost when backtesting with Flumine, did people get when upgrading to python 3.11?

*Tags: Performance*

---

**Rob** - *20:55:32*

I imagine this is something stupid I'm doing, but the `event_id` values in the historic data I just scraped have 9-digits and those obtained from `market_book.market_definition.event_id` in flumine have 8-digits, so if anyone could point out the obvious flaw....

*Tags: General Technical*

---

## 2024-09-26

**PeterLe** - *13:02:38*

Just wondered if anyone has been using o1-preview...

Worth a look if you haven't used it before

Im finding it is generating 400+ lines of code for me (Zero errors) and enabling me to do this I could only dream about 6 months ago

(Revisiting my ML journey, when time permits)



Also finding the answers are much more comprehensive, providing alternates and things to consider etc

*Tags: Errors Debugging*

---

**foxwood** - *15:26:14*

Ooh - didn't know that was there. Will have to try that and revisit some of the threads that "failed". Interesting that 4o can now look across all threads which should help but not seen evidence of that yet. Even so, have found 4o much better lately but it is making me lazy - I switch languages a lot so asking chat for silly stuff where I can't be bothered to check the docs for correct syntax lol

*Tags: Errors Debugging*

---

**ShaunW** - *16:09:52*

Haven't used o1 yet but I'm finding the new 'memory' feature to be a blessing and a curse. Once it's on the wrong track it's always been stubbornly wedded to it and those errors in understanding now compound across conversations.     I'm closing some convos with 'don't commit this to memory' because of it. The memory feature also raises new privacy issues imo.

*Tags: Errors Debugging, Feature Engineering, Performance*

---

**Newbie99** - *16:20:51*

[@UQL0QDEKA](@UQL0QDEKA) I would agree on the comprehensive aspect. The way it answers is clearer (eg outlining logic and potential alternatives).



But I find it still makes really basic errors in some cases and still goes on loops where it just repeats the same erroneous response multiple times.



So far I’m not particularly impressed with it (vs 4o) tbh.

*Tags: Errors Debugging*

---

**Newbie99** - *16:22:28*

One other thing that concerns me about all the GPT models is that if you challenge a response it almost always concedes, even if it was correct and my challenge was incorrect.

*Tags: Strategies*

---

**PeterLe** - *16:42:50*

by the way, you only get to ask 50 message per WEEK on the preview for time being, so I found it better to ask like so...

• write the code to achieve XYZ, test it, then make suggestions on how to ...etc (ie as one question rather than 3 questions)

Makes you wonder how much better this will be in six months time

*Tags: General Technical*

---

## 2024-09-30

**Paul** - *19:12:35*

&gt; One conclusion of this experiment and article is that there is little value in a crystal ball without sensible trade-sizing.

Over-betting has been mathematically been shown to guarantee ruin, even if you have +EV. If there is nothing else Kelly can give you, it’s this. Over-bet = guaranteed ruin. Doesn’t matter what the edge is, if there is variance, over-betting *will* ruin you.

*Tags: Strategies*

---

## 2024-10-02

**Paul** - *12:04:47*

I suspect a lot of people might have looked at this: are there decent fully baked models/approaches for being able to correlate time series predictions? As an example, let's suppose I have previous data for the height of a tidal river, and I wanted to understand how rainfall affects that level, I'd have a time series data set for rainfall in that area, and a time series data set from a river gauge, and I want to predict future river levels given predicted future rain, is there an out of the box method for that? I've been doing some digging around and found models for predicting a single time series, but not correlation, and some papers that talk about Pearson coefficient, but don't fancy coding them up if somebody can just say "Oh, use this library for that".

*Tags: Strategies*

---

**Leo** - *12:21:45*

Depends how you model time series. I just chuck it all In a lightgbm model and you can use lagged features of both river levels and rainfall 

*Tags: Feature Engineering, Strategies*

---

**Joe** - *12:52:47*

DTW is useful for this if I understand your question

*Tags: General Technical*

---

**Mo** - *16:32:30*

Sounds like multivariate time series analysis and you can use the vector equivalents of AR (VAR), ARMA (VARMA) and ARIMA (VARIMA) models

*Tags: Strategies*

---

## 2024-10-03

**Jonjonjon** - *09:51:39*

I think Autogluon can do that with the time series models, though I didn't like it when I tried. Didn't  [@U012XF5CNPN](@U012XF5CNPN) recommend it a while back?

*Tags: Strategies*

---

**Paul** - *17:19:29*

Autogluon is superb for a bunch of other tasks though, its first thing I reach for when facing a classic ML problem, as it knows a lot more about what makes sense than I do.

*Tags: General Technical*

---

## 2024-10-06

**D C** - *14:16:06*

This is nothing new. Race reading and horse body language courses have been around for a long time. Hunt for profit, everyone's favourite "polymath" Tony Hargraves. All the drone does is reduce your video latency. It's the same old shit, just pushing the drone angle to those who don't even realise what kind of video feed latencies are involved and how far down the food chain they actually are. Drone pics are an edge for those who know what they are looking at with horses and jockeys (not me I hasten to add) and have the patience to sit in front of a ladder and a video screen all day.

*Tags: Performance*

---

## 2024-10-07

**D C** - *10:54:22*

He has been around for years to be fair. Give it some time and they will be selling courses on how to manually trade using the GPS. Grifters have to keep up with the times after all.

*Tags: General Technical*

---

**Jonjonjon** - *18:23:23*

For people who bought property using Betfair income, was it a problem showing source of funds as Betfair?



I'm asking as a friend bought a property from employment income and had to show bank statements detailing the income to the solicitors. I'm wondering what they would say if I just had a load of "refunds" from Betfair.

*Tags: General Technical*

---

## 2024-10-08

**JL** - *10:43:14*

I wrote my own scraper for gbgb, wasn't very difficult and is ~60 lines of python code

*Tags: General Technical*

---

## 2024-10-09

**Clive** - *21:19:28*

KDB is great for huge volume streaming data - think multiple equity exchanges. Mainly used by financial institutions. It’s fantastic for massive aggregations over that data, but it has a very steep learning curve, and probably licensing costs. For betfair data I doubt you need it. 

*Tags: General Technical*

---

## 2024-10-10

**Prime** - *09:28:29*

mortgage out of the question of course. in the end, after endless paperwork and the solicitor definitely having a suspicion I was a heroin dealer, I got the fancy london lawyers we use for regulatory&tax to write them a "comfort letter". basically imagine giving your PE teacher a (real) letter from Ronaldo to let you off your lessons cos you needed to save your legs for him at the weekend. PE teacher rolls over and just signs off.

*Tags: General Technical*

---

**ShaunW** - *14:10:56*

The issue isn't the source of funds it's the likelihood it will be a sustainable.  Hence a cash purchase is no problem with your Betfair proof letter, but asking for credit might not be.

*Tags: General Technical*

---

## 2024-10-12

**Paul** - *10:40:36*

And if it does get into the media that the markets are indicating a Trump win, at least some of us will know that is not wisdom of the crowd. One thing worth learning from this is that arbs sometimes occur not because of new info being widely disseminated yet (the foundation of Kelly’s thought train on information theory), but because motives are misaligned. Market making books want to be greened up and need to move the line, some people believe their own BS, etc

*Tags: Strategies*

---

**D C** - *13:22:11*

I do wish bookies would make up their minds about whether they want to operate as RNG outfits or proper sportsbooks. The only positive in this article is that there seems to be some distinction between the two types of gambling and a recognition that RNG betting is more harmful in terms of potential addiction. Problem is that this current collection of halfwits seem intent on grabbing money from wherever they can but there really is no point speculating until this budget statement is announced.

*Tags: Strategies*

---

## 2024-10-13

**Paul** - *14:23:01*

I think if the government want to reduce problem gambling and do so in a way that protects jobs, they need to move to more heavily regulate online RNG to the point of almost making it impractical to operate. It's where most degens suffer, and at least you can point to tens of thousands of jobs supported directly with sports betting or in-person gaming...

*Tags: Strategies*

---

**Paul** - *15:29:11*

My take on it is not too far from the premise covered in [https://www.amazon.co.uk/Interception-Secrets-Modern-Sports-Betting-ebook/dp/B0CKS8GGX4/ref=sr_1_1?crid=3V8X13PPVX0S0&amp;dib=eyJ2IjoiMSJ9.rWpJIs_Gy1zJr2pM-4nqkGmV5GNE5Npr2krst8t4oyYAHRh-tyx88S1-pQeHsebQtU0ipaAqHftXXYPA8gbze8N1x9be32dRjgkSOyE4GomvmUktHTDq53aoo8a50-KQEYInDot_fdZPqjURXCxncspw4LDgXl9aHzOlHO7CBoIenKv5oc7A6_ZY81a8evFw3sb_VK80J-_5FauBF1NOuu6qcNPl45H_owT5TQGBBUY.uCKWCrPwifipksVyutW8QYay2w83z4Y7G-ltzZYKHxY&amp;dib_tag=se&amp;keywords=interception&amp;nsdOptOutParam=true&amp;qid=1728829608&amp;sprefix=interception%2Caps%2C102&amp;sr=8-1|Interception](https://www.amazon.co.uk/Interception-Secrets-Modern-Sports-Betting-ebook/dp/B0CKS8GGX4/ref=sr_1_1?crid=3V8X13PPVX0S0&amp;dib=eyJ2IjoiMSJ9.rWpJIs_Gy1zJr2pM-4nqkGmV5GNE5Npr2krst8t4oyYAHRh-tyx88S1-pQeHsebQtU0ipaAqHftXXYPA8gbze8N1x9be32dRjgkSOyE4GomvmUktHTDq53aoo8a50-KQEYInDot_fdZPqjURXCxncspw4LDgXl9aHzOlHO7CBoIenKv5oc7A6_ZY81a8evFw3sb_VK80J-_5FauBF1NOuu6qcNPl45H_owT5TQGBBUY.uCKWCrPwifipksVyutW8QYay2w83z4Y7G-ltzZYKHxY&amp;dib_tag=se&amp;keywords=interception&amp;nsdOptOutParam=true&amp;qid=1728829608&amp;sprefix=interception%2Caps%2C102&amp;sr=8-1|Interception) - most of these companies are going thin and broad because that's what their customer want/need. That means that it is likely possible to build better models than most of these firms can attempt.

*Tags: Errors Debugging, Strategies*

---

**Paul** - *15:29:26*

You don't need to build a model for every league in every sport - they do. Their attention is divided. Because their prices are either directly tradable or start to inform exchange markets, opportunities open up.

*Tags: Strategies*

---

## 2024-10-14

**Paul** - *10:25:48*

I get that the FAQ on the betcode site says "please don't ask people to give away their trade secrets", but there is _so much material some of us will never, ever implement_ I don't see a problem with throwing it on here gratis.

*Tags: General Technical*

---

**Paul** - *10:27:37*

It isn't. It's sincere. Example: I trade a little pre-off horses. I know horses well as somebody who watches _a lot_ of racing. If somebody said to me "what ideas do you have for inplay?" I could happily list (and have listed in pubs, ask [@UBS7QANF3](@UBS7QANF3)!), ideas about how I'd break that problem down. I don't see the problem: I'm never going to implement it, they're just ideas.

*Tags: General Technical*

---

**Jonjonjon** - *10:27:54*

As I mentioned, some comments you ([@U012XF5CNPN](@U012XF5CNPN)) made a couple of years helped me. [@U010GM77S4W](@U010GM77S4W) has also made some good comments that have push cash in my bank. And of course none of us would be here without Liam's framework.

*Tags: General Technical*

---

**D C** - *11:50:13*

Surely the Benter edge stems from that hard earned data though (at least the raw edge from pricing). You could scrape racing post and apply the same statistical technique to build a model but I'd imagine it would perform poorly. I've enough confidence in that opinion to have so far not bothered doing it but who knows, maybe I've been sitting on a gold mine all this time. I know the HK racing setup is very different to racing in other countries, but I'm just talking in general - freely available generic data versus specifically formulated data requiring hundreds of man hours to get hold of is always going to lose out.

*Tags: Getting Started, Strategies*

---

**Paul** - *11:57:18*

HK is special, that’s true. And there is value in proprietary data, but I suspect lots of value in just creating 2nd or 3rd order derivatives of the data that is publicly available, you don’t need horsemen watching tape for hours on end. Most people do not - and actually do not know how to - use basic form book data properly. Some people make money regardless. To expand on this point might tread into an idea I have for sharing some ideas December I’ve been thinking about. I’ll leave it there for now… :) 

*Tags: General Technical*

---

**Paul** - *12:26:26*

Let me just drag this back to the original book that [@UBS7QANF3](@UBS7QANF3) referenced.

&gt; In an engaging, colloquial style, Cotton argues that market-inspired “superminds” are likely to be very effective compared with other orchestration mechanisms in the domain of microprediction. He presents an ambitious yet practical alternative to the expensive “artisan” data science that currently drains money from firms. Challenging the machine learning revolution and exposing a contradiction at its heart, he offers engineers a new liberty: no longer reliant on quantitative experts, they are free to create intelligent applications using general-purpose application programming interfaces (APIs) and libraries. He describes work underway to encourage this approach, one that he says might someday prove to be as valuable to businesses—and society at large—as the internet.

That is one _hell_ of a claim It also sounds quite philosophical, but I note the [https://github.com/microprediction/home|GH repo](https://github.com/microprediction/home|GH repo) has pointers to code implementations. How practical is it [@UBS7QANF3](@UBS7QANF3)? How hand wavey?

*Tags: General Technical*

---

**ShaunW** - *14:07:00*

Sharing is a way to make you examine what you're thinking (nobody wants to recommend something stupid) and only a fraction of people who look at an idea will make anything, the rest add to the pool. And if you help someone to be a winner, they'll be more likely to recommend the game to other people and most of those will be losers.   Aaaand the more you give, the more you get in return.

*Tags: General Technical*

---

## 2024-10-15

**Paul** - *00:33:27*

Given that online slots players are six times more likely to be problem gamblers than sports bettors though, I suspect government want to be quite targeted about impact.

*Tags: General Technical*

---

**river_shah** - *09:52:58*

Peter Cotton hosts informal "office" hours every week. You can just drop onto a video call and talk about quant problems. There is typically no set agenda.

*Tags: General Technical*

---

## 2024-10-16

**Unknown** - *11:13:48*

Topics for this meetup included:

• the philosophical nature of Justified True Beliefs and Gettier in the context of open discussion of "alpha"

• almost _passionate_ disagreement on the quality of Nate Silver's knowledge, beliefs, and ability as a writer

• [@U05REBJ21EC](@U05REBJ21EC) honourably deciding to test the legality of trading on crypto prediction markets in the US from the UK for the rest of us - we'll send you a file in a cake if you end up in a Supermax Lorenzo, go for it, haters gonna hate!

• is the real alpha just starting your own exchange?

• dumb ideas that seem to make money, even though they're so obvious they _have_ to be just dimes in front of a steamroller, no?

• how much to invest in smart ideas that don't seem to make money because it _must_ just be the parameter search hasn't hit yet (aka, the source of all imposter syndrome in this domain)

• whether going to Rules for dinner is worth it (probably, yes - speak to [@UBS7QANF3](@UBS7QANF3) if you wish to join)

• would horse racing be the second largest spectator sport in the UK if it weren't for Cheltenham festival?

• undocumented forbidden stake amounts at certain price points created by rounding errors

• and, inevitably, "taxes are bad mmm'kay?", as a means to get a rise out of your local Northern Labour-voting cryptosocialist (:wave:)

Next one will be in a few weeks. Probably. I dunno. You figure it out.

*Tags: Errors Debugging, Strategies*

---

**Paul** - *18:30:59*

[@UPMUFSGCR](@UPMUFSGCR) it was a conversation about how some stake amounts can’t be used because of rounding errors that should only really apply because of you adjusting at very short odds. I have definitely hit rounding errors causing bet rejections in some scenarios.

*Tags: Errors Debugging*

---

**Jonjonjon** - *19:11:23*

Yes there's a specific error code for that. I think the rule is that the bet will be rejected if you'd get over 20% extra edge from it.

*Tags: Errors Debugging*

---

## 2024-10-18

**D C** - *21:40:59*

At the risk of adding to the pedantry, is it not the case that probabilities are variable over time, but that we are only able to approximate it within some degree of accuracy depending on what information we are privvy to at the time? And as there are lots of differing amounts of information that certain subsets have access to, the approximations are (very likely) very different to each other. It's an extreme case but a jockey who decides to throw a race and not tell anyone else effectively ensures that the probability that the horse wins is zero. We are all churning data to identify the outcome probabilities but the jockey's info is superior to everone else's. Of course as a human, he/she may subsequently change their mind about throwing the race up to a point at which it becomes too late. But there is just some information we can't ever have access to and so our models are always inaccurate (isn't there some quote along the lines of all models are incorrect but some models are useful). But the probability remains precise.

I've always thought of it along quantum mechanical lines where each eigenstate probability can vary over time up until the measurement is made (result has it's outcome) at which point state vector collapses onto the eigenstate represented by the observed value (projection postulate I think it was called?)

As people who build models, all we can do is approximate based on repeated measurement data from similar historic events? The probabilities are always precise - it's just we can't ever know for sure how far away our approximations are and we have to rely on longer term averages to show that prices/ implied probabilities match up with observed data frequencies.



I've had some beer and I feel I may regret this post in the morning.

*Tags: Strategies*

---

## 2024-10-20

**liam** - *20:23:39*

Tbh I don’t personally don’t have an opinion because I have no idea how to accurately price a market like this however the fact the price hasn’t been ‘corrected’ certainly says something 

*Tags: General Technical*

---

## 2024-10-22

**D C** - *15:52:08*

If you place a large back bet on an inplay market with a largeish inplay delay (question motivated by cricket markets specifically), market moves against you (BPE is active) and you get fully matched at a higher price than asked for . Is there any way to get hold of the individual price portions that you get matched at? Stream only returns an average price matched and the size. I've not used listCurrentOrders for a long time but does that have some option that would allow you see the breakdown in matched portions at each price band?

*Tags: General Technical*

---

**D C** - *17:38:40*

But once market is closed listMarketBook is not useable? Sorry if I'm being thick - I've become over-reliant on the stream and forgetting how to do it the old fashioned way.

*Tags: General Technical*

---

## 2024-10-23

**D C** - *11:20:23*

[https://www.totalperformancedata.com/triplesdata-and-total-performance-data-merger-talks-end/](https://www.totalperformancedata.com/triplesdata-and-total-performance-data-merger-talks-end/)



I'm a bit confused by this - I thought they had already merged? Leaves me wondering how this affects any future access to GPS tracking for AUS racing.

*Tags: Performance*

---

**liam** - *19:47:01*

Yeah that just leaves lots of questions 

*Tags: General Technical*

---

## 2024-10-29

**Jonjonjon** - *11:07:03*

Has anyone with a successful pre-off racing strategy attempted to sell it as a tipster service?

*Tags: Strategies*

---

**Justice** - *11:09:44*

Why would you want to do that unless your strategy isn't making money?

*Tags: Strategies*

---

**Jonjonjon** - *11:14:27*

Suppose I have a strategy that makes around £100 per month, placing £2 bets on UK horse racing on the morning of each race. The strategy is hard to scale. Maybe I can just sell it instead, by publishing the signals at the same time as I execute? I'm not claiming it'll be good value for the punter, but it won't really be worse than anything else out there.

*Tags: Strategies*

---

**Mo** - *11:24:22*

You ask the weirdest questions 

*Tags: General Technical*

---

**Ralegh** - *17:45:57*

I can’t imagine a strategy that’s hard to scale but that you could tip for? If it’s hard to scale then there’s limited liquidity ie other people couldn’t put the bet on (alternatively it’s super low sharpe but i assume from £2 bets that the variance isn’t that high)

*Tags: Strategies*

---

**Jonjonjon** - *17:59:11*

The strategy won't be great. But tipsters don't sell good tips.

*Tags: Strategies*

---

**Alex A** - *21:05:51*

Yeah, I guess for popular votes you can kind of cancel opposite side polling errors errors out across states in a way you can’t for the actual election.

*Tags: Errors Debugging*

---

## 2024-10-30

**Paul** - *19:49:16*

If it’s a coin toss (which I accept might be a big “if”), Kelly says 9% of bank is max bet (because Kamala is priced with a 9% edge over evens true odds). It seems unlikely the polls are so wide of reality that Fredi is Kelly optimal at that position size unless his bank runs to 9-10 figures. Occam’s razor to my mind says either: it’s nowhere near a coin flip and polls are a mess; the market won’t settle based on actual result (see comments from [@U05L8PZD2FM](@U05L8PZD2FM)), and Fredi is pricing in a coup of some sort here; or, there is a whale in a hot -EV mess skewing prices. I’m not sure which is true but I think public polling is likely closer to reality than being 10% out towards Harris - the error bars can’t be that wide.

*Tags: Errors Debugging, Strategies*

---

**Paul** - *19:57:23*

By saying Fredi can’t be Kelly optimal I’m assuming he has &lt;1% edge at those prices (I can’t accept he has a whole lot more without us diving into absurdity). So it’s either -EV, it’s +EV and he’s insanely rich (Musk/Bezos/Zuck levels), or there is something else going on like a market that won’t settle “right”

*Tags: Strategies*

---

## 2024-11-01

**Jonjonjon** - *19:25:42*

Under correct operating procedures, and assuming no errors on Betfair's behalf, is it possible for a greyhound to be removed after BSP has been reconciled?

*Tags: Errors Debugging*

---

## 2024-11-03

**D C** - *18:00:44*

Anyone having serious stream problems?

*Tags: General Technical*

---

## 2024-11-06

**Michael** - *07:21:00*

Ok I'll start then shall I? I think laying Trump was the right bet based on the information we had, but I think there are words to be eaten about the performance of the market, and I did say that the confidence being expressed was not well founded.

*Tags: Performance*

---

**Paul** - *08:52:06*

There was EV backing Harris at 2.5. The margin of victory is within error bars for polling, if you factored that in, the smart bet was to back Harris or lay Trump. Just because somebody was right in picking a winning bet, it doesn’t mean they got value. Keep doing that over and over again and eventually you’ll get ruined.

*Tags: Errors Debugging*

---

**Michael** - *10:15:08*

I mean if you added "Maybe" to the start of that sentence then you'd have a good case, but you didn't, so you're just repeating the error.

*Tags: Errors Debugging*

---

**Paul** - *13:36:46*

As to wider ramifications, if I did fiscals I’d now start to think about:



• Short US interest rates and the dollar - they’re gonna need to drop interest rates in the next few years to counter the tariff hit, and I think Euro will take a stronger roll as a reserve currency in next couple of years as the 2025 project picks up steam

• Go long oil - ME war will now escalate under US diplomatic cover of “not our problem, you lot figure it out”, which likely leads to Israel, Iran and Saudi all side eyeing each other with nukes by 2030

• Short anything touching Eastern Europe - or “Russia” as it’ll be known in 5 years

• Go long anything that helps EU biz/public sector get away from US tech - they’ve been paranoid for years, it’ll now accelerate, fast.

I’ve seen a lot of bad take reactions to a lot of elections, and mine might be one in itself, but I don’t see a realistic scenario as to how this doesn’t end up in a US economy fucked by import tariffs, genocide in Gaza &amp; West Bank spilling into Lebanon (and dragging Iran and Saudi in), and Russia pushing a mountain of North Korean bullet fodder towards Kyiv and Warsaw… 

*Tags: General Technical*

---

**Gooat** - *13:42:38*

Yeah that's my problem with him or just generally, I'd like to know I was wrong rather than just variance

*Tags: General Technical*

---

**Paul** - *13:43:59*

If it turns out the polls were systematically wrong through sampling error I’ll hold my hands up and say we shouldn’t have used them to establish an EV reckoning. It’s not obvious that’s the case, only that they weren’t correct. The cause of that is still an unknown. Think we’ll have the answer by early next year.

*Tags: Errors Debugging*

---

**Paul** - *13:45:41*

I had no reason to think polling, 538’s analysis or any other data source would be this wrong. Even the partisan republican polls seem off. If it didn’t sound hysterical and unhelpful I’d raise the question of fraud in Trump’s favour: it’s on the edge of the error bars, but not quite outside them.

*Tags: Errors Debugging*

---

**Paul** - *13:46:59*

So fine, I came out flat, I felt I had EV, I went to bed last night thinking it was much closer than it turned out to be, but it’s within the errors of margin of polling and my bet was EV. :shrug: 

*Tags: Errors Debugging*

---

**Gooat** - *13:49:55*

So pre votes what would now say was fair value?



Sorry Paul our messages dropped at the same time. 



Just trying to work out my mental model for low frequency events, do I adjust my pre held beliefs/pricing or hodl.

*Tags: Strategies*

---

**Paul** - *13:55:22*

[@U80AMMRKP](@U80AMMRKP) 1.9ish - polling put him slightly ahead. We did not have data to support shy Trump voter, sampling error, whatever else is uncovered as influencing in weeks and months to come. You can only make the call with the info you have. It’s the problem with this sort of betting, you deal with incomplete information, you are managing variance in an unknown distribution, this isn’t dice, roulette or even poker where you can do the maths with absolute or high degrees of confidence. It’s judgement you can add to with more information. I’d ask where is the additional info that made sense to price in that polymarket did price in? I’m not sure it exists. I’m not certain, but in my judgement, with the information available last week, Harris backers had EV, Trump backers didn’t… 

*Tags: Errors Debugging, Strategies*

---

**Paul** - *16:00:10*

I'd argue that the EV comes from the fact there were hundreds of polls that had been analysed, weighted and shifted based on multiple orgs approaches - including, most famously, 538's analysis  - that showed a coin toss was a reasonable summation of all the public source information to hand. It wasn't a single poll and a single market and everyone just going "the poll is wrong", it was tens of millions of dollars worth of data analysis that produced an indication and a model. It's a single market event, but not a single data point.

*Tags: Strategies*

---

**Gooat** - *16:25:33*

I should probably come to the next drinks to ask these questions

*Tags: General Technical*

---

**Alex A** - *22:15:38*

To the people saying Nate Silver is clearly wrong, this outcome (Trump winning all seven swing states) was literally the most likely outcome of his model for the past month. His final forecast had either candidate with a 50% chance of winning, which isn’t the same as expecting them to both get exactly 50% of the vote.

*Tags: Strategies*

---

**Alex A** - *22:19:05*

He did have some election night model thing going last night which was admittedly shit, but I assume everyone is talking about his pre-election forecasting.

*Tags: Strategies*

---

## 2024-11-07

**Derek C** - *09:46:00*

Going long oil after a Trump win is an interesting strategy. I would have gone the opposite way, based on likely increases in US production and Trump’s previous involvement with the Abraham accords. Time will tell.

*Tags: Deployment, Strategies*

---

**Paul** - *09:58:48*

I wasn't looking at Nate's work. I was looking at a bunch of analysis, but mostly 538 which he founded _but has no involvement in any more_. It's owned by ABC News, and uses methods that he started work on back in 2006-2008, but has been iterated on an improved every year since. I've been saying consistently that the result falls within the published error bars, just at the edge of those bars. The polling was skewed off to the left for reasons unknown (it now seems to be a mixture of "shy" Trump voters and sampling errors - again - which means like a good Bayesian next cycle I'll accept that information to update my prior), meaning those who skewed the market hard to the right were on this occasion correct, but given the public information known at the time, creating EV opportunities for those of us willing to be counter-parties.

*Tags: Errors Debugging*

---

**Bert Raven** - *11:11:34*

538, the silver bulletin, etc represent the public information as much as the racing post probably represent the public information for a horse race. if the bsp was massively different to the RP forecast on lots of volume I think most of us would on balance conclude that there might be a crazy owner who's really stupid, orr someones got a better model than the RP or better information.

*Tags: Strategies*

---

**George** - *11:14:32*

I am personally active in politics and political campaigns in the UK. The "shy Tory" - or in this case "shy Trump" effect is very well known in these circles. It has played out in most (perhaps not all, but definitely most) UK election polls in the last 40 years.



I don't know why polling companies haven't learnt their lesson, but they haven't. People lie, and they lie in a fairly systematic way (the effect size varies over time but the direction generally does not).



I have no doubt that there were +EV bets to be made on this election, but they could only have been made by someone who has very carefully studied the "shy" effect with data, and I suspect very few of us here have. Theo did, and his data gave him confidence that his bets were +EV, so he placed them - probably he got the Kelly staking wrong but the EV was there.



The idea that Harris was +EV at 2.x based on "the available information" is highly likely to be wrong (though I admit I cannot be 100% of this, having not studied the data in detail) because the available information included a long and predictable history of exactly this sort of polling error.

*Tags: Errors Debugging, Strategies*

---

**Dave** - *14:32:23*

Fwiw, if you consider something to have odds of a coin toss, it may also mean that your model/forecast is no better than a coin toss (i.e. you got no alpha, as opposed to strong alpha that is confident it is indeed a coin toss)

*Tags: Strategies*

---

## 2024-11-13

**Jonjonjon** - *21:51:58*

It could help to add liquidity. Some of the P&amp;L screenshots people post on the WSB reddit are crazy. Would be nice if some of them could throw some of their spare cash into the racing markets.

*Tags: General Technical*

---

## 2024-11-15

**Jonjonjon** - *23:23:21*

If I wanted to start using docker with Flumine, is there a base image I should start from?

*Tags: General Technical*

---

## 2024-11-16

**James** - *00:26:44*

I just use python debian.



```FROM python:3.11-bookworm```

I was running Alpine for slimmer images and faster deployments but I found the convenience of debian just worked better for me.

*Tags: Deployment*

---

**Jonjonjon** - *07:49:19*

Do you use docker to build a python env that is consistent with your deployment? I've been trying to read into that.

*Tags: Deployment*

---

**James** - *23:55:25*

Yeah I write my code locally on mac, and run my logic testing debugging locally. For my sims I use docker compose and run it in a container that mirrors my deployed.

*Tags: Errors Debugging, Deployment*

---

**James** - *23:56:42*

Caveat here though is a lot of my stuff is pre play or not massively latency sensitive so I haven’t had to push it too much.

*Tags: Performance*

---

## 2024-11-17

**Dave** - *13:53:52*

Thinking of updating my local box (which I use for backtesting), which may mean moving from the older to newer CPU in this comparison. [https://cpu.userbenchmark.com/Compare/Intel-Core-i7-4700MQ-vs-Intel-Core-i7-13650HX/2727vsm2049566](https://cpu.userbenchmark.com/Compare/Intel-Core-i7-4700MQ-vs-Intel-Core-i7-13650HX/2727vsm2049566) Any ideas how I can guage how much of a performance bump I can expect? The latter CPU is just one I've pulled from an arbitrary top of line performance laptop. I believe most of my backtesting is cpu-bound and not io-bound.

*Tags: Performance*

---

**thambie1** - *14:41:20*

P.S. I'm not using flumine. So my experience is based on my own code base. But I will say, very happy I made the switch.

*Tags: General Technical*

---

**Lee** - *15:14:03*

It sounds like you are looking for some rough numbers so can give you my comparisons just to get an idea.

I have a very old 4 core 8 thread i7 and a fairly old 12 core 24 thread ryzen. The ryzen is around 5-6x faster for me running the same flumine backtest.

*Tags: General Technical*

---

**Jonjonjon** - *15:48:07*

Would Flumine use P cores or E cores or both, on an Intel chip?

*Tags: General Technical*

---

**Paul** - *17:19:20*

macOS is a BSD unix under the hood, which I would contend, on many points is > Linux. Performance/$ the M4 is in a different class to anything you can run Linux (or Windows) on, and even if the Mach microkernel scheduler was crap and BSD sockets were in your way a bit, you’re probably going to end up still ahead than you would on a similarly priced PC, if you’re CPU bound. GPU bound, things get different.

*Tags: Performance*

---

**Paul** - *17:29:30*

Just checked, the stats I saw were adjusting for power consumption as well. Raw performance you might be better off with Xeon or Ryzen, but your power consumption will be much higher and I think the SKU price will be higher (the Mac tested here is a $600 complete system, including RAM, storage, PSU, etc): [https://www.phoronix.com/review/apple-m4-intel-amd-linux/5|https://www.phoronix.com/review/apple-m4-intel-amd-linux/5](https://www.phoronix.com/review/apple-m4-intel-amd-linux/5|https://www.phoronix.com/review/apple-m4-intel-amd-linux/5)

*Tags: Performance*

---

**Paul** - *17:38:33*

Under the hood, macOS is one of the best OSes out there. Open source package management via homebrew is better than anything else I've used elsewhere, everything "just works" due to vertical integration - no driver hacking - it's a solid stack. And while people say Apple is expensive, weirdly, for the new Apple Silicon stuff it's actually remarkably cheap for that performance level...

*Tags: Performance*

---

**Jonjonjon** - *18:10:00*

Omg. I had thought apple stuff gave poor performance/$. I guess I was wrong.

*Tags: Performance*

---

**Derek C** - *19:04:42*

I just got an M4 macbook pro and the performance is phenomenal.

*Tags: Performance*

---

**James** - *20:19:33*

Nah, the plugins might help but it’s not needed. I just use the CLI.  Feel free to fire through any questions if you get stuck. 

*Tags: General Technical*

---

**Clive** - *21:43:28*

The new mini is nice, but you don’t get much memory without forking out for it. The m4 in it is very very good - especially for single core performance. 

*Tags: Performance*

---

## 2024-11-18

**D C** - *11:56:24*

That's a shame if so. I was actually intending on coming to the last meet as I was unable to make the Xmas event but I anticipated that election modelling would dominate proceedings and I have less interest (and nothing to contribute) in that area than I do in medieval basket weaving and so I decided to leave it. Had I realised that the shelf life was going to be so limited on these things I would have shown up.

*Tags: Strategies*

---

## 2024-11-19

**D C** - *20:04:28*

A generic question about flumine (probably for [@U4H19D1D2](@U4H19D1D2)) - in terms of if you ran it just to record market data, what is the design behind the data flow? Is it blocking socket inside a thread? If so, are file writes threaded out or batched in some way? Just asking as I'm thinking of porting my nodejs stuff (all asynchronous JS event handlers) to C++ and use threading. Really wondering what is best from a design POV. My first instinct is blocking socket and thread safe queue of strings that are periodically written to file to avoid the socket listener code getting blocked with file I/O.

*Tags: General Technical*

---

**liam** - *20:10:19*

flumine is using bflw for the socket handling so you can read that code as it’s relatively simple python, this runs in a single thread and the data is pushed straight into the flumine main queue. flumine then picks this up and writes to disk. 



As you describe I/O has the potential to block, especially in python so the data is pushed straight into a FIFO queue as soon as possible. 

*Tags: General Technical*

---

**liam** - *20:17:25*

Yeah it uses a mutex / thread lock, I imagine the code would look very similar in c if not cleaner 



[https://github.com/python/cpython/blob/1c0a104eca189a932e0b44ca9bef46cce3d0b801/Lib/queue.py#L40|https://github.com/python/cpython/blob/1c0a104eca189a932e0b44ca9bef46cce3d0b801/Lib/queue.py#L40](https://github.com/python/cpython/blob/1c0a104eca189a932e0b44ca9bef46cce3d0b801/Lib/queue.py#L40|https://github.com/python/cpython/blob/1c0a104eca189a932e0b44ca9bef46cce3d0b801/Lib/queue.py#L40)

*Tags: General Technical*

---

## 2024-11-22

**D C** - *15:30:46*

On the Betfair mobile app, is anyone else unable to view their current bets (android app) ? I can see settled orders and multiples but current placed bets tab just hangs indefinitely. Had this problem for about a week now - anyone else?

*Tags: General Technical*

---

## 2024-11-23

**James** - *09:32:42*

What health checks have you built into your Flumine containers/deployments?

*Tags: Deployment*

---

## 2024-11-30

**Unknown** - *08:45:40*

Any chance this match is fixed? My guess it will be 3-3. Implied prob of > 50% for 3-3 most of the match??

*Tags: Errors Debugging*

---

## 2024-12-14

**Paul** - *15:15:38*

This feels like the wrong way to think about it. Kelly tells you what your stake should be relative to your bank factoring in edge and odds. Overbet, you die. Underbet, you plod, but don’t die.

*Tags: Strategies*

---

**Jonjonjon** - *15:42:05*

I'm one of the green brigade. So not sure if Kelly applies. Please don't flame me. :fire:

*Tags: Strategies*

---

**Unknown** - *17:08:57*

[@UPMUFSGCR](@UPMUFSGCR) I get your point, feeling exactly the same at the moment, this is a new football strategy 3 month "backtest", went live 3 days ago and then starts going off a cliff!!

*Tags: Deployment, Strategies*

---

**thambie1** - *17:25:18*

A big reason to not accept large drawdowns, is that it makes it hard to differentiate variance from a strategy that for one reason or another is no longer working (bugs, changing market conditions, etc). These days my max drawdown is ~6% of annual profits

*Tags: Errors Debugging, Strategies*

---

**Unknown** - *17:52:01*

Obviously market/event specific but in betting markets your concern should be optimising stake for liquidity / market impact. 



To answer your question any sort of drawdown that is outside of ‘normal’ should immediately make you question the impact you are having on the market. I am not sure what you are doing but it is very rare that you can simply 10x your bankroll (if that is what you are implying / concerned about) 



With my strategies it’s a case of thinking outside the box in order to increase turnover / profit, ie. can you scale horizontally 

*Tags: Strategies*

---

**AndyL** - *18:17:56*

When you say backtester what do you mean, a python plot class?

*Tags: General Technical*

---

**Jonjonjon** - *18:57:51*

[@U01PJ5YMFBJ](@U01PJ5YMFBJ) the scenario in your chart is what always scares me and makes me scale back. So far things have ironed themselves out but I wonder whether or not I should have just held on. There's always a chance that scaling back helped it to recover.

*Tags: General Technical*

---

## 2024-12-16

**Unknown** - *08:12:24*

Morning, its an interesting way to think about things. I know [@U4H19D1D2](@U4H19D1D2) posted this before and been meaning to test one of my strats (live production)

Id be interested to gain your opinion Liam. (this is in play 2seconds forward)

Ill need to check the scale of the EV, but it looks like im not placing many -ev. (On the cricket image you posted on the Ba forum it could be seen that the -ev bets had a minus PL so i assume you worked to strike these out?)

*Tags: Deployment*

---

**PeterLe** - *08:29:05*

Yep i thought that what ever point I enter on the bet (eg mid point) I should also use that for the future price too.

I would have thought 2 secs would be about right (in the thick of the action ie volatile), but Ill play around with this..

I think I need to alter the code as the graph i posted is both back and lays and im only calculating ev one way (so it can show -ev for a lay bet when it fact it is postive)...TBC



OK i see what you mean now on the cricket graph :+1:

I think I should be able to roll this out to other sports too...

Interesting though.. thanks for sharing Liam



Edit:

Now corrected the code and it does show a downturn on the negative side of ev (Still profitable overall and a good strat but could be a great one...)

One thing I though was useful was to plot the cumulative profit (back and lays) against ev as we have been doing, but to also plot the two sides too on the same graph.

I could quickly see that one side was having a bad effect on the overall PL...just need to fix that and then this time next year Rodney...:grinning:...

*Tags: Errors Debugging*

---

**Michael** - *09:52:18*

Just to return to the original question for a moment - I need a response stronger than :100: for [@U4H19D1D2](@U4H19D1D2)'s comment above (with the hand drawn diagram). I couldn't agree more with the summation:

_"any sort of drawdown that is outside of ‘normal’ should immediately make you question the impact you are having on the market"_ Outsized drawdown or increased volatility is always a bad sign and usually indicates over-staking.



Just to add something: Is a 10X increase realistic? That's really asking for trouble, especially for someone who's been playing for a long time.

*Tags: General Technical*

---

## 2024-12-18

**liam** - *16:44:51*

I assumed it was just a click bait title but questionable claims 

*Tags: General Technical*

---

## 2024-12-19

**Michael** - *12:44:19*

I think the shorthand that probability "quantifies the likelihood of X event" is unhelpful and confusing to a lot of people.

*Tags: General Technical*

---

**Ralegh** - *22:44:36*

Not that debugger is a new trick

*Tags: Errors Debugging*

---

## 2024-12-20

**Dave** - *09:44:18*

There was a lot of commotion around his election probabilities, and a lot of noise from the dude such as "I ran 80,000 simulations and Kamala won in 50.1% of them, the odds are really as close as you can get!". He got trolled a lot on twitter over that. Why - well if your model says "it's gonna be a coin flip" then maybe your model is just not good (except he kinda failed to see that).

*Tags: Errors Debugging, Strategies*

---

**D C** - *10:29:06*

I think the premise is basically kelly staking applied to multiple bets - rather like your own implementation. That was the reasoning behind my purchase anyway but hopefully there will be more in there too.

*Tags: Strategies*

---

**D C** - *12:06:20*

I have this problem with Taleb [@U012XF5CNPN](@U012XF5CNPN). The bloke is an absolute c*** and I refuse to read anything he writes or has written. I might miss out on some useful stuff but I absolutely loathe him. Arrogance is the worst human trait there is IMO and he reeks of it. I REALLY struggle to separate the artist from the art - which is definitely a shortcoming of mine.

*Tags: General Technical*

---

**Paul** - *12:39:25*

Berry's book reminds me a bit of Patrick Veitch's book. When Veitch appeared on Luck on Sunday a year or two back he was squirming in his seat as he talked about it. Too much "lifestyle" and showing off, not enough about showing he was actually a hard working analyst who had to make his own way because nobody else was going to help him. I wonder if Caan Berry will ever either a) get to Nick Luck's Sunday morning sofa or b) show anywhere near the same level of self-awareness

*Tags: General Technical*

---

**D C** - *13:18:07*

What is best practice here for the following situation:

You have thought of something that you want to discuss and ask a question. You wish to neither appear like an imbecile, nor accidently "leak alpha", nor piss on someone's parade by highlighting something that might be profitable already for others here. How do you proceed?

*Tags: General Technical*

---

**Mo** - *13:19:05*

Ask the question and to hell with the consequences

*Tags: General Technical*

---

**Dave** - *13:25:55*

Yes I have Fortunes Formula on my wishlist - I delayed getting it as I read it's mostly just about the application of Kelly in various scenarios/anecdotes?

*Tags: Strategies*

---

**Paul** - *13:32:51*

We are all idiots at some stuff, and expert at others. If this place isn't to help everyone get better at the bigger picture, it's just a place for people to post stack traces and for [@UBS7QANF3](@UBS7QANF3) and [@U4H19D1D2](@U4H19D1D2) to ask for sample code before it's pointed out they're missing a dependency. Fuck that.

*Tags: General Technical*

---

**Paul** - *13:32:58*

If you're super cautious, ask someone you trust via dm, and instead of asking the question, ask them how to ask the question better...

*Tags: General Technical*

---

**Paul** - *13:35:24*

Fortune's Formula is the story of how Kelly criterion came to be, taking in a narrative via Shannon and Thorpe. It's a great read. I re-read it every few years as it's just well written. His other books have some great stuff in too, but not _quite_ as strong, IMO

*Tags: Strategies*

---

**D C** - *13:52:57*

Just for clarity I suspect my question will fall into slot a) - me appearing an imbecile. It is actually something I can do a little bit of digging into first though so I will do that first.

*Tags: General Technical*

---

**liam** - *14:21:49*

Can you ask the question without the context? I do this a lot and is normally a very simple question but always starts an interesting discussion 

*Tags: General Technical*

---

**Johnnb** - *19:26:20*

I've been working my way through the python version of the ISL book for a while and found it pretty useful.

[https://www.statlearning.com/](https://www.statlearning.com/)

*Tags: General Technical*

---

**D C** - *20:29:52*

I was only joking [@UPMUFSGCR](@UPMUFSGCR) - I can't help myself with these things I am afraid. I loathe the course/ebook sellers

*Tags: General Technical*

---

**D C** - *20:30:29*

You're a 50% PC payer. Caan Berry should be paying you to teach him how to make money.

*Tags: General Technical*

---

**D C** - *21:18:38*

I recently got my betdaq reactivated and API usage granted. I was sent some truly shocking documentation - not just the SOAP API but there was also something with JSON which looked like a rudimentary sort of stream (all very amateurish with shocking docs). I implemented some of the SOAP stuff with the view of just throwing some simple strats in those markets to test the water. But people sitting at a ladder on variable refresh rates , possibly using polling updates are surely going to miss some price changes? That said, no excuse for Betdaq to not be able to either find an error or produce the paper trail evidence for why those bets were matched without BPE as it appears.

Either way think I will steer clear until they update that thread with a satisfactory explanation.

*Tags: Errors Debugging*

---

**birchy** - *23:27:52*

I haven't scraped bookies in recent years, but it was often easier to look at mobile/app/lightweight versions of the websites, e.g. [https://mobile.bet365.com|https://mobile.bet365.com](https://mobile.bet365.com|https://mobile.bet365.com). Spoofing a 'dumb' or older user agent often helped as it changed the content format. Also worth considering none-uk versions of the site.

As a general question, how delayed are aggregation sites like oddschecker, etc?

*Tags: General Technical*

---

**Paul** - *23:47:01*

I work _a lot_ with GenAI models. It's been my life for 18 months now. I can't talk about a lot of what we do, but it's cutting edge (we were doing RAG and GraphRAG within weeks of respective papers being published), and I get to work with applied and research scientists with PhDs in this space, trying to push the envelope, many of whom are getting papers selected for major confs and journals.



My 2p: I doubt this has applicability to this domain right now. It's getting there, directionally this is promising, but the fact you're going to need 2 orders of magnitude more money to go from 75.7% to 87.5%, and that higher number is still basically useless for a lot of things you can do for a lot less money with humans means I'd hold back on the excitement for now.

*Tags: Strategies*

---

**Paul** - *23:56:11*

I ~know~ strongly suspect that they're over-fitting a bit to ARC-AGI and AIME style problems. The coding capabilities are trained on competitive programming problems which aren't really like real world problems you and I care about.

*Tags: General Technical*

---

## 2024-12-27

**AndyL** - *21:56:32*

blimey, and I sniff at £40 a month on AWS servers !

*Tags: Deployment*

---

## 2024-12-28

**AndyL** - *10:11:53*

Thanks [@UUE6E1LA1](@UUE6E1LA1) yeah see what you mean 

Football im leaving as is at the moment as I don’t think I have enough data yet, ive just got one live football strategy i am leaving running for the moment 

*Tags: Deployment, Strategies*

---

## 2024-12-30

**Alex A** - *10:55:22*

Monzo have just decided to close my account I use to withdraw my winnings, after asking me some questions. Can anyone recommend a bank who aren’t bothered by frequent deposits from Betfair?

*Tags: General Technical*

---

**Jonjonjon** - *12:20:51*

Have people had problems with the more traditional banks? I've been withdrawing for years to a well known high street bank and have had no issues.

*Tags: General Technical*

---

**Mo** - *12:36:51*

Never had a problem with NatWest 

*Tags: General Technical*

---

**Dave** - *12:55:39*

What questions did Monzo ask?

*Tags: General Technical*

---

**Paul** - *13:44:02*

Of course we know this isn't laundering. It's such an exceptionally rare activity though (money normally goes only one way with betting operators), it's always going to be a little hard to convince a regular customer service agent that while it walks like a money laundering duck and talks like a money laundering duck, it's actually legit...

*Tags: Errors Debugging, Strategies*

---

**Paul** - *16:11:59*

In the same issue there is a tragic letters page contribution from a woman whose son committed suicide after being preyed on by US books "VIP'ing" him into a $10k NHL bet that he chased. Having red misted myself years ago, I honestly think it's all about trying to buy happiness, and so I don't have a problem with spending limits myself. All part of the same mix.

*Tags: General Technical*

---

**Jonjonjon** - *23:57:19*

Has anyone had problems withdrawing from Betfair to a Revolut card?

*Tags: General Technical*

---

## 2024-12-31

**liam** - *10:11:08*

This is cool, I currently use bitbar for todays pnl/exposure/ec2 instances etc. But I could imagine this showing far more although not sure it would help focus 



[https://x.com/usetrmnl|https://x.com/usetrmnl](https://x.com/usetrmnl|https://x.com/usetrmnl)

*Tags: Deployment*

---

**Jonjonjon** - *10:26:06*

Ah I looked into Barclays and they have free Apple TV. Guess I'll have to apply for that later. Thanks Liam. Do people here think it's likely to be a problem if I open a Barclays account just to receive Betfair income and then deposit it into Vanguard? I've had a Barclays SIPP for over 10 years.

*Tags: General Technical*

---

## 2025-01-06

**Paul** - *09:21:20*

Not relevant to your question, but there may also be glitches in the machine for that course. Weird markets last night at Sam Houston. I was watching them live. There would be huge delays (fine, BAU, US racing often delays as they wait for the betting pools to fill up), and the markets would turn to treacle (nothing matching), and then the market would be voided. And then again on the next and on the next. I assumed adverse weather meant a cancelled meeting but noted the races had actually run. Settled down by about 22:00 UTC.

*Tags: Deployment, Strategies*

---

**Mo** - *16:01:12*

Saw this paper "Maximizing Betting Profitability Through Predictive Modeling in European Football: A Feature-Driven Approach" shared on LinkedIn: [https://drive.google.com/file/d/1XOwLye3mxIyVEbFA1KrKbYOpYd0Lcloy/view](https://drive.google.com/file/d/1XOwLye3mxIyVEbFA1KrKbYOpYd0Lcloy/view)

*Tags: Feature Engineering, Strategies*

---

## 2025-01-10

**Unknown** - *18:22:26*

Quick Question please..(Sorry a simple question to those who know :grinning:)

Horseracing GPS feed...If i look at the marketstream like so (first image):

and want to match it to the racestream for the same race, I take it it uses the 'mid' field from the racestream?

(Appreciate that in the images they are different marketids, just trying to undertand the principle so i can edit my code)

Thanks in advance

*Tags: General Technical*

---

**liam** - *18:24:43*

I thought you were using flumine for this?

*Tags: General Technical*

---

**liam** - *18:32:16*

You will need a dummy strategy that has a market filter subscription with the markets you want 

*Tags: Strategies*

---

**liam** - *18:32:26*

But flumine does all the hard work for you 

*Tags: General Technical*

---

**PeterLe** - *18:40:28*

Ah I see



GPT explained that for me:

Yes—*if* Flumine is calling your `process_sports_data` method and passing in a valid `market` object, it means Flumine has already recognized that sports-data (“raceSubscription”) update *belongs* to one of the markets it’s tracking. In other words, Flumine does the internal ID matching (the RaceStream `'mid'` vs. the strategy’s `'market_id'`).

When It “Just Works”

In many cases (particularly UK racing), Betfair’s `'mid'` from the RaceStream *matches* the `'market_id'` in the MarketStream. Flumine will say:

• “I see a sports-data update for `'mid' = 1.23456...'`.”

• “I have a known Market object for `'market_id' = 1.23456...'`.”

• “So I’ll call `process_sports_data(market, sports_data)` with that Market object.”

That’s why in `process_sports_data`, you can trust `market.market_id` is the same ID Betfair used in `'mid'`. So you can store the GPS data under `self.gps_data[market_id]` safely.

When You See “Market Not Present for Sports Data”

This arises if Betfair sends `'rcm'` messages with a `'mid'` that *does not* match any Market object Flumine is currently tracking. In that scenario, Flumine logs something like *“Market not present”* or doesn’t call your `process_sports_data` for that `'mid'`. That mismatch usually happens if:

1. You’re subscribed to additional markets/venues (like US or Irish racing) that come through the same RaceStream feed but you aren’t actually “watching” them in your `market_filter`.

2. You see the RaceStream `'mid'` is slightly different (e.g. `'1.23456...'` in RaceStream vs `'1.23457...'` in MarketStream). Rare, but it can happen.

Bottom Line

• *Yes*, if `process_sports_data` is being invoked with a valid Market, you essentially have “correctly mapped” RaceStream data to that Market.

• If you ever see a mismatch (`"Market not present..."`) in the logs, that means Betfair sent RaceStream data for an `'mid'` Flumine does not recognize as an active Market object. That’s the scenario where you’d either *ignore* that data (since you’re not betting on it) or implement a “mapping” workaround if you suspect Betfair’s `'mid'` and `'market_id'` differ.

In most standard UK racing setups, you *won’t* need a custom mapping. Flumine’s built-in logic does the ID match automatically, and you’ll receive `process_sports_data(market, ...)` calls whenever the RaceStream `'mid'` matches your `'market_id'`.



...and on the dummy strategy:



Exactly—Flumine can subscribe to multiple data streams (Market and Race) simultaneously, and it handles the matching between those streams under the hood. The “dummy strategy” approach is one way to ensure you’re actively subscribing to all the right race data (the so-called raceSubscription stream). Meanwhile, your main strategy can use the same feed (or a separate feed) to place bets.

Why a “Dummy Strategy” Sometimes Helps

• *Two different filters*: You can run one strategy (the “dummy”) with a market filter that explicitly subscribes to certain markets or events, possibly with a custom sports data filter. This dummy strategy may not place bets but ensures Flumine is pulling in the RaceStream data for those markets.

• *Another strategy* (the “main” strategy) can also see that same data (or a subset) and perform the actual betting logic.

In practice, though, *a single strategy* that sets both:

```python





market_filter=streaming_market_filter(...),

sports_data_filter=["raceSubscription"],```

often suffices. Flumine will then:

1. Identify your target markets (via `market_filter`).

2. Subscribes to the race data (via `sports_data_filter=["raceSubscription"]`).

3. Calls `process_sports_data(market, sports_data)` with the correct *`market` object* whenever Betfair’s RaceStream updates arrive.

4. Calls `process_market_book(market, market_book)` whenever MarketStream updates arrive for that same market.

If Betfair provides matching IDs for both Market and Race streams (which is usually the case for UK/GB markets), you get the “best of both worlds” without needing an additional “dummy” subscription.

That said, if you see mismatches or logs complaining “Market not present for sports data,” using a “dummy strategy” (or broad filter) can force Flumine to track _all_ possible markets, thereby capturing RaceStream updates even for those you don’t necessarily plan to bet on. Then your real strategy can “cherry-pick” from that data.

In Short

• *Yes*, Flumine does the heavy lifting once you tell it which markets (`market_filter`) and which data feed(s) (`sports_data_filter`) you want.

• You _can_ use a dummy strategy to ensure you subscribe to as many RaceStreams as you want, but it’s not strictly necessary if your single strategy is set up with the correct filters and streams.

• Typically, you only need a second “dummy” strategy if the streams you want to subscribe to are intentionally more encompassing than what your main betting strategy handles. If all you need are your main markets plus the RaceStream for them, a single strategy does the job

Thanks Liam, I understand now

*Tags: Getting Started, Strategies*

---

## 2025-01-12

**PeterLe** - *10:42:01*

Morning

I'm going to set up a new Ubuntu instance on AWS

I currently have a 20.04 instance but see that there are later version available

Is 24.04 LTS the one to go for (I assume its fine with Flumine etc)?

Thanks

*Tags: Deployment*

---

**D C** - *11:40:47*

I personally see no value in sticking with an older LTS (although I don't use flumine) but if that wors for you then do it. When setting up new instances I just go with the latest LTS version then install whatever is needed on top of that and tweak any things that needed tweaking and go from there. You might get a few SSL issues that need resolving (I think I did when moving up from 20.04) due to having "older" BF cert files but I'd say it's worth sticking with the latest if you are setting up something new. I should be honest though and say that other than an initial update on a fresh install, once things are running I don't run updates as that requires restart usually.

In general I like to run the same OS on AWS as I am doing my dev work on and that's always going to be latest LTS ubuntu. Might review that if AWS start offering other linux flavours in future though.

*Tags: Getting Started, Deployment*

---

**PeterLe** - *11:43:21*

Thanks DC all that makes sense, Ill go with the latest

thanks for the help

*Tags: General Technical*

---

**D C** - *11:43:56*

Might be wise to see what a flumine user says though as I have no idea how compatible that is going to be?? I'm sure you'll be fine but I have no knowledge in that area.

*Tags: General Technical*

---

**Mo** - *13:30:24*

I created a new 24.04 instance recently for my personal strategies which are run through flumine and no issues

*Tags: General Technical*

---

## 2025-01-13

**D C** - *16:37:25*

Definitely some here use containers. I just build my application binaries locally, upload to AWS target and run using tmux. My current use case doesn't require anything more complicated than that.

*Tags: Deployment*

---

## 2025-01-18

**Paul** - *12:46:00*

Bull does an interesting piece in this on staking systems I might write up for the blog. It’s before Kelly, obviously, and it’s kind of funny but he’s working his way there a little…

*Tags: Strategies*

---

**Paul** - *13:36:11*

Obvious questions are: what variable, (or variables)? How well does that method perform? And given we are no longer constrained to ledger book entries noting the takeout in pounds, shillings, and pence, but are armed with a magical device that can do billions of calculations a second, is there a better way?

*Tags: General Technical*

---

**Paul** - *13:42:05*

There’s a section in Art of Legging I’ll share later which describes what you’re suggesting [@U01PJ5YMFBJ](@U01PJ5YMFBJ) - leaves a few open questions as an exercise for the reader… :)

*Tags: General Technical*

---

**Unknown** - *17:41:23*

Quick question please: What signals an error in the Racestream (ie Transponder incorrectly assigned etc)

is it the "warn" field?  (I guess anything other than a 0 denotes an error?

(I couldnt find it in the dev docs)

Thanks

*Tags: Errors Debugging*

---

**Mo** - *17:48:17*

Would be lovely to see you. Three big factors you've completely ignored:



1. How to apply margin

2. What about stake sizing

3. How do you manage inventory

*Tags: General Technical*

---

**AndyL** - *20:30:27*

1. So "margin" I thought is the difference from a selection "my book price" and "bookmaker price" ? not sure how that affects "my book price" ?

2. Staking methods/size is to do with whether you trade an opportunity "flat" stake, "kelly..", "liability",...?

3. "inventory" not sure what that means in this context? sounds like "managing a set of active trades" ?

*Tags: Strategies*

---

**Leo** - *22:48:59*

[@U05N9773A23](@U05N9773A23) can you get the historical data that way ?

*Tags: Data Quality*

---

## 2025-01-19

**D C** - *12:22:32*

In crude terms, if you were modelling, you'd get outcome probabilities, calculate "fair" price, then make them more shit (to the punter) by applying margin to those prices (making them shorter). How you spread the margin across the runners though is down to the bookie - and they may (or may not) adjust prices based on weight of punter money. Genuinely sounds like you could do with reading a basic book on betting [@U01PJ5YMFBJ](@U01PJ5YMFBJ) to get a firmer grip of this stuff. It may not be necessary but you'll get a more detailed explanation of things.

*Tags: Strategies*

---

**D C** - *12:26:58*

I only became aware of this change because Liam posted here the details (probably lost on the slack history). Not sure if you are/were in the same boat as me but I was not on the "update" emailing list so I contacted Neil and he added me and sent the up to date documentation

*Tags: General Technical*

---

**PeterLe** - *12:30:16*

Yes I saw it on the betangel forum initially (Liam probably saw it there too)

Would you mind send me the documentation please rather than me ask Neil?

*Tags: General Technical*

---

**D C** - *12:32:48*

In my last job I was reading "Fixed Odds Sports Betting" by Buchdahl when I had to get involved with applying and removing margins - it definitely had a section on that stuff somewhere. Probably any basic book on sports betting will do although some of them use more American terms (and odds format which I hate) which can be confusing.

*Tags: Errors Debugging, Strategies*

---

## 2025-01-20

**Justice** - *09:05:25*

A lot of the points are post race points that I would like to plug into a pre-race model. But only 2 years of back history and the possibility of look-ahead bias makes it of little use to me. My models are all very data hungry

*Tags: Strategies*

---

**D C** - *11:52:39*

Right I see, you have to go to "My Betfair Account" to get to accountsummary to get the page that has the Expert Fee link. All other options off that "My Account" seem to provide a base page without it. Thanks chaps at least I know how to get to it now!!

*Tags: General Technical*

---

## 2025-01-22

**river_shah** - *08:16:49*

Love this model: [https://chat.deepseek.com/](https://chat.deepseek.com/). We are going to have o3 levels of intelligence all open source (o3 is likely just o1 with far more inference time compute)

*Tags: Strategies*

---

**Paul** - *15:00:33*

One of my favourite exercises for these llms in this context is to ask it to give me a flumine strategy for market making while managing overall liability and skew, and then I spend a few minutes looking at the result and spotting all the leaks and estimating how fast it would lose money. GPT-4 produced a solution that would lose a sizeable bank within an hour on UK racing. This one, actually might be flat. Not much needed to get it a little above flat. Impressive. 

*Tags: Strategies*

---

**Justice** - *15:34:42*

My model backed 1,000 in that race due to a data error so I got excited for a minute... But no luck, it was the 3rd :joy:

*Tags: Errors Debugging, Strategies*

---

**Mo** - *15:35:20*

```I have added these parameters and there's been a large boost to the log-likelihood. Yet the backtest looks largely unchanged. With a significantly better model, how can this be? What should I do next to improve the model?```

*Tags: Strategies*

---

**Gooat** - *17:00:18*

This is interesting, it's an out of sample test in a way. 



I feel like current models are overtrained/perform on the popular testing suites, even after test updates. 



Do you run them through an actual backtest or just eyeball?

*Tags: Strategies*

---

**PeterLe** - *17:56:13*

[@U05N9773A23](@U05N9773A23) was there a data error on that race then? (I was wondering why i hadn't placed any bets?)

If so at least I know that is working then :grinning:

*Tags: Errors Debugging*

---

**D C** - *18:07:52*

???? Why is getting matched at 1000 a problem? I get matched at 1000 all the time?

*Tags: General Technical*

---

**Justice** - *18:11:25*

My model had the price much shorter than 1000 because the data showed it being much closer to the finish than it actually was. I actually hardly ever get dropouts or missing packets- I sub to multiple feeds and de-dupe. But I get the problems with inaccuracies all the time. I have some basic checks that act as a short circuit but only for obvious things... like runners not moving for a certain amount of time or going backwards

*Tags: Strategies*

---

**liam** - *18:12:20*

Justice, out of interest what is your average bet size? Struggling to understand why a bet matching at 1000 is a problem

*Tags: General Technical*

---

**Justice** - *18:13:55*

It isn't a problem per se... It just really wasn't a good bet in this case :joy: ~£5 but very frequently.

*Tags: General Technical*

---

**Justice** - *18:18:54*

[@UUE6E1LA1](@UUE6E1LA1) Yes true. It's more the fact my model had a much shorter price (&lt;5) which was clearly ridiculous. I admit that sometimes, just because of the nature of the price, it seems like you're wasting money

*Tags: Strategies*

---

**PeterLe** - *18:22:26*

[@U05N9773A23](@U05N9773A23) I recall you saying that you get the feed direct? I take it you have the warn field in there to show if there is a problem with the data?

*Tags: General Technical*

---

## 2025-01-23

**river_shah** - *10:09:01*

[@U012XF5CNPN](@U012XF5CNPN) Just asking programming / quant queries mostly. It also helps quite a bit with legal / finance / accounting questions which I have no expertise in

*Tags: General Technical*

---

## 2025-01-24

**Gooat** - *19:59:10*

[@U01B8031PM1](@U01B8031PM1) are you using it instead of something from openai or anthropic? Similar performance?

*Tags: Performance*

---

## 2025-01-27

**Mo** - *07:01:33*

Any recommendations on how to run DeepSeek-V3 locally?

*Tags: General Technical*

---

**Mo** - *08:33:04*

Define "spare"? I have 64 GB in total but - naive question - isn't it about the GPU?

*Tags: General Technical*

---

